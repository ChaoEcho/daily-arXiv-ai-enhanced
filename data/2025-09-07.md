<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 11]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.NI](#cs.NI) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies](https://arxiv.org/abs/2509.03525)
*Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori*

Main category: cs.CL

TL;DR: 本研究评估了在DementiaBank语料库上大型语言模型（LLM）用于痴呆症语音检测的多种适应策略，结果表明特定的微调和提示方法效果显著，并且适应良好的开源模型能与商业系统媲美或超越。


<details>
  <summary>Details</summary>
Motivation: 美国超过一半的阿尔茨海默病及相关痴呆症患者未确诊，语音筛查提供了一种可扩展的检测方法，因此需要研究如何优化LLM在语音数据上的痴呆症检测能力。

Method: 研究使用了DementiaBank语音语料库，比较了LLM的多种适应策略，包括上下文学习（采用不同示例选择策略）、推理增强提示、参数高效微调以及多模态整合。评估了九个纯文本模型和三个多模态音文本模型。

Result: 结果显示，类质心示例在上下文学习中表现最佳；推理功能改善了较小型模型；token级微调通常能产生最佳分数。为表现不佳的模型添加分类头可显著提高性能。多模态音文本系统虽然表现良好，但未超越顶级的纯文本模型。

Conclusion: 模型适应策略（包括示例选择、推理设计和微调方法）对基于语音的痴呆症检测至关重要。经过适当适应的开源模型能够达到甚至超越商业系统的性能。

Abstract: Over half of US adults with Alzheimer disease and related dementias remain
undiagnosed, and speech-based screening offers a scalable detection approach.
We compared large language model adaptation strategies for dementia detection
using the DementiaBank speech corpus, evaluating nine text-only models and
three multimodal audio-text models on recordings from DementiaBank speech
corpus. Adaptations included in-context learning with different demonstration
selection policies, reasoning-augmented prompting, parameter-efficient
fine-tuning, and multimodal integration. Results showed that class-centroid
demonstrations achieved the highest in-context learning performance, reasoning
improved smaller models, and token-level fine-tuning generally produced the
best scores. Adding a classification head substantially improved
underperforming models. Among multimodal models, fine-tuned audio-text systems
performed well but did not surpass the top text-only models. These findings
highlight that model adaptation strategies, including demonstration selection,
reasoning design, and tuning method, critically influence speech-based dementia
detection, and that properly adapted open-weight models can match or exceed
commercial systems.

</details>


### [2] [Enhancing Speech Large Language Models through Reinforced Behavior Alignment](https://arxiv.org/abs/2509.03526)
*Yansong Liu,Jiateng Li,Yuan Liu*

Main category: cs.CL

TL;DR: 本文提出RBA框架，通过强大的教师LLM自合成数据并结合强化学习，显著提升语音大语言模型（SpeechLMs）的指令遵循能力，并在多种任务上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型（SpeechLMs）在指令遵循方面与纯文本LLMs存在显著性能差距，尤其是在处理动态多变的语音请求时，这主要源于模态间的差异。

Method: 引入强化行为对齐（Reinforced Behavior Alignment, RBA）框架。该方法不依赖人工标注，而是通过一个强大的教师LLM自合成大量高质量的对齐数据，然后利用强化学习方法将SpeechLMs的行为与教师LLM进行对齐。

Result: RBA有效增强了SpeechLMs的指令遵循能力，性能优于传统蒸馏基线。此外，RBA可扩展至口语问答和语音到文本翻译等任务，仅使用自生成数据即在公开基准上取得了最先进的性能。

Conclusion: RBA框架通过自合成数据和强化学习，成功提升了SpeechLMs的语言生成能力和指令遵循表现，弥补了其与文本LLMs的差距，并在多模态任务上展示了卓越的泛化性和SOTA性能。

Abstract: The recent advancements of Large Language Models (LLMs) have spurred
considerable research interest in extending their linguistic capabilities
beyond text to other modalities, which leads to emergence of speech-based LLMs
(SpeechLMs) with capability of processing user request in either speech or
textual formats. However, owing to inter-modal discrepancies, these SpeechLMs
still exhibit a significant performance gap compared to their text-based LLM
counterparts in instruction-following, particularly when confronted with the
dynamic and variable nature of user speech. To address this challenge, this
paper introduces a framework termed Reinforced Behavior Alignment (RBA),
designed to bolster the language generation proficiency of SpeechLMs. Instead
of relying on supervised fine-tuning from human annotations, RBA employs a
self-synthesis methodology to generate extensive, high-fidelity alignment data
by a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of
a teacher using a reinforcement learning-based approach. Experimental results
demonstrate that this method effectively enhances the instruction-following
capabilities of SpeechLMs that outperform conventional distillation baselines.
Crucially, we demonstrate that RBA can be seamlessly extended to tasks such
including spoken question answering and speech-to-text translation, attaining
state-of-the-art performance on open benchmarks with only self-generated data.

</details>


### [3] [Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model](https://arxiv.org/abs/2509.03527)
*Bohdan M. Pavlyshenko*

Main category: cs.CL

TL;DR: 本文利用经过微调的Mistral 7B大语言模型结合RAG技术，对加密货币新闻进行多级别多任务分析，通过生成图文摘要和报告提供洞察，并利用知识图谱解决LLM幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 旨在对加密货币新闻进行多级别、多任务的深入分析，提供有价值的定性与定量洞察，并解决大语言模型（LLM）在信息生成过程中可能出现的幻觉问题。

Method: 使用经过4比特量化、基于PEFT/LoRA方法微调的Mistral 7B大语言模型，并结合检索增强生成（RAG）技术。分析分为多级别：第一级别生成包含情感得分的图文摘要及JSON表示；更高级别通过分层堆叠整合图文摘要及摘要的摘要，形成综合报告。通过将加密货币新闻表示为知识图谱，以消除LLM幻觉问题。

Result: 结果表明，利用微调的Mistral 7B LLM模型进行多级别加密货币新闻分析，能够有效进行信息丰富的定性与定量分析。

Conclusion: 该方法能够为加密货币新闻分析提供重要的见解。

Abstract: In the paper, we consider multilevel multitask analysis of cryptocurrency
news using a fine-tuned Mistral 7B large language model with
retrieval-augmented generation (RAG).
  On the first level of analytics, the fine-tuned model generates graph and
text summaries with sentiment scores as well as JSON representations of
summaries. Higher levels perform hierarchical stacking that consolidates sets
of graph-based and text-based summaries as well as summaries of summaries into
comprehensive reports. The combination of graph and text summaries provides
complementary views of cryptocurrency news. The model is fine-tuned with 4-bit
quantization using the PEFT/LoRA approach. The representation of cryptocurrency
news as knowledge graph can essentially eliminate problems with large language
model hallucinations.
  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM
models for multilevel cryptocurrency news analysis can conduct informative
qualitative and quantitative analytics, providing important insights.

</details>


### [4] [The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process](https://arxiv.org/abs/2509.03528)
*Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin*

Main category: cs.CL

TL;DR: 本文针对法律领域流程挖掘数据局限性问题，提出了ProLiFIC，一个利用大语言模型（LLMs）从非结构化数据构建的意大利立法流程综合事件日志，并建议其作为法律流程挖掘的基准以促进领域发展。


<details>
  <summary>Details</summary>
Motivation: 流程挖掘（PM）在法律领域的应用受到数据集可访问性和质量的限制。

Method: 引入了ProLiFIC（意大利议会立法流程），一个涵盖1987年至2022年意大利立法过程的综合事件日志。该日志通过使用大语言模型（LLMs）从Normattiva门户的非结构化数据中提取并结构化而创建。

Result: 对ProLiFIC进行了初步分析示例。

Conclusion: ProLiFIC被提议作为法律流程挖掘的基准，以促进该领域的新发展。

Abstract: Process Mining (PM), initially developed for industrial and business
contexts, has recently been applied to social systems, including legal ones.
However, PM's efficacy in the legal domain is limited by the accessibility and
quality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in
Italian Chambers), a comprehensive event log of the Italian lawmaking process
from 1987 to 2022. Created from unstructured data from the Normattiva portal
and structured using large language models (LLMs), ProLiFIC aligns with recent
efforts in integrating PM with LLMs. We exemplify preliminary analyses and
propose ProLiFIC as a benchmark for legal PM, fostering new developments.

</details>


### [5] [Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages](https://arxiv.org/abs/2509.03529)
*Alejandro Álvarez Castro,Joaquín Ordieres-Meré*

Main category: cs.CL

TL;DR: 本文提出一个新颖的多模态框架，通过将财报电话会议编码为分层话语树，并使用两阶段Transformer架构，生成语义丰富、结构感知的嵌入表示，整合了文本、音频、视频和结构化元数据。


<details>
  <summary>Details</summary>
Motivation: 现有的金融情感分析系统，即使结合了多模态信号，通常依赖于扁平的文档级或句子级模型，未能捕获财报电话会议中分层的话语结构，限制了其对复杂金融沟通的理解。

Method: 引入一种将财报电话会议编码为分层话语树的多模态框架。每个节点（独白或问答对）通过文本、音频、视频的情感信号以及连贯性得分、主题标签和答案覆盖率等结构化元数据进行丰富。采用两阶段Transformer架构：第一阶段使用对比学习编码节点级多模态内容和话语元数据；第二阶段综合生成整个会议的全局嵌入。

Result: 实验结果表明，生成的嵌入形成了稳定且具有语义意义的表示，能反映情感基调、结构逻辑和主题一致性。

Conclusion: 该方法为金融预测和话语评估等下游任务提供了实用价值，并且可以推广到远程医疗、教育和政治话语等其他高风险、非脚本的沟通领域，提供了一种鲁棒且可解释的多模态话语表示方法。

Abstract: Earnings calls represent a uniquely rich and semi-structured source of
financial communication, blending scripted managerial commentary with
unscripted analyst dialogue. Although recent advances in financial sentiment
analysis have integrated multi-modal signals, such as textual content and vocal
tone, most systems rely on flat document-level or sentence-level models,
failing to capture the layered discourse structure of these interactions. This
paper introduces a novel multi-modal framework designed to generate
semantically rich and structurally aware embeddings of earnings calls, by
encoding them as hierarchical discourse trees. Each node, comprising either a
monologue or a question-answer pair, is enriched with emotional signals derived
from text, audio, and video, as well as structured metadata including coherence
scores, topic labels, and answer coverage assessments. A two-stage transformer
architecture is proposed: the first encodes multi-modal content and discourse
metadata at the node level using contrastive learning, while the second
synthesizes a global embedding for the entire conference. Experimental results
reveal that the resulting embeddings form stable, semantically meaningful
representations that reflect affective tone, structural logic, and thematic
alignment. Beyond financial reporting, the proposed system generalizes to other
high-stakes unscripted communicative domains such as tele-medicine, education,
and political discourse, offering a robust and explainable approach to
multi-modal discourse representation. This approach offers practical utility
for downstream tasks such as financial forecasting and discourse evaluation,
while also providing a generalizable method applicable to other domains
involving high-stakes communication.

</details>


### [6] [Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts](https://arxiv.org/abs/2509.03530)
*Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 本文提出Early-SIB，一个基于Transformer的模型，用于在青少年明确表达自杀意念之前，从其在线论坛发帖中预测自杀意念和行为（SIB），并在荷兰青少年论坛上达到0.73的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 青少年自杀是主要死因之一，但难以预测且常因缺乏心理健康服务接触而未被发现。社交媒体为早期检测提供了独特机会，青少年常在线分享思想和困扰。

Method: 提出一项新任务和方法：在青少年明确表达自杀意念前，从论坛帖子中预测SIB。使用Early-SIB，一个基于Transformer的模型，顺序处理用户撰写和互动的帖子，以预测其是否会发布SIB相关内容，不使用任何自我披露作为输入。

Result: Early-SIB模型在荷兰青少年论坛上预测未来SIB的平衡准确率达到0.73。

Conclusion: 该研究表明，此类工具可以为传统的自杀预测方法提供有意义的补充。

Abstract: Suicide is a leading cause of death among adolescents (12-18), yet predicting
it remains a significant challenge. Many cases go undetected due to a lack of
contact with mental health services. Social media, however, offers a unique
opportunity, as young people often share their thoughts and struggles online in
real time. In this work, we propose a novel task and method to approach it:
predicting suicidal ideation and behavior (SIB) from forum posts before an
adolescent explicitly expresses suicidal ideation on an online forum. This
predictive framing, where no self-disclosure is used as input at any stage,
remains largely unexplored in the suicide prediction literature. To this end,
we introduce Early-SIB, a transformer-based model that sequentially processes
the posts a user writes and engages with to predict whether they will write a
SIB post. Our model achieves a balanced accuracy of 0.73 for predicting future
SIB on a Dutch youth forum, demonstrating that such tools can offer a
meaningful addition to traditional methods.

</details>


### [7] [Real-Time Detection of Hallucinated Entities in Long-Form Generation](https://arxiv.org/abs/2509.03531)
*Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda*

Main category: cs.CL

TL;DR: 提出了一种廉价、可扩展的实时幻觉检测方法，专门针对大型语言模型中的实体级幻觉，并在多模型上表现优于现有基线，具有实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在高风险应用中（如医疗、法律）出现幻觉可能造成严重危害。然而，现有的幻觉检测方法不切实际，要么仅限于简短事实查询，要么需要昂贵的外部验证。

Method: 本研究提出了一种针对“实体级幻觉”（如虚构的名称、日期、引用）的检测方法，实现令牌级标注和流式检测。开发了一种利用网络搜索进行标注的方法，以创建带有真实标签的数据集，用于训练高效的幻觉分类器（如线性探针），并成功将其扩展到70B参数模型。

Result: 研究结果显示，分类器在长文本生成中持续优于基线（例如，Llama-3.3-70B的AUC从0.71提升至0.90），并在短文本问答设置中也显示出改进。此外，尽管仅通过实体级标签训练，探针也能有效检测数学推理任务中的错误答案，表明其具有超越实体的泛化能力。团队还发现，一个模型的标注响应可用于训练其他模型的有效分类器，并已公开相关数据集。

Conclusion: 本工作为可扩展的、真实世界的幻觉检测提供了一种有前景的新方法，解决了现有方法的局限性，并展示了其在多种任务和模型上的有效性和泛化能力。

Abstract: Large language models are now routinely used in high-stakes applications
where hallucinations can cause serious harm, such as medical consultations or
legal advice. Existing hallucination detection methods, however, are
impractical for real-world use, as they are either limited to short factual
queries or require costly external verification. We present a cheap, scalable
method for real-time identification of hallucinated tokens in long-form
generations, and scale it effectively to 70B parameter models. Our approach
targets \emph{entity-level hallucinations} -- e.g., fabricated names, dates,
citations -- rather than claim-level, thereby naturally mapping to token-level
labels and enabling streaming detection. We develop an annotation methodology
that leverages web search to annotate model responses with grounded labels
indicating which tokens correspond to fabricated entities. This dataset enables
us to train effective hallucination classifiers with simple and efficient
methods such as linear probes. Evaluating across four model families, our
classifiers consistently outperform baselines on long-form responses, including
more expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for
Llama-3.3-70B), and are also an improvement in short-form question-answering
settings. Moreover, despite being trained only with entity-level labels, our
probes effectively detect incorrect answers in mathematical reasoning tasks,
indicating generalization beyond entities. While our annotation methodology is
expensive, we find that annotated responses from one model can be used to train
effective classifiers on other models; accordingly, we publicly release our
datasets to facilitate reuse. Overall, our work suggests a promising new
approach for scalable, real-world hallucination detection.

</details>


### [8] [Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck](https://arxiv.org/abs/2509.03533)
*Igor Halperin*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）存在幻觉问题，现有检测方法在主题识别上存在缺陷。本文提出UDIB方法，将确定性信息瓶颈（DIB）应用于几何聚类，通过高效近似解决了高维数据问题，提供了一种更具信息量的共享主题表示，从而显著提升了LLM幻觉的检测能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）容易产生内在忠实度幻觉（即，响应内容在语义上偏离提供的上下文）。现有的检测框架（如语义散度度量SDM）通过对句向量嵌入进行几何聚类来识别提示和响应间的潜在主题，但这些主题优化于空间邻近性而非下游信息论分析，导致其与实际分析目标脱节。

Method: 开发了一种基于确定性信息瓶颈（DIB）的几何聚类主题识别方法。通过将DIB中难以处理的KL散度项替换为计算高效的上界，将DIB转化为适用于高维数据的实用算法，并命名为UDIB。UDIB可被解释为K-means的熵正则化和鲁棒化版本，其本质上偏好数量适中且信息丰富的簇。该方法应用于LLM提示和响应嵌入的联合聚类。

Result: UDIB方法生成了一种共享主题表示，该表示不仅在空间上连贯，而且在根本上被构造为关于提示-响应关系的信息量最大。这为SDM框架提供了更优越的基础，并提供了一种新颖、更灵敏的幻觉（混淆）检测工具。

Conclusion: UDIB方法通过提供一种基于信息论的、更有效的主题识别机制，弥补了LLM幻觉检测中现有方法的不足，从而显著提升了对LLM幻觉的检测能力，为幻觉检测提供了更坚实的基础和更敏感的工具。

Abstract: Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.

</details>


### [9] [QuesGenie: Intelligent Multimodal Question Generation](https://arxiv.org/abs/2509.03535)
*Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy*

Main category: cs.CL

TL;DR: 开发了一个多模态问题生成系统，解决教育资源与练习材料不匹配的难题。


<details>
  <summary>Details</summary>
Motivation: 在信息丰富的时代，学习者虽拥有大量教育资源，但缺乏针对这些资源量身定制的练习材料，这是一个重大挑战。

Method: 开发了一个多模态问题生成系统，能自动从多种内容格式生成多样化问题。系统包含多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及端到端交互界面。

Result: 该项目为自动化、可扩展和智能的问题生成奠定了基础。

Conclusion: 该系统在资源效率、鲁棒功能和用户体验之间取得了精心平衡，有望实现高效、智能的问答自动化生成。

Abstract: In today's information-rich era, learners have access to abundant educational
resources, but the lack of practice materials tailored to these resources
presents a significant challenge. This project addresses that gap by developing
a multi-modal question generation system that can automatically generate
diverse question types from various content formats. The system features four
major components: multi-modal input handling, question generation,
reinforcement learning from human feedback (RLHF), and an end-to-end
interactive interface. This project lays the foundation for automated,
scalable, and intelligent question generation, carefully balancing resource
efficiency, robust functionality and a smooth user experience.

</details>


### [10] [AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models](https://arxiv.org/abs/2509.03537)
*Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 本研究提出AR$^2$框架，通过对抗性强化学习显式训练大型语言模型（LLM）的抽象推理能力，显著提高了LLM在复杂编程任务上的泛化准确性。


<details>
  <summary>Details</summary>
Motivation: 抽象能力是计算机科学的基础技能，对LLM的代码生成至关重要。然而，现有LLM训练方法主要关注表面模式识别，忽视了对抽象能力的显式训练。

Method: 提出AR$^2$（对抗性强化学习用于抽象推理）框架。该框架利用一个教师模型将核心问题转化为复杂叙述问题（逻辑不变），同时训练一个学生编码模型通过提取底层计算核心来解决这些复杂问题。

Result: 实验结果表明，AR$^2$显著提升了学生模型在未见过的、具有挑战性的编程任务上的准确性。

Conclusion: 抽象能力是增强LLM泛化能力的关键技能。

Abstract: Abstraction--the ability to recognize and distill essential computational
patterns from complex problem statements--is a foundational skill in computer
science, critical both for human problem-solvers and coding-oriented large
language models (LLMs). Despite recent advances in training LLMs for code
generation using reinforcement learning (RL), most existing approaches focus
primarily on superficial pattern recognition, overlooking explicit training for
abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement
Learning for Abstract Reasoning), a novel framework explicitly designed to
enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to
transform kernel problems into narrative-rich, challenging descriptions without
changing their fundamental logic. Simultaneously, a student coding model is
trained to solve these complex narrative problems by extracting their
underlying computational kernels. Experimental results demonstrate that AR$^2$
substantially improves the student model's accuracy on previously unseen,
challenging programming tasks, underscoring abstraction as a key skill for
enhancing LLM generalization.

</details>


### [11] [Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction](https://arxiv.org/abs/2509.03540)
*Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu*

Main category: cs.CL

TL;DR: 本文提出一种动态构建和扩展知识图谱（KG）的框架，在推理时结合LLM的内部知识和外部信息，以增强LLM的事实一致性。该方法在事实性问答基准上显著提升了准确性、精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）因参数记忆限制常难以生成事实一致的答案。现有的检索增强生成（RAG）方法虽引入外部知识，但将知识视为非结构化文本，这限制了其组合推理能力和事实不一致识别能力。

Method: 我们提出一个新颖的框架，在推理时动态构建并扩展知识图谱（KGs），整合LLMs提取的内部知识和外部来源检索的信息。方法首先通过提示从问题中提取一个种子KG，随后利用LLM的潜在知识进行迭代扩展，最后通过外部检索选择性精炼图谱，以增强事实覆盖率并纠正不准确性。

Result: 在三个多样化的事实性问答基准测试中，我们的方法在事实准确性、答案精度和可解释性方面，均比基线提示和静态KG增强方法展现出持续的改进。

Conclusion: 研究结果表明，在推理时构建知识图谱是增强LLM事实性的一个有前景的方向，能够以结构化、可解释和可扩展的方式提升其性能。

Abstract: Large Language Models (LLMs) often struggle with producing factually
consistent answers due to limitations in their parametric memory.
Retrieval-Augmented Generation (RAG) methods address this issue by
incorporating external knowledge from trusted sources at inference time.
However, such methods typically treat knowledge as unstructured text, which
limits their ability to support compositional reasoning and identify factual
inconsistencies. To overcome these limitations, we propose a novel framework
that dynamically constructs and expands knowledge graphs (KGs) during
inference, integrating both internal knowledge extracted from LLMs and external
information retrieved from external sources. Our method begins by extracting a
seed KG from the question via prompting, followed by iterative expansion using
the LLM's latent knowledge. The graph is then selectively refined through
external retrieval, enhancing factual coverage and correcting inaccuracies. We
evaluate our approach on three diverse factual QA benchmarks, demonstrating
consistent improvements in factual accuracy, answer precision, and
interpretability over baseline prompting and static KG-augmented methods. Our
findings suggest that inference-time KG construction is a promising direction
for enhancing LLM factuality in a structured, interpretable, and scalable
manner.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [Towards Efficient General Feature Prediction in Masked Skeleton Modeling](https://arxiv.org/abs/2509.03609)
*Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出通用特征预测（GFP）框架，通过高层特征预测而非低级重建，显著提升了自监督骨骼行为识别的效率和表示质量，并在多项下游任务中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于掩码自编码器（MAE）的骨骼行为识别方法，其重建目标通常局限于原始关节坐标或其简单变体，这导致计算冗余且语义表示能力有限。

Method: 提出通用特征预测（GFP）框架，核心创新是以高层特征预测取代传统的低级重建，这些特征涵盖从局部运动模式到全局语义表示。具体而言，该框架引入了一个协作学习机制，其中一个轻量级目标生成网络能动态地在时空层级上产生多样化的监督信号，避免依赖预计算的离线特征。此外，框架还结合了约束优化以确保特征多样性并防止模型崩溃。

Result: 在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD数据集上的实验表明，GFP框架与标准掩码骨骼建模方法相比，训练速度快6.2倍，并展现出卓越的表示质量，在各种下游任务中均取得了最先进的性能。

Conclusion: GFP框架通过创新的高层特征预测机制，成功解决了现有MAE范式在骨骼行为识别中计算效率低下和语义表示不足的问题，显著提升了自监督学习的性能和计算效率。

Abstract: Recent advances in the masked autoencoder (MAE) paradigm have significantly
propelled self-supervised skeleton-based action recognition. However, most
existing approaches limit reconstruction targets to raw joint coordinates or
their simple variants, resulting in computational redundancy and limited
semantic representation. To address this, we propose a novel General Feature
Prediction framework (GFP) for efficient mask skeleton modeling. Our key
innovation is replacing conventional low-level reconstruction with high-level
feature prediction that spans from local motion patterns to global semantic
representations. Specifically, we introduce a collaborative learning framework
where a lightweight target generation network dynamically produces diversified
supervision signals across spatial-temporal hierarchies, avoiding reliance on
pre-computed offline features. The framework incorporates constrained
optimization to ensure feature diversity while preventing model collapse.
Experiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits
of our approach: Computational efficiency (with 6.2$\times$ faster training
than standard masked skeleton modeling methods) and superior representation
quality, achieving state-of-the-art performance in various downstream tasks.

</details>


### [13] [Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge](https://arxiv.org/abs/2509.03614)
*Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Susan Done,Dimitrios Androutsos,April Khademi*

Main category: cs.CV

TL;DR: 本文提出一个基于UNet和教师-学生模型的统一框架，通过像素级分割处理有丝分裂检测和异常有丝分裂分类，并集成域泛化模块以应对域偏移和数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 病理学家手动计数有丝分裂耗时且存在观察者间差异。AI自动化检测虽有前景，但面临域偏移（不同器官、物种、染色方案导致性能下降）和数据严重不平衡（有丝分裂数量远少于正常细胞核）的挑战。

Method: 将有丝分裂检测公式化为像素级分割任务，并提出一个教师-学生模型同时处理有丝分裂检测（Track 1）和异常有丝分裂分类（Track 2）。该方法以UNet分割骨干为基础，集成了对比表征学习和域对抗训练等域泛化模块。采用教师-学生策略生成像素级伪掩膜（包括已标注的有丝分裂、难负样本和正常细胞核），以增强特征判别力并提高对域偏移的鲁棒性。分类任务引入一个多尺度CNN分类器，在多任务学习范式中利用分割模型的特征图。

Result: 在初步测试集上，该算法在Track 1（检测）中实现了0.7660的F1分数，在Track 2（分类）中实现了0.8414的平衡准确率。

Conclusion: 所提出的将基于分割的检测和分类集成到统一框架中的方法，在实现鲁棒的有丝分裂分析方面表现出有效性。

Abstract: Counting mitotic figures is time-intensive for pathologists and leads to
inter-observer variability. Artificial intelligence (AI) promises a solution by
automatically detecting mitotic figures while maintaining decision consistency.
However, AI tools are susceptible to domain shift, where a significant drop in
performance can occur due to differences in the training and testing sets,
including morphological diversity between organs, species, and variations in
staining protocols. Furthermore, the number of mitoses is much less than the
count of normal nuclei, which introduces severely imbalanced data for the
detection task. In this work, we formulate mitosis detection as a pixel-level
segmentation and propose a teacher-student model that simultaneously addresses
mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our
method is based on a UNet segmentation backbone that integrates domain
generalization modules, namely contrastive representation learning and
domain-adversarial training. A teacher-student strategy is employed to generate
pixel-level pseudo-masks not only for annotated mitoses and hard negatives but
also for normal nuclei, thereby enhancing feature discrimination and improving
robustness against domain shift. For the classification task, we introduce a
multi-scale CNN classifier that leverages feature maps from the segmentation
model within a multi-task learning paradigm. On the preliminary test set, the
algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of
0.8414 in Track 2, demonstrating the effectiveness of integrating
segmentation-based detection and classification into a unified framework for
robust mitosis analysis.

</details>


### [14] [Multi Attribute Bias Mitigation via Representation Learning](https://arxiv.org/abs/2509.03616)
*Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi*

Main category: cs.CV

TL;DR: 本文提出GMBM框架，通过两阶段方法（ABIL和梯度抑制微调）解决视觉模型中多重重叠偏差问题，并引入SBA指标，在多个数据集上显著提升了模型鲁棒性和公平性。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像中普遍存在多种重叠偏见（如纹理、水印、性别化妆等），这些偏见严重损害了现代视觉模型的鲁棒性和公平性。单独处理每种偏见效果不佳，甚至可能加剧其他偏见。

Method: 本研究提出广义多偏见缓解（GMBM）框架，一个轻量级的两阶段方法：
1.  **自适应偏见集成学习 (ABIL)**：通过为每个属性训练编码器并将其与主干网络集成，强制分类器明确识别已知捷径偏见的影响。
2.  **梯度抑制微调 (Gradient Suppression Fine Tuning)**：从主干网络的梯度中修剪掉这些偏见方向，留下一个紧凑的网络，使其忽略之前识别出的所有捷径。
此外，为解决现有偏见度量在子组不平衡和训练测试分布漂移下的失效问题，研究引入了**尺度偏见放大 (SBA)**：一种在测试时衡量的方法，用于分离模型引起的偏见放大和分布差异。

Result: GMBM在FB CMNIST、CelebA和COCO数据集上进行了验证，结果显示它显著提高了最差组准确率，将多属性偏见放大减半，并在偏见复杂性和分布漂移加剧的情况下，SBA指标达到了新低。

Conclusion: GMBM是第一个针对视觉识别领域中多重偏见问题的实用、端到端解决方案。

Abstract: Real world images frequently exhibit multiple overlapping biases, including
textures, watermarks, gendered makeup, scene object pairings, etc. These biases
collectively impair the performance of modern vision models, undermining both
their robustness and fairness. Addressing these biases individually proves
inadequate, as mitigating one bias often permits or intensifies others. We
tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a
lean two stage framework that needs group labels only while training and
minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)
deliberately identifies the influence of known shortcuts by training encoders
for each attribute and integrating them with the main backbone, compelling the
classifier to explicitly recognize these biases. Then Gradient Suppression Fine
Tuning prunes those very bias directions from the backbone's gradients, leaving
a single compact network that ignores all the shortcuts it just learned to
recognize. Moreover we find that existing bias metrics break under subgroup
imbalance and train test distribution shifts, so we introduce Scaled Bias
Amplification (SBA): a test time measure that disentangles model induced bias
amplification from distributional differences. We validate GMBM on FB CMNIST,
CelebA, and COCO, where we boost worst group accuracy, halve multi attribute
bias amplification, and set a new low in SBA even as bias complexity and
distribution shifts intensify, making GMBM the first practical, end to end
multibias solution for visual recognition. Project page:
http://visdomlab.github.io/GMBM/

</details>


### [15] [Lightweight image segmentation for echocardiography](https://arxiv.org/abs/2509.03631)
*Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver*

Main category: cs.CV

TL;DR: 开发了一种轻量级U-Net模型，在心室分割任务上实现了与nnU-Net统计等效的性能，但模型尺寸小16倍，速度快4倍，使其适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 虽然nnU-Net在超声心动图左心室分割中表现良好，但其模型过大且运行缓慢，限制了实时临床应用。

Method: 通过消融研究，系统评估了nnU-Net的数据增强方案、架构修改、损失函数和后处理技术，以识别最有效的组件。基于这些洞察，开发了一个轻量级U-Net模型。

Result: 分析显示，简单的仿射增强和深度监督是性能关键，而复杂增强和大型模型容量的回报递减。本研究开发的轻量级U-Net（2M参数）在CAMUS数据集上实现了与nnU-Net（33M参数）统计等效的性能（Dice分数：LV 0.93/0.93），且模型小16倍，速度快4倍（1.35ms vs 5.40ms/帧）。跨数据集评估也证实了其可比的泛化能力。

Conclusion: 本研究成功开发了一个轻量级、高效率的U-Net模型，其在心脏分割上的性能和泛化能力与nnU-Net相当，同时显著缩小了模型尺寸并提升了运行速度，为实时临床应用提供了可行方案。

Abstract: Accurate segmentation of the left ventricle in echocardiography can enable
fully automatic extraction of clinical measurements such as volumes and
ejection fraction. While models configured by nnU-Net perform well, they are
large and slow, thus limiting real-time use. We identified the most effective
components of nnU-Net for cardiac segmentation through an ablation study,
incrementally evaluating data augmentation schemes, architectural
modifications, loss functions, and post-processing techniques. Our analysis
revealed that simple affine augmentations and deep supervision drive
performance, while complex augmentations and large model capacity offer
diminishing returns. Based on these insights, we developed a lightweight U-Net
(2M vs 33M parameters) that achieves statistically equivalent performance to
nnU-Net on CAMUS (N=500) with Dice scores of 0.93/0.85/0.89 vs 0.93/0.86/0.89
for LV/MYO/LA ($p>0.05$), while being 16 times smaller and 4 times faster
(1.35ms vs 5.40ms per frame) than the default nnU-Net configuration.
Cross-dataset evaluation on an internal dataset (N=311) confirms comparable
generalization.

</details>


### [16] [treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds](https://arxiv.org/abs/2509.03633)
*Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner*

Main category: cs.CV

TL;DR: 提出了一种改进的无监督树木分割算法treeX，适用于地面和无人机激光扫描数据。该算法相比原版提升了精度和效率，对地面数据表现可与深度学习媲美，且资源高效。可用于林木提取及深度学习模型标注，并已开源。


<details>
  <summary>Details</summary>
Motivation: 近距离激光扫描数据缺乏高效的个体树木提取软件。深度学习虽有效但需要大量标注数据和计算资源，因此需要一种资源高效的替代方案。

Method: 提出并改进了无监督的treeX算法，结合基于聚类的树干检测和区域增长的树冠勾勒。为地面和无人机激光扫描数据分别设置了参数预设。在六个公共数据集上进行评估，并与六种开源方法进行比较。

Result: 相较于原始treeX算法，本方法运行时间更短，精度更高，地面数据F1-score提升0.11至0.49。无人机激光扫描数据F1-score达到0.58（原算法失败）。地面激光扫描数据精度与包括深度学习在内的最新开源方法相当。

Conclusion: 本方法可作为深度学习的资源高效替代方案，适用于特定数据条件下的林木提取，并可用于半自动生成深度学习模型的训练标签。已提供开源Python实现。

Abstract: Close-range laser scanning provides detailed 3D captures of forest stands but
requires efficient software for processing 3D point cloud data and extracting
individual trees. Although recent studies have introduced deep learning methods
for tree instance segmentation, these approaches require large annotated
datasets and substantial computational resources. As a resource-efficient
alternative, we present a revised version of the treeX algorithm, an
unsupervised method that combines clustering-based stem detection with region
growing for crown delineation. While the original treeX algorithm was developed
for personal laser scanning (PLS) data, we provide two parameter presets, one
for ground-based laser scanning (stationary terrestrial - TLS and PLS), and one
for UAV-borne laser scanning (ULS). We evaluated the method on six public
datasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham
Woods) and compared it to six open-source methods (original treeX, treeiso,
RayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original
treeX algorithm, our revision reduces runtime and improves accuracy, with
instance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data.
For ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original
algorithm fails to segment any correct instances. For TLS and PLS data, our
algorithm achieves accuracy similar to recent open-source methods, including
deep learning. Given its algorithmic design, we see two main applications for
our method: (1) as a resource-efficient alternative to deep learning approaches
in scenarios where the data characteristics align with the method design
(sufficient stem visibility and point density), and (2) for the semi-automatic
generation of labels for deep learning models. To enable broader adoption, we
provide an open-source Python implementation in the pointtree package.

</details>


### [17] [Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding](https://arxiv.org/abs/2509.03635)
*Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin*

Main category: cs.CV

TL;DR: 本文提出Reg3D框架，通过引入几何感知的双重监督（输入和学习目标）和重建任务，显著提升大型多模态模型在3D场景理解方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型在2D视觉理解方面取得进展，但在3D场景理解上仍面临挑战。主要问题在于现有方法依赖纯文本监督，缺乏学习鲁棒3D空间表示所需的几何约束。

Method: 引入Reg3D（Reconstructive Geometry Instruction Tuning）框架。其核心是直接将几何感知监督融入训练过程，通过重建底层几何结构而非仅描述来增强3D理解。Reg3D采用双重监督范式，将3D几何信息作为输入和明确的学习目标。具体设计了在双编码器架构内的互补对象级和帧级重建任务，以强制几何一致性并培养空间推理能力。

Result: 在ScanQA、Scan2Cap、ScanRefer和SQA3D等数据集上进行的大量实验表明，Reg3D取得了显著的性能提升。

Conclusion: Reg3D为空间感知多模态模型建立了一种新的训练范式。

Abstract: The rapid development of Large Multimodal Models (LMMs) has led to remarkable
progress in 2D visual understanding; however, extending these capabilities to
3D scene understanding remains a significant challenge. Existing approaches
predominantly rely on text-only supervision, which fails to provide the
geometric constraints required for learning robust 3D spatial representations.
In this paper, we introduce Reg3D, a novel Reconstructive Geometry Instruction
Tuning framework that addresses this limitation by incorporating geometry-aware
supervision directly into the training process. Our key insight is that
effective 3D understanding necessitates reconstructing underlying geometric
structures rather than merely describing them. Unlike existing methods that
inject 3D information solely at the input level, Reg3D adopts a
dual-supervision paradigm that leverages 3D geometric information both as input
and as explicit learning targets. Specifically, we design complementary
object-level and frame-level reconstruction tasks within a dual-encoder
architecture, enforcing geometric consistency to encourage the development of
spatial reasoning capabilities. Extensive experiments on ScanQA, Scan2Cap,
ScanRefer, and SQA3D demonstrate that Reg3D delivers substantial performance
improvements, establishing a new training paradigm for spatially aware
multimodal models.

</details>


### [18] [QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception](https://arxiv.org/abs/2509.03704)
*Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma*

Main category: cs.CV

TL;DR: QuantV2X是首个全量化多智能体V2X协同感知系统，通过端到端量化策略，在保持高准确性的同时，显著降低了计算和传输成本，提升了系统级效率、延迟和部署性。


<details>
  <summary>Details</summary>
Motivation: 现有VV2X协同感知研究主要侧重于提高准确性，但忽视了效率、延迟和实际部署性等系统级关键因素。多数系统依赖全精度模型，导致高计算和传输成本，不适用于资源受限环境中的实时操作。

Method: 提出QuantV2X，一个专门为高效可扩展的多模态、多智能体V2X协同感知部署而设计的第一款全量化多智能体系统。该系统引入了统一的端到端量化策略，涵盖神经网络模型和传输消息表示，以同步减少计算负载和传输带宽。

Result: QuantV2X在低比特约束下实现了与全精度系统相当的准确性。在部署导向指标评估下，QuantV2X将系统级延迟降低了3.2倍，mAP30比全精度基线提高了9.5。此外，QuantV2X具有更好的扩展性，允许在严格内存预算下使用更大、更强大的模型。

Conclusion: 研究结果突显了全量化多智能体中间融合系统在实际部署中的可行性。

Abstract: Cooperative perception through Vehicle-to-Everything (V2X) communication
offers significant potential for enhancing vehicle perception by mitigating
occlusions and expanding the field of view. However, past research has
predominantly focused on improving accuracy metrics without addressing the
crucial system-level considerations of efficiency, latency, and real-world
deployability. Noticeably, most existing systems rely on full-precision models,
which incur high computational and transmission costs, making them impractical
for real-time operation in resource-constrained environments. In this paper, we
introduce \textbf{QuantV2X}, the first fully quantized multi-agent system
designed specifically for efficient and scalable deployment of multi-modal,
multi-agent V2X cooperative perception. QuantV2X introduces a unified
end-to-end quantization strategy across both neural network models and
transmitted message representations that simultaneously reduces computational
load and transmission bandwidth. Remarkably, despite operating under low-bit
constraints, QuantV2X achieves accuracy comparable to full-precision systems.
More importantly, when evaluated under deployment-oriented metrics, QuantV2X
reduces system-level latency by 3.2$\times$ and achieves a +9.5 improvement in
mAP30 over full-precision baselines. Furthermore, QuantV2X scales more
effectively, enabling larger and more capable models to fit within strict
memory budgets. These results highlight the viability of a fully quantized
multi-agent intermediate fusion system for real-world deployment. The system
will be publicly released to promote research in this field:
https://github.com/ucla-mobility/QuantV2X.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 本文提出PG-Agent框架，通过将GUI操作转化为页面图并结合检索增强生成（RAG）技术，解决了现有GUI智能体难以捕捉页面复杂转换关系的问题，显著提升了智能体在未见场景下的感知和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体依赖顺序操作片段作为先验知识，未能捕捉页面间复杂的转换关系，导致其难以深入感知GUI环境并泛化到新场景。

Method: 1) 设计自动化流水线将顺序操作片段转化为显式建模页面图结构。2) 引入检索增强生成（RAG）技术，从页面图中有效检索可靠的GUI感知指南。3) 提出定制化的PG-Agent多智能体框架，结合任务分解策略，并注入这些指南以实现对未见场景的泛化。

Result: 在多个基准测试上的大量实验表明，PG-Agent即使在页面图构建所用片段有限的情况下，也能有效提升性能。

Conclusion: PG-Agent框架通过利用页面图和RAG技术，成功解决了现有GUI智能体在理解复杂页面转换关系上的不足，有效提升了其对GUI环境的感知能力和在新场景下的泛化能力。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [20] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 在部分可识别的因果模型中，由于外生变量未完全指定，无法精确计算概率，故研究计算紧密概率界限的方法。提出一种利用内生变量概率简化程序构建的新算法，并针对单一干预情况，采用列生成技术计算概率界限，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在因果模型中，当外生变量未完全指定而内生变量被观测时，无法精确计算感兴趣的概率值。因此，需要研究计算紧密的概率界限。

Method: 1. 研究准马尔可夫非循环结构因果模型中的部分可识别查询。2. 提出一种新算法，通过利用内生变量的输入概率来简化计算概率界限所需的多线性/线性程序的构建。3. 对于单一干预场景，应用列生成技术，通过一系列辅助线性整数规划计算概率界限，证明了外生变量多项式基数表示的可行性。

Result: 实验结果表明，列生成技术在计算概率界限方面优于现有方法。

Conclusion: 提出的新算法，特别是针对单一干预场景的列生成技术，为在具有未完全指定外生变量的部分可识别因果模型中计算紧密概率界限提供了一种有效且更优越的方法，并能实现更高效的计算。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [21] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Diffusion-AC的新型自主冲突解决框架，通过将扩散概率模型集成到深度强化学习中，生成多模态动作分布并结合密度渐进安全课程，有效克服了现有方法的单模态偏差，显著提升了空中交通管理中冲突解决的成功率和安全性，特别是在高密度交通场景下，大幅减少了近距空中碰撞。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习的空中交通冲突检测与解决（CD&R）方法存在“单模态偏差”问题，导致在复杂动态约束下决策缺乏灵活性和出现“决策僵局”，因此需要更灵活、鲁棒的冲突解决机制。

Method: 本文首创性地将扩散概率模型整合到CD&R任务中，提出了Diffusion-AC框架。该框架将策略建模为由价值函数引导的逆向去噪过程，以生成丰富、高质量和多模态的动作分布。同时，辅以密度渐进安全课程（DPSC）训练机制，确保在从稀疏到高密度交通环境的学习过程中保持稳定和高效。

Result: 仿真实验表明，Diffusion-AC显著优于一系列最先进的深度强化学习基准。在最具挑战性的高密度场景中，该方法不仅保持了94.1%的高成功率，还将近距空中碰撞（NMACs）的发生率比次优基线降低了约59%，显著增强了系统安全性。其性能提升源于独特的多模态决策能力，允许智能体灵活切换到有效的替代操作。

Conclusion: Diffusion-AC通过引入扩散模型实现多模态决策能力，成功克服了现有DRL在CD&R中面临的单模态偏差和决策僵局问题。这显著提高了空中交通管理系统在复杂高密度环境下的冲突解决成功率和安全性，为未来的空中交通自动化提供了新的方向。

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [22] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 本文提出并训练了一种LLM智能体的动态规划框架，使其能够灵活决定何时规划，通过两阶段训练（SFT+RL）在长周期任务中实现了更高的效率和更复杂的目标，并可受人类计划引导。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体（如ReAct）强制在每次行动前规划，但在长周期任务中，始终规划会消耗大量计算资源并导致性能下降，而从不规划则会限制其能力。因此，需要一种灵活的机制来动态分配规划计算资源。

Method: 引入了一个形式化LLM智能体动态规划的概念框架，使其能够灵活决定何时进行测试时规划。提出了一个简单的两阶段训练管道：1) 在多样化的合成数据上进行有监督微调（SFT）以初步学习动态规划；2) 通过强化学习（RL）在长周期环境中精炼这种能力。

Result: 在Crafter环境中的实验表明，使用此方法训练的动态规划智能体具有更高的样本效率，并能持续实现更复杂的目标。此外，这些智能体可以被人类编写的计划有效引导，超越其独立解决问题的能力。

Conclusion: 本研究首次探索了训练LLM智能体在序列决策任务中进行动态测试时计算分配，为开发更高效、自适应和可控的智能体系统奠定了基础。

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [23] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 针对RAG技术的不透明性问题，本文提出了KG-SMILE框架，它是一种基于扰动的、与方法无关的框架，旨在为图RAG提供令牌和组件级别的可解释性，通过识别关键图实体和关系来平衡模型效能与可解释性，最终提升机器学习的透明度和信任。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（如LLMs）虽有显著进展但仍会产生幻觉和不可验证的声明，限制了其在敏感领域的可靠性。RAG技术虽能通过外部知识提高准确性，但其本质仍是一个不透明的黑箱，且严重依赖数据质量。研究动机是解决RAG的这种不透明性，尤其是在图RAG中，以提高其在关键领域（如医疗保健）的可靠性、透明度和信任度。

Method: 开发了一种名为KG-SMILE的与方法无关、基于扰动的框架，旨在为图RAG提供令牌和组件级别的互操作性。该方法通过应用受控扰动、计算相似性以及训练加权线性代理模型，来识别对生成输出最有影响的图实体和关系，从而使RAG系统更加透明。KG-SMILE的评估使用了包括保真度、忠实性、一致性、稳定性和准确性在内的综合归因指标。

Result: 研究发现KG-SMILE能够生成稳定且符合人类理解的解释，这表明它有能力在模型效能与可解释性之间取得平衡。

Conclusion: KG-SMILE通过提供稳定、人类可理解的解释，成功地提升了图RAG的透明度和可信度，有助于平衡模型效能与可解释性，从而增强了机器学习技术的整体透明度和信任。

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [24] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: 引入CausalARC，一个基于结构因果模型（SCM）的实验测试平台，用于在低数据和分布外条件下评估AI推理，并展示其在四种语言模型评估设置中的应用。


<details>
  <summary>Details</summary>
Motivation: AI推理需要在有限数据和分布偏移的情况下适应新颖问题设置。

Method: 引入CausalARC，一个模仿抽象推理语料库（ARC）的AI推理实验测试平台。每个CausalARC任务都从一个完全指定的因果世界模型（结构因果模型）中采样。通过有原则的数据增强，以少样本、情境学习演示的形式提供观测、干预和反事实反馈。

Result: 作为概念验证，该工作展示了CausalARC在四种语言模型评估设置中的应用：抽象推理（测试时训练）、反事实推理（情境学习）、程序合成和因果发现（逻辑推理）。

Conclusion: CausalARC提供了一个有效的测试平台，用于评估AI在低数据和分布外条件下的推理能力，尤其擅长处理因果推理任务，并可用于语言模型评估。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [25] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 引入神经符号系统Embodied-LM，通过具身认知结构（基于图像图式和ASP的空间推理）提升LLMs的逻辑推理能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在逻辑推理方面表现不佳，缺乏类似人类的稳健心理表征。

Method: 提出Embodied-LM神经符号系统，通过基于图像图式（源自感觉运动经验的模式）的示意表征来建立理解和逻辑推理，并利用回答集编程（ASP）中的声明式空间推理操作这些认知结构的空间基础。

Result: 实验证明LLMs可被引导通过具身认知结构解释场景，这些结构可形式化为可执行程序，且支持有效且增强可解释性的逻辑推理。

Conclusion: 本研究为LLMs整合具身认知结构提供了计算基础，并为未来纳入更复杂动态的表征奠定了方向。

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [26] [The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric](https://arxiv.org/abs/2509.03594)
*Thomas R. Harvey*

Main category: cs.LG

TL;DR: 本文提出了一类基于损失函数黎曼度量的新型神经网络优化器，该优化器在低维示例中表现出色，并在训练神经网络时比现有最先进方法略有改进，同时具有良好的理论特性和与Adam相当的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 通过采纳损失函数在嵌入高维空间时自然产生的黎曼度量这一几何视角，开发出一种新的优化器，以期在神经网络训练中获得更有效的优化方法，并探索其潜在的理论优势。

Method: 开发了一类新型优化器，其核心是利用损失函数景观嵌入高维空间时自然诱导的黎曼度量。该方法将这种几何视角具体化。研究者将其与现有方法（包括SGD、Adam、AdamW和Muon）在一系列任务和架构上进行了比较。此外，该基本方法还可以用于修改任何现有的预处理方法。

Result: 经验证，这批新型优化器在低维示例中表现出高效性，并且在训练神经网络时比最先进的方法略有改进。理论上，它们具有理想的特性：有效学习率能在高曲率区域自动降低，起到平滑的梯度裁剪作用；其中一个变体还能诱导有效的计划学习率，并且解耦权重衰减在该几何视角下是自然的选择。其计算复杂度与Adam相当。

Conclusion: 基于黎曼度量的新型优化器为神经网络训练提供了一种有效且具有理论优势的方案。它们在实际应用中（尤其在低维场景下）表现良好，且在整体上略优于现有SOTA方法，同时保持了计算效率和修改现有方法的灵活性。

Abstract: We present a class of novel optimisers for training neural networks that
makes use of the Riemannian metric naturally induced when the loss landscape is
embedded in higher-dimensional space. This is the same metric that underlies
common visualisations of loss landscapes. By taking this geometric perspective
literally and using the induced metric, we develop a new optimiser and compare
it to existing methods, namely: SGD, Adam, AdamW, and Muon, across a range of
tasks and architectures. Empirically, we conclude that this new class of
optimisers is highly effective in low dimensional examples, and provides slight
improvement over state-of-the-art methods for training neural networks. These
new optimisers have theoretically desirable properties. In particular, the
effective learning rate is automatically decreased in regions of high curvature
acting as a smoothed out form of gradient clipping. Similarly, one variant of
these optimisers can also be viewed as inducing an effective scheduled learning
rate and decoupled weight decay is the natural choice from our geometric
perspective. The basic method can be used to modify any existing
preconditioning method. The new optimiser has a computational complexity
comparable to that of Adam.

</details>


### [27] [CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records](https://arxiv.org/abs/2509.03643)
*Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan*

Main category: cs.LG

TL;DR: CEHR-GPT是一个通用型EHR基础模型，集成了特征表示、零样本预测和合成数据生成能力，并引入时间令牌学习框架处理时序数据，展现出优异的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大多数EHR AI模型设计用于狭窄的单一任务，限制了其通用性和在真实世界场景中的实用性。

Method: 提出CEHR-GPT，一个统一架构的通用EHR基础模型，具备特征表示、零样本预测和合成数据生成能力。通过新颖的时间令牌学习框架，显式编码患者动态时间线以支持时序推理。

Result: CEHR-GPT在所有三项任务中均表现出色，并通过词汇扩展和微调有效泛化到外部数据集。

Conclusion: CEHR-GPT的通用性无需任务特定再训练即可实现快速模型开发、队列发现和患者结局预测。

Abstract: Electronic Health Records (EHRs) provide a rich, longitudinal view of patient
health and hold significant potential for advancing clinical decision support,
risk prediction, and data-driven healthcare research. However, most artificial
intelligence (AI) models for EHRs are designed for narrow, single-purpose
tasks, limiting their generalizability and utility in real-world settings.
Here, we present CEHR-GPT, a general-purpose foundation model for EHR data that
unifies three essential capabilities - feature representation, zero-shot
prediction, and synthetic data generation - within a single architecture. To
support temporal reasoning over clinical sequences, \cehrgpt{} incorporates a
novel time-token-based learning framework that explicitly encodes patients'
dynamic timelines into the model structure. CEHR-GPT demonstrates strong
performance across all three tasks and generalizes effectively to external
datasets through vocabulary expansion and fine-tuning. Its versatility enables
rapid model development, cohort discovery, and patient outcome forecasting
without the need for task-specific retraining.

</details>


### [28] [Nonnegative matrix factorization and the principle of the common cause](https://arxiv.org/abs/2509.03652)
*E. Khalafyan,A. E. Allahverdyan,A. Hovhannisyan*

Main category: cs.LG

TL;DR: 本文探讨了非负矩阵分解（NMF）与共同原因原则（PCC）之间的相互关系。研究表明，PCC能提供稳健的NMF有效秩估计，从而解决NMF的非识别性问题并生成稳定的特征；同时，NMF也能近似实现PCC，并应用于数据聚类和去噪。


<details>
  <summary>Details</summary>
Motivation: 探索非负矩阵分解（NMF）与概率因果关系中的共同原因原则（PCC）之间的紧密联系，并利用这种相互关系来改进各自的应用。

Method: 将灰度图像数据集映射为概率模型，通过PCC工具对NMF的有效秩进行鲁棒估计。在此估计秩的基础上实现NMF，并探索NMF近似实现PCC的可能性。基于此提出一种聚类方法，并将NMF用于数据去噪。

Result: PCC提供了一种对NMF有效秩的鲁棒估计方法，该方法对弱噪声具有稳定性，且能使NMF生成的特征（基图像）对噪声和局部优化种子保持稳定，从而解决NMF的非识别性问题。NMF能够以近似方式实现PCC，更好地解释较大且正相关的联合概率。文中还开发了一种基于共同原因的聚类方法，并展示了NMF在数据去噪方面的应用。

Conclusion: NMF与PCC之间存在紧密且互惠的关系。PCC能有效增强NMF的鲁棒性，实现稳定的秩估计和特征提取；NMF则为PCC的近似实现提供了途径，进而支持了新的聚类和数据去噪应用。

Abstract: Nonnegative matrix factorization (NMF) is a known unsupervised data-reduction
method. The principle of the common cause (PCC) is a basic methodological
approach in probabilistic causality, which seeks an independent mixture model
for the joint probability of two dependent random variables. It turns out that
these two concepts are closely related. This relationship is explored
reciprocally for several datasets of gray-scale images, which are conveniently
mapped into probability models. On one hand, PCC provides a predictability tool
that leads to a robust estimation of the effective rank of NMF. Unlike other
estimates (e.g., those based on the Bayesian Information Criteria), our
estimate of the rank is stable against weak noise. We show that NMF implemented
around this rank produces features (basis images) that are also stable against
noise and against seeds of local optimization, thereby effectively resolving
the NMF nonidentifiability problem. On the other hand, NMF provides an
interesting possibility of implementing PCC in an approximate way, where larger
and positively correlated joint probabilities tend to be explained better via
the independent mixture model. We work out a clustering method, where data
points with the same common cause are grouped into the same cluster. We also
show how NMF can be employed for data denoising.

</details>


### [29] [Semi-decentralized Federated Time Series Prediction with Client Availability Budgets](https://arxiv.org/abs/2509.03660)
*Yunkai Bao,Reza Safarzadeh,Xin Wang,Steve Drew*

Main category: cs.LG

TL;DR: 针对物联网联邦学习中客户端可用性与数据异构性问题，本文提出FedDeCAB，一种半去中心化客户端选择方法，通过概率排名和近邻协作优化离线客户端模型，并在真实数据集上验证其在复杂动态环境下的有效性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在物联网（IoT）场景中，除了数据异构性，客户端还受限于有限的能量和可用性。在这些挑战下，有效选择参与训练的客户端对于全局模型收敛和平衡客户端贡献至关重要，尤其是在客户端动态上线下线的情况下。

Method: 本文首先设置了三种影响时间序列数据可用性的场景。在此基础上，提出了一种新颖的半去中心化客户端选择方法FedDeCAB。FedDeCAB通过对可用客户端进行概率排名来选择参与者，并在客户端离线时允许其从最近邻客户端获取部分模型参数进行联合优化，以提高离线模型性能并减少通信开销。

Result: 在真实世界大规模出租车和船舶轨迹数据集上的实验结果表明，FedDeCAB在高度异构数据分布、有限通信预算以及客户端动态离线或重新加入的复杂条件下，均能有效提升模型性能并减少通信开销。

Conclusion: FedDeCAB通过其创新的半去中心化客户端选择策略和近邻协作机制，成功应对了物联网联邦学习中客户端可用性低和数据异构性的挑战，在各种复杂动态场景下展现出优越的性能和通信效率。

Abstract: Federated learning (FL) effectively promotes collaborative training among
distributed clients with privacy considerations in the Internet of Things (IoT)
scenarios. Despite of data heterogeneity, FL clients may also be constrained by
limited energy and availability budgets. Therefore, effective selection of
clients participating in training is of vital importance for the convergence of
the global model and the balance of client contributions. In this paper, we
discuss the performance impact of client availability with time-series data on
federated learning. We set up three different scenarios that affect the
availability of time-series data and propose FedDeCAB, a novel,
semi-decentralized client selection method applying probabilistic rankings of
available clients. When a client is disconnected from the server, FedDeCAB
allows obtaining partial model parameters from the nearest neighbor clients for
joint optimization, improving the performance of offline models and reducing
communication overhead. Experiments based on real-world large-scale taxi and
vessel trajectory datasets show that FedDeCAB is effective under highly
heterogeneous data distribution, limited communication budget, and dynamic
client offline or rejoining.

</details>


### [30] [AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management](https://arxiv.org/abs/2509.03666)
*Kenny Guo,Nicholas Eckhert,Krish Chhajer,Luthira Abeykoon,Lorne Schell*

Main category: cs.LG

TL;DR: 本文提出一个基于深度强化学习的自治微电网管理框架，利用Transformer进行可再生能源预测，并采用PPO智能体优化能源调度，以最小化成本并最大化可再生能源利用，实验结果显示能源效率和运行韧性显著提升。


<details>
  <summary>Details</summary>
Motivation: 旨在为偏远社区提供自治微电网管理方案，通过优化能源调度策略，最小化运营成本，并最大化太阳能、风能等可再生能源的利用，以推进零碳能源系统的发展。

Method: 采用深度强化学习框架，具体方法包括：1. 使用Transformer架构对可再生能源发电量进行时序预测。2. 部署近端策略优化（PPO）智能体在模拟环境中做出决策。

Result: 实验结果表明，与传统的基于规则的方法相比，该方法在能源效率和运行韧性方面均取得了显著改进。

Conclusion: 该工作通过提供基于深度强化学习的自治微电网管理方案，推动了智能电网技术向零碳能源系统的发展。此外，还提供了一个开源的微电网环境模拟框架。

Abstract: We present a deep reinforcement learning-based framework for autonomous
microgrid management. tailored for remote communities. Using deep reinforcement
learning and time-series forecasting models, we optimize microgrid energy
dispatch strategies to minimize costs and maximize the utilization of renewable
energy sources such as solar and wind. Our approach integrates the transformer
architecture for forecasting of renewable generation and a proximal-policy
optimization (PPO) agent to make decisions in a simulated environment. Our
experimental results demonstrate significant improvements in both energy
efficiency and operational resilience when compared to traditional rule-based
methods. This work contributes to advancing smart-grid technologies in pursuit
of zero-carbon energy systems. We finally provide an open-source framework for
simulating several microgrid environments.

</details>


### [31] [SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences](https://arxiv.org/abs/2509.03672)
*Arpan Mukherjee,Marcello Bullo,Deniz Gündüz*

Main category: cs.LG

TL;DR: 现有MaxMin-RLHF在少数群体表现不佳。本文提出SharedRep-RLHF，通过学习组间共享特征，显著提高了公平性RLHF的性能，尤其是在少数群体上。


<details>
  <summary>Details</summary>
Motivation: 统一奖励的RLHF无法捕捉多样化意见，偏袒多数群体。现有最先进的MaxMin-RLHF通过学习特定群体奖励模型并优化最低奖励群体来促进公平，但其在最低奖励群体为少数群体时表现不佳，这是本文研究的动机。

Method: 本文引入了SharedRep-RLHF框架，其核心是学习并利用各组注释中的“共享特征”，而非像MaxMin-RLHF那样学习独立的组特定奖励模型。研究证明了MaxMin-RLHF在学习共享特征方面是次优的，并量化了SharedRep-RLHF的样本复杂度。

Result: 在多样化的自然语言任务上的实验表明，SharedRep-RLHF比MaxMin-RLHF更有效，胜率提升高达20%。

Conclusion: SharedRep-RLHF通过关注和利用各组注释中的共享特征，成功克服了MaxMin-RLHF在处理少数群体时的性能局限性，显著提升了RLHF的公平性和整体表现。

Abstract: Uniform-reward reinforcement learning from human feedback (RLHF), which
trains a single reward model to represent the preferences of all annotators,
fails to capture the diversity of opinions across sub-populations,
inadvertently favoring dominant groups. The state-of-the-art, MaxMin-RLHF,
addresses this by learning group-specific reward models, and by optimizing for
the group receiving the minimum reward, thereby promoting fairness. However, we
identify that a key limitation of MaxMin-RLHF is its poor performance when the
minimum-reward group is a minority. To mitigate this drawback, we introduce a
novel framework, termed {\em SharedRep-RLHF}. At its core, SharedRep-RLHF
learns and leverages {\em shared traits} in annotations among various groups,
in contrast to learning separate reward models across groups. We first show
that MaxMin-RLHF is provably suboptimal in learning shared traits, and then
quantify the sample complexity of SharedRep-RLHF. Experiments across diverse
natural language tasks showcase the effectiveness of SharedRep-RLHF compared to
MaxMin-RLHF with a gain of up to 20% in win rate.

</details>


### [32] [A Machine Learning-Based Study on the Synergistic Optimization of Supply Chain Management and Financial Supply Chains from an Economic Perspective](https://arxiv.org/abs/2509.03673)
*Hang Wang,Huijie Tang,Ningai Leng,Zhoufan Yu*

Main category: cs.LG

TL;DR: 本研究提出并验证了一种结合经济理论和机器学习的协同供应链管理与金融供应链管理（SCM-FSCM）模型，旨在解决供应链效率、融资约束和风险传导问题，并通过数据驱动方法显著提升运营绩效。


<details>
  <summary>Details</summary>
Motivation: 解决供应链中存在的效率损失、融资约束和风险传导等问题。

Method: 整合交易成本理论和信息不对称理论；利用随机森林等算法处理多维数据，构建成本-效率-风险三维分析框架；应用“核心企业信用赋能+动态质押融资”的FSCM模型；采用LSTM进行需求预测，聚类/回归算法进行收益分配；结合博弈论和强化学习优化库存采购机制；使用XGBoost进行信用评估。

Result: 库存周转率提高30%；中小企业融资成本降低18%-22%；订单履行率稳定在95%以上；需求预测误差≤8%；信用评估准确率≥90%。

Conclusion: 该SCM-FSCM模型有效降低了运营成本，缓解了融资约束，并支持了供应链的高质量发展。

Abstract: Based on economic theories and integrated with machine learning technology,
this study explores a collaborative Supply Chain Management and Financial
Supply Chain Management (SCM - FSCM) model to solve issues like efficiency
loss, financing constraints, and risk transmission. We combine Transaction Cost
and Information Asymmetry theories and use algorithms such as random forests to
process multi-dimensional data and build a data-driven, three-dimensional
(cost-efficiency-risk) analysis framework. We then apply an FSCM model of "core
enterprise credit empowerment plus dynamic pledge financing." We use Long
Short-Term Memory (LSTM) networks for demand forecasting and
clustering/regression algorithms for benefit allocation. The study also
combines Game Theory and reinforcement learning to optimize the
inventory-procurement mechanism and uses eXtreme Gradient Boosting (XGBoost)
for credit assessment to enable rapid monetization of inventory. Verified with
20 core and 100 supporting enterprises, the results show a 30\% increase in
inventory turnover, an 18\%-22\% decrease in SME financing costs, a stable
order fulfillment rate above 95\%, and excellent model performance (demand
forecasting error <= 8\%, credit assessment accuracy >= 90\%). This SCM-FSCM
model effectively reduces operating costs, alleviates financing constraints,
and supports high-quality supply chain development.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [33] [Entanglement Purification With Finite Latency Classical Communication in Quantum Networks](https://arxiv.org/abs/2509.03667)
*Vivek Vasan,Alexander Nico-Katz,Boulat A. Bash,Daniel C. Kilper,Marco Ruffini*

Main category: cs.NI

TL;DR: 本文分析了纠缠纯化协议（BBPSSW, DEJMPS）在实际IP网络通信延迟下的可行性，评估了其在不同网络条件和量子存储技术下的性能，并提供了部署指导。


<details>
  <summary>Details</summary>
Motivation: 量子网络需要高保真纠缠对，但存储期间的退相干会降低其保真度。纠缠纯化虽能恢复保真度，但其经典通信延迟导致的空闲期，会使量子态进一步退相干，从而抵消纯化效果。

Method: 分析BBPSSW和DEJMPS两种纠缠纯化协议在非瞬时IP网络经典协调下的可行性。采用微观Lindblad处理量子动力学，结合当前城域IP网络的延迟统计数据和量子存储测试平台参数，在多种网络条件和量子存储技术下进行综合性能评估。

Result: 确定了纠缠纯化协议的成功与失败区域（通过相空间中的收支平衡等保真度等高线划分）。计算了完成多轮纯化协议所需的纠缠对总数，以及达到应用特定阈值纯化保真度的纠缠对的稳态吞吐量。

Conclusion: 为在当前和未来网络中部署纠缠纯化提供了延迟预算、存储器质量目标和资源开销估算，具有实际指导意义。

Abstract: Quantum networks rely on high fidelity entangled pairs distributed to nodes,
but maintaining their fidelity is challenged by environmental decoherence
during storage. Entanglement purification is used to restore fidelity, but the
idle periods imposed by the associated classical communication delays
counteract this goal by exposing the states to further decoherence. In this
work, we analyze the practical viability of entanglement purification protocols
(BBPSSW, DEJMPS), under non-instantaneous classical coordination over Internet
protocol (IP) communications networks. We present a comprehensive performance
evaluation of these protocols in various network conditions for a range of
quantum memory technologies. We employ a microscopic Lindblad treatment of the
underlying quantum dynamics, and use current-generation metropolitan IP network
latency statistics and parameters drawn from quantum memory testbeds. In doing
so we identify the regions in which entanglement purification succeeds and
fails, delineated by break-even iso-fidelity contours in the phase space. We
then determine the total number of entangled pairs required to complete a
multi-round purification protocol, and the steady-state throughput of entangled
pairs with purified fidelities that exceed application-specific thresholds.
This provides latency budgets, memory quality targets, and resource-overhead
estimates for deploying purification on current and near-future networks.

</details>


### [34] [Drift Plus Optimistic Penalty -- A Learning Framework for Stochastic Network Optimization](https://arxiv.org/abs/2509.03762)
*Sathwik Chadaga,Eytan Modiano*

Main category: cs.NI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the problem of joint routing and scheduling in queueing networks,
where the edge transmission costs are unknown. At each time-slot, the network
controller receives noisy observations of transmission costs only for those
edges it selects for transmission. The network controller's objective is to
make routing and scheduling decisions so that the total expected cost is
minimized. This problem exhibits an exploration-exploitation trade-off,
however, previous bandit-style solutions cannot be directly applied to this
problem due to the queueing dynamics. In order to ensure network stability, the
network controller needs to optimize throughput and cost simultaneously. We
show that the best achievable cost is lower bounded by the solution to a static
optimization problem, and develop a network control policy using techniques
from Lyapunov drift-plus-penalty optimization and multi-arm bandits. We show
that the policy achieves a sub-linear regret of order $O(\sqrt{T}\log T)$, as
compared to the best policy that has complete knowledge of arrivals and costs.
Finally, we evaluate the proposed policy using simulations and show that its
regret is indeed sub-linear.

</details>


### [35] [A Versatile and Programmable UAV Platform for Radio Access Network and End-to-End Cellular Measurements](https://arxiv.org/abs/2509.03818)
*Sherwan Jalal Abdullah,Sravan Reddy Chintareddy,Victor S. Frost,Shawn Keshmiri,Morteza Hashemi*

Main category: cs.NI

TL;DR: 该研究开发了一种基于无人机的移动网络性能测量平台，用于解决传统方法在偏远或复杂区域的局限性。实验结果显示，升高高度会改善信号强度但降低信号质量，并且强信号不一定意味着一致的覆盖。


<details>
  <summary>Details</summary>
Motivation: 传统移动网络覆盖测试耗时、费力且有时危险；众包方法在农村地区因人口稀疏和地形复杂而失效。

Method: 开发了一个基于无人机的测量平台，通过空中作业收集无线接入网络（RAN）信号和端到端网络性能指标。平台整合了机载计算单元和商用现成蜂窝调制解调器，收集的数据使用地理空间映射工具和统计技术进行分析。

Result: 实验结果显示，在较高海拔处，由于视距条件改善，接收信号功率有所提高，但由于邻近小区的干扰增加，信号质量下降。在大部分测试区域，系统维持了可接受的信号质量、足够的上下行吞吐量和满意的往返时间。值得注意的是，强大的无线电信号指标并不一定意味着在整个测试区域内具有一致的空间覆盖。

Conclusion: 该无人机平台为传统测试受限区域的移动网络性能测量提供了有效方案。研究发现，虽然高海拔有助于信号强度，但会牺牲信号质量；同时，仅靠信号强度不足以保证一致的区域覆盖。

Abstract: In this work, we develop a measurement platform to capture mobile network
performance metrics including coverage and quality of service in regions where
conventional coverage testing approaches are frequently time-intensive,
labor-demanding, and occasionally hazardous. Traditionally, crowd-sourcing
methods are used to collect cellular network performance metrics. However,
these approaches are inadequate in rural areas due to low-density population,
and difficult terrain. The platform described here is a UAV-based and is
designed to investigate the mobile network performance through aerial
operations and gather Radio Access Network (RAN) signal alongside end-to-end
network performance metrics. Our platform gathers metrics through the
integration of an onboard computation unit and commercial off-the-shelf
cellular modem. The gathered data are subsequently analyzed and displayed using
geospatial mapping utilities and statistical techniques to deliver key
observations on cellular network performance. Experimental results showed that
the received signal power improves at higher altitudes due to enhanced
line-of-sight (LoS) conditions as expected. However, the signal quality
degrades as a result of increased interference from neighboring cells. The
analysis reveals that for most of the geographic area covered in the initial
experiments the system maintained acceptable signal quality, with adequate
throughput performance for both uplink and downlink communications, while
maintaining satisfactory round-trip time characteristics. Notably, the
experiment showed that a strong radio signal metric for a given cell does not
necessarily translate to consistent spatial coverage across the tested region.

</details>


### [36] [Indoor Positioning with Wi-Fi Location: A Survey of IEEE 802.11mc/az/bk Fine Timing Measurement Research](https://arxiv.org/abs/2509.03901)
*Katarzyna Kosek-Szott,Szymon Szott,Wojciech Ciezobka,Maksymilian Wojnar,Krzysztof Rusek,Jonathan Segev*

Main category: cs.NI

TL;DR: 本文对IEEE 802.11mc FTM协议及其最新增强功能在室内定位领域的应用进行了首次全面综述，涵盖其精度、改进方法、组合应用、安全问题和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管室内定位技术需求广泛且IEEE 802.11mc FTM协议潜力巨大，但目前缺乏针对FTM及其最新增强功能的专门综述，现有文献未填补此空白。

Method: 通过分类和审阅超过180篇相关研究论文，内容涉及FTM的实际精度、精度提升方法（包括机器学习）、FTM与其他定位系统结合、FTM应用以及安全问题。

Result: 总结了FTM室内定位领域最重要的研究成果。

Conclusion: 基于综述结果，提出了未来研究的开放性领域和方向。

Abstract: Indoor positioning is an enabling technology for home, office, and industrial
network users because it provides numerous information and communication
technology (ICT) and Internet of things (IoT) functionalities such as indoor
navigation, smart meter localization, asset tracking, support for emergency
services, and detection of hazardous situations. The IEEE 802.11mc fine timing
measurement (FTM) protocol (commercially known as Wi-Fi Location) has great
potential to enable indoor positioning in future generation devices, primarily
because of the high availability of Wi-Fi networks, FTM's high accuracy and
device support. Furthermore, new FTM enhancements are available in the released
(802.11az) and recently completed (802.11bk) amendments. Despite the multitude
of literature reviews on indoor positioning, a survey dedicated to FTM and its
recent enhancements has so far been lacking. We fill this gap by classifying
and reviewing over 180 research papers related to the practical accuracy
achieved with FTM, methods for improving its accuracy (also with machine
learning), combining FTM with other indoor positioning systems, FTM-based
applications, and security issues. Based on the conducted survey, we summarize
the most important research achievements and formulate open areas for further
research.

</details>


### [37] [Autonomous Task Offloading of Vehicular Edge Computing with Parallel Computation Queues](https://arxiv.org/abs/2509.03935)
*Sungho Cho,Sung Il Choi,Seung Hyun Oh,Ian P. Roberts,Sang Hyun Lee*

Main category: cs.NI

TL;DR: 本研究针对车载边缘计算（VEC）网络，提出一种基于网络协作的任务卸载方案，旨在平衡资源利用与负载拥堵，以最小化车辆用户等待延迟。该方案经验证能实现全局最优的延迟降低性能。


<details>
  <summary>Details</summary>
Motivation: 在车载边缘计算（VEC）网络中，边缘服务器需处理车辆用户卸载的计算任务。研究动机是最小化车辆用户的整体等待延迟。

Method: 提出了一种新颖的任务卸载解决方案，该方案基于网络协作，旨在平衡资源利用不足和负载拥堵。通过预测边缘服务器的瞬时处理能力来识别过载服务器，并考虑队列的离散变量进行精确估计，以有效解决组合挑战。

Result: 所开发的解决方案与现有方法相比，实现了全局最优的延迟降低性能。这一结果已通过理论分析、数值模拟以及在真实地图虚拟环境中的可行性测试得到验证。深入分析表明，预测边缘服务器的瞬时处理能力对于确定网络延迟至关重要，且能有效识别过载服务器。

Conclusion: 该任务卸载技术通过平衡网络资源利用与负载拥堵，并结合对边缘服务器处理能力的预测和队列离散变量的精确估计，能有效应对VEC网络中的组合挑战，从而实现最小化车辆用户等待延迟的全局最优性能。

Abstract: This work considers a parallel task execution strategy in vehicular edge
computing (VEC) networks, where edge servers are deployed along the roadside to
process offloaded computational tasks of vehicular users. To minimize the
overall waiting delay among vehicular users, a novel task offloading solution
is implemented based on the network cooperation balancing resource
under-utilization and load congestion. Dual evaluation through theoretical and
numerical ways shows that the developed solution achieves a globally optimal
delay reduction performance compared to existing methods, which is also
approved by the feasibility test over a real-map virtual environment. The
in-depth analysis reveals that predicting the instantaneous processing power of
edge servers facilitates the identification of overloaded servers, which is
critical for determining network delay. By considering discrete variables of
the queue, the proposed technique's precise estimation can effectively address
these combinatorial challenges to achieve optimal performance.

</details>


### [38] [Analyzing the Effect of an Extreme Weather Event on Telecommunications and Information Technology: Insights from 30 Days of Flooding](https://arxiv.org/abs/2509.04219)
*Leandro Márcio Bertholdo,Renan Barreto Paredes,Gabriela de Lima Marin,Cesar A. H. Loureiro,Milton Kaoru Kashiwakura Pedro de Botelho Marcos*

Main category: cs.NI

TL;DR: 本研究构建了2024年5月巴西洪水期间的综合电信数据集（互联网测量、光纤中断报告、IXP路由数据），以分析网络弹性、基础设施漏洞和用户行为变化，旨在支持灾难恢复策略和更稳健的系统开发。


<details>
  <summary>Details</summary>
Motivation: 2024年5月巴西南部发生严重洪灾，对基础设施和230万人造成广泛影响，凸显了在气候事件中理解电信网络弹性及其面临挑战的必要性。

Method: 构建了包含互联网测量、光纤中断报告和互联网交换路由数据的综合电信数据集。通过将网络中断与水文及运行因素相关联，研究了ICT基础设施的故障。

Result: 数据集揭示了光纤网络、数据中心和互联网流量在关键事件中的弹性，初步发现包括连接恢复趋势、基础设施脆弱性和用户行为变化。

Conclusion: 本研究构建的数据集及初步分析旨在为未来的灾难恢复策略研究和稳健电信系统的开发提供支持，并强调了在弹性受到严峻考验时ICT基础设施所面临的挑战。

Abstract: In May 2024, weeks of severe rainfall in Rio Grande do Sul, Brazil caused
widespread damage to infrastructure, impacting over 400 cities and 2.3 million
people. This study presents the construction of comprehensive
telecommunications datasets during this climatic event, encompassing Internet
measurements, fiber cut reports, and Internet Exchange routing data. By
correlating network disruptions with hydrological and operational factors, the
dataset offers insights into the resilience of fiber networks, data centers,
and Internet traffic during critical events. For each scenario, we investigate
failures related to the Information and Communication Technology infrastructure
and highlight the challenges faced when its resilience is critically tested.
Preliminary findings reveal trends in connectivity restoration, infrastructure
vulnerabilities, and user behavior changes. These datasets and pre-analysis aim
to support future research on disaster recovery strategies and the development
of robust telecommunications systems.

</details>
