{"id": "2505.00001", "pdf": "https://arxiv.org/pdf/2505.00001", "abs": "https://arxiv.org/abs/2505.00001", "authors": ["Shaun Baek", "Shaun Esua-Mensah", "Cyrus Tsui", "Sejan Vigneswaralingam", "Abdullah Alali", "Michael Lu", "Vasu Sharma", "Kevin Zhu"], "title": "Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are primarily trained on high-resource natural\nlanguages, limiting their effectiveness in low-resource settings and in tasks\nrequiring deep logical reasoning. This research introduces Rosetta-PL, a\nbenchmark designed to evaluate LLMs' logical reasoning and generalization\ncapabilities in a controlled environment. We construct Rosetta-PL by\ntranslating a dataset of logical propositions from Lean into a custom logical\nlanguage, which is then used to fine-tune an LLM (e.g., GPT-4o). Our\nexperiments analyze the impact of the size of the dataset and the translation\nmethodology on the performance of the model. Our results indicate that\npreserving logical relationships in the translation process significantly\nboosts precision, with accuracy plateauing beyond roughly 20,000 training\nsamples. These insights provide valuable guidelines for optimizing LLM training\nin formal reasoning tasks and improving performance in various low-resource\nlanguage applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86 Rosetta-PL \u57fa\u51c6\uff0c\u901a\u8fc7\u5c06 Lean \u903b\u8f91\u547d\u9898\u7ffb\u8bd1\u6210\u81ea\u5b9a\u4e49\u903b\u8f91\u8bed\u8a00\u6765\u8bc4\u4f30\u548c\u5fae\u8c03 LLM \u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4fdd\u7559\u903b\u8f91\u5173\u7cfb\u7684\u7ffb\u8bd1\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u4e14\u8bad\u7ec3\u6837\u672c\u8fbe 2 \u4e07\u6761\u5de6\u53f3\u65f6\u51c6\u786e\u7387\u8d8b\u4e8e\u7a33\u5b9a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3b\u8981\u5728\u9ad8\u8d44\u6e90\u81ea\u7136\u8bed\u8a00\u4e0a\u8bad\u7ec3\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u548c\u9700\u8981\u6df1\u5ea6\u903b\u8f91\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u540d\u4e3a Rosetta-PL \u7684\u65b0\u57fa\u51c6\u3002\u901a\u8fc7\u5c06 Lean \u7684\u903b\u8f91\u547d\u9898\u6570\u636e\u96c6\u7ffb\u8bd1\u6210\u4e00\u79cd\u81ea\u5b9a\u4e49\u903b\u8f91\u8bed\u8a00\u6765\u6784\u5efa\u8be5\u57fa\u51c6\u3002\u4f7f\u7528\u8fd9\u4e2a\u7ffb\u8bd1\u540e\u7684\u6570\u636e\u96c6\u6765\u5fae\u8c03 LLM\uff08\u4f8b\u5982 GPT-4o\uff09\u3002\u5206\u6790\u6570\u636e\u96c6\u5927\u5c0f\u548c\u7ffb\u8bd1\u65b9\u6cd5\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5728\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u4fdd\u7559\u903b\u8f91\u5173\u7cfb\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u7684\u7cbe\u786e\u5ea6\u3002\u5f53\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u8d85\u8fc7\u5927\u7ea6 20,000 \u6761\u65f6\uff0c\u6a21\u578b\u7684\u51c6\u786e\u7387\u8d8b\u4e8e\u5e73\u7a33\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u4f18\u5316 LLM \u5728\u5f62\u5f0f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8bad\u7ec3\u4ee5\u53ca\u63d0\u9ad8\u5176\u5728\u5404\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u65b9\u9488\u3002"}}
{"id": "2505.00002", "pdf": "https://arxiv.org/pdf/2505.00002", "abs": "https://arxiv.org/abs/2505.00002", "authors": ["Vincent C. M\u00fcller"], "title": "Symbol grounding in computational systems: A paradox of intentions", "categories": ["cs.CL"], "comment": null, "summary": "The paper presents a paradoxical feature of computational systems that\nsuggests that computationalism cannot explain symbol grounding. If the mind is\na digital computer, as computationalism claims, then it can be computing either\nover meaningful symbols or over meaningless symbols. If it is computing over\nmeaningful symbols its functioning presupposes the existence of meaningful\nsymbols in the system, i.e. it implies semantic nativism. If the mind is\ncomputing over meaningless symbols, no intentional cognitive processes are\navailable prior to symbol grounding. In this case, no symbol grounding could\ntake place since any grounding presupposes intentional cognitive processes. So,\nwhether computing in the mind is over meaningless or over meaningful symbols,\ncomputationalism implies semantic nativism.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u8ba1\u7b97\u4e3b\u4e49\u65e0\u6cd5\u89e3\u91ca\u7b26\u53f7\u63a5\u5730\u95ee\u9898\uff0c\u56e0\u4e3a\u5b83\u65e0\u8bba\u5904\u7406\u6709\u610f\u4e49\u8fd8\u662f\u65e0\u610f\u4e49\u7684\u7b26\u53f7\uff0c\u6700\u7ec8\u90fd\u8574\u542b\u4e86\u8bed\u4e49\u5148\u5929\u8bba\u3002", "motivation": "\u63a2\u8ba8\u8ba1\u7b97\u4e3b\u4e49\uff08\u8ba4\u4e3a\u5fc3\u667a\u662f\u6570\u5b57\u8ba1\u7b97\u673a\uff09\u662f\u5426\u80fd\u591f\u89e3\u91ca\u7b26\u53f7\u63a5\u5730\uff08\u7b26\u53f7\u5982\u4f55\u83b7\u5f97\u610f\u4e49\uff09\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u903b\u8f91\u5206\u6790\uff0c\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u8ba1\u7b97\u4e3b\u4e49\u5904\u7406\u4e24\u79cd\u4e0d\u540c\u7c7b\u578b\u7b26\u53f7\uff08\u6709\u610f\u4e49 vs. \u65e0\u610f\u4e49\uff09\u6240\u4ea7\u751f\u7684\u6096\u8bba\u3002", "result": "\u5206\u6790\u8868\u660e\uff1a\u5982\u679c\u5fc3\u667a\u5904\u7406\u6709\u610f\u4e49\u7b26\u53f7\uff0c\u5219\u9884\u8bbe\u4e86\u610f\u4e49\u7684\u5b58\u5728\uff08\u8bed\u4e49\u5148\u5929\u8bba\uff09\uff1b\u5982\u679c\u5904\u7406\u65e0\u610f\u4e49\u7b26\u53f7\uff0c\u5219\u65e0\u6cd5\u8fdb\u884c\u9700\u8981\u610f\u5411\u6027\u7684\u7b26\u53f7\u63a5\u5730\u8fc7\u7a0b\u3002\u4e24\u79cd\u60c5\u51b5\u90fd\u5bfc\u5411\u8bed\u4e49\u5148\u5929\u8bba\u3002", "conclusion": "\u8ba1\u7b97\u4e3b\u4e49\u65e0\u6cd5\u89e3\u91ca\u7b26\u53f7\u63a5\u5730\uff0c\u56e0\u4e3a\u5b83\u5185\u5728\u5730\u8574\u542b\u4e86\u8bed\u4e49\u5148\u5929\u8bba\uff0c\u5373\u9884\u8bbe\u4e86\u9700\u8981\u89e3\u91ca\u7684\u4e1c\u897f\u3002"}}
{"id": "2505.00003", "pdf": "https://arxiv.org/pdf/2505.00003", "abs": "https://arxiv.org/abs/2505.00003", "authors": ["Zizhou Liu", "Ziwei Gong", "Lin Ai", "Zheng Hui", "Run Chen", "Colin Wayne Leach", "Michelle R. Greene", "Julia Hirschberg"], "title": "The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Psychological insights have long shaped pivotal NLP breakthroughs, including\nthe cognitive underpinnings of attention mechanisms, formative reinforcement\nlearning, and Theory of Mind-inspired social modeling. As Large Language Models\n(LLMs) continue to grow in scale and complexity, there is a rising consensus\nthat psychology is essential for capturing human-like cognition, behavior, and\ninteraction. This paper reviews how psychological theories can inform and\nenhance stages of LLM development, including data, pre-training, post-training,\nand evaluation\\&application. Our survey integrates insights from cognitive,\ndevelopmental, behavioral, social, personality psychology, and\npsycholinguistics. Our analysis highlights current trends and gaps in how\npsychological theories are applied. By examining both cross-domain connections\nand points of tension, we aim to bridge disciplinary divides and promote more\nthoughtful integration of psychology into future NLP research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u5fc3\u7406\u5b66\u7406\u8bba\u5982\u4f55\u5e94\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f00\u53d1\u7684\u5404\u4e2a\u9636\u6bb5\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u7c7b\u4eba\u7684\u8ba4\u77e5\u3001\u884c\u4e3a\u548c\u4ea4\u4e92\u3002", "motivation": "\u9274\u4e8e\u5fc3\u7406\u5b66\u5728\u5386\u53f2\u4e0a\u5bf9NLP\u7a81\u7834\u7684\u8d21\u732e\u4ee5\u53caLLM\u65e5\u76ca\u589e\u957f\u7684\u590d\u6742\u6027\uff0c\u7814\u7a76\u8005\u8ba4\u4e3a\u5fc3\u7406\u5b66\u5bf9\u4e8e\u5b9e\u73b0LLM\u7684\u7c7b\u4eba\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u6574\u5408\u8ba4\u77e5\u5fc3\u7406\u5b66\u3001\u53d1\u5c55\u5fc3\u7406\u5b66\u3001\u884c\u4e3a\u5fc3\u7406\u5b66\u3001\u793e\u4f1a\u5fc3\u7406\u5b66\u3001\u4eba\u683c\u5fc3\u7406\u5b66\u548c\u5fc3\u7406\u8bed\u8a00\u5b66\u7684\u89c1\u89e3\uff0c\u5206\u6790\u5b83\u4eec\u5728LLM\u7684\u6570\u636e\u3001\u9884\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\u3001\u8bc4\u4f30\u4e0e\u5e94\u7528\u9636\u6bb5\u7684\u5e94\u7528\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u5f53\u524d\u5fc3\u7406\u5b66\u7406\u8bba\u5728LLM\u4e2d\u5e94\u7528\u7684\u8d8b\u52bf\u548c\u5b58\u5728\u7684\u5dee\u8ddd\uff0c\u5e76\u6307\u51fa\u4e86\u8de8\u9886\u57df\u8054\u7cfb\u548c\u6f5c\u5728\u7684\u51b2\u7a81\u70b9\u3002", "conclusion": "\u8bba\u6587\u65e8\u5728\u4fc3\u8fdb\u5fc3\u7406\u5b66\u4e0eNLP\u7814\u7a76\u7684\u66f4\u6df1\u5165\u878d\u5408\uff0c\u5f25\u5408\u5b66\u79d1\u9e3f\u6c9f\uff0c\u4ee5\u6307\u5bfc\u672a\u6765LLM\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.00004", "pdf": "https://arxiv.org/pdf/2505.00004", "abs": "https://arxiv.org/abs/2505.00004", "authors": ["Danilo S. Carvalho", "Yingji Zhang", "Harriet Unsworth", "Andr\u00e9 Freitas"], "title": "LangVAE and LangSpace: Building and Probing for Language Model VAEs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present LangVAE, a novel framework for modular construction of variational\nautoencoders (VAEs) on top of pre-trained large language models (LLMs). Such\nlanguage model VAEs can encode the knowledge of their pre-trained components\ninto more compact and semantically disentangled representations. The\nrepresentations obtained in this way can be analysed with the LangVAE companion\nframework: LangSpace, which implements a collection of probing methods, such as\nvector traversal and interpolation, disentanglement measures, and cluster\nvisualisations. LangVAE and LangSpace offer a flexible, efficient and scalable\nway of building and analysing textual representations, with simple integration\nfor models available on the HuggingFace Hub. Additionally, we conducted a set\nof experiments with different encoder and decoder combinations, as well as\nannotated inputs, revealing a wide range of interactions across architectural\nfamilies and sizes w.r.t. generalisation and disentanglement. Our findings\ndemonstrate a promising framework for systematising the experimentation and\nunderstanding of textual representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aLangVAE\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e4b\u4e0a\u6784\u5efa\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\uff0c\u4ee5\u751f\u6210\u66f4\u7d27\u51d1\u3001\u8bed\u4e49\u89e3\u8026\u7684\u8868\u793a\u3002\u540c\u65f6\u63d0\u51fa\u4e86LangSpace\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u8fd9\u4e9b\u8868\u793a\u3002", "motivation": "\u9700\u8981\u5c06\u9884\u8bad\u7ec3LLM\u4e2d\u7684\u77e5\u8bc6\u7f16\u7801\u6210\u66f4\u7d27\u51d1\u3001\u8bed\u4e49\u66f4\u89e3\u8026\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u5e76\u9700\u8981\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u548c\u5206\u6790\u8fd9\u4e9b\u6587\u672c\u8868\u793a\u3002", "method": "1. \u63d0\u51faLangVAE\u6846\u67b6\uff1a\u5728\u9884\u8bad\u7ec3LLM\u57fa\u7840\u4e0a\u6a21\u5757\u5316\u6784\u5efaVAE\u30022. \u63d0\u51faLangSpace\u6846\u67b6\uff1a\u63d0\u4f9b\u4e00\u7cfb\u5217\u63a2\u6d4b\u65b9\u6cd5\uff08\u5411\u91cf\u904d\u5386\u4e0e\u63d2\u503c\u3001\u89e3\u8026\u5ea6\u91cf\u3001\u805a\u7c7b\u53ef\u89c6\u5316\uff09\u6765\u5206\u6790LangVAE\u751f\u6210\u7684\u8868\u793a\u30023. \u8fdb\u884c\u5b9e\u9a8c\uff1a\u6d4b\u8bd5\u4e0d\u540c\u7684\u7f16\u7801\u5668/\u89e3\u7801\u5668\u7ec4\u5408\u548c\u6807\u6ce8\u8f93\u5165\u3002", "result": "1. LangVAE\u548cLangSpace\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u3001\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u6765\u6784\u5efa\u548c\u5206\u6790\u6587\u672c\u8868\u793a\u30022. \u5b9e\u9a8c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u5c3a\u5bf8\u5728\u6cdb\u5316\u6027\u548c\u89e3\u8026\u6027\u65b9\u9762\u5b58\u5728\u5e7f\u6cdb\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u7cfb\u7edf\u5316\u5b9e\u9a8c\u548c\u7406\u89e3\u6587\u672c\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.00138", "pdf": "https://arxiv.org/pdf/2505.00138", "abs": "https://arxiv.org/abs/2505.00138", "authors": ["Martin Haenggi"], "title": "Q Cells in Wireless Networks", "categories": ["cs.NI", "cs.IT", "math.IT", "math.PR"], "comment": null, "summary": "For a given set of transmitters such as cellular base stations or WiFi access\npoints, is it possible to analytically characterize the set of locations that\nare \"covered\" in the sense that users at these locations experience a certain\nminimum quality of service? In this paper, we affirmatively answer this\nquestion, by providing explicit simple outer bounds and estimates for the\ncoverage manifold. The key geometric elements of our analytical method are the\nQ cells, defined as the intersections of a small number of disks. The Q cell of\na transmitter is an outer bound to the service region of the transmitter, and,\nin turn, the union of Q cells is an outer bound to the coverage manifold. In\ninfinite networks, connections to the meta distribution of the\nsignal-to-interference ratio allow for a scaling of the Q cells to obtain\naccurate estimates of the coverage manifold.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u201cQ\u5355\u5143\u201d\uff08\u5706\u76d8\u4ea4\u96c6\uff09\u6765\u5206\u6790\u6027\u5730\u63cf\u8ff0\u548c\u4f30\u8ba1\u65e0\u7ebf\u53d1\u5c04\u5668\u8986\u76d6\u533a\u57df\u7684\u65b9\u6cd5\u3002", "motivation": "\u786e\u5b9a\u662f\u5426\u53ef\u4ee5\u5206\u6790\u6027\u5730\u63cf\u8ff0\u4fdd\u8bc1\u7528\u6237\u6700\u4f4e\u670d\u52a1\u8d28\u91cf\u7684\u5730\u7406\u4f4d\u7f6e\uff08\u8986\u76d6\u533a\u57df\uff09\u3002", "method": "\u5f15\u5165\u201cQ\u5355\u5143\u201d\uff08Q cells\uff09\u4f5c\u4e3a\u53d1\u5c04\u5668\u670d\u52a1\u533a\u57df\u7684\u5916\u8fb9\u754c\uff0cQ\u5355\u5143\u5b9a\u4e49\u4e3a\u5c11\u91cf\u5706\u76d8\u7684\u4ea4\u96c6\u3002\u8986\u76d6\u533a\u57df\u5219\u7531\u6240\u6709\u53d1\u5c04\u5668Q\u5355\u5143\u7684\u5e76\u96c6\u4f5c\u4e3a\u5916\u8fb9\u754c\u3002\u5bf9\u4e8e\u65e0\u9650\u7f51\u7edc\uff0c\u7ed3\u5408\u4fe1\u5e72\u6bd4\uff08SINR\uff09\u7684\u5143\u5206\u5e03\uff08meta distribution\uff09\u6765\u7f29\u653eQ\u5355\u5143\uff0c\u4ee5\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u4f30\u8ba1\u3002", "result": "\u63d0\u4f9b\u4e86\u8986\u76d6\u533a\u57df\u7684\u660e\u786e\u3001\u7b80\u5355\u7684\u5916\u8fb9\u754c\u548c\u4f30\u8ba1\u65b9\u6cd5\u3002\u8bc1\u660e\u4e86Q\u5355\u5143\u53ca\u5176\u5e76\u96c6\u5206\u522b\u6784\u6210\u4e86\u5355\u4e2a\u53d1\u5c04\u5668\u670d\u52a1\u533a\u57df\u548c\u603b\u8986\u76d6\u533a\u57df\u7684\u5916\u8fb9\u754c\u3002\u5728\u65e0\u9650\u7f51\u7edc\u4e2d\uff0c\u901a\u8fc7\u7f29\u653eQ\u5355\u5143\u53ef\u4ee5\u51c6\u786e\u4f30\u8ba1\u8986\u76d6\u533a\u57df\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u5730\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u6790\u65b9\u6cd5\uff08\u57fa\u4e8eQ\u5355\u5143\uff09\u6765\u8868\u5f81\u65e0\u7ebf\u7f51\u7edc\u7684\u8986\u76d6\u533a\u57df\uff0c\u4e3a\u8986\u76d6\u8303\u56f4\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u754c\u9650\u548c\u4f30\u8ba1\u3002"}}
{"id": "2505.00101", "pdf": "https://arxiv.org/pdf/2505.00101", "abs": "https://arxiv.org/abs/2505.00101", "authors": ["Barak Gahtan", "Sanketh Vedula", "Gil Samuelly Leichtag", "Einat Kodesh", "Alex M. Bronstein"], "title": "From Lab to Wrist: Bridging Metabolic Monitoring and Consumer Wearables for Heart Rate and Oxygen Consumption Modeling", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Understanding physiological responses during running is critical for\nperformance optimization, tailored training prescriptions, and athlete health\nmanagement. We introduce a comprehensive framework -- what we believe to be the\nfirst capable of predicting instantaneous oxygen consumption (VO$_{2}$)\ntrajectories exclusively from consumer-grade wearable data. Our approach\nemploys two complementary physiological models: (1) accurate modeling of heart\nrate (HR) dynamics via a physiologically constrained ordinary differential\nequation (ODE) and neural Kalman filter, trained on over 3 million HR\nobservations, achieving 1-second interval predictions with mean absolute errors\nas low as 2.81\\,bpm (correlation 0.87); and (2) leveraging the principles of\nprecise HR modeling, a novel VO$_{2}$ prediction architecture requiring only\nthe initial second of VO$_{2}$ data for calibration, enabling robust,\nsequence-to-sequence metabolic demand estimation. Despite relying solely on\nsmartwatch and chest-strap data, our method achieves mean absolute percentage\nerrors of approximately 13\\%, effectively capturing rapid physiological\ntransitions and steady-state conditions across diverse running intensities. Our\nsynchronized dataset, complemented by blood lactate measurements, further lays\nthe foundation for future noninvasive metabolic zone identification. By\nembedding physiological constraints within modern machine learning, this\nframework democratizes advanced metabolic monitoring, bridging laboratory-grade\naccuracy and everyday accessibility, thus empowering both elite athletes and\nrecreational fitness enthusiasts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f7f\u7528\u6d88\u8d39\u7ea7\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\uff08\u667a\u80fd\u624b\u8868\u3001\u5fc3\u7387\u5e26\uff09\u6765\u9884\u6d4b\u8dd1\u6b65\u8fc7\u7a0b\u4e2d\u77ac\u65f6\u6444\u6c27\u91cf\uff08VO$_{2}$\uff09\u8f68\u8ff9\u7684\u65b0\u6846\u67b6\u3002", "motivation": "\u7406\u89e3\u8dd1\u6b65\u65f6\u7684\u751f\u7406\u53cd\u5e94\u5bf9\u4f18\u5316\u8868\u73b0\u3001\u4e2a\u6027\u5316\u8bad\u7ec3\u548c\u5065\u5eb7\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4ec5\u901a\u8fc7\u6d88\u8d39\u7ea7\u8bbe\u5907\u5b9e\u65f6\u3001\u51c6\u786e\u9884\u6d4bVO$_{2}$\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u751f\u7406\u6a21\u578b\uff1a1) \u901a\u8fc7\u751f\u7406\u7ea6\u675f\u7684\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u548c\u795e\u7ecf\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7cbe\u786e\u5efa\u6a21\u5fc3\u7387\uff08HR\uff09\u52a8\u6001\uff1b2) \u57fa\u4e8e\u5fc3\u7387\u6a21\u578b\uff0c\u6784\u5efa\u65b0\u7684VO$_{2}$\u9884\u6d4b\u67b6\u6784\uff0c\u4ec5\u9700\u521d\u59cb\u79d2\u7ea7VO$_{2}$\u6570\u636e\u6821\u51c6\uff0c\u8fdb\u884c\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u4ee3\u8c22\u9700\u6c42\u4f30\u8ba1\u3002", "result": "\u5fc3\u7387\u6a21\u578b\u9884\u6d4b1\u79d2\u95f4\u9694\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f4e\u81f32.81 bpm\uff08\u76f8\u5173\u60270.87\uff09\u3002VO$_{2}$\u9884\u6d4b\u7684\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u7ea6\u4e3a13%\uff0c\u80fd\u6709\u6548\u6355\u6349\u4e0d\u540c\u5f3a\u5ea6\u4e0b\u7684\u5feb\u901f\u751f\u7406\u8f6c\u53d8\u548c\u7a33\u6001\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u751f\u7406\u7ea6\u675f\u4e0e\u673a\u5668\u5b66\u4e60\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u5148\u8fdb\u4ee3\u8c22\u76d1\u6d4b\u7684\u666e\u53ca\u5316\uff0c\u8fde\u63a5\u4e86\u5b9e\u9a8c\u5ba4\u7cbe\u5ea6\u4e0e\u65e5\u5e38\u53ef\u53ca\u6027\uff0c\u8d4b\u80fd\u8fd0\u52a8\u5458\u548c\u5065\u8eab\u7231\u597d\u8005\uff0c\u5e76\u4e3a\u672a\u6765\u65e0\u521b\u4ee3\u8c22\u533a\u95f4\u8bc6\u522b\u5960\u5b9a\u57fa\u7840\u3002"}}
