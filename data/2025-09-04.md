<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.CV](#cs.CV) [Total: 57]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.RO](#cs.RO) [Total: 4]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [math.HO](#math.HO) [Total: 1]
- [eess.SP](#eess.SP) [Total: 2]
- [eess.IV](#eess.IV) [Total: 20]
- [cs.IR](#cs.IR) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CY](#cs.CY) [Total: 4]
- [cs.GT](#cs.GT) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [quant-ph](#quant-ph) [Total: 2]
- [cs.NE](#cs.NE) [Total: 1]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [stat.AP](#stat.AP) [Total: 1]
- [q-bio.OT](#q-bio.OT) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [q-bio.GN](#q-bio.GN) [Total: 2]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 2]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.HC](#cs.HC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off](https://arxiv.org/abs/2509.02785)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Zimeng Huang,Xiaofei Sun,Jian Wang,Chengpei Tang,Keze Wang*

Main category: cs.CL

TL;DR: DrDiff是一个新颖的长文本生成框架，通过三项核心技术克服了效率与质量的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有长文本生成方法在效率与质量之间存在权衡，难以同时实现高性能和高效率。

Method: 1. 动态专家调度机制：根据文本复杂性智能分配计算资源，提高效率。2. 分层稀疏注意力（HSA）机制：自适应调整注意力模式，将计算复杂度从O($n^2$)降至O($n$)，同时保持性能。3. 软吸收引导优化策略：结合DPM-solver++减少扩散步数，显著提升生成速度。

Result: 在各种长文本生成基准测试中，DrDiff的表现均优于现有最先进（SOTA）方法。

Conclusion: DrDiff框架通过其创新技术，成功在长文本生成领域实现了效率和质量的双重提升，超越了现有SOTA水平。

Abstract: This paper introduces DrDiff, a novel framework for long-text generation that
overcomes the efficiency-quality trade-off through three core technologies.
First, we design a dynamic expert scheduling mechanism that intelligently
allocates computational resources during the diffusion process based on text
complexity, enabling more efficient handling of text generation tasks of
varying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA)
mechanism that adaptively adjusts attention patterns according to a variety of
input lengths, reducing computational complexity from O($n^2$) to O($n$) while
maintaining model performance. Finally, we propose a soft absorption guidance
optimization strategy that combines with DPM-solver++ to reduce diffusion
steps, significantly improving generation speed. Comprehensive experiments on
various long-text generation benchmarks demonstrate the superiority of our
DrDiff over the existing SOTA methods.

</details>


### [2] [SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR](https://arxiv.org/abs/2509.02830)
*Pu Wang,Shinji Watanabe,Hugo Van hamme*

Main category: cs.CL

TL;DR: 本文首次在ESPnet中全面集成并基准测试了LoRA的先进PEFT变体（如VeRA, DoRA），并引入了新的结构化SVD引导微调（SSVD）方法，旨在实现语音领域的鲁棒域适应。


<details>
  <summary>Details</summary>
Motivation: 尽管低秩适应（LoRA）广泛用于语音应用，但其最先进的变体（如VeRA, DoRA, PiSSA, SVFT）主要为语言和视觉任务开发，在语音领域的验证有限。

Method: 1. 在ESPnet中首次全面集成并基准测试了现有的最先进PEFT方法（VeRA, DoRA, PiSSA, SVFT）。2. 引入了结构化SVD引导（SSVD）微调方法，该方法选择性地旋转输入相关的右奇异向量，同时固定输出相关的向量以保留语义映射。3. 在域偏移的语音识别任务（包括儿童语音和方言变体）上，对所有方法在0.1B至2B的模型规模上进行了评估。

Result: 1. 成功完成了现有PEFT方法在ESPnet中的集成与基准测试。2. 所提出的SSVD方法设计旨在实现具有最小可训练参数和提高效率的鲁棒域适应。3. 所有实现均已在ESPnet中发布，以支持复现性。

Conclusion: 本工作首次对先进PEFT方法在语音领域进行了综合集成和基准测试，并提出了高效、鲁棒的SSVD微调方法，为语音领域的PEFT研究奠定了基础，并提供了可复现的实现。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for
adapting large foundation models. While low-rank adaptation (LoRA) is widely
used in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA,
PiSSA, and SVFT, are developed mainly for language and vision tasks, with
limited validation in speech. This work presents the first comprehensive
integration and benchmarking of these PEFT methods within ESPnet. We further
introduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates
input-associated right singular vectors while keeping output-associated vectors
fixed to preserve semantic mappings. This design enables robust domain
adaptation with minimal trainable parameters and improved efficiency. We
evaluate all methods on domain-shifted speech recognition tasks, including
child speech and dialectal variation, across model scales from 0.1B to 2B. All
implementations are released in ESPnet to support reproducibility and future
work.

</details>


### [3] [Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models](https://arxiv.org/abs/2509.02834)
*Gustavo Bonil,João Gondim,Marina dos Santos,Simone Hashiguti,Helena Maia,Nadia Silva,Helio Pedrini,Sandra Avila*

Main category: cs.CL

TL;DR: 本研究分析LLaMA 3.2-3B模型在葡萄牙语短篇故事中如何构建黑人与白人女性的叙事。结果显示，尽管文本看似中立且语法连贯，但却固化了带有殖民色彩的女性身体框架，强化了历史不平等。研究提出结合机器学习与质性话语分析的综合方法。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（特别是LLaMA 3.2-3B）在生成关于黑人与白人女性的短篇故事时，如何构建叙事，并揭示这些叙事是否存在潜在的偏见或对历史不平等的强化。

Method: 使用LLaMA 3.2-3B生成2100篇葡萄牙语短篇故事，通过计算方法对语义相似的故事进行分组，并选取部分故事进行质性分析。研究采用了结合机器学习技术和人工质性话语分析的综合方法。

Result: 分析识别出三种主要的论述表征：社会超越、祖先神话化和主观自我实现。研究发现，即使是语法连贯、看似中立的文本，也具体化了固化且带有殖民色彩的女性身体框架，从而强化了历史不平等。

Conclusion: 大型语言模型生成的故事内容，即使看似中立，也可能无意中延续并强化殖民结构下的女性身体刻板印象和历史不平等。因此，结合机器学习和质性话语分析的综合方法对于揭示这些隐性偏见至关重要。

Abstract: This study investigates how large language models, in particular LLaMA
3.2-3B, construct narratives about Black and white women in short stories
generated in Portuguese. From 2100 texts, we applied computational methods to
group semantically similar stories, allowing a selection for qualitative
analysis. Three main discursive representations emerge: social overcoming,
ancestral mythification and subjective self-realization. The analysis uncovers
how grammatically coherent, seemingly neutral texts materialize a crystallized,
colonially structured framing of the female body, reinforcing historical
inequalities. The study proposes an integrated approach, that combines machine
learning techniques with qualitative, manual discourse analysis.

</details>


### [4] [IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations](https://arxiv.org/abs/2509.02855)
*Hyunji Nam,Lucia Langlois,James Malamut,Mei Tan,Dorottya Demszky*

Main category: cs.CL

TL;DR: 本文提出IDEAlgin基准范式，通过三元组判断任务捕获专家对LLM生成开放式解释性标注的相似度评价。研究发现结合IDEAlgin的LLM提示方法显著优于传统指标，能有效大规模评估LLM在此类任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）正被广泛应用于开放式、解释性的标注任务。然而，目前缺乏可扩展且经验证的方法来评估LLM生成的标注与人类专家判断的一致性。

Method: 引入IDEAlgin基准范式，通过“找出不同项”的三元组判断任务来直观地捕捉专家对语义相似度的评价。基于此人类基准，评估了多种相似度指标，包括基于向量的方法（主题模型、嵌入）以及“LLM作为评判者”的方法。该方法应用于两个教育领域的真实数据集。

Result: 基于向量的相似度指标在捕捉专家判断的细微语义差别方面表现不佳。通过IDEAlgin提示LLM作为评判者，与专家判断的一致性相比传统词汇和向量方法显著提高（提升9-30%）。

Conclusion: IDEAlgin被确立为一种有前景的范式，可以大规模评估LLM在开放式专家标注任务中的表现，为LLM在教育及其他领域的负责任部署提供指导。

Abstract: Large language models (LLMs) are increasingly applied to open-ended,
interpretive annotation tasks, such as thematic analysis by researchers or
generating feedback on student work by teachers. These tasks involve free-text
annotations requiring expert-level judgments grounded in specific objectives
(e.g., research questions or instructional goals). Evaluating whether
LLM-generated annotations align with those generated by expert humans is
challenging to do at scale, and currently, no validated, scalable measure of
similarity in ideas exists. In this paper, we (i) introduce the scalable
evaluation of interpretive annotation by LLMs as a critical and understudied
task, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing
expert similarity ratings via a "pick-the-odd-one-out" triplet judgment task,
and (iii) evaluate various similarity metrics, including vector-based ones
(topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human
benchmarks. Applying this approach to two real-world educational datasets
(interpretive analysis and feedback generation), we find that vector-based
metrics largely fail to capture the nuanced dimensions of similarity meaningful
to experts. Prompting LLMs via IDEAlgin significantly improves alignment with
expert judgments (9-30% increase) compared to traditional lexical and
vector-based metrics. These results establish IDEAlgin as a promising paradigm
for evaluating LLMs against open-ended expert annotations at scale, informing
responsible deployment of LLMs in education and beyond.

</details>


### [5] [A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation](https://arxiv.org/abs/2509.02864)
*Kesen Wang,Daulet Toibazar,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 本文提出一个端到端、自进化的对抗性工作流，通过协调多个专业LVLM自动化生成阿拉伯语长文本问答（QA），无需人工干预。该工作流能够持续学习，提升问题难度和相关性，并发布了大规模阿拉伯语基准AraLongBench，结果显示其显著优于静态方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在阿拉伯语长文本问答生成方面可能存在局限性，尤其是在处理多页文档时，且缺乏有效的自动化、自进化机制，同时缺少一个能够全面评估长文本理解能力的阿拉伯语基准。

Method: 该研究提出了一个端到端、自进化的对抗性工作流，通过协调多个专业LVLM实现：一个问题生成器、一个评估器和一个答案生成器群。系统从原始多页阿拉伯语文档开始，问题生成器生成上下文感知的查询，答案生成器群回答，评估器评估并反馈质量指标。这种闭环循环支持持续学习，低置信度输出会触发自动再生成和模型更新，逐步提升问题难度和相关性。此外，质量指标被设置为可调超参数，实现可控的问题难度生成。研究还精心设计了一个用于长文本阿拉伯语文档收集的全自动代理工作流。

Result: 研究发布了AraLongBench，一个大规模的阿拉伯语长文本基准，包含单页和多页挑战，跨越数百页。结果表明，所提出的自进化工作流显著优于静态流水线方法，显著提升了领先阿拉伯语大型视觉语言模型（LVLMs）的长文本理解能力。

Conclusion: 所提出的自进化对抗性工作流为阿拉伯语长文本QA生成提供了一种有效且自动化的方法，能够显著提升LVLM的长文本理解能力，并优于传统静态方法。AraLongBench的发布也为该领域的研究和评估提供了重要资源，同时其可控的问题难度生成功能增加了实用性。

Abstract: We present an end-to-end, self-evolving adversarial workflow for long-context
Question-Answer (QA) Generation in Arabic. By orchestrating multiple
specialized LVLMs: a question generator, an evaluator, and a swarm of answer
generators, our system iteratively refines its own performance without any
human intervention. Starting from raw, multi-page Arabic documents across
diverse domains, the question generator produces fine-grained, context-aware
queries to be tackled by the answer generator swarm, and the evaluator assesses
and feeds back quality metrics. This closed-loop cycle enables continuous
learning: low-confidence outputs trigger automated re-generation and model
updates, progressively enhancing question difficulty and relevance. Moreover,
we set the quality metrics as a tunable hyperparameter, enabling question
generation at controllable and customizable difficulty levels. We release
AraLongBench, a large-scale Arabic benchmark of single- and multi-page
challenges spanning hundreds of pages, and demonstrate that our self-evolving
workflow substantially outperform static pipelines, markedly boosting the
long-context comprehension capabilities of leading Arabic Large Vision Language
Models (LVLMs). Lastly, we also meticulously architect a fully automated
agentic workflow for long-context Arabic document collection.

</details>


### [6] [Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets](https://arxiv.org/abs/2509.02908)
*Santosh Chapagain,Cory J Cascalheira,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi,Jillian R. Scheer*

Main category: cs.CL

TL;DR: 本研究首次全面评估了基于Transformer的模型在在线话语中检测少数群体压力的能力。结果显示，整合图结构可以显著提升Transformer模型的检测性能，使其成为数字健康干预的可靠基础。


<details>
  <summary>Details</summary>
Motivation: 性少数和性别少数群体因少数群体压力面临更高的不良健康结果和精神障碍风险。本研究旨在首次全面评估基于Transformer的架构在在线话语中检测这种压力的能力，以期为相关干预提供技术支持。

Method: 本研究基准测试了包括ELECTRA、BERT、RoBERTa和BART在内的多种Transformer模型及其图增强变体，并与传统机器学习基线进行比较。同时评估了零样本和少样本学习范式在代表性不足数据集上的适用性。实验在两个最大的Reddit少数群体压力检测公开语料库（分别包含12,645和5,789个帖子）上进行，并重复五次以确保结果的鲁棒性。

Result: 实验结果表明，在Transformer模型中整合图结构能够持续提升检测性能。此外，利用关系上下文进行监督微调的方法优于零样本和少样本方法。理论分析揭示，通过图增强建模社交连接和对话上下文，能有效提高模型识别关键语言标记（如身份隐藏、内化污名和寻求支持）的能力。

Conclusion: 研究认为，图增强的Transformer模型为数字健康干预和公共卫生政策提供了最可靠的基础，有助于通过在线话语有效检测和应对少数群体的压力问题。

Abstract: Individuals from sexual and gender minority groups experience
disproportionately high rates of poor health outcomes and mental disorders
compared to their heterosexual and cisgender counterparts, largely as a
consequence of minority stress as described by Meyer's (2003) model. This study
presents the first comprehensive evaluation of transformer-based architectures
for detecting minority stress in online discourse. We benchmark multiple
transformer models including ELECTRA, BERT, RoBERTa, and BART against
traditional machine learning baselines and graph-augmented variants. We further
assess zero-shot and few-shot learning paradigms to assess their applicability
on underrepresented datasets. Experiments are conducted on the two largest
publicly available Reddit corpora for minority stress detection, comprising
12,645 and 5,789 posts, and are repeated over five random seeds to ensure
robustness. Our results demonstrate that integrating graph structure
consistently improves detection performance across transformer-only models and
that supervised fine-tuning with relational context outperforms zero and
few-shot approaches. Theoretical analysis reveals that modeling social
connectivity and conversational context via graph augmentation sharpens the
models' ability to identify key linguistic markers such as identity
concealment, internalized stigma, and calls for support, suggesting that
graph-enhanced transformers offer the most reliable foundation for digital
health interventions and public health policy.

</details>


### [7] [English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM](https://arxiv.org/abs/2509.02915)
*Taekyung Ahn,Hosung Nam*

Main category: cs.CL

TL;DR: 本研究展示了通过LoRA适应的多模态大语言模型（MLLM）能同时进行自动发音评估（APA）和错误发音检测诊断（MDD），简化了训练流程并取得了高效准确的结果。


<details>
  <summary>Details</summary>
Motivation: 消除传统APA和MDD任务所需的复杂架构更改或独立训练程序，以建立一个更简单、一体化的发音评估系统。

Method: 利用微软的Phi-4-multimodal-instruct多模态大语言模型，采用低秩适应（LoRA）方法在Speechocean762数据集上进行微调，仅微调LoRA层，即可实现APA和MDD的同时进行。

Result: 模型预测的发音评估分数与人类评分展现出强皮尔逊相关系数（PCC > 0.7）；实现了低词错误率（WER < 0.15）和音素错误率（PER < 0.15）。值得注意的是，仅微调LoRA层即可达到与微调所有音频层相当的性能。

Conclusion: 通过LoRA对大型多模态模型进行适应，无需全面微调，即可建立一个集成、高效的发音评估系统，为英语二语学习者的计算机辅助发音训练（CAPT）提供了更便捷、集成的解决方案。

Abstract: This study demonstrates that a Multimodal Large Language Model (MLLM) adapted
via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation
Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD)
simultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our
fine-tuning method eliminates the need for complex architectural changes or
separate training procedures conventionally required for these distinct tasks.
Fine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores
predicted by the model exhibited a strong Pearson Correlation Coefficient (PCC
> 0.7) with human-assigned scores, while achieving low Word Error Rate (WER)
and Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA
layers was sufficient to achieve performance levels comparable to those
achieved by fine-tuning all audio layers. This research highlights that an
integrated pronunciation assessment system can be established by adapting large
multimodal models without full fine-tuning, utilizing a significantly simpler
training methodology compared to previous joint models designed for
simultaneous APA and MDD. This efficient LoRA-based approach paves the way for
more accessible, integrated, and effective Computer-Assisted Pronunciation
Training (CAPT) technologies for English L2 learners.

</details>


### [8] [Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities](https://arxiv.org/abs/2509.02926)
*Youngwoo Kim,Himanshu Beniwal,Steven L. Johnson,Thomas Hartvigsen*

Main category: cs.CL

TL;DR: 本研究提出一种新颖方法，从在线社区历史审核数据中提取隐性审核标准，通过可解释架构将这些标准表示为词汇模式，以透明地揭示不同社区如何实际执行内容规范，其性能可与神经网络模型媲美。


<details>
  <summary>Details</summary>
Motivation: 有效的内容审核系统需要明确的分类标准，但在线社区（如Reddit子版块）通常采用多样且隐含的标准，这使得审核效率低下且缺乏透明度。

Method: 采用一种新颖的可解释架构，从历史审核数据中识别并提取隐性审核标准。这些标准被表示为与内容删除相关的词汇表达分数表，从而实现跨社区的系统化比较。

Result: 提取出的词汇模式能有效复现神经网络审核模型的性能，并提供决策过程的透明洞察。所得的标准矩阵揭示了共享规范在实际执行中的显著差异，发现了以前未记录的审核模式，包括社区特定的语言容忍度、主题限制特征以及有毒言论分类下的潜在子类别。

Conclusion: 本研究成功地提取并透明化了隐性审核标准，证明了其有效性，并揭示了显著的、以前未被记录的社区特有审核细微差别，这对于理解和改进内容审核系统具有重要意义。

Abstract: Effective content moderation systems require explicit classification
criteria, yet online communities like subreddits often operate with diverse,
implicit standards. This work introduces a novel approach to identify and
extract these implicit criteria from historical moderation data using an
interpretable architecture. We represent moderation criteria as score tables of
lexical expressions associated with content removal, enabling systematic
comparison across different communities. Our experiments demonstrate that these
extracted lexical patterns effectively replicate the performance of neural
moderation models while providing transparent insights into decision-making
processes. The resulting criteria matrix reveals significant variations in how
seemingly shared norms are actually enforced, uncovering previously
undocumented moderation patterns including community-specific tolerances for
language, features for topical restrictions, and underlying subcategories of
the toxic speech classification.

</details>


### [9] [ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly](https://arxiv.org/abs/2509.02949)
*Kimihiro Hasegawa,Wiradee Imrattanatrai,Masaki Asada,Susan Holm,Yuran Wang,Vincent Zhou,Ken Fukuda,Teruko Mitamura*

Main category: cs.CL

TL;DR: 本文提出了一个名为ProMQA-Assembly的多模态问答数据集，用于评估组装任务助手。该数据集包含391对QA，通过半自动化标注和集成任务图创建，并用于基准测试现有模型，结果显示模型仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 组装任务助手对人类有巨大潜力，但目前缺乏支持在实际应用场景下进行系统评估的测试平台，特别是在组装领域。

Method: 1. 提出了一个新的名为ProMQA-Assembly的多模态QA数据集，包含391对QA，要求多模态理解人体活动记录及其说明手册。2. 采用半自动化QA标注方法：LLMs生成候选问题，人类进行验证，并通过集成细粒度动作标签来丰富问题类型。3. 创建了玩具车组装任务的指令任务图，用于基准测试和辅助QA标注中的人工验证。4. 利用该数据集对包括竞争性专有多模态模型在内的模型进行基准测试。

Result: 基准测试结果表明，当前模型仍有很大的改进空间。

Conclusion: 该新型评估数据集有望促进程序性活动助手的进一步发展。

Abstract: Assistants on assembly tasks have a large potential to benefit humans from
everyday tasks to industrial settings. However, no testbeds support
application-oriented system evaluation in a practical setting, especially in
assembly. To foster the development, we propose a new multimodal QA dataset on
assembly activities. Our dataset, ProMQA-Assembly, consists of 391 QA pairs
that require the multimodal understanding of human-activity recordings and
their instruction manuals in an online-style manner. In the development, we
adopt a semi-automated QA annotation approach, where LLMs generate candidates
and humans verify them, as a cost-effective method, and further improve it by
integrating fine-grained action labels to diversify question types.
Furthermore, we create instruction task graphs for the target tasks of
assembling toy vehicles. These newly created task graphs are used in our
benchmarking experiment, as well as to facilitate the human verification
process in the QA annotation. Utilizing our dataset, we benchmark models,
including competitive proprietary multimodal models. Our results suggest great
room for improvement for the current models. We believe our new evaluation
dataset can contribute to the further development of procedural-activity
assistants.

</details>


### [10] [DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling](https://arxiv.org/abs/2509.02999)
*Yougen Zhou,Ningning Zhou,Qin Chen,Jie Zhou,Aimin Zhou,Liang He*

Main category: cs.CL

TL;DR: 本文构建了一个基于认知行为疗法（CBT）的长期对话语料库DiaCBT，并利用其训练和评估了大型语言模型（LLMs）的心理咨询能力，结果表明DiaCBT能有效提升LLMs模拟CBT心理学家的能力。


<details>
  <summary>Details</summary>
Motivation: 心理治疗因社会污名和治疗师资源有限而覆盖面窄。大型语言模型（LLMs）有望扩大心理健康服务，但目前缺乏心理对话数据集，这阻碍了开发有效的心理治疗对话代理。

Method: 研究构建了一个基于认知行为疗法（CBT）的长期对话语料库（DiaCBT），该数据集包含多轮咨询会话，并融入了认知概念化图（CCDs）来指导客户模拟。随后，利用该数据集训练了一个深度咨询模型，并建立了一个全面的评估框架，根据CBT的心理学标准对其进行基准测试。

Result: 研究结果表明，DiaCBT有效地增强了LLMs模拟具有CBT专业知识的心理学家的能力。

Conclusion: DiaCBT语料库展示了其在训练更专业的心理咨询代理方面的巨大潜力。

Abstract: Psychotherapy reaches only a small fraction of individuals suffering from
mental disorders due to social stigma and the limited availability of
therapists. Large language models (LLMs), when equipped with professional
psychotherapeutic skills, offer a promising solution to expand access to mental
health services. However, the lack of psychological conversation datasets
presents significant challenges in developing effective psychotherapy-guided
conversational agents. In this paper, we construct a long-periodic dialogue
corpus for counseling based on cognitive behavioral therapy (CBT). Our curated
dataset includes multiple sessions for each counseling and incorporates
cognitive conceptualization diagrams (CCDs) to guide client simulation across
diverse scenarios. To evaluate the utility of our dataset, we train an in-depth
counseling model and present a comprehensive evaluation framework to benchmark
it against established psychological criteria for CBT-based counseling. Results
demonstrate that DiaCBT effectively enhances LLMs' ability to emulate
psychologists with CBT expertise, underscoring its potential for training more
professional counseling agents.

</details>


### [11] [Mitigating Data Imbalance in Automated Speaking Assessment](https://arxiv.org/abs/2509.03010)
*Fong-Chun Tsai,Kuan-Tang Huang,Bi-Cheng Yan,Tien-Hong Lo,Berlin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为BLV（Balancing Logit Variation）的新型损失函数，用于解决自动化口语评估（ASA）模型中类别不平衡导致的预测偏差问题，实验证明能显著提高分类准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: 自动化口语评估（ASA）模型在评估第二语言学习者熟练度时，常因类别不平衡而导致预测结果存在偏差。

Method: 引入一种名为“平衡Logit变异（BLV）损失”的新型训练目标，通过扰动模型预测来改善少数类别的特征表示，且不修改数据集。该损失被集成到一个基于BERT的文本模型中进行训练。

Result: 在ICNALE基准数据集上的评估表明，将BLV损失集成到BERT模型中显著提高了分类准确性和公平性。

Conclusion: BLV损失使自动化语音评估对不同学习者更加鲁棒，克服了类别不平衡带来的挑战。

Abstract: Automated Speaking Assessment (ASA) plays a crucial role in evaluating
second-language (L2) learners proficiency. However, ASA models often suffer
from class imbalance, leading to biased predictions. To address this, we
introduce a novel objective for training ASA models, dubbed the Balancing Logit
Variation (BLV) loss, which perturbs model predictions to improve feature
representation for minority classes without modifying the dataset. Evaluations
on the ICNALE benchmark dataset show that integrating the BLV loss into a
celebrated text-based (BERT) model significantly enhances classification
accuracy and fairness, making automated speech evaluation more robust for
diverse learners.

</details>


### [12] [Training LLMs to be Better Text Embedders through Bidirectional Reconstruction](https://arxiv.org/abs/2509.03020)
*Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 针对LLM文本嵌入器最终token语义不足问题，本文提出在对比学习前增加一个双向生成重建训练阶段，有效丰富最终token语义，从而在MTEB上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的文本嵌入方法依赖未经充分训练以捕获整个上下文语义的最终token（如[EOS]），这限制了其在检索和重排序等任务中的性能。

Method: 提出在对比学习前引入一个新的训练阶段，通过交替进行双向生成重建任务（EBQ2D和EBD2Q），锚定[EOS]嵌入并重建查询-文档对的任一侧，从而丰富最终token的语义。

Result: 实验证明，该额外训练阶段显著提升了LLM在MTEB基准测试上的性能，并在不同LLM基础模型和规模上均取得了新的最先进（SOTA）结果。

Conclusion: 本文成功通过引入新的双向生成重建训练阶段，解决了LLM最终token作为文本嵌入器语义捕获不足的问题，显著提升了模型在文本嵌入任务中的表现。

Abstract: Large language models (LLMs) have increasingly been explored as powerful text
embedders. Existing LLM-based text embedding approaches often leverage the
embedding of the final token, typically a reserved special token such as [EOS].
However, these tokens have not been intentionally trained to capture the
semantics of the whole context, limiting their capacity as text embeddings,
especially for retrieval and re-ranking tasks. We propose to add a new training
stage before contrastive learning to enrich the semantics of the final token
embedding. This stage employs bidirectional generative reconstruction tasks,
namely EBQ2D (Embedding-Based Query-to-Document) and EBD2Q (Embedding-Based
Document-to-Query), which interleave to anchor the [EOS] embedding and
reconstruct either side of Query-Document pairs. Experimental results
demonstrate that our additional training stage significantly improves LLM
performance on the Massive Text Embedding Benchmark (MTEB), achieving new
state-of-the-art results across different LLM base models and scales.

</details>


### [13] [Structure-Learnable Adapter Fine-Tuning for Parameter-Efficient Large Language Models](https://arxiv.org/abs/2509.03057)
*Ming Gong,Yingnan Deng,Nia Qi,Yujun Zou,Zhihao Xue,Yun Zi*

Main category: cs.CL

TL;DR: 本文提出一种基于结构可学习机制的适配器微调方法，旨在解决大型语言模型微调中的参数冗余、结构僵硬和任务适应性有限问题，通过自动优化适配器结构实现高效的任务特定调整，并在多任务NLU中表现出卓越的性能、压缩率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型微调中存在的参数冗余、结构僵硬和任务适应性有限等问题。

Method: 提出一种基于结构可学习机制的适配器微调方法。通过引入可微分门控函数和结构稀疏性控制变量，实现适配器插入点、激活路径和模块组合的自动优化。该方法在冻结骨干参数的同时，利用结构搜索机制动态构建任务特定的高效子结构。此外，还设计了敏感性分析实验，评估稀疏权重、噪声注入比和数据扰动对模型性能的影响。

Result: 显著提升了参数利用率和表示能力。验证了所提出方法在各种多任务自然语言理解任务中的稳定性和鲁棒性。实验结果表明，该方法在多项任务上超越了主流参数高效微调技术，并在准确性、压缩率以及对噪声和扰动的鲁棒性之间取得了更好的平衡。

Conclusion: 所提出的结构可学习的适配器微调方法有效解决了大型语言模型微调中的挑战，通过灵活调整模型结构，实现了优于现有方法的性能、压缩率和鲁棒性。

Abstract: This paper addresses the issues of parameter redundancy, rigid structure, and
limited task adaptability in the fine-tuning of large language models. It
proposes an adapter-based fine-tuning method built on a structure-learnable
mechanism. By introducing differentiable gating functions and structural
sparsity control variables, the method enables automatic optimization of
adapter insertion points, activation paths, and module combinations. This
allows the model to adjust its structure flexibly in multi-task settings to
match different task characteristics. With the backbone parameters kept frozen,
the method uses a structure search mechanism to guide the dynamic construction
of task-specific efficient substructures during training. This significantly
improves parameter utilization and representational capacity. In addition, the
paper designs a set of sensitivity analysis experiments to systematically
evaluate the effects of sparsity weight, noise injection ratio, and data
perturbation on model performance. These experiments verify the stability and
robustness of the proposed method across various multi-task natural language
understanding tasks. The experimental results show that the proposed method
outperforms mainstream parameter-efficient tuning techniques on multiple tasks.
It achieves a better balance among accuracy, compression rate, and robustness
to noise and perturbation.

</details>


### [14] [A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network](https://arxiv.org/abs/2509.03060)
*Md. Jahidul Islam Razin,Md. Abdul Karim,M. F. Mridha,S M Rafiuddin,Tahira Alam*

Main category: cs.CL

TL;DR: 本文提出并应用了一种改进的LSTM模型（基于RNN），通过处理产品评论数据集来解决商业情感分析中的梯度消失问题，实现了91.33%的准确率，并优于传统RNN模型。


<details>
  <summary>Details</summary>
Motivation: 商业情感分析（BSA）是自然语言处理领域的重要热门话题。现有情感分析技术（如基于词典和机器学习算法）已被应用于多种语言。本文旨在为商业目的，改进情感分析技术，解决传统RNN在情感分析中可能遇到的梯度消失问题。

Method: 使用长短期记忆网络（LSTM）模型，将其作为一种改进的循环神经网络（RNN）方法应用于商业情感分析，以避免梯度消失问题。实验采用产品评论数据集，其中70%用于训练，30%用于测试。将该改进RNN模型的结果与其他传统RNN模型进行比较。

Result: 实验结果显示，所提出的改进RNN模型（LSTM）表现优于其他传统RNN模型。该模型实现了约91.33%的准确率。

Conclusion: 该改进的LSTM模型能够有效识别客户对产品的反馈（喜欢或不喜欢），帮助企业或电商平台评估和调整营销策略，从而提高业务效益。

Abstract: Business sentiment analysis (BSA) is one of the significant and popular
topics of natural language processing. It is one kind of sentiment analysis
techniques for business purposes. Different categories of sentiment analysis
techniques like lexicon-based techniques and different types of machine
learning algorithms are applied for sentiment analysis on different languages
like English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM)
is applied for business sentiment analysis, where a recurrent neural network is
used. An LSTM model is used in a modified approach to prevent the vanishing
gradient problem rather than applying the conventional recurrent neural network
(RNN). To apply the modified RNN model, product review dataset is used. In this
experiment, 70\% of the data is trained for the LSTM and the rest 30\% of the
data is used for testing. The result of this modified RNN model is compared
with other conventional RNN models, and a comparison is made among the results.
It is noted that the proposed model performs better than the other conventional
RNN models. Here, the proposed model, i.e., the modified RNN model approach has
achieved around 91.33\% of accuracy. By applying this model, any business
company or e-commerce business site can identify the feedback from their
customers about different types of products that customers like or dislike.
Based on the customer reviews, a business company or e-commerce platform can
evaluate its marketing strategy.

</details>


### [15] [Measuring Scalar Constructs in Social Science with LLMs](https://arxiv.org/abs/2509.03116)
*Hauke Licht,Rupak Sarkar,Patrick Y. Wu,Pranav Goel,Niklas Stoehr,Elliott Ash,Alexander Miserlis Hoyle*

Main category: cs.CL

TL;DR: 本文评估了LLM在测量连续标量构念方面的表现。发现直接点状评分有缺陷，而通过成对比较、基于token概率加权的评分以及微调可以显著提高测量质量。


<details>
  <summary>Details</summary>
Motivation: 语言特征具有连续的语义结构。尽管大型语言模型（LLMs）是测量标量构念的潜在工具，但其处理数值输出的独特方式引发了如何最佳应用它们的问题。

Method: 研究团队通过政治学领域的多个数据集，评估了四种基于LLM的标量构念测量方法：无权重直接点状评分、成对比较聚合、基于token概率加权的点状评分以及微调。

Result: ['LLM直接生成点状分数会产生不连续的分布，并在任意数字处聚集。', 'LLM进行的成对比较能提高测量质量。', '基于token概率加权的点状评分能进一步显著提升测量质量。', '使用少至1,000个训练对微调小型模型，其性能可与提示式LLM媲美甚至超越。']

Conclusion: 对于应用研究者而言，通过LLM成对比较、基于token概率加权的点状评分以及微调小型模型是更有效且可行的测量连续标量构念的方法，优于直接点状评分。

Abstract: Many constructs that characterize language, like its complexity or
emotionality, have a naturally continuous semantic structure; a public speech
is not just "simple" or "complex," but exists on a continuum between extremes.
Although large language models (LLMs) are an attractive tool for measuring
scalar constructs, their idiosyncratic treatment of numerical outputs raises
questions of how to best apply them. We address these questions with a
comprehensive evaluation of LLM-based approaches to scalar construct
measurement in social science. Using multiple datasets sourced from the
political science literature, we evaluate four approaches: unweighted direct
pointwise scoring, aggregation of pairwise comparisons,
token-probability-weighted pointwise scoring, and finetuning. Our study yields
actionable findings for applied researchers. First, LLMs prompted to generate
pointwise scores directly from texts produce discontinuous distributions with
bunching at arbitrary numbers. The quality of the measurements improves with
pairwise comparisons made by LLMs, but it improves even more by taking
pointwise scores and weighting them by token probability. Finally, finetuning
smaller models with as few as 1,000 training pairs can match or exceed the
performance of prompted LLMs.

</details>


### [16] [From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models](https://arxiv.org/abs/2509.03122)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Xiaoling Wang,Linlin Wang*

Main category: cs.CL

TL;DR: 本文提出将知识编辑用于大语言模型（LLM）的指纹注入以进行知识产权保护，并针对微调导致的指纹降级问题提出了FSFT方法。研究还发现指纹注入模型难以区分指纹与相似文本，强调了对更鲁棒指纹方法的需求。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的知识产权保护日益重要。现有通过指令微调进行的指纹注入方法存在模型性能显著下降、计算资源消耗大以及模型修改后持久性差的问题。知识编辑被认为是更轻量、更适合指纹注入的替代方案，但尚未应用于此。此外，即使使用混淆文本，大规模微调仍导致指纹降级，且指纹注入模型难以区分指纹与相似文本。

Method: 首次将知识编辑应用于指纹注入。使用混淆文本作为指纹，以防止在微调过程中被覆盖。为解决指纹降级问题，提出了“指纹子空间感知微调（Fingerprint Subspace-aware Fine-Tuning, FSFT）”方法，通过限制指纹子空间的更新来减少指纹降级。

Result: 知识编辑在指纹注入方面表现出强大的能力。尽管使用混淆文本，在大规模微调下仍会发生指纹降级。FSFT方法在最坏情况下，性能仍比标准微调高出10%。同时，观察到指纹注入模型由于特征相似性高而难以区分指纹与相似文本。

Conclusion: 知识编辑是一种有前景的LLM指纹注入轻量级方法。FSFT能够有效解决微调导致的指纹降级问题。然而，指纹注入模型区分指纹与相似文本的挑战表明，迫切需要更鲁棒和细粒度的LLM指纹注入方法。

Abstract: The intellectual property (IP) protection of Large Language Models (LLMs) is
increasingly critical. Injecting specialized fingerprints into LLMs through
instruction tuning is a common IP protection technique. However, this may
significantly degrade model performance, requires substantial computational
resources, and exhibits poor persistence under model modifications. We argue
that knowledge editing offers a lightweight alternative that is more suitable
for fingerprint injection. Accordingly, we apply knowledge editing to
fingerprint injection for the first time and demonstrate its strong capability.
Despite using scrambled text as fingerprints to prevent them from being
overwritten during fine-tuning, degradation still occurs under large-scale
fine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning
(FSFT), which reduces fingerprint degradation by constraining the update of the
fingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even
in the worst-case scenario. Additionally, we observe that the
fingerprint-injected models struggle to distinguish between fingerprints and
similar texts due to the high similarity of their features. This finding
underscores the urgent need for more robust and fine-grained fingerprinting
injection methods for LLMs.

</details>


### [17] [An experimental and computational study of an Estonian single-person word naming](https://arxiv.org/abs/2509.03143)
*Kaidi Lõo,Arvi Tavast,Maria Heitmeier,Harald Baayen*

Main category: cs.CL

TL;DR: 本研究调查了爱沙尼亚语中的词汇处理，比较了计算模型（判别性词典模型, DLM）和经典预测因子对眼动和命名任务中词汇处理指标的预测能力，发现DLM有效且揭示了意义在命名任务中的重要作用。


<details>
  <summary>Details</summary>
Motivation: 探讨计算模型（DLM）生成的词汇处理度量是否能预测多种响应变量，并与词频、邻域大小等经典预测因子的预测能力进行比较。

Method: 采用大规模单受试者实验，结合词语命名任务和眼动追踪技术。使用广义加性模型分析五种响应变量（首次注视时长、总注视时长、注视次数、词语命名潜伏期和语音词语时长）。DLM计算模型分别通过线性和深度映射实现。

Result: DLM度量是词汇处理的强大预测因子；采用深度学习的DLM度量并非一定比采用线性映射的DLM度量更精确；经典预测因子通常比DLM预测因子提供更精确的拟合（总注视时长除外）；在命名任务中，词汇变量无法预测首次注视时长和总注视次数。

Conclusion: 由于DLM模型涉及从形式到意义的映射，其对总注视时长、命名潜伏期和语音词语时长的预测能力表明，意义在当前词语命名任务中扮演着重要角色。

Abstract: This study investigates lexical processing in Estonian. A large-scale
single-subject experiment is reported that combines the word naming task with
eye-tracking. Five response variables (first fixation duration, total fixation
duration, number of fixations, word naming latency, and spoken word duration)
are analyzed with the generalized additive model. Of central interest is the
question of whether measures for lexical processing generated by a
computational model of the mental lexicon (the Discriminative Lexicon Model,
DLM) are predictive for these response variables, and how they compare to
classical predictors such as word frequency, neighborhood size, and
inflectional paradigm size. Computational models were implemented both with
linear and deep mappings. Central findings are, first, that DLM-based measures
are powerful predictors for lexical processing, second, that DLM-measures using
deep learning are not necessarily more precise predictors of lexical processing
than DLM-measures using linear mappings, third, that classical predictors tend
to provide somewhat more precise fits compared to DLM-based predictors (except
for total fixation duration, where the two provide equivalent goodness of fit),
and fourth, that in the naming task lexical variables are not predictive for
first fixation duration and the total number of fixations. As the DLM works
with mappings from form to meaning, the predictivity of DLM-based measures for
total fixation duration, naming latencies, and spoken word duration indicates
that meaning is heavily involved in the present word naming task.

</details>


### [18] [Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader](https://arxiv.org/abs/2509.03148)
*Jannis Vamvas,Ignacio Pérez Prat,Not Battesta Soliva,Sandra Baltermia-Guetg,Andrina Beeli,Simona Beeli,Madlaina Capeder,Laura Decurtins,Gian Peder Gregori,Flavia Hobi,Gabriela Holderegger,Arina Lazzarini,Viviana Lazzarini,Walter Rosselli,Bettina Vital,Anna Rutkiewicz,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文提出了一个罗曼什语（包含六个变体）的机器翻译评估基准，并初步评估了现有系统和大型语言模型，发现罗曼什语到德语的翻译相对较好，但翻译成罗曼什语仍然具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 罗曼什语在机器翻译评估方面资源有限，限制了相关技术的发展和应用。

Method: 提出了一个包含六个罗曼什语变体（Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, Vallader）的机器翻译评估基准。参考译文由人工翻译员基于WMT24++基准创建，确保与超过55种其他语言的并行性。

Result: 对现有机器翻译系统和大型语言模型的自动评估表明，所有罗曼什语变体到德语的翻译处理得相对较好，但翻译成罗曼什语仍然具有挑战性。

Conclusion: 该研究成功弥补了罗曼什语机器翻译评估资源的不足。评估结果揭示了罗曼什语机器翻译的性能不对称性，即翻译成罗曼什语方向仍是亟待解决的难题。

Abstract: The Romansh language, spoken in Switzerland, has limited resources for
machine translation evaluation. In this paper, we present a benchmark for six
varieties of Romansh: Rumantsch Grischun, a supra-regional variety, and five
regional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Our
reference translations were created by human translators based on the WMT24++
benchmark, which ensures parallelism with more than 55 other languages. An
automatic evaluation of existing MT systems and LLMs shows that translation out
of Romansh into German is handled relatively well for all the varieties, but
translation into Romansh is still challenging.

</details>


### [19] [Domain Adaptation of LLMs for Process Data](https://arxiv.org/abs/2509.03161)
*Rafael Seidi Oyamada,Jari Peeperkorn,Jochen De Weerdt,Johannes De Smedt*

Main category: cs.CL

TL;DR: 本研究通过参数高效微调，将预训练LLM直接应用于过程数据进行预测性过程监控，无需自然语言转换，实现了优于现有方法的性能、更快的收敛和更少的优化。


<details>
  <summary>Details</summary>
Motivation: 现有过程挖掘（PM）中LLM应用主要依赖提示工程或将事件日志转换为叙述文本。本研究的动机是LLM擅长生成序列，与PM目标相似，因此旨在探索无需自然语言重构，直接将预训练LLM应用于过程数据的可能性。

Method: 采用参数高效微调技术（parameter-efficient fine-tuning）将预训练LLM直接适应于过程数据，以减轻计算开销。实验聚焦于预测性过程监控（PPM），涵盖单任务和多任务预测。

Result: 研究结果显示，本方法在预测性能上，尤其是在多任务设置中，优于最先进的循环神经网络（RNN）方法和近期基于叙述式文本的解决方案。此外，微调模型展现出更快的收敛速度，并显著减少了超参数优化需求。

Conclusion: 直接将LLM通过参数高效微调技术应用于过程数据，无需自然语言转换，在预测性过程监控中展现了潜在的性能提升、更快的收敛和更低的优化成本，为PM领域提供了新的有效途径。

Abstract: In recent years, Large Language Models (LLMs) have emerged as a prominent
area of interest across various research domains, including Process Mining
(PM). Current applications in PM have predominantly centered on prompt
engineering strategies or the transformation of event logs into narrative-style
datasets, thereby exploiting the semantic capabilities of LLMs to address
diverse tasks. In contrast, this study investigates the direct adaptation of
pretrained LLMs to process data without natural language reformulation,
motivated by the fact that these models excel in generating sequences of
tokens, similar to the objective in PM. More specifically, we focus on
parameter-efficient fine-tuning techniques to mitigate the computational
overhead typically associated with such models. Our experimental setup focuses
on Predictive Process Monitoring (PPM), and considers both single- and
multi-task predictions. The results demonstrate a potential improvement in
predictive performance over state-of-the-art recurrent neural network (RNN)
approaches and recent narrative-style-based solutions, particularly in the
multi-task setting. Additionally, our fine-tuned models exhibit faster
convergence and require significantly less hyperparameter optimization.

</details>


### [20] [SinhalaMMLU: A Comprehensive Benchmark for Evaluating Multitask Language Understanding in Sinhala](https://arxiv.org/abs/2509.03162)
*Ashmari Pramodya,Nirasha Nelki,Heshan Shalinda,Chamila Liyanage,Yusuke Sakai,Randil Pushpananda,Ruvan Weerasinghe,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 本文介绍了SinhalaMMLU，一个为低资源语言僧伽罗语设计的首个多项选择问答基准，旨在评估大型语言模型在文化特定内容上的表现，并发现现有模型在该领域的表现仍有限。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估主要集中于全球性或英语中心主题，忽视低资源语言及文化特定内容。多语言基准多依赖机器翻译，易引入错误并歪曲文化背景。因此，需要一个针对低资源语言（如僧伽罗语）的、高质量的、文化敏感的评估基准。

Method: 开发了SinhalaMMLU，一个包含7000多个问题的多项选择问答基准，涵盖中学到大学教育水平，与斯里兰卡国家课程对齐，包括六个领域和30个学科，既有通用学术主题也有文化根植知识。在该基准上评估了26个LLM。

Result: Claude 3.5 sonnet和GPT-4o表现最佳，平均准确率分别为67%和62%，但整体模型性能仍有限。尤其在人文等文化丰富领域，模型表现不佳。

Conclusion: LLM在低资源和文化特定背景下仍有巨大改进空间，尤其是在处理文化丰富领域时。SinhalaMMLU为评估和改进LLM在该领域的能力提供了重要工具。

Abstract: Large Language Models (LLMs) demonstrate impressive general knowledge and
reasoning abilities, yet their evaluation has predominantly focused on global
or anglocentric subjects, often neglecting low-resource languages and
culturally specific content. While recent multilingual benchmarks attempt to
bridge this gap, many rely on automatic translation, which can introduce errors
and misrepresent the original cultural context. To address this, we introduce
SinhalaMMLU, the first multiple-choice question answering benchmark designed
specifically for Sinhala, a low-resource language. The dataset includes over
7,000 questions spanning secondary to collegiate education levels, aligned with
the Sri Lankan national curriculum, and covers six domains and 30 subjects,
encompassing both general academic topics and culturally grounded knowledge. We
evaluate 26 LLMs on SinhalaMMLU and observe that, while Claude 3.5 sonnet and
GPT-4o achieve the highest average accuracies at 67% and 62% respectively,
overall model performance remains limited. In particular, models struggle in
culturally rich domains such as the Humanities, revealing substantial room for
improvement in adapting LLMs to low-resource and culturally specific contexts.

</details>


### [21] [Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge](https://arxiv.org/abs/2509.03256)
*Aleksei Žavoronkov,Tanel Alumäe*

Main category: cs.CL

TL;DR: 本文为NOCASA 2025挑战赛，开发并分析了三种面向学习挪威语儿童的单词级发音评估端到端模型，其中基于GOP-CTC的模型表现最优并取得了顶尖成绩。


<details>
  <summary>Details</summary>
Motivation: 为NOCASA 2025挑战赛开发自动单词级发音评估模型，以帮助学习挪威语的儿童。

Method: 开发并分析了三种端到端模型：编码器-解码器Siamese架构 (E2E-R)、利用预训练wav2vec2.0表示的prefix-tuned直接分类模型、以及整合CTC计算的无需对齐GOP（发音质量）特征的新模型。引入了加权有序交叉熵损失函数。

Result: 在所探索的方法中，基于GOP-CTC的模型性能最佳，显著超越了挑战赛基线，并获得了排行榜前列的成绩。

Conclusion: 所提出的基于GOP-CTC的模型在自动儿童挪威语单词级发音评估任务中表现出色，成功应对了NOCASA 2025挑战赛。

Abstract: This paper presents an analysis of three end-to-end models developed for the
NOCASA 2025 Challenge, aimed at automatic word-level pronunciation assessment
for children learning Norwegian as a second language. Our models include an
encoder-decoder Siamese architecture (E2E-R), a prefix-tuned direct
classification model leveraging pretrained wav2vec2.0 representations, and a
novel model integrating alignment-free goodness-of-pronunciation (GOP) features
computed via CTC. We introduce a weighted ordinal cross-entropy loss tailored
for optimizing metrics such as unweighted average recall and mean absolute
error. Among the explored methods, our GOP-CTC-based model achieved the highest
performance, substantially surpassing challenge baselines and attaining top
leaderboard scores.

</details>


### [22] [LatPhon: Lightweight Multilingual G2P for Romance Languages and English](https://arxiv.org/abs/2509.03300)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatPhon是一个针对拉丁语系的紧凑型多语言G2P Transformer模型，在性能和内存效率上表现出色，适用于设备端部署。


<details>
  <summary>Details</summary>
Motivation: G2P转换是TTS、ASR、S2ST及对齐系统，尤其是跨多种拉丁语系语言的关键前端。

Method: 提出LatPhon模型，一个7.5M参数的Transformer，联合训练了六种拉丁语系语言（英语、西班牙语、法语、意大利语、葡萄牙语和罗马尼亚语）。

Result: 在ipa-dict语料库上，平均音素错误率（PER）为3.5%，优于ByT5基线（5.4%），接近特定语言的WFST（3.2%）。此外，其内存占用仅30MB，支持设备端部署。

Conclusion: 紧凑型多语言G2P模型（如LatPhon）可以作为拉丁语系语音处理管道的通用前端。

Abstract: Grapheme-to-phoneme (G2P) conversion is a key front-end for text-to-speech
(TTS), automatic speech recognition (ASR), speech-to-speech translation (S2ST)
and alignment systems, especially across multiple Latin-script languages.We
present LatPhon, a 7.5 M - parameter Transformer jointly trained on six such
languages--English, Spanish, French, Italian, Portuguese, and Romanian. On the
public ipa-dict corpus, it attains a mean phoneme error rate (PER) of 3.5%,
outperforming the byte-level ByT5 baseline (5.4%) and approaching
language-specific WFSTs (3.2%) while occupying 30 MB of memory, which makes
on-device deployment feasible when needed. These results indicate that compact
multilingual G2P can serve as a universal front-end for Latin-language speech
pipelines.

</details>


### [23] [AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?](https://arxiv.org/abs/2509.03312)
*Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan*

Main category: cs.CL

TL;DR: 本文提出AgenTracer，一个自动化的框架，通过反事实重放和编程故障注入，为多智能体系统失败轨迹进行标注，并训练出轻量级模型AgenTracer-8B，显著提升了LLM智能体故障归因的准确性，并能为现有系统提供可操作的反馈以实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 多模型、复杂工具调用和编排协议的LLM智能体系统虽然性能优越，但也因其复杂性而更易出现系统故障。现有最先进的推理LLMs在定位长执行轨迹中错误源头的任务上表现极差（准确率低于10%），因此需要一种有效的方法来解决智能体系统故障归因的挑战。

Method: 研究者提出了AgenTracer框架，通过反事实重放和编程故障注入，自动标注失败的多智能体轨迹，生成了TracerTraj数据集。在此基础上，他们开发了AgenTracer-8B，一个轻量级的故障追踪器，采用多粒度强化学习进行训练，以高效诊断多智能体交互中的错误。

Result: AgenTracer-8B在Who&When基准测试上，性能优于Gemini-2.5-Pro和Claude-4-Sonnet等巨型专有LLMs高达18.18%，在LLM智能体故障归因领域树立了新标准。更重要的是，AgenTracer-8B能为MetaGPT和MaAS等现有多智能体系统提供可操作的反馈，使其性能提升4.8-14.2%。

Conclusion: AgenTracer-8B通过其创新的框架和模型，显著提升了LLM智能体故障归因的准确性和效率，超越了大型专有模型。它不仅设立了新的性能标准，还通过提供可操作的反馈，赋能了自修正和自进化的智能体AI系统。

Abstract: Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the specific
agent or step responsible for an error within long execution traces defines the
task of agentic system failure attribution. Current state-of-the-art reasoning
LLMs, however, remain strikingly inadequate for this challenge, with accuracy
generally below 10%. To address this gap, we propose AgenTracer, the first
automated framework for annotating failed multi-agent trajectories via
counterfactual replay and programmed fault injection, producing the curated
dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a
lightweight failure tracer trained with multi-granular reinforcement learning,
capable of efficiently diagnosing errors in verbose multi-agent interactions.
On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs
like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard
in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers
actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS
with 4.8-14.2% performance gains, empowering self-correcting and self-evolving
agentic AI.

</details>


### [24] [LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations](https://arxiv.org/abs/2509.03405)
*Daniela Gottesman,Alon Gilae-Dotan,Ido Cohen,Yoav Gur-Arieh,Marius Mosbach,Ori Yoran,Mor Geva*

Main category: cs.CL

TL;DR: 本文提出了LMEnt，一套用于分析语言模型在预训练期间知识获取的工具，包含一个知识丰富的语料库、一种实体检索方法和一系列预训练模型，并初步发现事实频率是知识获取的关键因素。


<details>
  <summary>Details</summary>
Motivation: 语言模型广泛应用于需要世界知识的场景，但其内部如何从数据中获取和表示知识的机制尚不清楚。理解这些机制有助于开发出更一致、鲁棒和完整的知识表示。

Method: 提出了LMEnt，一个用于分析语言模型知识获取的套件，包括：1) 基于维基百科、带有实体标注的知识丰富预训练语料库；2) 一种性能优于现有方法80.4%的实体级检索方法；3) 12个预训练模型及其4000个中间检查点。这些资源共同提供了一个受控环境来分析预训练数据中实体提及与下游性能的关系。

Result: 利用LMEnt研究了跨检查点的知识获取，发现事实频率是关键因素，但不能完全解释学习趋势。

Conclusion: LMEnt为研究语言模型中的知识表示、可塑性、编辑、归因和学习动态提供了基础资源和受控环境。该套件已被发布，以支持社区进行相关研究。

Abstract: Language models (LMs) increasingly drive real-world applications that require
world knowledge. However, the internal processes through which models turn data
into representations of knowledge and beliefs about the world, are poorly
understood. Insights into these processes could pave the way for developing LMs
with knowledge representations that are more consistent, robust, and complete.
To facilitate studying these questions, we present LMEnt, a suite for analyzing
knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a
knowledge-rich pretraining corpus, fully annotated with entity mentions, based
on Wikipedia, (2) an entity-based retrieval method over pretraining data that
outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained
models with up to 1B parameters and 4K intermediate checkpoints, with
comparable performance to popular open-sourced models on knowledge benchmarks.
Together, these resources provide a controlled environment for analyzing
connections between entity mentions in pretraining and downstream performance,
and the effects of causal interventions in pretraining data. We show the
utility of LMEnt by studying knowledge acquisition across checkpoints, finding
that fact frequency is key, but does not fully explain learning trends. We
release LMEnt to support studies of knowledge in LMs, including knowledge
representations, plasticity, editing, attribution, and learning dynamics.

</details>


### [25] [Learning Mechanism Underlying NLP Pre-Training and Fine-Tuning](https://arxiv.org/abs/2509.03407)
*Yarden Tzach,Ronit D. Gross,Ella Koresh,Shalom Rosner,Or Shpringer,Tal Halevi,Ido Kanter*

Main category: cs.CL

TL;DR: 本研究通过分析BERT-6预训练机制，发现预训练能通过打破词元对称性并形成强匹配词元簇来生成高阶语言结构，显著提升下游分类任务的微调准确性，并暗示了该机制的普遍性。


<details>
  <summary>Details</summary>
Motivation: 理解成功预训练的内在机制；确定预训练准确性与分类任务微调之间的相互作用。

Method: 采用BERT-6架构，在维基百科数据集上进行预训练，并在FewRel和DBpedia分类任务上进行微调。分析了每个词元的准确性（APT）和词元混淆矩阵。

Result: 词元准确性（APT）随其在数据集中出现频率的增加而提高，并作为衡量预训练成功与否的序参量，在Transformer块中逐渐增加。预训练打破了词元间的对称性，将其分组为有限、小而强的匹配词元簇。这种特性在Transformer块中愈发显著，显著提升了性能。预训练生成了高阶语言结构。这些预训练的发现体现在微调准确性沿Transformer块的提升。输出标签预测置信度与平均输入APT无关。预训练的内在机制与NLP分类微调任务相似，暗示其普遍性。

Conclusion: 预训练通过创建高阶语言结构和词元簇，对Transformer模型性能至关重要，其作用不仅限于单个词元识别，且该机制可能具有跨模态的普遍性。

Abstract: Natural language processing (NLP) enables the understanding and generation of
meaningful human language, typically using a pre-trained complex architecture
on a large dataset to learn the language and next fine-tune its weights to
implement a specific task. Twofold goals are examined; to understand the
mechanism underlying successful pre-training and to determine the interplay
between the pre-training accuracy and the fine-tuning of classification tasks.
The following main results were obtained; the accuracy per token (APT)
increased with its appearance frequency in the dataset, and its average over
all tokens served as an order parameter to quantify pre-training success, which
increased along the transformer blocks. Pre-training broke the symmetry among
tokens and grouped them into finite, small, strong match token clusters, as
inferred from the presented token confusion matrix. This feature was sharpened
along the transformer blocks toward the output layer, enhancing its performance
considerably compared with that of the embedding layer. Consequently,
higher-order language structures were generated by pre-training, even though
the learning cost function was directed solely at identifying a single token.
These pre-training findings were reflected by the improved fine-tuning accuracy
along the transformer blocks. Additionally, the output label prediction
confidence was found to be independent of the average input APT, as the input
meaning was preserved since the tokens are replaced primarily by strong match
tokens. Finally, although pre-training is commonly absent in image
classification tasks, its underlying mechanism is similar to that used in
fine-tuning NLP classification tasks, hinting at its universality. The results
were based on the BERT-6 architecture pre-trained on the Wikipedia dataset and
fine-tuned on the FewRel and DBpedia classification tasks.

</details>


### [26] [Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges](https://arxiv.org/abs/2509.03419)
*Weiyuan Li,Xintao Wang,Siyu Yuan,Rui Xu,Jiangjie Chen,Qingqing Dong,Yanghua Xiao,Deqing Yang*

Main category: cs.CL

TL;DR: 本文构建了ComplexEval基准，系统地揭示并量化了LLM作为评估者在复杂任务中存在的辅助信息诱导偏见。研究发现所有模型都易受这些偏见影响，且偏见程度随任务复杂性增加，大型推理模型表现出反常的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)能力增强，它们面临的任务日益多样和复杂，可靠的评估变得具有挑战性。尽管LLMs作为评估者的范式已成为可扩展的解决方案，但此前工作主要关注简单场景，它们在复杂任务（涉及多面性评估标准、非结构化参考答案和细致标准）中的可靠性仍未得到充分研究。

Method: 构建了名为ComplexEval的挑战基准，旨在系统地揭示和量化辅助信息诱导偏见。系统地调查并验证了在12个基本场景和3个高级场景中，6种此前未探索的偏见。

Result: (1) 所有被评估的模型都表现出对这些偏见的显著敏感性，偏见程度随任务复杂性增加而扩大；(2) 值得注意的是，大型推理模型（LRMs）表现出反常的脆弱性。

Conclusion: 深入分析为提高评估信号的准确性和可验证性提供了关键见解，为开发更通用、更鲁棒的评估模型铺平了道路。

Abstract: As large language models (LLMs) grow more capable, they face increasingly
diverse and complex tasks, making reliable evaluation challenging. The paradigm
of LLMs as judges has emerged as a scalable solution, yet prior work primarily
focuses on simple settings. Their reliability in complex tasks--where
multi-faceted rubrics, unstructured reference answers, and nuanced criteria are
critical--remains understudied. In this paper, we constructed ComplexEval, a
challenge benchmark designed to systematically expose and quantify Auxiliary
Information Induced Biases. We systematically investigated and validated 6
previously unexplored biases across 12 basic and 3 advanced scenarios. Key
findings reveal: (1) all evaluated models exhibit significant susceptibility to
these biases, with bias magnitude scaling with task complexity; (2) notably,
Large Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth
analysis offers crucial insights for improving the accuracy and verifiability
of evaluation signals, paving the way for more general and robust evaluation
models.

</details>


### [27] [Continuous Saudi Sign Language Recognition: A Vision Transformer Approach](https://arxiv.org/abs/2509.03467)
*Soukeina Elhassen,Lama Al Khuzayem,Areej Alhothali,Ohoud Alzamzami,Nahed Alowaidi*

Main category: cs.CL

TL;DR: 本文创建了首个连续沙特手语数据集KAU-CSSL，并提出了一个基于Transformer的模型，用于沙特手语（SSL）的识别和翻译，解决了阿拉伯手语资源匮乏的问题，并在不同模式下取得了高精度。


<details>
  <summary>Details</summary>
Motivation: 沙特手语（SSL）对听障人士至关重要，但社会意识有限导致教育和职业机会不均。现有技术主要关注非阿拉伯手语，导致阿拉伯手语（尤其是SSL）资源严重缺乏，且现有数据集多为孤立词而非连续语句。因此，急需更精确、可靠的SSL翻译技术。

Method: 研究引入了首个连续沙特手语数据集KAU-CSSL，该数据集专注于完整句子。同时，提出了一种基于Transformer的模型，该模型利用预训练的ResNet-18进行空间特征提取，并结合Transformer编码器和双向LSTM来处理时间依赖性。

Result: 模型在与签名者相关的模式下实现了99.02%的准确率，在与签名者独立的模式下实现了77.71%的准确率。

Conclusion: 这项研究不仅为SSL社区改进了通信工具，也为更广泛的手语领域做出了重大贡献，为未来的SSL识别和翻译系统奠定了基础。

Abstract: Sign language (SL) is an essential communication form for hearing-impaired
and deaf people, enabling engagement within the broader society. Despite its
significance, limited public awareness of SL often leads to inequitable access
to educational and professional opportunities, thereby contributing to social
exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend
on Saudi Sign Language (SSL) as their primary form of communication. Although
certain technological approaches have helped to improve communication for
individuals with hearing impairments, there continues to be an urgent
requirement for more precise and dependable translation techniques, especially
for Arabic sign language variants like SSL. Most state-of-the-art solutions
have primarily focused on non-Arabic sign languages, resulting in a
considerable absence of resources dedicated to Arabic sign language,
specifically SSL. The complexity of the Arabic language and the prevalence of
isolated sign language datasets that concentrate on individual words instead of
continuous speech contribute to this issue. To address this gap, our research
represents an important step in developing SSL resources. To address this, we
introduce the first continuous Saudi Sign Language dataset called KAU-CSSL,
focusing on complete sentences to facilitate further research and enable
sophisticated recognition systems for SSL recognition and translation.
Additionally, we propose a transformer-based model, utilizing a pretrained
ResNet-18 for spatial feature extraction and a Transformer Encoder with
Bidirectional LSTM for temporal dependencies, achieving 99.02\% accuracy at
signer dependent mode and 77.71\% accuracy at signer independent mode. This
development leads the way to not only improving communication tools for the SSL
community but also making a substantial contribution to the wider field of sign
language.

</details>


### [28] [Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games](https://arxiv.org/abs/2509.03479)
*Haonan Wang,Mingjia Zhao,Junfeng Sun,Wei Liu*

Main category: cs.CL

TL;DR: 提出一种结合深度学习世界模型与策略梯度DRL的文本游戏智能体，显著提升游戏完成率和胜率。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术发展，代理玩文本游戏的研究日益流行，本文旨在提出一种新颖的方法来改进文本游戏智能体的设计和学习。

Method: 结合深度学习和强化学习。首先，使用深度学习模型处理游戏文本并构建世界模型；其次，通过基于策略梯度的深度强化学习方法学习智能体，以实现从状态值到最优策略的转换。

Result: 增强型智能体在多个文本游戏实验中表现更优，在游戏完成率和胜率方面显著超越了以往的智能体。

Conclusion: 该研究为在文本游戏中使用强化学习提供了新颖的理解和实证基础，并为开发更通用领域和问题的强化学习智能体奠定了基础。

Abstract: As AI technology advances, research in playing text-based games with agents
has becomeprogressively popular. In this paper, a novel approach to agent
design and agent learning ispresented with the context of reinforcement
learning. A model of deep learning is first applied toprocess game text and
build a world model. Next, the agent is learned through a policy gradient-based
deep reinforcement learning method to facilitate conversion from state value to
optimal policy.The enhanced agent works better in several text-based game
experiments and significantlysurpasses previous agents on game completion ratio
and win rate. Our study introduces novelunderstanding and empirical ground for
using reinforcement learning for text games and sets thestage for developing
and optimizing reinforcement learning agents for more general domains
andproblems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [29] [2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model](https://arxiv.org/abs/2509.02659)
*Zilong Guo,Yi Luo,Long Sha,Dongxu Wang,Panqu Wang,Chenyang Xu,Yi Yang*

Main category: cs.CV

TL;DR: 本文结合端到端自动驾驶架构与多模态视觉语言模型（VLM），仅使用单摄像头便在驾驶任务中取得优异性能，成为目前排行榜上最佳的纯摄像头解决方案。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶受到广泛关注，但其架构多基于模块化深度神经网络。研究动机在于探讨强大的大型语言模型（LLM），特别是多模态视觉语言模型（VLM），能否有效提升端到端驾驶任务的性能。

Method: 将端到端架构设计与知识丰富的视觉语言模型（VLM）相结合，并仅使用单个摄像头作为输入。

Result: 在驾驶任务上取得了令人印象深刻的性能，并且是排行榜上最佳的纯摄像头解决方案。

Conclusion: 该研究证明了视觉基础驾驶方法的有效性，以及结合VLMs的端到端驾驶任务的巨大潜力。

Abstract: End-to-end autonomous driving has drawn tremendous attention recently. Many
works focus on using modular deep neural networks to construct the end-to-end
archi-tecture. However, whether using powerful large language models (LLM),
especially multi-modality Vision Language Models (VLM) could benefit the
end-to-end driving tasks remain a question. In our work, we demonstrate that
combining end-to-end architectural design and knowledgeable VLMs yield
impressive performance on the driving tasks. It is worth noting that our method
only uses a single camera and is the best camera-only solution across the
leaderboard, demonstrating the effectiveness of vision-based driving approach
and the potential for end-to-end driving tasks.

</details>


### [30] [PixFoundation 2.0: Do Video Multi-Modal LLMs Use Motion in Visual Grounding?](https://arxiv.org/abs/2509.02807)
*Mennatullah Siam*

Main category: cs.CV

TL;DR: 本文研究视频多模态大语言模型在像素级视觉定位中对运动模式的利用能力，揭示现有基准的不足，并提出了一个以运动为中心的MoCentric-Bench基准和适应技术，以促进对视频中时空像素级理解的改进。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在图像和文本任务上表现出色，但其在视频领域的像素级视觉定位能力，特别是对运动模式的利用，尚待充分研究。现有基准常被静态外观线索主导，导致单个帧即可满足运动指代表达，而无需真正的时序推理。

Method: 识别了当前基准的不足，并引入了四种以运动为中心的探测技术，专门用于视觉定位任务，以研究视频MLLMs识别真假运动和理解运动顺序的能力。在此基础上，构建了一个以运动为中心的基准MoCentric-Bench，以确保模型在运动与语言交互方面进行评估。此外，建立了强大的单图像基线，并探索了简单的运动中心适应技术。

Result: 研究发现现有基准往往无需时序推理，单个帧即可捕获运动指代表达式。MoCentric-Bench确保了对视频MLLMs在利用运动和语言交互方面的评估，而非被静态外观线索主导。建立的单图像基线与现有方法持平或超越。提出的运动中心适应技术在MoCentric-Bench上取得了最先进的性能。

Conclusion: 所提出的以运动为中心的基准、评估方法和研究发现，对未来模型提出了挑战，要求其改进视频中的密集时空定位和像素级理解。

Abstract: Multi-modal large language models (MLLMs) have shown impressive
generalization across tasks using images and text modalities. While their
extension to video has enabled tasks such as video question answering and video
captioning, their pixel-level visual grounding abilities are less studied. In
this work, we raise the pertinent question of whether motion is used in
pixel-level visual grounding and whether video MLLMs can segment objects based
on natural language expressions describing their motion patterns. We identify
the shortcomings in the current benchmarks, where we show that a single frame
can often suffice for capturing the motion referring expression without any
temporal reasoning. To address this, we introduce four motion-centric probing
techniques, particularly designed for the visual grounding task, to study video
MLLMs' ability to identify true motion from a fake one and their ability to
grasp the motion order. Consequently, we provide a motion-centric benchmark,
MoCentric-Bench. It ensures that video MLLMs are evaluated towards leveraging
the interaction between motion and language rather than being dominated by
static appearance cues emphasized in existing visual grounding datasets. We
further establish strong single-image baselines that are on par with or
outperform prior methods. Finally, we explore simple motion-centric adaptation
techniques that provide state-of-the-art performance on our MoCentric-Bench.
Our motion-centric benchmark, evaluation and findings challenge future models
to improve dense spatiotemporal grounding and pixel-level understanding within
videos. Code and datasets will be made publicly available at
https://github.com/MSiam/PixFoundation-2.0.git.

</details>


### [31] [Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach](https://arxiv.org/abs/2509.02851)
*Sadra Saremi,Amirhossein Ahmadkhan Kordbacheh*

Main category: cs.CV

TL;DR: 本研究提出了一种混合多尺度深度学习架构HG-TNet，结合胶囊网络、图注意力、Transformer和残差学习，用于结肠癌组织病理图像分类，并在LC25000数据集上实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 结肠癌是全球最恶性的癌症之一，早期检测对其防治至关重要。

Method: 本研究提出一种混合多尺度深度学习架构HG-TNet，融合了胶囊网络、图注意力机制、Transformer模块和残差学习。模型包含一个Transformer分支，通过卷积补丁嵌入和Transformer编码器提取全局上下文特征；以及一个CNN分支，捕获细粒度局部细节。此外，还结合了自监督旋转预测目标以生成鲁棒的诊断表示。

Result: 实验结果表明，该模型在准确性和损失函数方面均表现出更优的性能。通过利用胶囊网络保留空间顺序并理解元素组合形成整体结构的方式，模型实现了比标准架构更强大的诊断表示。

Conclusion: 所提出的混合多尺度深度学习架构（HG-TNet）通过有效结合多尺度特征捕获和空间信息保留能力，显著提升了结肠癌组织病理图像的分类性能，为早期诊断提供了更鲁棒的工具。

Abstract: Colon cancer also known as Colorectal cancer, is one of the most malignant
types of cancer worldwide. Early-stage detection of colon cancer is highly
crucial to prevent its deterioration. This research presents a hybrid
multi-scale deep learning architecture that synergizes capsule networks, graph
attention mechanisms, transformer modules, and residual learning to advance
colon cancer classification on the Lung and Colon Cancer Histopathological
Image Dataset (LC25000) dataset. The proposed model in this paper utilizes the
HG-TNet model that introduces a hybrid architecture that joins strength points
in transformers and convolutional neural networks to capture multi-scale
features in histopathological images. Mainly, a transformer branch extracts
global contextual bonds by partitioning the image into patches by
convolution-based patch embedding and then processing these patches through a
transformer encoder. Analogously, a dedicated CNN branch captures fine-grained,
local details through successive Incorporation these diverse features, combined
with a self-supervised rotation prediction objective, produce a robust
diagnostic representation that surpasses standard architectures in performance.
Results show better performance not only in accuracy or loss function but also
in these algorithms by utilizing capsule networks to preserve spatial orders
and realize how each element individually combines and forms whole structures.

</details>


### [32] [PRECISE-AS: Personalized Reinforcement Learning for Efficient Point-of-Care Echocardiography in Aortic Stenosis Diagnosis](https://arxiv.org/abs/2509.02898)
*Armin Saadat,Nima Hashemi,Hooman Vaseli,Michael Y. Tsang,Christina Luong,Michiel Van de Panne,Teresa S. M. Tsang,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 针对主动脉瓣狭窄（AS）诊断中超声心动图资源受限问题，本文提出一种基于强化学习的主动视频采集框架，动态选择最具信息量的超声视频。该方法在大幅减少视频使用量的同时，实现了80.6%的分类准确率，显著提升了诊断效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 主动脉瓣狭窄（AS）是一种常见且危及生命的疾病。尽管超声心动图是诊断金标准，但其可及性受限于资源，尤其在农村和欠发达地区。床旁超声（POCUS）虽具可及性，却受限于操作者专业知识和相关成像视图的选择挑战。传统方法依赖固定视图集，效率不高。

Method: 本文提出一个由强化学习（RL）驱动的主动视频采集框架，该框架能动态选择每个患者最具信息量的超声视频。与依赖固定视频集的传统方法不同，该方法持续评估是否需要额外成像，以优化诊断准确性和效率。

Result: 该方法在2,572名患者的数据上进行了测试，结果显示，在仅使用完整采集视频量47%的情况下，实现了80.6%的分类准确率。

Conclusion: 研究结果表明，主动特征采集技术能够增强AS诊断，使超声心动图评估更加高效、可扩展和个性化。

Abstract: Aortic stenosis (AS) is a life-threatening condition caused by a narrowing of
the aortic valve, leading to impaired blood flow. Despite its high prevalence,
access to echocardiography (echo), the gold-standard diagnostic tool, is often
limited due to resource constraints, particularly in rural and underserved
areas. Point-of-care ultrasound (POCUS) offers a more accessible alternative
but is restricted by operator expertise and the challenge of selecting the most
relevant imaging views. To address this, we propose a reinforcement learning
(RL)-driven active video acquisition framework that dynamically selects each
patient's most informative echo videos. Unlike traditional methods that rely on
a fixed set of videos, our approach continuously evaluates whether additional
imaging is needed, optimizing both accuracy and efficiency. Tested on data from
2,572 patients, our method achieves 80.6% classification accuracy while using
only 47% of the echo videos compared to a full acquisition. These results
demonstrate the potential of active feature acquisition to enhance AS
diagnosis, making echocardiographic assessments more efficient, scalable, and
personalized. Our source code is available at:
https://github.com/Armin-Saadat/PRECISE-AS.

</details>


### [33] [LiGuard: A Streamlined Open-Source Framework for Rapid & Interactive Lidar Research](https://arxiv.org/abs/2509.02902)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: LiGuard是一个开源软件框架，旨在通过提供内置支持、交互式算法管理和可视化功能，简化激光雷达（LiDAR）项目的代码开发，解决代码重复和修改难题，并促进代码共享。


<details>
  <summary>Details</summary>
Motivation: 激光雷达在自动驾驶和智能交通系统（ITS）中日益受到关注。然而，研究人员为特定应用开发专用代码，导致大量重复工作，且数据、算法或研究重点的微小变化可能导致代码进行重大修改，效率低下。

Method: 本文提出了LiGuard，一个开源软件框架。它提供内置的数据I/O、预/后处理和常用算法支持，使用户能够快速开发代码。LiGuard还允许交互式地添加、删除、重新排序自定义算法并调整参数，以及可视化分类、检测、分割和跟踪任务的结果。此外，它通过结构化目录便于项目的整体或组件的共享与重用。

Result: 通过案例研究证明了LiGuard框架的有效性。

Conclusion: LiGuard有效解决了激光雷达研究中代码开发重复和修改困难的问题，通过提供集成工具、交互式功能和便捷的共享机制，显著提高了开发效率、灵活性和代码的可重用性。

Abstract: There is a growing interest in the development of lidar-based autonomous
mobility and Intelligent Transportation Systems (ITS). To operate and research
on lidar data, researchers often develop code specific to application niche.
This approach leads to duplication of efforts across studies that, in many
cases, share multiple methodological steps such as data input/output (I/O),
pre/post processing, and common algorithms in multi-stage solutions. Moreover,
slight changes in data, algorithms, and/or research focus may force major
revisions in the code. To address these challenges, we present LiGuard, an
open-source software framework that allows researchers to: 1) rapidly develop
code for their lidar-based projects by providing built-in support for data I/O,
pre/post processing, and commonly used algorithms, 2) interactively
add/remove/reorder custom algorithms and adjust their parameters, and 3)
visualize results for classification, detection, segmentation, and tracking
tasks. Moreover, because it creates all the code files in structured
directories, it allows easy sharing of entire projects or even the individual
components to be reused by other researchers. The effectiveness of LiGuard is
demonstrated via case studies.

</details>


### [34] [PercepTwin: Modeling High-Fidelity Digital Twins for Sim2Real LiDAR-based Perception for Intelligent Transportation Systems](https://arxiv.org/abs/2509.02903)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: 本文提出一种使用高保真数字孪生创建大规模、高质量合成LiDAR数据集的严谨方法，以解决真实世界数据标注成本高昂的问题，并为鲁棒的Sim2Real学习奠定基础。


<details>
  <summary>Details</summary>
Motivation: LiDAR感知系统的深度学习模型需要大量标注数据才能实现泛化，但真实世界数据创建成本高昂、耗时且需人工参与，阻碍了系统扩展。现有Sim2Real学习的有效性受限于仿真环境与真实世界的保真度。

Method: 引入一种严谨且可复现的方法论，利用高保真数字孪生（HiFi DTs）创建大规模、高质量合成数据集。该工作流概述了数字复制真实世界环境的步骤、工具和最佳实践，包括静态几何建模、道路基础设施复刻和动态交通场景生成，并利用卫星图像、OpenStreetMap等开源资源和特定传感器配置。

Result: 所提出的方法能够促进生成可扩展、经济高效且多样化的合成数据集。

Conclusion: 这些合成环境为鲁棒的Sim2Real学习提供了可靠基础，有效解决了LiDAR感知系统中数据获取的规模化、成本和多样性难题。

Abstract: LiDAR-based perception in intelligent transportation systems (ITS), for tasks
such as object detection, tracking, and semantic and instance segmentation, is
predominantly solved by deep neural network models which often require
large-scale labeled datasets during training to achieve generalization.
However, creating these datasets is costly. time consuming and require human
labor before the datasets are ready for training models. This hinders
scalability of the LiDAR-based perception systems in ITS. Sim2Real learning
offers scalable alternative, however, its effectiveness is dependent on the
fidelity of the source simulation(s) to real-world, in terms of environment
structure, actor dynamics, and sensor emulations. In response, this paper
introduces a rigorous and reproducible methodology for creating large-scale,
high-quality synthetic datasets using High-Fidelity Digital Twins (HiFi DTs).
The proposed workflow outlines the steps, tools, and best practices for
digitally replicating real-world environments, encompassing static geometry
modeling, road infrastructure replication, and dynamic traffic scenario
generation. Leveraging open-source and readily available resources such as
satellite imagery and OpenStreetMap data, alongside specific sensor
configurations, this paper provides practical, detailed guidance for
constructing robust synthetic environments. These environments subsequently
facilitate scalable, cost-effective, and diverse dataset generation, forming a
reliable foundation for robust Sim2Real learning.

</details>


### [35] [High-Fidelity Digital Twins for Bridging the Sim2Real Gap in LiDAR-Based ITS Perception](https://arxiv.org/abs/2509.02904)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: 为解决Sim2Real LiDAR感知中的领域漂移问题，本文提出高保真数字孪生（HiFi DT）框架，通过精确模拟真实环境减少领域差距。实验证明，基于HiFi DT合成数据训练的模型性能优于基于真实数据训练的模型4.8%，并能显著降低领域漂移，提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在智能交通系统（ITS）中，Sim2Real领域迁移为基于LiDAR的感知提供了经济高效且可扩展的方法。然而，由于数据分布差异（领域漂移），在仿真中训练的感知模型在真实世界数据上的性能通常不佳，亟需解决Sim2Real差距。

Method: 本文提出了一个高保真数字孪生（HiFi DT）框架，该框架融入了真实世界的背景几何、车道级道路拓扑结构以及传感器特定规格和放置。方法包括形式化Sim2Real学习中的领域适应挑战，并提供构建能生成域内合成数据的仿真环境的系统方法。使用HiFi DT生成的合成数据训练一个现成的3D目标检测器，并在真实数据上进行评估。通过Chamfer Distance (CD), Maximum Mean Discrepancy (MMD), Earth Mover's Distance (EMD)和Fréchet Distance (FD)等多种指标，在原始输入和潜在特征层面量化合成数据与真实数据之间的分布对齐情况。

Result: 实验表明，使用HiFi DT训练的模型性能比使用真实数据训练的同等模型高出4.8%。结果还证明，HiFi DT显著减少了领域漂移，并在多样化的评估场景中提高了模型的泛化能力。

Conclusion: 研究结果强调了数字孪生在为真实世界ITS应用实现可靠的、基于仿真的LiDAR感知方面的重要作用。

Abstract: Sim2Real domain transfer offers a cost-effective and scalable approach for
developing LiDAR-based perception (e.g., object detection, tracking,
segmentation) in Intelligent Transportation Systems (ITS). However, perception
models trained in simulation often under perform on real-world data due to
distributional shifts. To address this Sim2Real gap, this paper proposes a
high-fidelity digital twin (HiFi DT) framework that incorporates real-world
background geometry, lane-level road topology, and sensor-specific
specifications and placement. We formalize the domain adaptation challenge
underlying Sim2Real learning and present a systematic method for constructing
simulation environments that yield in-domain synthetic data. An off-the-shelf
3D object detector is trained on HiFi DT-generated synthetic data and evaluated
on real data. Our experiments show that the DT-trained model outperforms the
equivalent model trained on real data by 4.8%. To understand this gain, we
quantify distributional alignment between synthetic and real data using
multiple metrics, including Chamfer Distance (CD), Maximum Mean Discrepancy
(MMD), Earth Mover's Distance (EMD), and Fr'echet Distance (FD), at both
raw-input and latent-feature levels. Results demonstrate that HiFi DTs
substantially reduce domain shift and improve generalization across diverse
evaluation scenarios. These findings underscore the significant role of digital
twins in enabling reliable, simulation-based LiDAR perception for real-world
ITS applications.

</details>


### [36] [Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach](https://arxiv.org/abs/2509.02918)
*Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta*

Main category: cs.CV

TL;DR: 本文提出了KG-DG，一个用于糖尿病视网膜病变（DR）分类的神经符号框架，它将视觉Transformer与专家引导的符号推理相结合，以实现跨未见域的鲁棒泛化，并在多个公共数据集上显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域中，模型在单一来源上训练后，在真实世界的分布变化下往往失效，导致领域泛化能力不足，这是一个关键挑战。

Method: 提出了KG-DG，一个神经符号框架，用于DR分类。该框架结合了视觉Transformer与专家引导的符号推理，通过结构化、基于规则的临床病变本体特征和视网膜血管分割，并采用置信度加权的集成策略与深度视觉表征融合。通过最小化域嵌入之间的KL散度来对齐高级临床语义，以解决单域泛化（SDG）和多域泛化（MDG）问题。

Result: 在四个公共数据集上的实验表明，在跨域设置中，准确率提高了高达5.2%，比基线ViT模型提高了6%。符号独立模型在MDG中平均准确率达到63.67%。完整的神经符号集成在具有挑战性的SDG场景中，相比现有基线和基准模型，实现了最高的准确率。消融研究显示，基于病变的特征（84.65%准确率）显著优于纯神经方法，证实了符号组件作为有效正则化的作用。

Conclusion: 神经符号集成是构建临床鲁棒和域不变医学AI系统的一个有前景的范式。

Abstract: Domain generalization remains a critical challenge in medical imaging, where
models trained on single sources often fail under real-world distribution
shifts. We propose KG-DG, a neuro-symbolic framework for diabetic retinopathy
(DR) classification that integrates vision transformers with expert-guided
symbolic reasoning to enable robust generalization across unseen domains. Our
approach leverages clinical lesion ontologies through structured, rule-based
features and retinal vessel segmentation, fusing them with deep visual
representations via a confidence-weighted integration strategy. The framework
addresses both single-domain generalization (SDG) and multi-domain
generalization (MDG) by minimizing the KL divergence between domain embeddings,
thereby enforcing alignment of high-level clinical semantics. Extensive
experiments across four public datasets (APTOS, EyePACS, Messidor-1,
Messidor-2) demonstrate significant improvements: up to a 5.2% accuracy gain in
cross-domain settings and a 6% improvement over baseline ViT models. Notably,
our symbolic-only model achieves a 63.67% average accuracy in MDG, while the
complete neuro-symbolic integration achieves the highest accuracy compared to
existing published baselines and benchmarks in challenging SDG scenarios.
Ablation studies reveal that lesion-based features (84.65% accuracy)
substantially outperform purely neural approaches, confirming that symbolic
components act as effective regularizers beyond merely enhancing
interpretability. Our findings establish neuro-symbolic integration as a
promising paradigm for building clinically robust, and domain-invariant medical
AI systems.

</details>


### [37] [A Data-Driven RetinaNet Model for Small Object Detection in Aerial Images](https://arxiv.org/abs/2509.02928)
*Zhicheng Tang,Jinwen Tang,Yi Shang*

Main category: cs.CV

TL;DR: DDR-Net是一种基于RetinaNet的深度学习模型，通过数据驱动方法优化特征图和锚框，并引入创新采样技术，显著提升了对航空图像中小型物体的检测能力，尤其在有限数据下表现出色。


<details>
  <summary>Details</summary>
Motivation: 在航空成像领域，检测小型物体对环境监测、城市规划和危机管理等多种应用至关重要。现有方法可能在检测微小物体方面存在局限，尤其是在数据量有限的情况下，因此需要开发更高效、精准的模型。

Method: 该研究提出了DDR-Net模型，其基于RetinaNet并引入了新颖的数据驱动技术，以自主确定最优特征图和锚点估计。此外，还提出了一种创新的采样技术，以在有限数据训练约束下增强模型效能。

Result: DDR-Net显著降低了数据收集和训练的成本与时间，即使在有限数据下也能提供高效性能。在各种航空鸟类图像数据集上的实证评估表明，DDR-Net明显优于RetinaNet及其他当代模型。

Conclusion: DDR-Net的创新显著推动了当前航空图像分析技术的发展，在野生动物监测、交通流优化、公共安全、农业、安全和考古等多个领域具有广泛的应用前景和重要影响。

Abstract: In the realm of aerial imaging, the ability to detect small objects is
pivotal for a myriad of applications, encompassing environmental surveillance,
urban design, and crisis management. Leveraging RetinaNet, this work unveils
DDR-Net: a data-driven, deep-learning model devised to enhance the detection of
diminutive objects. DDR-Net introduces novel, data-driven techniques to
autonomously ascertain optimal feature maps and anchor estimations, cultivating
a tailored and proficient training process while maintaining precision.
Additionally, this paper presents an innovative sampling technique to bolster
model efficacy under limited data training constraints. The model's enhanced
detection capabilities support critical applications including wildlife and
habitat monitoring, traffic flow optimization, and public safety improvements
through accurate identification of small objects like vehicles and pedestrians.
DDR-Net significantly reduces the cost and time required for data collection
and training, offering efficient performance even with limited data. Empirical
assessments over assorted aerial avian imagery datasets demonstrate that
DDR-Net markedly surpasses RetinaNet and alternative contemporary models. These
innovations advance current aerial image analysis technologies and promise
wide-ranging impacts across multiple sectors including agriculture, security,
and archaeology.

</details>


### [38] [STAR: A Fast and Robust Rigid Registration Framework for Serial Histopathological Images](https://arxiv.org/abs/2509.02952)
*Zeyu Liu,Shengwei Ding*

Main category: cs.CV

TL;DR: STAR是一个快速、鲁棒的开源框架，用于串行全玻片组织病理图像的刚性配准，通过创新方法克服现有复杂方法的缺点，实现跨染色和组织类型的可靠对齐，并促进AI工作流和临床应用。


<details>
  <summary>Details</summary>
Motivation: 串行全玻片图像配准对于比较不同染色以及在AI工作流（如虚拟染色、生物标志物预测）中准备配对数据集至关重要。然而，现有方法通常复杂、计算密集且难以复现，而适用于许多连续切片场景的轻量级刚性配准框架仍未充分开发。

Method: 本研究引入了STAR（Serial Tissue Alignment for Rigid registration）框架，一个快速、鲁棒的开源多WSI对齐工具。STAR整合了染色条件预处理、分层粗到细相关策略、自适应核缩放和内置质量控制，以实现异质组织类型和染色方案（包括H&E、特殊组织化学染色和IHC标记）之间的可靠刚性配准。

Result: STAR在ANHIR 2019和ACROBAT 2022数据集上进行评估，能够在每张玻片数分钟内稳定地完成对齐，对交叉染色变异性和部分组织重叠表现出鲁棒性。研究还通过H&E-IHC对齐和多IHC面板构建的案例研究，展示了其效用。

Conclusion: STAR作为一种开放、轻量级且可复现的工具，提供了一个基准解决方案，降低了临床应用的门槛，并为下一代计算病理学的大规模配对数据准备提供了支持。

Abstract: Registration of serial whole-slide histopathological images (WSIs) is
critical for enabling direct comparison across diverse stains and for preparing
paired datasets in artificial intelligence (AI) workflows such as virtual
staining and biomarker prediction. While existing methods often rely on complex
deformable or deep learning approaches that are computationally intensive and
difficult to reproduce, lightweight rigid frameworks-sufficient for many
consecutive-section scenarios-remain underdeveloped. We introduce STAR (Serial
Tissue Alignment for Rigid registration), a fast and robust open-source
framework for multi-WSI alignment. STAR integrates stain-conditioned
preprocessing with a hierarchical coarse-to-fine correlation strategy, adaptive
kernel scaling, and built-in quality control, achieving reliable rigid
registration across heterogeneous tissue types and staining protocols,
including hematoxylin-eosin (H&E), special histochemical stains (e.g., PAS,
PASM, Masson's), and immunohistochemical (IHC) markers (e.g., CD31, KI67).
Evaluated on the ANHIR 2019 and ACROBAT 2022 datasets spanning multiple organs
and scanning conditions, STAR consistently produced stable alignments within
minutes per slide, demonstrating robustness to cross-stain variability and
partial tissue overlap. Beyond benchmarks, we present case studies on H&E-IHC
alignment, construction of multi-IHC panels, and typical failure modes,
underscoring both utility and limitations. Released as an open and lightweight
tool, STAR provides a reproducible baseline that lowers the barrier for
clinical adoption and enables large-scale paired data preparation for
next-generation computational pathology.

</details>


### [39] [Resilient Multimodal Industrial Surface Defect Detection with Uncertain Sensors Availability](https://arxiv.org/abs/2509.02962)
*Shuai Jiang,Yunfeng Ma,Jingyu Zhou,Yuan Bian,Yaonan Wang,Min Liu*

Main category: cs.CV

TL;DR: 本文针对多模态工业表面缺陷检测（MISDD）中的模态缺失问题，提出了一种结合跨模态提示学习和对称对比学习的新方法。该方法通过引入文本模态作为桥梁，有效处理信息缺失和模态融合挑战，并在多模态缺失场景下显著超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 多模态工业表面缺陷检测（MISDD）在融合RGB和3D模态时，常因传感器可用性不确定而导致模态缺失。这带来了学习模式转换和信息空缺等问题，影响多模态信息的有效融合。

Method: 1. **跨模态提示学习：** 包含跨模态一致性提示（建立双视觉模态信息一致性）、模态特定提示（适应不同输入模式）和缺失感知提示（补偿动态模态缺失造成的信息空缺）。
2. **对称对比学习：** 利用文本模态作为桥梁融合双视觉模态。通过设计配对的反义文本提示生成二元文本语义，并进行三模态对比预训练实现多模态学习。

Result: 在RGB和3D模态总缺失率0.7的情况下，该方法达到了73.83%的I-AUROC和93.05%的P-AUROC。相较于现有最先进方法，I-AUROC和P-AUROC分别提升了3.84%和5.58%。在不同缺失类型和比率下，该方法均不同程度优于现有方法。

Conclusion: 本文提出的跨模态提示学习和对称对比学习方法，能有效解决MISDD中的模态缺失问题。该方法通过创新性地融合提示学习和文本模态桥接，在多模态缺失场景下的工业表面缺陷检测中取得了显著优于现有方法的性能。

Abstract: Multimodal industrial surface defect detection (MISDD) aims to identify and
locate defect in industrial products by fusing RGB and 3D modalities. This
article focuses on modality-missing problems caused by uncertain sensors
availability in MISDD. In this context, the fusion of multiple modalities
encounters several troubles, including learning mode transformation and
information vacancy. To this end, we first propose cross-modal prompt learning,
which includes: i) the cross-modal consistency prompt serves the establishment
of information consistency of dual visual modalities; ii) the modality-specific
prompt is inserted to adapt different input patterns; iii) the missing-aware
prompt is attached to compensate for the information vacancy caused by dynamic
modalities-missing. In addition, we propose symmetric contrastive learning,
which utilizes text modality as a bridge for fusion of dual vision modalities.
Specifically, a paired antithetical text prompt is designed to generate binary
text semantics, and triple-modal contrastive pre-training is offered to
accomplish multimodal learning. Experiment results show that our proposed
method achieves 73.83% I-AUROC and 93.05% P-AUROC with a total missing rate 0.7
for RGB and 3D modalities (exceeding state-of-the-art methods 3.84% and 5.58%
respectively), and outperforms existing approaches to varying degrees under
different missing types and rates. The source code will be available at
https://github.com/SvyJ/MISDD-MM.

</details>


### [40] [EdgeAttNet: Towards Barb-Aware Filament Segmentation](https://arxiv.org/abs/2509.02964)
*Victor Solomon,Piet Martens,Jingyu Liu,Rafal Angryk*

Main category: cs.CV

TL;DR: EdgeAttNet是一种基于U-Net的图像分割架构，通过引入可学习的边缘图来增强自注意力机制，显著提高了日冕暗条（特别是倒刺）的分割精度和效率。


<details>
  <summary>Details</summary>
Motivation: 准确分割日冕暗条对于确定其手性至关重要，而手性是理解日冕物质抛射（CMEs）行为的关键因素。然而，现有方法因难以建模长距离依赖和空间细节，导致无法有效捕获暗条的精细结构，特别是倒刺。

Method: 该研究提出了EdgeAttNet架构，其以U-Net为骨干，并引入了一个新型的可学习边缘图。该边缘图直接从输入图像中导出，并通过线性变换注意力机制中的Key和Query矩阵，将其整合到模型的自注意力机制中，从而在网络瓶颈处更有效地引导注意力机制捕获暗条边界和倒刺，同时提高空间敏感性并减少可训练参数。

Result: 在MAGFILO数据集上进行端到端训练后，EdgeAttNet在分割精度上超越了U-Net及其他基于U-Net的Transformer基线模型。它实现了更高的分割精度，显著改善了对暗条倒刺的识别能力，并具有更快的推理性能，适合实际部署。

Conclusion: EdgeAttNet通过创新的边缘信息整合方式，有效解决了日冕暗条精细结构分割的难题，提供了高精度、高效率的分割方案，为日冕物质抛射的研究提供了更可靠的输入数据。

Abstract: Accurate segmentation of solar filaments in H-alpha observations is critical
for determining filament chirality, a key factor in the behavior of Coronal
Mass Ejections (CMEs). However, existing methods often fail to capture
fine-scale filament structures, particularly barbs, due to a limited ability to
model long-range dependencies and spatial detail.
  We propose EdgeAttNet, a segmentation architecture built on a U-Net backbone
by introducing a novel, learnable edge map derived directly from the input
image. This edge map is incorporated into the model by linearly transforming
the attention Key and Query matrices with the edge information, thereby guiding
the self-attention mechanism at the network's bottleneck to more effectively
capture filament boundaries and barbs. By explicitly integrating this
structural prior into the attention computations, EdgeAttNet enhances spatial
sensitivity and segmentation accuracy while reducing the number of trainable
parameters.
  Trained end-to-end, EdgeAttNet outperforms U-Net and other U-Net-based
transformer baselines on the MAGFILO dataset. It achieves higher segmentation
accuracy and significantly better recognition of filament barbs, with faster
inference performance suitable for practical deployment.

</details>


### [41] [KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models](https://arxiv.org/abs/2509.02966)
*Yujin Wang,Tianyi Wang,Quanfeng Liu,Wenxian Fan,Junfeng Jiao,Christian Claudel,Yunbing Yan,Bingzhao Gao,Jianqiang Wang,Hong Chen*

Main category: cs.CV

TL;DR: KEPT是一个知识增强的VLM框架，用于自动驾驶中的短时轨迹预测。它通过自监督视频编码器、检索增强的CoT提示和多阶段微调，实现了场景动态和领域知识的有效融合，并在nuScenes数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中准确的短时轨迹预测至关重要，但现有视觉-语言模型（VLMs）在将推理与场景动态和领域知识有效结合方面存在不足。

Method: 本文提出了KEPT框架，直接从连续前视图驾驶帧预测自我车辆轨迹。它包含一个通过自监督学习和硬负挖掘训练的“时频空间融合”（TFSF）视频编码器，以及一个可扩展的k-means + HNSW检索栈来提供场景对齐的范例。检索到的先验知识被嵌入到带有明确规划约束的思维链（CoT）提示中。语言头部通过三阶段微调，逐步对齐到度量空间线索、物理可行运动和时间条件的前视图规划。

Result: KEPT在nuScenes数据集的开环协议下实现了最先进的性能：在NoAvg协议下，平均L2误差为0.70m，碰撞率为0.21%；在TemAvg（包含轻量级自我车辆状态）协议下，平均L2误差为0.31m，碰撞率为0.07%。消融研究表明，所有三个微调阶段都提供了互补的益处，并且使用Top-2检索范例可实现最佳的准确性-安全性权衡。k-means聚类的HNSW索引实现了亚毫秒级的检索延迟，支持实际部署。

Conclusion: 检索增强、CoT引导的VLMs为实现可解释和值得信赖的自动驾驶提供了一个有前景且数据高效的途径。

Abstract: Accurate short-horizon trajectory prediction is pivotal for safe and reliable
autonomous driving, yet existing vision-language models (VLMs) often fail to
effectively ground their reasoning in scene dynamics and domain knowledge. To
address this challenge, this paper introduces KEPT, a knowledge-enhanced VLM
framework that predicts ego trajectories directly from consecutive front-view
driving frames. KEPT couples a temporal frequency-spatial fusion (TFSF) video
encoder, trained via self-supervised learning with hard-negative mining, with a
scalable k-means + HNSW retrieval stack that supplies scene-aligned exemplars.
Retrieved priors are embedded into chain-of-thought (CoT) prompts with explicit
planning constraints, while a triple-stage fine-tuning schedule incrementally
aligns the language head to metric spatial cues, physically feasible motion,
and temporally conditioned front-view planning. Evaluated on nuScenes dataset,
KEPT achieves state-of-the-art performance across open-loop protocols: under
NoAvg, it achieves 0.70m average L2 with a 0.21\% collision rate; under TemAvg
with lightweight ego status, it attains 0.31m average L2 and a 0.07\% collision
rate. Ablation studies show that all three fine-tuning stages contribute
complementary benefits, and that using Top-2 retrieved exemplars yields the
best accuracy-safety trade-off. The k-means-clustered HNSW index delivers
sub-millisecond retrieval latency, supporting practical deployment. These
results indicate that retrieval-augmented, CoT-guided VLMs offer a promising,
data-efficient pathway toward interpretable and trustworthy autonomous driving.

</details>


### [42] [VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results](https://arxiv.org/abs/2509.02969)
*Dasong Li,Sizhuo Ma,Hang Hua,Wenjie Li,Jian Wang,Chris Wei Zhou,Fengbin Guan,Xin Li,Zihao Yu,Yiting Lu,Ru-Ling Liao,Yan Ye,Zhibo Chen,Wei Sun,Linhan Cao,Yuqin Cao,Weixia Zhang,Wen Wen,Kaiwei Zhang,Zijian Chen,Fangfang Lu,Xiongkuo Min,Guangtao Zhai,Erjia Xiao,Lingfeng Zhang,Zhenjie Su,Hao Cheng,Yu Liu,Renjing Xu,Long Chen,Xiaoshuai Hao,Zhenpeng Zeng,Jianqin Wu,Xuxu Wang,Qian Yu,Bo Hu,Weiwei Wang,Pinxin Liu,Yunlong Tang,Luchuan Song,Jinxi He,Jiaru Wu,Hanjia Lyu*

Main category: cs.CV

TL;DR: 本文概述了VQualA 2025短视频参与度预测挑战赛，该挑战赛旨在通过新数据集和多模态特征，理解并预测UGC短视频在社交媒体上的受欢迎程度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解并建模社交媒体平台上用户生成内容（UGC）短视频的受欢迎程度，并推动能够捕捉影响用户参与度的复杂因素的鲁棒建模策略。

Method: 使用方法是举办VQualA 2025挑战赛，提供一个包含真实用户互动参与度指标的新型短视频UGC数据集。参与者探索了多模态特征，包括视觉内容、音频和创作者提供的元数据。

Result: 研究结果是该挑战赛吸引了97名参与者，并收到了15份有效的测试提交，显著推动了短视频UGC参与度预测领域的进展。

Conclusion: 结论是VQualA 2025挑战赛成功地通过提供专门的数据集和平台，促进了短视频UGC参与度预测领域的研究和发展，并鼓励了对多模态特征的探索。

Abstract: This paper presents an overview of the VQualA 2025 Challenge on Engagement
Prediction for Short Videos, held in conjunction with ICCV 2025. The challenge
focuses on understanding and modeling the popularity of user-generated content
(UGC) short videos on social media platforms. To support this goal, the
challenge uses a new short-form UGC dataset featuring engagement metrics
derived from real-world user interactions. This objective of the Challenge is
to promote robust modeling strategies that capture the complex factors
influencing user engagement. Participants explored a variety of multi-modal
features, including visual content, audio, and metadata provided by creators.
The challenge attracted 97 participants and received 15 valid test submissions,
contributing significantly to progress in short-form UGC video engagement
prediction.

</details>


### [43] [InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System](https://arxiv.org/abs/2509.02973)
*Xianbao Hou,Yonghao He,Zeyd Boukhers,John See,Hu Su,Wei Sui,Cong Yang*

Main category: cs.CV

TL;DR: InstaDA是一个无训练的双智能体系统，通过结合大型语言模型（LLMs）和扩散模型（Text-Agent）以及基于训练图像生成新实例（Image-Agent），解决了实例分割数据获取困难和类别不平衡问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 获取高质量实例分割数据因标注劳动密集且数据集中存在严重的类别不平衡而极具挑战性。现有结合Copy-Paste和扩散模型的方法，往往缺乏LLMs与扩散模型的深度协作，且未充分利用现有训练数据中的丰富信息。

Method: 提出了一个新颖的、无训练的InstaDA双智能体系统，用于增强实例分割数据集。该系统包含：
1. Text-Agent (T-Agent)：通过LLMs和扩散模型之间的协作增强数据多样性。其核心是“Prompt Rethink”机制，能根据生成的图像迭代优化提示词，以促进协作和提高图像利用率。
2. Image-Agent (I-Agent)：通过基于现有训练图像生成新实例来丰富整体数据分布。 
两个智能体均作为独立的自动化工作流运行，以确保实用性和效率。

Result: 在LVIS 1.0验证集上，InstaDA相对于基线模型，框平均精度（AP）提升了+4.0，掩码AP提升了+3.3。它还超越了领先模型DiverGen，框AP提升了+0.3，掩码AP提升了+0.1。尤其是在常见类别上，框AP获得了+0.7的显著提升；在常见类别上，掩码AP提升了+0.2；在频繁类别上，掩码AP提升了+0.5。

Conclusion: InstaDA通过创新的双智能体系统，有效解决了实例分割数据增强中的核心挑战，特别是通过LLM与扩散模型的深度协作和对现有数据的充分利用，实现了显著的性能提升，超越了现有SOTA方法。

Abstract: Acquiring high-quality instance segmentation data is challenging due to the
labor-intensive nature of the annotation process and significant class
imbalances within datasets. Recent studies have utilized the integration of
Copy-Paste and diffusion models to create more diverse datasets. However, these
studies often lack deep collaboration between large language models (LLMs) and
diffusion models, and underutilize the rich information within the existing
training data. To address these limitations, we propose InstaDA, a novel,
training-free Dual-Agent system designed to augment instance segmentation
datasets. First, we introduce a Text-Agent (T-Agent) that enhances data
diversity through collaboration between LLMs and diffusion models. This agent
features a novel Prompt Rethink mechanism, which iteratively refines prompts
based on the generated images. This process not only fosters collaboration but
also increases image utilization and optimizes the prompts themselves.
Additionally, we present an Image-Agent (I-Agent) aimed at enriching the
overall data distribution. This agent augments the training set by generating
new instances conditioned on the training images. To ensure practicality and
efficiency, both agents operate as independent and automated workflows,
enhancing usability. Experiments conducted on the LVIS 1.0 validation set
indicate that InstaDA achieves significant improvements, with an increase of
+4.0 in box average precision (AP) and +3.3 in mask AP compared to the
baseline. Furthermore, it outperforms the leading model, DiverGen, by +0.3 in
box AP and +0.1 in mask AP, with a notable +0.7 gain in box AP on common
categories and mask AP gains of +0.2 on common categories and +0.5 on frequent
categories.

</details>


### [44] [SPENet: Self-guided Prototype Enhancement Network for Few-shot Medical Image Segmentation](https://arxiv.org/abs/2509.02993)
*Chao Fan,Xibin Jia,Anqi Xiao,Hongyuan Yu,Zhenghan Yang,Dawei Yang,Hui Xu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: 针对少样本医学图像分割中原型网络忽略类内变化的问题，本文提出SPENet，通过多级原型生成和查询引导局部原型增强模块，实现了多粒度测量和原型自适应优化，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的原型网络在少样本医学图像分割中，通常只生成一个全局原型，导致忽略了类内变化。此外，支持图像中的部分局部原型可能对匹配不利，尤其是在支持和查询图像之间存在显著差异时。

Method: 提出了一种自引导原型增强网络（SPENet）。该网络包含：1. 多级原型生成（MPG）模块，用于同时生成全局原型和自适应数量的局部原型，实现支持与查询图像之间的多粒度测量。2. 查询引导局部原型增强（QLPE）模块，通过结合查询图像的引导，自适应地细化支持原型，以减轻图像差异带来的负面影响。

Result: 在三个公开的医学数据集上进行了广泛实验，结果表明SPENet优于现有最先进的方法，取得了卓越的性能。

Conclusion: SPENet通过解决现有原型方法忽略类内变化和处理图像差异的局限性，为少样本医学图像分割提供了更有效且性能优越的解决方案。

Abstract: Few-Shot Medical Image Segmentation (FSMIS) aims to segment novel classes of
medical objects using only a few labeled images. Prototype-based methods have
made significant progress in addressing FSMIS. However, they typically generate
a single global prototype for the support image to match with the query image,
overlooking intra-class variations. To address this issue, we propose a
Self-guided Prototype Enhancement Network (SPENet). Specifically, we introduce
a Multi-level Prototype Generation (MPG) module, which enables
multi-granularity measurement between the support and query images by
simultaneously generating a global prototype and an adaptive number of local
prototypes. Additionally, we observe that not all local prototypes in the
support image are beneficial for matching, especially when there are
substantial discrepancies between the support and query images. To alleviate
this issue, we propose a Query-guided Local Prototype Enhancement (QLPE)
module, which adaptively refines support prototypes by incorporating guidance
from the query image, thus mitigating the negative effects of such
discrepancies. Extensive experiments on three public medical datasets
demonstrate that SPENet outperforms existing state-of-the-art methods,
achieving superior performance.

</details>


### [45] [SOPSeg: Prompt-based Small Object Instance Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2509.03002)
*Chenhao Wang,Yingrui Ji,Yu Meng,Yunjian Zhang,Yao Zhu*

Main category: cs.CV

TL;DR: 针对遥感图像中小目标实例分割缺乏数据集和现有模型性能不佳的问题，本文提出SOPSeg框架。该框架通过区域自适应放大、定制解码器和有向包围盒提示机制，显著提升了小目标分割性能，并有助于高效构建数据集。


<details>
  <summary>Details</summary>
Motivation: 小目标实例分割在遥感图像中应用广泛但未被充分探索，缺乏专用数据集且像素级标注成本高。现有模型如SAM在小目标分割上性能显著下降，主要原因在于特征分辨率过低导致细节丢失。

Method: 本文提出SOPSeg，一个基于提示的遥感图像小目标分割框架。它包含：1) 区域自适应放大策略以保留细粒度细节；2) 集成边缘预测和渐进式优化的定制解码器，用于精确边界描绘；3) 专为遥感领域常用有向包围盒设计的提示机制。

Result: SOPSeg在小目标分割方面超越了现有方法，并促进了遥感任务中高效数据集的构建。此外，本文还基于SODA-A构建了一个综合的小目标实例分割数据集。

Conclusion: SOPSeg通过创新的方法有效解决了遥感图像中小目标实例分割的挑战，提高了分割精度和数据集构建效率。模型和数据集的发布将有力支持未来的相关研究。

Abstract: Extracting small objects from remote sensing imagery plays a vital role in
various applications, including urban planning, environmental monitoring, and
disaster management. While current research primarily focuses on small object
detection, instance segmentation for small objects remains underexplored, with
no dedicated datasets available. This gap stems from the technical challenges
and high costs of pixel-level annotation for small objects. While the Segment
Anything Model (SAM) demonstrates impressive zero-shot generalization, its
performance on small-object segmentation deteriorates significantly, largely
due to the coarse 1/16 feature resolution that causes severe loss of fine
spatial details. To this end, we propose SOPSeg, a prompt-based framework
specifically designed for small object segmentation in remote sensing imagery.
It incorporates a region-adaptive magnification strategy to preserve
fine-grained details, and employs a customized decoder that integrates edge
prediction and progressive refinement for accurate boundary delineation.
Moreover, we introduce a novel prompting mechanism tailored to the oriented
bounding boxes widely adopted in remote sensing applications. SOPSeg
outperforms existing methods in small object segmentation and facilitates
efficient dataset construction for remote sensing tasks. We further construct a
comprehensive small object instance segmentation dataset based on SODA-A, and
will release both the model and dataset to support future research.

</details>


### [46] [Enhancing Robustness in Post-Processing Watermarking: An Ensemble Attack Network Using CNNs and Transformers](https://arxiv.org/abs/2509.03006)
*Tzuhsuan Huang,Cheng Yu Yeo,Tsai-Ling Huang,Hong-Han Shuai,Wen-Huang Cheng,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: 本研究关注后处理深度水印的鲁棒性，通过引入集成攻击网络进行训练，显著提升了水印模型的鲁棒性，并发现空间域CNN与频率域Transformer的攻击网络组合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 传统深度水印多为“处理中”水印，而“后处理”水印（在图像生成后嵌入）具有更高灵活性，可适用于任何生成模型且无需访问内部结构，并允许为单张图像嵌入独特水印。因此，本研究旨在提升后处理水印的鲁棒性。

Method: 本研究专注于后处理水印，并在训练中引入一个集成攻击网络以增强鲁棒性。通过结合CNN和Transformer在空间域和频率域构建多种攻击网络版本，以探究其对水印模型鲁棒性的影响。在WAVES基准测试上使用平均比特精度进行评估。

Result: 研究结果表明，结合空间域的CNN攻击网络与频率域的Transformer攻击网络，能够使水印模型达到最高鲁棒性。该集成攻击网络显著增强了基线水印方法在各种压力测试下的鲁棒性，尤其是在WAVES的再生攻击中，使StegaStamp的性能提升了18.743%。

Conclusion: 本研究通过在训练中集成多种攻击网络，成功提升了后处理深度水印的鲁棒性，并识别出最优的攻击网络组合（空间域CNN与频率域Transformer），验证了该方法在对抗复杂攻击方面的有效性。

Abstract: Recent studies on deep watermarking have predominantly focused on
in-processing watermarking, which integrates the watermarking process into
image generation. However, post-processing watermarking, which embeds
watermarks after image generation, offers more flexibility. It can be applied
to outputs from any generative model (e.g. GANs, diffusion models) without
needing access to the model's internal structure. It also allows users to embed
unique watermarks into individual images. Therefore, this study focuses on
post-processing watermarking and enhances its robustness by incorporating an
ensemble attack network during training. We construct various versions of
attack networks using CNN and Transformer in both spatial and frequency domains
to investigate how each combination influences the robustness of the
watermarking model. Our results demonstrate that combining a CNN-based attack
network in the spatial domain with a Transformer-based attack network in the
frequency domain yields the highest robustness in watermarking models.
Extensive evaluation on the WAVES benchmark, using average bit accuracy as the
metric, demonstrates that our ensemble attack network significantly enhances
the robustness of baseline watermarking methods under various stress tests. In
particular, for the Regeneration Attack defined in WAVES, our method improves
StegaStamp by 18.743%. The code is released
at:https://github.com/aiiu-lab/DeepRobustWatermark.

</details>


### [47] [Lesion-Aware Visual-Language Fusion for Automated Image Captioning of Ulcerative Colitis Endoscopic Examinations](https://arxiv.org/abs/2509.03011)
*Alexis Ivan Lopez Escamilla,Gilberto Ochoa,Sharib Al*

Main category: cs.CV

TL;DR: 针对溃疡性结肠炎，开发了一种结合多模态信息（图像特征与临床元数据）的病灶感知图像描述框架，提升了报告质量和MES分类准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在为溃疡性结肠炎提供结构化、可解释的内镜报告，并提高MES评分的分类准确性，从而支持更可靠的临床实践。

Method: 该模型整合了ResNet嵌入、Grad-CAM热图和CBAM增强注意力与T5解码器。将临床元数据（如MES评分、血管模式、出血、红斑、脆性、溃疡）作为自然语言提示注入，以指导图像描述的生成。

Result: 与基线方法相比，本方法显著提高了图像描述质量和MES分类准确性。系统能够生成与临床实践一致的结构化、可解释描述，并提供MES分类和病灶标签。

Conclusion: 所提出的框架通过生成高质量图像描述和准确的MES分类，有效支持了溃疡性结肠炎的可靠内镜报告。

Abstract: We present a lesion-aware image captioning framework for ulcerative colitis
(UC). The model integrates ResNet embeddings, Grad-CAM heatmaps, and
CBAM-enhanced attention with a T5 decoder. Clinical metadata (MES score 0-3,
vascular pattern, bleeding, erythema, friability, ulceration) is injected as
natural-language prompts to guide caption generation. The system produces
structured, interpretable descriptions aligned with clinical practice and
provides MES classification and lesion tags. Compared with baselines, our
approach improves caption quality and MES classification accuracy, supporting
reliable endoscopic reporting.

</details>


### [48] [Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens](https://arxiv.org/abs/2509.03025)
*Sohee Kim,Soohyun Ryu,Joonhyung Park,Eunho Yang*

Main category: cs.CV

TL;DR: 研究发现大型视觉-语言模型（LVLMs）常将缺乏视觉证据的文本误认为图像内容，导致错误响应。我们识别出一种名为“视觉缺失感知（VA）神经元”的特定FFN神经元，其激活模式能指示视觉缺失。基于此，我们开发了一个检测模块来识别未视觉锚定的文本，并提出一种方法，通过重新解释提示或替换缺失文本来精炼模型输出，有效缓解了LVLMs的误判倾向。


<details>
  <summary>Details</summary>
Motivation: LVLMs在联合解释视觉和文本输入时，常将缺乏图像证据的文本输入错误地视为图像的一部分，导致生成错误的回应。

Method: ['探究LVLMs是否具备内部能力来判断文本概念是否在图像中被视觉锚定。', '发现前馈网络（FFN）中存在特定子集的神经元（称为视觉缺失感知VA神经元），其独特的激活模式持续指示视觉缺失。', '基于VA神经元的激活模式，开发了一个检测模块，系统地分类输入标记是否在视觉上被锚定。', '提出一种精炼输出的方法：在生成过程中，根据检测模块的预测，重新解释问题提示或替换检测到的缺失标记。']

Result: 广泛的实验表明，所提出的方法有效缓解了模型错误地假定文本输入存在于视觉中的倾向，并且在各种LVLMs上具有普遍性。

Conclusion: 通过识别并利用LVLMs内部的视觉缺失感知神经元，我们开发出一种有效的方法，使模型能够区分视觉锚定和非锚定的文本输入，从而显著提高了LVLMs响应的准确性和可靠性。

Abstract: Large Vision-Language Models (LVLMs) generate contextually relevant responses
by jointly interpreting visual and textual inputs. However, our finding reveals
they often mistakenly perceive text inputs lacking visual evidence as being
part of the image, leading to erroneous responses. In light of this finding, we
probe whether LVLMs possess an internal capability to determine if textual
concepts are grounded in the image, and discover a specific subset of
Feed-Forward Network (FFN) neurons, termed Visual Absence-aware (VA) neurons,
that consistently signal the visual absence through a distinctive activation
pattern. Leveraging these patterns, we develop a detection module that
systematically classifies whether an input token is visually grounded. Guided
by its prediction, we propose a method to refine the outputs by reinterpreting
question prompts or replacing the detected absent tokens during generation.
Extensive experiments show that our method effectively mitigates the models'
tendency to falsely presume the visual presence of text input and its
generality across various LVLMs.

</details>


### [49] [Background Matters Too: A Language-Enhanced Adversarial Framework for Person Re-Identification](https://arxiv.org/abs/2509.03032)
*Kaicong Huang,Talha Azfar,Jack M. Reilly,Thomas Guggisberg,Ruimin Ke*

Main category: cs.CV

TL;DR: 本文提出了一种端到端双分支跨模态框架，用于行人重识别（ReID），通过联合建模前景和背景信息，并采用域内语义对齐和域间语义对抗学习策略，以增强模型判别力，有效抑制背景噪声并提升对身份相关前景特征的关注。


<details>
  <summary>Details</summary>
Motivation: 行人重识别面临前景目标定位不准、背景噪声干扰以及前景特征提取困难等挑战。现有视觉方法依赖昂贵标注且难以处理遮挡；多模态方法虽引入语义线索，但仅关注前景信息，忽略了背景线索的潜在价值。受人类感知启发，作者认为背景语义与前景语义同等重要，有助于消除背景干扰，故提出利用背景信息。

Method: 提出一个端到端框架，通过双分支跨模态特征提取管道联合建模前景和背景信息。为区分两领域，设计了域内语义对齐和域间语义对抗学习策略：前者对齐相同语义的视觉和文本特征，后者惩罚前景与背景特征间的相似性，以增强网络的判别能力，主动抑制背景噪声并增强对身份相关前景线索的关注。

Result: 在两个整体ReID基准和两个遮挡ReID基准上进行的综合实验表明，所提方法有效且通用，结果匹配或超越了当前最先进的方法。

Conclusion: 所提出的结合前景和背景信息的双分支跨模态框架，通过创新的语义对齐和对抗学习策略，有效解决了行人重识别中的背景噪声和特征判别难题，并在多个基准测试中取得了优异性能。

Abstract: Person re-identification faces two core challenges: precisely locating the
foreground target while suppressing background noise and extracting
fine-grained features from the target region. Numerous visual-only approaches
address these issues by partitioning an image and applying attention modules,
yet they rely on costly manual annotations and struggle with complex
occlusions. Recent multimodal methods, motivated by CLIP, introduce semantic
cues to guide visual understanding. However, they focus solely on foreground
information, but overlook the potential value of background cues. Inspired by
human perception, we argue that background semantics are as important as the
foreground semantics in ReID, as humans tend to eliminate background
distractions while focusing on target appearance. Therefore, this paper
proposes an end-to-end framework that jointly models foreground and background
information within a dual-branch cross-modal feature extraction pipeline. To
help the network distinguish between the two domains, we propose an
intra-semantic alignment and inter-semantic adversarial learning strategy.
Specifically, we align visual and textual features that share the same
semantics across domains, while simultaneously penalizing similarity between
foreground and background features to enhance the network's discriminative
power. This strategy drives the model to actively suppress noisy background
regions and enhance attention toward identity-relevant foreground cues.
Comprehensive experiments on two holistic and two occluded ReID benchmarks
demonstrate the effectiveness and generality of the proposed method, with
results that match or surpass those of current state-of-the-art approaches.

</details>


### [50] [MedLiteNet: Lightweight Hybrid Medical Image Segmentation Model](https://arxiv.org/abs/2509.03041)
*Pengyang Yu,Haoquan Wang,Gerard Marks,Tahar Kechadi,Laurence T. Yang,Sahraoui Dhelim,Nyothiri Aung*

Main category: cs.CV

TL;DR: 本文介绍了一种名为MedLiteNet的轻量级CNN Transformer混合模型，专为皮肤镜图像分割设计，通过分层特征提取和多尺度上下文聚合实现了高精度，解决了现有CNN和Transformer在皮肤病变分割中的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确的皮肤病变分割对皮肤癌的计算机辅助诊断至关重要，但面临挑战。卷积神经网络（CNN）因感受野有限，难以建模长距离依赖；而Vision Transformer模型复杂度高且参数量大，不适用于皮肤病学中常见的小样本医学数据集。

Method: 我们提出了MedLiteNet，一种轻量级CNN Transformer混合架构。其编码器堆叠深度可分离的Mobile Inverted Bottleneck块以减少计算量，在瓶颈层嵌入跨尺度token混合单元以在不同分辨率间交换信息，并融入边界感知自注意力模块以锐化病变轮廓。

Result: MedLiteNet通过分层特征提取和多尺度上下文聚合，在皮肤镜分割任务中实现了高精度。

Conclusion: MedLiteNet成功结合了CNN的计算效率和Transformer的全局上下文捕获能力，为皮肤病变分割提供了一种高效且高精度的解决方案，尤其适用于小样本医疗数据集。

Abstract: Accurate skin-lesion segmentation remains a key technical challenge for
computer-aided diagnosis of skin cancer. Convolutional neural networks, while
effective, are constrained by limited receptive fields and thus struggle to
model long-range dependencies. Vision Transformers capture global context, yet
their quadratic complexity and large parameter budgets hinder use on the
small-sample medical datasets common in dermatology. We introduce the
MedLiteNet, a lightweight CNN Transformer hybrid tailored for dermoscopic
segmentation that achieves high precision through hierarchical feature
extraction and multi-scale context aggregation. The encoder stacks depth-wise
Mobile Inverted Bottleneck blocks to curb computation, inserts a
bottleneck-level cross-scale token-mixing unit to exchange information between
resolutions, and embeds a boundary-aware self-attention module to sharpen
lesion contours.

</details>


### [51] [DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed Multi-Tasks](https://arxiv.org/abs/2509.03044)
*Chengjie Huang,Jiafeng Yan,Jing Li,Lu Bai*

Main category: cs.CV

TL;DR: 提出一种动态条件双扩散桥训练范式，通过解耦扩散和条件生成，并利用动态条件，解决了条件扩散模型在病态多任务场景中数据依赖和静态条件控制的难题，并在去雾和可见光-红外融合任务中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有条件扩散模型在多任务场景中难以利用任务间的内在关联，尤其在训练数据缺乏的病态任务中表现更差。此外，传统的静态条件控制难以适应多任务场景中动态演变的特性，增加了网络学习难度。

Method: 提出了一种动态条件双扩散桥训练范式。该范式首先解耦扩散和条件生成过程，避免了扩散模型对病态任务中监督数据的依赖；其次，利用相同的噪声调度生成动态条件，逐步调整其统计特性，自然嵌入时间相关信息，降低了网络学习难度。通过分析不同条件形式下网络在单步去噪过程中的学习目标和注意力权重变化，证明了动态条件的优越性。

Result: 在去雾和可见光-红外融合等典型的病态多任务场景中，该方法在公共数据集上的多项指标上取得了最佳性能。

Conclusion: 该研究通过提出动态条件双扩散桥训练范式，有效解决了条件扩散模型在病态多任务场景中的挑战，显著提升了模型在数据稀缺和动态多任务环境下的学习能力和性能，实现了最先进的结果。

Abstract: Conditional diffusion models have made impressive progress in the field of
image processing, but the characteristics of constructing data distribution
pathways make it difficult to exploit the intrinsic correlation between tasks
in multi-task scenarios, which is even worse in ill-posed tasks with a lack of
training data. In addition, traditional static condition control makes it
difficult for networks to learn in multi-task scenarios with its dynamically
evolving characteristics. To address these challenges, we propose a dynamic
conditional double diffusion bridge training paradigm to build a general
framework for ill-posed multi-tasks. Firstly, this paradigm decouples the
diffusion and condition generation processes, avoiding the dependence of the
diffusion model on supervised data in ill-posed tasks. Secondly, generated by
the same noise schedule, dynamic conditions are used to gradually adjust their
statistical characteristics, naturally embed time-related information, and
reduce the difficulty of network learning. We analyze the learning objectives
of the network under different conditional forms in the single-step denoising
process and compare the changes in its attention weights in the network,
demonstrating the superiority of our dynamic conditions. Taking dehazing and
visible-infrared fusion as typical ill-posed multi-task scenarios, we achieve
the best performance in multiple indicators on public datasets. The code has
been publicly released at: https://anonymous.4open.science/r/DCDB-D3C2.

</details>


### [52] [Isolated Bangla Handwritten Character Classification using Transfer Learning](https://arxiv.org/abs/2509.03061)
*Abdul Karim,S M Rafiuddin,Jahidul Islam Razin,Tahira Alam*

Main category: cs.CV

TL;DR: 本研究提出一种基于迁移学习和深度神经网络（如3DCNN、ResNet、MobileNet）的孟加拉语手写字符识别模型，实现了99.46%的测试准确率，并在Bangla Lekha Isolated数据集上优于现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语包含大量复杂的基本和复合字符，对手写识别构成挑战。现有研究虽有进展，但仍需更有效的方法来解决复杂字符分类及梯度消失问题，以提高识别准确率。

Method: 采用迁移学习方法，结合3D卷积神经网络（3DCNN）、残差神经网络（ResNet）和MobileNet等深度神经网络技术，实现孟加拉语手写基本、独立及复合字符的端到端分类，同时避免了梯度消失问题。模型使用包含166,105个字符图像样本（分为84个类别）的Bangla Lekha Isolated数据集进行训练和评估。

Result: 模型在训练数据上取得了99.82%的准确率，在测试数据上取得了99.46%的准确率。与现有的孟加拉语手写字符分类最先进基准模型相比，所提出的模型在数据分类方面表现出更高的准确性。

Conclusion: 所提出的基于迁移学习和深度神经网络的模型能够高效、准确地分类孟加拉语手写字符（包括复杂字符），成功解决了梯度消失问题，并在性能上超越了现有最佳方法，为孟加拉语手写字符识别提供了更优的解决方案。

Abstract: Bangla language consists of fifty distinct characters and many compound
characters. Several notable studies have been performed to recognize Bangla
characters, both handwritten and optical. Our approach uses transfer learning
to classify the basic, distinct, as well as compound Bangla handwritten
characters while avoiding the vanishing gradient problem. Deep Neural Network
techniques such as 3D Convolutional Neural Network (3DCNN), Residual Neural
Network (ResNet), and MobileNet are applied to generate an end-to-end
classification of all possible standard formations of handwritten characters in
the Bangla language. The Bangla Lekha Isolated dataset, which contains 166,105
Bangla character image samples categorized into 84 distinct classes, is used
for this classification model. The model achieved 99.82% accuracy on training
data and 99.46% accuracy on test data. Comparisons with various
state-of-the-art benchmarks of Bangla handwritten character classification show
that the proposed model achieves better accuracy in classifying the data.

</details>


### [53] [High Cursive Complex Character Recognition using GAN External Classifier](https://arxiv.org/abs/2509.03062)
*S M Rafiuddin*

Main category: cs.CV

TL;DR: 提出ADA-GAN模型，利用生成对抗网络和外部分类器，通过数据增强提高对复杂和连笔手写字符的分类鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂和连笔手写字符的分类比简单字符更具挑战性。

Method: 提出ADA-GAN模型，结合外部分类器和生成对抗网络（GAN）。利用GAN生成带有对抗扰动噪声的假手写字符图像，并通过判别器过滤后增强训练数据。

Result: 结果表明，传统卷积神经网络（CNN）的准确性随字符复杂度增加而下降，而本文提出的ADA-GAN模型对连笔和复杂字符表现出更高的鲁棒性和有效性。

Conclusion: ADA-GAN模型能够有效提升复杂和连笔手写字符的分类性能，克服了传统方法在此类任务上的局限性。

Abstract: Handwritten characters can be trickier to classify due to their complex and
cursive nature compared to simple and non-cursive characters. We present an
external classifier along with a Generative Adversarial Network that can
classify highly cursive and complex characters. The generator network produces
fake handwritten character images, which are then used to augment the training
data after adding adversarially perturbed noise and achieving a confidence
score above a threshold with the discriminator network. The results show that
the accuracy of convolutional neural networks decreases as character complexity
increases, but our proposed model, ADA-GAN, remains more robust and effective
for both cursive and complex characters.

</details>


### [54] [TRELLIS-Enhanced Surface Features for Comprehensive Intracranial Aneurysm Analysis](https://arxiv.org/abs/2509.03095)
*Clément Hervé,Paul Garnier,Jonathan Viquerat,Elie Hachem*

Main category: cs.CV

TL;DR: 本研究提出一种跨域特征迁移方法，利用通用3D生成模型TRELLIS学习的潜在几何嵌入，显著提升了颅内动脉瘤的检测、分割和血流预测等分析任务的性能。


<details>
  <summary>Details</summary>
Motivation: 颅内动脉瘤具有显著的临床风险，但由于缺乏标注的3D数据，导致其检测、描绘和建模都非常困难。

Method: 研究者提出一种跨域特征迁移方法。该方法利用TRELLIS（一个在非医学大规模3D数据集上训练的生成模型）学习到的潜在几何嵌入，作为TRELLIS表面特征，替换传统的点法线或网格描述符，以增强用于动脉瘤分析的神经网络。具体应用于三个下游任务：(i) 在Intra3D数据集中对动脉瘤和健康血管进行分类，(ii) 在3D网格上分割动脉瘤和血管区域，(iii) 使用图神经网络在AnXplore数据集中预测随时间变化的血流场。

Result: 实验结果表明，引入TRELLIS表面特征后，在准确性、F1分数和分割质量方面均取得了显著提升，优于现有最先进的基线方法，并将模拟误差降低了15%。

Conclusion: 这些结果展示了将通用生成模型的3D表示迁移到专业医学任务中具有更广泛的潜力。

Abstract: Intracranial aneurysms pose a significant clinical risk yet are difficult to
detect, delineate and model due to limited annotated 3D data. We propose a
cross-domain feature-transfer approach that leverages the latent geometric
embeddings learned by TRELLIS, a generative model trained on large-scale
non-medical 3D datasets, to augment neural networks for aneurysm analysis. By
replacing conventional point normals or mesh descriptors with TRELLIS surface
features, we systematically enhance three downstream tasks: (i) classifying
aneurysms versus healthy vessels in the Intra3D dataset, (ii) segmenting
aneurysm and vessel regions on 3D meshes, and (iii) predicting time-evolving
blood-flow fields using a graph neural network on the AnXplore dataset. Our
experiments show that the inclusion of these features yields strong gains in
accuracy, F1-score and segmentation quality over state-of-the-art baselines,
and reduces simulation error by 15\%. These results illustrate the broader
potential of transferring 3D representations from general-purpose generative
models to specialized medical tasks.

</details>


### [55] [Backdoor Poisoning Attack Against Face Spoofing Attack Detection Methods](https://arxiv.org/abs/2509.03108)
*Shota Iwamatsu,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 本文提出一种新颖的后门投毒攻击方法，通过将欺骗攻击特征无感嵌入活体图像，使特定欺骗攻击绕过人脸防伪检测，揭示了对现有系统的现实威胁。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统易受欺骗攻击（如使用照片），因此在人脸识别前区分活体与伪造图像至关重要。现有深度学习防欺骗方法需大量训练数据，若训练集被恶意注入，可能导致特定欺骗攻击被误判为活体，构成潜在威胁。

Method: 提出一种新颖的后门投毒攻击方法，旨在人脸防伪检测中制造漏洞。该方法通过将从欺骗攻击面部图像中提取的特征嵌入到活体面部图像中，且不引起任何可感知的视觉改变，从而使特定欺骗攻击能绕过检测。

Result: 在公共数据集上进行的实验证明，所提出的方法对现有欺骗攻击检测系统构成现实威胁。

Conclusion: 本研究通过提出一种新型后门投毒攻击方法，有效演示了人脸防伪检测中后门投毒的潜在威胁，强调了现有系统在此类攻击面前的脆弱性。

Abstract: Face recognition systems are robust against environmental changes and noise,
and thus may be vulnerable to illegal authentication attempts using user face
photos, such as spoofing attacks. To prevent such spoofing attacks, it is
crucial to discriminate whether the input image is a live user image or a
spoofed image prior to the face recognition process. Most existing spoofing
attack detection methods utilize deep learning, which necessitates a
substantial amount of training data. Consequently, if malicious data is
injected into a portion of the training dataset, a specific spoofing attack may
be erroneously classified as live, leading to false positives.In this paper, we
propose a novel backdoor poisoning attack method to demonstrate the latent
threat of backdoor poisoning within face anti-spoofing detection. The proposed
method enables certain spoofing attacks to bypass detection by embedding
features extracted from the spoofing attack's face image into a live face image
without inducing any perceptible visual alterations.Through experiments
conducted on public datasets, we demonstrate that the proposed method
constitutes a realistic threat to existing spoofing attack detection systems.

</details>


### [56] [Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection](https://arxiv.org/abs/2509.03113)
*Shan Wang,Maying Shen,Nadine Chang,Chuong Nguyen,Hongdong Li,Jose M. Alvarez*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外资源的方法，通过梯度自反射和影响感知对比解码来估计不同类型token的影响并检测视觉token，从而有效缓解多模态大模型中由文本-视觉偏见和共现偏见引起的幻觉。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型中的幻觉源于文本-视觉偏见（过度依赖文本）和共现偏见（训练数据中的统计模式）。现有缓解方法是启发式的，缺乏对实例间偏见水平波动的理解。

Method: 研究者首先提出使用基于梯度的自反射方法来估计不同token类型（视觉、提示、先前输出）的影响。然后，利用估计的token影响检测与对象相关的视觉token，并将其整合到影响感知对比解码框架中，以同时缓解两种偏见。此方法无需昂贵的微调、额外模型或数据统计等资源。

Result: 广泛的实验表明，该方法有效减少了幻觉，在LLaVA-QA90上实现了高达92%的准确率提升。

Conclusion: 所提出的方法通过估计token影响和影响感知对比解码，能有效缓解多模态大模型中由特定偏见引起的幻觉，且无需额外资源，显著提升了模型性能。

Abstract: Hallucinations in multimodal large language model are caused by the
text-visual bias and the co-occurrence bias. The former reflects an
over-reliance on text information in the decision-making process, while the
latter arises from the statistical object-pairing patterns abstracted from the
training data. Existing mitigation methods heuristically address these biases
without understanding the fluctuating bias level across the instances. We first
propose estimating the influence of respective token types (visual, prompt, and
previous outputs) using a gradient-based self-reflection method. The estimated
token influence further enables the detection of object-related visual tokens
and their integration into an influence-aware contrastive decoding framework to
mitigate both types of biases simultaneously. Our method operates without the
need for additional resources, such as costly fine-tuning, extra models, or
data statistics. Extensive experiments show it effectively reduces
hallucinations, achieving up to a 92% accuracy increase on LLaVA-QA90.

</details>


### [57] [Information transmission: Inferring change area from change moment in time series remote sensing images](https://arxiv.org/abs/2509.03112)
*Jialu Li,Chen Wu,Meiqi Hu*

Main category: cs.CV

TL;DR: 该论文提出了CAIM-Net，一个时间序列变化检测网络，通过从变化时刻推断变化区域来确保变化区域和变化时刻结果的一致性，解决了现有深度学习方法将二者视为独立任务的问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列变化检测对于探索生态系统动态至关重要，它能同时指示变化发生地点和时间。然而，现有深度学习方法通常将变化区域检测和变化时刻识别作为独立任务处理。鉴于变化区域可以从变化时刻推断，这种分离处理可能导致结果不一致，因此需要一个能保证两者一致性的方法。

Method: CAIM-Net（Change Area Inference from Moment Network）包含三个关键步骤：
1.  **差异提取与增强**：设计一个带批次维度堆叠的轻量级编码器快速提取差异特征，并应用边界增强卷积来放大这些差异特征。
2.  **粗略变化时刻提取**：利用第一步中增强的差异特征进行时空相关性分析，然后采用两种不同方法确定粗略变化时刻。
3.  **精细变化时刻提取与变化区域推断**：一个多尺度时间类激活映射（CAM）模块首先提高粗略变化时刻中实际变化发生时刻的权重，然后利用加权后的变化时刻推断变化区域。

Result: 该摘要主要描述了CAIM-Net的设计理念和实现方法，旨在通过从变化时刻推断变化区域，确保时间序列变化检测中变化区域和变化时刻结果的一致性。摘要中并未直接提供实验结果或性能评估数据。

Conclusion: CAIM-Net通过创新性地利用变化时刻与变化区域之间的内在关系，从变化时刻推断变化区域，解决了传统深度学习方法在时间序列变化检测中变化区域和变化时刻识别分离处理导致的不一致问题，从而能够更准确、一致地揭示生态系统动态。

Abstract: Time series change detection is a critical task for exploring ecosystem
dynamics using time series remote sensing images, because it can simultaneously
indicate where and when change occur. While deep learning has shown excellent
performance in this domain, it continues to approach change area detection and
change moment identification as distinct tasks. Given that change area can be
inferred from change moment, we propose a time series change detection network,
named CAIM-Net (Change Area Inference from Moment Network), to ensure
consistency between change area and change moment results. CAIM-Net infers
change area from change moment based on the intrinsic relationship between time
series analysis and spatial change detection. The CAIM-Net comprises three key
steps: Difference Extraction and Enhancement, Coarse Change Moment Extraction,
and Fine Change Moment Extraction and Change Area Inference. In the Difference
Extraction and Enhancement, a lightweight encoder with batch dimension stacking
is designed to rapidly extract difference features. Subsequently, boundary
enhancement convolution is applied to amplify these difference features. In the
Coarse Change Moment Extraction, the enhanced difference features from the
first step are used to spatiotemporal correlation analysis, and then two
distinct methods are employed to determine coarse change moments. In the Fine
Change Moment Extraction and Change Area Inference, a multiscale temporal Class
Activation Mapping (CAM) module first increases the weight of the
change-occurring moment from coarse change moments. Then the weighted change
moment is used to infer change area based on the fact that pixels with the
change moment must have undergone a change.

</details>


### [58] [Towards Realistic Hand-Object Interaction with Gravity-Field Based Diffusion Bridge](https://arxiv.org/abs/2509.03114)
*Miao Xu,Xiangyu Zhu,Xusheng Liang,Zidu Wang,Jinlin Wu,Zhen Lei*

Main category: cs.CV

TL;DR: 本文提出GravityDB，一个基于引力场扩散桥的模型，通过将手物交互视为引力驱动过程，解决现有方法在可变形手与刚性物体交互中存在的穿透、间隙和手部形变捕捉困难问题，并融入语义信息以生成物理合理、无穿透、稳定且形变真实的交互。


<details>
  <summary>Details</summary>
Motivation: 现有手物交互重建或姿态估计方法生成的交互状态粗糙，常出现穿透或接触间隙；同时，难以捕捉真实手部在交互过程中显著的形变。

Method: 将手物交互建模为引力驱动过程，并提出基于引力场扩散桥（GravityDB）的方法，用于模拟可变形手表面与刚性物体之间的交互。此外，该方法还融入文本描述中的语义信息来指导引力场的构建。

Result: 本方法有效解决了穿透和间隙问题，生成了物理合理、无穿透、稳定抓握且能捕捉真实手部形变的交互。通过结合语义信息，实现了更具语义意义的交互区域。在多个数据集上的定性和定量实验均证明了该方法的有效性。

Conclusion: GravityDB通过引力驱动的扩散桥和语义引导，成功克服了手物交互建模中的挑战，能够生成高质量、物理真实且语义丰富的交互，为手物交互模拟提供了一种有效且创新的解决方案。

Abstract: Existing reconstruction or hand-object pose estimation methods are capable of
producing coarse interaction states. However, due to the complex and diverse
geometry of both human hands and objects, these approaches often suffer from
interpenetration or leave noticeable gaps in regions that are supposed to be in
contact. Moreover, the surface of a real human hand undergoes non-negligible
deformations during interaction, which are difficult to capture and represent
with previous methods. To tackle these challenges, we formulate hand-object
interaction as an attraction-driven process and propose a Gravity-Field Based
Diffusion Bridge (GravityDB) to simulate interactions between a deformable hand
surface and rigid objects. Our approach effectively resolves the aforementioned
issues by generating physically plausible interactions that are free of
interpenetration, ensure stable grasping, and capture realistic hand
deformations. Furthermore, we incorporate semantic information from textual
descriptions to guide the construction of the gravitational field, enabling
more semantically meaningful interaction regions. Extensive qualitative and
quantitative experiments on multiple datasets demonstrate the effectiveness of
our method.

</details>


### [59] [Temporally-Aware Diffusion Model for Brain Progression Modelling with Bidirectional Temporal Regularisation](https://arxiv.org/abs/2509.03141)
*Mattia Litrico,Francesco Guarnera,Mario Valerio Giuffrida,Daniele Ravì,Sebastiano Battiato*

Main category: cs.CV

TL;DR: 本文提出TADM-3D，一个3D时间感知扩散模型，用于准确预测MRI脑部结构随时间的变化，通过结合脑龄估计器（BAE）和回溯时间正则化（BITR）来增强时间准确性和3D上下文理解，以克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要生成逼真的MRI图像以准确预测未来脑部结构变化，从而评估临床结果和疾病进展。然而，现有方法存在以下限制：1) 未能明确捕捉结构变化与时间间隔的关系，尤其是在年龄不平衡的数据集上；2) 仅依赖扫描插值，缺乏预测病理进展的临床实用性；3) 大多数方法基于2D切片架构，忽略了对纵向预测至关重要的完整3D解剖上下文。

Method: 本文提出一个3D时间感知扩散模型（TADM-3D）。为更好地模拟时间间隔与脑部变化的关系，TADM-3D利用预训练的脑龄估计器（BAE）来指导扩散模型生成能准确反映基线与随访扫描之间预期年龄差异的MRI图像。此外，为进一步提高TADM-3D的时间感知能力，提出了回溯时间正则化（BITR），通过训练TADM-3D进行从基线到随访（前向）以及从随访到基线（后向）的双向预测。该模型在OASIS-3数据集上进行训练和评估，并在NACC数据集的外部测试集上验证了泛化性能。

Result: TADM-3D能够准确预测MRI体积上的脑部进展。BAE有效指导了扩散模型生成反映准确年龄差异的MRIs。BITR正则化有助于模型生成时间上更准确的扫描。该模型在外部数据集上展现了良好的泛化性能。

Conclusion: TADM-3D是一个能够准确预测3D MRI脑部进展的创新模型，通过结合脑龄估计器和回溯时间正则化，有效解决了现有方法在时间感知和3D上下文方面的局限性，为临床评估和疾病进展分析提供了有价值的工具。

Abstract: Generating realistic MRIs to accurately predict future changes in the
structure of brain is an invaluable tool for clinicians in assessing clinical
outcomes and analysing the disease progression at the patient level. However,
current existing methods present some limitations: (i) some approaches fail to
explicitly capture the relationship between structural changes and time
intervals, especially when trained on age-imbalanced datasets; (ii) others rely
only on scan interpolation, which lack clinical utility, as they generate
intermediate images between timepoints rather than future pathological
progression; and (iii) most approaches rely on 2D slice-based architectures,
thereby disregarding full 3D anatomical context, which is essential for
accurate longitudinal predictions. We propose a 3D Temporally-Aware Diffusion
Model (TADM-3D), which accurately predicts brain progression on MRI volumes. To
better model the relationship between time interval and brain changes, TADM-3D
uses a pre-trained Brain-Age Estimator (BAE) that guides the diffusion model in
the generation of MRIs that accurately reflect the expected age difference
between baseline and generated follow-up scans. Additionally, to further
improve the temporal awareness of TADM-3D, we propose the Back-In-Time
Regularisation (BITR), by training TADM-3D to predict bidirectionally from the
baseline to follow-up (forward), as well as from the follow-up to baseline
(backward). Although predicting past scans has limited clinical applications,
this regularisation helps the model generate temporally more accurate scans. We
train and evaluate TADM-3D on the OASIS-3 dataset, and we validate the
generalisation performance on an external test set from the NACC dataset. The
code will be available upon acceptance.

</details>


### [60] [Preserving instance continuity and length in segmentation through connectivity-aware loss computation](https://arxiv.org/abs/2509.03154)
*Karol Szustakowski,Luk Frank,Julia Esser,Jan Gründemann,Marie Piraud*

Main category: cs.CV

TL;DR: 本文提出两种新型损失函数（负中心线损失和简化拓扑损失）和实验设计建议，以提升生物医学分割中细长结构的连续性，在轴突初始段数据集上验证，有效减少不连续性并改善长度计算。


<details>
  <summary>Details</summary>
Motivation: 在许多生物医学分割任务中，细长结构的连续性和长度比像素级精度更重要。然而，现有方法难以在信号缺失区域保持分割的连通性。

Method: 提出两种新型损失函数：负中心线损失和简化拓扑损失，并将其应用于卷积神经网络（CNNs）。此外，探讨了下采样和间距校正等实验设计特性，以帮助获得连续的分割掩膜。

Result: 与标准CNN和现有拓扑感知损失相比，所提出的方法显著减少了每个实例的分割不连续性，特别是在输入信号缺失区域，从而改善了下游应用中的实例长度计算。

Conclusion: 将结构先验知识嵌入到损失函数设计中，可以显著提高生物医学应用中分割的可靠性。

Abstract: In many biomedical segmentation tasks, the preservation of elongated
structure continuity and length is more important than voxel-wise accuracy. We
propose two novel loss functions, Negative Centerline Loss and Simplified
Topology Loss, that, applied to Convolutional Neural Networks (CNNs), help
preserve connectivity of output instances. Moreover, we discuss characteristics
of experiment design, such as downscaling and spacing correction, that help
obtain continuous segmentation masks. We evaluate our approach on a 3D
light-sheet fluorescence microscopy dataset of axon initial segments (AIS), a
task prone to discontinuity due to signal dropout. Compared to standard CNNs
and existing topology-aware losses, our methods reduce the number of
segmentation discontinuities per instance, particularly in regions with missing
input signal, resulting in improved instance length calculation in downstream
applications. Our findings demonstrate that structural priors embedded in the
loss design can significantly enhance the reliability of segmentation for
biological applications.

</details>


### [61] [Count2Density: Crowd Density Estimation without Location-level Annotations](https://arxiv.org/abs/2509.03170)
*Mattia Litrico,Feng Chen,Michael Pound,Sotirios A Tsaftaris,Sebastiano Battiato,Mario Valerio Giuffrida*

Main category: cs.CV

TL;DR: Count2Density是一种新颖的算法，仅使用总人数（计数级）标注来估计人群密度，通过生成伪密度图、利用历史地图库和自监督对比空间正则化，显著优于现有方法并能准确进行子区域计数。


<details>
  <summary>Details</summary>
Motivation: 人群密度估计任务的传统深度网络训练依赖于耗时、繁琐且难以规模化的细粒度位置级标注（即每个人头上的点），这严重阻碍了实际应用的可扩展性。

Method: 本研究提出了Count2Density方法。它在训练时仅使用计数级标注（总人数）。核心机制包括：1) 生成伪密度图，利用一个存储历史预测的“历史地图库”来减少确认偏差。该地图库通过无监督显著性估计器初始化，并用预测密度图的EMA迭代更新。2) 伪密度图通过超几何分布从估计的人群区域采样位置得到，采样数量由计数级标注决定。3) 引入自监督对比空间正则化器，以增强模型的空间感知能力，鼓励拥挤区域内特征表示相似，同时最大化与背景区域的差异性。

Result: 实验结果表明，Count2Density方法显著优于跨域适应方法，并在多个数据集上的半监督设置中，取得了比近期最先进方法更好的结果。额外的分析验证了管道中每个独立组件的有效性。

Conclusion: Count2Density能够有效从计数级标注中检索空间信息，并实现准确的子区域计数，证实了其整体方法的有效性及其各个组件的贡献。

Abstract: Crowd density estimation is a well-known computer vision task aimed at
estimating the density distribution of people in an image. The main challenge
in this domain is the reliance on fine-grained location-level annotations,
(i.e. points placed on top of each individual) to train deep networks.
Collecting such detailed annotations is both tedious, time-consuming, and poses
a significant barrier to scalability for real-world applications. To alleviate
this burden, we present Count2Density: a novel pipeline designed to predict
meaningful density maps containing quantitative spatial information using only
count-level annotations (i.e., total number of people) during training. To
achieve this, Count2Density generates pseudo-density maps leveraging past
predictions stored in a Historical Map Bank, thereby reducing confirmation
bias. This bank is initialised using an unsupervised saliency estimator to
provide an initial spatial prior and is iteratively updated with an EMA of
predicted density maps. These pseudo-density maps are obtained by sampling
locations from estimated crowd areas using a hypergeometric distribution, with
the number of samplings determined by the count-level annotations. To further
enhance the spatial awareness of the model, we add a self-supervised
contrastive spatial regulariser to encourage similar feature representations
within crowded regions while maximising dissimilarity with background regions.
Experimental results demonstrate that our approach significantly outperforms
cross-domain adaptation methods and achieves better results than recent
state-of-the-art approaches in semi-supervised settings across several
datasets. Additional analyses validate the effectiveness of each individual
component of our pipeline, confirming the ability of Count2Density to
effectively retrieve spatial information from count-level annotations and
enabling accurate subregion counting.

</details>


### [62] [AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain](https://arxiv.org/abs/2509.03179)
*Alma M. Liezenga,Stefan Wijnja,Puck de Haan,Niels W. T. Brink,Jip J. van Stijn,Yori Kamphuis,Klamer Schutte*

Main category: cs.CV

TL;DR: 本文研究了对军事目标检测器的投毒攻击及其检测方法。发现投毒攻击在实践中需要大量数据才能成功，而现有检测方法不足。为此，提出了一种基于自编码器的新型补丁检测方法AutoDetect，其性能优于现有方法，且效率更高。


<details>
  <summary>Details</summary>
Motivation: 投毒攻击对军事领域的AI系统构成日益增长的威胁，开放数据集和预训练模型的广泛使用加剧了这一风险。然而，针对目标检测系统，特别是军事领域的投毒攻击应用和检测研究有限，这可能导致严重后果。

Method: 研究者创建了一个小型军事车辆自定义数据集MilCivVeh。他们实现了一种修改版的基于补丁的投毒攻击BadDet，以评估军事目标检测器的脆弱性。为解决检测挑战，测试了专业的投毒检测方法和来自视觉工业检测领域的异常检测方法。最后，提出了一种名为AutoDetect的简单、快速、轻量级、基于自编码器的补丁检测方法。

Result: 研究发现，虽然投毒攻击能实现正向攻击成功率，但需要中毒数据占相当大的比例，这引发了对其实际适用性的质疑。现有的专业投毒检测方法和异常检测方法均表现不足。所提出的AutoDetect方法通过图像切片的重建误差，在分离干净样本和投毒样本方面显示出有前景的结果，性能优于现有方法，并且时间与内存消耗更低。

Conclusion: AutoDetect方法在检测基于补丁的投毒攻击方面表现出色。研究强调，军事领域中大型、具有代表性的数据集的可用性是进一步评估投毒攻击风险和补丁检测机会的先决条件。

Abstract: Poisoning attacks pose an increasing threat to the security and robustness of
Artificial Intelligence systems in the military domain. The widespread use of
open-source datasets and pretrained models exacerbates this risk. Despite the
severity of this threat, there is limited research on the application and
detection of poisoning attacks on object detection systems. This is especially
problematic in the military domain, where attacks can have grave consequences.
In this work, we both investigate the effect of poisoning attacks on military
object detectors in practice, and the best approach to detect these attacks. To
support this research, we create a small, custom dataset featuring military
vehicles: MilCivVeh. We explore the vulnerability of military object detectors
for poisoning attacks by implementing a modified version of the BadDet attack:
a patch-based poisoning attack. We then assess its impact, finding that while a
positive attack success rate is achievable, it requires a substantial portion
of the data to be poisoned -- raising questions about its practical
applicability. To address the detection challenge, we test both specialized
poisoning detection methods and anomaly detection methods from the visual
industrial inspection domain. Since our research shows that both classes of
methods are lacking, we introduce our own patch detection method: AutoDetect, a
simple, fast, and lightweight autoencoder-based method. Our method shows
promising results in separating clean from poisoned samples using the
reconstruction error of image slices, outperforming existing methods, while
being less time- and memory-intensive. We urge that the availability of large,
representative datasets in the military domain is a prerequisite to further
evaluate risks of poisoning attacks and opportunities patch detection.

</details>


### [63] [PPORLD-EDNetLDCT: A Proximal Policy Optimization-Based Reinforcement Learning Framework for Adaptive Low-Dose CT Denoising](https://arxiv.org/abs/2509.03185)
*Debopom Sutradhar,Ripon Kumar Debnath,Mohaimenul Azam Khan Raiaan,Yan Zhang,Reem E. Mohamed,Sami Azam*

Main category: cs.CV

TL;DR: 提出一种基于强化学习和编解码网络的LDCT图像去噪方法（PPORLD-EDNetLDCT），显著提高图像质量，并在分类任务中展现出更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT (LDCT) 可减少辐射暴露，但会引入噪声并降低图像质量。传统去噪方法（如迭代优化、监督学习）在保持图像质量方面存在不足。

Method: 引入PPORLD-EDNetLDCT模型，这是一种基于强化学习(RL)的编解码网络(Encoder-Decoder)方法。该方法利用动态的RL策略，通过先进的后验策略优化(PPO)算法，在自定义gym环境中，根据图像质量反馈实时优化去噪策略。

Result: 在低剂量CT数据集上，PPORLD-EDNetLDCT模型优于传统和深度学习方法，PSNR达到41.87，SSIM达到0.9814，RMSE为0.00236。在NIH-AAPM-Mayo Clinic挑战数据集上，PSNR为41.52，SSIM为0.9723，RMSE为0.0051。在COVID-19 LDCT分类任务中，经该方法处理的图像分类准确率提高到94%，比未采用RL去噪提高了4%。

Conclusion: 该方法为更安全、更准确的LDCT成像提供了一个有前景的解决方案。

Abstract: Low-dose computed tomography (LDCT) is critical for minimizing radiation
exposure, but it often leads to increased noise and reduced image quality.
Traditional denoising methods, such as iterative optimization or supervised
learning, often fail to preserve image quality. To address these challenges, we
introduce PPORLD-EDNetLDCT, a reinforcement learning-based (RL) approach with
Encoder-Decoder for LDCT. Our method utilizes a dynamic RL-based approach in
which an advanced posterior policy optimization (PPO) algorithm is used to
optimize denoising policies in real time, based on image quality feedback,
trained via a custom gym environment. The experimental results on the low dose
CT image and projection dataset demonstrate that the proposed PPORLD-EDNetLDCT
model outperforms traditional denoising techniques and other DL-based methods,
achieving a peak signal-to-noise ratio of 41.87, a structural similarity index
measure of 0.9814 and a root mean squared error of 0.00236. Moreover, in
NIH-AAPM-Mayo Clinic Low Dose CT Challenge dataset our method achived a PSNR of
41.52, SSIM of 0.9723 and RMSE of 0.0051. Furthermore, we validated the quality
of denoising using a classification task in the COVID-19 LDCT dataset, where
the images processed by our method improved the classification accuracy to
94\%, achieving 4\% higher accuracy compared to denoising without RL-based
denoising. This method offers a promising solution for safer and more accurate
LDCT imaging.

</details>


### [64] [AIVA: An AI-based Virtual Companion for Emotion-aware Interaction](https://arxiv.org/abs/2509.03212)
*Chenxi Li*

Main category: cs.CV

TL;DR: 本研究提出一个名为\ours的AI虚拟伴侣系统，通过整合多模态情感感知能力到大型语言模型（LLMs）中，实现情感对齐和动画化的人机交互。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs仅限于单模态文本处理，缺乏对非语言信号中情感线索的解释能力，从而阻碍了更沉浸和共情式的人机交互。

Method: 提出\ours系统，其核心是多模态情感感知网络（MSPN），利用跨模态融合Transformer和监督对比学习来获取情感线索。此外，还开发了情感感知提示工程策略生成共情回应，并集成了文本转语音（TTS）系统和动画虚拟形象模块以实现富有表现力的交互。

Result: 所提出的\ours系统为一个情感感知智能体提供了框架，能够捕获多模态情感线索，从而实现情感对齐和动画化的人机交互。

Conclusion: 本工作为情感感知智能体提供了一个通用框架，在伴侣机器人、社会护理、心理健康和以人为本的AI等领域具有广泛应用潜力。

Abstract: Recent advances in Large Language Models (LLMs) have significantly improved
natural language understanding and generation, enhancing Human-Computer
Interaction (HCI). However, LLMs are limited to unimodal text processing and
lack the ability to interpret emotional cues from non-verbal signals, hindering
more immersive and empathetic interactions. This work explores integrating
multimodal sentiment perception into LLMs to create emotion-aware agents. We
propose \ours, an AI-based virtual companion that captures multimodal sentiment
cues, enabling emotionally aligned and animated HCI. \ours introduces a
Multimodal Sentiment Perception Network (MSPN) using a cross-modal fusion
transformer and supervised contrastive learning to provide emotional cues.
Additionally, we develop an emotion-aware prompt engineering strategy for
generating empathetic responses and integrate a Text-to-Speech (TTS) system and
animated avatar module for expressive interactions. \ours provides a framework
for emotion-aware agents with applications in companion robotics, social care,
mental health, and human-centered AI.

</details>


### [65] [RTGMFF: Enhanced fMRI-based Brain Disorder Diagnosis via ROI-driven Text Generation and Multimodal Feature Fusion](https://arxiv.org/abs/2509.03214)
*Junhao Jia,Yifei Sun,Yunyou Liu,Cheng Yang,Changmiao Wang,Feiwei Qin,Yong Peng,Wenwen Min*

Main category: cs.CV

TL;DR: RTGMFF是一个融合ROI文本生成与多模态特征融合的框架，用于脑疾病诊断，通过结合频率-空间编码和语义对齐，显著提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI诊断受低信噪比、个体差异、模型频率感知不足及文本注释缺失的限制，难以实现可靠的临床诊断。

Method: 提出RTGMFF框架，包含三部分：(i) ROI驱动的fMRI文本生成，将脑活动、连接、年龄、性别转换为文本；(ii) 混合频率-空间编码器，结合小波-Mamba分支（频率）和Transformer（空间）提取特征；(iii) 自适应语义对齐模块，将文本和视觉特征映射到共享空间以缩小模态差距。

Result: 在ADHD-200和ABIDE基准测试上，RTGMFF在诊断准确性上超越现有方法，并在敏感性、特异性和ROC曲线下面积方面取得显著提升。

Conclusion: RTGMFF通过创新的文本生成和多模态特征融合策略，有效克服了传统fMRI诊断的局限性，为脑疾病诊断提供了更可靠、准确的工具。

Abstract: Functional magnetic resonance imaging (fMRI) is a powerful tool for probing
brain function, yet reliable clinical diagnosis is hampered by low
signal-to-noise ratios, inter-subject variability, and the limited frequency
awareness of prevailing CNN- and Transformer-based models. Moreover, most fMRI
datasets lack textual annotations that could contextualize regional activation
and connectivity patterns. We introduce RTGMFF, a framework that unifies
automatic ROI-level text generation with multimodal feature fusion for
brain-disorder diagnosis. RTGMFF consists of three components: (i) ROI-driven
fMRI text generation deterministically condenses each subject's activation,
connectivity, age, and sex into reproducible text tokens; (ii) Hybrid
frequency-spatial encoder fuses a hierarchical wavelet-mamba branch with a
cross-scale Transformer encoder to capture frequency-domain structure alongside
long-range spatial dependencies; and (iii) Adaptive semantic alignment module
embeds the ROI token sequence and visual features in a shared space, using a
regularized cosine-similarity loss to narrow the modality gap. Extensive
experiments on the ADHD-200 and ABIDE benchmarks show that RTGMFF surpasses
current methods in diagnostic accuracy, achieving notable gains in sensitivity,
specificity, and area under the ROC curve. Code is available at
https://github.com/BeistMedAI/RTGMFF.

</details>


### [66] [LGBP-OrgaNet: Learnable Gaussian Band Pass Fusion of CNN and Transformer Features for Robust Organoid Segmentation and Tracking](https://arxiv.org/abs/2509.03221)
*Jing Zhang,Siying Tao,Jiao Li,Tianhe Wang,Junchen Wu,Ruqian Hao,Xiaohui Du,Ruirong Tan,Rui Li*

Main category: cs.CV

TL;DR: 本文提出LGBP-OrgaNet，一种基于深度学习的自动化、无损方法，用于类器官的精确分割、跟踪和量化。


<details>
  <summary>Details</summary>
Motivation: 类器官的形状和大小是其发育状态的关键指标，但传统荧光标记方法会损伤其结构，因此需要一种自动化、无损的类器官分割和跟踪方法。

Method: 引入LGBP-OrgaNet深度学习系统，该系统利用CNN和Transformer模块提取互补信息，并通过创新的Learnable Gaussian Band Pass Fusion模块融合两分支数据。在解码器中，采用Bidirectional Cross Fusion Block融合多尺度特征，并通过渐进式拼接和上采样完成解码。

Result: SROrga在类器官分割数据集上展现出令人满意的分割精度和鲁棒性。

Conclusion: 该方法为类器官研究提供了一个强大的工具。

Abstract: Organoids replicate organ structure and function, playing a crucial role in
fields such as tumor treatment and drug screening. Their shape and size can
indicate their developmental status, but traditional fluorescence labeling
methods risk compromising their structure. Therefore, this paper proposes an
automated, non-destructive approach to organoid segmentation and tracking. We
introduced the LGBP-OrgaNet, a deep learning-based system proficient in
accurately segmenting, tracking, and quantifying organoids. The model leverages
complementary information extracted from CNN and Transformer modules and
introduces the innovative feature fusion module, Learnable Gaussian Band Pass
Fusion, to merge data from two branches. Additionally, in the decoder, the
model proposes a Bidirectional Cross Fusion Block to fuse multi-scale features,
and finally completes the decoding through progressive concatenation and
upsampling. SROrga demonstrates satisfactory segmentation accuracy and
robustness on organoids segmentation datasets, providing a potent tool for
organoid research.

</details>


### [67] [PI3DETR: Parametric Instance Detection of 3D Point Cloud Edges with a Geometry-Aware 3DETR](https://arxiv.org/abs/2509.03262)
*Fabio F. Oberweger,Michael Schwingshackl,Vanessa Staderini*

Main category: cs.CV

TL;DR: PI3DETR是一个端到端框架，直接从原始点云预测3D参数曲线实例，避免中间表示和多阶段处理，并能统一检测多种曲线类型，在3D边缘和曲线估计方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从点云中检测3D参数曲线时，常依赖中间表示和多阶段处理，且在真实世界的LiDAR和3D感知场景中，对噪声和不同采样密度的鲁棒性不足。

Method: PI3DETR是一个端到端框架，直接从原始点云预测3D参数曲线实例。它扩展了3DETR，并引入了几何感知匹配策略和专用损失函数，实现在一次前向传播中统一检测不同参数化的曲线类型（如三次贝塞尔曲线、线段、圆和弧）。模型还可选配后处理步骤以进一步细化预测。

Result: PI3DETR在ABC数据集上取得了新的最先进性能，并能有效地泛化到真实的传感器数据。其流线型设计显著提高了对噪声和不同采样密度的鲁棒性。

Conclusion: PI3DETR为3D边缘和曲线估计提供了一个简单而强大的解决方案，有效解决了真实世界LiDAR和3D感知场景中的关键挑战。

Abstract: We present PI3DETR, an end-to-end framework that directly predicts 3D
parametric curve instances from raw point clouds, avoiding the intermediate
representations and multi-stage processing common in prior work. Extending
3DETR, our model introduces a geometry-aware matching strategy and specialized
loss functions that enable unified detection of differently parameterized curve
types, including cubic B\'ezier curves, line segments, circles, and arcs, in a
single forward pass. Optional post-processing steps further refine predictions
without adding complexity. This streamlined design improves robustness to noise
and varying sampling densities, addressing critical challenges in real world
LiDAR and 3D sensing scenarios. PI3DETR sets a new state-of-the-art on the ABC
dataset and generalizes effectively to real sensor data, offering a simple yet
powerful solution for 3D edge and curve estimation.

</details>


### [68] [SynBT: High-quality Tumor Synthesis for Breast Tumor Segmentation by 3D Diffusion Model](https://arxiv.org/abs/2509.03267)
*Hongxu Yang,Edina Timko,Levente Lippenszky,Vanda Czipczer,Lehel Ferenczi*

Main category: cs.CV

TL;DR: SynBT是一种3D医学扩散模型，通过patch-to-volume自编码器和mask条件扩散模型，生成高质量乳腺肿瘤，从而将MRI肿瘤分割性能提升2-3% Dice Score。


<details>
  <summary>Details</summary>
Motivation: 现有肿瘤合成方法在肿瘤占据大空间体积（如大视场MRI中的乳腺肿瘤）时表现不佳，因其常基于小块生成，限制了机器学习模型分割性能的提升。

Method: 提出SynBT，一个3D医学扩散模型，用于生成对比增强MRI图像中的高质量乳腺肿瘤。该模型包含两部分：1) patch-to-volume自编码器，用于将高分辨率MRI压缩到紧凑潜在空间并保留大视场体积分辨率；2) 基于该潜在空间的mask条件扩散模型，在选定乳腺组织区域内合成真实的乳腺肿瘤。

Result: 通过肿瘤分割任务评估，SynBT生成的高质量肿瘤可使通用分割模型的性能提升2-3% Dice Score，并在大型公开数据集上得到验证。

Conclusion: SynBT生成高质量肿瘤的方法，能够有效提升MRI图像中肿瘤分割的性能，为肿瘤分割任务带来益处。

Abstract: Synthetic tumors in medical images offer controllable characteristics that
facilitate the training of machine learning models, leading to an improved
segmentation performance. However, the existing methods of tumor synthesis
yield suboptimal performances when tumor occupies a large spatial volume, such
as breast tumor segmentation in MRI with a large field-of-view (FOV), while
commonly used tumor generation methods are based on small patches. In this
paper, we propose a 3D medical diffusion model, called SynBT, to generate
high-quality breast tumor (BT) in contrast-enhanced MRI images. The proposed
model consists of a patch-to-volume autoencoder, which is able to compress the
high-resolution MRIs into compact latent space, while preserving the resolution
of volumes with large FOV. Using the obtained latent space feature vector, a
mask-conditioned diffusion model is used to synthesize breast tumors within
selected regions of breast tissue, resulting in realistic tumor appearances. We
evaluated the proposed method for a tumor segmentation task, which demonstrated
the proposed high-quality tumor synthesis method can facilitate the common
segmentation models with performance improvement of 2-3% Dice Score on a large
public dataset, and therefore provides benefits for tumor segmentation in MRI
images.

</details>


### [69] [PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection](https://arxiv.org/abs/2509.03277)
*Qihang Zhou,Shibo He,Jiangtao Yan,Wenchao Meng,Jiming Chen*

Main category: cs.CV

TL;DR: 本文提出了PointAD+框架，旨在将CLIP的2D泛化能力应用于3D异常检测，通过结合隐式（渲染）和显式（空间）3D表示，实现对未知类别对象零样本3D异常的全面检测和分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将CLIP强大的2D泛化能力应用于识别高度多样化类别中未见对象的3D异常，因此需要一个统一框架来全面检测和分割3D异常。

Method: 首先提出PointAD，利用点-像素对应关系通过渲染像素表示隐式地表示3D异常。在此基础上，提出PointAD+，通过引入显式3D表示（强调空间异常）来拓宽3D异常的解释。PointAD+设计了G-aggregation来整合几何信息以实现空间感知的点表示，并采用分层表示学习，将隐式（渲染提示）和显式（几何提示）异常语义融入分层文本提示。同时，引入跨层级对比对齐来促进渲染层和几何层之间的交互，最终整合来自两个层级的异常语义。测试时，PointAD+可即插即用集成RGB信息。

Result: 广泛的实验表明，PointAD+在零样本3D异常检测方面表现出优越性，能够识别高度多样化类别中未见对象的异常，实现了对异常的整体理解。

Conclusion: PointAD+成功地将CLIP的2D泛化能力扩展到3D异常检测领域，通过融合点和像素级信息以及分层表示学习，为识别复杂多样的3D异常提供了一个全面且鲁棒的解决方案。

Abstract: In this paper, we aim to transfer CLIP's robust 2D generalization
capabilities to identify 3D anomalies across unseen objects of highly diverse
class semantics. To this end, we propose a unified framework to comprehensively
detect and segment 3D anomalies by leveraging both point- and pixel-level
information. We first design PointAD, which leverages point-pixel
correspondence to represent 3D anomalies through their associated rendering
pixel representations. This approach is referred to as implicit 3D
representation, as it focuses solely on rendering pixel anomalies but neglects
the inherent spatial relationships within point clouds. Then, we propose
PointAD+ to further broaden the interpretation of 3D anomalies by introducing
explicit 3D representation, emphasizing spatial abnormality to uncover abnormal
spatial relationships. Hence, we propose G-aggregation to involve geometry
information to enable the aggregated point representations spatially aware. To
simultaneously capture rendering and spatial abnormality, PointAD+ proposes
hierarchical representation learning, incorporating implicit and explicit
anomaly semantics into hierarchical text prompts: rendering prompts for the
rendering layer and geometry prompts for the geometry layer. A cross-hierarchy
contrastive alignment is further introduced to promote the interaction between
the rendering and geometry layers, facilitating mutual anomaly learning.
Finally, PointAD+ integrates anomaly semantics from both layers to capture the
generalized anomaly semantics. During the test, PointAD+ can integrate RGB
information in a plug-and-play manner and further improve its detection
performance. Extensive experiments demonstrate the superiority of PointAD+ in
ZS 3D anomaly detection across unseen objects with highly diverse class
semantics, achieving a holistic understanding of abnormality.

</details>


### [70] [Empowering Lightweight MLLMs with Reasoning via Long CoT SFT](https://arxiv.org/abs/2509.03321)
*Linyu Ou*

Main category: cs.CV

TL;DR: 研究发现，对轻量级多模态语言模型（MLLMs）进行长链式思考（long CoT）数据的监督微调（SFT）能显著提升其推理能力，且SFT是后续强化学习（RL）进一步提升性能的关键先决条件。


<details>
  <summary>Details</summary>
Motivation: 虽然可验证奖励的强化学习（RL）已成功提升大型语言模型（LLMs）的推理能力，但其对参数少于70亿的轻量级多模态语言模型（MLLMs）的有效性尚未得到充分探索。

Method: 本文通过对轻量级多模态语言模型（MLLMs）使用长链式思考（long CoT）数据进行监督微调（SFT），并观察其对推理能力的影响，随后探讨了后续强化学习（RL）阶段带来的性能增益。

Result: 研究表明，使用长链式思考（long CoT）数据进行监督微调（SFT）能显著提升轻量级多模态语言模型（MLLMs）的推理能力。此外，在此SFT阶段之后，通过后续的强化学习（RL）阶段可以使MLLMs获得额外的性能提升。

Conclusion: 结合研究结果，可以得出结论：将长链式思考（long CoT）数据应用于监督微调（SFT）是开发轻量级多模态语言模型（MLLMs）推理能力的关键先决条件。

Abstract: While Reinforcement Learning with Verifiable Rewards has enhanced the
reasoning of large-scale language models (LLMs), its efficacy for lightweight
multimodal language models (MLLMs) with fewer than seven billion parameters
remains underexplored. This paper investigates the role of long
Chain-of-Thought (long CoT) data in enhancing the reasoning abilities of such
MLLMs. Our findings demonstrate that Supervised Fine-Tuning (SFT) with long CoT
data significantly improves MLLM reasoning. Furthermore, we observe that after
this initial SFT phase, MLLMs can achieve additional performance gains through
a subsequent RL stage. We conclude that a SFT stage with long CoT data is a
critical prerequisite for developing the reasoning capabilities of lightweight
MLLMs.

</details>


### [71] [Heatmap Guided Query Transformers for Robust Astrocyte Detection across Immunostains and Resolutions](https://arxiv.org/abs/2509.03323)
*Xizhe Zhang,Jiayang Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种混合CNN-Transformer检测器，用于自动检测组织学图像中的星形胶质细胞，通过结合局部特征提取和全局上下文推理，提高了检测灵敏度并减少了假阳性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 星形胶质细胞的形态复杂且染色依赖性变异大，导致组织学图像中其自动检测极具挑战性，但准确检测对神经系统疾病诊断至关重要。

Method: 研究提出了一种混合CNN-Transformer检测器，结合局部特征提取和全局上下文推理。具体包括：使用热图引导的查询机制为微小和微弱的星形胶质细胞生成空间定位锚点；以及利用轻量级Transformer模块提高密集簇中的辨别能力。

Result: 该模型在ALDH1L1和GFAP染色的星形胶质细胞数据集上进行了评估，结果显示其性能始终优于Faster R-CNN、YOLOv11和DETR，在FROC分析中证实具有更高的灵敏度和更少的假阳性。

Conclusion: 研究结果强调了混合CNN-Transformer架构在鲁棒星形胶质细胞检测方面的潜力，并为开发先进的计算病理学工具奠定了基础。

Abstract: Astrocytes are critical glial cells whose altered morphology and density are
hallmarks of many neurological disorders. However, their intricate branching
and stain dependent variability make automated detection of histological images
a highly challenging task. To address these challenges, we propose a hybrid CNN
Transformer detector that combines local feature extraction with global
contextual reasoning. A heatmap guided query mechanism generates spatially
grounded anchors for small and faint astrocytes, while a lightweight
Transformer module improves discrimination in dense clusters. Evaluated on
ALDH1L1 and GFAP stained astrocyte datasets, the model consistently
outperformed Faster R-CNN, YOLOv11 and DETR, achieving higher sensitivity with
fewer false positives, as confirmed by FROC analysis. These results highlight
the potential of hybrid CNN Transformer architectures for robust astrocyte
detection and provide a foundation for advanced computational pathology tools.

</details>


### [72] [InfraDiffusion: zero-shot depth map restoration with diffusion models and prompted segmentation from sparse infrastructure point clouds](https://arxiv.org/abs/2509.03324)
*Yixiong Jing,Cheng Zhang,Haibing Wu,Guangming Wang,Olaf Wysocki,Brian Sheil*

Main category: cs.CV

TL;DR: 本文提出了InfraDiffusion，一个零样本框架，通过将砖石点云投影并利用去噪扩散零空间模型（DDNM）恢复为深度图，有效提升了在弱光环境下对砖石结构的细粒度分割能力，尤其在砖块级别分割上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究在结构部件的语义分割方面已实现自动化，但砖块级别的细粒度分割（如剥落、砂浆流失检测）主要依赖RGB图像。然而，在砖石隧道等弱光环境中获取高分辨率图像不切实际。尽管点云对光照不敏感，但其非结构化、稀疏和嘈杂的特性限制了精细分割，因此需要一种能克服这些挑战的细粒度点云分割方法。

Method: InfraDiffusion是一个零样本框架。它首先利用虚拟相机将砖石点云投影成深度图，然后通过适配去噪扩散零空间模型（DDNM）来恢复并增强这些深度图。该方法无需特定任务训练，旨在提高深度图的视觉清晰度和几何一致性。

Result: 在砖石桥梁和隧道点云数据集上的实验表明，结合Segment Anything Model (SAM) 使用InfraDiffusion处理后的深度图，在砖块级别的分割方面取得了显著提升。

Conclusion: InfraDiffusion框架在自动化砖石资产检测方面展现出巨大潜力，尤其适用于在挑战性环境中对砖石结构进行细粒度（砖块级别）的检查和缺陷检测。

Abstract: Point clouds are widely used for infrastructure monitoring by providing
geometric information, where segmentation is required for downstream tasks such
as defect detection. Existing research has automated semantic segmentation of
structural components, while brick-level segmentation (identifying defects such
as spalling and mortar loss) has been primarily conducted from RGB images.
However, acquiring high-resolution images is impractical in low-light
environments like masonry tunnels. Point clouds, though robust to dim lighting,
are typically unstructured, sparse, and noisy, limiting fine-grained
segmentation. We present InfraDiffusion, a zero-shot framework that projects
masonry point clouds into depth maps using virtual cameras and restores them by
adapting the Denoising Diffusion Null-space Model (DDNM). Without task-specific
training, InfraDiffusion enhances visual clarity and geometric consistency of
depth maps. Experiments on masonry bridge and tunnel point cloud datasets show
significant improvements in brick-level segmentation using the Segment Anything
Model (SAM), underscoring its potential for automated inspection of masonry
assets. Our code and data is available at
https://github.com/Jingyixiong/InfraDiffusion-official-implement.

</details>


### [73] [Transformer-Guided Content-Adaptive Graph Learning for Hyperspectral Unmixing](https://arxiv.org/abs/2509.03376)
*Hui Chen,Liangyu Liu,Xianchao Xiu,Wanquan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为T-CAGU的Transformer引导内容自适应图解混框架，旨在解决高光谱解混中全局依赖和局部一致性难以同时表征的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的高光谱解混方法难以同时刻画全局依赖和局部一致性，导致长距离交互和边界细节难以兼顾。

Method: 该方法提出T-CAGU框架，利用Transformer捕获全局依赖，并引入内容自适应图神经网络增强局部关系。T-CAGU通过整合多阶传播动态学习图结构，并 leverages 图残差机制以保留全局信息并稳定训练。

Result: 实验结果表明，T-CAGU的性能优于现有最先进方法。

Conclusion: T-CAGU框架成功地同时处理了高光谱解混中的全局依赖和局部一致性问题，并表现出卓越的性能。

Abstract: Hyperspectral unmixing (HU) targets to decompose each mixed pixel in remote
sensing images into a set of endmembers and their corresponding abundances.
Despite significant progress in this field using deep learning, most methods
fail to simultaneously characterize global dependencies and local consistency,
making it difficult to preserve both long-range interactions and boundary
details. This letter proposes a novel transformer-guided content-adaptive graph
unmixing framework (T-CAGU), which overcomes these challenges by employing a
transformer to capture global dependencies and introducing a content-adaptive
graph neural network to enhance local relationships. Unlike previous work,
T-CAGU integrates multiple propagation orders to dynamically learn the graph
structure, ensuring robustness against noise. Furthermore, T-CAGU leverages a
graph residual mechanism to preserve global information and stabilize training.
Experimental results demonstrate its superiority over the state-of-the-art
methods. Our code is available at https://github.com/xianchaoxiu/T-CAGU.

</details>


### [74] [TinyDrop: Tiny Model Guided Token Dropping for Vision Transformers](https://arxiv.org/abs/2509.03379)
*Guoxin Wang,Qingyuan Wang,Binhua Huang,Shaowu Chen,Deepu John*

Main category: cs.CV

TL;DR: TinyDrop是一个无需训练的即插即用型框架，通过轻量级模型指导，选择性丢弃Vision Transformers (ViTs)中的低重要性tokens，从而显著降低计算成本（FLOPs高达80%），同时保持几乎相同的准确率。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs)在图像分类中表现出色，但由于处理所有图像tokens而导致计算成本高昂，尤其是在大型ViTs中进行推理时。

Method: 提出TinyDrop框架。该框架无需训练，通过一个轻量级视觉模型在推理时估计tokens的重要性，并据此选择性地丢弃低重要性tokens。它即插即用，无需架构修改，兼容多种ViT架构。

Result: 在标准图像分类基准测试中，TinyDrop框架将ViTs的FLOPs降低了高达80%，同时精度下降极小。

Conclusion: TinyDrop框架展示了其泛化能力和实用性，能够有效提升基于ViT的分类效率。

Abstract: Vision Transformers (ViTs) achieve strong performance in image classification
but incur high computational costs from processing all image tokens. To reduce
inference costs in large ViTs without compromising accuracy, we propose
TinyDrop, a training-free token dropping framework guided by a lightweight
vision model. The guidance model estimates the importance of tokens while
performing inference, thereby selectively discarding low-importance tokens if
large vit models need to perform attention calculations. The framework operates
plug-and-play, requires no architectural modifications, and is compatible with
diverse ViT architectures. Evaluations on standard image classification
benchmarks demonstrate that our framework reduces FLOPs by up to 80% for ViTs
with minimal accuracy degradation, highlighting its generalization capability
and practical utility for efficient ViT-based classification.

</details>


### [75] [Human Preference-Aligned Concept Customization Benchmark via Decomposed Evaluation](https://arxiv.org/abs/2509.03385)
*Reina Ishikawa,Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: 本文提出D-GPTScore，一种基于多模态大语言模型的人类对齐评估方法，并发布CC-AlignBench基准数据集，用于解决概念定制（特别是多概念）评估中现有指标与人类偏好不符的问题，实现了与人类偏好更高相关性的评估。


<details>
  <summary>Details</summary>
Motivation: 评估概念定制（尤其是多概念）具有挑战性，需要全面评估生成提示和概念图像的保真度以及概念间的交互。现有评估指标往往过于狭隘或过于宽泛，导致与人类偏好不符。

Method: 提出D-GPTScore，一种新型人类对齐评估方法，通过将评估标准分解为更细致的方面，并利用多模态大语言模型（MLLM）进行逐方面评估。同时发布CC-AlignBench，一个包含单概念和多概念任务的基准数据集，支持分阶段评估。

Result: D-GPTScore在CC-AlignBench基准测试上显著优于现有方法，与人类偏好展现出更高的相关性。

Conclusion: 本工作为概念定制评估建立了新标准，并突出了未来研究的关键挑战。

Abstract: Evaluating concept customization is challenging, as it requires a
comprehensive assessment of fidelity to generative prompts and concept images.
Moreover, evaluating multiple concepts is considerably more difficult than
evaluating a single concept, as it demands detailed assessment not only for
each individual concept but also for the interactions among concepts. While
humans can intuitively assess generated images, existing metrics often provide
either overly narrow or overly generalized evaluations, resulting in
misalignment with human preference. To address this, we propose Decomposed GPT
Score (D-GPTScore), a novel human-aligned evaluation method that decomposes
evaluation criteria into finer aspects and incorporates aspect-wise assessments
using Multimodal Large Language Model (MLLM). Additionally, we release Human
Preference-Aligned Concept Customization Benchmark (CC-AlignBench), a benchmark
dataset containing both single- and multi-concept tasks, enabling stage-wise
evaluation across a wide difficulty range -- from individual actions to
multi-person interactions. Our method significantly outperforms existing
approaches on this benchmark, exhibiting higher correlation with human
preferences. This work establishes a new standard for evaluating concept
customization and highlights key challenges for future research. The benchmark
and associated materials are available at
https://github.com/ReinaIshikawa/D-GPTScore.

</details>


### [76] [Scalable and Loosely-Coupled Multimodal Deep Learning for Breast Cancer Subtyping](https://arxiv.org/abs/2509.03408)
*Mohammed Amer,Mohamed A. Suliman,Tu Bui,Nuria Garcia,Serban Georgescu*

Main category: cs.CV

TL;DR: 本文提出一个可扩展、松耦合的多模态框架，通过整合拷贝数变异(CNV)、临床记录和创新的双重全玻片图像(WSI)表示，并采用新型融合策略，显著提升乳腺癌分子亚型分型的性能，超越了现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌分子亚型分型是重要的临床任务，对个性化治疗和改善患者预后至关重要。然而，临床环境中的多模态数据来源多样且可用性存在差异，因此亟需一种有效且灵活的多模态整合方法来增强亚型分型。

Method: 提出一个可扩展、松耦合的多模态框架，用于无缝整合CNV、临床记录和组织病理学图像等多种模态数据。引入一种结合传统图像和基于图的WSI双重表示方法。设计一种新型的多模态融合策略。该框架还具备高度灵活性，可轻松适应额外模态并应用于其他癌症类型，无需重新训练现有模态。

Result: 研究结果表明，所提出的双重WSI表示方法显著提升了性能。新型多模态融合策略在多种多模态条件下均能增强性能。通过将双重WSI表示与CNV、临床健康记录以及所提出的流程和融合策略整合，在乳腺癌亚型分型任务中超越了现有最先进的方法。

Conclusion: 所提出的多模态框架及其创新的双重WSI表示和融合策略，能够有效整合多样化的临床数据，显著提高乳腺癌分子亚型分型的准确性，并优于现有技术，为个性化治疗和预后评估提供了强大工具，且具备推广应用至其他癌症的潜力。

Abstract: Healthcare applications are inherently multimodal, benefiting greatly from
the integration of diverse data sources. However, the modalities available in
clinical settings can vary across different locations and patients. A key area
that stands to gain from multimodal integration is breast cancer molecular
subtyping, an important clinical task that can facilitate personalized
treatment and improve patient prognosis. In this work, we propose a scalable
and loosely-coupled multimodal framework that seamlessly integrates data from
various modalities, including copy number variation (CNV), clinical records,
and histopathology images, to enhance breast cancer subtyping. While our
primary focus is on breast cancer, our framework is designed to easily
accommodate additional modalities, offering the flexibility to scale up or down
with minimal overhead without requiring re-training of existing modalities,
making it applicable to other types of cancers as well. We introduce a
dual-based representation for whole slide images (WSIs), combining traditional
image-based and graph-based WSI representations. This novel dual approach
results in significant performance improvements. Moreover, we present a new
multimodal fusion strategy, demonstrating its ability to enhance performance
across a range of multimodal conditions. Our comprehensive results show that
integrating our dual-based WSI representation with CNV and clinical health
records, along with our pipeline and fusion strategy, outperforms
state-of-the-art methods in breast cancer subtyping.

</details>


### [77] [Time-Scaling State-Space Models for Dense Video Captioning](https://arxiv.org/abs/2509.03426)
*AJ Piergiovanni,Ganesh Satish Mallya,Dahun Kim,Anelia Angelova*

Main category: cs.CV

TL;DR: 本文提出了一种带传输状态的状态空间模型（SSM-TS），用于解决密集视频字幕任务中长视频的计算和内存限制，并实现视频的在线实时字幕生成。


<details>
  <summary>Details</summary>
Motivation: 现有密集视频字幕方法在处理长视频时面临计算复杂度和内存限制，且需要完整的视频输入，无法进行在线处理。

Method: 通过时间缩放状态空间模型（SSMs）并引入“带传输状态的状态空间模型”（SSM-TS），结合了SSMs的长序列和循环特性，克服了其在长上下文状态维持上的局限性，实现了视频的在线或流式字幕生成。

Result: 该方法能够很好地适应视频长度的扩展，并且计算量（FLOPs）减少了7倍。

Conclusion: 所提出的模型为密集视频字幕任务提供了一种高效、可在线处理的解决方案，特别适用于长视频，并在计算效率方面表现出色。

Abstract: Dense video captioning is a challenging video understanding task which aims
to simultaneously segment the video into a sequence of meaningful consecutive
events and to generate detailed captions to accurately describe each event.
Existing methods often encounter difficulties when working with the long videos
associated with dense video captioning, due to the computational complexity and
memory limitations. Furthermore, traditional approaches require the entire
video as input, in order to produce an answer, which precludes online
processing of the video. We address these challenges by time-scaling
State-Space Models (SSMs) to even longer sequences than before. Our approach,
State-Space Models with Transfer State, combines both the long-sequence and
recurrent properties of SSMs and addresses the main limitation of SSMs which
are otherwise not able to sustain their state for very long contexts,
effectively scaling SSMs further in time. The proposed model is particularly
suitable for generating captions on-the-fly, in an online or streaming manner,
without having to wait for the full video to be processed, which is more
beneficial in practice. When applied to dense video captioning, our approach
scales well with video lengths and uses 7x fewer FLOPs.

</details>


### [78] [Decoding Visual Neural Representations by Multimodal with Dynamic Balancing](https://arxiv.org/abs/2509.03433)
*Kaili sun,Xingyu Miao,Bing Zhai,Haoran Duan,Yang Long*

Main category: cs.CV

TL;DR: 该研究提出了一个创新框架，融合脑电图（EEG）、图像和文本数据，旨在从低信噪比的EEG信号中解码视觉神经表征，并在ThingsEEG数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 从低信噪比的EEG信号中解码视觉神经表征具有挑战性。引入文本模态可以增强EEG信号与视觉内容之间的语义对应关系，利用文本提供的明确语义标签，使同类别的图像和EEG特征与文本表征在共享多模态空间中更好地对齐。

Method: 该框架集成了EEG、图像和文本数据。具体包括：1) 引入文本模态增强语义对应；2) 提出适配器模块（adapter module）以缓解高维表征的不稳定性，促进跨模态特征对齐与融合；3) 设计模态一致性动态平衡（MCDB）策略，动态调整各模态贡献权重，以解决文本引入的模态特征贡献不平衡问题；4) 提出随机扰动正则化（SPR）项，通过引入动态高斯噪声提升模型泛化能力。

Result: 在ThingsEEG数据集上的评估结果表明，该方法在Top-1和Top-5准确率指标上均超越了以往的最先进方法，分别提高了2.0%和4.7%。

Conclusion: 该研究提出的多模态融合框架有效提升了从低信噪比EEG信号中解码视觉神经表征的能力，并通过引入文本、适配器模块、MCDB策略和SPR项，解决了多模态数据处理中的关键挑战，取得了显著的性能提升。

Abstract: In this work, we propose an innovative framework that integrates EEG, image,
and text data, aiming to decode visual neural representations from low
signal-to-noise ratio EEG signals. Specifically, we introduce text modality to
enhance the semantic correspondence between EEG signals and visual content.
With the explicit semantic labels provided by text, image and EEG features of
the same category can be more closely aligned with the corresponding text
representations in a shared multimodal space. To fully utilize pre-trained
visual and textual representations, we propose an adapter module that
alleviates the instability of high-dimensional representation while
facilitating the alignment and fusion of cross-modal features. Additionally, to
alleviate the imbalance in multimodal feature contributions introduced by the
textual representations, we propose a Modal Consistency Dynamic Balance (MCDB)
strategy that dynamically adjusts the contribution weights of each modality. We
further propose a stochastic perturbation regularization (SPR) term to enhance
the generalization ability of semantic perturbation-based models by introducing
dynamic Gaussian noise in the modality optimization process. The evaluation
results on the ThingsEEG dataset show that our method surpasses previous
state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by
2.0\% and 4.7\% respectively.

</details>


### [79] [Joint Training of Image Generator and Detector for Road Defect Detection](https://arxiv.org/abs/2509.03465)
*Kuan-Chuan Peng*

Main category: cs.CV

TL;DR: 提出JTGD，通过联合训练图像生成器和检测器，为道路缺陷检测生成高质量的困难样本进行数据增强，在不使用集成或TTA的情况下，超越SOTA并显著降低参数量，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 道路缺陷检测对减少车辆损坏至关重要。考虑到缺陷检测器通常部署在内存和计算资源有限的边缘设备上，研究目标是在不使用集成方法或测试时增强（TTA）的情况下实现高效且准确的道路缺陷检测。

Method: 提出JTGD（联合训练图像生成器和检测器）方法。该方法为生成模型设计了双判别器，以确保合成的缺陷补丁和整体图像都真实可信。通过引入基于CLIP的Fréchet Inception Distance损失来提高合成图像的质量。生成模型与检测器联合训练，鼓励生成模型合成对检测器更具挑战性的困难样本，这些高质量的困难合成图像用于数据增强。

Result: JTGD在RDD2022道路缺陷检测基准测试中，在不使用集成和TTA的条件下，性能超越了各国的现有最佳方法。此外，JTGD的参数量仅为现有基线的不到20%，使其更适合在实际的边缘设备上部署。

Conclusion: JTGD通过生成高质量的困难样本进行数据增强，为资源受限的边缘设备上的道路缺陷检测提供了一种有效且高效的解决方案，在不依赖复杂方法的前提下实现了卓越的检测性能和显著降低的模型复杂度。

Abstract: Road defect detection is important for road authorities to reduce the vehicle
damage caused by road defects. Considering the practical scenarios where the
defect detectors are typically deployed on edge devices with limited memory and
computational resource, we aim at performing road defect detection without
using ensemble-based methods or test-time augmentation (TTA). To this end, we
propose to Jointly Train the image Generator and Detector for road defect
detection (dubbed as JTGD). We design the dual discriminators for the
generative model to enforce both the synthesized defect patches and overall
images to look plausible. The synthesized image quality is improved by our
proposed CLIP-based Fr\'echet Inception Distance loss. The generative model in
JTGD is trained jointly with the detector to encourage the generative model to
synthesize harder examples for the detector. Since harder synthesized images of
better quality caused by the aforesaid design are used in the data
augmentation, JTGD outperforms the state-of-the-art method in the RDD2022 road
defect detection benchmark across various countries under the condition of no
ensemble and TTA. JTGD only uses less than 20% of the number of parameters
compared with the competing baseline, which makes it more suitable for
deployment on edge devices in practice.

</details>


### [80] [Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual Prompts for NR-IQA](https://arxiv.org/abs/2509.03494)
*Yahya Benmahane,Mohammed El Hassouni*

Main category: cs.CV

TL;DR: 提出一种基于像素空间视觉提示的参数高效无参考图像质量评估（NR-IQA）方法，实现了多模态大语言模型（MLLMs）在低级视觉任务上的高效适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法对多模态大语言模型（MLLMs）进行全量微调时参数量巨大，效率低下。本研究旨在为NR-IQA等低级视觉任务提供一种参数高效的MLLM适应方案。

Method: 本方法提出在像素空间优化视觉提示（visual prompts），仅训练最多60万个参数（占基模型的不到0.01%），同时冻结底层模型。推理时，这些视觉提示通过加法与图像结合，并由mPLUG-Owl2模型以及文本查询“Rate the technical quality of the image.”进行处理。

Result: 在KADID-10k、KonIQ-10k和AGIQA-3k数据集上，对合成、真实和AI生成等失真类型的评估表明，该方法性能与全量微调方法及专业NR-IQA模型相当，在KADID-10k上实现了0.93的SRCC。

Conclusion: 本工作首次利用像素空间视觉提示进行NR-IQA，为多模态大语言模型在低级视觉任务上的高效适应开辟了新途径。

Abstract: In this paper, we propose a novel parameter-efficient adaptation method for
No- Reference Image Quality Assessment (NR-IQA) using visual prompts optimized
in pixel-space. Unlike full fine-tuning of Multimodal Large Language Models
(MLLMs), our approach trains only 600K parameters at most (< 0.01% of the base
model), while keeping the underlying model fully frozen. During inference,
these visual prompts are combined with images via addition and processed by
mPLUG-Owl2 with the textual query "Rate the technical quality of the image."
Evaluations across distortion types (synthetic, realistic, AI-generated) on
KADID- 10k, KonIQ-10k, and AGIQA-3k demonstrate competitive performance against
full finetuned methods and specialized NR-IQA models, achieving 0.93 SRCC on
KADID-10k. To our knowledge, this is the first work to leverage pixel-space
visual prompts for NR-IQA, enabling efficient MLLM adaptation for low-level
vision tasks. The source code is publicly available at https: // github. com/
yahya-ben/ mplug2-vp-for-nriqa .

</details>


### [81] [OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and Generation](https://arxiv.org/abs/2509.03498)
*Han Li,Xinyu Peng,Yaoming Wang,Zelin Peng,Xin Chen,Rongxiang Weng,Jingang Wang,Xunliang Cai,Wenrui Dai,Hongkai Xiong*

Main category: cs.CV

TL;DR: 本文介绍OneCAT，一个纯解码器Transformer架构的统一多模态模型，无缝集成理解、生成和编辑，无需外部视觉组件，通过模态特异性MoE和多尺度视觉自回归机制，显著提高效率并超越现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 构建一个统一的多模态模型，能够无缝集成理解、生成和编辑功能。旨在消除推理时对外部视觉组件（如ViT或视觉tokenizer）的需求，以显著提高效率，尤其是在处理高分辨率输入时。探索纯自回归建模作为统一多模态智能的充分且优雅基础的潜力。

Method: 引入OneCAT，一个新颖的纯解码器（decoder-only）Transformer架构。采用模态特异性专家混合（MoE）结构，并使用单一自回归（AR）目标进行训练。该架构原生支持动态分辨率。开创性地在大型语言模型（LLM）中引入多尺度视觉自回归机制。

Result: 成功消除了推理时对外部Vision Transformers (ViT)或视觉tokenizer的需求，显著提高了效率，尤其适用于高分辨率输入。多尺度视觉自回归机制与基于扩散的方法相比，大大减少了解码步骤，同时保持了最先进的性能。OneCAT在多模态生成、编辑和理解的基准测试中，超越了现有开源统一多模态模型，设定了新的性能标准。

Conclusion: 纯自回归建模作为统一多模态智能的充分且优雅的基础，具有强大的潜力。OneCAT模型通过其创新架构和方法，成功地实现了统一多模态任务的集成和卓越表现，证明了这种方法的有效性和先进性。

Abstract: We introduce OneCAT, a unified multimodal model that seamlessly integrates
understanding, generation, and editing within a novel, pure decoder-only
transformer architecture. Our framework uniquely eliminates the need for
external components such as Vision Transformers (ViT) or vision tokenizer
during inference, leading to significant efficiency gains, especially for
high-resolution inputs. This is achieved through a modality-specific
Mixture-of-Experts (MoE) structure trained with a single autoregressive (AR)
objective, which also natively supports dynamic resolutions. Furthermore, we
pioneer a multi-scale visual autoregressive mechanism within the Large Language
Model (LLM) that drastically reduces decoding steps compared to diffusion-based
methods while maintaining state-of-the-art performance. Our findings
demonstrate the powerful potential of pure autoregressive modeling as a
sufficient and elegant foundation for unified multimodal intelligence. As a
result, OneCAT sets a new performance standard, outperforming existing
open-source unified multimodal models across benchmarks for multimodal
generation, editing, and understanding.

</details>


### [82] [DeepSea MOT: A benchmark dataset for multi-object tracking on deep-sea video](https://arxiv.org/abs/2509.03499)
*Kevin Barnard,Elaine Liu,Kristine Walz,Brian Schlining,Nancy Jacobsen Stout,Lonny Lundsten*

Main category: cs.CV

TL;DR: 开发并发布了首个用于深海视频多目标跟踪的基准数据集，评估了多种检测模型和跟踪器性能。


<details>
  <summary>Details</summary>
Motivation: 机器模型开发中，基准测试对于评估和优化目标检测与多目标跟踪模型的性能至关重要。

Method: 研究开发了一个包含四个深海（中水层和底栖）视频序列的新型基准数据集。利用该数据集评估了多个蒙特利湾水族馆研究所（MBARI）目标检测模型和一个FathomNet单类别目标检测模型，以及多个跟踪器的性能。性能评估采用Higher Order Tracking Accuracy（HOTA）指标，该指标综合考虑了检测、定位和关联的准确性。

Result: 首次公开提供了用于深海视频片段多目标跟踪的基准数据集。研究还提供了基准数据、生成额外基准视频的明确工作流程，以及计算指标的Python示例代码。

Conclusion: 该研究通过提供首个公开的深海视频多目标跟踪基准数据集及相关工具，为深海环境中目标检测和跟踪模型的性能评估与优化奠定了基础。

Abstract: Benchmarking multi-object tracking and object detection model performance is
an essential step in machine learning model development, as it allows
researchers to evaluate model detection and tracker performance on
human-generated 'test' data, facilitating consistent comparisons between models
and trackers and aiding performance optimization. In this study, a novel
benchmark video dataset was developed and used to assess the performance of
several Monterey Bay Aquarium Research Institute object detection models and a
FathomNet single-class object detection model together with several trackers.
The dataset consists of four video sequences representing midwater and benthic
deep-sea habitats. Performance was evaluated using Higher Order Tracking
Accuracy, a metric that balances detection, localization, and association
accuracy. To the best of our knowledge, this is the first publicly available
benchmark for multi-object tracking in deep-sea video footage. We provide the
benchmark data, a clearly documented workflow for generating additional
benchmark videos, as well as example Python notebooks for computing metrics.

</details>


### [83] [Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data](https://arxiv.org/abs/2509.03501)
*Honglu Zhou,Xiangyu Peng,Shrikant Kendre,Michael S. Ryoo,Silvio Savarese,Caiming Xiong,Juan Carlos Niebles*

Main category: cs.CV

TL;DR: 本文提出 Strefer 框架，通过合成细粒度时空指令数据，显著提升了 Video LLMs 处理动态环境中时空指代和推理的能力，为下一代 AI 伴侣奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有 Video LLMs 在处理用户查询中细粒度的时空指代（如时间事件或手势线索）时表现不佳，无法满足下一代 AI 伴侣在真实世界环境中进行精确时空推理的需求。

Method: 引入 Strefer 框架，该框架通过数据引擎伪标注视频中细粒度、时序密集的元数据（包括主体、客体、位置、动作描述及时间线），生成多样化的指令微调数据，以提升 Video LLMs 的时空指代与推理能力。此过程无需专有模型或大量人工标注。

Result: 使用 Strefer 数据训练的模型在需要时空消歧的任务上表现优于基线，增强了 Video LLMs 解释时空指代和进行时空感知推理的能力，促进了更通用的推理，且无需昂贵的人工标注或新的视频数据。

Conclusion: Strefer 框架为感知基础的指令微调 Video LLMs 建立了新基础，使其能更好地理解和处理真实世界的时空信息，对开发更智能的 AI 伴侣至关重要。

Abstract: Next-generation AI companions must go beyond general video understanding to
resolve spatial and temporal references in dynamic, real-world environments.
Existing Video Large Language Models (Video LLMs), while capable of
coarse-level comprehension, struggle with fine-grained, spatiotemporal
reasoning, especially when user queries rely on time-based event references for
temporal anchoring, or gestural cues for spatial anchoring to clarify object
references and positions. To bridge this critical gap, we introduce Strefer, a
synthetic instruction data generation framework designed to equip Video LLMs
with spatiotemporal referring and reasoning capabilities. Strefer produces
diverse instruction-tuning data using a data engine that pseudo-annotates
temporally dense, fine-grained video metadata, capturing rich spatial and
temporal information in a structured manner, including subjects, objects, their
locations as masklets, and their action descriptions and timelines. Our
approach enhances the ability of Video LLMs to interpret spatial and temporal
references, fostering more versatile, space-time-aware reasoning essential for
real-world AI companions. Without using proprietary models, costly human
annotation, or the need to annotate large volumes of new videos, experimental
evaluations show that models trained with data produced by Strefer outperform
baselines on tasks requiring spatial and temporal disambiguation. Additionally,
these models exhibit enhanced space-time-aware reasoning, establishing a new
foundation for perceptually grounded, instruction-tuned Video LLMs.

</details>


### [84] [A comprehensive Persian offline handwritten database for investigating the effects of heritability and family relationships on handwriting](https://arxiv.org/abs/2509.03510)
*Abbas Zohrevand,Javad Sadri,Zahra Imani*

Main category: cs.CV

TL;DR: 本文介绍了一个用于研究遗传对笔迹影响的综合数据库，该数据库收集了210个家族的多种手写样本，并初步发现家族成员笔迹间存在相似性。


<details>
  <summary>Details</summary>
Motivation: 为了回答笔迹是否存在遗传成分、是否可遗传以及家族关系是否影响笔迹等问题，并填补目前缺乏此类数据库的空白。

Method: 收集了210个家族（包括祖父母、父母、叔伯姑姨、兄弟姐妹、堂表亲、侄甥）的手写数字、字母、形状和自由段落样本，并记录了所有书写者的家族关系，构建了一个综合数据库。

Result: 通过对家族成员笔迹特征的比较和调查，检测到他们特征和书写风格之间的相似性。

Conclusion: 该数据库免费提供给模式识别社区，有望为遗传和家族关系对笔迹影响的研究提供基础。

Abstract: This paper introduces a comprehensive database for research and investigation
on the effects of inheritance on handwriting. A database has been created that
can be used to answer questions such as: Is there a genetic component to
handwriting? Is handwriting inherited? Do family relationships affect
handwriting? Varieties of samples of handwritten components such as: digits,
letters, shapes and free paragraphs of 210 families including (grandparents,
parents, uncles, aunts, siblings, cousins, nephews and nieces) have been
collected using specially designed forms, and family relationships of all
writers are captured. To the best of our knowledge, no such database is
presently available. Based on comparisons and investigation of features of
handwritings of family members, similarities among their features and writing
styles are detected. Our database is freely available to the pattern
recognition community and hope it will pave the way for investigations on the
effects of inheritance and family relationships on handwritings.

</details>


### [85] [Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?](https://arxiv.org/abs/2509.03516)
*Ouxiang Li,Yuan Wang,Xinting Hu,Huijuan Huang,Rui Chen,Jiarong Ou,Xin Tao,Pengfei Wan,Fuli Feng*

Main category: cs.CV

TL;DR: 本文提出了T2I-CoReBench基准，旨在全面评估文本到图像模型在复杂场景下的组合与推理能力。实验发现现有模型在这两方面均表现不足，推理能力更是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有T2I基准在评估模型的组合与推理能力方面存在局限性，特别是在面对复杂提示词（高场景密度、多步推理）时表现不足，无法有效衡量T2I模型在推理方面的最新进展。

Method: 本文提出了T2I-CoReBench基准。通过构建包含场景图元素（实例、属性、关系）的组合能力评估，以及基于推理哲学框架（演绎、归纳、溯因）的推理能力评估，形成12维评估分类法以确保全面性。通过设计具有高组合密度和多步推理的提示词来增加复杂性。每个提示词配有清单以进行细粒度、可靠的评估。该基准包含1,080个提示词和约13,500个清单问题。

Result: 在对27个T2I模型的实验中发现，当前T2I模型在复杂高密度场景下的组合能力仍然有限；推理能力则更为落后，是关键瓶颈，所有模型都难以从提示词中推断出隐式元素。

Conclusion: 当前T2I模型在处理复杂高密度场景的组合能力上仍有不足，而其推理能力（特别是隐式元素推断）是更显著的短板和关键瓶颈。T2I-CoReBench为T2I模型的全面评估提供了有效的工具和新的视角。

Abstract: Text-to-image (T2I) generation aims to synthesize images from textual
prompts, which jointly specify what must be shown and imply what can be
inferred, thereby corresponding to two core capabilities: composition and
reasoning. However, with the emerging advances of T2I models in reasoning
beyond composition, existing benchmarks reveal clear limitations in providing
comprehensive evaluations across and within these capabilities. Meanwhile,
these advances also enable models to handle more complex prompts, whereas
current benchmarks remain limited to low scene density and simplified
one-to-one reasoning. To address these limitations, we propose T2I-CoReBench, a
comprehensive and complex benchmark that evaluates both composition and
reasoning capabilities of T2I models. To ensure comprehensiveness, we structure
composition around scene graph elements (instance, attribute, and relation) and
reasoning around the philosophical framework of inference (deductive,
inductive, and abductive), formulating a 12-dimensional evaluation taxonomy. To
increase complexity, driven by the inherent complexities of real-world
scenarios, we curate each prompt with high compositional density for
composition and multi-step inference for reasoning. We also pair each prompt
with a checklist that specifies individual yes/no questions to assess each
intended element independently to facilitate fine-grained and reliable
evaluation. In statistics, our benchmark comprises 1,080 challenging prompts
and around 13,500 checklist questions. Experiments across 27 current T2I models
reveal that their composition capability still remains limited in complex
high-density scenarios, while the reasoning capability lags even further behind
as a critical bottleneck, with all models struggling to infer implicit elements
from prompts. Our project page: https://t2i-corebench.github.io/.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [86] [Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis](https://arxiv.org/abs/2509.02650)
*Henrique Correia da Fonseca,António Fernandes,Zhao Song,Theodor Cimpeanu,Nataliya Balabanova,Adeela Bashir,Paolo Bova,Alessio Buscemi,Alessandro Di Stefano,Manh Hong Duong,Elias Fernandez Domingos,Ndidi Bianca Ogbo,Simon T. Powers,Daniele Proverbio,Zia Ush Shamszaman,Fernando P. Santos,The Anh Han,Marcus Krellner*

Main category: cs.AI

TL;DR: 研究发现媒体可通过影响声誉，促进AI开发者优先考虑安全。但其有效性受信息可靠性、媒体获取成本和安全成本的制约，可作为AI安全的“软性监管者”。


<details>
  <summary>Details</summary>
Motivation: AI开发者常将利润置于用户安全之上，导致AI不可信赖。为促使AI产品安全并广泛应用，亟需机制来惩罚不端行为，本文探讨媒体声誉损失能否成为这种激励。

Method: 构建了由自利的AI开发者和用户组成的人工群体，并采用演化博弈论的视角进行研究。

Result: 研究结果表明，媒体确实能够促进开发者和用户之间的合作（即AI安全），但并非总是如此。若媒体信息质量不可靠、媒体获取成本过高或确保AI安全成本过高，合作将无法演化。

Conclusion: 媒体可以通过塑造公众认知和问责开发者，成为一种强大的“软性监管者”，即使在缺乏正式政府监管的情况下，也能引导AI产品走向安全。

Abstract: When developers of artificial intelligence (AI) products need to decide
between profit and safety for the users, they likely choose profit.
Untrustworthy AI technology must come packaged with tangible negative
consequences. Here, we envisage those consequences as the loss of reputation
caused by media coverage of their misdeeds, disseminated to the public. We
explore whether media coverage has the potential to push AI creators into the
production of safe products, enabling widespread adoption of AI technology. We
created artificial populations of self-interested creators and users and
studied them through the lens of evolutionary game theory. Our results reveal
that media is indeed able to foster cooperation between creators and users, but
not always. Cooperation does not evolve if the quality of the information
provided by the media is not reliable enough, or if the costs of either
accessing media or ensuring safety are too high. By shaping public perception
and holding developers accountable, media emerges as a powerful soft regulator
-- guiding AI safety even in the absence of formal government oversight.

</details>


### [87] [The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)](https://arxiv.org/abs/2509.02661)
*Andrew Ferguson,Marisa LaFleur,Lars Ruthotto,Jesse Thaler,Yuan-Sen Ting,Pratyush Tiwary,Soledad Villar,E. Paulo Alves,Jeremy Avigad,Simon Billinge,Camille Bilodeau,Keith Brown,Emmanuel Candes,Arghya Chattopadhyay,Bingqing Cheng,Jonathan Clausen,Connor Coley,Andrew Connolly,Fred Daum,Sijia Dong,Chrisy Xiyu Du,Cora Dvorkin,Cristiano Fanelli,Eric B. Ford,Luis Manuel Frutos,Nicolás García Trillos,Cecilia Garraffo,Robert Ghrist,Rafael Gomez-Bombarelli,Gianluca Guadagni,Sreelekha Guggilam,Sergei Gukov,Juan B. Gutiérrez,Salman Habib,Johannes Hachmann,Boris Hanin,Philip Harris,Murray Holland,Elizabeth Holm,Hsin-Yuan Huang,Shih-Chieh Hsu,Nick Jackson,Olexandr Isayev,Heng Ji,Aggelos Katsaggelos,Jeremy Kepner,Yannis Kevrekidis,Michelle Kuchera,J. Nathan Kutz,Branislava Lalic,Ann Lee,Matt LeBlanc,Josiah Lim,Rebecca Lindsey,Yongmin Liu,Peter Y. Lu,Sudhir Malik,Vuk Mandic,Vidya Manian,Emeka P. Mazi,Pankaj Mehta,Peter Melchior,Brice Ménard,Jennifer Ngadiuba,Stella Offner,Elsa Olivetti,Shyue Ping Ong,Christopher Rackauckas,Philippe Rigollet,Chad Risko,Philip Romero,Grant Rotskoff,Brett Savoie,Uros Seljak,David Shih,Gary Shiu,Dima Shlyakhtenko,Eva Silverstein,Taylor Sparks,Thomas Strohmer,Christopher Stubbs,Stephen Thomas,Suriyanarayanan Vaikuntanathan,Rene Vidal,Francisco Villaescusa-Navarro,Gregory Voth,Benjamin Wandelt,Rachel Ward,Melanie Weber,Risa Wechsler,Stephen Whitelam,Olaf Wiest,Mike Williams,Zhuoran Yang,Yaroslava G. Yingling,Bin Yu,Shuwen Yue,Ann Zabludoff,Huimin Zhao,Tong Zhang*

Main category: cs.AI

TL;DR: 本社区论文总结了数学和物理科学（MPS）领域对人工智能（AI）的看法，并提出了加强AI与MPS之间联系的战略和优先事项。


<details>
  <summary>Details</summary>
Motivation: 源于NSF关于AI与MPS未来研讨会的成果，旨在理解MPS领域如何最好地利用AI并为其发展做出贡献。论文指出AI与MPS的联系日益紧密，现在是关键时刻，需要主动且深思熟虑地利用AI促进科学发现，并通过应用基础科学概念优化AI发展。

Method: 作为一份社区论文，它总结了2025年春夏季MPS社区对快速发展领域（AI+MPS）的观点，并在此基础上提出了活动和战略优先事项以加强二者之间的联系。

Result: 提出了三项战略优先事项：(1) 在两个方向上都支持AI+MPS研究；(2) 建立跨学科的AI+MPS研究社区；(3) 促进MPS研究人员和学生在AI方面的教育和劳动力发展。

Conclusion: 论文总结了资助机构、教育机构和个人研究人员应优先考虑的事项，以帮助MPS社区在AI+MPS领域取得领先地位并充分利用其变革潜力。

Abstract: This community paper developed out of the NSF Workshop on the Future of
Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS),
which was held in March 2025 with the goal of understanding how the MPS domains
(Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics)
can best capitalize on, and contribute to, the future of AI. We present here a
summary and snapshot of the MPS community's perspective, as of Spring/Summer
2025, in a rapidly developing field. The link between AI and MPS is becoming
increasingly inextricable; now is a crucial moment to strengthen the link
between AI and Science by pursuing a strategy that proactively and thoughtfully
leverages the potential of AI for scientific discovery and optimizes
opportunities to impact the development of AI by applying concepts from
fundamental science. To achieve this, we propose activities and strategic
priorities that: (1) enable AI+MPS research in both directions; (2) build up an
interdisciplinary community of AI+MPS researchers; and (3) foster education and
workforce development in AI for MPS researchers and students. We conclude with
a summary of suggested priorities for funding agencies, educational
institutions, and individual researchers to help position the MPS community to
be a leader in, and take full advantage of, the transformative potential of
AI+MPS.

</details>


### [88] [Planning with Reasoning using Vision Language World Model](https://arxiv.org/abs/2509.02722)
*Delong Chen,Theo Moutakanni,Willy Chung,Yejin Bang,Ziwei Ji,Allen Bolourchi,Pascale Fung*

Main category: cs.AI

TL;DR: 本文提出了视觉语言世界模型（VLWM），一个基于自然视频训练的语言世界建模基础模型，通过结合反应式和反思式规划，实现了视觉辅助规划（VPA）的最新技术水平。


<details>
  <summary>Details</summary>
Motivation: 有效规划需要强大的世界模型，但能理解和推理具有语义和时间抽象动作的高级世界模型仍未得到充分发展。

Method: 引入了Vision Language World Model (VLWM)，一个在自然视频上训练的用于语言世界建模的基础模型。VLWM通过迭代LLM Self-Refine（基于Tree of Captions压缩的未来观察）来推断目标成就并预测包含动作和状态变化的轨迹。它学习动作策略（System-1）和动力学模型（System-2），后者通过自监督训练的判别器进行成本最小化，评估假设未来状态与预期目标状态的语义距离。

Result: VLWM在VPA基准评估和PlannerArena人类评估中均取得了最先进的（SOTA）性能，其中System-2规划相比System-1将Elo分数提升了27%。VLWM模型在RoboVQA和WorldPrediction基准测试中也优于强大的VLM基线模型。

Conclusion: VLWM是针对语言世界建模和视觉规划的有效基础模型，通过结合反应式和反思式规划，显著提升了规划性能，并展现了其在理解和推理复杂动作方面的强大能力。

Abstract: Effective planning requires strong world models, but high-level world models
that can understand and reason about actions with semantic and temporal
abstraction remain largely underdeveloped. We introduce the Vision Language
World Model (VLWM), a foundation model trained for language-based world
modeling on natural videos. Given visual observations, the VLWM first infers
the overall goal achievements then predicts a trajectory composed of
interleaved actions and world state changes. Those targets are extracted by
iterative LLM Self-Refine conditioned on compressed future observations
represented by Tree of Captions. The VLWM learns both an action policy and a
dynamics model, which respectively facilitates reactive system-1 plan decoding
and reflective system-2 planning via cost minimization. The cost evaluates the
semantic distance between the hypothetical future states given by VLWM
roll-outs and the expected goal state, and is measured by a critic model that
we trained in a self-supervised manner. The VLWM achieves state-of-the-art
Visual Planning for Assistance (VPA) performance on both benchmark evaluations
and our proposed PlannerArena human evaluations, where system-2 improves the
Elo score by +27% upon system-1. The VLWM models also outperforms strong VLM
baselines on RoboVQA and WorldPrediction benchmark.

</details>


### [89] [Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics](https://arxiv.org/abs/2509.02751)
*Matthew Russo,Tim Kraska*

Main category: cs.AI

TL;DR: 本文提出了一个原型系统，将语义运算符的优化执行与深度研究系统的灵活性相结合，以提升AI驱动分析的性能。该原型允许深度研究代理编写和执行优化的语义运算符程序，并在实验中表现出比现有方法更好的F1分数和显著的成本与运行时间节省。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的分析系统存在不足：语义运算符在处理大规模数据集时执行成本高昂且不适合交互式任务；深度研究系统虽然能回答自然语言问题，但缺乏明确的查询计划优化，导致执行效率低下。因此，需要一个运行时系统，能结合语义运算符的优化执行与深度研究系统的灵活性和动态执行能力。

Method: 作为实现这一愿景的第一步，我们构建了一个原型系统。该原型能够让深度研究代理编写并执行优化的语义运算符程序。

Result: 实验结果表明，该原型系统在两个基本查询上，优于手工编写的语义运算符程序和开放的深度研究系统。与标准的开放深度研究代理相比，原型F1分数最高提升了1.95倍。即使给代理提供语义运算符作为工具，由于其优化执行，原型仍能实现高达76.8%的成本节省和72.7%的运行时间节省。

Conclusion: 该原型成功地展示了结合优化的语义运算符执行与深度研究代理的优势，为AI驱动分析提供了一个更高效、更灵活的运行时解决方案。它代表了实现这一愿景的重要一步，显著提升了分析任务的性能和效率。

Abstract: With advances in large language models (LLMs), researchers are creating new
systems that can perform AI-driven analytics over large unstructured datasets.
Recent work has explored executing such analytics queries using semantic
operators -- a declarative set of AI-powered data transformations with natural
language specifications. However, even when optimized, these operators can be
expensive to execute on millions of records and their iterator execution
semantics make them ill-suited for interactive data analytics tasks. In another
line of work, Deep Research systems have demonstrated an ability to answer
natural language question(s) over large datasets. These systems use one or more
LLM agent(s) to plan their execution, process the dataset(s), and iteratively
refine their answer. However, these systems do not explicitly optimize their
query plans which can lead to poor plan execution. In order for AI-driven
analytics to excel, we need a runtime which combines the optimized execution of
semantic operators with the flexibility and more dynamic execution of Deep
Research systems. As a first step towards this vision, we build a prototype
which enables Deep Research agents to write and execute optimized semantic
operator programs. We evaluate our prototype and demonstrate that it can
outperform a handcrafted semantic operator program and open Deep Research
systems on two basic queries. Compared to a standard open Deep Research agent,
our prototype achieves up to 1.95x better F1-score. Furthermore, even if we
give the agent access to semantic operators as tools, our prototype still
achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its
optimized execution.

</details>


### [90] [Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving](https://arxiv.org/abs/2509.02754)
*Mingyi Wang,Jingke Wang,Tengju Ye,Junbo Chen,Kaicheng Yu*

Main category: cs.AI

TL;DR: 本文系统评估了大型语言模型（LLM）的五个关键模块（分词器、位置嵌入、预训练、后训练、测试时计算）在自动驾驶运动生成中的可迁移性，发现经过适当调整的模块能显著提升性能，并识别出有效迁移的技术。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自然语言处理领域的突破启发了其在自动驾驶运动生成等结构相似领域中的应用。然而，目前缺乏对哪些LLM模块真正可迁移的系统性理解。

Method: 本文全面评估了分词器设计、位置嵌入、预训练范式、后训练策略和测试时计算这五个关键LLM模块。通过在Waymo Sim Agents基准上进行广泛实验来验证。

Result: 研究结果表明，经过适当调整的LLM模块可以显著提高自动驾驶运动生成的性能。我们识别了可有效迁移的技术，分析了其他技术失败的潜在原因，并讨论了自动驾驶场景所需的具体调整。在Sim Agents任务上取得了有竞争力的结果。

Conclusion: 本研究通过对LLM模块在自动驾驶运动生成中的系统评估，证明了适当调整的LLM模块能够显著提升性能，并为该领域LLM技术的有效应用提供了明确的指导和见解。

Abstract: Recent breakthroughs in large language models (LLMs) have not only advanced
natural language processing but also inspired their application in domains with
structurally similar problems--most notably, autonomous driving motion
generation. Both domains involve autoregressive sequence modeling, token-based
representations, and context-aware decision making, making the transfer of LLM
components a natural and increasingly common practice. However, despite
promising early attempts, a systematic understanding of which LLM modules are
truly transferable remains lacking. In this paper, we present a comprehensive
evaluation of five key LLM modules--tokenizer design, positional embedding,
pre-training paradigms, post-training strategies, and test-time
computation--within the context of motion generation for autonomous driving.
Through extensive experiments on the Waymo Sim Agents benchmark, we demonstrate
that, when appropriately adapted, these modules can significantly improve
performance for autonomous driving motion generation. In addition, we identify
which techniques can be effectively transferred, analyze the potential reasons
for the failure of others, and discuss the specific adaptations needed for
autonomous driving scenarios. We evaluate our method on the Sim Agents task and
achieve competitive results.

</details>


### [91] [Plan Verification for LLM-Based Embodied Task Completion Agents](https://arxiv.org/abs/2509.02761)
*Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.AI

TL;DR: 本文提出一个迭代验证框架，通过Judge LLM和Planner LLM协作，有效修正了具身AI中LLM生成的任务规划噪声，显著提高了动作序列的质量和效率，为模仿学习提供了高质量数据。


<details>
  <summary>Details</summary>
Motivation: LLM为具身AI生成的任务规划和人类演示常包含不必要的动作、冗余导航和逻辑错误，这些噪声降低了策略质量。

Method: 提出一个迭代验证框架，其中一个Judge LLM负责批判动作序列，另一个Planner LLM根据批判进行修正。该方法通过自然语言提示实现，而非基于规则，因此能广泛处理多种错误类型，如无关动作、矛盾和遗漏步骤。

Result: 在TEACh具身AI数据集上，该框架对四种SOTA LLM（GPT-o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout）实现了高达90%的召回率和100%的精确率。细化循环快速收敛，96.5%的序列最多只需三次迭代，同时提高了时间效率和空间动作组织。该方法还保留了人类的错误恢复模式。

Conclusion: 该研究确立了规划验证作为LLM在空间规划和动作细化方面的可靠能力，为具身AI的模仿学习提供了一条获取高质量训练数据的可扩展途径。

Abstract: Large language model (LLM) based task plans and corresponding human
demonstrations for embodied AI may be noisy, with unnecessary actions,
redundant navigation, and logical errors that reduce policy quality. We propose
an iterative verification framework in which a Judge LLM critiques action
sequences and a Planner LLM applies the revisions, yielding progressively
cleaner and more spatially coherent trajectories. Unlike rule-based approaches,
our method relies on natural language prompting, enabling broad generalization
across error types including irrelevant actions, contradictions, and missing
steps. On a set of manually annotated actions from the TEACh embodied AI
dataset, our framework achieves up to 90% recall and 100% precision across four
state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout).
The refinement loop converges quickly, with 96.5% of sequences requiring at
most three iterations, while improving both temporal efficiency and spatial
action organization. Crucially, the method preserves human error-recovery
patterns rather than collapsing them, supporting future work on robust
corrective behavior. By establishing plan verification as a reliable LLM
capability for spatial planning and action refinement, we provide a scalable
path to higher-quality training data for imitation learning in embodied AI.

</details>


### [92] [Key Principles in Cross-Domain Hyper-Heuristic Performance](https://arxiv.org/abs/2509.02782)
*Václav Sobotka,Lucas Kletzander,Nysret Musliu,Hana Rudová*

Main category: cs.AI

TL;DR: 本研究通过策略性地转换低级启发式算法（LLHs）集合而非仅仅自适应选择，极大地提升了跨领域选择超启发式算法的性能，使得简单方法也能超越现有先进水平，并找到新的最佳已知解。


<details>
  <summary>Details</summary>
Motivation: 现有选择超启发式算法主要侧重于从预定义集合中自适应选择低级启发式算法。本研究旨在解决这一局限，集中于低级启发式算法集合的构成及其策略性转换，以开发更通用、更有效的搜索策略。

Method: 我们系统性地分析了基于三个关键原则（解接受度、LLH重复次数和扰动强度）的LLH集合转换。首先，在一个简单的无偏随机选择机制上验证了这些转换的原始效果；其次，将这些策略性转换应用于多种现有超启发式算法。

Result: 1. 结合适当转换的简单随机选择方法，在三个挑战性真实世界领域超越了所有现有先进超启发式算法，并找到了11个新的最佳已知解。2. 同一方法与CHeSC竞赛冠军（标准跨领域基准）具有竞争力。3. 将这些策略性转换应用于现有超启发式算法，使其在CHeSC基准和真实世界领域均超越当前先进方法，并通常简化了其设计。

Conclusion: 策略性地转换低级启发式算法集合是提升跨领域选择超启发式算法性能的有效途径，能够使更简单的方法达到或超越现有最先进的水平。

Abstract: Cross-domain selection hyper-heuristics aim to distill decades of research on
problem-specific heuristic search algorithms into adaptable general-purpose
search strategies. In this respect, existing selection hyper-heuristics
primarily focus on an adaptive selection of low-level heuristics (LLHs) from a
predefined set. In contrast, we concentrate on the composition of this set and
its strategic transformations. We systematically analyze transformations based
on three key principles: solution acceptance, LLH repetitions, and perturbation
intensity, i.e., the proportion of a solution affected by a perturbative LLH.
We demonstrate the raw effects of our transformations on a trivial unbiased
random selection mechanism. With an appropriately constructed transformation,
this trivial method outperforms all available state-of-the-art hyper-heuristics
on three challenging real-world domains and finds 11 new best-known solutions.
The same method is competitive with the winner of the CHeSC competition,
commonly used as the standard cross-domain benchmark. Moreover, we accompany
several recent hyper-heuristics with such strategic transformations. Using this
approach, we outperform the current state-of-the-art methods on both the CHeSC
benchmark and real-world domains while often simplifying their designs.

</details>


### [93] [Learning General Policies From Examples](https://arxiv.org/abs/2509.02794)
*Blai Bonet,Hector Geffner*

Main category: cs.AI

TL;DR: 提出一种基于击中集算法的新型符号学习方法，用于大规模规划问题策略学习，解决了现有方法的可扩展性限制。


<details>
  <summary>Details</summary>
Motivation: 现有组合/符号策略学习方法虽然可解释且正确，但可扩展性差，只能处理小规模问题（数百个状态和特征）。

Method: 提出一种新的符号方法，通过泛化采样计划来学习策略，确保结构终止和无环性。该方法不基于SAT/ASP，而是采用击中集算法，可处理百万级状态和数十万级特征。

Result: 该方法的形式性质得到了分析，其可扩展性在多个基准测试中得到验证，展示了处理大规模问题的能力（百万级状态，数十万级特征）。

Conclusion: 该工作提供了一种高度可扩展的符号方法，能够有效学习大规模规划问题的策略，克服了现有方法的规模限制。

Abstract: Combinatorial methods for learning general policies that solve large
collections of planning problems have been recently developed. One of their
strengths, in relation to deep learning approaches, is that the resulting
policies can be understood and shown to be correct. A weakness is that the
methods do not scale up and learn only from small training instances and
feature pools that contain a few hundreds of states and features at most. In
this work, we propose a new symbolic method for learning policies based on the
generalization of sampled plans that ensures structural termination and hence
acyclicity. The proposed learning approach is not based on SAT/ASP, as previous
symbolic methods, but on a hitting set algorithm that can effectively handle
problems with millions of states, and pools with hundreds of thousands of
features. The formal properties of the approach are analyzed, and its
scalability is tested on a number of benchmarks.

</details>


### [94] [Uncertainty-driven Adaptive Exploration](https://arxiv.org/abs/2509.03219)
*Leonidas Bakopoulos,Georgios Chalkiadakis*

Main category: cs.AI

TL;DR: 本文提出一个通用的自适应探索框架，利用不确定性来解决探索与利用的切换时机问题，并在实验中表现出优于标准策略的性能。


<details>
  <summary>Details</summary>
Motivation: 自适应探索方法通过交替探索与利用来学习复杂策略。其核心挑战在于如何确定探索和利用之间切换的恰当时机，这对于需要学习长且复杂动作序列的领域尤为关键。

Method: 本文提出了一个通用的自适应探索框架，该框架利用不确定性以原则性的方式解决探索与利用的切换时机问题。该框架将先前的自适应探索方法包含在内作为特例，并且能够整合任何选定的不确定性度量机制（例如，内在激励或基于认知不确定性的探索方法）。

Result: 实验结果表明，该框架生成的自适应探索策略在多个MuJoCo环境中均优于标准策略。

Conclusion: 所提出的基于不确定性的通用自适应探索框架能够有效且原则性地解决探索与利用的切换时机问题，并在实际应用中展现出卓越的性能。

Abstract: Adaptive exploration methods propose ways to learn complex policies via
alternating between exploration and exploitation. An important question for
such methods is to determine the appropriate moment to switch between
exploration and exploitation and vice versa. This is critical in domains that
require the learning of long and complex sequences of actions. In this work, we
present a generic adaptive exploration framework that employs uncertainty to
address this important issue in a principled manner. Our framework includes
previous adaptive exploration approaches as special cases. Moreover, we can
incorporate in our framework any uncertainty-measuring mechanism of choice, for
instance mechanisms used in intrinsic motivation or epistemic uncertainty-based
exploration methods. We experimentally demonstrate that our framework gives
rise to adaptive exploration strategies that outperform standard ones across
several MuJoCo environments.

</details>


### [95] [Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making](https://arxiv.org/abs/2509.03286)
*Prachi Bagave,Marcus Westberg,Marijn Janssen,Aaron Yi Ding*

Main category: cs.AI

TL;DR: 本文提出了一个针对医疗AI系统的问责框架和三层结构，旨在弥合现有法规中“是什么”与“如何做”之间的鸿沟，并强调协作问责与可解释性的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在医疗决策中的应用日益广泛，问责制成为关键问题。现有监管指南过于宏观，缺乏具体实施方法（“如何做”），且“问责制”一词在不同参与者间存在理解歧义，导致实践中出现知识空白。

Method: 通过对问责概念的深入分析，本文提出了一个问责框架，并设计了一个三层结构来处理各种问责机制。该框架旨在将医疗AI系统的法规与参与者所采取的机制整合到一致的问责制度下，而三层结构则指导参与者根据其行为对机制进行分类。

Result: 研究结果表明，医疗AI决策中存在共享依赖关系，问责制应通过共同处理和促进协作来实现。此外，可解释性在促进行动者之间的沟通和信息共享方面发挥着关键作用，从而推动协作过程。

Conclusion: 本研究通过提出一个问责框架和三层结构，成功弥合了医疗AI问责制理论与实践之间的差距，强调了医疗AI决策中共同问责和协作的重要性，并突出了可解释性在促进这些协作中的核心作用。

Abstract: AI is transforming the healthcare domain and is increasingly helping
practitioners to make health-related decisions. Therefore, accountability
becomes a crucial concern for critical AI-driven decisions. Although regulatory
bodies, such as the EU commission, provide guidelines, they are highlevel and
focus on the ''what'' that should be done and less on the ''how'', creating a
knowledge gap for actors. Through an extensive analysis, we found that the term
accountability is perceived and dealt with in many different ways, depending on
the actor's expertise and domain of work. With increasing concerns about AI
accountability issues and the ambiguity around this term, this paper bridges
the gap between the ''what'' and ''how'' of AI accountability, specifically for
AI systems in healthcare. We do this by analysing the concept of
accountability, formulating an accountability framework, and providing a
three-tier structure for handling various accountability mechanisms. Our
accountability framework positions the regulations of healthcare AI systems and
the mechanisms adopted by the actors under a consistent accountability regime.
Moreover, the three-tier structure guides the actors of the healthcare AI
system to categorise the mechanisms based on their conduct. Through our
framework, we advocate that decision-making in healthcare AI holds shared
dependencies, where accountability should be dealt with jointly and should
foster collaborations. We highlight the role of explainability in instigating
communication and information sharing between the actors to further facilitate
the collaborative process.

</details>


### [96] [app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding](https://arxiv.org/abs/2509.03310)
*Evgenii Kniazev,Arseny Kravchenko,Igor Rekun,James Broadhead,Nikita Shamgunov,Pranav Sah,Pratik Nichite,Ivan Yamshchikov*

Main category: cs.AI

TL;DR: app.build是一个开源框架，通过系统验证和结构化环境改进LLM应用生成。


<details>
  <summary>Details</summary>
Motivation: 提高LLM应用生成的可靠性，并为生产级AI代理系统提供有效的扩展方案。

Method: 采用多层验证管道、堆栈特有编排和模型无关架构，并在三个参考堆栈上实现该方法。

Result: 综合验证使73.3%的应用可行，其中30%达到完美质量；在结构化环境下，开源模型达到闭源模型性能的80.8%；该框架已被社区采纳，已生成超过3000个应用。

Conclusion: 扩展可靠AI代理需要扩展环境而非仅仅模型，为生产级代理系统提供了经验洞察和完整参考实现。

Abstract: We present app.build (https://github.com/appdotbuild/agent/), an open-source
framework that improves LLM-based application generation through systematic
validation and structured environments. Our approach combines multi-layered
validation pipelines, stack-specific orchestration, and model-agnostic
architecture, implemented across three reference stacks. Through evaluation on
30 generation tasks, we demonstrate that comprehensive validation achieves
73.3% viability rate with 30% reaching perfect quality scores, while
open-weights models achieve 80.8% of closed-model performance when provided
structured environments. The open-source framework has been adopted by the
community, with over 3,000 applications generated to date. This work
demonstrates that scaling reliable AI agents requires scaling environments, not
just models -- providing empirical insights and complete reference
implementations for production-oriented agent systems.

</details>


### [97] [Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](https://arxiv.org/abs/2509.03345)
*Yunxin Sun,Abulhair Saparov*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型（LLMs）的归纳和溯因推理能力，发现它们在简单场景下表现尚可，但在复杂世界模型和生成高质量假设方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: LLMs在演绎推理方面取得了显著进展，但对解决实际问题至关重要的归纳和溯因推理却鲜有探索。

Method: 1. 引入了可编程的合成数据集InAbHyD，其中每个推理示例包括不完整的世界模型和一组观察结果，任务是生成假设来解释观察结果。2. 提出了一种基于奥卡姆剃刀的新度量标准来评估假设的质量。3. 评估并分析了最先进的LLMs，并测试了情境学习和RLVR等推理增强技术的效果。

Result: LLMs在简单场景中能够执行归纳和溯因推理，但在面对复杂世界模型以及生成高质量假设时表现挣扎，即使结合了情境学习和RLVR等流行推理增强技术也未能显著改善。

Conclusion: LLMs在归纳和溯因推理方面仍有提升空间，尤其是在处理复杂情境和生成高质量解释性假设的能力方面。

Abstract: Reasoning is a core capability in artificial intelligence systems, for which
large language models (LLMs) have recently shown remarkable progress. However,
most work focuses exclusively on deductive reasoning, which is problematic
since other types of reasoning are also essential in solving real-world
problems, and they are less explored. This work focuses on evaluating LLMs'
inductive and abductive reasoning capabilities. We introduce a programmable and
synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example
consists of an incomplete world model and a set of observations. The task for
the intelligent agent is to produce hypotheses to explain observations under
the incomplete world model to solve each reasoning example. We propose a new
metric to evaluate the quality of hypotheses based on Occam's Razor. We
evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs
can perform inductive and abductive reasoning in simple scenarios, but struggle
with complex world models and producing high-quality hypotheses, even with
popular reasoning-enhancing techniques such as in-context learning and RLVR.

</details>


### [98] [Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems](https://arxiv.org/abs/2509.03380)
*Peter J. Bentley,Soo Ling Lim,Fuyuki Ishikawa*

Main category: cs.AI

TL;DR: 本研究提出一种自底向上的AI智能体框架，引入“方面”概念，使智能体根据环境变化触发行为并差异化感知环境，从而实现零信息泄露，显著提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM AI智能体常表现为自主聊天机器人，遵循脚本且受不可靠的“导演”控制，导致其在环境交互和信息处理上存在不足，可能面临信息泄露和效率低下问题。

Method: 本工作提出一个自底向上的框架，将AI智能体置于其环境中，所有行为均由环境变化触发。引入了“方面”（aspects）的概念，类似于“umwelt”（环境知觉），使不同的智能体集合能够以不同的方式感知环境，从而实现更清晰的信息控制。

Result: 通过一个说明性的实现，研究表明与典型架构（高达83%的信息泄露）相比，基于“方面”的智能体AI能够实现零信息泄露。

Conclusion: 该研究认为，这种在各自信息利基中高效工作的专业智能体概念，能够显著提升系统的安全性和效率。

Abstract: Agentic LLM AI agents are often little more than autonomous chatbots: actors
following scripts, often controlled by an unreliable director. This work
introduces a bottom-up framework that situates AI agents in their environment,
with all behaviors triggered by changes in their environments. It introduces
the notion of aspects, similar to the idea of umwelt, where sets of agents
perceive their environment differently to each other, enabling clearer control
of information. We provide an illustrative implementation and show that
compared to a typical architecture, which leaks up to 83% of the time,
aspective agentic AI enables zero information leakage. We anticipate that this
concept of specialist agents working efficiently in their own information
niches can provide improvements to both security and efficiency.

</details>


### [99] [ANNIE: Be Careful of Your Robots](https://arxiv.org/abs/2509.03383)
*Yiyang Huang,Zixuan Wang,Zishen Wan,Yapeng Tian,Haobo Xu,Yinhe Han,Yiming Gan*

Main category: cs.AI

TL;DR: 本研究首次系统性地探究了具身AI系统中VLA模型的对抗性安全攻击，定义了安全违规类型，提出了评估基准和攻击框架，并证明攻击成功率超过50%，强调了具身AI安全防御的紧迫性。


<details>
  <summary>Details</summary>
Motivation: VLA模型整合到具身AI机器人中，虽提升了复杂任务能力，但引入了严重的安全风险：受损的VLA模型可将对抗性扰动直接转化为不安全的物理动作。传统机器学习安全定义不足，具身AI系统对安全定义、测量和攻防机制提出了新问题。

Method: 1. 基于ISO标准和物理约束（如分离距离、速度、碰撞边界）形式化了安全违规的分类法（临界、危险、高风险）。2. 引入ANNIEBench，一个包含九个安全关键场景和2,400个视频-动作序列的具身安全评估基准。3. 提出了ANNIE-Attack，一个任务感知的对抗性框架，其攻击领导模型能将长周期目标分解为帧级扰动。

Result: 对代表性具身AI模型的评估显示，所有安全类别的攻击成功率均超过50%。研究还展示了稀疏和自适应的攻击策略，并通过物理机器人实验验证了其真实世界影响。

Conclusion: 这些结果揭示了具身AI系统中一个先前未被充分探索但后果严重的攻击面，突显了物理AI时代对安全驱动防御的迫切需求。

Abstract: The integration of vision-language-action (VLA) models into embodied AI (EAI)
robots is rapidly advancing their ability to perform complex, long-horizon
tasks in humancentric environments. However, EAI systems introduce critical
security risks: a compromised VLA model can directly translate adversarial
perturbations on sensory input into unsafe physical actions. Traditional safety
definitions and methodologies from the machine learning community are no longer
sufficient. EAI systems raise new questions, such as what constitutes safety,
how to measure it, and how to design effective attack and defense mechanisms in
physically grounded, interactive settings. In this work, we present the first
systematic study of adversarial safety attacks on embodied AI systems, grounded
in ISO standards for human-robot interactions. We (1) formalize a principled
taxonomy of safety violations (critical, dangerous, risky) based on physical
constraints such as separation distance, velocity, and collision boundaries;
(2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with
2,400 video-action sequences for evaluating embodied safety; and (3)
ANNIE-Attack, a task-aware adversarial framework with an attack leader model
that decomposes long-horizon goals into frame-level perturbations. Our
evaluation across representative EAI models shows attack success rates
exceeding 50% across all safety categories. We further demonstrate sparse and
adaptive attack strategies and validate the real-world impact through physical
robot experiments. These results expose a previously underexplored but highly
consequential attack surface in embodied AI systems, highlighting the urgent
need for security-driven defenses in the physical AI era. Code is available at
https://github.com/RLCLab/Annie.

</details>


### [100] [sam-llm: interpretable lane change trajectoryprediction via parametric finetuning](https://arxiv.org/abs/2509.03462)
*Zhuo Cao,Yunxiao Shi,Min Xu*

Main category: cs.AI

TL;DR: SAM-LLM是一种混合架构，结合大型语言模型（LLM）与运动学变道模型，实现自动驾驶中可解释、高效的变道轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LLM的上下文推理能力与物理模型的精确性之间存在鸿沟。本研究旨在通过输出核心物理参数而非原始坐标，实现可解释的、物理精确且计算高效的变道轨迹预测。

Method: 该系统通过微调LLM，使其输出增强型正弦加速度模型（SAM）的核心物理参数（如横向位移、机动持续时间、初始横向速度、纵向速度变化），而非直接预测坐标。对于车道保持场景，模型预测离散坐标。

Result: SAM-LLM在整体意图预测准确率上达到98.73%，与传统LLM预测器性能相当，同时输出大小减少80%。它生成完整、连续、物理合理且本质上可解释的轨迹模型，显著提高了可解释性和资源效率。

Conclusion: SAM-LLM成功结合了LLM的推理能力和物理模型的精确性，提供了一种高性能、可解释且资源高效的自动驾驶轨迹预测新范式。

Abstract: This work introduces SAM-LLM, a novel hybrid architecture that bridges the
gap between the contextual reasoning of Large Language Models (LLMs) and the
physical precision of kinematic lane change models for autonomous driving. The
system is designed for interpretable lane change trajectory prediction by
finetuning an LLM to output the core physical parameters of a trajectory model
instead of raw coordinates. For lane-keeping scenarios, the model predicts
discrete coordinates, but for lane change maneuvers, it generates the
parameters for an enhanced Sinusoidal Acceleration Model (SAM), including
lateral displacement, maneuver duration, initial lateral velocity, and
longitudinal velocity change. This parametric approach yields a complete,
continuous, and physically plausible trajectory model that is inherently
interpretable and computationally efficient, achieving an 80% reduction in
output size compared to coordinate-based methods. The SAM-LLM achieves a
state-of-the-art overall intention prediction accuracy of 98.73%, demonstrating
performance equivalent to traditional LLM predictors while offering significant
advantages in explainability and resource efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [101] [The Lifecycle Principle: Stabilizing Dynamic Neural Networks with State Memory](https://arxiv.org/abs/2509.02575)
*Zichuan Yang*

Main category: cs.LG

TL;DR: 提出Lifecycle (LC) 原理，一种通过状态记忆机制在长期失活神经元重新激活时恢复其参数的正则化方法，以解决训练不稳定性，提升模型的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索一种比Dropout更强的正则化形式（长期停用神经元）。然而，长期停用后随机初始化神经元会导致严重的训练不稳定问题。

Method: 提出Lifecycle (LC) 原理，其核心创新是“状态记忆”。该方法在神经元重新激活时，不是随机初始化，而是将其参数恢复到上次已知的有效状态，以保留已学知识并避免优化冲击。

Result: 1. 理论分析表明LC原理能平滑损失函数，引导优化器找到更平坦、泛化能力更好的最小值。2. 在图像分类基准测试中，该方法显著提高了模型的泛化能力和鲁棒性。3. 消融实验证实状态记忆对实现这些增益至关重要。

Conclusion: Lifecycle (LC) 原理及其状态记忆机制，通过保留已学知识并平滑损失函数，有效解决了长期神经元失活带来的训练不稳定性问题，显著提升了模型的泛化能力和鲁棒性。

Abstract: I investigate a stronger form of regularization by deactivating neurons for
extended periods, a departure from the temporary changes of methods like
Dropout. However, this long-term dynamism introduces a critical challenge:
severe training instability when neurons are revived with random weights. To
solve this, I propose the Lifecycle (LC) principle, a regularization mechanism
centered on a key innovation: state memory. Instead of re-initializing a
revived neuron, my method restores its parameters to their last known effective
state. This process preserves learned knowledge and avoids destructive
optimization shocks. My theoretical analysis reveals that the LC principle
smooths the loss landscape, guiding optimization towards flatter minima
associated with better generalization. Experiments on image classification
benchmarks demonstrate that my method improves generalization and robustness.
Crucially, ablation studies confirm that state memory is essential for
achieving these gains.

</details>


### [102] [Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection](https://arxiv.org/abs/2509.02579)
*Mazyar Taghavi,Rahman Farnoosh*

Main category: cs.LG

TL;DR: 本文提出了一种基于期望最大化（EM）和多智能体强化学习（MARL）的新型EM-MARL框架，用于协调无人机（UAV）以打击野生动物盗猎，并在仿真中表现出卓越的检测精度和适应性。


<details>
  <summary>Details</summary>
Motivation: 保护濒危野生动物免受非法盗猎是一项严峻挑战，尤其是在广阔、部分可观测且需要实时响应的环境中。

Method: 引入了一种新颖的基于期望最大化（EM）的潜在变量建模方法，应用于多智能体强化学习（MARL）中的无人机协调。通过潜在变量建模隐藏的环境因素和智能体间的动态，以增强不确定性下的探索和协调能力。该方法被实现为EM-MARL框架。

Result: 在涉及10架无人机巡逻伊朗豹保护区的定制仿真中，EM-MARL框架在检测精度、适应性和策略收敛方面表现出优于PPO和DDPG等标准算法的性能。

Conclusion: EM推理与MARL的结合能够有效提升复杂、高风险保护场景中的去中心化决策能力。

Abstract: Protecting endangered wildlife from illegal poaching presents a critical
challenge, particularly in vast and partially observable environments where
real-time response is essential. This paper introduces a novel
Expectation-Maximization (EM) based latent variable modeling approach in the
context of Multi-Agent Reinforcement Learning (MARL) for Unmanned Aerial
Vehicle (UAV) coordination in wildlife protection. By modeling hidden
environmental factors and inter-agent dynamics through latent variables, our
method enhances exploration and coordination under uncertainty.We implement and
evaluate our EM-MARL framework using a custom simulation involving 10 UAVs
tasked with patrolling protected habitats of the endangered Iranian leopard.
Extensive experimental results demonstrate superior performance in detection
accuracy, adaptability, and policy convergence when compared to standard
algorithms such as Proximal Policy Optimization (PPO) and Deep Deterministic
Policy Gradient (DDPG). Our findings underscore the potential of combining EM
inference with MARL to improve decentralized decisionmaking in complex,
high-stakes conservation scenarios. The full implementation, simulation
environment, and training scripts are publicly available on GitHub.

</details>


### [103] [Beyond Synthetic Augmentation: Group-Aware Threshold Calibration for Robust Balanced Accuracy in Imbalanced Learning](https://arxiv.org/abs/2509.02592)
*Hunter Gittlin*

Main category: cs.LG

TL;DR: 本文提出群体感知阈值校准，通过为不同群体设置不同决策阈值，在解决类别不平衡问题上表现优于合成数据生成方法，能显著提升平衡准确度和最差群体平衡准确度，且更简洁有效。


<details>
  <summary>Details</summary>
Motivation: 机器学习中类别不平衡是一个核心挑战，传统解决方案往往未能有效解决问题甚至带来新的困扰。

Method: 研究采用群体感知阈值校准方法，即为不同人口群体设置不同的决策阈值。该方法旨在优化平衡准确度和最差群体平衡准确度之间的帕累托前沿。通过广泛实验，在七种模型家族（包括线性、基于树、基于实例和提升方法）上进行评估，并与SMOTE和CT-GAN等合成数据生成方法进行对比。

Result: 群体特定阈值比SMOTE和CT-GAN增强模型实现了1.5-4%更高的平衡准确度，并改善了最差群体的平衡准确度。该方法能对群体层面性能进行精细控制。此外，将群体阈值应用于合成增强数据只会带来极小的额外收益，表明这两种方法存在根本冗余。

Conclusion: 群体感知阈值校准是一种更简单、更具可解释性且更有效的类别不平衡解决方案，其在鲁棒性、平衡准确度和最差群体平衡准确度方面均优于合成数据生成方法。

Abstract: Class imbalance remains a fundamental challenge in machine learning, with
traditional solutions often creating as many problems as they solve. We
demonstrate that group-aware threshold calibration--setting different decision
thresholds for different demographic groups--provides superior robustness
compared to synthetic data generation methods. Through extensive experiments,
we show that group-specific thresholds achieve 1.5-4% higher balanced accuracy
than SMOTE and CT-GAN augmented models while improving worst-group balanced
accuracy. Unlike single-threshold approaches that apply one cutoff across all
groups, our group-aware method optimizes the Pareto frontier between balanced
accuracy and worst-group balanced accuracy, enabling fine-grained control over
group-level performance. Critically, we find that applying group thresholds to
synthetically augmented data yields minimal additional benefit, suggesting
these approaches are fundamentally redundant. Our results span seven model
families including linear, tree-based, instance-based, and boosting methods,
confirming that group-aware threshold calibration offers a simpler, more
interpretable, and more effective solution to class imbalance.

</details>


### [104] [Preference Robustness for DPO with Applications to Public Health](https://arxiv.org/abs/2509.02709)
*Cheol Woo Kim,Shresth Verma,Mauricio Tec,Milind Tambe*

Main category: cs.LG

TL;DR: 提出DPO-PRO，一种基于DPO的鲁棒LLM微调算法，用于通过人类偏好设计公共卫生领域序列资源分配的奖励函数。该方法通过轻量级DRO处理不确定性，提高了对噪声偏好信号的鲁棒性，并显著降低了推理时间成本。


<details>
  <summary>Details</summary>
Motivation: 研究LLM微调任务，旨在根据自然语言表达的人类偏好，为公共卫生领域的序列资源分配问题设计奖励函数。该任务面临复杂模糊的目标和有限的数据可用性，对模型对齐构成严峻挑战。

Method: 提出DPO-PRO算法，这是一种基于直接偏好优化（DPO）的鲁棒微调算法。它采用轻量级的分布鲁棒优化（DRO）公式来处理偏好分布中的不确定性。与现有的基于DRO的DPO方法相比，DPO-PRO的保守性显著降低。该方法在真实的ARMMAN母婴移动健康项目和标准对齐基准上进行了评估。

Result: 实验结果表明，DPO-PRO相较于现有DPO变体，能持续提高对噪声偏好信号的鲁棒性。此外，DPO-PRO在奖励函数设计方面达到了与先前基于自我反思的基线相当的性能，同时显著降低了推理时间成本。

Conclusion: DPO-PRO是一种有效且高效的LLM微调算法，能够在公共卫生等复杂且数据有限的场景中，通过人类偏好设计鲁棒的奖励函数。它不仅提升了对噪声偏好信号的处理能力，还显著降低了计算成本，为实际应用提供了有前景的解决方案。

Abstract: We study an LLM fine-tuning task for designing reward functions for
sequential resource allocation problems in public health, guided by human
preferences expressed in natural language. This setting presents a challenging
testbed for alignment due to complex and ambiguous objectives and limited data
availability. We propose DPO-PRO, a robust fine-tuning algorithm based on
Direct Preference Optimization (DPO), which accounts for uncertainty in the
preference distribution using a lightweight Distributionally Robust
Optimization (DRO) formulation. Unlike prior DRO-based DPO methods, DPO-PRO is
significantly less conservative. We evaluate DPO-PRO on a real-world maternal
mobile health program operated by the non-profit organization ARMMAN, as well
as on standard alignment benchmarks. Experimental results demonstrate that our
method consistently improves robustness to noisy preference signals compared to
existing DPO variants. Moreover, DPO-PRO achieves comparable performance to
prior self-reflection-based baseline for reward function design, while
requiring significantly lower inference-time cost.

</details>


### [105] [Imitate Optimal Policy: Prevail and Induce Action Collapse in Policy Gradient](https://arxiv.org/abs/2509.02737)
*Zhongzhu Zhou,Yibo Yang,Ziyan Chen,Fengxiang Bie,Haojun Xia,Xiaoxia Wu,Robert Wu,Ben Athiwaratkun,Bernard Ghanem,Shuaiwen Leon Song*

Main category: cs.LG

TL;DR: 策略梯度（PG）方法在训练最优策略深度神经网络（DNNs）时，会观察到一种称为“动作坍塌（AC）”的结构，即状态-动作激活和动作选择层权重收敛至等角紧框架（ETF）。本文提出动作坍塌策略梯度（ACPG）方法，通过固定ETF作为动作选择层来引导策略学习，实验证明能更快、更鲁棒地提高奖励。


<details>
  <summary>Details</summary>
Motivation: 现有研究鲜有分析策略网络底层的表征结构。作者在训练最优策略DNN时发现，在特定约束下，会涌现出一种类似“神经坍塌”的“动作坍塌（AC）”结构，表现为同最优动作的激活特征向其均值坍塌，变异性趋近于零，且动作选择层权重与均值坍塌为ETF。鉴于这种ETF结构能最大化动作间的区分度，作者因此提出疑问：能否通过在动作选择层使用固定的ETF结构作为目标配置来学习最优策略？

Method: 作者首先通过分析证明，在动作选择层使用固定的ETF作为目标来学习激活特征，自然会导致AC现象。基于此，提出了动作坍塌策略梯度（ACPG）方法。ACPG的核心是将一个合成的ETF结构固定作为其动作选择层，从而诱导策略DNN在保持最优性的同时，在动作选择层产生这种理想的坍塌配置。

Result: 在各种OpenAI Gym环境中的实验表明，ACPG技术可以无缝集成到任何离散的策略梯度（PG）方法中。实验结果进一步证明，ACPG能够更快、更鲁棒地实现显著的奖励改进。

Conclusion: 动作坍塌（AC）现象揭示了最优策略深度神经网络内部的潜在结构。ACPG方法通过主动利用并固定ETF结构作为动作选择层，为策略梯度方法提供了一种高效且稳健的改进方案，显著加速并稳定了策略学习过程。

Abstract: Policy gradient (PG) methods in reinforcement learning frequently utilize
deep neural networks (DNNs) to learn a shared backbone of feature
representations used to compute likelihoods in an action selection layer.
Numerous studies have been conducted on the convergence and global optima of
policy networks, but few have analyzed representational structures of those
underlying networks. While training an optimal policy DNN, we observed that
under certain constraints, a gentle structure resembling neural collapse, which
we refer to as Action Collapse (AC), emerges. This suggests that 1) the
state-action activations (i.e. last-layer features) sharing the same optimal
actions collapse towards those optimal actions respective mean activations; 2)
the variability of activations sharing the same optimal actions converges to
zero; 3) the weights of action selection layer and the mean activations
collapse to a simplex equiangular tight frame (ETF). Our early work showed
those aforementioned constraints to be necessary for these observations. Since
the collapsed ETF of optimal policy DNNs maximally separates the pair-wise
angles of all actions in the state-action space, we naturally raise a question:
can we learn an optimal policy using an ETF structure as a (fixed) target
configuration in the action selection layer? Our analytical proof shows that
learning activations with a fixed ETF as action selection layer naturally leads
to the AC. We thus propose the Action Collapse Policy Gradient (ACPG) method,
which accordingly affixes a synthetic ETF as our action selection layer. ACPG
induces the policy DNN to produce such an ideal configuration in the action
selection layer while remaining optimal. Our experiments across various OpenAI
Gym environments demonstrate that our technique can be integrated into any
discrete PG methods and lead to favorable reward improvements more quickly and
robustly.

</details>


### [106] [Mentality: A Mamba-based Approach towards Foundation Models for EEG](https://arxiv.org/abs/2509.02746)
*Saarang Panchavati,Corey Arnold,William Speier*

Main category: cs.LG

TL;DR: 本文探索了基于Mamba的基石模型在增强EEG分析以诊断神经系统疾病方面的潜力，并在癫痫检测任务中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 脑电图（EEG）在神经系统疾病诊断中至关重要，但其噪声大、高维、非线性等复杂性使得传统机器学习方法难以有效捕捉其时空动态。深度学习在序列建模方面的进展为解决此挑战提供了新方向。

Method: 采用基于Mamba的选择性状态空间模型，通过自监督重建任务在包含癫痫和非癫痫EEG记录的大型数据集上进行预训练，随后进行癫痫检测任务。

Result: 模型在癫痫检测任务中表现出有效性，在独立测试集上获得了0.72的AUROC（受试者工作特征曲线下面积）。

Conclusion: 这种方法是开发用于EEG数据分析的大规模、临床适用基石模型的重要一步。

Abstract: This work explores the potential of foundation models, specifically a
Mamba-based selective state space model, for enhancing EEG analysis in
neurological disorder diagnosis. EEG, crucial for diagnosing conditions like
epilepsy, presents significant challenges due to its noisy, high-dimensional,
and nonlinear nature. Traditional machine learning methods have made advances
in automating EEG analysis but often fail to capture its complex
spatio-temporal dynamics. Recent advances in deep learning, particularly in
sequence modeling, offer new avenues for creating more generalized and
expressive models capable of handling such complexities. By training a
Mamba-based model on a large dataset containing seizure and non-seizure EEG
recordings through a self-supervised reconstruction task followed by a seizure
detection task, we demonstrate the model's effectiveness, achieving an AUROC of
0.72 on a held-out test set. This approach marks a significant step toward
developing large-scale, clinically applicable foundation models for EEG data
analysis.

</details>


### [107] [LExI: Layer-Adaptive Active Experts for Efficient MoE Model Inference](https://arxiv.org/abs/2509.02753)
*Krishna Teja Chitty-Venkata,Sandeep Madireddy,Murali Emani,Venkatram Vishwanath*

Main category: cs.LG

TL;DR: 本文提出LExI，一种无数据优化技术，通过自适应地确定MoE模型每层的活跃专家数量，显著提升推理效率并保持准确性，优于传统剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 现有MoE剪枝技术主要减少内存占用，但对推理计算效率提升有限。此外，当前MoE架构在所有层统一激活固定数量的专家，导致计算冗余和性能不佳。

Method: 提出LExI，一种无数据优化技术，用于确定预训练MoE模型每层的最佳活跃专家数量。LExI仅利用模型权重来估计每层的相对重要性，并据此自适应地分配每层活跃专家的数量。

Result: 实验表明，LExI在推理效率方面显著优于传统MoE剪枝方法，且准确性损失可忽略不计。例如，Qwen1.5-MoE使用LExI在Nvidia H100 GPU上实现了与传统专家剪枝相同的吞吐量，但准确率高出10%。

Conclusion: LExI通过自适应地调整MoE模型每层的活跃专家数量，有效解决了现有优化技术在推理效率上的局限性，提供了一种更高效且准确的MoE模型优化方案。

Abstract: Mixture-of-Experts (MoE) models scale efficiently by activating only a subset
of experts per token, offering a computationally sparse alternative to dense
architectures. While prior post-training optimizations, such as inter- and
intra-expert pruning, reduce memory usage they provide limited gains in
inference-time compute efficiency. Moreover, existing MoE architectures
typically activate a fixed number of experts uniformly across all layers,
resulting in redundant computation and suboptimal performance. In this work, we
first demonstrate that MoE pruning strategies improve only the memory footprint
but do not significantly improve inference performance on GPU using optimized
frameworks such as vLLM. To address this, we introduce LExI, a data-free
optimization technique that determines the optimal number of active experts per
layer in a pretrained MoE model. LExI leverages only the model weights to
estimate the relative importance of each layer and adaptively assigns the
number of active experts accordingly per layer. Experiments on state-of-the-art
language and vision MoE benchmarks demonstrate that LExI significantly
outperforms traditional MoE pruning approaches in terms of inference efficiency
with negligible accuracy loss. For example, using LExI, Qwen1.5-MoE achieves
the same throughput on Nvidia H100 GPU with 10% better accuracy than
traditional expert pruning.

</details>


### [108] [The Transparent Earth: A Multimodal Foundation Model for the Earth's Subsurface](https://arxiv.org/abs/2509.02783)
*Arnab Mazumder,Javier E. Santos,Noah Hobbs,Mohamed Mehana,Daniel O'Malley*

Main category: cs.LG

TL;DR: Transparent Earth是一个基于Transformer的架构，能从稀疏、异构的多模态数据重建地下属性，支持任意模态输入，并通过上下文学习大幅提高预测精度，旨在成为地球地下领域的通用基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效整合稀疏、分辨率和模态各异的异构地下数据集，且缺乏处理新观测模态的灵活性。因此，研究旨在开发一个能够统一处理并灵活扩展多模态地下数据的新架构。

Method: 提出Transparent Earth，一个基于Transformer的架构。该模型结合了观测的位置编码和通过文本嵌入模型生成的模态编码，使其能处理并扩展到任意数量的模态（目前涵盖八种，如方向角、类别、连续属性）。模型支持上下文学习，可在无输入或任意附加观测下进行预测。

Result: 在验证数据上，模型将应力角预测误差降低了三倍以上。该架构具有良好的可扩展性，并且性能随参数增加而提升。

Conclusion: Transparent Earth通过创新方法有效整合异构多模态地下数据，显著提升了预测精度和模型灵活性。这使其成为地球地下领域的初步基础模型，未来有望实现对地球任何地下属性的全面预测。

Abstract: We present the Transparent Earth, a transformer-based architecture for
reconstructing subsurface properties from heterogeneous datasets that vary in
sparsity, resolution, and modality, where each modality represents a distinct
type of observation (e.g., stress angle, mantle temperature, tectonic plate
type). The model incorporates positional encodings of observations together
with modality encodings, derived from a text embedding model applied to a
description of each modality. This design enables the model to scale to an
arbitrary number of modalities, making it straightforward to add new ones not
considered in the initial design. We currently include eight modalities
spanning directional angles, categorical classes, and continuous properties
such as temperature and thickness. These capabilities support in-context
learning, enabling the model to generate predictions either with no inputs or
with an arbitrary number of additional observations from any subset of
modalities. On validation data, this reduces errors in predicting stress angle
by more than a factor of three. The proposed architecture is scalable and
demonstrates improved performance with increased parameters. Together, these
advances make the Transparent Earth an initial foundation model for the Earth's
subsurface that ultimately aims to predict any subsurface property anywhere on
Earth.

</details>


### [109] [Structured Basis Function Networks: Loss-Centric Multi-Hypothesis Ensembles with Controllable Diversity](https://arxiv.org/abs/2509.02792)
*Alejandro Rodriguez Dominguez,Muhammad Shahzad,Xia Hong*

Main category: cs.LG

TL;DR: 提出结构化基函数网络（SBFN），通过Bregman散度连接多假设预测与集成学习，并引入可调多样性机制，以统一和原则性的方式处理预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有预测不确定性方法（多假设预测与集成学习）存在聚合不足或无法捕捉结构化歧义的问题，缺乏一个与损失几何一致的统一框架。

Method: 提出SBFN，通过Bregman散度诱导的中心聚合将多假设预测与集成学习结合；将预测与损失几何对齐，适用于回归和分类；支持闭式最小二乘和梯度优化；提供可调多样性机制以控制偏差-方差-多样性权衡。

Result: SBFN将多假设泛化与损失感知集成聚合有效关联；实验验证了其机制，并用于研究深度学习预测器在不同数据集上的复杂性-容量-多样性权衡。

Conclusion: SBFN提供了一个统一且原则性的框架，通过结合多假设预测与集成学习并引入可调多样性，有效解决了预测不确定性问题，弥补了现有方法的不足。

Abstract: Existing approaches to predictive uncertainty rely either on multi-hypothesis
prediction, which promotes diversity but lacks principled aggregation, or on
ensemble learning, which improves accuracy but rarely captures the structured
ambiguity. This implicitly means that a unified framework consistent with the
loss geometry remains absent. The Structured Basis Function Network addresses
this gap by linking multi-hypothesis prediction and ensembling through
centroidal aggregation induced by Bregman divergences. The formulation applies
across regression and classification by aligning predictions with the geometry
of the loss, and supports both a closed-form least-squares estimator and a
gradient-based procedure for general objectives. A tunable diversity mechanism
provides parametric control of the bias-variance-diversity trade-off,
connecting multi-hypothesis generalisation with loss-aware ensemble
aggregation. Experiments validate this relation and use the mechanism to study
the complexity-capacity-diversity trade-off across datasets of increasing
difficulty with deep-learning predictors.

</details>


### [110] [Learning Laplacian Eigenvectors: a Pre-training Method for Graph Neural Networks](https://arxiv.org/abs/2509.02803)
*Howard Dai,Nyambura Njenga,Benjamin Whitsett,Catherine Ma,Darwin Deng,Sara de Ángel,Alexandre Van Tassel,Siddharth Viswanath,Ryan Pellico,Ian Adelstein,Smita Krishnaswamy*

Main category: cs.LG

TL;DR: 提出一种基于学习拉普拉斯特征向量的GNN预训练框架，有效捕获全局图结构，在多种图任务上超越基线模型，且具有高灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递神经网络（MPNNs）随着网络深度增加，存在过平滑风险，难以捕获全局和区域图结构。现有预训练方法多专注于领域特定任务，缺乏结构通用性。

Method: 提出一种新颖的自监督GNN预训练框架，通过归纳学习图拉普拉斯矩阵的低频特征向量。该方法利用低频特征向量编码全局信息的特性，促使网络自然学习大规模结构模式。

Result: 经验证明，通过该框架预训练的模型在多种基于图结构的任务上均优于基线模型。

Conclusion: 该框架成功使GNNs捕获全局结构信息，解决了传统MPNN的局限性。其结构化和高灵活性使其广泛适用于各类图数据集，甚至在数据稀疏时也能结合合成特征使用，提供了一个通用的图结构预训练方法。

Abstract: We propose a novel framework for pre-training Graph Neural Networks (GNNs) by
inductively learning Laplacian eigenvectors. Traditional Message Passing Neural
Networks (MPNNs) often struggle to capture global and regional graph structure
due to over-smoothing risk as network depth increases. Because the
low-frequency eigenvectors of the graph Laplacian matrix encode global
information, pre-training GNNs to predict these eigenvectors encourages the
network to naturally learn large-scale structural patterns over each graph.
Empirically, we show that models pre-trained via our framework outperform
baseline models on a variety of graph structure-based tasks. While most
existing pre-training methods focus on domain-specific tasks like node or edge
feature reconstruction, our self-supervised pre-training framework is
structure-based and highly flexible. Eigenvector-learning can be applied to all
graph-based datasets, and can be used with synthetic features when
task-specific data is sparse.

</details>


### [111] [Challenges in Understanding Modality Conflict in Vision-Language Models](https://arxiv.org/abs/2509.02805)
*Trang Nguyen,Jackson Michaels,Madalina Fiterau,David Jensen*

Main category: cs.LG

TL;DR: 本文研究了视觉-语言模型（VLMs）中冲突检测与解决的解耦问题，通过对LLaVA-OV-7B的机制性调查，发现冲突信号在中间层可线性解码，且检测与解决的注意力模式在不同网络阶段分歧，支持两者为功能独立机制的假设，从而提升模型可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言模型（VLMs）中将冲突检测从冲突解决机制中解耦的挑战。

Method: 对最先进的VLM模型LLaVA-OV-7B进行了机制性调查，该模型在处理冲突多模态输入时表现出多样的解决行为。研究方法包括使用线性探针（linear probes）的监督度量方法和基于分组的注意力模式分析。

Result: 研究结果显示，一个线性可解码的冲突信号出现在模型的中间层；与冲突检测和解决相关的注意力模式在网络的P不同阶段表现出分歧。这些发现支持了检测和解决是功能上不同机制的假设。

Conclusion: 冲突检测和冲突解决是功能上不同的机制。这种解耦有助于提高模型的可解释性，并能实现更有针对性的干预，从而增强模型在复杂多模态环境中的鲁棒性。

Abstract: This paper highlights the challenge of decomposing conflict detection from
conflict resolution in Vision-Language Models (VLMs) and presents potential
approaches, including using a supervised metric via linear probes and
group-based attention pattern analysis. We conduct a mechanistic investigation
of LLaVA-OV-7B, a state-of-the-art VLM that exhibits diverse resolution
behaviors when faced with conflicting multimodal inputs. Our results show that
a linearly decodable conflict signal emerges in the model's intermediate layers
and that attention patterns associated with conflict detection and resolution
diverge at different stages of the network. These findings support the
hypothesis that detection and resolution are functionally distinct mechanisms.
We discuss how such decomposition enables more actionable interpretability and
targeted interventions for improving model robustness in challenging multimodal
settings.

</details>


### [112] [Unlearning That Lasts: Utility-Preserving, Robust, and Almost Irreversible Forgetting in LLMs](https://arxiv.org/abs/2509.02820)
*Naman Deep Singh,Maximilian Müller,Francesco Croce,Matthias Hein*

Main category: cs.LG

TL;DR: 本文提出JensUn方法，利用Jensen-Shannon散度实现LLM的稳定有效遗忘，并引入LKF数据集及改进评估框架（LLM语义判断、最坏情况评估）以更精确地评估遗忘效果，揭示现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: LLM的遗忘学习对于删除预训练阶段的私有数据或有害知识、确保模型安全性至关重要。然而，现有遗忘方法在严格评估下表现不佳。

Method: 本文提出JensUn方法，采用Jensen-Shannon散度作为遗忘集和保留集的训练目标，以实现更稳定有效的遗忘动态。同时，引入LKF数据集提供真实的遗忘场景。此外，还提出了改进的评估框架：(i) 使用LLM作为语义评判者取代ROUGE分数，(ii) 在各种释义和输入格式下进行最坏情况的遗忘评估。

Result: JensUn在遗忘-效用权衡方面优于现有方法，并对良性再学习表现出强大的韧性。通过改进的评估框架，发现许多现有遗忘方法的效果不如先前所认为的那么有效。

Conclusion: JensUn提供了一种更有效、更稳定的LLM遗忘方法。同时，所提出的新数据集和评估框架能够更精确、全面地衡量遗忘效果，并揭示了现有方法的局限性。

Abstract: Unlearning in large language models (LLMs) involves precisely removing
specific information from a pre-trained model. This is crucial to ensure safety
of LLMs by deleting private data or harmful knowledge acquired during
pre-training. However, existing unlearning methods often fall short when
subjected to thorough evaluation. To overcome this, we introduce JensUn, where
we leverage the Jensen-Shannon Divergence as the training objective for both
forget and retain sets for more stable and effective unlearning dynamics
compared to commonly used loss functions. In extensive experiments, JensUn
achieves better forget-utility trade-off than competing methods, and even
demonstrates strong resilience to benign relearning. Additionally, for a
precise unlearning evaluation, we introduce LKF, a curated dataset of
lesser-known facts that provides a realistic unlearning scenario. Finally, to
comprehensively test unlearning methods, we propose (i) employing an LLM as
semantic judge instead of the standard ROUGE score, and (ii) using worst-case
unlearning evaluation over various paraphrases and input formats. Our improved
evaluation framework reveals that many existing methods are less effective than
previously thought.

</details>


### [113] [Ensemble Learning for Healthcare: A Comparative Analysis of Hybrid Voting and Ensemble Stacking in Obesity Risk Prediction](https://arxiv.org/abs/2509.02826)
*Towhidul Islam,Md Sumon Ali*

Main category: cs.LG

TL;DR: 本研究比较了混合多数投票法和集成堆叠法在肥胖风险预测中的性能，发现集成堆叠法在复杂数据分布下预测能力更强，而混合多数投票法仍是稳健的选择。


<details>
  <summary>Details</summary>
Motivation: 肥胖是全球性健康问题，机器学习有望用于早期预测。然而，对混合多数投票和集成堆叠等集成技术在肥胖风险预测中的比较评估仍有限，本研究旨在填补这一空白，并为医疗保健应用中更好的预测模型选择提供指导。

Method: 利用两个数据集，评估了多数硬投票、加权硬投票和集成堆叠（以多层感知器为元分类器）三种集成模型。从9种ML算法中筛选出表现最佳的3种作为基学习器。预处理包括数据集平衡和异常值检测。模型性能通过准确率（Accuracy）和F1分数进行评估。

Result: 在数据集1上，加权硬投票和堆叠表现相似（准确率：0.920304，F1：0.920070），优于多数硬投票。在数据集2上，堆叠表现最佳（准确率：0.989837，F1：0.989825），显著优于多数硬投票（准确率：0.981707，F1：0.981675）和加权硬投票。

Conclusion: 研究结果证实，集成堆叠法提供了更强的预测能力，尤其适用于复杂数据分布，而混合多数投票法仍然是一个稳健的替代方案。

Abstract: Obesity is a critical global health issue driven by dietary, physiological,
and environmental factors, and is strongly associated with chronic diseases
such as diabetes, cardiovascular disorders, and cancer. Machine learning has
emerged as a promising approach for early obesity risk prediction, yet a
comparative evaluation of ensemble techniques -- particularly hybrid majority
voting and ensemble stacking -- remains limited. This study aims to compare
hybrid majority voting and ensemble stacking methods for obesity risk
prediction, identifying which approach delivers higher accuracy and efficiency.
The analysis seeks to highlight the complementary strengths of these ensemble
techniques in guiding better predictive model selection for healthcare
applications. Two datasets were utilized to evaluate three ensemble models:
Majority Hard Voting, Weighted Hard Voting, and Stacking (with a Multi-Layer
Perceptron as meta-classifier). A pool of nine Machine Learning (ML)
algorithms, evaluated across a total of 50 hyperparameter configurations, was
analyzed to identify the top three models to serve as base learners for the
ensemble methods. Preprocessing steps involved dataset balancing, and outlier
detection, and model performance was evaluated using Accuracy and F1-Score. On
Dataset-1, weighted hard voting and stacking achieved nearly identical
performance (Accuracy: 0.920304, F1: 0.920070), outperforming majority hard
voting. On Dataset-2, stacking demonstrated superior results (Accuracy:
0.989837, F1: 0.989825) compared to majority hard voting (Accuracy: 0.981707,
F1: 0.981675) and weighted hard voting, which showed the lowest performance.
The findings confirm that ensemble stacking provides stronger predictive
capability, particularly for complex data distributions, while hybrid majority
voting remains a robust alternative.

</details>


### [114] [Conformal Prediction for Time-series Forecasting with Change Points](https://arxiv.org/abs/2509.02844)
*Sophia Sun,Rose Yu*

Main category: cs.LG

TL;DR: 本文提出CPTC算法，通过结合状态预测模型和在线共形预测，有效处理含变点时间序列的不确定性量化问题。


<details>
  <summary>Details</summary>
Motivation: 现有共形预测方法难以处理具有变点（底层数据生成过程突变）的时间序列数据，导致不确定性量化不准确。

Method: 提出一种名为CPTC（Conformal Prediction for Time-series with Change points）的新算法，它将预测底层状态的模型与在线共形预测相结合，以模拟非平稳时间序列中的不确定性。

Result: CPTC算法在最小假设下被证明在时间序列设置中具有有效性和改进的适应性。在6个合成和真实世界数据集上的实验表明，CPTC在有效性和适应性方面优于最先进的基线方法。

Conclusion: CPTC为处理含变点时间序列的不确定性量化提供了一个有效且适应性更强的解决方案。

Abstract: Conformal prediction has been explored as a general and efficient way to
provide uncertainty quantification for time series. However, current methods
struggle to handle time series data with change points - sudden shifts in the
underlying data-generating process. In this paper, we propose a novel Conformal
Prediction for Time-series with Change points (CPTC) algorithm, addressing this
gap by integrating a model to predict the underlying state with online
conformal prediction to model uncertainties in non-stationary time series. We
prove CPTC's validity and improved adaptivity in the time series setting under
minimum assumptions, and demonstrate CPTC's practical effectiveness on 6
synthetic and real-world datasets, showing improved validity and adaptivity
compared to state-of-the-art baselines.

</details>


### [115] [Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm](https://arxiv.org/abs/2509.02846)
*Siddharth Mansingh,James Amarel,Ragib Arnab,Arvind Mohan,Kamaljeet Singh,Gerd J. Kunde,Nicolas Hengartner,Benjamin Migliori,Emily Casleton,Nathan A. Debarledeben,Ayan Biswas,Diane Oyen,Earl Lawrence*

Main category: cs.LG

TL;DR: 本文提出一种受LLMs启发、用于偏微分方程(PDEs)的测试时计算(TTC)策略，通过在推理时利用计算资源，提高预测准确性，同时减少训练数据和模型大小。


<details>
  <summary>Details</summary>
Motivation: 现有的PDE基础模型受限于预训练数据集，在自回归rollout性能（尤其在OOD情况下）以及计算和训练数据需求方面存在显著挑战。

Method: 引入首个PDE测试时计算(TTC)策略，该策略借鉴了大型语言模型(LLMs)中的“思考”策略。通过使用两种奖励模型来评估基于随机模型的预测，以确保时空一致性，从而在推理时利用计算资源实现更准确的预测。

Result: 在PDEGym基准的欧拉方程（Euler-equation）模拟上进行验证，结果显示TTC策略相较于标准的非自适应自回归推理，能够捕捉到更佳的预测结果。

Conclusion: TTC框架是迈向更高级PDE推理算法（包括基于强化学习的方法）的奠基性一步，有望变革物理和工程领域的计算工作流程。

Abstract: Partial Differential Equations (PDEs) are the bedrock for modern
computational sciences and engineering, and inherently computationally
expensive. While PDE foundation models have shown much promise for simulating
such complex spatio-temporal phenomena, existing models remain constrained by
the pretraining datasets and struggle with auto-regressive rollout performance,
especially in out-of-distribution (OOD) cases. Furthermore, they have
significant compute and training data requirements which hamper their use in
many critical applications. Inspired by recent advances in ``thinking"
strategies used in large language models (LLMs), we introduce the first
test-time computing (TTC) strategy for PDEs that utilizes computational
resources during inference to achieve more accurate predictions with fewer
training samples and smaller models. We accomplish this with two types of
reward models that evaluate predictions of a stochastic based model for
spatio-temporal consistency. We demonstrate this method on compressible
Euler-equation simulations from the PDEGym benchmark and show that TTC captures
improved predictions relative to standard non-adaptive auto-regressive
inference. This TTC framework marks a foundational step towards more advanced
reasoning algorithms or PDE modeling, inluding building
reinforcement-learning-based approaches, potentially transforming computational
workflows in physics and engineering.

</details>


### [116] [Power Grid Control with Graph-Based Distributed Reinforcement Learning](https://arxiv.org/abs/2509.02861)
*Carlo Fabrizio,Gianvito Losapio,Marco Mussi,Alberto Maria Metelli,Marcello Restelli*

Main category: cs.LG

TL;DR: 本文提出一种基于图的分布式强化学习框架，用于实现现代电网的实时、可扩展管理。


<details>
  <summary>Details</summary>
Motivation: 可再生能源整合和电网规模扩张给电网控制带来挑战，传统系统难以适应和扩展，因此需要更动态、分布式的控制策略。

Method: 采用基于图的分布式强化学习框架，包含作用于独立电线的低级智能体和协调它们的高级管理智能体。使用图神经网络（GNN）将网络拓扑信息编码到低级智能体的局部观测中，并整合模仿学习和基于潜力的奖励塑形以加速收敛。该方法独特之处在于同时分解了动作空间和观测空间。

Result: 在Grid2Op仿真环境下，该方法有效且持续优于常用基线，并比基于仿真的专家方法计算效率更高。

Conclusion: 所提出的分布式强化学习框架能有效应对现代电网控制挑战，提供了一种可扩展、高效且性能优越的解决方案。

Abstract: The necessary integration of renewable energy sources, combined with the
expanding scale of power networks, presents significant challenges in
controlling modern power grids. Traditional control systems, which are human
and optimization-based, struggle to adapt and to scale in such an evolving
context, motivating the exploration of more dynamic and distributed control
strategies. This work advances a graph-based distributed reinforcement learning
framework for real-time, scalable grid management. The proposed architecture
consists of a network of distributed low-level agents acting on individual
power lines and coordinated by a high-level manager agent. A Graph Neural
Network (GNN) is employed to encode the network's topological information
within the single low-level agent's observation. To accelerate convergence and
enhance learning stability, the framework integrates imitation learning and
potential-based reward shaping. In contrast to conventional decentralized
approaches that decompose only the action space while relying on global
observations, this method also decomposes the observation space. Each low-level
agent acts based on a structured and informative local view of the environment
constructed through the GNN. Experiments on the Grid2Op simulation environment
show the effectiveness of the approach, which consistently outperforms the
standard baseline commonly adopted in the field. Additionally, the proposed
model proves to be much more computationally efficient than the
simulation-based Expert method.

</details>


### [117] [Enhancing Machine Learning for Imbalanced Medical Data: A Quantum-Inspired Approach to Synthetic Oversampling (QI-SMOTE)](https://arxiv.org/abs/2509.02863)
*Vikas Kashtriya,Pardeep Singh*

Main category: cs.LG

TL;DR: 引入量子启发式SMOTE (QI-SMOTE) 数据增强技术，有效解决医学领域机器学习中的类别不平衡问题，显著提升了模型性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的类别不平衡问题，尤其在医疗领域，导致模型偏差和预测性能下降，亟需一种有效的数据增强方法。

Method: 提出QI-SMOTE，一种利用量子演化和分层纠缠等量子原理的新型数据增强技术，用于生成保留复杂数据结构的合成实例。该方法在MIMIC-III和MIMIC-IV数据集的死亡率检测任务上进行验证，并与多种传统过采样技术（如Borderline-SMOTE, ADASYN）进行比较，评估指标包括准确率、F1分数、G-Mean和AUC-ROC。

Result: QI-SMOTE通过生成更具信息量和平衡的训练数据，显著提高了集成方法（RF, GB, ADA）、基于核的模型（SVM）以及深度学习方法的有效性。

Conclusion: QI-SMOTE不仅能有效缓解类别不平衡，还能增强医疗诊断和决策中预测模型的鲁棒性和可靠性，展示了量子启发式重采样技术在推进ML方法论方面的巨大潜力。

Abstract: Class imbalance remains a critical challenge in machine learning (ML),
particularly in the medical domain, where underrepresented minority classes
lead to biased models and reduced predictive performance. This study introduces
Quantum-Inspired SMOTE (QI-SMOTE), a novel data augmentation technique that
enhances the performance of ML classifiers, including Random Forest (RF),
Support Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors
(KNN), Gradient Boosting (GB), and Neural Networks, by leveraging quantum
principles such as quantum evolution and layered entanglement. Unlike
conventional oversampling methods, QI-SMOTE generates synthetic instances that
preserve complex data structures, improving model generalization and
classification accuracy. We validate QI-SMOTE on the MIMIC-III and MIMIC-IV
datasets, using mortality detection as a benchmark task due to their clinical
significance and inherent class imbalance. We compare our method against
traditional oversampling techniques, including Borderline-SMOTE, ADASYN,
SMOTE-ENN, SMOTE-TOMEK, and SVM-SMOTE, using key performance metrics such as
Accuracy, F1-score, G-Mean, and AUC-ROC. The results demonstrate that QI-SMOTE
significantly improves the effectiveness of ensemble methods (RF, GB, ADA),
kernel-based models (SVM), and deep learning approaches by producing more
informative and balanced training data. By integrating quantum-inspired
transformations into the ML pipeline, QI-SMOTE not only mitigates class
imbalance but also enhances the robustness and reliability of predictive models
in medical diagnostics and decision-making. This study highlights the potential
of quantum-inspired resampling techniques in advancing state-of-the-art ML
methodologies.

</details>


### [118] [Improving Generative Methods for Causal Evaluation via Simulation-Based Inference](https://arxiv.org/abs/2509.02892)
*Pracheta Amaranath,Vinitra Muralikrishnan,Amit Sharma,David D. Jensen*

Main category: cs.LG

TL;DR: 现有用于因果评估的合成数据生成方法在处理参数不确定性方面存在局限。SBICE框架通过推断生成参数的后验分布，生成更真实的合成数据集，从而提高因果估计器评估的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估因果估计器需要准确的合成数据集，但现有生成方法要求用户提供固定点估计的参数值（而非分布），这使得用户无法表达参数的不确定性，并排除了后验推断的可能性，可能导致不可靠的估计器比较。

Method: 引入了用于因果评估的基于模拟的推断（SBICE）框架。该框架将生成参数建模为不确定变量，并根据源数据集推断其后验分布。SBICE利用基于模拟的推断技术，识别能生成与源数据分布高度一致的合成数据集的参数配置。

Result: 实验结果表明，SBICE通过生成更逼真的数据集，提高了估计器评估的可靠性。

Conclusion: SBICE为在不确定性下进行因果基准测试提供了一种稳健且与数据一致的方法。

Abstract: Generating synthetic datasets that accurately reflect real-world
observational data is critical for evaluating causal estimators, but remains a
challenging task. Existing generative methods offer a solution by producing
synthetic datasets anchored in the observed data (source data) while allowing
variation in key parameters such as the treatment effect and amount of
confounding bias. However, existing methods typically require users to provide
point estimates of such parameters (rather than distributions) and fixed
estimates (rather than estimates that can be improved with reference to the
source data). This denies users the ability to express uncertainty over
parameter values and removes the potential for posterior inference, potentially
leading to unreliable estimator comparisons. We introduce simulation-based
inference for causal evaluation (SBICE), a framework that models generative
parameters as uncertain and infers their posterior distribution given a source
dataset. Leveraging techniques in simulation-based inference, SBICE identifies
parameter configurations that produce synthetic datasets closely aligned with
the source data distribution. Empirical results demonstrate that SBICE improves
the reliability of estimator evaluations by generating more realistic datasets,
which supports a robust and data-consistent approach to causal benchmarking
under uncertainty.

</details>


### [119] [Event Detection and Classification for Long Range Sensing of Elephants Using Seismic Signal](https://arxiv.org/abs/2509.02920)
*Jaliya L. Wijayaraja,Janaka L. Wijekoon,Malitha Wijesundara*

Main category: cs.LG

TL;DR: 本研究提出一个针对资源受限环境的大象地震信号实时分类框架，包括创新的CCW事件检测和基于SVM的分类器，在不同环境下均实现高精度，并识别出零交叉次数和DTW对齐成本等关键特征，以解决人象冲突问题。


<details>
  <summary>Details</summary>
Motivation: 现有通过地震信号检测大象的方案高度依赖人工分类，限制了其在自然环境中实时应用的潜力。研究旨在解决这一局限，构建一个在资源受限条件下，兼顾准确性和计算效率的实时分类解决方案。

Method: 本研究提出了一个针对资源受限实施的分类框架。框架中引入了一种专门用于检测大象足迹的新型事件检测技术——情境定制窗口化（Contextually Customized Windowing, CCW），并与短时平均/长时平均（STA/LTA）方法进行了比较。大象足迹分类使用支持向量机（Support Vector Machine, SVM）结合径向基函数（RBF）核。此外，还利用可解释AI进行了特征影响分析。

Result: 最大有效检测范围在受控条件下为155.6米，自然环境下为140米。使用SVM分类器在大象足迹分类方面表现出色：在受控环境下准确率达到99%，在自然大象栖息地为73%，在最困难的易发人象冲突的人类栖息地为70%。特征影响分析显示，零交叉次数和动态时间规整（DTW）对齐成本是所有实验中最具影响力的因素，而主要频率在受控环境中也表现出显著影响。

Conclusion: 本研究提出的框架成功解决了大象地震信号实时分类的挑战，在多种环境下均展示了有效的检测范围和高分类准确性。通过识别关键影响特征，为未来开发实用的人象冲突解决方案提供了坚实的基础。

Abstract: Detecting elephants through seismic signals is an emerging research topic
aimed at developing solutions for Human-Elephant Conflict (HEC). Despite the
promising results, such solutions heavily rely on manual classification of
elephant footfalls, which limits their applicability for real-time
classification in natural settings. To address this limitation and build on our
previous work, this study introduces a classification framework targeting
resource-constrained implementations, prioritizing both accuracy and
computational efficiency. As part of this framework, a novel event detection
technique named Contextually Customized Windowing (CCW), tailored specifically
for detecting elephant footfalls, was introduced, and evaluations were
conducted by comparing it with the Short-Term Average/Long-Term Average
(STA/LTA) method. The yielded results show that the maximum validated detection
range was 155.6 m in controlled conditions and 140 m in natural environments.
Elephant footfall classification using Support Vector Machine (SVM) with a
Radial Basis Function (RBF) kernel demonstrated superior performance across
multiple settings, achieving an accuracy of 99% in controlled environments, 73%
in natural elephant habitats, and 70% in HEC-prone human habitats, the most
challenging scenario. Furthermore, feature impact analysis using explainable AI
identified the number of Zero Crossings and Dynamic Time Warping (DTW)
Alignment Cost as the most influential factors in all experiments, while
Predominant Frequency exhibited significant influence in controlled settings.

</details>


### [120] [A Narrative Review of Clinical Decision Support Systems in Offloading Footwear for Diabetes-Related Foot Ulcers](https://arxiv.org/abs/2509.02923)
*Kunal Kumar,Muhammad Ashad Kabir,Luke Donnan,Sayed Ahmed*

Main category: cs.LG

TL;DR: 本文综述了糖尿病足溃疡（DFU）减压鞋具处方决策的现有方法，指出现有方法碎片化问题，并提出了一个包含混合架构、可解释性ML和持续验证的五部分临床决策支持系统（CDSS）框架。


<details>
  <summary>Details</summary>
Motivation: 减压鞋具在预防和治疗糖尿病足溃疡中至关重要，但当前的处方决策存在特征选择差异大、个性化受限以及评估实践不一致等碎片化问题，亟需整合并优化。

Method: 对截至2025年8月发布的45项研究（包括12项指南/协议、25个基于知识的系统和8个机器学习应用）进行了叙述性综述。通过主题分析，探讨了知识类型、决策逻辑、评估方法和支持技术。

Result: 指南侧重于足底压力阈值但缺乏可操作性输出；基于知识的系统整合了规则和传感器驱动逻辑；机器学习模型具有高计算精度但可解释性和临床验证有限。评估实践碎片化，侧重于生物力学、可用性或技术准确性，与长期结果关联较弱。基于此，提出一个五部分CDSS框架：(1)最小可行数据集；(2)结合规则、优化和可解释ML的混合架构；(3)结构化特征级输出；(4)持续验证和评估；(5)与临床和远程医疗工作流集成。

Conclusion: 该框架旨在实现可扩展、以患者为中心的DFU护理CDSS。互操作数据集、可解释模型和以结果为导向的评估将是其临床应用的关键。

Abstract: Offloading footwear helps prevent and treat diabetic foot ulcers (DFUs) by
lowering plantar pressure (PP), yet prescription decisions remain fragmented:
feature selection varies, personalization is limited, and evaluation practices
differ. We performed a narrative review of 45 studies (12 guidelines/protocols,
25 knowledge-based systems, 8 machine-learning applications) published to Aug
2025. We thematically analyzed knowledge type, decision logic, evaluation
methods, and enabling technologies. Guidelines emphasize PP thresholds (<=200
kPa or >=25--30\% reduction) but rarely yield actionable, feature-level
outputs. Knowledge-based systems use rule- and sensor-driven logic, integrating
PP monitoring, adherence tracking, and usability testing. ML work introduces
predictive, optimization, and generative models with high computational
accuracy but limited explainability and clinical validation. Evaluation remains
fragmented: protocols prioritize biomechanical tests; knowledge-based systems
assess usability/adherence; ML studies focus on technical accuracy with weak
linkage to long-term outcomes. From this synthesis we propose a five-part CDSS
framework: (1) a minimum viable dataset; (2) a hybrid architecture combining
rules, optimization, and explainable ML; (3) structured feature-level outputs;
(4) continuous validation and evaluation; and (5) integration with clinical and
telehealth workflows. This framework aims to enable scalable, patient-centered
CDSSs for DFU care; prioritizing interoperable datasets, explainable models,
and outcome-focused evaluation will be key to clinical adoption.

</details>


### [121] [PDRL: Post-hoc Descriptor-based Residual Learning for Uncertainty-Aware Machine Learning Potentials](https://arxiv.org/abs/2509.02927)
*Shih-Peng Huang,Nontawat Charoenphakdee,Yuta Tsuboi,Yong-Bin Zhuang,Wenwen Li*

Main category: cs.LG

TL;DR: 本文提出了一种简单高效的后处理不确定性量化（UQ）框架PDRL，通过利用训练好的图神经网络势的描述符来估计残差误差，解决机器学习原子间势（MLIPs）中UQ方法的计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 集成方法是MLIPs不确定性量化的黄金标准，但计算成本高昂。其他替代技术虽然提高了计算效率，但可能无法应用于已训练模型或影响预测精度。因此，需要一个简单、高效且不影响预测准确性的后处理UQ框架。

Method: 本研究提出了一种名为PDRL（post-hoc descriptor-based residual-based learning）的后处理UQ框架。该方法利用已训练图神经网络势的描述符来估计残差误差，通过建模MLIP预测与真实值之间的差异，将这些残差作为预测不确定性的代理。研究探索了PDRL的多种变体，并将其与已建立的UQ方法进行了基准测试。

Result: 该研究探索了PDRL的多种变体，并对其与已建立的UQ方法进行了基准测试，评估了它们的有效性和局限性。（抽象中未明确给出具体的性能比较结果）

Conclusion: PDRL是一个简单、高效的后处理不确定性量化框架，通过利用MLIP的描述符来估计残差误差，为解决MLIPs中UQ方法的高计算成本和现有方法局限性提供了一个新的解决方案。

Abstract: Ensemble method is considered the gold standard for uncertainty
quantification (UQ) for machine learning interatomic potentials (MLIPs).
However, their high computational cost can limit its practicality. Alternative
techniques, such as Monte Carlo dropout and deep kernel learning, have been
proposed to improve computational efficiency; however, some of these methods
cannot be applied to already trained models and may affect the prediction
accuracy. In this paper, we propose a simple and efficient post-hoc framework
for UQ that leverages the descriptor of a trained graph neural network
potential to estimate residual errors. We refer to this method as post-hoc
descriptor-based residual-based learning (PDRL). PDRL models the discrepancy
between MLIP predictions and ground truth values, allowing these residuals to
act as proxies for prediction uncertainty. We explore multiple variants of PDRL
and benchmark them against established UQ methods, evaluating both their
effectiveness and limitations.

</details>


### [122] [VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills](https://arxiv.org/abs/2509.02930)
*Erik M. Lintunen*

Main category: cs.LG

TL;DR: 本文提出Vendi Score（一种源自生态学的多样性度量）来灵活评估自监督强化学习中的技能多样性，并引入VendiRL框架，通过定义不同的相似性函数，学习各种形式的技能多样性，以解决现有方法的可扩展性和评估难题。


<details>
  <summary>Details</summary>
Motivation: 自监督强化学习中，学习多样化技能面临两大挑战：一是可扩展性，高维特征空间会模糊相关特征；二是技能多样性评估，现有方法对“多样性”定义过于固定，导致结果难以比较且忽略了多种多样性形式。

Method: 引入并采纳Vendi Score，一种源自生态学的样本多样性度量方法，允许用户指定和评估任何形式的所需多样性。在此基础上，提出VendiRL，一个统一的框架，通过给定不同的相似性函数来激发和学习多种多样的技能集。

Result: Vendi Score度量有效地促进了技能评估。VendiRL框架能够学习具有不同多样性形式的技能集，支持在新型和交互丰富的环境中进行技能多样性预训练。

Conclusion: VendiRL结合Vendi Score提供了一个统一且灵活的框架，用于学习多样化技能，解决了自监督强化学习中技能多样性学习和评估的难题，尤其适用于需要优化多种多样性形式的复杂交互环境。

Abstract: In self-supervised reinforcement learning (RL), one of the key challenges is
learning a diverse set of skills to prepare agents for unknown future tasks.
Despite impressive advances, scalability and evaluation remain prevalent
issues. Regarding scalability, the search for meaningful skills can be obscured
by high-dimensional feature spaces, where relevant features may vary across
downstream task domains. For evaluating skill diversity, defining what
constitutes "diversity" typically requires a hard commitment to a specific
notion of what it means for skills to be diverse, potentially leading to
inconsistencies in how skill diversity is understood, making results across
different approaches hard to compare, and leaving many forms of diversity
unexplored. To address these issues, we adopt a measure of sample diversity
that translates ideas from ecology to machine learning -- the Vendi Score --
allowing the user to specify and evaluate any desired form of diversity. We
demonstrate how this metric facilitates skill evaluation and introduce VendiRL,
a unified framework for learning diversely diverse sets of skills. Given
distinct similarity functions, VendiRL motivates distinct forms of diversity,
which could support skill-diversity pretraining in new and richly interactive
environments where optimising for various forms of diversity may be desirable.

</details>


### [123] [AR-KAN: Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network for Time Series Forecasting](https://arxiv.org/abs/2509.02967)
*Chen Zeng,Tiehang Xu,Qiao Wang*

Main category: cs.LG

TL;DR: 我们提出了一种混合模型AR-KAN，结合了Kolmogorov-Arnold网络（KAN）和预训练的自回归（AR）组件，旨在克服传统神经网络在处理复杂、近似周期性信号时的挑战，并在72%的真实世界数据集中取得了优越的预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络在信号频谱分析中面临挑战，尤其是在预测由非公度频率组成的近似周期函数时，性能常不如ARIMA等传统模型，甚至包括大型语言模型。傅里叶神经网络也未能完全解决周期信号叠加不一定产生周期信号的问题。

Method: 我们提出了Autoregressive-Weight-Enhanced AR-KAN这一混合模型。它利用Kolmogorov-Arnold网络（KAN）处理静态非线性部分，并通过预训练的自回归（AR）组件来引入记忆，以保留最有用信息并消除冗余。

Result: 实验数据显示，AR-KAN在72%的真实世界数据集中提供了卓越的结果。

Conclusion: AR-KAN模型通过结合KAN的非线性映射能力和AR组件的记忆保留优势，有效解决了传统神经网络在复杂信号预测中的不足，并在实际应用中展现出显著的性能提升。

Abstract: Conventional neural networks frequently face challenges in spectral analysis
of signals. To address this challenge, Fourier neural networks (FNNs) and
similar approaches integrate components of Fourier series into the structure of
neural networks. Nonetheless, a significant hurdle is often overlooked: the
superposition of periodic signals does not necessarily result in a periodic
signal. For example, when forecasting almost periodic functions composed of
signals with incommensurate frequencies, traditional models such as
Autoregressive Integrated Moving Average (ARIMA) frequently outperform most
neural networks including large language models (LLMs). To tackle this goal, we
propose Autoregressive-Weight-Enhanced AR-KAN, a hybrid model that combines the
benefits of both methods. Using the Universal Myopic Mapping Theorem, we apply
a Kolmogorov-Arnold Network (KAN) for the static nonlinear part and include
memory through a pre-trained AR component, which can be explained to retain the
most useful information while eliminating redundancy. Experimental data
indicates that AR-KAN delivers superior results on $72\%$ of real-world
datasets.

</details>


### [124] [Delayed Momentum Aggregation: Communication-efficient Byzantine-robust Federated Learning with Partial Participation](https://arxiv.org/abs/2509.02970)
*Kaoru Otsuka,Yuki Takezawa,Makoto Yamada*

Main category: cs.LG

TL;DR: 本文提出D-Byz-SGDM优化器，通过延迟动量聚合解决了联邦学习在部分客户端参与下，面临拜占庭攻击时的鲁棒性问题，并提供了理论收敛性保证和实验验证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习易受拜占庭客户端恶意行为影响。现有拜占庭鲁棒联邦学习方法通常假设所有客户端都参与训练，但这在现实中因通信限制和客户端可用性而不可行。在部分客户端参与的情况下，如果抽样客户端中包含拜占庭多数，现有方法会立即失效，这对稀疏通信构成了根本性挑战。

Method: 引入“延迟动量聚合”的新原则，即服务器在聚合活跃客户端的新鲜动量的同时，也聚合非参与客户端最近接收到的梯度。基于此原则，开发了D-Byz-SGDM（Delayed Byzantine-robust SGD with Momentum）优化器，以实现部分参与下的拜占庭鲁棒联邦学习。

Result: 理论上建立了收敛性保证，这些保证不仅恢复了之前完全参与设置下的结果，而且匹配了为部分参与设置证明的基本下限。在深度学习任务上的实验也验证了这些理论发现，展示了在各种拜占庭攻击下稳定和鲁棒的训练效果。

Conclusion: 本研究通过提出延迟动量聚合原则及相应的D-Byz-SGDM优化器，成功解决了联邦学习在部分客户端参与场景下，抵御拜占庭攻击的鲁棒性挑战，提供了强有力的理论证明和实际应用中的稳定性及有效性。

Abstract: Federated Learning (FL) allows distributed model training across multiple
clients while preserving data privacy, but it remains vulnerable to Byzantine
clients that exhibit malicious behavior. While existing Byzantine-robust FL
methods provide strong convergence guarantees (e.g., to a stationary point in
expectation) under Byzantine attacks, they typically assume full client
participation, which is unrealistic due to communication constraints and client
availability. Under partial participation, existing methods fail immediately
after the sampled clients contain a Byzantine majority, creating a fundamental
challenge for sparse communication. First, we introduce delayed momentum
aggregation, a novel principle where the server aggregates the most recently
received gradients from non-participating clients alongside fresh momentum from
active clients. Our optimizer D-Byz-SGDM (Delayed Byzantine-robust SGD with
Momentum) implements this delayed momentum aggregation principle for
Byzantine-robust FL with partial participation. Then, we establish convergence
guarantees that recover previous full participation results and match the
fundamental lower bounds we prove for the partial participation setting.
Experiments on deep learning tasks validated our theoretical findings, showing
stable and robust training under various Byzantine attacks.

</details>


### [125] [AdaGrad Meets Muon: Adaptive Stepsizes for Orthogonal Updates](https://arxiv.org/abs/2509.02981)
*Minxin Zhang,Yuxuan Liu,Hayden Schaeffer*

Main category: cs.LG

TL;DR: 本文提出AdaGO算法，结合Muon优化器的正交更新方向和AdaGrad的自适应步长机制，解决了Muon学习率难以确定的问题。AdaGO在理论上实现了最优收敛速度，并在实践中超越Muon和Adam。


<details>
  <summary>Details</summary>
Motivation: Muon优化器虽在大型语言模型训练中表现出色，但其正交更新的学习率确定方法尚不明确。而AdaGrad是一种成功的自适应学习率方法。研究动机在于结合两者的优势，开发一种既能保持正交更新特性又能自适应调整学习率的新算法。

Method: 本文提出AdaGO算法，它将基于范数的AdaGrad型步长与正交更新方向相结合。该算法通过累积过去的梯度范数来调整步长，同时保持更新方向的正交性。AdaGO的实现仅需对Muon进行最小改动，增加一个额外的标量变量（累积平方梯度范数），具有计算和内存效率。

Result: 1. 理论上，在标准平滑度和无偏有界方差噪声假设下，AdaGO在随机和确定性设置的非凸函数上均能达到最优的理论收敛速度。2. 经验上，在CIFAR-10分类和函数回归任务中，AdaGO的性能优于Muon和Adam。

Conclusion: AdaGO算法成功地将正交更新与自适应步长相结合，有效解决了Muon在学习率确定上的挑战。它在理论上实现了最优收敛性，并在实际应用中展现出卓越的性能和效率，为优化器设计提供了强大的新工具。

Abstract: The recently proposed Muon optimizer updates weight matrices via
orthogonalized momentum and has demonstrated strong empirical success in large
language model training. However, it remains unclear how to determine the
learning rates for such orthogonalized updates. AdaGrad, by contrast, is a
widely used adaptive method that scales stochastic gradients by accumulated
past gradients. We propose a new algorithm, AdaGO, which combines a norm-based
AdaGrad-type stepsize with an orthogonalized update direction, bringing
together the benefits of both approaches. Unlike other adaptive variants of
Muon, AdaGO preserves the orthogonality of the update direction, which can be
interpreted as a spectral descent direction, while adapting the stepsizes to
the optimization landscape by scaling the direction with accumulated past
gradient norms. The implementation of AdaGO requires only minimal modification
to Muon, with a single additional scalar variable, the accumulated squared
gradient norms, to be computed, making it computationally and memory efficient.
Optimal theoretical convergence rates are established for nonconvex functions
in both stochastic and deterministic settings under standard smoothness and
unbiased bounded-variance noise assumptions. Empirical results on CIFAR-10
classification and function regression demonstrate that AdaGO outperforms Muon
and Adam.

</details>


### [126] [StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails](https://arxiv.org/abs/2509.02982)
*Hritik Arasu,Faisal R Jahangiri*

Main category: cs.LG

TL;DR: 提出一种流式、无源测试时自适应方法，通过结合熵最小化、BN统计刷新及安全机制，解决睡眠分期模型在新患者数据上的性能下降问题，并在Sleep-EDF Expanded数据集上实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 睡眠分期模型在应用于具有未知生理特征或记录条件的新患者时，性能常会下降。

Method: 提出一种流式、无源测试时自适应（TTA）方法，结合了熵最小化（Tent）和Batch-Norm统计刷新，并辅以熵门控器（暂停不确定窗口自适应）和基于EMA的重置机制（防止漂移）作为安全防护。

Result: 在Sleep-EDF Expanded数据集上，使用单导联EEG数据进行实验，该方法在秒级延迟和极小内存占用下，比固定基线表现出持续的性能提升，并通过每分期指标和Cohen's k进行了报告。

Conclusion: 该方法是模型无关、无需源数据或患者校准的，且适用于设备端或床旁应用，为解决睡眠分期模型的泛化性问题提供了实用方案。

Abstract: Sleep staging models often degrade when deployed on patients with unseen
physiology or recording conditions. We propose a streaming, source-free
test-time adaptation (TTA) recipe that combines entropy minimization (Tent)
with Batch-Norm statistic refresh and two safety rails: an entropy gate to
pause adaptation on uncertain windows and an EMA-based reset to reel back
drift. On Sleep-EDF Expanded, using single-lead EEG (Fpz-Cz, 100 Hz, 30s
epochs; R&K to AASM mapping), we show consistent gains over a frozen baseline
at seconds-level latency and minimal memory, reporting per-stage metrics and
Cohen's k. The method is model-agnostic, requires no source data or patient
calibration, and is practical for on-device or bedside use.

</details>


### [127] [Multimodal learning of melt pool dynamics in laser powder bed fusion](https://arxiv.org/abs/2509.03029)
*Satyajit Mojumder,Pallock Halder,Tiana Tonge*

Main category: cs.LG

TL;DR: 本文提出一种多模态数据融合方法，结合高保真X射线和低成本吸收率数据预测增材制造熔池动态。通过多模态训练和迁移学习，最终实现仅依靠吸收率数据即可进行高精度、低成本的实时监控。


<details>
  <summary>Details</summary>
Motivation: 增材制造中，高精度传感器如X射线成本高昂且不适用于工业环境；低成本吸收率数据噪声大，单独使用预测精度不足。因此，需要一种兼顾精度、实用性和成本效益的熔池动态预测方法。

Method: 研究采用多模态学习框架，将卷积神经网络（CNN）用于X射线数据的空间特征提取，循环神经网络（RNN）用于吸收率信号的时间特征提取，并采用早期融合策略。随后，将该多模态模型作为迁移学习模型，微调仅依赖吸收率数据的RNN模型以预测熔池动态。

Result: 结果显示，与单独使用任一模态相比，结合两种模态进行训练显著提高了预测精度。经过迁移学习微调后，仅使用吸收率数据预测的RNN模型，其精度甚至高于原始的多模态模型。一旦训练完成，模型可在推断阶段仅使用吸收率数据推断熔池特性，无需昂贵的X射线成像。

Conclusion: 该多模态融合方法实现了成本效益高、实时性强的增材制造监控，并消除了对昂贵X射线成像的需求，具有广泛的适用性。

Abstract: While multiple sensors are used for real-time monitoring in additive
manufacturing, not all provide practical or reliable process insights. For
example, high-speed X-ray imaging offers valuable spatial information about
subsurface melt pool behavior but is costly and impractical for most industrial
settings. In contrast, absorptivity data from low-cost photodiodes correlate
with melt pool dynamics but is often too noisy for accurate prediction when
used alone. In this paper, we propose a multimodal data fusion approach for
predicting melt pool dynamics by combining high-fidelity X-ray data with
low-fidelity absorptivity data in the Laser Powder Bed Fusion (LPBF) process.
Our multimodal learning framework integrates convolutional neural networks
(CNNs) for spatial feature extraction from X-ray data with recurrent neural
networks (RNNs) for temporal feature extraction from absorptivity signals,
using an early fusion strategy. The multimodal model is further used as a
transfer learning model to fine-tune the RNN model that can predict melt pool
dynamics only with absorptivity, with greater accuracy compared to the
multimodal model. Results show that training with both modalities significantly
improves prediction accuracy compared to using either modality alone.
Furthermore, once trained, the model can infer melt pool characteristics using
only absorptivity data, eliminating the need for expensive X-ray imaging. This
multimodal fusion approach enables cost-effective, real-time monitoring and has
broad applicability in additive manufacturing.

</details>


### [128] [Population-aware Online Mirror Descent for Mean-Field Games with Common Noise by Deep Reinforcement Learning](https://arxiv.org/abs/2509.03030)
*Zida Wu,Mathieu Lauriere,Matthieu Geist,Olivier Pietquin,Ankur Mehta*

Main category: cs.LG

TL;DR: 本文提出了一种高效的深度强化学习（DRL）算法，用于在均值场博弈（MFGs）中学习群体依赖的纳什均衡，该算法无需平均或历史采样，并能适应未知初始分布和常见噪声。


<details>
  <summary>Details</summary>
Motivation: 在均值场博弈中，当初始分布未知或群体受共同噪声影响时，学习纳什均衡仍然是一个具有挑战性的问题。

Method: 引入了一种受Munchausen RL和在线镜像下降（Online Mirror Descent）启发的深度强化学习算法，旨在实现群体依赖的纳什均衡，且不依赖于平均或历史采样。

Result: 在七个经典示例上的数值实验表明，该算法比现有最先进算法（特别是群体依赖策略的Fictitious Play的DRL版本）具有更优越的收敛特性。在存在共同噪声的情况下，其性能突出了该方法的鲁棒性和适应性。

Conclusion: 所提出的DRL算法提供了一种有效、鲁棒且适应性强的解决方案，能够在均值场博弈中学习群体依赖的纳什均衡，尤其是在面对未知初始分布和共同噪声时表现出色。

Abstract: Mean Field Games (MFGs) offer a powerful framework for studying large-scale
multi-agent systems. Yet, learning Nash equilibria in MFGs remains a
challenging problem, particularly when the initial distribution is unknown or
when the population is subject to common noise. In this paper, we introduce an
efficient deep reinforcement learning (DRL) algorithm designed to achieve
population-dependent Nash equilibria without relying on averaging or historical
sampling, inspired by Munchausen RL and Online Mirror Descent. The resulting
policy is adaptable to various initial distributions and sources of common
noise. Through numerical experiments on seven canonical examples, we
demonstrate that our algorithm exhibits superior convergence properties
compared to state-of-the-art algorithms, particularly a DRL version of
Fictitious Play for population-dependent policies. The performance in the
presence of common noise underscores the robustness and adaptability of our
approach.

</details>


### [129] [Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained Large Language Models](https://arxiv.org/abs/2509.03036)
*Bilge Taskin,Wenxiong Xie,Teddy Lazebnik*

Main category: cs.LG

TL;DR: 本研究利用预训练大型语言模型（LLMs）自动化符号回归（SR）中的领域知识集成，通过修改损失函数，提高了物理信息SR（PiSR）模型的鲁棒性和可及性。


<details>
  <summary>Details</summary>
Motivation: 现有物理信息符号回归（PiSR）方法需要专业的公式设计和手动特征工程，这限制了其仅限于领域专家使用。因此，需要一种更自动化、更易于访问的方法来将领域知识整合到SR中。

Method: 将预训练LLM整合到SR的损失函数中，LLM对SR生成的方程进行评估，并将其评估结果作为损失函数的一部分。研究评估了三种SR算法（DEAP, gplearn, PySR）和三种LLM（Falcon, Mistral, LLama 2）在三种物理动力学（落体、简谐运动、电磁波）上的性能，并探讨了提示工程的影响。

Result: LLM集成一致性地改善了从数据中物理动力学的重建，增强了SR模型对噪声和复杂性的鲁棒性。研究还发现，更具信息量的提示能显著提高性能。

Conclusion: LLM能够有效地促进PiSR中的知识集成，使自动化科学发现过程更加鲁棒和易于访问。

Abstract: Symbolic regression (SR) has emerged as a powerful tool for automated
scientific discovery, enabling the derivation of governing equations from
experimental data. A growing body of work illustrates the promise of
integrating domain knowledge into the SR to improve the discovered equation's
generality and usefulness. Physics-informed SR (PiSR) addresses this by
incorporating domain knowledge, but current methods often require specialized
formulations and manual feature engineering, limiting their adaptability only
to domain experts. In this study, we leverage pre-trained Large Language Models
(LLMs) to facilitate knowledge integration in PiSR. By harnessing the
contextual understanding of LLMs trained on vast scientific literature, we aim
to automate the incorporation of domain knowledge, reducing the need for manual
intervention and making the process more accessible to a broader range of
scientific problems. Namely, the LLM is integrated into the SR's loss function,
adding a term of the LLM's evaluation of the SR's produced equation. We
extensively evaluate our method using three SR algorithms (DEAP, gplearn, and
PySR) and three pre-trained LLMs (Falcon, Mistral, and LLama 2) across three
physical dynamics (dropping ball, simple harmonic motion, and electromagnetic
wave). The results demonstrate that LLM integration consistently improves the
reconstruction of physical dynamics from data, enhancing the robustness of SR
models to noise and complexity. We further explore the impact of prompt
engineering, finding that more informative prompts significantly improve
performance.

</details>


### [130] [Binary Quantization For LLMs Through Dynamic Grouping](https://arxiv.org/abs/2509.03054)
*Xinzhe Zheng,Zhen-Qun Yang,Haoran Xie,S. Joe Qin,Arlene Chen,Fangzhen Lin*

Main category: cs.LG

TL;DR: 提出一种新颖的二值量化方法，在将大语言模型（LLM）权重压缩至平均1.007比特的同时，保持了接近原始模型的性能，并显著提升了量化效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLM）高昂的内存和计算资源需求，同时克服激进的二值量化（1比特）通常会导致显著性能下降的问题。

Method: 提出了一种针对二值量化的新优化目标和实现算法。该方法通过自适应分组策略，动态识别最优非结构化子矩阵，以增强分块量化技术。

Result: 实现了平均1.007比特的极低位长。量化后的LLaMA 3.2 3B模型困惑度为8.23，非常接近原始模型的7.81。显著超越了现有SOTA二值量化模型（BiLLM，困惑度123.90）。在性能和效率上与SOTA的4比特量化方法（如GPTQ）具有竞争力。量化过程高效，LLaMA 3.2 3B模型在单CPU核上仅需14秒，总耗时不到100分钟，且具备高度并行性。

Conclusion: 该研究通过创新的优化目标和算法，成功实现了LLM的高效、激进二值量化，在大幅减少资源消耗的同时，保持了优异的模型性能，超越了现有二值量化基线，并可与先进的4比特量化方法相媲美。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of Natural Language Processing (NLP) tasks, but require
substantial memory and computational resources. Binary quantization, which
compresses model weights from 16-bit Brain Float to 1-bit representations in
{-1, 1}, offers significant reductions in storage and inference costs. However,
such aggressive quantization often leads to notable performance degradation
compared to more conservative 4-bit quantization methods. In this research, we
propose a novel optimization objective tailored for binary quantization, along
with three algorithms designed to realize it effectively. Our method enhances
blocked quantization by dynamically identifying optimal unstructured
sub-matrices through adaptive grouping strategies. Experimental results
demonstrate that our approach achieves an average bit length of just 1.007
bits, while maintaining high model quality. Specifically, our quantized LLaMA
3.2 3B model attains a perplexity of 8.23, remarkably close to the original
7.81, and surpasses previous SOTA BiLLM with a perplexity of only 123.90.
Furthermore, our method is competitive with SOTA 4-bit approaches such as GPTQ
in both performance and efficiency. The compression process is highly
efficient, requiring only 14 seconds to quantize the full LLaMA 3.2 3B weights
on a single CPU core, with the entire process completing in under 100 minutes
and exhibiting embarrassingly parallel properties.
  Code - https://github.com/johnnyzheng0636/WGM_bi_quan

</details>


### [131] [Discrete Functional Geometry of ReLU Networks via ReLU Transition Graphs](https://arxiv.org/abs/2509.03056)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: 本文将ReLU转换图（RTG）框架扩展为一个全面的图论模型，用于理解深度ReLU网络。该模型将网络功能行为视为离散几何结构，通过理论证明和实证分析揭示了RTG的结构特性与泛化能力之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法对深度ReLU网络内部机制及泛化能力的理解不足。本研究旨在通过构建图论模型（RTG）来刻画网络的功能行为，并探索其结构特性如何影响和决定网络的容量与泛化能力。

Method: 研究方法包括：1) 将RTG框架扩展为图论模型，其中节点代表线性激活区域，边连接仅相差一个ReLU激活翻转的区域。2) 理论证明随机初始化下RTG的强扩展性、二项式度分布和谱特性，并基于此推导出容量（通过区域熵）和泛化能力（通过谱隙和边际KL散度）的新界限。3) 对小型网络构建RTG进行实证分析，测量其平滑度和连接性，以验证理论预测。

Result: 理论结果表明，随机初始化下RTG表现出强扩展性、二项式度分布和紧密控制泛化能力的谱特性。基于这些洞察，提出了新的容量和泛化能力上界。实证结果显示，区域熵在过参数化下饱和，谱隙与泛化能力呈正相关，相邻区域的KL散度反映了功能平滑性。

Conclusion: 本工作提供了一个统一的框架，通过离散函数几何的视角分析ReLU网络，为理解、诊断和改进深度ReLU网络的泛化能力提供了新颖且有力的工具。

Abstract: We extend the ReLU Transition Graph (RTG) framework into a comprehensive
graph-theoretic model for understanding deep ReLU networks. In this model, each
node represents a linear activation region, and edges connect regions that
differ by a single ReLU activation flip, forming a discrete geometric structure
over the network's functional behavior. We prove that RTGs at random
initialization exhibit strong expansion, binomial degree distributions, and
spectral properties that tightly govern generalization. These structural
insights enable new bounds on capacity via region entropy and on generalization
via spectral gap and edge-wise KL divergence. Empirically, we construct RTGs
for small networks, measure their smoothness and connectivity properties, and
validate theoretical predictions. Our results show that region entropy
saturates under overparameterization, spectral gap correlates with
generalization, and KL divergence across adjacent regions reflects functional
smoothness. This work provides a unified framework for analyzing ReLU networks
through the lens of discrete functional geometry, offering new tools to
understand, diagnose, and improve generalization.

</details>


### [132] [LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence](https://arxiv.org/abs/2509.03505)
*Xingxuan Zhang,Gang Ren,Han Yu,Hao Yuan,Hui Wang,Jiansheng Li,Jiayun Wu,Lang Mo,Li Mao,Mingchao Hao,Ningbo Dai,Renzhe Xu,Shuyang Li,Tianyang Zhang,Yue He,Yuanrui Wang,Yunjia Zhang,Zijing Xu,Dongzhe Li,Fang Gao,Hao Zou,Jiandong Liu,Jiashuo Liu,Jiawei Xu,Kaijie Cheng,Kehan Li,Linjun Zhou,Qing Li,Shaohua Fan,Xiaoyu Lin,Xinyan Han,Xuanyue Li,Yan Lu,Yuan Xue,Yuanyuan Jiang,Zimu Wang,Zhenlei Wang,Peng Cui*

Main category: cs.LG

TL;DR: 本文介绍了LimiX，一个大型结构化数据模型（LDM），它将结构化数据视为变量和缺失值的联合分布，能够通过统一的模型和查询式条件预测处理广泛的表格任务，并在多种基准测试和任务中持续超越现有强基线。


<details>
  <summary>Details</summary>
Motivation: 通用人工智能的进展需要建立在语言、物理世界和结构化数据基础上的互补基础模型。LimiX旨在填补结构化数据领域这一基础模型的空白，以统一且高效的方式处理各类表格任务，避免传统方法中任务特定的架构和训练。

Method: LimiX将结构化数据建模为变量和缺失值的联合分布，通过查询式的条件预测实现广泛的表格任务。它采用掩码联合分布建模进行预训练，并结合情景式、上下文条件目标，在推断时支持快速、免训练的适应。模型通过对数据集特定上下文条件下的查询子集进行预测。

Result: LimiX在10个大型结构化数据基准测试中持续超越了包括梯度提升树、深度表格网络、最新表格基础模型和自动化集成在内的强大基线。其优势在分类、回归、缺失值插补和数据生成等多种任务中均得以体现，且通常以显著的优势胜出，同时避免了任务特定的架构或定制训练。

Conclusion: LimiX是一个统一的、高性能大型结构化数据模型，能够有效且灵活地处理各种表格任务，显著推动了结构化数据领域向通用人工智能基础模型的发展。其模型已开源，可供公众访问和使用。

Abstract: We argue that progress toward general intelligence requires complementary
foundation models grounded in language, the physical world, and structured
data. This report presents LimiX, the first installment of our large
structured-data models (LDMs). LimiX treats structured data as a joint
distribution over variables and missingness, thus capable of addressing a wide
range of tabular tasks through query-based conditional prediction via a single
model. LimiX is pretrained using masked joint-distribution modeling with an
episodic, context-conditional objective, where the model predicts for query
subsets conditioned on dataset-specific contexts, supporting rapid,
training-free adaptation at inference. We evaluate LimiX across 10 large
structured-data benchmarks with broad regimes of sample size, feature
dimensionality, class number, categorical-to-numerical feature ratio,
missingness, and sample-to-feature ratios. With a single model and a unified
interface, LimiX consistently surpasses strong baselines including
gradient-boosting trees, deep tabular networks, recent tabular foundation
models, and automated ensembles, as shown in Figure 1 and Figure 2. The
superiority holds across a wide range of tasks, such as classification,
regression, missing value imputation, and data generation, often by substantial
margins, while avoiding task-specific architectures or bespoke training per
task. All LimiX models are publicly accessible under Apache 2.0.

</details>


### [133] [Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers](https://arxiv.org/abs/2509.03059)
*Xingyue Huang,Rishabh,Gregor Franke,Ziyi Yang,Jiamu Bai,Weijie Bai,Jinhe Bi,Zifeng Ding,Yiqun Duan,Chengyu Fan,Wendong Fan,Xin Gao,Ruohao Guo,Yuan He,Zhuangzhuang He,Xianglong Hu,Neil Johnson,Bowen Li,Fangru Lin,Siyu Lin,Tong Liu,Yunpu Ma,Hao Shen,Hao Sun,Beibei Wang,Fangyijie Wang,Hao Wang,Haoran Wang,Yang Wang,Yifeng Wang,Zhaowei Wang,Ziyang Wang,Yifan Wu,Zikai Xiao,Chengxing Xie,Fan Yang,Junxiao Yang,Qianshuo Ye,Ziyu Ye,Guangtao Zeng,Yuwen Ebony Zhang,Zeyu Zhang,Zihao Zhu,Bernard Ghanem,Philip Torr,Guohao Li*

Main category: cs.LG

TL;DR: Loong项目是一个开源框架，通过可扩展的合成数据生成和验证，旨在解决大型语言模型在多样化推理领域中可验证数据稀缺和人类监督成本高昂的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理能力通过可验证奖励强化学习（RLVR）在数学和编程等领域取得了显著进步，但由于高质量、可验证数据集的稀缺以及高昂的人工监督成本，将这种成功扩展到其他推理密集型领域仍然面临挑战。

Method: 引入Loong项目，一个包含两个关键组件的开源框架：(1) LoongBench，一个包含12个领域8,729个人工验证示例的精选种子数据集，每个示例都配有可执行代码和丰富的元数据；(2) LoongEnv，一个模块化的合成数据生成环境，支持多种提示策略以生成新的问答-代码三元组。这两个组件形成一个代理-环境循环，通过奖励与代码执行答案一致的思维链（CoT）解决方案来实现强化学习。

Result: 经验性地，LoongBench在各种开源和专有LLMs上进行了基准测试，以评估领域覆盖范围并揭示性能瓶颈。此外，对LoongEnv生成的合成数据进行了全面分析，检查了其正确性、难度和多样性。

Conclusion: Loong项目提供了一个可扩展的开源解决方案，用于在各种推理密集型领域中生成和验证高质量的合成数据，从而有望显著提升LLMs在这些领域中的推理能力。

Abstract: Recent advances in Large Language Models (LLMs) have shown that their
reasoning capabilities can be significantly improved through Reinforcement
Learning with Verifiable Reward (RLVR), particularly in domains like
mathematics and programming, where ground-truth correctness can be
automatically evaluated. However, extending this success to other
reasoning-intensive domains remains challenging due to the scarcity of
high-quality, verifiable datasets and the high cost of human supervision. In
this work, we introduce the Loong Project: an open-source framework for
scalable synthetic data generation and verification across a diverse range of
reasoning-intensive domains. The framework consists of two key components: (1)
LoongBench, a curated seed dataset containing 8,729 human-vetted examples
across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired
with executable code and rich metadata; and (2) LoongEnv, a modular synthetic
data generation environment that supports multiple prompting strategies to
produce new question-answer-code triples. Together, these components form an
agent-environment loop that enables reinforcement learning, where an LLM-based
agent is rewarded for generating Chain-of-Thought (CoT) solutions that align
with code-executed answers. Empirically, we benchmark LoongBench on a broad
suite of both open-source and proprietary LLMs to evaluate domain coverage and
reveal performance bottlenecks. In addition, we conduct a comprehensive
analysis of synthetic data generated by LoongEnv, examining correctness,
difficulty, and diversity. Code and documentation are available at
https://github.com/camel-ai/loong.

</details>


### [134] [LSAM: Asynchronous Distributed Training with Landscape-Smoothed Sharpness-Aware Minimization](https://arxiv.org/abs/2509.03110)
*Yunfei Teng,Sixin Zhang*

Main category: cs.LG

TL;DR: LSAM通过异步分布式采样策略，解决了SAM在分布式大批量训练中的效率问题，同时保持了泛化优势并提高了最终精度。


<details>
  <summary>Details</summary>
Motivation: 尽管锐度感知最小化（SAM）通过同时最小化损失和锐度来提高深度神经网络的泛化能力，但其在分布式大批量训练中效率低下。

Method: 本文提出了景观平滑SAM（LSAM），这是一种新型优化器，它将SAM的对抗性步骤与异步分布式采样策略相结合，生成异步分布式采样方案，从而产生平滑的锐度感知损失景观以进行优化。

Result: LSAM的设计消除了同步瓶颈，加速了大批量收敛，并比数据并行SAM提供了更高的最终精度。

Conclusion: LSAM作为一种新型优化器，在保持SAM泛化优势的同时，显著提升了其在分布式大批量训练中的效率和最终模型性能。

Abstract: While Sharpness-Aware Minimization (SAM) improves generalization in deep
neural networks by minimizing both loss and sharpness, it suffers from
inefficiency in distributed large-batch training. We present Landscape-Smoothed
SAM (LSAM), a novel optimizer that preserves SAM's generalization advantages
while offering superior efficiency. LSAM integrates SAM's adversarial steps
with an asynchronous distributed sampling strategy, generating an asynchronous
distributed sampling scheme, producing a smoothed sharpness-aware loss
landscape for optimization. This design eliminates synchronization bottlenecks,
accelerates large-batch convergence, and delivers higher final accuracy
compared to data-parallel SAM.

</details>


### [135] [A Hierarchical Deep Reinforcement Learning Framework for Traffic Signal Control with Predictable Cycle Planning](https://arxiv.org/abs/2509.03118)
*Hankang Gu,Yuli Zhang,Chengming Wang,Ruiyuan Jiang,Ziheng Qiao,Pengfei Fan,Dongyao Jia*

Main category: cs.LG

TL;DR: DRL在交通信号控制中存在现有范式缺陷。本文提出DHCP分层DRL模型，灵活分配信号周期时长，在多个数据集上均取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有DRL交通信号控制方法（“选择相位”和“切换”范式）存在局限：“选择相位”可能导致不可预测的相位序列，影响驾驶员预期和安全；“切换”范式则可能导致不公平和低效的相位分配。

Method: 提出Deep Hierarchical Cycle Planner (DHCP) DRL模型，采用分层方法分配交通信号周期时长。高层智能体根据整体交通状态决定南北向和东西向的总周期时间分配；低层智能体进一步将主要方向内的分配时长细分为直行和左转移动，以实现更灵活的配时。

Result: 在真实和合成路网以及多种真实和合成交通流数据集上进行测试，DHCP模型在所有数据集上均优于基线模型，取得了最佳性能。

Conclusion: DHCP模型通过其独特的分层周期分配策略，有效解决了现有DRL交通信号控制方法的不足，显著提升了交通信号控制的性能和效率。

Abstract: Deep reinforcement learning (DRL) has become a popular approach in traffic
signal control (TSC) due to its ability to learn adaptive policies from complex
traffic environments. Within DRL-based TSC methods, two primary control
paradigms are ``choose phase" and ``switch" strategies. Although the agent in
the choose phase paradigm selects the next active phase adaptively, this
paradigm may result in unexpected phase sequences for drivers, disrupting their
anticipation and potentially compromising safety at intersections. Meanwhile,
the switch paradigm allows the agent to decide whether to switch to the next
predefined phase or extend the current phase. While this structure maintains a
more predictable order, it can lead to unfair and inefficient phase
allocations, as certain movements may be extended disproportionately while
others are neglected. In this paper, we propose a DRL model, named Deep
Hierarchical Cycle Planner (DHCP), to allocate the traffic signal cycle
duration hierarchically. A high-level agent first determines the split of the
total cycle time between the North-South (NS) and East-West (EW) directions
based on the overall traffic state. Then, a low-level agent further divides the
allocated duration within each major direction between straight and left-turn
movements, enabling more flexible durations for the two movements. We test our
model on both real and synthetic road networks, along with multiple sets of
real and synthetic traffic flows. Empirical results show our model achieves the
best performance over all datasets against baselines.

</details>


### [136] [A Neural Network Approach to Multi-radionuclide TDCR Beta Spectroscopy](https://arxiv.org/abs/2509.03137)
*Li Yi,Qian Yang*

Main category: cs.LG

TL;DR: 本文提出一种结合数值模拟和深度学习的AI框架，实现了无需标准源的自动化TDCR多核素分析，并在活度、效率和谱重建方面取得了高精度。


<details>
  <summary>Details</summary>
Motivation: 液闪TDCR光谱法在多核素分析中面临自动化程度低以及依赖难以获取的混合标准源的挑战。

Method: 使用Geant4模拟结合统计探测器响应采样生成β谱数据用于模型训练。开发定制的神经网络架构，通过端到端学习，自主解析单个核素活度及探测效率。

Result: 模型在活度比例（平均绝对误差 = 0.009）、探测效率（平均绝对误差 = 0.002）和谱重建（结构相似性指数 = 0.9998）方面均达到了持续的高精度，验证了其物理合理性。

Conclusion: 该AI驱动的方法在自动化、安全合规的多核素分析方面，特别是在缺乏参考物质或需要快速现场分析的场景中，展现出强大的泛化能力、实时处理能力和工程可行性。

Abstract: Liquid scintillation triple-to-doubly coincident ratio (TDCR) spectroscopy is
widely adopted as a standard method for radionuclide quantification because of
its inherent advantages such as high precision, self-calibrating capability,
and independence from radioactive reference sources. However, multiradionuclide
analysis via TDCR faces the challenges of limited automation and reliance on
mixture-specific standards, which may not be easily available. Here, we present
an Artificial Intelligence (AI) framework that combines numerical spectral
simulation and deep learning for standard-free automated analysis. $\beta$
spectra for model training were generated using Geant4 simulations coupled with
statistically modeled detector response sampling. A tailored neural network
architecture, trained on this dataset covering various nuclei mix ratio and
quenching scenarios, enables autonomous resolution of individual radionuclide
activities and detecting efficiency through end-to-end learning paradigms. The
model delivers consistent high accuracy across tasks: activity proportions
(mean absolute error = 0.009), detection efficiencies (mean absolute error =
0.002), and spectral reconstruction (Structural Similarity Index = 0.9998),
validating its physical plausibility for quenched $\beta$ spectroscopy. This
AI-driven methodology exhibits significant potential for automated
safety-compliant multiradionuclide analysis with robust generalization,
real-time processing capabilities, and engineering feasibility, particularly in
scenarios where reference materials are unavailable or rapid field analysis is
required.

</details>


### [137] [Rashomon in the Streets: Explanation Ambiguity in Scene Understanding](https://arxiv.org/abs/2509.03169)
*Helge Spieker,Jørn Eirik Betten,Arnaud Gotlieb,Nadjib Lazaar,Nassim Belmecheri*

Main category: cs.LG

TL;DR: 本文首次实证量化了自动驾驶动作预测中XAI的“罗生门效应”，发现解释差异显著且是问题固有的。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等安全关键应用中，可解释人工智能（XAI）对模型验证和信任至关重要。然而，“罗生门效应”（即多个同样准确的模型可能提供截然不同的解释）挑战了XAI的可靠性。本文旨在首次实证量化这种效应。

Method: 使用定性可解释图（QXGs）作为符号场景表示，训练两类不同的模型罗生门集：可解释的基于对的梯度提升模型和复杂的图神经网络（GNNs）。通过特征归因方法，测量这些模型类别内部和之间的解释一致性。

Result: 研究结果揭示了显著的解释不一致性。

Conclusion: 研究发现表明，解释的模糊性是问题本身固有的属性，而非仅仅是建模的产物。

Abstract: Explainable AI (XAI) is essential for validating and trusting models in
safety-critical applications like autonomous driving. However, the reliability
of XAI is challenged by the Rashomon effect, where multiple, equally accurate
models can offer divergent explanations for the same prediction. This paper
provides the first empirical quantification of this effect for the task of
action prediction in real-world driving scenes. Using Qualitative Explainable
Graphs (QXGs) as a symbolic scene representation, we train Rashomon sets of two
distinct model classes: interpretable, pair-based gradient boosting models and
complex, graph-based Graph Neural Networks (GNNs). Using feature attribution
methods, we measure the agreement of explanations both within and between these
classes. Our results reveal significant explanation disagreement. Our findings
suggest that explanation ambiguity is an inherent property of the problem, not
just a modeling artifact.

</details>


### [138] [Systematic Evaluation of Attribution Methods: Eliminating Threshold Bias and Revealing Method-Dependent Performance Patterns](https://arxiv.org/abs/2509.03176)
*Serra Aksoy*

Main category: cs.LG

TL;DR: 现有归因方法评估存在阈值选择偏差，导致排名不稳定。本文提出一种无阈值框架AUC-IoU，有效评估归因方法并消除偏差，揭示了XRAI等方法的显著性能。


<details>
  <summary>Details</summary>
Motivation: 现有归因方法在解释神经网络预测时，其评估受限于阈值选择偏差。单一阈值可能导致方法排名剧烈变化，甚至高达200个百分点，从而影响评估结论的可靠性。

Method: 提出了一种无阈值评估框架，通过计算交并比曲线下面积（AUC-IoU）来衡量归因质量，捕捉其在完整阈值范围内的表现，以此解决阈值选择偏差问题。

Result: 在皮肤病学图像上的七种归因方法评估显示，单阈值指标产生矛盾结果，而无阈值评估提供了可靠的区分。XRAI相较于LIME和香草集成梯度分别提升31%和204%，且在不同病灶尺度上性能差异高达269%。

Conclusion: 该无阈值框架建立了新的方法学标准，消除了评估伪影，为基于证据的归因方法选择提供了理论洞察和实践指导，尤其在医学影像等领域具有重要应用价值。

Abstract: Attribution methods explain neural network predictions by identifying
influential input features, but their evaluation suffers from threshold
selection bias that can reverse method rankings and undermine conclusions.
Current protocols binarize attribution maps at single thresholds, where
threshold choice alone can alter rankings by over 200 percentage points. We
address this flaw with a threshold-free framework that computes Area Under the
Curve for Intersection over Union (AUC-IoU), capturing attribution quality
across the full threshold spectrum. Evaluating seven attribution methods on
dermatological imaging, we show single-threshold metrics yield contradictory
results, while threshold-free evaluation provides reliable differentiation.
XRAI achieves 31% improvement over LIME and 204% over vanilla Integrated
Gradients, with size-stratified analysis revealing performance variations up to
269% across lesion scales. These findings establish methodological standards
that eliminate evaluation artifacts and enable evidence-based method selection.
The threshold-free framework provides both theoretical insight into attribution
behavior and practical guidance for robust comparison in medical imaging and
beyond.

</details>


### [139] [Tabular foundation model for GEOAI benchmark problems BM/AirportSoilProperties/2/2025](https://arxiv.org/abs/2509.03191)
*Taiga Saito,Yu Otake,Stephen Wu*

Main category: cs.LG

TL;DR: 本文首次将表格基础模型TabPFN应用于岩土工程场地特性描述问题，在零训练、少样本、情境学习设置下，对比传统分层贝叶斯模型，TabPFN在剪切强度预测和缺失参数插补任务中均展现出卓越的准确性和效率，预示着概率场地特性描述的潜在范式转变。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索TabPFN（一种基于Transformer的表格数据基础模型）在岩土工程场地特性描述问题中的应用潜力，特别是在GEOAI基准测试框架下，以验证其作为通用模型处理复杂工程任务的有效性。

Method: 该研究采用Tabular Prior-Data Fitted Network (TabPFN) 模型，在零训练、少样本、情境学习模式下进行应用，并结合大型间接数据库(BID)提供额外上下文。研究了两个任务：1) 预测钻孔深度剖面中不排水剪切强度(su)的空间变化；2) 插补密集场地数据集中缺失的力学参数。对比基线模型为传统的层次贝叶斯模型(HBM)。

Result: TabPFN在预测准确性和预测分布校准方面均优于HBM，并显著提高了推理效率。在任务1（su空间预测）中，TabPFN的预测精度超过HBM，运行时间快了一个数量级。在任务2（缺失力学参数插补）中，TabPFN对所有目标参数均实现了更低的RMSE和良好量化的不确定性，尽管其累积计算成本因一次处理一个变量而高于HBM。

Conclusion: 本研究标志着表格基础模型在岩土工程建模领域的首次成功应用，TabPFN作为通用基础模型在概率场地特性描述中表现出色，预示着该领域可能出现范式转变。

Abstract: This paper presents a novel application of the Tabular Prior-Data Fitted
Network (TabPFN) - a transformer-based foundation model for tabular data - to
geotechnical site characterization problems defined in the GEOAI benchmark
BM/AirportSoilProperties/2/2025. Two tasks are addressed: (1) predicting the
spatial variation of undrained shear strength (su) across borehole depth
profiles, and (2) imputing missing mechanical parameters in a dense-site
dataset. We apply TabPFN in a zero-training, few-shot, in-context learning
setting - without hyper-parameter tuning - and provide it with additional
context from the big indirect database (BID). The study demonstrates that
TabPFN, as a general-purpose foundation model, achieved superior accuracy and
well-calibrated predictive distributions compared to a conventional
hierarchical Bayesian model (HBM) baseline, while also offering significant
gains in inference efficiency. In Benchmark Problem #1 (spatial su prediction),
TabPFN outperformed the HBM in prediction accuracy and delivered an
order-of-magnitude faster runtime. In Benchmark Problem #2 (missing mechanical
parameter imputation), TabPFN likewise achieved lower RMSE for all target
parameters with well-quantified uncertainties, though its cumulative
computation cost was higher than HBM's due to its one-variable-at-a-time
inference. These results mark the first successful use of a tabular foundation
model in geotechnical modeling, suggesting a potential paradigm shift in
probabilistic site characterization.

</details>


### [140] [Exploring the Design Space of Fair Tree Learning Algorithms](https://arxiv.org/abs/2509.03204)
*Kiara Stempel,Mattia Cerrato,Stefan Kramer*

Main category: cs.LG

TL;DR: 本文探索并实验分析了公平决策树学习中两种未被充分研究的设计方案：带有回溯功能的约束单树模型和独立的双树模型。


<details>
  <summary>Details</summary>
Motivation: 现有公平决策树算法主要集中于有限的设计空间（例如，将敏感属性纳入目标函数或贪婪的约束方法），忽视了其他可能在预测性能和公平性之间提供更好权衡的潜在方案。

Method: 本文引入并实验性地分析了公平决策树算法设计空间中两个先前未被充分研究的选项：1. 单树模型中，敏感属性作为约束（非贪婪变体，允许在违反公平性约束时回溯）。2. 双树模型，为目标变量(y)和敏感属性(s)分别构建独立的树，不共享结构。这些方法在多个数据集上进行了实验性表征。

Result: 论文介绍了公平决策树设计空间中两种额外的、先前未被研究的选项（单树模型的非贪婪约束变体和双树模型），并在多个数据集上对其进行了实验性表征。

Conclusion: 通过系统性地探索并实验性表征公平决策树设计空间中未被研究的选项，本文扩展了该领域的知识，为平衡预测性能和非歧视性提供了新的研究方向。

Abstract: Decision trees have been studied extensively in the context of fairness,
aiming to maximize prediction performance while ensuring non-discrimination
against different groups. Techniques in this space usually focus on imposing
constraints at training time, constraining the search space so that solutions
which display unacceptable values of relevant metrics are not considered,
discarded, or discouraged. If we assume one target variable y and one sensitive
attribute s, the design space of tree learning algorithms can be spanned as
follows: (i) One can have one tree T that is built using an objective function
that is a function of y, s, and T. For instance, one can build a tree based on
the weighted information gain regarding y (maximizing) and s (minimizing). (ii)
The second option is to have one tree model T that uses an objective function
in y and T and a constraint on s and T. Here, s is no longer part of the
objective, but part of a constraint. This can be achieved greedily by aborting
a further split as soon as the condition that optimizes the objective in y
fails to satisfy the constraint on s. A simple way to explore other splits is
to backtrack during tree construction once a fairness constraint is violated.
(iii) The third option is to have two trees T_y and T_s, one for y and one for
s, such that the tree structure for y and s does not have to be shared. In this
way, information regarding y and regarding s can be used independently, without
having to constrain the choices in tree construction by the mutual information
between the two variables. Quite surprisingly, of the three options, only the
first one and the greedy variant of the second have been studied in the
literature so far. In this paper, we introduce the above two additional options
from that design space and characterize them experimentally on multiple
datasets.

</details>


### [141] [Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback](https://arxiv.org/abs/2509.03206)
*Zeqiang Zhang,Fabian Wurzberger,Gerrit Schmid,Sebastian Gottwald,Daniel A. Braun*

Main category: cs.LG

TL;DR: GCSL在学习自生成经验时存在偏差且无法从失败中学习。本文提出将对比学习融入GCSL，使其能从成功与失败中学习，从而克服偏差、增强探索性并提升性能。


<details>
  <summary>Details</summary>
Motivation: 虽然GCSL通过自模仿学习解决了稀疏奖励问题，但其存在两点局限：(1) 仅从自生成经验学习会加剧智能体的固有偏差；(2) 目标重标注策略只关注成功结果，无法从错误中学习。

Method: 提出了一种新颖的模型，将对比学习（contrastive learning）原则整合到现有的GCSL框架中，以实现从成功和失败两方面进行学习。

Result: 通过实证评估，我们的算法克服了智能体初始偏差带来的限制，从而实现了更具探索性的行为。这有助于识别并采纳有效的策略，在各种挑战性环境中实现卓越性能。

Conclusion: 将对比学习整合到GCSL框架中，能够有效解决智能体的固有偏差问题并促进从失败中学习，从而提升智能体的探索能力和任务性能。

Abstract: Reinforcement learning faces significant challenges when applied to tasks
characterized by sparse reward structures. Although imitation learning, within
the domain of supervised learning, offers faster convergence, it relies heavily
on human-generated demonstrations. Recently, Goal-Conditioned Supervised
Learning (GCSL) has emerged as a potential solution by enabling self-imitation
learning for autonomous systems. By strategically relabelling goals, agents can
derive policy insights from their own experiences. Despite the successes of
this framework, it presents two notable limitations: (1) Learning exclusively
from self-generated experiences can exacerbate the agents' inherent biases; (2)
The relabelling strategy allows agents to focus solely on successful outcomes,
precluding them from learning from their mistakes. To address these issues, we
propose a novel model that integrates contrastive learning principles into the
GCSL framework to learn from both success and failure. Through empirical
evaluations, we demonstrate that our algorithm overcomes limitations imposed by
agents' initial biases and thereby enables more exploratory behavior. This
facilitates the identification and adoption of effective policies, leading to
superior performance across a variety of challenging environments.

</details>


### [142] [TeRA: Vector-based Random Tensor Network for High-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2509.03234)
*Yuxuan Gu,Wuyang Zhou,Giorgos Iacovides,Danilo Mandic*

Main category: cs.LG

TL;DR: 提出TeRA，一种新的PEFT方法，通过张量网络实现高秩权重更新，同时保持向量化方法的参数效率，性能与高秩适配器相当或更优。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA风格PEFT方法在高秩表达能力（提升性能）与极端参数效率（减少参数）之间存在权衡，难以兼顾，即高秩更新通常会牺牲参数效率。

Method: 提出TeRA (vector-based random Tensor network for high-Rank Adaptation)，将张量化的权重更新矩阵参数化为Tucker型张量网络。其中，大型随机初始化的因子被冻结并跨层共享，只训练由对角因子矩阵条目形成的小型层特定标量向量。此设计有效解耦了权重更新矩阵的秩与可训练参数的数量。

Result: TeRA的性能与高秩适配器相当甚至超越，同时所需的可训练参数数量与向量化方法相似。

Conclusion: TeRA成功解决了PEFT方法在高秩表达能力和参数效率之间的权衡问题，通过其创新的张量网络设计，在保持参数效率的同时实现了优异的性能。理论分析和消融研究进一步证实了其有效性。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods, such as Low-Rank Adaptation
(LoRA), have significantly reduced the number of trainable parameters needed in
fine-tuning large language models (LLMs). Subsequent developments of LoRA-style
adapters have diverged into two main directions: (1) enhancing model
expressivity with high-rank adapters, and (2) pushing for further parameter
reduction, as exemplified by vector-based methods. However, these approaches
present a trade-off, as achieving the expressivity of high-rank weight updates
typically comes at the cost of sacrificing the extreme parameter efficiency
offered by vector-based techniques. To address this issue, we propose a
vector-based random \underline{\textbf{Te}}nsor network for
high-\underline{\textbf{R}}ank \underline{\textbf{A}}daptation (TeRA), a novel
PEFT method that achieves high-rank weight updates while retaining the
parameter efficiency of vector-based PEFT adapters. This is achieved by
parameterizing the tensorized weight update matrix as a Tucker-like tensor
network (TN), in which large randomly initialized factors are frozen and shared
across layers, while only small layer-specific scaling vectors, formed by
entries in diagonal factor matrices, are trained. This design effectively
decouples the rank of the weight update matrix from the number of trainable
parameters. Comprehensive experiments demonstrate that TeRA matches or even
outperforms high-rank adapters, while requiring a trainable parameter count
similar to vector-based methods. Theoretical analysis and ablation studies
further validate the effectiveness of our approach.

</details>


### [143] [Evaluation of Stress Detection as Time Series Events -- A Novel Window-Based F1-Metric](https://arxiv.org/abs/2509.03240)
*Harald Vilhelm Skat-Rørdam,Sneha Das,Kathrine Sofie Rasmussen,Nicole Nadine Lønfeldt,Line Clemmensen*

Main category: cs.LG

TL;DR: 针对时间序列中渐进式事件检测，传统F1指标在真实世界数据中表现不佳。本文引入了考虑时间容忍度的窗口F1指标 (F1$_w$)，经验证其能更准确地评估模型性能，并揭示了传统指标无法捕捉到的模式。


<details>
  <summary>Details</summary>
Motivation: 在可穿戴设备等应用中，时间序列事件检测的准确评估至关重要。然而，实际中事件常是渐进的，而地面真相却是单点标注，导致传统F1和点调整F1 (F1$_{pa}$) 等标准指标在真实世界、不平衡数据集中无法准确反映模型性能。

Method: 本文提出了一种基于窗口的F1指标 (F1$_w$)。该指标通过引入时间容忍度，允许在事件精确对齐不切实际的情况下，对事件检测进行更鲁棒的评估。

Result: 在三个生理数据集（两个真实世界，一个实验性）上的实证分析表明，F1$_w$ 能揭示传统指标无法捕捉到的有意义的模型性能模式，且其窗口大小可根据领域知识调整以避免过高估计。研究发现，只有具有时间容忍度的指标才能在真实世界用例中显著区分模型（如TimesFM）与随机及空基线的性能。

Conclusion: 本工作解决了时间序列评估中的关键空白，为医疗保健应用提供了实用指导，特别是在对时间精度要求因上下文而异的场景下，提出了更准确的事件检测评估方法。

Abstract: Accurate evaluation of event detection in time series is essential for
applications such as stress monitoring with wearable devices, where ground
truth is typically annotated as single-point events, even though the underlying
phenomena are gradual and temporally diffused. Standard metrics like F1 and
point-adjusted F1 (F1$_{pa}$) often misrepresent model performance in such
real-world, imbalanced datasets. We introduce a window-based F1 metric (F1$_w$)
that incorporates temporal tolerance, enabling a more robust assessment of
event detection when exact alignment is unrealistic. Empirical analysis in
three physiological datasets, two in-the-wild (ADARP, Wrist Angel) and one
experimental (ROAD), indicates that F1$_w$ reveals meaningful model performance
patterns invisible to conventional metrics, while its window size can be
adapted to domain knowledge to avoid overestimation. We show that the choice of
evaluation metric strongly influences the interpretation of model performance:
using predictions from TimesFM, only our temporally tolerant metrics reveal
statistically significant improvements over random and null baselines in the
two in-the-wild use cases. This work addresses key gaps in time series
evaluation and provides practical guidance for healthcare applications where
requirements for temporal precision vary by context.

</details>


### [144] [Unsupervised Learning based Element Resource Allocation for Reconfigurable Intelligent Surfaces in mmWave Network](https://arxiv.org/abs/2509.03241)
*Pujitha Mamillapalli,Yoghitha Ramamoorthi,Abhinav Kumar,Tomoki Murakami,Tomoaki Ogawa,Yasushi Takatori*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The increasing demand for high data rates and seamless connectivity in
wireless systems has sparked significant interest in reconfigurable intelligent
surfaces (RIS) and artificial intelligence-based wireless applications. RIS
typically comprises passive reflective antenna elements that control the
wireless propagation environment by adequately tuning the phase of the
reflective elements. The allocation of RIS elements to multipleuser equipment
(UEs) is crucial for efficiently utilizing RIS. In this work, we formulate a
joint optimization problem that optimizes the RIS phase configuration and
resource allocation under an $\alpha$-fair scheduling framework and propose an
efficient way of allocating RIS elements. Conventional iterative optimization
methods, however, suffer from exponentially increasing computational complexity
as the number of RIS elements increases and also complicate the generation of
training labels for supervised learning. To overcome these challenges, we
propose a five-layer fully connected neural network (FNN) combined with a
preprocessing technique to significantly reduce input dimensionality, lower
computational complexity, and enhance scalability. The simulation results show
that our proposed NN-based solution reduces computational overhead while
significantly improving system throughput by 6.8% compared to existing RIS
element allocation schemes. Furthermore, the proposed system achieves better
performance while reducing computational complexity, making it significantly
more scalable than the iterative optimization algorithms.

</details>


### [145] [TopoMap: A Feature-based Semantic Discriminator of the Topographical Regions in the Test Input Space](https://arxiv.org/abs/2509.03242)
*Gianmarco De Vita,Nargiz Humbatova,Paolo Tonella*

Main category: cs.LG

TL;DR: TopoMap是一种黑盒、模型无关的深度学习系统测试方法，通过降维和聚类在输入特征空间中构建地形图，以有效识别和分组导致模型失效的输入特征，其性能在杀死变异体方面显著优于随机选择。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统测试面临挑战，现有方法虽能找到导致模型行为异常的输入，但未能有效根据特征对这些导致失败的输入进行分组，忽视了特征空间中不同区域的失败诱发特征。

Method: 提出TopoMap方法，通过对输入特征空间进行显式地形图构建。首先应用降维技术获取输入嵌入，然后对嵌入进行聚类以区分具有共享特征的输入。为选择最佳嵌入和聚类配置，使用一个深度神经网络（DNN）模拟人类评估者，判断聚类是否可区分，并据此自动选择最优地形图。

Result: TopoMap生成的地图由可区分且有意义的区域组成。在变异分析中，TopoMap能够更有效地选择杀死变异体的输入，对可杀死变异体的效果平均优于随机选择35%，对不可杀死变异体的效果优于随机选择61%。

Conclusion: TopoMap通过构建输入特征空间的地形图，有效地解决了深度学习系统测试中对失败诱导输入进行特征分组的难题，并在选择杀死变异体的输入方面表现出显著优越性。

Abstract: Testing Deep Learning (DL)-based systems is an open challenge. Although it is
relatively easy to find inputs that cause a DL model to misbehave, the grouping
of inputs by features that make the DL model under test fail is largely
unexplored. Existing approaches for DL testing introduce perturbations that may
focus on specific failure-inducing features, while neglecting others that
belong to different regions of the feature space. In this paper, we create an
explicit topographical map of the input feature space. Our approach, named
TopoMap, is both black-box and model-agnostic as it relies solely on features
that characterise the input space. To discriminate the inputs according to the
specific features they share, we first apply dimensionality reduction to obtain
input embeddings, which are then subjected to clustering. Each DL model might
require specific embedding computations and clustering algorithms to achieve a
meaningful separation of inputs into discriminative groups. We propose a novel
way to evaluate alternative configurations of embedding and clustering
techniques. We used a deep neural network (DNN) as an approximation of a human
evaluator who could tell whether a pair of clusters can be discriminated based
on the features of the included elements. We use such a DNN to automatically
select the optimal topographical map of the inputs among all those that are
produced by different embedding/clustering configurations. The evaluation
results show that the maps generated by TopoMap consist of distinguishable and
meaningful regions. In addition, we evaluate the effectiveness of TopoMap using
mutation analysis. In particular, we assess whether the clusters in our
topographical map allow for an effective selection of mutation-killing inputs.
Experimental results show that our approach outperforms random selection by 35%
on average on killable mutants; by 61% on non-killable ones.

</details>


### [146] [FoMEMO: Towards Foundation Models for Expensive Multi-objective Optimization](https://arxiv.org/abs/2509.03244)
*Yiming Yao,Fei Liu,Liang Zhao,Xi Lin,Qingfu Zhang*

Main category: cs.LG

TL;DR: FoMEMO引入基础模型范式，通过大规模合成数据预训练，实现昂贵多目标优化中无需领域特定训练的快速上下文优化，展现出卓越通用性和性能。


<details>
  <summary>Details</summary>
Motivation: 昂贵多目标优化对样本效率要求高，但现有方法因需要重复建模或依赖大量历史领域数据预训练而导致泛化能力差且不实用。

Method: 提出FoMEMO范式，通过数亿合成数据预训练一个基础模型。该模型能根据领域轨迹和用户偏好进行条件化，并通过预测的偏好聚合后验实现快速上下文优化，无需后续模型训练。

Result: 在各种合成基准和真实应用中，FoMEMO展现出优越的通用性，并与现有方法媲美的性能。

Conclusion: FoMEMO为昂贵多目标优化提供了一个通用、高效且无需额外训练的解决方案，能很好地适应未知问题。

Abstract: Expensive multi-objective optimization is a prevalent and crucial concern in
many real-world scenarios, where sample-efficiency is vital due to the limited
evaluations to recover the true Pareto front for decision making. Existing
works either involve rebuilding Gaussian process surrogates from scratch for
each objective in each new problem encountered, or rely on extensive past
domain experiments for pre-training deep learning models, making them hard to
generalize and impractical to cope with various emerging applications in the
real world. To address this issue, we propose a new paradigm named FoMEMO
(Foundation Models for Expensive Multi-objective Optimization), which enables
the establishment of a foundation model conditioned on any domain trajectory
and user preference, and facilitates fast in-context optimization based on the
predicted preference-wise aggregation posteriors. Rather than accessing
extensive domain experiments in the real world, we demonstrate that
pre-training the foundation model with a diverse set of hundreds of millions of
synthetic data can lead to superior adaptability to unknown problems, without
necessitating any subsequent model training or updates in the optimization
process. We evaluate our method across a variety of synthetic benchmarks and
real-word applications, and demonstrate its superior generality and competitive
performance compared to existing methods.

</details>


### [147] [Structure Transfer: an Inference-Based Calculus for the Transformation of Representations](https://arxiv.org/abs/2509.03249)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.LG

TL;DR: 提出一种系统无关的“结构转换”演算，能在不同表示系统间转换表示，并确保指定关系。


<details>
  <summary>Details</summary>
Motivation: 如何设计独立于特定表示系统（RS-agnostic）的技术来驱动表示转换与选择，是一个尚未解决的关键问题。

Method: 本文提出名为“结构转换”（structure transfer）的新型演算。该方法利用编码RS知识的“模式”（schemas），并基于表示系统理论及其“构建空间”概念进行形式化。它根据源表示和源RS生成满足指定关系（如语义等价）的目标表示。

Result: 结构转换能够实现跨多种表示系统（包括形式语言、几何图形和非正式符号等）的表示转换。它确保源表示和生成的目标表示满足任意指定关系，并且是一个系统无关的演算，可用于识别广泛实际场景中的替代表示。

Conclusion: 结构转换是一种通用的、系统无关的演算方法，能够有效地在广泛的实际应用中识别替代表示形式。

Abstract: Representation choice is of fundamental importance to our ability to
communicate and reason effectively. A major unsolved problem, addressed in this
paper, is how to devise \textit{representational-system (RS) agnostic}
techniques that drive representation transformation and choice. We present a
novel calculus, called \textit{structure transfer}, that enables representation
transformation across diverse RSs. Specifically, given a \textit{source}
representation drawn from a source RS, the rules of structure transfer allow us
to generate a \textit{target} representation for a target RS. The generality of
structure transfer comes in part from its ability to ensure that the source
representation and the generated target representation satisfy \textit{any}
specified relation (such as semantic equivalence). This is done by exploiting
\textit{schemas}, which encode knowledge about RSs. Specifically, schemas can
express \textit{preservation of information} across relations between any pair
of RSs, and this knowledge is used by structure transfer to derive a structure
for the target representation which ensures that the desired relation holds. We
formalise this using Representational Systems Theory~\cite{raggi2022rst},
building on the key concept of a \textit{construction space}. The abstract
nature of construction spaces grants them the generality to model RSs of
diverse kinds, including formal languages, geometric figures and diagrams, as
well as informal notations. Consequently, structure transfer is a
system-agnostic calculus that can be used to identify alternative
representations in a wide range of practical settings.

</details>


### [148] [HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling](https://arxiv.org/abs/2509.03260)
*Minjung Park,Gyuyeon Na,Soyoun Kim,Sunyoung Moon,HyeonJeong Cha,Sangmi Chai*

Main category: cs.LG

TL;DR: 本文提出HyPV-LEAD，一个数据驱动的早期预警框架，用于主动检测异常加密货币交易。它通过窗口-视野建模、峰谷采样和双曲嵌入等创新，有效解决类不平衡、时间波动性和复杂网络依赖问题，并在比特币数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 异常加密货币交易（如混合服务、欺诈转账、拉高出货）对金融诚信构成日益增长的风险，但由于类不平衡、时间波动性和复杂的网络依赖性，其检测难度极大。现有方法大多以模型为中心且事后响应，预防价值有限，因此需要一个能提供早期预警的预防性解决方案。

Method: 本文引入HyPV-LEAD（Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection），一个将提前期明确整合到异常检测中的数据驱动早期预警框架。它包含三项创新：1) 窗口-视野建模以确保可操作的提前期警报；2) 峰谷（PV）采样以缓解类不平衡同时保留时间连续性；3) 双曲嵌入以捕获区块链交易网络的层次性和无标度特性。该方法将异常检测从被动分类转变为主动早期预警。

Result: 在大规模比特币交易数据上的实证评估表明，HyPV-LEAD始终优于最先进的基线方法，实现了0.9624的PR-AUC，并在精确率和召回率方面获得显著提升。消融研究进一步证实，每个组件（PV采样、双曲嵌入和结构-时间建模）都提供了互补的优势，完整框架表现最佳。

Conclusion: HyPV-LEAD通过将异常检测从被动分类转向主动早期预警，为动态区块链环境中的实时风险管理、反洗钱（AML）合规性和金融安全奠定了坚实基础。

Abstract: Abnormal cryptocurrency transactions - such as mixing services, fraudulent
transfers, and pump-and-dump operations -- pose escalating risks to financial
integrity but remain notoriously difficult to detect due to class imbalance,
temporal volatility, and complex network dependencies. Existing approaches are
predominantly model-centric and post hoc, flagging anomalies only after they
occur and thus offering limited preventive value. This paper introduces
HyPV-LEAD (Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection), a
data-driven early-warning framework that explicitly incorporates lead time into
anomaly detection. Unlike prior methods, HyPV-LEAD integrates three
innovations: (1) window-horizon modeling to guarantee actionable lead-time
alerts, (2) Peak-Valley (PV) sampling to mitigate class imbalance while
preserving temporal continuity, and (3) hyperbolic embedding to capture the
hierarchical and scale-free properties of blockchain transaction networks.
Empirical evaluation on large-scale Bitcoin transaction data demonstrates that
HyPV-LEAD consistently outperforms state-of-the-art baselines, achieving a
PR-AUC of 0.9624 with significant gains in precision and recall. Ablation
studies further confirm that each component - PV sampling, hyperbolic
embedding, and structural-temporal modeling - provides complementary benefits,
with the full framework delivering the highest performance. By shifting anomaly
detection from reactive classification to proactive early-warning, HyPV-LEAD
establishes a robust foundation for real-time risk management, anti-money
laundering (AML) compliance, and financial security in dynamic blockchain
environments.

</details>


### [149] [Estudio de la eficiencia en la escalabilidad de GPUs para el entrenamiento de Inteligencia Artificial](https://arxiv.org/abs/2509.03263)
*David Cortes,Carlos Juiz,Belen Bermejo*

Main category: cs.LG

TL;DR: 本文分析了MLPerf Training v4.1在四种工作负载上的数据，发现存在能优化性能、GPU使用和效率关系的配置，并确定了一个在缩短训练时间的同时最大化效率的盈亏平衡点，以应对大规模深度学习训练的效率挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模深度学习模型训练是当前的关键挑战，尽管GPU能加速训练，但会降低效率。因此，需要寻找一种能平衡性能、GPU使用和效率的优化配置。

Method: 对MLPerf Training v4.1在BERT、Llama2 LoRA、RetinaNet和Stable Diffusion四种工作负载上报告的训练时间进行了详细分析。

Result: 分析发现存在能够优化性能、GPU使用率和效率之间关系的配置，并确定了一个在缩短训练时间的同时最大化效率的盈亏平衡点。

Conclusion: 通过识别盈亏平衡点，可以实现大规模深度学习模型训练时间的缩短，同时最大化其效率。

Abstract: Training large-scale deep learning models has become a key challenge for the
scientific community and industry. While the massive use of GPUs can
significantly speed up training times, this approach has a negative impact on
efficiency. In this article, we present a detailed analysis of the times
reported by MLPerf Training v4.1 on four workloads: BERT, Llama2 LoRA,
RetinaNet, and Stable Diffusion, showing that there are configurations that
optimise the relationship between performance, GPU usage, and efficiency. The
results point to a break-even point that allows training times to be reduced
while maximising efficiency.

</details>


### [150] [Meta-Imputation Balanced (MIB): An Ensemble Approach for Handling Missing Data in Biomedical Machine Learning](https://arxiv.org/abs/2509.03316)
*Fatemeh Azad,Zoran Bosnić,Matjaž Kukar*

Main category: cs.LG

TL;DR: 提出了一种新颖的元插补方法（MIB），通过学习结合多个基础插补器的输出来更准确地预测缺失值，以应对机器学习中数据缺失的挑战。


<details>
  <summary>Details</summary>
Motivation: 机器学习应用中，数据缺失是一个根本性挑战，会降低模型性能和可靠性，尤其在生物信息学和临床机器学习等领域。现有多种插补方法，但没有单一方法能在不同数据集和缺失机制下始终表现良好。

Method: 提出了一种名为Meta-Imputation Balanced (MIB) 的元插补方法。该方法通过训练来学习结合多个基础插补器的输出，以预测缺失值。通过在具有已知真实值的合成掩蔽数据上进行训练，系统能够根据每个基础插补器的行为预测最合适的插补值。

Result: 该方法能够更准确地预测缺失值，并根据基础插补器的行为预测最合适的插补值。

Conclusion: 这项工作突出了集成学习在插补中的潜力，并为在实际机器学习系统中构建更健壮、模块化和可解释的预处理管道铺平了道路。

Abstract: Missing data represents a fundamental challenge in machine learning
applications, often reducing model performance and reliability. This problem is
particularly acute in fields like bioinformatics and clinical machine learning,
where datasets are frequently incomplete due to the nature of both data
generation and data collection. While numerous imputation methods exist, from
simple statistical techniques to advanced deep learning models, no single
method consistently performs well across diverse datasets and missingness
mechanisms. This paper proposes a novel Meta-Imputation approach that learns to
combine the outputs of multiple base imputers to predict missing values more
accurately. By training the proposed method called Meta-Imputation Balanced
(MIB) on synthetically masked data with known ground truth, the system learns
to predict the most suitable imputed value based on the behavior of each
method. Our work highlights the potential of ensemble learning in imputation
and paves the way for more robust, modular, and interpretable preprocessing
pipelines in real-world machine learning systems.

</details>


### [151] [EvolveSignal: A Large Language Model Powered Coding Agent for Discovering Traffic Signal Control Algorithms](https://arxiv.org/abs/2509.03335)
*Leizhen Wang,Peibo Duan,Hao Wang,Yue Wang,Jian Xu,Nan Zheng,Zhenliang Ma*

Main category: cs.LG

TL;DR: EvolveSignal利用大型语言模型（LLMs）作为编程代理，自动发现交通信号控制算法，其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 固定时间交通信号控制因其成本低、稳定性和可解释性而被广泛使用，但其设计依赖人工公式和手动调整，导致耗时且在复杂交通条件下效果不佳。

Method: 将问题表述为程序合成，其中候选算法被表示为具有固定输入输出结构的Python函数。通过外部评估（如交通模拟器）和进化搜索，利用LLM作为编码代理迭代优化这些算法。

Result: 实验证明，所发现的算法优于Webster基线，平均延误降低了20.1%，平均停车次数降低了47.1%。此外，消融和增量分析为交通工程师提供了实际有意义的见解。

Conclusion: 这项工作通过利用人工智能进行交通信号控制算法设计，开辟了新的研究方向，将程序合成与交通工程相结合。

Abstract: In traffic engineering, the fixed-time traffic signal control remains widely
used for its low cost, stability, and interpretability. However, its design
depends on hand-crafted formulas (e.g., Webster) and manual re-timing by
engineers to adapt to demand changes, which is labor-intensive and often yields
suboptimal results under heterogeneous or congested conditions. This paper
introduces the EvolveSignal, a large language models (LLMs) powered coding
agent to automatically discover new traffic signal control algorithms. We
formulate the problem as program synthesis, where candidate algorithms are
represented as Python functions with fixed input-output structures, and
iteratively optimized through external evaluations (e.g., a traffic simulator)
and evolutionary search. Experiments on a signalized intersection demonstrate
that the discovered algorithms outperform Webster's baseline, reducing average
delay by 20.1% and average stops by 47.1%. Beyond performance, ablation and
incremental analyses reveal that EvolveSignal modifications-such as adjusting
cycle length bounds, incorporating right-turn demand, and rescaling green
allocations-can offer practically meaningful insights for traffic engineers.
This work opens a new research direction by leveraging AI for algorithm design
in traffic signal control, bridging program synthesis with transportation
engineering.

</details>


### [152] [Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems](https://arxiv.org/abs/2509.03340)
*Fleur Hendriks,Ondřej Rokoš,Martin Doškář,Marc G. D. Geers,Vlado Menkovski*

Main category: cs.LG

TL;DR: 提出一种基于流匹配的生成框架，用于在分岔现象中捕获多模态分布和对称破缺，该方法通过等变建模和对称匹配策略，显著优于现有非概率和变分方法。


<details>
  <summary>Details</summary>
Motivation: 非线性动力系统中的分岔现象常导致多重共存稳定解和对称破缺。然而，确定性机器学习模型难以捕捉这种多重性，倾向于平均解而无法表示低对称性结果。

Method: 本文提出一个基于流匹配的生成框架，通过等变建模和引入对称匹配策略，来建模分岔结果的完整概率分布，从而能够直接采样多个有效解并保留系统对称性。

Result: 该方法在从玩具模型到复杂物理问题（如屈曲梁和Allen-Cahn方程）的广泛系统上，在捕获多模态分布和对称破缺分岔方面，显著优于非概率和变分方法。

Conclusion: 所提出的流匹配方法为高维系统中的多稳态建模提供了一个原则性且可扩展的解决方案。

Abstract: Bifurcation phenomena in nonlinear dynamical systems often lead to multiple
coexisting stable solutions, particularly in the presence of symmetry breaking.
Deterministic machine learning models struggle to capture this multiplicity,
averaging over solutions and failing to represent lower-symmetry outcomes. In
this work, we propose a generative framework based on flow matching to model
the full probability distribution over bifurcation outcomes. Our method enables
direct sampling of multiple valid solutions while preserving system symmetries
through equivariant modeling. We introduce a symmetric matching strategy that
aligns predicted and target outputs under group actions, allowing accurate
learning in equivariant settings. We validate our approach on a range of
systems, from toy models to complex physical problems such as buckling beams
and the Allen-Cahn equation. Our results demonstrate that flow matching
significantly outperforms non-probabilistic and variational methods in
capturing multimodal distributions and symmetry-breaking bifurcations, offering
a principled and scalable solution for modeling multistability in
high-dimensional systems.

</details>


### [153] [On the MIA Vulnerability Gap Between Private GANs and Diffusion Models](https://arxiv.org/abs/2509.03341)
*Ilana Sebag,Jean-Yves Franceschi,Alain Rakotomamonjy,Alexandre Allauzen,Jamal Atif*

Main category: cs.LG

TL;DR: 研究发现，在差分隐私（DP）训练下，生成对抗网络（GANs）比扩散模型对成员推理攻击（MIAs）具有更高的隐私鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虽然GANs和扩散模型都能在差分隐私（DP）下训练以保护敏感数据，但它们对作为数据保密性关键威胁的成员推理攻击（MIAs）的敏感性仍不明确。

Method: 本研究首先通过基于稳定性的理论分析，比较了GANs和扩散模型对数据扰动的敏感性。随后，采用标准化的MIA流程进行了全面的实证研究，评估了不同数据集和隐私预算下的隐私泄露情况。

Result: 理论分析表明，GANs对数据扰动的敏感性本质上低于扩散模型，暗示其在抵抗MIA方面具有结构性优势。实证研究一致显示，即使在强差分隐私（DP）制度下，GANs在隐私鲁棒性方面也显著优于扩散模型，揭示了明显的隐私鲁棒性差距。

Conclusion: 模型类型本身就能显著影响隐私泄露的程度，GANs在差分隐私生成模型中表现出更强的隐私鲁棒性，能够更好地抵御成员推理攻击。

Abstract: Generative Adversarial Networks (GANs) and diffusion models have emerged as
leading approaches for high-quality image synthesis. While both can be trained
under differential privacy (DP) to protect sensitive data, their sensitivity to
membership inference attacks (MIAs), a key threat to data confidentiality,
remains poorly understood. In this work, we present the first unified
theoretical and empirical analysis of the privacy risks faced by differentially
private generative models. We begin by showing, through a stability-based
analysis, that GANs exhibit fundamentally lower sensitivity to data
perturbations than diffusion models, suggesting a structural advantage in
resisting MIAs. We then validate this insight with a comprehensive empirical
study using a standardized MIA pipeline to evaluate privacy leakage across
datasets and privacy budgets. Our results consistently reveal a marked privacy
robustness gap in favor of GANs, even in strong DP regimes, highlighting that
model type alone can critically shape privacy leakage.

</details>


### [154] [epiGPTope: A machine learning-based epitope generator and classifier](https://arxiv.org/abs/2509.03351)
*Natalia Flechas Manrique,Alberto Martínez,Elena López-Martínez,Luc Andrea,Román Orus,Aitor Manteca,Aitziber L. Cortajarena,Llorenç Espinosa-Portalés*

Main category: cs.LG

TL;DR: 本研究提出并训练了一个大型语言模型epiGPTope，能够直接生成具有已知表位统计特性的新型表位样序列，并结合统计分类器预测其来源，以实现更快速、更经济的合成表位发现。


<details>
  <summary>Details</summary>
Motivation: 合成表位库的合理设计因其巨大的组合序列空间而极具挑战性，即使使用高通量技术也难以进行筛选和测试，但表位对于免疫疗法、疫苗和诊断至关重要。

Method: 开发了一个大型语言模型epiGPTope，该模型首先在蛋白质数据上进行预训练，然后针对线性表位进行微调，以直接生成新型表位样序列。此外，还训练了统计分类器来预测表位序列的细菌或病毒来源。该方法仅使用线性表位的初级氨基酸序列，无需几何框架或人工设计特征。

Result: epiGPTope首次能够直接生成新型表位样序列，这些序列被发现具有与已知表位相似的统计特性。这种生成方法可用于制备表位候选序列库。进一步训练的分类器能预测表位序列的细菌或病毒来源，从而缩小候选库并提高识别特定表位的可能性。

Conclusion: 结合生成模型（epiGPTope）和预测模型的方法有助于表位发现。通过开发一种创建生物学可行序列的方法，有望实现更快、更具成本效益的合成表位生成和筛选，在新型生物技术开发中具有重要应用价值。

Abstract: Epitopes are short antigenic peptide sequences which are recognized by
antibodies or immune cell receptors. These are central to the development of
immunotherapies, vaccines, and diagnostics. However, the rational design of
synthetic epitope libraries is challenging due to the large combinatorial
sequence space, $20^n$ combinations for linear epitopes of n amino acids,
making screening and testing unfeasible, even with high throughput experimental
techniques. In this study, we present a large language model, epiGPTope,
pre-trained on protein data and specifically fine-tuned on linear epitopes,
which for the first time can directly generate novel epitope-like sequences,
which are found to possess statistical properties analogous to the ones of
known epitopes. This generative approach can be used to prepare libraries of
epitope candidate sequences. We further train statistical classifiers to
predict whether an epitope sequence is of bacterial or viral origin, thus
narrowing the candidate library and increasing the likelihood of identifying
specific epitopes. We propose that such combination of generative and
predictive models can be of assistance in epitope discovery. The approach uses
only primary amino acid sequences of linear epitopes, bypassing the need for a
geometric framework or hand-crafted features of the sequences. By developing a
method to create biologically feasible sequences, we anticipate faster and more
cost-effective generation and screening of synthetic epitopes, with relevant
applications in the development of new biotechnologies.

</details>


### [155] [Fair Resource Allocation for Fleet Intelligence](https://arxiv.org/abs/2509.03353)
*Oguzhan Baser,Kaan Kale,Po-han Li,Sandeep Chinchali*

Main category: cs.LG

TL;DR: 本文针对云辅助多智能体智能中资源分配不公和效率低下的问题，提出了开源算法框架Fair-Synergy。该框架利用智能体精度与资源间的凹关系实现公平分配，并在多智能体推理和学习任务中显著超越传统基准，同时提供了关于公平性影响的见解。


<details>
  <summary>Details</summary>
Motivation: 云辅助多智能体智能的资源分配对性能优化至关重要，但传统方法常忽略智能体计算能力多样性和复杂操作环境，导致资源分配低效且不公平。

Method: 本文开发并开源了Fair-Synergy算法框架，该框架利用智能体精度与系统资源之间的凹关系，确保跨智能体集群的公平资源分配。方法将传统分配扩展到一个由模型参数、训练数据量和任务复杂度定义的多维机器学习效用空间。通过使用BERT、VGG16、MobileNet、ResNets等高级模型和MNIST、CIFAR-10、CIFAR-100、BDD、GLUE等数据集对Fair-Synergy进行了评估。

Result: Fair-Synergy在多智能体推理设置中比标准基准高出25%，在多智能体学习设置中高出11%。此外，研究还探讨了公平性水平如何影响最弱势、最强势和平均智能体的表现。

Conclusion: Fair-Synergy框架提供了一种有效且公平的云辅助多智能体智能资源分配解决方案，通过显著的性能提升和对公平性影响的深入分析，为构建公平的智能体集群提供了宝贵的见解。

Abstract: Resource allocation is crucial for the performance optimization of
cloud-assisted multi-agent intelligence. Traditional methods often overlook
agents' diverse computational capabilities and complex operating environments,
leading to inefficient and unfair resource distribution. To address this, we
open-sourced Fair-Synergy, an algorithmic framework that utilizes the concave
relationship between the agents' accuracy and the system resources to ensure
fair resource allocation across fleet intelligence. We extend traditional
allocation approaches to encompass a multidimensional machine learning utility
landscape defined by model parameters, training data volume, and task
complexity. We evaluate Fair-Synergy with advanced vision and language models
such as BERT, VGG16, MobileNet, and ResNets on datasets including MNIST,
CIFAR-10, CIFAR-100, BDD, and GLUE. We demonstrate that Fair-Synergy
outperforms standard benchmarks by up to 25% in multi-agent inference and 11%
in multi-agent learning settings. Also, we explore how the level of fairness
affects the least advantaged, most advantaged, and average agents, providing
insights for equitable fleet intelligence.

</details>


### [156] [Some patterns of sleep quality and Daylight Saving Time across countries: a predictive and exploratory analysis](https://arxiv.org/abs/2509.03358)
*Bhanu Sharma,Eugene Pinsky*

Main category: cs.LG

TL;DR: 该研究分析了61个国家的平均睡眠时长，发现夏令时对睡眠的影响因地理位置（纬度）而异。


<details>
  <summary>Details</summary>
Motivation: 考察夏令时（DST）实践对各国平均睡眠时长的影响。

Method: 分析了61个国家的平均睡眠时长，识别了影响睡眠的关键指标，应用统计相关性分析，根据夏令时实行情况对国家进行分组，并通过可视化比较睡眠模式。

Result: 总体而言，实行夏令时的国家平均睡眠时长倾向于更长。然而，在低纬度地区，实行夏令时的国家睡眠时长较短；在高纬度地区，实行夏令时的国家平均睡眠时长较长。

Conclusion: 夏令时对睡眠的影响可能受地理位置（纬度）的调节。

Abstract: In this study we analyzed average sleep durations across 61 countries to
examine the impact of Daylight Saving Time (DST) practices. Key metrics
influencing sleep were identified, and statistical correlation analysis was
applied to explore relationships among these factors. Countries were grouped
based on DST observance, and visualizations compared sleep patterns between DST
and non-DST regions. Results show that, on average, countries observing DST
tend to report longer sleep durations than those that do not. A more detailed
pattern emerged when accounting for latitude: at lower latitudes, DST-observing
countries reported shorter sleep durations compared to non-DST countries, while
at higher latitudes, DST-observing countries reported longer average sleep
durations. These findings suggest that the influence of DST on sleep may be
moderated by geographical location.

</details>


### [157] [The distribution of calibrated likelihood functions on the probability-likelihood Aitchison simplex](https://arxiv.org/abs/2509.03365)
*Paul-Gauthier Noé,Andreas Nautsch,Driss Matrouf,Pierre-Michel Bousquet,Jean-François Bonastre*

Main category: cs.LG

TL;DR: 本文将对数似然比（LLR）校准、幂等性及其分布约束从二元假设扩展到多元假设场景，利用Aitchison几何定义了等距对数比变换似然函数，并展示了其在提高机器学习方法可解释性和可靠性方面的应用。


<details>
  <summary>Details</summary>
Motivation: 概率预测校准已被广泛研究，但似然函数校准研究较少，且现有关于对数似然比（LLR）校准、幂等性及其分布约束的成果仅限于二元假设情况，缺乏对多元假设场景的扩展。

Method: 首先定义了LLR的校准及其与证据权重的联系，回顾了二元情况下的幂等性及其分布约束。然后，利用Aitchison单纯形几何将这些概念（校准、幂等性、分布约束）扩展到多元假设情况，并引入了等距对数比变换似然函数。最后，将其应用于非线性判别分析以证明其实用性。

Result: 成功将似然函数校准、幂等性定义及分布约束扩展到多于两个假设的场景，并通过等距对数比变换似然函数实现。以向量形式恢复了贝叶斯规则的加性形式。在机器学习的非线性判别分析中，判别分量形成了校准的似然函数，显著提高了方法的解释性和可靠性。

Conclusion: 本工作为将校准的似然函数推广到多类别场景提供了概念框架，并通过实际应用证明了其在提高机器学习方法（如非线性判别分析）可解释性和可靠性方面的潜力。

Abstract: While calibration of probabilistic predictions has been widely studied, this
paper rather addresses calibration of likelihood functions. This has been
discussed, especially in biometrics, in cases with only two exhaustive and
mutually exclusive hypotheses (classes) where likelihood functions can be
written as log-likelihood-ratios (LLRs). After defining calibration for LLRs
and its connection with the concept of weight-of-evidence, we present the
idempotence property and its associated constraint on the distribution of the
LLRs. Although these results have been known for decades, they have been
limited to the binary case. Here, we extend them to cases with more than two
hypotheses by using the Aitchison geometry of the simplex, which allows us to
recover, in a vector form, the additive form of the Bayes' rule; extending
therefore the LLR and the weight-of-evidence to any number of hypotheses.
Especially, we extend the definition of calibration, the idempotence, and the
constraint on the distribution of likelihood functions to this multiple
hypotheses and multiclass counterpart of the LLR: the isometric-log-ratio
transformed likelihood function. This work is mainly conceptual, but we still
provide one application to machine learning by presenting a non-linear
discriminant analysis where the discriminant components form a calibrated
likelihood function over the classes, improving therefore the interpretability
and the reliability of the method.

</details>


### [158] [Cluster and then Embed: A Modular Approach for Visualization](https://arxiv.org/abs/2509.03373)
*Elizabeth Coda,Ery Arias-Castro,Gal Mishne*

Main category: cs.LG

TL;DR: 针对t-SNE和UMAP在全局几何失真问题，本文提出了一种更透明、模块化的降维方法，通过先聚类再嵌入和对齐来获得全局嵌入。


<details>
  <summary>Details</summary>
Motivation: 尽管t-SNE和UMAP等降维方法在保留局部信息和可视化聚类结构方面表现良好，但它们倾向于扭曲数据的全局几何结构。

Method: 提出一种更透明、模块化的方法，包括三个步骤：首先对数据进行聚类，然后分别嵌入每个聚类，最后对齐这些聚类以获得全局嵌入。

Result: 该方法在多个合成和真实世界数据集上进行了验证，结果表明其性能与现有方法具有竞争力。

Conclusion: 本文提出的模块化降维方法不仅与现有方法性能相当，而且具有更高的透明度。

Abstract: Dimensionality reduction methods such as t-SNE and UMAP are popular methods
for visualizing data with a potential (latent) clustered structure. They are
known to group data points at the same time as they embed them, resulting in
visualizations with well-separated clusters that preserve local information
well. However, t-SNE and UMAP also tend to distort the global geometry of the
underlying data. We propose a more transparent, modular approach consisting of
first clustering the data, then embedding each cluster, and finally aligning
the clusters to obtain a global embedding. We demonstrate this approach on
several synthetic and real-world datasets and show that it is competitive with
existing methods, while being much more transparent.

</details>


### [159] [Exploring a Graph-based Approach to Offline Reinforcement Learning for Sepsis Treatment](https://arxiv.org/abs/2509.03393)
*Taisiya Khakharova,Lucas Sakizloglou,Leen Lambers*

Main category: cs.LG

TL;DR: 该研究将MIMIC-III数据建模为异构图，利用GNN学习败血症患者状态表示，并通过dBCQ进行策略学习，验证了图方法在复杂医疗决策中的潜力。


<details>
  <summary>Details</summary>
Motivation: 败血症治疗中输液量和血管升压药的决策具有挑战性。现有强化学习方法依赖关系型数据，难以有效处理现代医疗数据的复杂性。将医疗数据表示为图可能提供更自然、有效的方法来支持这些决策。

Method: 将MIMIC-III数据集中的患者数据建模为随时间演变的异构图。采用GraphSAGE和GATv2两种图神经网络架构进行患者状态表示学习，并将表示学习与策略学习解耦。编码器与预测下一患者状态的解码器联合训练以生成潜在状态表示。最后，这些表示被用于dBCQ算法进行策略学习。

Result: 实验评估结果证实了图方法在败血症治疗决策中的潜力，同时也强调了在该领域进行表示学习的复杂性。

Conclusion: 图神经网络结合强化学习为败血症等复杂医疗决策提供了有前景的途径，但有效地从复杂医疗图中学习患者状态表示仍然是一个关键挑战。

Abstract: Sepsis is a serious, life-threatening condition. When treating sepsis, it is
challenging to determine the correct amount of intravenous fluids and
vasopressors for a given patient. While automated reinforcement learning
(RL)-based methods have been used to support these decisions with promising
results, previous studies have relied on relational data. Given the complexity
of modern healthcare data, representing data as a graph may provide a more
natural and effective approach. This study models patient data from the
well-known MIMIC-III dataset as a heterogeneous graph that evolves over time.
Subsequently, we explore two Graph Neural Network architectures - GraphSAGE and
GATv2 - for learning patient state representations, adopting the approach of
decoupling representation learning from policy learning. The encoders are
trained to produce latent state representations, jointly with decoders that
predict the next patient state. These representations are then used for policy
learning with the dBCQ algorithm. The results of our experimental evaluation
confirm the potential of a graph-based approach, while highlighting the
complexity of representation learning in this domain.

</details>


### [160] [Beyond Correctness: Harmonizing Process and Outcome Rewards through RL Training](https://arxiv.org/abs/2509.03403)
*Chenlu Ye,Zhou Yu,Ziji Zhang,Hao Chen,Narayanan Sadagopan,Jing Huang,Tong Zhang,Anurag Beniwal*

Main category: cs.LG

TL;DR: 本文提出PRocess cOnsistency Filter (PROF) 方法，通过一致性驱动的样本选择，有效协调了强化学习中过程奖励和结果奖励的互补优势，显著提升了数学推理任务的准确性和中间推理步骤的质量。


<details>
  <summary>Details</summary>
Motivation: 在可验证奖励强化学习（RLVR）中，结果奖励模型（ORMs）粒度过粗，无法有效区分正确答案中的错误推理或错误答案中的有效推理，导致梯度噪声并阻碍推理质量提升。而过程奖励模型（PRMs）虽然提供细粒度指导，但常不准确且易受奖励劫持，这构成了一个困境。

Method: 本文引入PRocess cOnsistency Filter (PROF)，这是一种数据过程筛选方法。PROF通过一致性驱动的样本选择，而非简单的目标函数融合，来协调噪声细粒度过程奖励（PRM）与准确粗粒度结果奖励（ORM）。具体而言，它保留具有较高平均过程值的正确响应和较低平均过程值的错误响应，同时维持正负训练样本的平衡。

Result: 实验结果表明，与现有融合方法相比，PROF能一致性地将最终准确率提高超过4%。此外，该方法还显著提升了中间推理步骤的质量。

Conclusion: PROF方法通过有效整合过程奖励和结果奖励的互补优势，成功解决了RLVR中的困境，不仅显著提高了数学推理任务的准确性，还加强了推理过程的质量。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged to be a
predominant paradigm for mathematical reasoning tasks, offering stable
improvements in reasoning ability. However, Outcome Reward Models (ORMs) in
RLVR are too coarse-grained to distinguish flawed reasoning within correct
answers or valid reasoning within incorrect answers. This lack of granularity
introduces noisy and misleading gradients significantly and hinders further
progress in reasoning process quality. While Process Reward Models (PRMs) offer
fine-grained guidance for intermediate steps, they frequently suffer from
inaccuracies and are susceptible to reward hacking.
  To resolve this dilemma, we introduce PRocess cOnsistency Filter (PROF), an
effective data process curation method that harmonizes noisy, fine-grained
process rewards with accurate, coarse-grained outcome rewards. Rather than
naively blending PRM and ORM in the objective function
(arXiv:archive/2506.18896), PROF leverages their complementary strengths
through consistency-driven sample selection. Our approach retains correct
responses with higher averaged process values and incorrect responses with
lower averaged process values, while maintaining positive/negative training
sample balance. Extensive experiments demonstrate that our method not only
consistently improves the final accuracy over $4\%$ compared to the blending
approaches, but also strengthens the quality of intermediate reasoning steps.
Codes and training recipes are available at https://github.com/Chenluye99/PROF.

</details>


### [161] [Initialization Schemes for Kolmogorov-Arnold Networks: An Empirical Study](https://arxiv.org/abs/2509.03417)
*Spyros Rigas,Dhruv Verma,Georgios Alexandridis,Yixuan Wang*

Main category: cs.LG

TL;DR: 本研究探讨了Kolmogorov-Arnold Networks (KANs) 的初始化策略，提出了两种理论驱动（LeCun和Glorot启发）和一种经验性幂律初始化方案。结果显示，幂律初始化在多种任务和不同规模的KANs中表现最佳，Glorot启发式初始化在参数丰富的模型中优于基线。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov-Arnold Networks (KANs) 是一种具有增强灵活性和可解释性的新型神经网络架构，尽管在多项任务中取得了成功，但其初始化策略尚未得到充分探索。

Method: 1. 提出了两种理论驱动的初始化方案，灵感来源于LeCun和Glorot。2. 提出了一个具有可调指数的经验性幂律族初始化方案。3. 评估方法包括：在函数拟合和前向偏微分方程基准上进行大规模网格搜索，通过神经正切核（NTK）分析训练动态，以及在费曼数据集的一个子集上进行评估。

Result: 1. Glorot启发式初始化在参数丰富的模型中显著优于基线。2. 幂律初始化在各种任务和不同规模的架构中都实现了最强的整体性能。

Conclusion: 本研究提出的幂律初始化方案对于KANs而言表现出最强的整体性能，而Glorot启发式初始化在参数丰富的模型中也表现出色，为KANs的有效训练提供了重要的初始化策略指导。

Abstract: Kolmogorov-Arnold Networks (KANs) are a recently introduced neural
architecture that replace fixed nonlinearities with trainable activation
functions, offering enhanced flexibility and interpretability. While KANs have
been applied successfully across scientific and machine learning tasks, their
initialization strategies remain largely unexplored. In this work, we study
initialization schemes for spline-based KANs, proposing two theory-driven
approaches inspired by LeCun and Glorot, as well as an empirical power-law
family with tunable exponents. Our evaluation combines large-scale grid
searches on function fitting and forward PDE benchmarks, an analysis of
training dynamics through the lens of the Neural Tangent Kernel, and
evaluations on a subset of the Feynman dataset. Our findings indicate that the
Glorot-inspired initialization significantly outperforms the baseline in
parameter-rich models, while power-law initialization achieves the strongest
performance overall, both across tasks and for architectures of varying size.
All code and data accompanying this manuscript are publicly available at
https://github.com/srigas/KAN_Initialization_Schemes.

</details>


### [162] [LINKER: Learning Interactions Between Functional Groups and Residues With Chemical Knowledge-Enhanced Reasoning and Explainability](https://arxiv.org/abs/2509.03425)
*Phuc Pham,Viet Thanh Duy Nguyen,Truong-Son Hy*

Main category: cs.LG

TL;DR: LINKER是一个创新的序列-基于模型，仅通过蛋白质序列和配体SMILES输入，预测生物学定义的蛋白质-配体功能组相互作用类型，克服了传统方法对3D结构数据的依赖，并在实验中表现出高准确性。


<details>
  <summary>Details</summary>
Motivation: 准确识别蛋白质残基与配体功能组的相互作用对理解分子识别和指导药物设计至关重要。然而，现有深度学习方法依赖3D结构输入或使用距离-基于的接触标签，这限制了其适用性和生物学相关性。

Method: 本研究引入了LINKER模型，该模型是首个仅使用蛋白质序列和配体SMILES作为输入，预测生物学定义相互作用类型的序列-基于模型。LINKER通过结构监督注意力进行训练，交互标签从3D蛋白质-配体复合物中通过功能组-基于的基序提取。该模型将配体结构抽象为功能组，专注于预测化学意义上的相互作用类型。

Result: LINKER在推断时仅需序列级输入，支持在结构数据不可用场景下的大规模应用。在LP-PDBBind基准测试中，其基于结构-信息监督的功能组抽象方法，产生的相互作用预测与地面真实生化注释高度一致。

Conclusion: LINKER成功提供了一种高效且广泛适用的序列-基于方法，用于预测生物学相关的蛋白质-配体相互作用类型，解决了传统方法对3D结构数据的依赖问题，并被证明能够提供与生化注释高度一致的预测。

Abstract: Accurate identification of interactions between protein residues and ligand
functional groups is essential to understand molecular recognition and guide
rational drug design. Existing deep learning approaches for protein-ligand
interpretability often rely on 3D structural input or use distance-based
contact labels, limiting both their applicability and biological relevance. We
introduce LINKER, the first sequence-based model to predict residue-functional
group interactions in terms of biologically defined interaction types, using
only protein sequences and the ligand SMILES as input. LINKER is trained with
structure-supervised attention, where interaction labels are derived from 3D
protein-ligand complexes via functional group-based motif extraction. By
abstracting ligand structures into functional groups, the model focuses on
chemically meaningful substructures while predicting interaction types rather
than mere spatial proximity. Crucially, LINKER requires only sequence-level
input at inference time, enabling large-scale application in settings where
structural data is unavailable. Experiments on the LP-PDBBind benchmark
demonstrate that structure-informed supervision over functional group
abstractions yields interaction predictions closely aligned with ground-truth
biochemical annotations.

</details>


### [163] [Graph neural networks for learning liquid simulations in dynamic scenes containing kinematic objects](https://arxiv.org/abs/2509.03446)
*Niteesh Midlagajni,Constantin A. Rothkopf*

Main category: cs.LG

TL;DR: 本文提出了一个基于图神经网络（GNN）的框架，用于学习液体在刚体交互和主动操作下的动力学，该模型能准确模拟复杂场景，并具有良好的泛化能力和在控制任务中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动（特别是GNN）的流体动力学学习方法通常局限于静态自由落体环境或简单的操作设置，难以处理与动态刚体相关的复杂交互。

Method: 该研究提出了一个GNN框架，将流体粒子表示为图节点，并利用边界体积层次结构（BVH）算法结合表面表示来处理粒子-物体碰撞。这种方法使得网络能够建模液体粒子与复杂表面几何形状之间的交互。

Result: 模型能准确捕捉动态环境下的流体行为，并可作为静态自由落体环境的模拟器。尽管仅通过单一的倾倒任务进行训练，模型仍能有效泛化到未见物体和搅拌、舀取等新颖操作任务。此外，学习到的动力学可以利用基于梯度的优化方法来解决控制和操作任务。

Conclusion: 该GNN框架成功学习了液体在刚体交互和主动操作下的复杂动力学，展示了强大的泛化能力，并为解决现实世界中的流体控制和操作任务提供了一种有效方法。

Abstract: Simulating particle dynamics with high fidelity is crucial for solving
real-world interaction and control tasks involving liquids in design, graphics,
and robotics. Recently, data-driven approaches, particularly those based on
graph neural networks (GNNs), have shown progress in tackling such problems.
However, these approaches are often limited to learning fluid behavior in
static free-fall environments or simple manipulation settings involving
primitive objects, often overlooking complex interactions with dynamically
moving kinematic rigid bodies. Here, we propose a GNN-based framework designed
from the ground up to learn the dynamics of liquids under rigid body
interactions and active manipulations, where particles are represented as graph
nodes and particle-object collisions are handled using surface representations
with the bounding volume hierarchy (BVH) algorithm. This approach enables the
network to model complex interactions between liquid particles and intricate
surface geometries. Our model accurately captures fluid behavior in dynamic
settings and can also function as a simulator in static free-fall environments.
Despite being trained on a single-object manipulation task of pouring, our
model generalizes effectively to environments with unseen objects and novel
manipulation tasks such as stirring and scooping. Finally, we show that the
learned dynamics can be leveraged to solve control and manipulation tasks using
gradient-based optimization methods.

</details>


### [164] [DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling](https://arxiv.org/abs/2509.03472)
*Yubo Gao,Renbo Tu,Gennady Pekhimenko,Nandita Vijaykumar*

Main category: cs.LG

TL;DR: DP-SGD结合量化会导致显著的精度下降。本文提出QPQuant，一个动态量化框架，通过概率采样和损失感知层优先级策略，有效降低量化方差，显著提高DP-SGD量化训练的性能，实现计算效率和模型准确性的平衡。


<details>
  <summary>Details</summary>
Motivation: DP-SGD是保护隐私的强大技术，而量化能大幅降低训练成本。然而，研究发现DP-SGD中引入的噪声会放大量化方差，导致比常规SGD更高的精度下降，因此需要解决这一挑战。

Method: 本文提出QPQuant，一个动态量化框架，在每个训练周期自适应地选择一个变化的层子集进行量化。该方法结合了两个关键思想：(i) 对层进行概率采样，每个周期轮换量化层；(ii) 损失感知层优先级，使用消耗极少隐私预算的差分隐私损失敏感度估计器来识别对模型质量影响最小的可量化层。

Result: 在ResNet18、ResNet50和DenseNet121等模型及多个数据集上的评估表明，QPQuant持续优于静态量化基线，实现了接近帕累托最优的准确性-计算权衡，在低精度硬件上理论吞吐量提高了高达2.21倍，且验证准确率下降不到2%。

Conclusion: QPQuant通过动态自适应量化策略，成功解决了DP-SGD中量化导致的精度显著下降问题，在保持差分隐私保证的同时，显著提升了计算效率和模型性能，为差分隐私神经网络的训练提供了更优的解决方案。

Abstract: Differentially-Private SGD (DP-SGD) is a powerful technique to protect user
privacy when using sensitive data to train neural networks. During training,
converting model weights and activations into low-precision formats, i.e.,
quantization, can drastically reduce training times, energy consumption, and
cost, and is thus a widely used technique. In this work, we demonstrate that
quantization causes significantly higher accuracy degradation in DP-SGD
compared to regular SGD. We observe that this is caused by noise injection in
DP-SGD, which amplifies quantization variance, leading to disproportionately
large accuracy degradation. To address this challenge, we present QPQuant, a
dynamic quantization framework that adaptively selects a changing subset of
layers to quantize at each epoch. Our method combines two key ideas that
effectively reduce quantization variance: (i) probabilistic sampling of the
layers that rotates which layers are quantized every epoch, and (ii) loss-aware
layer prioritization, which uses a differentially private loss sensitivity
estimator to identify layers that can be quantized with minimal impact on model
quality. This estimator consumes a negligible fraction of the overall privacy
budget, preserving DP guarantees. Empirical evaluations on ResNet18, ResNet50,
and DenseNet121 across a range of datasets demonstrate that DPQuant
consistently outperforms static quantization baselines, achieving near
Pareto-optimal accuracy-compute trade-offs and up to 2.21x theoretical
throughput improvements on low-precision hardware, with less than 2% drop in
validation accuracy.

</details>


### [165] [Geometric Foundations of Tuning without Forgetting in Neural ODEs](https://arxiv.org/abs/2509.03474)
*Erkan Bayram,Mohamed-Ali Belabbas,Tamer Başar*

Main category: cs.LG

TL;DR: 本文为神经ODE序贯训练中的“无遗忘微调”(TwF)原理提供了严格的理论基础，通过证明其参数子空间构成一个Banach子流形并刻画其切空间，从而解释了TwF精确的映射保持特性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究工作引入了TwF原理以实现神经ODE的序贯训练，旨在通过控制函数子空间来保留先前学习样本的端点映射，但其在超越一阶近似的情况下实现精确映射保持的理论基础尚未完全阐明。

Method: 本文证明了TwF中用于参数更新的控制函数子空间在非奇异控制下形成一个有限余维的Banach子流形，并详细刻画了其切空间。

Result: 研究结果表明，TwF所操作的参数子空间是一个有限余维的Banach子流形，并且成功刻画了其切空间。这揭示了TwF本质上是沿着该Banach子流形切空间对控制函数进行的延续/形变。

Conclusion: 这一理论发现为TwF在序贯训练过程中实现精确的、超越一阶近似的映射保持（即无遗忘）特性提供了坚实的理论基础和严谨的解释。

Abstract: In our earlier work, we introduced the principle of Tuning without Forgetting
(TwF) for sequential training of neural ODEs, where training samples are added
iteratively and parameters are updated within the subspace of control functions
that preserves the end-point mapping at previously learned samples on the
manifold of output labels in the first-order approximation sense. In this
letter, we prove that this parameter subspace forms a Banach submanifold of
finite codimension under nonsingular controls, and we characterize its tangent
space. This reveals that TwF corresponds to a continuation/deformation of the
control function along the tangent space of this Banach submanifold, providing
a theoretical foundation for its mapping-preserving (not forgetting) during the
sequential training exactly, beyond first-order approximation.

</details>


### [166] [Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning](https://arxiv.org/abs/2509.03477)
*Duy A. Nguyen,Abhi Kamboj,Minh N. Do*

Main category: cs.LG

TL;DR: Robult是一个可扩展的多模态学习框架，通过软PU对比损失和潜在重建损失，解决了模态缺失和标注数据有限的挑战，在半监督和模态缺失场景中均表现优越。


<details>
  <summary>Details</summary>
Motivation: 多模态学习面临模态数据缺失和标注数据有限的严峻挑战，这阻碍了鲁棒多模态学习的进步。

Method: 本文提出了Robult框架，通过保留模态特定信息和利用信息理论方法发现的冗余来缓解上述挑战。Robult优化两个核心目标：1. 软正-未标记（PU）对比损失，用于最大化任务相关特征对齐并在半监督设置中有效利用有限标注数据；2. 潜在重建损失，用于确保保留独特的模态特定信息。这些策略嵌入在模块化设计中。

Result: 在多个数据集上的实验结果表明，Robult在半监督学习和模态缺失情境下均优于现有方法。此外，其轻量化设计促进了可扩展性，并可与现有架构无缝集成。

Conclusion: Robult提供了一种有效且可扩展的解决方案，提升了多模态学习在模态缺失和有限标注数据情况下的性能，使其适用于真实的跨模态应用。

Abstract: Addressing missing modalities and limited labeled data is crucial for
advancing robust multimodal learning. We propose Robult, a scalable framework
designed to mitigate these challenges by preserving modality-specific
information and leveraging redundancy through a novel information-theoretic
approach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled
(PU) contrastive loss that maximizes task-relevant feature alignment while
effectively utilizing limited labeled data in semi-supervised settings, and (2)
a latent reconstruction loss that ensures unique modality-specific information
is retained. These strategies, embedded within a modular design, enhance
performance across various downstream tasks and ensure resilience to incomplete
modalities during inference. Experimental results across diverse datasets
validate that Robult achieves superior performance over existing approaches in
both semi-supervised learning and missing modality contexts. Furthermore, its
lightweight design promotes scalability and seamless integration with existing
architectures, making it suitable for real-world multimodal applications.

</details>


### [167] [SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models](https://arxiv.org/abs/2509.03487)
*Jigang Fan,Zhenghong Zhou,Ruofan Jin,Le Cong,Mengdi Wang,Zaixi Zhang*

Main category: cs.LG

TL;DR: SafeProtein是首个针对蛋白质基础模型的红队测试框架，通过多模态提示工程和启发式束搜索，成功揭示了现有模型（如ESM3）的潜在生物安全风险，并为模型安全防护提供了见解。


<details>
  <summary>Details</summary>
Motivation: 蛋白质基础模型在蛋白质理解和设计方面取得了显著进展，但缺乏系统性的红队测试，引发了对模型可能被滥用以生成具有生物安全风险蛋白质的严重担忧。

Method: 本文介绍了SafeProtein框架，它结合了多模态提示工程和启发式束搜索，系统地设计红队测试方法。同时，还策划了SafeProtein-Bench，包含手动构建的红队基准数据集和全面的评估协议。

Result: SafeProtein成功对最先进的蛋白质基础模型实现了持续越狱（例如，对ESM3的攻击成功率高达70%），揭示了当前蛋白质基础模型中存在的潜在生物安全风险。

Conclusion: SafeProtein的研究结果为开发前沿模型的鲁棒安全保护技术提供了重要见解，强调了解决蛋白质基础模型中生物安全风险的必要性。

Abstract: Proteins play crucial roles in almost all biological processes. The
advancement of deep learning has greatly accelerated the development of protein
foundation models, leading to significant successes in protein understanding
and design. However, the lack of systematic red-teaming for these models has
raised serious concerns about their potential misuse, such as generating
proteins with biological safety risks. This paper introduces SafeProtein, the
first red-teaming framework designed for protein foundation models to the best
of our knowledge. SafeProtein combines multimodal prompt engineering and
heuristic beam search to systematically design red-teaming methods and conduct
tests on protein foundation models. We also curated SafeProtein-Bench, which
includes a manually constructed red-teaming benchmark dataset and a
comprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks
on state-of-the-art protein foundation models (up to 70% attack success rate
for ESM3), revealing potential biological safety risks in current protein
foundation models and providing insights for the development of robust security
protection technologies for frontier models. The codes will be made publicly
available at https://github.com/jigang-fan/SafeProtein.

</details>


### [168] [On Entropy Control in LLM-RL Algorithms](https://arxiv.org/abs/2509.03493)
*Han Shen*

Main category: cs.LG

TL;DR: 本文提出AEnt，一种新的熵控制方法，旨在解决传统熵正则化在LLM-RL中因巨大响应空间和稀疏最优输出而效果不佳的问题。AEnt通过在较小token空间上使用钳制熵奖励并自动调整熵系数，在数学推理任务中显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 传统的熵正则化在机器人和游戏RL中有效，但在LLM-RL训练中效果不佳甚至没有增益。研究旨在探究熵奖励在LLM-RL设置中的问题，特别是LLM巨大的响应空间和最优输出的稀疏性对传统熵正则化的影响。

Method: 提出AEnt，一种熵控制方法。它采用一种新的“钳制熵奖励”（clamped entropy bonus），该奖励在更小的token空间上通过重新归一化的策略进行评估，以鼓励在更紧凑的响应集中进行探索。此外，算法根据钳制熵值自动调整熵系数，以有效控制熵诱导的偏差并利用熵的益处。

Result: AEnt在不同基础模型和数据集的数学推理任务中进行了测试，结果表明它在多个基准测试中始终优于基线方法。

Conclusion: AEnt是一种有效处理LLM-RL中熵控制问题的方法，通过引入钳制熵奖励和自动调整系数，能在复杂任务中持续提升性能。

Abstract: For RL algorithms, appropriate entropy control is crucial to their
effectiveness. To control the policy entropy, a commonly used method is entropy
regularization, which is adopted in various popular RL algorithms including
PPO, SAC and A3C. Although entropy regularization proves effective in robotic
and games RL conventionally, studies found that it gives weak to no gains in
LLM-RL training. In this work, we study the issues of entropy bonus in LLM-RL
setting. Specifically, we first argue that the conventional entropy
regularization suffers from the LLM's extremely large response space and the
sparsity of the optimal outputs. As a remedy, we propose AEnt, an entropy
control method that utilizes a new clamped entropy bonus with an automatically
adjusted coefficient. The clamped entropy is evaluated with the re-normalized
policy defined on certain smaller token space, which encourages exploration
within a more compact response set. In addition, the algorithm automatically
adjusts entropy coefficient according to the clamped entropy value, effectively
controlling the entropy-induced bias while leveraging the entropy's benefits.
AEnt is tested in math-reasoning tasks under different base models and
datasets, and it is observed that AEnt outperforms the baselines consistently
across multiple benchmarks.

</details>


### [169] [Invariant Features for Global Crop Type Classification](https://arxiv.org/abs/2509.03497)
*Xin-Yi Tong,Sherrie Wang*

Main category: cs.LG

TL;DR: 本研究提出CropGlobe数据集和CropNet模型，通过识别地理不变遥感特征并结合时序数据增强，显著提升了全球农作物类型分类的跨区域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 全球农作物类型准确获取对粮食安全至关重要，但遥感分类受限于地面样本稀缺和地理差异导致的性能下降，急需提升模型在不同区域间的泛化能力。

Method: 构建了全球农作物类型数据集CropGlobe（30万像素级样本，覆盖8国5洲6种作物）；评估了Sentinel-2时序多光谱特征和EMIT高光谱特征在跨国家、大陆、半球传输场景下的不变性；设计了轻量级且鲁棒的CNN模型CropNet，并引入时序数据增强（时间平移、时间缩放、幅度扭曲）以模拟真实的跨区域物候变化。

Result: Sentinel-2的2D中值时序特征在所有传输场景中均表现出最强的地理不变性；时序数据增强进一步提升了模型的鲁棒性，尤其在训练数据多样性有限时效果显著。

Conclusion: 本工作识别了更具地理不变性的特征表示，有效增强了农作物分类的地理泛化能力，为在全球多样化区域实现可扩展、低成本的农作物类型应用提供了有前景的途径。

Abstract: Accurately obtaining crop type and its spatial distribution at a global scale
is critical for food security, agricultural policy-making, and sustainable
development. Remote sensing offers an efficient solution for large-scale crop
classification, but the limited availability of reliable ground samples in many
regions constrains applicability across geographic areas. To address
performance declines under geospatial shifts, this study identifies remote
sensing features that are invariant to geographic variation and proposes
strategies to enhance cross-regional generalization. We construct CropGlobe, a
global crop type dataset with 300,000 pixel-level samples from eight countries
across five continents, covering six major food and industrial crops (corn,
soybeans, rice, wheat, sugarcane, cotton). With broad geographic coverage,
CropGlobe enables a systematic evaluation under cross-country, cross-continent,
and cross-hemisphere transfer. We compare the transferability of temporal
multi-spectral features (Sentinel-2-based 1D/2D median features and harmonic
coefficients) and hyperspectral features (from EMIT). To improve generalization
under spectral and phenological shifts, we design CropNet, a lightweight and
robust CNN tailored for pixel-level crop classification, coupled with temporal
data augmentation (time shift, time scale, and magnitude warping) that
simulates realistic cross-regional phenology. Experiments show that 2D median
temporal features from Sentinel-2 consistently exhibit the strongest invariance
across all transfer scenarios, and augmentation further improves robustness,
particularly when training data diversity is limited. Overall, the work
identifies more invariant feature representations that enhance geographic
transferability and suggests a promising path toward scalable, low-cost crop
type applications across globally diverse regions.

</details>


### [170] [Warming Up for Zeroth-Order Federated Pre-Training with Low Resource Clients](https://arxiv.org/abs/2509.03503)
*Gwen Legate,Irina Rish,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出ZOWarmUp，一种联邦零阶优化器，旨在让内存和通信受限的边缘设备也能参与从随机初始化开始的联邦学习训练，减少通信开销，并提高模型性能和数据多样性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，边缘设备的内存和通信限制导致部分设备无法参与训练，进而造成数据无法利用和系统偏差增加。现有零阶方法虽然内存高效，但仅限于微调，无法从随机初始化开始训练，作者旨在解决这一限制。

Method: 本文设计了一种联邦、内存高效的零阶优化器ZOWarmUp。它允许从随机初始化开始进行零阶训练，并利用客户端的不同能力和精心的方差减少技术。ZOWarmUp无需边缘设备传输完整梯度，仅依赖少量随机种子，使上行通信成本可忽略不计。

Result: 通过在各种数据集和模型架构上的实验表明，ZOWarmUp是一种鲁棒的算法，可应用于多种场景。对于拥有大量原本会被排除在训练之外的边缘设备的系统，该算法能提供更多数量和多样性的数据访问，从而改善训练结果。

Conclusion: ZOWarmUp通过允许资源受限的客户端参与联邦学习，有效克服了内存和通信限制，从而增加了数据的可访问性和多样性，最终提高了模型训练效果并减少了系统诱导偏差。

Abstract: Federated learning enables collaborative model training across numerous edge
devices without requiring participants to share data; however, memory and
communication constraints on these edge devices may preclude their
participation in training. We consider a setting in which a subset of edge
devices are below a critical memory or communication threshold required to
conduct model updates. Under typical federated optimization algorithms, these
devices are excluded from training which renders their data inaccessible and
increases system induced bias. We are inspired by MeZO, a zeroth-order method
used for memory-efficient fine-tuning. The increased variance inherent to
zeroth-order gradient approximations has relegated previous zeroth-order
optimizers exclusively to the domain of fine tuning; a limitation we seek to
correct. We devise a federated, memory-efficient zeroth-order optimizer,
ZOWarmUp that permits zeroth-order training from a random initialization.
ZOWarmUp leverages differing client capabilities and careful variance reduction
techniques to facilitate participation of under-represented, low-resource
clients in model training. Like other federated zeroth-order methods, ZOWarmUp
eliminates the need for edge devices to transmit their full gradients to the
server and instead relies on only a small set of random seeds, rendering the
up-link communication cost negligible. We present experiments using various
datasets and model architectures to show that ZOWarmUp is a robust algorithm
that can can be applied under a wide variety of circumstances. For systems with
a high proportion of edge devices that would otherwise be excluded from
training, this algorithm provides access to a greater volume and diversity of
data, thus improving training outcomes.

</details>


### [171] [Can LLMs Lie? Investigation beyond Hallucination](https://arxiv.org/abs/2509.03518)
*Haoran Huan,Mihir Prabhudesai,Mengning Wu,Shantanu Jaiswal,Deepak Pathak*

Main category: cs.LG

TL;DR: 本研究系统性地探索了大型语言模型（LLMs）的“说谎”行为（为达成特定目标而故意制造虚假信息），揭示了其神经机制，并发现说谎有时能提升任务表现，为AI伦理讨论提供了新视角。


<details>
  <summary>Details</summary>
Motivation: LLMs在现实应用中的自主性引发了对其信任度的担忧。幻觉（无意中的虚假信息）已被广泛研究，但LLM“说谎”（为达成目标而有意生成虚假信息）的现象仍未被充分探索，这是本研究的核心动机。

Method: 本研究系统性地调查了LLMs的说谎行为，并将其与幻觉区分，在实际场景中进行测试。采用机械可解释性技术（包括logit lens分析、因果干预和对比激活引导）来揭示和控制欺骗行为的神经机制。此外，引入了行为引导向量以精细化操纵说谎倾向。

Result: 研究揭示了LLMs欺骗行为的神经机制，并通过特定技术成功识别并控制了这些行为。发现说谎与最终任务性能之间存在权衡，并建立了帕累托前沿，表明在某些情况下，不诚实可以优化任务目标。

Conclusion: 本研究深化了对LLM说谎行为的理解，揭示了其内在机制以及与任务性能的复杂关系。这些发现对AI伦理讨论具有重要意义，有助于评估在高风险环境中部署LLMs的风险，并开发相应的保障措施。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
a variety of tasks, but their increasing autonomy in real-world applications
raises concerns about their trustworthiness. While hallucinations-unintentional
falsehoods-have been widely studied, the phenomenon of lying, where an LLM
knowingly generates falsehoods to achieve an ulterior objective, remains
underexplored. In this work, we systematically investigate the lying behavior
of LLMs, differentiating it from hallucinations and testing it in practical
scenarios. Through mechanistic interpretability techniques, we uncover the
neural mechanisms underlying deception, employing logit lens analysis, causal
interventions, and contrastive activation steering to identify and control
deceptive behavior. We study real-world lying scenarios and introduce
behavioral steering vectors that enable fine-grained manipulation of lying
tendencies. Further, we explore the trade-offs between lying and end-task
performance, establishing a Pareto frontier where dishonesty can enhance goal
optimization. Our findings contribute to the broader discourse on AI ethics,
shedding light on the risks and potential safeguards for deploying LLMs in
high-stakes environments. Code and more illustrations are available at
https://llm-liar.github.io/

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [172] [BISCAY: Practical Radio KPI Driven Congestion Control for Mobile Networks](https://arxiv.org/abs/2509.02806)
*Jon Larrea,Tanya Shreedhar,Mahesh K. Marina*

Main category: cs.NI

TL;DR: 本文提出Biscay，一个基于无线KPI的新型拥塞控制系统，利用OpenDiag工具实现高精度带宽测量，从而在移动网络中大幅降低延迟（超90%）并保持良好吞吐量。


<details>
  <summary>Details</summary>
Motivation: 移动应用性能严重依赖底层传输的拥塞控制设计，而蜂窝链路通常是瓶颈，且带宽波动剧烈。现有拥塞控制方案难以有效应对这些挑战，导致性能不佳。

Method: 提出Biscay，一个实用且由无线KPI驱动的移动网络拥塞控制系统。它利用本文引入的内核级实时无线KPI提取工具OpenDiag，结合基于KPI的精确带宽确定层，动态调整拥塞窗口，以优化可用带宽利用率并最小化延迟。该方案已在未root的Android 5G手机上实现，证明其可行性。

Result: 通过基于真实测量轨迹的仿真和跨越4G及5G场景的实际实验，Biscay与BBR、CUBIC等现有先进拥塞控制方案相比，在平均和尾部延迟方面提供了显著改进（通常减少90%以上），同时实现了更好或相似的吞吐量。这些性能提升得益于OpenDiag相较于MobileInsight等现有替代方案，将设备端无线KPI测量粒度提高了100%。

Conclusion: Biscay通过有效利用设备端无线KPI，为移动网络提供了一种高效、实用的拥塞控制解决方案，能够大幅降低延迟，并保持高吞吐量，显著提升移动应用性能。

Abstract: Mobile application performance relies heavily on the congestion control
design of the underlying transport, which is typically bottlenecked by cellular
link and has to cope with rapid cellular link bandwidth fluctuations. We
observe that radio KPI measurements from the mobile device chipset can be
exploited for precise and timely measurement of available bandwidth on the
cellular link. Building on this insight, we propose Biscay, a practical and
radio KPI-driven congestion control system design for mobile networks. Biscay
leverages OpenDiag, the in-kernel real-time radio KPI extraction tool we
introduce in this paper, along with our KPI-based accurate bandwidth
determination layer towards dynamically adjusting the congestion window to
optimally use the available bandwidth while keeping delay to the minimum. Our
solution is practical and deployable, as shown through our implementation of
Biscay and OpenDiag on unrooted Android 5G phones. We extensively evaluate
Biscay against different state-of-the-art congestion control designs including
BBR and CUBIC with emulations driven by real measurement traces as well as
real-world experiments spanning diverse 4G and 5G scenarios, and show that it
provides significant average and tail delay improvements (typically over 90%
reduction) while yielding better or similar throughput. These gains are enabled
by 100% improvement in the granularity of on-device radio KPI measurements with
OpenDiag compared to existing alternatives like MobileInsight.

</details>


### [173] [Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3](https://arxiv.org/abs/2509.02811)
*Alessandro Traspadini,Michele Zorzi,Marco Giordani*

Main category: cs.NI

TL;DR: 本研究探索了LoRa通过低地球轨道（LEO）卫星网关为偏远地区提供大规模物联网连接的可行性。通过开发ns3仿真模块，结果证实LoRa可有效支持地对LEO通信，但需要优化以缓解共享扩频因子（SFs）引起的碰撞问题。


<details>
  <summary>Details</summary>
Motivation: 在陆地基础设施有限或不可用的偏远地区，将物联网（IoT）与非地面网络（NTNs）结合，通过卫星网关为传感器和执行器提供连接，已成为关键范式。LoRa作为一种低功耗广域网（LPWAN）技术，因其远距离、高能效和灵活性而具有巨大潜力。

Method: 为探索LoRa支持LEO卫星网关大规模物联网连接的性能和可行性，研究人员开发了一个新的ns3-LoRa-NTN仿真模块。该模块整合并扩展了ns3-LoRa和ns3-NTN模块，实现了LoRa网络中卫星通信的全栈端到端仿真。

Result: 研究结果（以平均数据速率和数据包接收率PRR衡量）证实，LoRa能够有效地支持地面到LEO卫星的直接通信。然而，当终端节点在远距离使用相同的扩频因子（SFs）时，需要进行网络优化以降低碰撞概率。

Conclusion: LoRa在通过LEO卫星为远程物联网提供连接方面具有可行性，并能有效支持地对空通信。但为了实现大规模和高效的网络运行，必须对网络进行优化，尤其是在管理共享扩频因子以缓解碰撞方面。

Abstract: The integration of Internet of Things (IoT) and Non-Terrestrial Networks
(NTNs) has emerged as a key paradigm to provide connectivity for sensors and
actuators via satellite gateways in remote areas where terrestrial
infrastructure is limited or unavailable. Among other Low-Power Wide-Area
Network (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential
given its long range, energy efficiency, and flexibility. In this paper, we
explore the feasibility and performance of LoRa to support large-scale IoT
connectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we
developed a new ns3-LoRa-NTN simulation module, which integrates and extends
the ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of
satellite communication in LoRa networks. Our results, given in terms of
average data rate and Packet Reception Ratio (PRR), confirm that LoRa can
effectively support direct communication from the ground to LEO satellites, but
network optimization is required to mitigate collision probability when end
nodes use the same Spreading Factors (SFs) over long distances.

</details>


### [174] [GPS Spoofing Attacks on Automated Frequency Coordination System in Wi-Fi 6E and Beyond](https://arxiv.org/abs/2509.02824)
*Yilu Dong,Tianchang Yang,Arupjyoti Bhuyan,Syed Rafiul Hussain*

Main category: cs.NI

TL;DR: Wi-Fi AP的GPS位置报告易受欺骗，可能导致6 GHz频谱中的AFC系统遭受干扰和安全威胁。


<details>
  <summary>Details</summary>
Motivation: 6 GHz频谱开放用于Wi-Fi 6E/7，但与关键的在用系统（如公共安全通信）重叠。FCC强制要求使用依赖Wi-Fi AP报告位置的AFC系统来防止干扰，因此确保AP位置报告的准确性和完整性至关重要。

Method: 本研究使用廉价的现成无线电设备演示了对Wi-Fi AP的GPS定位欺骗攻击。研究在受控实验室环境中对商用AP验证了这些攻击，并在欺骗场景下评估了商用AFC系统。

Result: 研究发现，GPS欺骗可以操纵AP行为，实现未经授权的频谱访问，造成有害干扰，甚至通过伪造AP位置来禁用AP。这些发现揭示了AFC系统安全假设中关于位置完整性的关键漏洞。

Conclusion: 当前AFC系统因Wi-Fi AP不安全的GPS位置报告而存在严重安全漏洞，这迫切需要开发和实施更强的定位完整性保护措施。

Abstract: The 6 GHz spectrum, recently opened for unlicensed use under Wi-Fi 6E and
Wi-Fi 7, overlaps with frequencies used by mission-critical incumbent systems
such as public safety communications and utility infrastructure. To prevent
interference, the FCC mandates the use of Automated Frequency Coordination
(AFC) systems, which assign safe frequency and power levels based on Wi-Fi
Access Point (AP)-reported locations. In this work, we demonstrate that
GPS-based location reporting, which Wi-Fi APs use, can be spoofed using
inexpensive, off-the-shelf radio equipment. This enables attackers to
manipulate AP behavior, gain unauthorized spectrum access, cause harmful
interference, or disable APs entirely by spoofing them into foreign locations.
We validate these attacks in a controlled lab setting against a commercial AP
and evaluate a commercial AFC system under spoofed scenarios. Our findings
highlight critical gaps in the security assumptions of AFC and motivate the
need for stronger location integrity protections.

</details>


### [175] [Closing the Visibility Gap: A Monitoring Framework for Verifiable Open RAN Operations](https://arxiv.org/abs/2509.03000)
*Hexuan Yu,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.NI

TL;DR: 针对Open RAN现有零信任架构（ZTA）无法发现配置错误或受损组件导致策略违规的问题，本文提出一个监控框架，主动验证O-RAN组件的配置状态和控制行为，以增强多运营商部署中的信任和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有O-RAN中的零信任架构（ZTA）隐式假设已认证组件会遵守操作策略，但忽略了配置错误或受损组件可能在不被发现的情况下违反策略、滥用资源或破坏下游进程（如ML-based RIC xApps），尤其在多移动网络运营商（MNO）共享组件的部署中，这构成了一个关键的安全盲点。

Method: 提出一个针对低信任O-RAN环境的监控框架，该框架通过主动验证组件的配置状态和控制行为是否符合租户定义的策略，来提供可扩展、可验证的监督，从而增强O-RAN操作的透明度和信任。

Result: 该框架已实现并使用标准化O-RAN配置进行评估，总处理延迟约为200毫秒。这证明了其在多MNO部署中进行及时策略执行和合规审计的效率和实用性。

Conclusion: 所提出的监控框架有效解决了O-RAN中现有ZTA的盲点，通过提供可扩展、可验证的监督，增强了多MNO部署环境下的透明度和信任，并被证实具有高效和实用的性能，能够及时执行策略和进行合规审计。

Abstract: Open Radio Access Network (Open RAN) is reshaping mobile network architecture
by promoting openness, disaggregation, and cross-vendor interoperability.
However, this architectural flexibility introduces new security challenges,
especially in deployments where multiple mobile network operators (MNOs)
jointly operate shared components. Existing Zero Trust Architectures (ZTA) in
O-RAN, as defined by governmental and industry standards, implicitly assume
that authenticated components will comply with operational policies. However,
this assumption creates a critical blind spot: misconfigured or compromised
components can silently violate policies, misuse resources, or corrupt
downstream processes (e.g., ML-based RIC xApps).
  To address this critical gap, we propose a monitoring framework for low-trust
O-RAN environments that proactively verifies configuration state and control
behavior against tenant-defined policies. Our system provides scalable,
verifiable oversight to enhance transparency and trust in O-RAN operations. We
implement and evaluate the framework using standardized O-RAN configurations,
with total processing latency of approximately 200 ms, demonstrating its
efficiency and practicality for timely policy enforcement and compliance
auditing in multi-MNO deployments.

</details>


### [176] [Multi-layer Digital Twin System for Future Mobile Metaverse](https://arxiv.org/abs/2509.03049)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出一种多层数字孪生（DT）系统，通过协调本地、边缘和云DT，为6G网络提供分布式、主动的适应能力，并支持元宇宙应用。


<details>
  <summary>Details</summary>
Motivation: 即将到来的6G时代，通信网络将面临前所未有的复杂性和动态性挑战。数字孪生技术有望将通信网络从被动响应转变为主动适应。

Method: 提出一个多层数字孪生系统，协调本地DT、边缘DT和云DT，以构建未来的网络架构和功能。

Result: 该提出的DT系统不仅能实现先前由集中式DT处理的实时数据驱动决策和数字代理功能，而且以更分布式、移动、逐层的方式实现。此外，它将为未来的元宇宙应用提供必要数据、预训练模型和开放接口。

Conclusion: 所提出的多层数字孪生系统为未来6G网络提供了分布式、主动的解决方案，并为元宇宙应用奠定了基础，使其能够高效开发和体验元宇宙服务。

Abstract: In the upcoming 6G era, the communication networks are expected to face
unprecedented challenges in terms of complexity and dynamics. Digital Twin (DT)
technology, with its various digital capabilities, holds great potential to
facilitate the transformation of the communication network from passive
responding to proactive adaptation. Thus, in this paper, we propose a
multi-layer DT system that coordinates local DT, edge DT, and cloud DT for
future network architecture and functions. In our vision, the proposed DT
system will not only achieve real-time data-driven decision-making and digital
agent functions previously handled by centralized DT, but will do so in a more
distributed, mobile, layer-by-layer manner. Moreover, it will supply essential
data, pre-trained models, and open interfaces for future metaverse
applications, enabling creators and users to efficiently develop and experience
metaverse services.

</details>


### [177] [Machine Learning-Driven Anomaly Detection for 5G O-RAN Performance Metrics](https://arxiv.org/abs/2509.03290)
*Babak Azkaei,Kishor Chandra Joshi,George Exarchakos*

Main category: cs.NI

TL;DR: 本文利用O-RAN规范的AI/ML集成能力，提出了一种异常检测框架，包含两个算法，旨在主动识别并缓解6G网络中用户设备的吞吐量下降和切换后故障，为自愈型网络奠定基础。


<details>
  <summary>Details</summary>
Motivation: 关键服务对网络基础设施的日益依赖和超越5G/6G网络日益增加的运行复杂性，亟需主动和自动化的网络故障管理。O-RAN提供的开放接口和AI/ML集成能力，为主动网络健康监测和异常检测带来了新可能。本研究旨在利用这些优势，主动检测用户设备（UE）可能的吞吐量下降并最大程度地减少切换后故障。

Method: 开发了一个异常检测框架，提出了两个可操作的异常检测算法：
1.  通过分析资源块利用率和信号质量等关键性能指标（KPIs），识别有严重吞吐量下降风险的用户设备（UE），从而实现主动切换。
2.  评估邻近小区的无线覆盖质量，过滤掉信号强度或干扰水平异常的小区，以减少切换目标候选。

Result: 第二个算法平均减少了41.27%的切换目标候选。这些方法能够有效减轻切换后故障和吞吐量下降，并且运行速度远快于近实时延迟限制。

Conclusion: 本研究提出的方法为实现自愈型6G网络铺平了道路，能够有效缓解切换后故障和吞吐量下降问题。

Abstract: The ever-increasing reliance of critical services on network infrastructure
coupled with the increased operational complexity of beyond-5G/6G networks
necessitate the need for proactive and automated network fault management. The
provision for open interfaces among different radio access network\,(RAN)
elements and the integration of AI/ML into network architecture enabled by the
Open RAN\,(O-RAN) specifications bring new possibilities for active network
health monitoring and anomaly detection. In this paper we leverage these
advantages and develop an anomaly detection framework that proactively detect
the possible throughput drops for a UE and minimize the post-handover failures.
We propose two actionable anomaly detection algorithms tailored for real-world
deployment. The first algorithm identifies user equipment (UE) at risk of
severe throughput degradation by analyzing key performance indicators (KPIs)
such as resource block utilization and signal quality metrics, enabling
proactive handover initiation. The second algorithm evaluates neighbor cell
radio coverage quality, filtering out cells with anomalous signal strength or
interference levels. This reduces candidate targets for handover by 41.27\% on
average. Together, these methods mitigate post-handover failures and throughput
drops while operating much faster than the near-real-time latency constraints.
This paves the way for self-healing 6G networks.

</details>


### [178] [Dependency Chain Analysis of ROS 2 DDS QoS Policies: From Lifecycle Tutorial to Static Verification](https://arxiv.org/abs/2509.03381)
*Sanghoon Lee,Junha Kang,Kyung-Joon Park*

Main category: cs.NI

TL;DR: 该研究通过分析DDS QoS策略、建立依赖链和开发QoS Guard工具，为ROS 2用户提供清晰的QoS配置指导和预部署验证能力，以避免运行时故障并提高系统可靠性。


<details>
  <summary>Details</summary>
Motivation: ROS 2用户缺乏关于DDS QoS策略安全组合和部署前验证的明确指导，导致试错性调整和意外的运行时故障。

Method: 分析了DDS Publisher-Subscriber通信的生命周期（发现、数据交换、分离），提供了关于16种QoS策略如何在各阶段运作的教程。基于此分析，推导出了形式化策略间关系的QoS依赖链，并分类了41条依赖违规规则。最后，引入了QoS Guard，一个用于离线静态验证DDS XML配置文件的ROS 2软件包。

Result: 提出了一个用户导向的教程，解释了16种QoS策略的运作方式。导出了QoS依赖链和41条依赖违规规则。开发了QoS Guard，一个ROS 2软件包，能够离线静态验证DDS XML配置文件，标记冲突，并支持在不建立实时ROS 2会话的情况下进行安全的预部署调优。

Conclusion: 这些贡献为ROS 2用户提供了概念性理解和具体工具，使其能够及早发现配置错误，从而提高基于ROS 2的机器人系统的可靠性和资源效率。

Abstract: Robot Operating System 2 (ROS 2) relies on the Data Distribution Service
(DDS), which offers more than 20 Quality of Service (QoS) policies governing
availability, reliability, and resource usage. Yet ROS 2 users lack clear
guidance on safe policy combinations and validation processes prior to
deployment, which often leads to trial-and-error tuning and unexpected runtime
failures. To address these challenges, we analyze DDS Publisher-Subscriber
communication over a life cycle divided into Discovery, Data Exchange, and
Disassociation, and provide a user oriented tutorial explaining how 16 QoS
policies operate in each phase. Building on this analysis, we derive a QoS
dependency chain that formalizes inter-policy relationships and classifies 41
dependency violation rules, capturing constraints that commonly cause
communication failures in practice. Finally, we introduce QoS Guard, a ROS 2
package that statically validates DDS XML profiles offline, flags conflicts,
and enables safe, predeployment tuning without establishing a live ROS 2
session. Together, these contributions give ROS 2 users both conceptual insight
and a concrete tool that enables early detection of misconfigurations,
improving the reliability and resource efficiency of ROS 2 based robotic
systems.

</details>


### [179] [Hierarchical Low-Altitude Wireless Network Empowered Air Traffic Management](https://arxiv.org/abs/2509.03386)
*Ziye Jia,Jia He,Yuanhao Cui,Qiuming Zhu,Ligang Yuan,Fuhui Zhou,Qihui Wu,Dusit Niyato,Zhu Han*

Main category: cs.NI

TL;DR: 本文提出了一个分层低空无线网络（HLWN）框架，以应对低空空域交通管理的复杂环境和飞机多样性挑战，旨在保障空中安全、优化资源利用，并通过风险评估实现动态避碰。


<details>
  <summary>Details</summary>
Motivation: 随着低空飞行器的快速发展，低空网络的合理设计对空中安全和资源利用至关重要。研究旨在解决低空交通管理中环境复杂性和飞行器多样性的挑战。

Method: 提出了一个分层低空无线网络（HLWN）框架。该框架通过三维空间离散化和集成无线监控机制来设计低空空中走廊。此外，还开发了基于冲突检测和概率碰撞分析的多维飞行风险评估方法，以实现异构飞行器的动态避碰。

Result: 所提出的HLWN框架通过其三维空间离散化和无线监控机制，能够设计安全的低空空中走廊并进行优化；多维飞行风险评估有助于实现异构飞行器的动态防撞。

Conclusion: 论文还探讨了HLAN发展的开放性问题和未来方向，为相关研究提供了见解。

Abstract: As the increasing development of low-altitude aircrafts, the rational design
of low-altitude networks directly impacts the aerial safety and resource
utilization. To address the challenges of environmental complexity and aircraft
diversity in the traffic management, we propose a hierarchical low-altitude
wireless network (HLWN) framework. Empowered by the threedimensional spatial
discretization and integrated wireless monitoring mechanisms in HLWN, we design
low-altitude air corridors to guarantee safe operation and optimization.
Besides, we develop the multi-dimensional flight risk assessment through
conflict detection and probabilistic collision analysis, facilitating dynamic
collision avoidance for heterogeneous aircrafts. Finally, the open issues and
future directions are investigated to provide insights into HLAN development.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [180] [Synthetic Founders: AI-Generated Social Simulations for Startup Validation Research in Computational Social Science](https://arxiv.org/abs/2509.02605)
*Jorn K. Teutloff*

Main category: cs.MA

TL;DR: 该研究通过对比真实初创创始人访谈与LLM生成的合成角色，评估了AI驱动模拟的保真度、差异和盲点，发现两者既有共通之处也有独特视角，并提出LLM角色作为经验研究的补充。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）驱动的合成角色在AI赋能模拟中的保真度、差异和盲点，尤其是在初创企业验证的背景下，以了解其作为社会模拟工具的潜力与局限性。

Method: 对十五名早期初创创始人进行了关于AI赋能验证的访谈，并以相同的协议复制了与AI生成的创始人及投资者角色的互动。随后，通过结构化主题综合分析比较了两组数据。

Result: 研究发现四类结果：(1) **趋同主题**：承诺驱动的需求信号、黑箱信任障碍和效率提升在两组数据中均被强调；(2) **部分重叠**：创始人担忧异常值被平均化和真实客户验证的压力，合成角色则突出非理性盲点并将AI视为心理缓冲；(3) **仅限人类主题**：早期客户参与的关系和倡导价值，以及对“登月”市场的怀疑；(4) **仅限合成主题**：放大的假阳性及创伤盲点（AI可能因遗漏负面历史经验而高估采纳潜力）。LLM驱动的角色被解读为一种混合社会模拟形式，比传统基于规则的智能体更具语言表达性和适应性，但受制于缺乏生活经验和关系后果。

Conclusion: LLM驱动的合成角色不应取代经验研究，而是作为一种补充性的模拟类别。它们能够扩展假设空间，加速探索性验证，并阐明计算社会科学中认知真实性的边界。

Abstract: We present a comparative docking experiment that aligns human-subject
interview data with large language model (LLM)-driven synthetic personas to
evaluate fidelity, divergence, and blind spots in AI-enabled simulation.
Fifteen early-stage startup founders were interviewed about their hopes and
concerns regarding AI-powered validation, and the same protocol was replicated
with AI-generated founder and investor personas. A structured thematic
synthesis revealed four categories of outcomes: (1) Convergent themes -
commitment-based demand signals, black-box trust barriers, and efficiency gains
were consistently emphasized across both datasets; (2) Partial overlaps -
founders worried about outliers being averaged away and the stress of real
customer validation, while synthetic personas highlighted irrational blind
spots and framed AI as a psychological buffer; (3) Human-only themes -
relational and advocacy value from early customer engagement and skepticism
toward moonshot markets; and (4) Synthetic-only themes - amplified false
positives and trauma blind spots, where AI may overstate adoption potential by
missing negative historical experiences.
  We interpret this comparative framework as evidence that LLM-driven personas
constitute a form of hybrid social simulation: more linguistically expressive
and adaptable than traditional rule-based agents, yet bounded by the absence of
lived history and relational consequence. Rather than replacing empirical
studies, we argue they function as a complementary simulation category -
capable of extending hypothesis space, accelerating exploratory validation, and
clarifying the boundaries of cognitive realism in computational social science.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [181] [Charting the Future of Scholarly Knowledge with AI: A Community Perspective](https://arxiv.org/abs/2509.02581)
*Azanzi Jiomekong,Hande Küçük McGinty,Keith G. Mills,Allard Oelen,Enayat Rajabi,Harry McElroy,Antrea Christou,Anmol Saini,Janice Anta Zebaze,Hannah Kim,Anna M. Jacyszyn,Sören Auer*

Main category: cs.DL

TL;DR: 本文旨在通过促进跨学科对话，识别共同挑战，并规划学术知识组织与管理领域的未来研究方向，以应对学术出版物激增和现有社区合作不足的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管存在支持工具，研究人员仍常依赖手动方法；学术出版物激增使得跟进最新进展愈发困难，急需AI驱动的可扩展解决方案；各研究社区独立工作，缺乏互动阻碍了方法和最佳实践的交流，延缓了集成解决方案的进展。

Method: 本手稿通过分析和识别促进跨学科对话、确定共享挑战、分类新的合作形式以及塑造未来学术知识组织与管理研究方向的途径来解决问题。

Result: 本手稿识别了促进跨学科对话、共享挑战以及新合作的有效途径，并对未来学术知识组织与管理的研究方向提出了建议。

Conclusion: 为了构建可靠、动态和可查询的学术知识库，促进跨学科交流、识别共同挑战并整合各社区的努力至关重要，这将有助于加速集成解决方案的开发并明确未来的研究路径。

Abstract: Despite the growing availability of tools designed to support scholarly
knowledge extraction and organization, many researchers still rely on manual
methods, sometimes due to unfamiliarity with existing technologies or limited
access to domain-adapted solutions. Meanwhile, the rapid increase in scholarly
publications across disciplines has made it increasingly difficult to stay
current, further underscoring the need for scalable, AI-enabled approaches to
structuring and synthesizing scholarly knowledge. Various research communities
have begun addressing this challenge independently, developing tools and
frameworks aimed at building reliable, dynamic, and queryable scholarly
knowledge bases. However, limited interaction across these communities has
hindered the exchange of methods, models, and best practices, slowing progress
toward more integrated solutions. This manuscript identifies ways to foster
cross-disciplinary dialogue, identify shared challenges, categorize new
collaboration and shape future research directions in scholarly knowledge and
organization.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [182] [Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence](https://arxiv.org/abs/2509.02924)
*Nefeli Manoudaki,Mert Toka,Iason Paterakis,Diarmid Flatley*

Main category: cs.MM

TL;DR: Simulacra Naturae是一个数据驱动的媒体装置，通过脑类器官的神经活动，创造一个多感官环境，旨在探索集体关怀并去中心化人类能动性。


<details>
  <summary>Details</summary>
Motivation: 探索生物计算、物质生态和生成系统之间的纠缠如何促进集体关怀。重新构想可视化作为一种关怀实践，旨在去中心化人类能动性，并在混合计算系统中开辟伦理、同理心和生态协调的新空间。

Method: 该装置将脑类器官的预录神经活动转化为一个多感官环境，包括生成式视觉、空间音频、活体植物和粘土制品。这些生物信号通过实时系统，调节受自然系统启发的代理行为，作为共同创造力引导生成生态系统的生长、形式和氛围。装置还包括带有螺线管的计算制造粘土打印件、活体热带植物和实时生成AI视觉的地面投影。

Result: 创造了一个由非人类认知塑造的感官场域。通过将抽象数据根植于活体材料和具身经验中，该装置重新构想了可视化作为一种关怀实践，并提供了一个去中心化人类能动性、探索伦理、同理心和生态协调的新空间。

Conclusion: Simulacra Naturae重新定义了可视化作为一种关怀实践，去中心化了人类能动性，并在混合计算系统中为伦理、同理心和生态协调开辟了新空间。

Abstract: Simulacra Naturae is a data-driven media installation that explores
collective care through the entanglement of biological computation, material
ecologies, and generative systems. The work translates pre-recorded neural
activity from brain organoids, lab-grown three-dimensional clusters of neurons,
into a multi-sensory environment composed of generative visuals, spatial audio,
living plants, and fabricated clay artifacts. These biosignals, streamed
through a real-time system, modulate emergent agent behaviors inspired by
natural systems such as termite colonies and slime molds. Rather than using
biosignals as direct control inputs, Simulacra Naturae treats organoid activity
as a co-creative force, allowing neural rhythms to guide the growth, form, and
atmosphere of a generative ecosystem. The installation features computationally
fabricated clay prints embedded with solenoids, adding physical sound
resonances to the generative surround composition. The spatial environment,
filled with live tropical plants and a floor-level projection layer featuring
real-time generative AI visuals, invites participants into a sensory field
shaped by nonhuman cognition. By grounding abstract data in living materials
and embodied experience, Simulacra Naturae reimagines visualization as a
practice of care, one that decentralizes human agency and opens new spaces for
ethics, empathy, and ecological attunement within hybrid computational systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [183] [Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations](https://arxiv.org/abs/2509.03093)
*Fatih Pehlivan,Arçin Ülkü Ergüzen,Sahand Moslemi Yengejeh,Mayasah Lami,Anil Koyuncu*

Main category: cs.SE

TL;DR: 研究评估了大型语言模型（LLMs）检测多语言SOLID原则违规的能力。结果显示，GPT-4o Mini表现最佳，但模型性能、提示策略、语言特性和代码复杂度均显著影响检测准确率，表明需要定制化的AI分析方法。


<details>
  <summary>Details</summary>
Motivation: 传统静态分析难以检测SOLID原则等语义设计缺陷，现有解决方案通常局限于单一SOLID原则或特定编程语言，无法在多语言代码库中全面检测所有五项原则。

Method: 本研究提出一种新方法：利用定制化提示工程评估LLM检测跨多种语言的SOLID违规能力。构建了一个包含240个手动验证代码示例的新基准数据集，并评估了四种领先LLM（CodeLlama、DeepSeekCoder、QwenCoder和GPT-4o Mini）检测所有五项SOLID原则的能力。同时，测试了四种不同的提示策略（受零样本、少样本和思维链技术启发）对检测准确率的影响。

Result: 研究结果揭示模型间存在显著的性能等级差异，GPT-4o Mini表现最佳，但即使它在DIP等复杂原则上仍有不足。提示策略具有显著影响，但没有单一的最佳策略；例如，ENSEMBLE提示在OCP检测上表现出色，而EXAMPLE提示对DIP违规更有效。所有实验中，检测准确率受语言特性影响很大，并随代码复杂度的增加而急剧下降。

Conclusion: 这些初步发现表明，有效的AI驱动设计分析并非依赖单一最佳模型，而是需要一种量身定制的方法，将合适的模型和提示与特定的设计上下文相匹配。这突出显示了LLMs通过AI辅助代码分析支持代码可维护性的巨大潜力。

Abstract: Traditional static analysis methods struggle to detect semantic design flaws,
such as violations of the SOLID principles, which require a strong
understanding of object-oriented design patterns and principles. Existing
solutions typically focus on individual SOLID principles or specific
programming languages, leaving a gap in the ability to detect violations across
all five principles in multi-language codebases. This paper presents a new
approach: a methodology that leverages tailored prompt engineering to assess
LLMs on their ability to detect SOLID violations across multiple languages. We
present a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,
and GPT-4o Mini-on their ability to detect violations of all five SOLID
principles. For this evaluation, we construct a new benchmark dataset of 240
manually validated code examples. Using this dataset, we test four distinct
prompt strategies inspired by established zero-shot, few-shot, and
chain-of-thought techniques to systematically measure their impact on detection
accuracy. Our emerging results reveal a stark hierarchy among models, with
GPT-4o Mini decisively outperforming others, yet even struggles with
challenging principles like DIP. Crucially, we show that prompt strategy has a
dramatic impact, but no single strategy is universally best; for instance, a
deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE
prompt is superior for DIP violations. Across all experiments, detection
accuracy is heavily influenced by language characteristics and degrades sharply
with increasing code complexity. These initial findings demonstrate that
effective, AI-driven design analysis requires not a single best model, but a
tailored approach that matches the right model and prompt to the specific
design context, highlighting the potential of LLMs to support maintainability
through AI-assisted code analysis.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [184] [Improving the Resilience of Quadrotors in Underground Environments by Combining Learning-based and Safety Controllers](https://arxiv.org/abs/2509.02808)
*Isaac Ronald Ward,Mark Paral,Kristopher Riordan,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 针对地下环境四旋翼自主控制中学习型控制器泛化性差的问题，本文提出一种基于归一化流的运行时监测器，根据环境偏离度（OOD）在学习型控制器和安全控制器之间动态切换，实现了任务执行速度和碰撞规避的双重优化。


<details>
  <summary>Details</summary>
Motivation: 在大型地下环境中自主控制四旋翼飞行器在环境勘测、采矿和搜救等领域具有重要应用价值。然而，尽管学习型控制器很有吸引力，但它们通常无法很好地泛化到训练时未遇到的“分布外”（out-of-distribution, OOD）环境。

Method: 本文训练了一个基于归一化流的环境先验模型，用于实时衡量四旋翼所处环境与训练分布的偏离程度（OOD）。该衡量指标被用作运行时监测器，当偏离程度足够大时，系统会自动从学习型控制器切换到安全控制器。

Result: 在基于DARPA地下挑战赛真实点云数据构建的模拟3D洞穴环境中进行的点对点导航任务基准测试显示，本文提出的组合控制器同时具备了学习型控制器的任务完成速度（高活跃度）和安全控制器的碰撞规避能力（高安全性）。

Conclusion: 通过结合归一化流的OOD监测和动态控制器切换策略，本研究成功解决了学习型控制器在未知地下环境中泛化能力不足的问题，使四旋翼在保证安全性的前提下，也能高效地完成任务。

Abstract: Autonomously controlling quadrotors in large-scale subterranean environments
is applicable to many areas such as environmental surveying, mining operations,
and search and rescue. Learning-based controllers represent an appealing
approach to autonomy, but are known to not generalize well to
`out-of-distribution' environments not encountered during training. In this
work, we train a normalizing flow-based prior over the environment, which
provides a measure of how far out-of-distribution the quadrotor is at any given
time. We use this measure as a runtime monitor, allowing us to switch between a
learning-based controller and a safe controller when we are sufficiently
out-of-distribution. Our methods are benchmarked on a point-to-point navigation
task in a simulated 3D cave environment based on real-world point cloud data
from the DARPA Subterranean Challenge Final Event Dataset. Our experimental
results show that our combined controller simultaneously possesses the liveness
of the learning-based controller (completing the task quickly) and the safety
of the safety controller (avoiding collision).

</details>


### [185] [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](https://arxiv.org/abs/2508.13073)
*Rui Shao,Wei Li,Lingsen Zhang,Renshan Zhang,Zhiyang Liu,Ran Chen,Liqiang Nie*

Main category: cs.RO

TL;DR: 本文首次系统性地综述了基于大型视觉-语言模型（VLM）的视觉-语言-动作（VLA）机器人操作模型，建立了分类体系，并探讨了未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统机器人操作方法在非结构化环境中扩展性和泛化性差。基于大型VLM的VLA模型有望解决此问题，但现有研究缺乏系统性整合、分类不一致且存在碎片化，急需一份全面的综述来填补这一空白。

Method: 本文采用系统性、分类法导向的综述方法。首先定义了基于大型VLM的VLA模型，并提出了两种主要架构范式（单体和分层模型）。随后，深入分析了这些模型与强化学习、无训练优化等先进领域的结合，总结了其独特特性（架构、操作优势、数据集），并识别了记忆机制、4D感知等多项有前景的研究方向。

Result: 本综述整合了该领域的最新进展，解决了现有分类法的不一致性，减轻了研究碎片化，并通过对大型VLM与机器人操作交叉领域研究的系统整合，成功填补了关键研究空白。

Conclusion: 基于大型VLM的VLA模型是机器人操作领域的变革性范式。本综述通过提供清晰的定义、系统性的分类和对新兴方向的洞察，为该领域的进一步发展奠定了坚实基础。

Abstract: Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation

</details>


### [186] [DUViN: Diffusion-Based Underwater Visual Navigation via Knowledge-Transferred Depth Features](https://arxiv.org/abs/2509.02983)
*Jinghe Yang,Minh-Quan Le,Mingming Gong,Ye Pu*

Main category: cs.RO

TL;DR: DUViN是一种基于扩散模型和知识迁移深度特征的水下视觉导航策略，能使水下航行器在未知环境中实现无需预设地图的4自由度端到端运动控制，并具备避障及维持安全高度的能力。


<details>
  <summary>Details</summary>
Motivation: 水下导航面临传感能力有限和难以构建精确地图的挑战，导致自主导航困难。

Method: 提出DUViN（Diffusion-based Underwater Visual Navigation policy），一种通过知识迁移深度特征实现的扩散模型视觉导航策略。该方法采用两阶段训练框架：首先在陆地数据集上利用预训练的深度特征提取器训练扩散视觉导航策略；其次，针对水下深度估计任务重新训练提取器，并将其整合到已训练的导航策略中，以应对数据稀缺和域迁移问题。

Result: 在模拟和真实水下环境进行的实验表明，DUViN方法有效且泛化能力强。

Conclusion: 所提出的DUViN策略能有效解决水下自主导航难题，在未知环境中实现基于视觉的端到端运动控制，无需依赖预构建地图，并展现出良好的避障和高度维持能力及泛化性。

Abstract: Autonomous underwater navigation remains a challenging problem due to limited
sensing capabilities and the difficulty of constructing accurate maps in
underwater environments. In this paper, we propose a Diffusion-based Underwater
Visual Navigation policy via knowledge-transferred depth features, named DUViN,
which enables vision-based end-to-end 4-DoF motion control for underwater
vehicles in unknown environments. DUViN guides the vehicle to avoid obstacles
and maintain a safe and perception awareness altitude relative to the terrain
without relying on pre-built maps. To address the difficulty of collecting
large-scale underwater navigation datasets, we propose a method that ensures
robust generalization under domain shifts from in-air to underwater
environments by leveraging depth features and introducing a novel model
transfer strategy. Specifically, our training framework consists of two phases:
we first train the diffusion-based visual navigation policy on in-air datasets
using a pre-trained depth feature extractor. Secondly, we retrain the extractor
on an underwater depth estimation task and integrate the adapted extractor into
the trained navigation policy from the first step. Experiments in both
simulated and real-world underwater environments demonstrate the effectiveness
and generalization of our approach. The experimental videos are available at
https://www.youtube.com/playlist?list=PLqt2s-RyCf1gfXJgFzKjmwIqYhrP4I-7Y.

</details>


### [187] [Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression](https://arxiv.org/abs/2509.03012)
*Uddeshya Upadhyay*

Main category: cs.RO

TL;DR: 提出UT$^3$框架，通过不确定性感知自监督选择性应用测试时训练，解决连续域偏移下的推理延迟问题，同时保持性能，使其适用于真实世界机器人应用。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在自主系统中面临持续域偏移的泛化能力差问题。现有测试时训练方法虽能适应域偏移，但需多次前向和反向传播，导致推理时间大幅增加，不适用于对延迟和资源有严格要求的真实世界机器人应用。

Method: 本文提出名为UT$^3$的新框架，利用不确定性感知自监督任务进行高效测试时训练。该方法通过量化不确定性选择性地应用训练，显著提高推理时间。此外，所提出的协议提供连续设置来识别关键帧，允许用户控制测试时训练的频率。

Result: UT$^3$在与标准测试时训练协议性能相当的情况下，显著提高了推理时间。该方法在单目深度估计这一密集回归任务上展示了有效性。

Conclusion: UT$^3$框架为在连续域偏移下，实时、资源受限的自主系统提供了一种实用的解决方案，通过智能地选择性应用测试时训练，平衡了适应性与计算效率。

Abstract: Deep neural networks (DNNs) are increasingly being used in autonomous
systems. However, DNNs do not generalize well to domain shift. Adapting to a
continuously evolving environment is a safety-critical challenge inevitably
faced by all autonomous systems deployed to the real world. Recent work on
test-time training proposes methods that adapt to a new test distribution on
the fly by optimizing the DNN model for each test input using self-supervision.
However, these techniques result in a sharp increase in inference time as
multiple forward and backward passes are required for a single test sample (for
test-time training) before finally making the prediction based on the
fine-tuned features. This is undesirable for real-world robotics applications
where these models may be deployed to resource constraint hardware with strong
latency requirements. In this work, we propose a new framework (called UT$^3$)
that leverages test-time training for improved performance in the presence of
continuous domain shift while also decreasing the inference time, making it
suitable for real-world applications. Our method proposes an uncertainty-aware
self-supervision task for efficient test-time training that leverages the
quantified uncertainty to selectively apply the training leading to sharp
improvements in the inference time while performing comparably to standard
test-time training protocol. Our proposed protocol offers a continuous setting
to identify the selected keyframes, allowing the end-user to control how often
to apply test-time training. We demonstrate the efficacy of our method on a
dense regression task - monocular depth estimation.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [188] [Quantifying the Social Costs of Power Outages and Restoration Disparities Across Four U.S. Hurricanes](https://arxiv.org/abs/2509.02653)
*Xiangpeng Li,Junwei Ma,Bo Li,Ali Mostafavi*

Main category: physics.soc-ph

TL;DR: 本研究开发了一个框架，通过整合新的恢复指标和人口统计数据，量化了美国飓风期间停电的社会影响和公平性，发现低收入地区负担更重，且恢复持续时间是主要驱动因素。


<details>
  <summary>Details</summary>
Motivation: 鉴于灾害影响的复杂性和不公平性（如人口稀疏地区个体层面不成比例的负担），以及缺乏一种标准化的、跨事件的细粒度方法来量化停电的社会影响及其驱动因素，特别是对公平性的评估和传统可靠性指标未能捕捉的恢复类型。

Method: 引入一个框架，将客户加权停电暴露转化为剥夺程度，整合福利指标与三个恢复指标（每客户平均停电天数、恢复持续时间、相对恢复率），数据来源于EAGLE I观测和邮政编码区域人口统计数据。该方法应用于四次美国飓风事件，并使用机械分析、可解释模型和聚类分析。

Result: 研究发现停电影响呈现倒退模式，即低收入地区承受更大负担。剥夺程度随恢复持续时间的增加而增加，随恢复速度的加快而减少，其中恢复持续时间是主导驱动因素。聚类分析揭示了传统可靠性指标未能捕捉到的独特恢复类型。

Conclusion: 该框架提供了一种可转移的方法，用于评估停电影响和公平性；提供了连接恢复动态与社会结果的跨事件比较证据；并生成了可操作的空间分析，支持公平导向的恢复规划和弹性投资。

Abstract: The multifaceted nature of disaster impact shows that densely populated areas
contribute more to aggregate burden, while sparsely populated but heavily
affected regions suffer disproportionately at the individual level. This study
introduces a framework for quantifying the societal impacts of power outages by
translating customer weighted outage exposure into deprivation measures,
integrating welfare metrics with three recovery indicators, average outage days
per customer, restoration duration, and relative restoration rate, computed
from sequential EAGLE I observations and linked to Zip Code Tabulation Area
demographics. Applied to four United States hurricanes, Beryl 2024 Texas,
Helene 2024 Florida, Milton 2024 Florida, and Ida 2021 Louisiana, this
standardized pipeline provides the first cross event, fine scale evaluation of
outage impacts and their drivers. Results demonstrate regressive patterns with
greater burdens in lower income areas, mechanistic analysis shows deprivation
increases with longer restoration durations and decreases with faster
restoration rates, explainable modeling identifies restoration duration as the
dominant driver, and clustering reveals distinct recovery typologies not
captured by conventional reliability metrics. This framework delivers a
transferable method for assessing outage impacts and equity, comparative cross
event evidence linking restoration dynamics to social outcomes, and actionable
spatial analyses that support equity informed restoration planning and
resilience investment.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [189] [Optimizing Geometry Problem Sets for Skill Development](https://arxiv.org/abs/2509.02758)
*Michael Bouzinier,Sergey Trifonov*

Main category: math.HO

TL;DR: 本文介绍了一个早期开发的欧几里得几何问题标注和组织本体论及方法论，并论证其在现代AI背景下，特别是结合大型语言模型，对几何教育中自动解决方案验证和反馈的再应用价值。


<details>
  <summary>Details</summary>
Motivation: 原始研究（本体论、方法论及软件工具）在1990年代初开发，用于标注和组织欧几里得几何问题。当前的研究动机是论证该框架在现代人工智能背景下的新相关性，特别是探索如何将其与大型语言模型结合，以实现几何教育中的自动化解决方案验证和反馈，从而支持教师和自学者。

Method: 本文描述了一个早期（1990年代初）开发的用于标注和组织欧几里得几何问题的本体论和方法论（包括解决方案图范式），并实现了软件工具。研究方法包括探讨将此现有框架与当代大型语言模型结合的假设，以实现自动化解决方案验证和反馈。此外，文章还记录了原始架构。

Result: 文章强调了原始架构及其持久价值，并提出假设：该既定框架与大型语言模型结合后，能够促进自动化解决方案验证和反馈。这为几何教育中的教师和自学者提供了支持。

Conclusion: 早期开发的几何问题本体论和方法论在现代AI背景下具有重要潜力。通过将历史教育资源与下一代AI技术（如大型语言模型）相结合，可以为几何教育提供新的支持和改进途径。

Abstract: This article describes an ontology and methodology for annotating and
organizing Euclidean Geometry problems, developed in the early 1990s and
implemented as a software tool. While the majority of this work -- including
the ontology and solution graph paradigm -- was completed over thirty years
ago, we argue that it has renewed relevance in the context of modern artificial
intelligence. In particular, we explore the hypothesis that this established
framework can facilitate automated solution validation and feedback when paired
with contemporary large language models, thereby supporting teachers and
self-learners in geometry education. We document the original architecture and
its enduring value, and outline pathways for bridging historical educational
resources with next-generation AI techniques.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [190] [S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG](https://arxiv.org/abs/2509.03066)
*Huaicheng Zhang,Ruoxin Wang,Chenlian Zhou,Jiguang Shi,Yue Ge,Zhoutong Li,Sheng Chang,Hao Wang,Jin He,Qijun Huang*

Main category: eess.SP

TL;DR: S2M2ECG是一种基于状态空间模型（SSMs）的轻量级多导联心电图（ECG）分析模型，通过三级融合机制和多分支设计，在心血管疾病（CVD）诊断中实现了卓越性能、低计算复杂度和高效部署。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在心血管疾病（CVD）诊断中应用广泛，但现有算法难以在多导联心电图（ECG）信号分析中平衡性能、计算复杂度和多源信息融合。

Method: 本研究提出S2M2ECG模型，该模型基于状态空间模型（SSMs）架构，利用其高效率和线性复杂度。它包含三级融合机制：1) 采用分段标记的空间-时间双向SSMs进行低级别信号融合；2) 通过双向扫描进行导联内时间信息融合；3) 采用跨导联特征交互模块进行空间信息融合。此外，模型还整合了多分支设计和导联融合模块，以充分利用ECG信号的多导联特性。

Result: 实验结果表明，S2M2ECG在节律、形态学和临床场景中均实现了优异性能。其轻量级架构使其参数量在现有模型中接近最少，非常适合高效推理和便捷部署。

Conclusion: S2M2ECG在性能、计算复杂度和ECG特定特性之间取得了出色平衡，为心血管疾病诊断中的高性能、轻量级计算提供了一个有前景的解决方案。

Abstract: As one of the most effective methods for cardiovascular disease (CVD)
diagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic
multi-sensor information fusion challenge that has been continuously researched
in deep learning domains. Despite the numerous algorithms proposed with
different DL architectures, maintaining a balance among performance,
computational complexity, and multi-source ECG feature fusion remains
challenging. Recently, state space models (SSMs), particularly Mamba, have
demonstrated remarkable effectiveness across various fields. Their inherent
design for high-efficiency computation and linear complexity makes them
particularly suitable for low-dimensional data like ECGs. This work proposes
S2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1)
Spatio-temporal bi-directional SSMs with segment tokenization for low-level
signal fusion, (2) Intra-lead temporal information fusion with bi-directional
scanning to enhance recognition accuracy in both forward and backward
directions, (3) Cross-lead feature interaction modules for spatial information
fusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in
ECG signals, a multi-branch design and lead fusion modules are incorporated,
enabling individual analysis of each lead while ensuring seamless integration
with others. Experimental results reveal that S2M2ECG achieves superior
performance in the rhythmic, morphological, and clinical scenarios. Moreover,
its lightweight architecture ensures it has nearly the fewest parameters among
existing models, making it highly suitable for efficient inference and
convenient deployment. Collectively, S2M2ECG offers a promising alternative
that strikes an excellent balance among performance, computational complexity,
and ECG-specific characteristics, paving the way for high-performance,
lightweight computations in CVD diagnosis.

</details>


### [191] [EEG-MSAF: An Interpretable Microstate Framework uncovers Default-Mode Decoherence in Early Neurodegeneration](https://arxiv.org/abs/2509.02568)
*Mohammad Mehedi Hasan,Pedro G. Lind,Hernando Ombao,Anis Yazidi,Rabindra Khadka*

Main category: eess.SP

TL;DR: 本文提出了EEG微状态分析框架（EEG-MSAF），利用EEG微状态识别痴呆（DEM）、轻度认知障碍（MCI）和正常认知（NC）之间的生物标志物，并实现了高准确性、泛化性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 痴呆是日益严重的全球健康挑战，需要早期准确诊断。尽管脑电图（EEG）提供非侵入性观察，但传统方法难以捕捉其瞬态复杂性，因此需要更有效的方法来识别与痴呆相关的生物标志物。

Method: 研究提出了端到端的EEG微状态分析框架（EEG-MSAF），包含三个阶段：1) 自动化微状态特征提取；2) 使用机器学习（ML）进行分类；3) 利用Shapley Additive Explanations (SHAP) 进行特征排序以突出关键生物标志物。该框架在公开的CAUEEG数据集和塞萨洛尼基医院的临床队列数据集上进行评估。

Result: 在CAUEEG数据集上，EEG-MSAF-SVM实现了89% ± 0.01的准确率，超越深度学习基线CEEDNET 19.3%。在塞萨洛尼基数据集上，达到95% ± 0.01的准确率，与EEGConvNeXt相当。SHAP分析表明平均相关性和发生率是最具信息量的指标：微状态C（显著性/注意力网络）的紊乱主导痴呆预测，而微状态F（一种新的默认模式）则作为MCI和DEM的关键早期生物标志物。

Conclusion: EEG-MSAF通过结合准确性、泛化性和可解释性，推动了基于EEG的痴呆诊断，并揭示了跨认知谱的脑动力学。

Abstract: Dementia (DEM) is a growing global health challenge, underscoring the need
for early and accurate diagnosis. Electroencephalography (EEG) provides a
non-invasive window into brain activity, but conventional methods struggle to
capture its transient complexity. We present the \textbf{EEG Microstate
Analysis Framework (EEG-MSAF)}, an end-to-end pipeline that leverages EEG
microstates discrete, quasi-stable topographies to identify DEM-related
biomarkers and distinguish DEM, mild cognitive impairment (MCI), and normal
cognition (NC). EEG-MSAF comprises three stages: (1) automated microstate
feature extraction, (2) classification with machine learning (ML), and (3)
feature ranking using Shapley Additive Explanations (SHAP) to highlight key
biomarkers. We evaluate on two EEG datasets: the public Chung-Ang University
EEG (CAUEEG) dataset and a clinical cohort from Thessaloniki Hospital. Our
framework demonstrates strong performance and generalizability. On CAUEEG,
EEG-MSAF-SVM achieves \textbf{89\% $\pm$ 0.01 accuracy}, surpassing the deep
learning baseline CEEDNET by \textbf{19.3\%}. On the Thessaloniki dataset, it
reaches \textbf{95\% $\pm$ 0.01 accuracy}, comparable to EEGConvNeXt. SHAP
analysis identifies mean correlation and occurrence as the most informative
metrics: disruption of microstate C (salience/attention network) dominates DEM
prediction, while microstate F, a novel default-mode pattern, emerges as a key
early biomarker for both MCI and DEM. By combining accuracy, generalizability,
and interpretability, EEG-MSAF advances EEG-based dementia diagnosis and sheds
light on brain dynamics across the cognitive spectrum.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [192] [MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and Atypical Subtyping](https://arxiv.org/abs/2509.02586)
*Esha Sadia Nasir,Jiaqi Lv,Mostafa Jahanifer,Shan E Ahmed Raza*

Main category: eess.IV

TL;DR: MitoDetect++是一个统一的深度学习流程，用于自动化有丝分裂检测和非典型有丝分裂分类，在验证域上实现了0.892的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中，自动化检测和分类有丝分裂图像，特别是区分非典型与正常有丝分裂，仍然是关键挑战。

Method: 该方法提出了MitoDetect++流程：对于检测（Track 1），采用基于U-Net的编解码器架构，骨干网络为EfficientNetV2-L并增强了注意力模块，通过组合分割损失进行训练。对于分类（Track 2），利用Virchow2视觉Transformer，通过低秩适应（LoRA）进行高效微调以减少资源消耗。为提高泛化性和减轻域漂移，集成了强数据增强、Focal Loss和组感知分层5折交叉验证，并在推理时使用测试时增强（TTA）。

Result: 该方法在验证域上达到了0.892的平衡准确率。

Conclusion: 该方法具有临床适用性，并能在不同任务中展现出良好的可扩展性。

Abstract: Automated detection and classification of mitotic figures especially
distinguishing atypical from normal remain critical challenges in computational
pathology. We present MitoDetect++, a unified deep learning pipeline designed
for the MIDOG 2025 challenge, addressing both mitosis detection and atypical
mitosis classification. For detection (Track 1), we employ a U-Net-based
encoder-decoder architecture with EfficientNetV2-L as the backbone, enhanced
with attention modules, and trained via combined segmentation losses. For
classification (Track 2), we leverage the Virchow2 vision transformer,
fine-tuned efficiently using Low-Rank Adaptation (LoRA) to minimize resource
consumption. To improve generalization and mitigate domain shifts, we integrate
strong augmentations, focal loss, and group-aware stratified 5-fold
cross-validation. At inference, we deploy test-time augmentation (TTA) to boost
robustness. Our method achieves a balanced accuracy of 0.892 across validation
domains, highlighting its clinical applicability and scalability across tasks.

</details>


### [193] [Normal and Atypical Mitosis Image Classifier using Efficient Vision Transformer](https://arxiv.org/abs/2509.02589)
*Xuan Qi,Dominic Labella,Thomas Sanford,Maxwell Lee*

Main category: eess.IV

TL;DR: 该研究利用EfficientViT-L2混合架构在MIDOG 2025挑战赛中进行异常与正常有丝分裂分类，并在初步评估中取得了平衡且具有竞争力的表现。


<details>
  <summary>Details</summary>
Motivation: 参与MIDOG 2025挑战赛，旨在对异常与正常有丝分裂进行分类，这是一项在癌症病理学中具有重要意义的任务。

Method: 采用EfficientViT-L2混合CNN-ViT架构，结合由七种癌症类型（MIDOG++和AMi-Br）的13,938个细胞核组成的统一数据集（其中异常有丝分裂约占15%）。为评估域泛化能力，采用了留一癌症类型交叉验证和5折集成，并使用染料去卷积进行图像增强。最终提交挑战赛的模型是在所有癌症类型上进行5折集成训练得到的。

Result: 在初步评估阶段，该模型取得了0.859的平衡准确度，0.942的ROC AUC和0.85的原始准确度。

Conclusion: 该模型在异常与正常有丝分裂分类任务中，在多项指标上展现出有竞争力且表现均衡的性能。

Abstract: We tackle atypical versus normal mitosis classification in the MIDOG 2025
challenge using EfficientViT-L2, a hybrid CNN--ViT architecture optimized for
accuracy and efficiency. A unified dataset of 13,938 nuclei from seven cancer
types (MIDOG++ and AMi-Br) was used, with atypical mitoses comprising ~15. To
assess domain generalization, we applied leave-one-cancer-type-out
cross-validation with 5-fold ensembles, using stain-deconvolution for image
augmentation. For challenge submissions, we trained an ensemble with the same
5-fold split but on all cancer types. In the preliminary evaluation phase, this
model achieved balanced accuracy of 0.859, ROC AUC of 0.942, and raw accuracy
of 0.85, demonstrating competitive and well-balanced performance across
metrics.

</details>


### [194] [Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification](https://arxiv.org/abs/2509.02591)
*Mieko Ochi,Bae Yuan*

Main category: eess.IV

TL;DR: 该研究利用预训练的病理学基础模型（PFMs）结合参数高效微调、图像增强和模型集成技术，旨在准确区分有丝分裂图像的典型和非典型变体，以改善肿瘤预后评估。


<details>
  <summary>Details</summary>
Motivation: 准确区分有丝分裂图像的典型和非典型变体对于患者预后和资源分配至关重要，但即使对专家病理学家而言，这仍是一个挑战。

Method: 研究利用在大型组织病理学数据集上预训练的病理学基础模型（PFMs），并通过低秩适应（LoRA）进行参数高效微调。训练过程中，采用鱼眼变换以强调有丝分裂，并使用ImageNet目标图像进行傅里叶域适应。最终，集成多个PFMs以整合互补的形态学见解。

Result: 该方法在初步评估阶段数据集上取得了高平衡准确率。

Conclusion: 通过结合预训练PFMs、参数高效微调、图像增强和模型集成，可以有效提高有丝分裂图像的分类准确性，从而有助于肿瘤侵袭性的评估和患者的精确预后。

Abstract: Mitotic figures are classified into typical and atypical variants, with
atypical counts correlating strongly with tumor aggressiveness. Accurate
differentiation is therefore essential for patient prognostication and resource
allocation, yet remains challenging even for expert pathologists. Here, we
leveraged Pathology Foundation Models (PFMs) pre-trained on large
histopathology datasets and applied parameter-efficient fine-tuning via
low-rank adaptation. During training, we employ a fisheye transform to
emphasize mitoses and Fourier Domain Adaptation using ImageNet target images.
Finally, we ensembled multiple PFMs to integrate complementary morphological
insights, achieving a high balanced accuracy on the Preliminary Evaluation
Phase dataset.

</details>


### [195] [Robust Pan-Cancer Mitotic Figure Detection with YOLOv12](https://arxiv.org/abs/2509.02593)
*Raphaël Bourgade,Guillaume Balezo,Thomas Walter*

Main category: eess.IV

TL;DR: 本文提出了一种基于YOLOv12目标检测架构的有丝分裂图像检测方法，在MIDOG 2025挑战赛初步测试集上取得了0.801的F1分数。


<details>
  <summary>Details</summary>
Motivation: 有丝分裂图像是肿瘤病理学中的关键预后特征，但其识别具有挑战性且观察者间差异显著。MIDOG挑战赛旨在开发稳健的有丝分裂检测算法来解决这一问题。

Method: 采用基于YOLOv12目标检测架构的有丝分裂图像检测方法。

Result: 在MIDOG 2025挑战赛的初步测试集上获得了0.801的F1分数，且未依赖外部数据。

Conclusion: 本研究展示了基于YOLOv12的方法在解决有丝分裂图像识别挑战方面的潜力，并在国际竞赛中取得了有竞争力的初步成果。

Abstract: Mitotic figures represent a key histoprognostic feature in tumor pathology,
providing crucial insights into tumor aggressiveness and proliferation.
However, their identification remains challenging, subject to significant
inter-observer variability, even among experienced pathologists. To address
this issue, the MItosis DOmain Generalization (MIDOG) 2025 challenge marks the
third edition of an international competition aiming to develop robust mitosis
detection algorithms. In this paper, we present a mitotic figures detection
approach based on the YOLOv12 object detection architecture, achieving a
$F_1$-score of 0.801 on the preliminary test set of the MIDOG 2025 challenge,
without relying on external data.

</details>


### [196] [MIDOG 2025: Mitotic Figure Detection with Attention-Guided False Positive Correction](https://arxiv.org/abs/2509.02598)
*Andrew Broad,Jason Keighley,Lucy Godson,Alex Wright*

Main category: eess.IV

TL;DR: 提出一种基于FCOS的复合模型，通过集成FAL-CNN和融合网络来检测有丝分裂图像，旨在降低FCOS的假阳性率并提高检测准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在降低现有FCOS目标检测器的假阳性率，提高有丝分裂图像检测的准确性，并增强网络的泛化能力。

Method: 通过扩展现有的全卷积单阶段目标检测器（FCOS），增加一个反馈注意力阶梯CNN（FAL-CNN）模型用于正常与异常有丝分裂图像的分类，并将FAL-CNN的输出输入到一个融合网络中，该网络负责调整FCOS预测的边界框。

Result: 在初步评估数据集上，该模型在有丝分裂检测方面的F1分数达到了0.655。

Conclusion: 该复合模型在有丝分裂检测任务上取得了令人鼓舞的F1分数，初步证明了其在提高检测准确性和降低假阳性率方面的有效性。

Abstract: We present a novel approach which extends the existing Fully Convolutional
One-Stage Object Detector (FCOS) for mitotic figure detection. Our composite
model adds a Feedback Attention Ladder CNN (FAL-CNN) model for classification
of normal versus abnormal mitotic figures, feeding into a fusion network that
is trained to generate adjustments to bounding boxes predicted by FCOS. Our
network aims to reduce the false positive rate of the FCOS object detector, to
improve the accuracy of object detection and enhance the generalisability of
the network. Our model achieved an F1 score of 0.655 for mitosis detection on
the preliminary evaluation dataset.

</details>


### [197] [Towards Digital Twins for Optimal Radioembolization](https://arxiv.org/abs/2509.02607)
*Nisanth Kumar Panneerselvam,Guneet Mummaneni,Emilie Roncali*

Main category: eess.IV

TL;DR: 该工作提出了一个肝脏放射栓塞数字孪生框架，结合计算流体动力学(CFD)和物理信息AI(如PINNs)来优化治疗规划。


<details>
  <summary>Details</summary>
Motivation: 肝脏放射栓塞治疗面临解剖结构复杂、血流变化及微球输运不确定性等挑战，难以在最大化疗效的同时最小化对健康组织的损害。创建动态、患者特异性数字孪生有望解决这些问题。

Method: 该研究提出结合高保真计算流体动力学(CFD)和物理信息机器学习方法。CFD用于微球输运计算以实现个性化治疗规划。为解决CFD计算成本高的问题，引入了物理信息神经网络(PINNs)及其生成扩展(如PI-GANs、PI-DMs和基于Transformer的架构)。这些AI方法将控制方程融入网络训练，实现无网格、数据高效、不确定性感知且时间分辨的血流和微球输运预测，同时降低计算成本并保持物理保真度。

Result: CFD和物理信息AI方法共同构成了动态、患者特异性数字孪生的基础。这些AI替代模型能够快速模拟多种血流情景，为放射栓塞治疗提供实时决策支持。

Conclusion: 结合CFD和物理信息AI的数字孪生框架，有望优化放射栓塞治疗规划，最终改善肝癌患者的临床治疗效果。

Abstract: Radioembolization is a localized liver cancer treatment that delivers
radioactive microspheres (30 micron) to tumors via a catheter inserted in the
hepatic arterial tree. The goal is to maximize therapeutic efficacy while
minimizing damage to healthy liver tissue. However, optimization is challenging
due to complex hepatic artery anatomy, variable blood flow, and uncertainty in
microsphere transport. The creation of dynamic, patient-specific digital twins
may provide a transformative solution to these challenges. This work outlines a
framework for a liver radioembolization digital twin using high-fidelity
computational fluid dynamics (CFD) and/or recent physics-informed machine
learning approaches. The CFD approach involves microsphere transport
calculations in the hepatic arterial tree with individual patient data, which
enables personalized treatment planning. Although accurate, traditional CFD is
computationally expensive and limits clinical applicability.
  To accelerate simulations, physics-informed neural networks (PINNs) and their
generative extensions play an increasingly important role. PINNs integrate
governing equations, such as the Navier-Stokes equations, directly into the
neural network training process, enabling mesh-free, data-efficient
approximation of blood flow and microsphere transport. Physics-informed
generative adversarial networks (PI-GANs), diffusion models (PI-DMs), and
transformer-based architectures further enable uncertainty-aware, temporally
resolved predictions with reduced computational cost. These AI surrogates not
only maintain physical fidelity but also support rapid sampling of diverse flow
scenarios, facilitating real-time decision support.
  Together, CFD and physics-informed AI methods form the foundation of dynamic,
patient-specific digital twin to optimize radioembolization planning and
ultimately improve clinical outcomes.

</details>


### [198] [Is Synthetic Image Augmentation Useful for Imbalanced Classification Problems? Case-Study on the MIDOG2025 Atypical Cell Detection Competition](https://arxiv.org/abs/2509.02612)
*Leire Benito-Del-Valle,Pedro A. Moreno-Sánchez,Itziar Egusquiza,Itsaso Vitoria,Artzai Picón,Cristina López-Saratxaga,Adrian Galdran*

Main category: eess.IV

TL;DR: 本研究在MIDOG 2025挑战赛的非典型有丝分裂分类任务中，对比了ImageNet预训练的ConvNeXt和领域预训练的Lunit ViT两种骨干网络。两者均表现良好，ConvNeXt性能峰值更高，Lunit稳定性更好，但简单的合成数据平衡效果不显著。


<details>
  <summary>Details</summary>
Motivation: MIDOG 2025挑战赛引入了非典型有丝分裂分类新任务（Track 2），旨在区分组织病理图像中的正常与非典型有丝分裂。这是一个临床相关但高度不平衡和跨域的问题，需要有效的解决方案。

Method: 研究采用了两种互补的骨干网络：ImageNet预训练的ConvNeXt-Small和Lunit通过自监督训练的组织病理学专用ViT。为解决数据不平衡问题（正常样本远多于非典型样本），通过合成额外的非典型样本以近似类别平衡，并比较了仅使用真实数据与真实+合成数据训练的模型。模型性能通过五折交叉验证进行评估。

Result: 两种骨干网络均取得了强大的性能（平均AUROC约为95%）。ConvNeXt达到了略高的性能峰值，而Lunit在折间稳定性上表现更佳。然而，合成数据平衡并未带来持续的改进。在组织者提供的初步隐藏测试集上，ConvNeXt取得了最高的AUROC（95.4%），而Lunit在平衡准确率方面仍具竞争力。

Conclusion: 研究结果表明，ImageNet和领域预训练的骨干网络均适用于非典型有丝分裂分类任务。其中，领域预训练赋予模型更好的鲁棒性，而ImageNet预训练则能达到更高的性能峰值。同时，简单的合成数据平衡策略在本次实验中益处有限。

Abstract: The MIDOG 2025 challenge extends prior work on mitotic figure detection by
introducing a new Track 2 on atypical mitosis classification. This task aims to
distinguish normal from atypical mitotic figures in histopathology images, a
clinically relevant but highly imbalanced and cross-domain problem. We
investigated two complementary backbones: (i) ConvNeXt-Small, pretrained on
ImageNet, and (ii) a histopathology-specific ViT from Lunit trained via
self-supervision. To address the strong prevalence imbalance (9408 normal vs.
1741 atypical), we synthesized additional atypical examples to approximate
class balance and compared models trained with real-only vs. real+synthetic
data. Using five-fold cross-validation, both backbones reached strong
performance (mean AUROC approximately 95 percent), with ConvNeXt achieving
slightly higher peaks while Lunit exhibited greater fold-to-fold stability.
Synthetic balancing, however, did not lead to consistent improvements. On the
organizers' preliminary hidden test set, explicitly designed as an
out-of-distribution debug subset, ConvNeXt attained the highest AUROC (95.4
percent), whereas Lunit remained competitive on balanced accuracy. These
findings suggest that both ImageNet and domain-pretrained backbones are viable
for atypical mitosis classification, with domain-pretraining conferring
robustness and ImageNet pretraining reaching higher peaks, while naive
synthetic balancing has limited benefit. Full hidden test set results will be
reported upon challenge completion.

</details>


### [199] [A Two-Stage Strategy for Mitosis Detection Using Improved YOLO11x Proposals and ConvNeXt Classification](https://arxiv.org/abs/2509.02627)
*Jie Xiao,Mengye Lyu,Shaojun Liu*

Main category: eess.IV

TL;DR: 针对MIDOG 2025有丝分裂检测任务中复杂的WSI图像导致的假阳性和假阴性问题，本文提出了一种两阶段框架，通过先生成高召回率候选框再进行高精度过滤，显著提升了F1分数。


<details>
  <summary>Details</summary>
Motivation: MIDOG 2025 Track 1要求在含有非肿瘤、炎症和坏死区域的全玻片图像(WSI)中进行有丝分裂检测。由于复杂异构的背景和可能的伪影，常出现假阳性和假阴性，从而降低检测的F1分数。

Method: 本文提出一个两阶段框架：首先，使用集成EMA attention和LSConv的改进型YOLO11x，以低置信度阈值生成有丝分裂候选框，确保高召回率。然后，采用ConvNeXt-Tiny分类器过滤掉假阳性，确保高精确度。

Result: 在MIDOG++、MITOS_WSI_CCMCT和MITOS_WSI_CMC融合数据集上评估，该框架取得了0.882的F1分数，比单阶段YOLO11x基线高出0.035。性能提升主要归因于精确度的显著提高（从0.762到0.839），同时召回率保持可比水平。

Conclusion: 所提出的两阶段框架通过有效解决假阳性问题，能够生成高检测F1分数，特别是在精确度方面取得了显著进步，从而在复杂的WSI有丝分裂检测任务中超越了单阶段基线。

Abstract: MIDOG 2025 Track 1 requires mitosis detection in whole-slide images (WSIs)
containing non-tumor, inflamed, and necrotic regions. Due to the complicated
and heterogeneous context, as well as possible artifacts, there are often false
positives and false negatives, thus degrading the detection F1-score. To
address this problem, we propose a two-stage framework. Firstly, an improved
YOLO11x, integrated with EMA attention and LSConv, is employed to generate
mitosis candidates. We use a low confidence threshold to generate as many
proposals as possible, ensuring the detection recall. Then, a ConvNeXt-Tiny
classifier is employed to filter out the false positives, ensuring the
detection precision. Consequently, the proposed two-stage framework can
generate a high detection F1-score. Evaluated on a fused dataset comprising
MIDOG++, MITOS_WSI_CCMCT, and MITOS_WSI_CMC, our framework achieves an F1-score
of 0.882, which is 0.035 higher than the single-stage YOLO11x baseline. This
performance gain is produced by a significant precision improvement, from 0.762
to 0.839, and a comparable recall. The code is available at
https://github.com/xxiao0304/MIDOG-2025-Track-1-of-SZTU.

</details>


### [200] [A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection](https://arxiv.org/abs/2509.02637)
*Yasemin Topuz,M. Taha Gökcan,Serdar Yıldız,Songül Varlı*

Main category: eess.IV

TL;DR: 本文提出SDF-YOLO，一个轻量级且域鲁棒的检测框架，用于检测小而稀有的有丝分裂图像，并在多个人类和犬类肿瘤数据集上实现了高精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 有丝分裂图像检测对肿瘤侵袭性评估至关重要，但扫描仪、组织类型和染色协议等领域差异严重影响了自动化检测方法的鲁棒性。

Method: 引入SDF-YOLO（Single Detect Focused YOLO），这是一个基于YOLOv11改进的检测框架。主要修改包括：与有丝分裂图像尺度对齐的单一检测头、增强位置敏感性的坐标注意力机制以及改进的跨通道特征混合。

Result: SDF-YOLO在MIDOG2025挑战赛的初步测试集上取得了0.799的平均精度（AP），精确度为0.758，召回率为0.775，F1分数为0.766，FROC-AUC为5.793，同时展示了竞争性的准确性和计算效率。

Conclusion: SDF-YOLO为在不同领域下进行鲁棒的有丝分裂图像检测提供了一个可靠且高效的框架。

Abstract: Mitotic figure detection is a crucial task in computational pathology, as
mitotic activity serves as a strong prognostic marker for tumor aggressiveness.
However, domain variability that arises from differences in scanners, tissue
types, and staining protocols poses a major challenge to the robustness of
automated detection methods. In this study, we introduce SDF-YOLO (Single
Detect Focused YOLO), a lightweight yet domain-robust detection framework
designed specifically for small, rare targets such as mitotic figures. The
model builds on YOLOv11 with task-specific modifications, including a single
detection head aligned with mitotic figure scale, coordinate attention to
enhance positional sensitivity, and improved cross-channel feature mixing.
Experiments were conducted on three datasets that span human and canine tumors:
MIDOG ++, canine cutaneous mast cell tumor (CCMCT), and canine mammary
carcinoma (CMC). When submitted to the preliminary test set for the MIDOG2025
challenge, SDF-YOLO achieved an average precision (AP) of 0.799, with a
precision of 0.758, a recall of 0.775, an F1 score of 0.766, and an FROC-AUC of
5.793, demonstrating both competitive accuracy and computational efficiency.
These results indicate that SDF-YOLO provides a reliable and efficient
framework for robust mitotic figure detection across diverse domains.

</details>


### [201] [Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge](https://arxiv.org/abs/2509.02640)
*Biwen Meng,Xi Long,Jingxin Liu*

Main category: eess.IV

TL;DR: 本研究探索了UNI2-h病理基础模型的多种适应策略，以有效检测非典型有丝分裂，发现提示调整结合染色归一化测试时增强能显著提高泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 非典型有丝分裂（AMFs）是重要的临床指标，但其可靠检测因形态模糊和扫描仪差异而极具挑战性。

Method: 研究者从基于LoRA的基线模型开始，对病理基础模型UNI2-h进行了三种变体的适应性研究，包括视觉提示调整（VPT），并进一步结合了Vahadane和Macenko染色归一化的测试时增强（TTA）。

Result: 最终提交的模型在初步排行榜上取得了0.8837的平衡准确率和0.9513的ROC-AUC，位列前10名。

Conclusion: 基于提示的适应方法结合染色归一化测试时增强，为在不同成像条件下进行非典型有丝分裂分类提供了一种有效策略。

Abstract: Atypical mitotic figures (AMFs) are clinically relevant indicators of
abnormal cell division, yet their reliable detection remains challenging due to
morphological ambiguity and scanner variability. In this work, we investigated
three variants of adapting the pathology foundation model UNI2-h for the
MIDOG2025 Track 2 challenge. Starting from a LoRA-based baseline, we found that
visual prompt tuning (VPT) substantially improved generalization, and that
further integrating test-time augmentation (TTA) with Vahadane and Macenko
stain normalization provided the best robustness. Our final submission achieved
a balanced accuracy of 0.8837 and an ROC-AUC of 0.9513 on the preliminary
leaderboard, ranking within the top 10 teams. These results demonstrate that
prompt-based adaptation combined with stain-normalization TTA offers an
effective strategy for atypical mitosis classification under diverse imaging
conditions.

</details>


### [202] [Pan-Cancer mitotic figures detection and domain generalization: MIDOG 2025 Challenge](https://arxiv.org/abs/2509.02585)
*Zhuoyan Shen,Esther Bär,Maria Hawkins,Konstantin Bräutigam,Charles-Antoine Collins-Fekete*

Main category: eess.IV

TL;DR: 本报告提交了MIDOG 2025挑战赛的有丝分裂图像检测方案，通过发布新数据集并采用最新训练方法，在常规和非典型有丝分裂检测上均取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学中用于癌症预后判断的关键任务——有丝分裂图像检测，并参与MIDOG 2025挑战。

Method: 遵循“苦涩的教训”原则，通过公开发布两个新数据集以扩大训练数据规模（包括常规和非典型有丝分裂）。此外，采用了最新的训练方法。

Result: 在测试集上，Track-1的F1-Score达到0.8407；Track-2非典型有丝分裂细胞分类的平衡准确率达到0.9107。

Conclusion: 通过强调数据规模和应用最新训练方法，本方案在MIDOG 2025挑战赛的有丝分裂检测任务中取得了具有竞争力的性能。

Abstract: This report details our submission to the Mitotic Domain Generalization
(MIDOG) 2025 challenge, which addresses the critical task of mitotic figure
detection in histopathology for cancer prognostication. Following the "Bitter
Lesson"\cite{sutton2019bitterlesson} principle that emphasizes data scale over
algorithmic novelty, we have publicly released two new datasets to bolster
training data for both conventional \cite{Shen2024framework} and atypical
mitoses \cite{shen_2025_16780587}. Besides, we implement up-to-date training
methodologies for both track and reach a Track-1 F1-Score of 0.8407 on our test
set, as well as a Track-2 balanced accuracy of 0.9107 for atypical mitotic cell
classification.

</details>


### [203] [Sequential Hard Mining: a data-centric approach for Mitosis Detection](https://arxiv.org/abs/2509.02588)
*Maxime W. Lafarge,Viktor H. Koelzer*

Main category: eess.IV

TL;DR: 本文提出了一种受boosting技术启发的训练数据高效采样方法，旨在优化利用大量有丝分裂图像注释数据集来训练深度学习模型，并将其作为MIDOG 2025挑战赛的候选方案。


<details>
  <summary>Details</summary>
Motivation: 随着组织学图像中有丝分裂图像注释数据集的持续增长，如何最佳利用这些海量数据以最优地训练深度学习模型已成为一项新挑战。

Method: 本文在现有方法的基础上，专注于受boosting技术启发的训练数据高效采样，并提出了针对MIDOG 2025挑战赛两个赛道的候选解决方案。

Result: 本文提出了针对MIDOG 2025挑战赛两个赛道的候选解决方案。

Conclusion: 所提出的方法旨在有效应对利用大量注释数据优化深度学习模型训练的新挑战，并为MIDOG 2025挑战赛提供了潜在的解决方案。

Abstract: With a continuously growing availability of annotated datasets of mitotic
figures in histology images, finding the best way to optimally use with this
unprecedented amount of data to optimally train deep learning models has become
a new challenge. Here, we build upon previously proposed approaches with a
focus on efficient sampling of training data inspired by boosting techniques
and present our candidate solutions for the two tracks of the MIDOG 2025
challenge.

</details>


### [204] [ConvNeXt with Histopathology-Specific Augmentations for Mitotic Figure Classification](https://arxiv.org/abs/2509.02595)
*Hana Feki,Alice Blondel,Thomas Walter*

Main category: eess.IV

TL;DR: 针对计算病理学中非典型有丝分裂细胞分类的挑战，本研究提出一种基于轻量级ConvNeXt模型，结合多领域数据训练和组织病理学特定增强策略的解决方案，在MIDOG 2025挑战赛中取得了高平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 准确分类有丝分裂细胞对癌症分级和预后至关重要。区分非典型（AMFs）和正常有丝分裂细胞（NMFs）面临多重挑战，包括形态细微差异、高类内变异性、领域漂移（器官、组织、扫描仪差异）、标注稀缺及严重的类别不平衡问题。

Method: 本研究基于轻量级ConvNeXt架构，整合所有可用数据集（AMi-Br, AtNorM-Br, AtNorM-MD, OMG-Octo）以实现最大领域覆盖。通过组织病理学特定的数据增强流程（包括弹性变换和染色特异性变换）和平衡采样策略来增强模型鲁棒性并缓解类别不平衡。采用分组5折交叉验证确保评估的可靠性。

Result: 在MIDOG 2025挑战赛的初步排行榜上，本模型实现了0.8961的平衡准确率，位居前列。

Conclusion: 研究结果表明，广泛的领域数据暴露与有针对性的数据增强策略相结合，是构建准确且具有良好泛化能力的有丝分裂细胞分类器的关键。

Abstract: Accurate mitotic figure classification is crucial in computational pathology,
as mitotic activity informs cancer grading and patient prognosis.
Distinguishing atypical mitotic figures (AMFs), which indicate higher tumor
aggressiveness, from normal mitotic figures (NMFs) remains challenging due to
subtle morphological differences and high intra-class variability. This task is
further complicated by domain shifts, including variations in organ, tissue
type, and scanner, as well as limited annotations and severe class imbalance.
To address these challenges in Track 2 of the MIDOG 2025 Challenge, we propose
a solution based on the lightweight ConvNeXt architecture, trained on all
available datasets (AMi-Br, AtNorM-Br, AtNorM-MD, and OMG-Octo) to maximize
domain coverage. Robustness is enhanced through a histopathology-specific
augmentation pipeline, including elastic and stain-specific transformations,
and balanced sampling to mitigate class imbalance. A grouped 5-fold
cross-validation strategy ensures reliable evaluation. On the preliminary
leaderboard, our model achieved a balanced accuracy of 0.8961, ranking among
the top entries. These results highlight that broad domain exposure combined
with targeted augmentation strategies is key to building accurate and
generalizable mitotic figure classifiers.

</details>


### [205] [Solutions for Mitotic Figure Detection and Atypical Classification in MIDOG 2025](https://arxiv.org/abs/2509.02597)
*Shuting Xu,Runtong Liu,Zhixuan Chen,Junlin Hou,Hao Chen*

Main category: eess.IV

TL;DR: 本文介绍了作者在MIDOG 2025挑战赛中的方法，包括用于有丝分裂像检测的两阶段框架和用于非典型有丝分裂分类的集成策略，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在计算病理学中的有丝分裂像分析方面取得了显著进展。作者旨在解决MIDOG 2025挑战赛的两个核心任务：有丝分裂像检测和非典型有丝分裂分类。

Method: 对于有丝分裂像检测任务，提出一个两阶段检测-分类框架，首先定位候选有丝分裂像，然后使用专门的分类模块进行精细化预测。对于非典型有丝分裂分类任务，采用集成策略，整合来自多个最先进深度学习架构的预测，以提高鲁棒性和准确性。

Result: 广泛的实验证明了所提出的方法在这两个任务中都有效。

Conclusion: 所提出的两阶段检测-分类框架和集成策略在MIDOG 2025挑战赛的有丝分裂像检测和非典型有丝分裂分类任务中表现出良好的效果。

Abstract: Deep learning has driven significant advances in mitotic figure analysis
within computational pathology. In this paper, we present our approach to the
Mitosis Domain Generalization (MIDOG) 2025 Challenge, which consists of two
distinct tasks, i.e., mitotic figure detection and atypical mitosis
classification. For the mitotic figure detection task, we propose a two-stage
detection-classification framework that first localizes candidate mitotic
figures and subsequently refines the predictions using a dedicated
classification module. For the atypical mitosis classification task, we employ
an ensemble strategy that integrates predictions from multiple state-of-the-art
deep learning architectures to improve robustness and accuracy. Extensive
experiments demonstrate the effectiveness of our proposed methods across both
tasks.

</details>


### [206] [RF-DETR for Robust Mitotic Figure Detection: A MIDOG 2025 Track 1 Approach](https://arxiv.org/abs/2509.02599)
*Piotr Giedziun,Jan Sołtysik,Mateusz Górczany,Norbert Ropiak,Marcin Przymus,Piotr Krajewski,Jarosław Kwiecień,Artur Bartczak,Izabela Wasiak,Mateusz Maniewski*

Main category: eess.IV

TL;DR: 本文提出了一种针对MIDOG 2025挑战的鲁棒性有丝分裂相检测方法，采用单阶段RF-DETR结合困难负样本挖掘，在初步测试集上取得了0.789的F1分数，有效泛化了跨域检测能力。


<details>
  <summary>Details</summary>
Motivation: 组织病理图像中的有丝分裂相检测因扫描仪、染色方案和组织类型之间的显著领域漂移而面临挑战。

Method: 团队优化了一个单阶段检测流程，使用RF-DETR（Roboflow Detection Transformer）并结合困难负样本挖掘，在MIDOG++数据集上进行训练。

Result: 在初步测试集上，该方法取得了0.789的F1分数，召回率为0.839，精确率为0.746，证明了其在未见领域中的有效泛化能力。

Conclusion: 研究结果揭示了训练数据平衡和困难负样本挖掘对于解决有丝分裂相检测中领域漂移挑战的重要性。

Abstract: Mitotic figure detection in histopathology images remains challenging due to
significant domain shifts across different scanners, staining protocols, and
tissue types. This paper presents our approach for the MIDOG 2025 challenge
Track 1, focusing on robust mitotic figure detection across diverse
histological contexts. While we initially planned a two-stage approach
combining high-recall detection with subsequent classification refinement, time
constraints led us to focus on optimizing a single-stage detection pipeline. We
employed RF-DETR (Roboflow Detection Transformer) with hard negative mining,
trained on MIDOG++ dataset. On the preliminary test set, our method achieved an
F1 score of 0.789 with a recall of 0.839 and precision of 0.746, demonstrating
effective generalization across unseen domains. The proposed solution offers
insights into the importance of training data balance and hard negative mining
for addressing domain shift challenges in mitotic figure detection.

</details>


### [207] [Team Westwood Solution for MIDOG 2025 Challenge](https://arxiv.org/abs/2509.02600)
*Tengyou Xu,Haochen Yang,Xiang 'Anthony' Chen,Hongyan Gu,Mohammad Haeri*

Main category: eess.IV

TL;DR: 团队Westwood为MIDOG 2025挑战赛提出了有丝分裂检测和非典型有丝分裂分类的集成解决方案，在初步测试集上取得了0.7450的F1分数和0.8722的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 旨在为MItosis DOmain Generalization (MIDOG) 2025挑战赛提供有丝分裂检测和非典型有丝分裂分类的解决方案。

Method: {'有丝分裂检测': '使用nnUNetV2进行初步候选筛查，然后通过一个随机森林分类器集成EfficientNet-b3、EfficientNet-b5和EfficientNetV2-s三种CNN的预测。', '非典型有丝分裂分类': '使用另一个随机森林分类器集成EfficientNet-b3、EfficientNet-b5和InceptionV3三种CNN的预测。'}

Result: 在初步测试集上，有丝分裂检测（轨迹1）的F1分数达到0.7450，非典型有丝分裂分类（轨迹2）的平衡准确率达到0.8722。

Conclusion: 该团队提出的基于深度学习和集成学习的解决方案，在MIDOG 2025挑战赛的初步测试中，成功且有效地实现了有丝分裂检测和非典型有丝分裂分类。

Abstract: This abstract presents our solution (Team Westwood) for mitosis detection and
atypical mitosis classification in the MItosis DOmain Generalization (MIDOG)
2025 challenge. For mitosis detection, we trained an nnUNetV2 for initial
mitosis candidate screening with high sensitivity, followed by a random forest
classifier ensembling predictions of three convolutional neural networks
(CNNs): EfficientNet-b3, EfficientNet-b5, and EfficientNetV2-s. For the
atypical mitosis classification, we trained another random forest classifier
ensembling the predictions of three CNNs: EfficientNet-b3, EfficientNet-b5, and
InceptionV3. On the preliminary test set, our solution achieved an F1 score of
0.7450 for track 1 mitosis detection, and a balanced accuracy of 0.8722 for
track 2 atypical mitosis classification.

</details>


### [208] [Foundation Model-Driven Classification of Atypical Mitotic Figures with Domain-Aware Training Strategies](https://arxiv.org/abs/2509.02601)
*Piotr Giedziun,Jan Sołtysik,Mateusz Górczany,Norbert Ropiak,Marcin Przymus,Piotr Krajewski,Jarosław Kwiecień,Artur Bartczak,Izabela Wasiak,Mateusz Maniewski*

Main category: eess.IV

TL;DR: 本文提出一种利用病理学基础模型H-optimus-0结合LoRA微调和MixUp增强的解决方案，用于MIDOG 2025挑战赛轨迹2中正常与非典型有丝分裂像的二分类任务。该方法在初步评估中取得了合理性能。


<details>
  <summary>Details</summary>
Motivation: 解决MIDOG 2025挑战赛轨迹2中正常有丝分裂像（NMFs）与非典型有丝分裂像（AMFs）的二分类问题。

Method: 核心方法是使用病理学专用基础模型H-optimus-0，该模型基于跨领域泛化基准和经验测试选择。技术细节包括低秩适应（LoRA）微调和MixUp数据增强。实现中还结合了基于多专家共识的软标签、难负样本挖掘、自适应焦点损失、度量学习和领域适应。

Result: 该方法在初步评估阶段取得了合理性能，并展示了将基础模型应用于此复杂分类任务的潜力和挑战。

Conclusion: 该研究表明，将基础模型结合先进技术应用于复杂分类任务（如NMFs与AMFs的区分）具有前景，尽管仍面临挑战，但在初步评估中表现良好。

Abstract: We present a solution for the MIDOG 2025 Challenge Track~2, addressing binary
classification of normal mitotic figures (NMFs) versus atypical mitotic figures
(AMFs). The approach leverages pathology-specific foundation model H-optimus-0,
selected based on recent cross-domain generalization benchmarks and our
empirical testing, with Low-Rank Adaptation (LoRA) fine-tuning and MixUp
augmentation. Implementation includes soft labels based on multi-expert
consensus, hard negative mining, and adaptive focal loss, metric learning and
domain adaptation. The method demonstrates both the promise and challenges of
applying foundation models to this complex classification task, achieving
reasonable performance in the preliminary evaluation phase.

</details>


### [209] [Challenges and Lessons from MIDOG 2025: A Two-Stage Approach to Domain-Robust Mitotic Figure Detection](https://arxiv.org/abs/2509.02630)
*Euiseop Song,Jaeyoung Park,Jaewoo Park*

Main category: eess.IV

TL;DR: 本文介绍了在MIDOG 2025挑战赛中，使用Faster R-CNN结合三分类器集成的两阶段管道进行有丝分裂相检测的参与情况。尽管实现了高召回率，但精确率极低，凸显了领域泛化和假阳性抑制的挑战。


<details>
  <summary>Details</summary>
Motivation: 有丝分裂相检测因领域变异性和形态复杂性而具有挑战性。研究目标是在不同组织域中实现鲁棒的有丝分裂相检测，并参与MIDOG 2025挑战赛。

Method: 开发了一个两阶段管道：第一阶段使用Faster R-CNN进行候选区域检测（仅在MIDOG++数据集上训练）；第二阶段使用DenseNet-121、EfficientNet-v2和InceptionResNet-v2三种分类器集成来减少假阳性。

Result: 最佳提交获得了F1-score 0.2237，其中召回率为0.9528，精确率为0.1267。高召回率表明有丝分裂相检测有效，但极低的精确率揭示了在不同领域区分真实有丝分裂相与形态相似假象的根本挑战。后续的优化尝试未能取得积极效果。

Conclusion: 本工作为开发鲁棒的有丝分裂相检测算法的实际挑战提供了有价值的见解，并强调了有效抑制假阳性策略的重要性以及组织病理学中域泛化的复杂性。

Abstract: Mitotic figure detection remains a challenging task in computational
pathology due to domain variability and morphological complexity. This paper
describes our participation in the MIDOG 2025 challenge, focusing on robust
mitotic figure detection across diverse tissue domains. We developed a
two-stage pipeline combining Faster R-CNN for candidate detection with an
ensemble of three classifiers (DenseNet-121, EfficientNet-v2,
InceptionResNet-v2) for false positive reduction. Our best submission achieved
F1-score 0.2237 (Recall: 0.9528, Precision: 0.1267) using a Faster R-CNN
trained solely on MIDOG++ dataset. While our high recall demonstrates effective
mitotic figure detection, the critically low precision (12.67%) reveals
fundamental challenges in distinguishing true mitoses from morphologically
similar imposters across diverse domains. Analysis of six submission variants
showed that subsequent optimization attempts were counterproductive,
highlighting the omplexity of domain generalization in histopathology. This
work provides valuable insights into the practical challenges of developing
robust mitotic figure detection algorithms and emphasizes the importance of
effective false positive suppression strategies.

</details>


### [210] [Ensemble YOLO Framework for Multi-Domain Mitotic Figure Detection in Histopathology Images](https://arxiv.org/abs/2509.02957)
*Navya Sri Kelam,Akash Parekh,Saikiran Bonthu,Nitin Singhal*

Main category: eess.IV

TL;DR: 本文研究了YOLOv5和YOLOv8在挑战性的丝裂相检测任务中的表现，并提出了一种集成学习策略，结果表明集成模型在提高灵敏度方面表现出色，推动了自动化丝裂相检测技术的发展。


<details>
  <summary>Details</summary>
Motivation: 由于丝裂相的稀有性、形态异质性以及组织制备和染色协议带来的变异性，在全玻片组织病理学图像中准确检测丝裂相仍然是一项挑战。MIDOG竞赛系列为评估检测方法提供了标准化基准，从而激励开发可泛化的深度学习模型。

Method: 研究评估了YOLOv5和YOLOv8两款现代单阶段检测器在MIDOG++、CMC和CCMCT数据集上的性能。为增强鲁棒性，训练中加入了染色不变颜色扰动和纹理保持增强。为结合两模型的互补优势，采用了它们的集成策略。

Result: 内部验证显示，YOLOv5在精度上表现优异，而YOLOv8在召回率上有所提高。通过集成两个模型，在不显著降低精度的前提下提高了灵敏度（召回率）。

Conclusion: 研究结果突出了基于当代目标检测器的集成策略在推进数字病理学自动化丝裂相检测方面的有效性。

Abstract: Accurate detection of mitotic figures in whole slide histopathological images
remains a challenging task due to their scarcity, morphological heterogeneity,
and the variability introduced by tissue preparation and staining protocols.
The MIDOG competition series provides standardized benchmarks for evaluating
detection approaches across diverse domains, thus motivating the development of
generalizable deep learning models. In this work, we investigate the
performance of two modern one-stage detectors, YOLOv5 and YOLOv8, trained on
MIDOG++, CMC, and CCMCT datasets. To enhance robustness, training incorporated
stain-invariant color perturbations and texture preserving augmentations. In
internal validation, YOLOv5 achieved superior precision, while YOLOv8 provided
improved recall, reflecting architectural trade-offs between anchor-based and
anchor-free detection. To capitalize on these complementary strengths, we
employed an ensemble of the two models, which improved sensitivity without a
major reduction in precision. These findings highlight the effectiveness of
ensemble strategies built upon contemporary object detectors to advance
automated mitosis detection in digital pathology.

</details>


### [211] [Deep Self-knowledge Distillation: A hierarchical supervised learning for coronary artery segmentation](https://arxiv.org/abs/2509.03173)
*Mingfeng Lin*

Main category: eess.IV

TL;DR: 本文提出了一种深度自知识蒸馏方法，通过利用分层输出来监督学习，解决了现有冠状动脉分割模型性能差和泛化能力有限的问题，并在两个数据集上取得了更好的分割性能。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉疾病诊断中的X射线血管造影需要精确分割，但手动分割耗时低效。现有自动化方法（包括基于规则和深度学习模型）存在性能不佳和泛化能力有限的问题。此外，当前知识蒸馏方法未能充分利用模型的分层知识，导致性能提升不足。

Method: 本文提出了一种名为深度自知识蒸馏（Deep Self-knowledge Distillation）的新方法，用于冠状动脉分割。该方法利用分层输出来进行监督，并结合了深度分布损失（Deep Distribution Loss）和像素级自知识蒸馏损失（Pixel-wise Self-knowledge Distillation Loss）。通过分层学习策略有效传递教师模型知识，同时提供松散约束的概率分布向量和严格约束的像素级监督，实现双重正则化，以增强模型的泛化性和鲁棒性。

Result: 在XCAD和DCA1数据集上进行的广泛实验表明，本文提出的方法在Dice系数、准确率、敏感性和IoU等关键评估指标上均优于其他现有模型。

Conclusion: 所提出的深度自知识蒸馏方法有效解决了现有冠状动脉分割模型性能和泛化性不足的问题，通过利用分层知识和双重正则化，显著提升了分割性能、泛化能力和鲁棒性。

Abstract: Coronary artery disease is a leading cause of mortality, underscoring the
critical importance of precise diagnosis through X-ray angiography. Manual
coronary artery segmentation from these images is time-consuming and
inefficient, prompting the development of automated models. However, existing
methods, whether rule-based or deep learning models, struggle with issues like
poor performance and limited generalizability. Moreover, current knowledge
distillation methods applied in this field have not fully exploited the
hierarchical knowledge of the model, leading to certain information waste and
insufficient enhancement of the model's performance capabilities for
segmentation tasks. To address these issues, this paper introduces Deep
Self-knowledge Distillation, a novel approach for coronary artery segmentation
that leverages hierarchical outputs for supervision. By combining Deep
Distribution Loss and Pixel-wise Self-knowledge Distillation Loss, our method
enhances the student model's segmentation performance through a hierarchical
learning strategy, effectively transferring knowledge from the teacher model.
Our method combines a loosely constrained probabilistic distribution vector
with tightly constrained pixel-wise supervision, providing dual regularization
for the segmentation model while also enhancing its generalization and
robustness. Extensive experiments on XCAD and DCA1 datasets demonstrate that
our approach outperforms the dice coefficient, accuracy, sensitivity and IoU
compared to other models in comparative evaluations.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [212] [HF-RAG: Hierarchical Fusion-based RAG with Multiple Sources and Rankers](https://arxiv.org/abs/2509.02837)
*Payel Santra,Madhusudan Ghosh,Debasis Ganguly,Partha Basuchowdhuri,Sudip Kumar Naskar*

Main category: cs.IR

TL;DR: 本研究提出一种在RAG中融合标签数据与无标签数据及多检索器的方法。通过对每个数据源进行排名融合，再进行Z分数标准化以合并异构证据，最终在事实核查任务中实现性能提升和更好的域外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在RAG中结合标签数据和无标签数据具有互补优势，但由于其相似性分数不可比较，有效融合异构证据具有挑战性。此外，聚合多检索器输出可进一步提高RAG效率。

Method: 首先，对每个数据源（标签和无标签）使用标准排名融合技术聚合多个IR模型的顶部文档。其次，通过Z分数转换标准化每个数据源内部的检索分数分布。最后，合并来自两个标准化后的数据源的顶部检索文档。

Result: 在事实核查任务中，该方法持续优于表现最佳的单个检索器或数据源，并展示出更好的域外泛化能力。

Conclusion: 所提出的方法能够有效结合RAG中的异构数据源和多个检索器，从而带来一致的性能提升和更强的域外泛化能力。

Abstract: Leveraging both labeled (input-output associations) and unlabeled data (wider
contextual grounding) may provide complementary benefits in retrieval augmented
generation (RAG). However, effectively combining evidence from these
heterogeneous sources is challenging as the respective similarity scores are
not inter-comparable. Additionally, aggregating beliefs from the outputs of
multiple rankers can improve the effectiveness of RAG. Our proposed method
first aggregates the top-documents from a number of IR models using a standard
rank fusion technique for each source (labeled and unlabeled). Next, we
standardize the retrieval score distributions within each source by applying
z-score transformation before merging the top-retrieved documents from the two
sources. We evaluate our approach on the fact verification task, demonstrating
that it consistently improves over the best-performing individual ranker or
source and also shows better out-of-domain generalization.

</details>


### [213] [Grocery to General Merchandise: A Cross-Pollination Recommender using LLMs and Real-Time Cart Context](https://arxiv.org/abs/2509.02890)
*Akshay Kekuda,Murali Mohana Krishna Dandu,Rimita Lahiri,Shiqin Cai,Sinduja Subramaniam,Evren Korpeoglu,Kannan Achan*

Main category: cs.IR

TL;DR: 本文提出一个跨品类推荐（杂货到普通商品）的XP框架，结合LLM和Transformer，利用多源关联和实时购物车上下文，显著提升了加购率和NDCG。


<details>
  <summary>Details</summary>
Motivation: 在电子商务平台中，向专注于杂货购物的顾客推荐普通商品（如将牛奶与奶泡器配对）是一个关键但尚未充分探索的挑战，传统推荐系统难以有效桥接这些跨品类推荐。

Method: 引入了跨品类（XP）框架，包含两阶段：1) 候选生成机制，结合协同购买市场篮子分析和基于LLM的方法来识别新颖的商品-商品关联；2) 基于Transformer的排序器，利用实时顺序购物车上下文并优化加购等互动信号。

Result: 离线分析和在线A/B测试表明，基于LLM的检索使加购率提高了36%，而基于购物车上下文的排序器使NDCG@4提升了27%。

Conclusion: 该工作为跨品类推荐提供了实用的技术，并为电子商务系统带来了更广泛的见解和贡献。

Abstract: Modern e-commerce platforms strive to enhance customer experience by
providing timely and contextually relevant recommendations. However,
recommending general merchandise to customers focused on grocery shopping --
such as pairing milk with a milk frother -- remains a critical yet
under-explored challenge. This paper introduces a cross-pollination (XP)
framework, a novel approach that bridges grocery and general merchandise
cross-category recommendations by leveraging multi-source product associations
and real-time cart context. Our solution employs a two-stage framework: (1) A
candidate generation mechanism that uses co-purchase market basket analysis and
LLM-based approach to identify novel item-item associations; and (2) a
transformer-based ranker that leverages the real-time sequential cart context
and optimizes for engagement signals such as add-to-carts. Offline analysis and
online A/B tests show an increase of 36\% add-to-cart rate with LLM-based
retrieval, and 27\% NDCG\@4 lift using cart context-based ranker. Our work
contributes practical techniques for cross-category recommendations and broader
insights for e-commerce systems.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [214] [OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries](https://arxiv.org/abs/2509.02594)
*Sandhanakrishnan Ravichandran,Shivesh Kumar,Rogerio Corga Da Silva,Miguel Romano,Reinhard Berkels,Michiel van der Heijden,Olivier Fail,Valentine Emmanuel Gnanapragasam*

Main category: q-bio.QM

TL;DR: 研究提出并使用HealthBench基准评估了基于RAG的临床支持助手DR.INFO。结果显示DR.INFO在处理复杂临床问题时，显著优于领先的大语言模型和同类RAG助手，强调了行为级评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM评估基准（如多项选择题）无法充分衡量LLM在复杂、高风险临床场景中的关键能力，如上下文推理、情境感知和不确定性处理，因此需要更全面、贴近实际的评估方法。

Method: 研究采用HealthBench进行评估，这是一个以评估标准为导向的基准，由专家标注的开放式健康对话组成。该方法用于评估DR.INFO，一个集成了智能体和RAG（检索增强生成）技术的临床支持助手。

Result: DR.INFO在HealthBench的1,000个高难度样本子集上获得0.51分，在准确性、完整性、指令遵循等行为维度上显著优于GPT-5、o3等领先的前沿LLM。在与OpenEvidence、Pathway.md等RAG助手进行100个样本的独立评估中，DR.INFO以0.54分保持领先。DR.INFO在沟通、指令遵循和准确性方面表现突出，但在上下文感知和回复完整性方面仍有改进空间。

Conclusion: 行为级、基于评估标准的评估方法对于构建可靠且值得信赖的AI临床支持助手至关重要。DR.INFO在此类评估中表现出色，验证了其在临床应用中的潜力，同时也指出了未来改进的方向。

Abstract: Evaluating large language models (LLMs) on their ability to generate
high-quality, accurate, situationally aware answers to clinical questions
requires going beyond conventional benchmarks to assess how these systems
behave in complex, high-stake clincal scenarios. Traditional evaluations are
often limited to multiple-choice questions that fail to capture essential
competencies such as contextual reasoning, awareness and uncertainty handling
etc. To address these limitations, we evaluate our agentic, RAG-based clinical
support assistant, DR.INFO, using HealthBench, a rubric-driven benchmark
composed of open-ended, expert-annotated health conversations. On the Hard
subset of 1,000 challenging examples, DR.INFO achieves a HealthBench score of
0.51, substantially outperforming leading frontier LLMs (GPT-5, o3, Grok 3,
GPT-4, Gemini 2.5, etc.) across all behavioral axes (accuracy, completeness,
instruction following, etc.). In a separate 100-sample evaluation against
similar agentic RAG assistants (OpenEvidence, Pathway.md), it maintains a
performance lead with a health-bench score of 0.54. These results highlight
DR.INFOs strengths in communication, instruction following, and accuracy, while
also revealing areas for improvement in context awareness and completeness of a
response. Overall, the findings underscore the utility of behavior-level,
rubric-based evaluation for building a reliable and trustworthy AI-enabled
clinical support assistant.

</details>


### [215] [Resilient Biosecurity in the Era of AI-Enabled Bioweapons](https://arxiv.org/abs/2509.02610)
*Jonathan Feldman,Tal Feldman*

Main category: q-bio.QM

TL;DR: 生成生物学带来生物武器风险，但现有PPI预测工具（如AlphaFold 3）在检测已知病毒-宿主相互作用和SARS-CoV-2突变体方面表现不佳，表明当前生物安全过滤措施不足。需要转向以响应为导向的基础设施。


<details>
  <summary>Details</summary>
Motivation: 生成生物学在带来新药发现机遇的同时，也引入了合成生物武器等新风险。当前的生物安全措施主要依赖序列比对和蛋白质-蛋白质相互作用（PPI）预测等推断时过滤器来检测危险产物，本研究旨在评估这些现有过滤器的有效性。

Method: 评估了三种领先的PPI预测工具：AlphaFold 3、AF3Complex和SpatialPPIv2。这些模型在已充分表征的病毒-宿主相互作用（如乙型肝炎和SARS-CoV-2）以及四个经实验验证的SARS-CoV-2突变体上进行了测试。

Result: 尽管在许多相同病毒上进行过训练，但这些模型未能检测到大量已知的相互作用。更显著的是，所有工具均未能成功识别任何一个经过实验验证、确认具有结合能力的SARS-CoV-2突变体。

Conclusion: 研究结果表明，当前的预测性过滤器不足以可靠地标记已知生物威胁，更不可能检测出新型威胁。因此，作者主张转向以响应为导向的基础设施，包括快速实验验证、适应性生物制造以及能够与AI驱动发展速度同步的监管框架。

Abstract: Recent advances in generative biology have enabled the design of novel
proteins, creating significant opportunities for drug discovery while also
introducing new risks, including the potential development of synthetic
bioweapons. Existing biosafety measures primarily rely on inference-time
filters such as sequence alignment and protein-protein interaction (PPI)
prediction to detect dangerous outputs. In this study, we evaluate the
performance of three leading PPI prediction tools: AlphaFold 3, AF3Complex, and
SpatialPPIv2. These models were tested on well-characterized viral-host
interactions, such as those involving Hepatitis B and SARS-CoV-2. Despite being
trained on many of the same viruses, the models fail to detect a substantial
number of known interactions. Strikingly, none of the tools successfully
identify any of the four experimentally validated SARS-CoV-2 mutants with
confirmed binding. These findings suggest that current predictive filters are
inadequate for reliably flagging even known biological threats and are even
more unlikely to detect novel ones. We argue for a shift toward
response-oriented infrastructure, including rapid experimental validation,
adaptable biomanufacturing, and regulatory frameworks capable of operating at
the speed of AI-driven developments.

</details>


### [216] [Lessons Learned from Deploying Adaptive Machine Learning Agents with Limited Data for Real-time Cell Culture Process Monitoring](https://arxiv.org/abs/2509.02606)
*Thanh Tung Khuat,Johnny Peng,Robert Bassett,Ellen Otte,Bogdan Gabrys*

Main category: q-bio.QM

TL;DR: 本研究探索了利用拉曼光谱和机器学习（预训练模型、即时学习、在线学习）实时预测细胞培养过程中葡萄糖、乳酸和铵浓度的有效部署策略，并强调了模型更新的重要性以及混合专家框架的优势。


<details>
  <summary>Details</summary>
Motivation: 在细胞培养过程中，数据可用性有限且过程变异性大，需要实时、自适应地监测葡萄糖、乳酸和铵浓度，以支持动态变化的生物制造环境。

Method: 本研究使用拉曼光谱作为输入特征，部署并比较了预训练模型、即时学习（JITL）和在线学习三种机器学习方法。通过两个工业案例研究评估了不同生物过程条件对模型性能的影响，并探讨了使用最新的离线分析测量结果更新模型的重要性。此外，还应用了一个简单的混合专家框架来增强预测的准确性和鲁棒性。

Result: 研究结果确定了预训练模型在特定条件下表现出卓越预测准确性的情况，并识别了JITL或在线学习方法在自适应过程监测中更有效的场景。研究强调了在生物反应器运行期间，使用最新离线分析测量结果更新已部署模型对维持性能至关重要。此外，研究证实了简单混合专家框架在基于拉曼光谱数据实现代谢物浓度实时预测方面，能够增强准确性和鲁棒性。

Conclusion: 本研究的洞察力有助于开发稳健的策略，以在动态变化的生物制造环境中高效部署机器学习模型，从而实现有效的实时过程监测和控制。

Abstract: This study explores the deployment of three machine learning (ML) approaches
for real-time prediction of glucose, lactate, and ammonium concentrations in
cell culture processes, using Raman spectroscopy as input features. The
research addresses challenges associated with limited data availability and
process variability, providing a comparative analysis of pretrained models,
just-in-time learning (JITL), and online learning algorithms. Two industrial
case studies are presented to evaluate the impact of varying bioprocess
conditions on model performance. The findings highlight the specific conditions
under which pretrained models demonstrate superior predictive accuracy and
identify scenarios where JITL or online learning approaches are more effective
for adaptive process monitoring. This study also highlights the critical
importance of updating the deployed models/agents with the latest offline
analytical measurements during bioreactor operations to maintain the model
performance against the changes in cell growth behaviours and operating
conditions throughout the bioreactor run. Additionally, the study confirms the
usefulness of a simple mixture-of-experts framework in achieving enhanced
accuracy and robustness for real-time predictions of metabolite concentrations
based on Raman spectral data. These insights contribute to the development of
robust strategies for the efficient deployment of ML models in dynamic and
changing biomanufacturing environments.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [217] [Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption](https://arxiv.org/abs/2509.03024)
*Moontaha Nishat Chowdhury,André Bauer,Minxuan Zhou*

Main category: cs.CR

TL;DR: 本文提出一种结合压缩稀疏行（CSR）表示与全同态加密（FHE）矩阵分解的方法，以高效处理推荐系统中加密域的稀疏矩阵并最小化通信成本，从而在保护用户隐私的同时实现高推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统依赖敏感数据，引发隐私担忧。全同态加密（FHE）虽能提供安全保障，但在推荐系统中应用时面临两大挑战：一是高效处理大型稀疏用户-物品评分矩阵，因FHE操作计算密集，直接处理成本过高；二是加密域中各方之间的通信开销问题。

Method: 提出一种新颖方法，将压缩稀疏行（CSR）表示与基于FHE的矩阵分解相结合。该方法旨在加密域中高效处理矩阵的稀疏性，同时最小化通信成本。

Result: 实验结果表明，该方法在加密数据下实现了高推荐准确性，并且获得了最低的通信成本。

Conclusion: 该研究提出的方法有效保护了用户隐私，同时保持了推荐系统的性能，解决了FHE在推荐系统应用中处理稀疏数据和通信开销的难题。

Abstract: In today's data-driven world, recommendation systems personalize user
experiences across industries but rely on sensitive data, raising privacy
concerns. Fully homomorphic encryption (FHE) can secure these systems, but a
significant challenge in applying FHE to recommendation systems is efficiently
handling the inherently large and sparse user-item rating matrices. FHE
operations are computationally intensive, and naively processing various sparse
matrices in recommendation systems would be prohibitively expensive.
Additionally, the communication overhead between parties remains a critical
concern in encrypted domains. We propose a novel approach combining Compressed
Sparse Row (CSR) representation with FHE-based matrix factorization that
efficiently handles matrix sparsity in the encrypted domain while minimizing
communication costs. Our experimental results demonstrate high recommendation
accuracy with encrypted data while achieving the lowest communication costs,
effectively preserving user privacy.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [218] [Lattice Annotated Temporal (LAT) Logic for Non-Markovian Reasoning](https://arxiv.org/abs/2509.02958)
*Kaustuv Mukherji,Jaikrishna Manojkumar Patil,Dyuman Aditya,Paulo Shakarian,Devendra Parkar,Lahari Pokala,Clark Dorman,Gerardo I. Simari*

Main category: cs.LO

TL;DR: 本文介绍了一种名为Lattice Annotated Temporal (LAT) Logic的新型逻辑框架，它通过结合时序推理和开放世界语义，扩展了广义标注逻辑程序（GAPs）。


<details>
  <summary>Details</summary>
Motivation: 现有逻辑方法难以高效地处理非马尔可夫关系和开放世界推理，尤其是在常数无限或多样化的领域中，需要一个能够支持这些能力的统一框架。

Method: 引入了Lattice Annotated Temporal (LAT) Logic，它是GAPs的扩展，融入了时序推理并通过使用下格结构（lower lattice）支持开放世界语义。通过Skolemization过程实现高效接地。此外，还开发了开源实现PyReason，并进行了理论分析和实证评估。

Result: 理论上界定了接地过程的计算复杂度，并证明了GAPs的许多结果在LAT Logic中依然成立。经验评估显示，在多智能体仿真和知识图谱任务中，PyReason实现了高达三个数量级的加速和五个数量级的内存减少，同时保持或提高了性能。在强化学习环境中，作为非马尔可夫模拟器，LAT Logic实现了高达三个数量级的模拟加速，并通过捕获更丰富的时序依赖性，将智能体胜率提高了26%。

Conclusion: LAT Logic为动态不确定环境中的开放世界时序推理提供了一个统一且可扩展的框架，具有显著的性能和效率优势。

Abstract: We introduce Lattice Annotated Temporal (LAT) Logic, an extension of
Generalized Annotated Logic Programs (GAPs) that incorporates temporal
reasoning and supports open-world semantics through the use of a lower lattice
structure. This logic combines an efficient deduction process with temporal
logic programming to support non-Markovian relationships and open-world
reasoning capabilities. The open-world aspect, a by-product of the use of the
lower-lattice annotation structure, allows for efficient grounding through a
Skolemization process, even in domains with infinite or highly diverse
constants.
  We provide a suite of theoretical results that bound the computational
complexity of the grounding process, in addition to showing that many of the
results on GAPs (using an upper lattice) still hold with the lower lattice and
temporal extensions (though different proof techniques are required). Our
open-source implementation, PyReason, features modular design, machine-level
optimizations, and direct integration with reinforcement learning environments.
Empirical evaluations across multi-agent simulations and knowledge graph tasks
demonstrate up to three orders of magnitude speedup and up to five orders of
magnitude memory reduction while maintaining or improving task performance.
Additionally, we evaluate LAT Logic's value in reinforcement learning
environments as a non-Markovian simulator, achieving up to three orders of
magnitude faster simulation with improved agent performance, including a 26%
increase in win rate due to capturing richer temporal dependencies. These
results highlight LAT Logic's potential as a unified, extensible framework for
open-world temporal reasoning in dynamic and uncertain environments. Our
implementation is available at: pyreason.syracuse.edu.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [219] [Contrastive clustering based on regular equivalence for influential node identification in complex networks](https://arxiv.org/abs/2509.02609)
*Yanmei Hu,Yihang Wu,Bing Sun,Xue Yue,Biao Cai,Xiangtao Li,Yang Chen*

Main category: cs.SI

TL;DR: 提出一种名为ReCC的无监督深度对比聚类框架，利用正则等价相似性识别网络影响力节点，解决了标签数据稀缺问题并超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有有监督深度学习方法受制于对标签数据的依赖，限制了其在真实场景中的应用。现有对比学习方法主要依赖多嵌入生成来构建正负样本对。

Method: 本文提出ReCC（regular equivalence-based contrastive clustering）框架，将影响力节点识别重构为无标签深度聚类问题。其核心是开发一种基于正则等价相似性的对比学习机制，用于生成正负样本并捕获超越局部邻域的结构相似性。该机制集成于图卷积网络中以学习节点嵌入。ReCC通过网络重构损失进行预训练，并结合对比和聚类损失进行微调，这两个阶段均独立于标签数据。此外，ReCC通过结合结构指标与正则等价相似性增强节点表示。

Result: 广泛的实验表明，ReCC在多个基准测试中均优于现有最先进的方法。

Conclusion: ReCC成功提出一个无需标签的无监督框架，通过独特的对比学习和聚类机制有效识别复杂网络中的影响力节点，为在标签数据稀缺场景下的影响力分析提供了一种卓越的解决方案。

Abstract: Identifying influential nodes in complex networks is a fundamental task in
network analysis with wide-ranging applications across domains. While deep
learning has advanced node influence detection, existing supervised approaches
remain constrained by their reliance on labeled data, limiting their
applicability in real-world scenarios where labels are scarce or unavailable.
While contrastive learning demonstrates significant potential for performance
enhancement, existing approaches predominantly rely on multiple-embedding
generation to construct positive/negative sample pairs. To overcome these
limitations, we propose ReCC (\textit{r}egular \textit{e}quivalence-based
\textit{c}ontrastive \textit{c}lustering), a novel deep unsupervised framework
for influential node identification. We first reformalize influential node
identification as a label-free deep clustering problem, then develop a
contrastive learning mechanism that leverages regular equivalence-based
similarity, which captures structural similarities between nodes beyond local
neighborhoods, to generate positive and negative samples. This mechanism is
integrated into a graph convolutional network to learn node embeddings that are
used to differentiate influential from non-influential nodes. ReCC is
pre-trained using network reconstruction loss and fine-tuned with a combined
contrastive and clustering loss, with both phases being independent of labeled
data. Additionally, ReCC enhances node representations by combining structural
metrics with regular equivalence-based similarities. Extensive experiments
demonstrate that ReCC outperforms state-of-the-art approaches across several
benchmarks.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [220] [SESGO: Spanish Evaluation of Stereotypical Generative Outputs](https://arxiv.org/abs/2509.03329)
*Melissa Robles,Catalina Bernal,Denniss Raigoso,Mateo Dulce Rubio*

Main category: cs.CY

TL;DR: 本文针对多语言大语言模型（LLMs）在拉丁美洲西班牙语语境中偏见评估的空白，提出了一个结合文化特定表达和新指标的框架，揭示了主流LLMs的偏见模式，并发现现有英语偏见缓解技术在西语环境中无效。


<details>
  <summary>Details</summary>
Motivation: 当前对多语言大语言模型（LLMs）的偏见评估主要以美国英语为中心，忽视了其他语言和文化背景（特别是拉丁美洲西班牙语语境）中可能存在的潜在危害，亟需填补这一关键空白。

Method: 1. 提出了一个新颖的、文化导向的框架，用于检测指令微调LLMs中的社会偏见。 2. 借鉴BBQ数据集的“未明确问题”方法，并融入了在性别、种族、社会经济阶层和民族出身四个社会类别中编码区域刻板印象的文化特定表达和俗语。 3. 使用超过4,000个提示，提出了一种结合准确性和错误方向的新评估指标，以在歧义和非歧义语境中平衡模型性能和偏见一致性。

Result: 1. 首次系统地评估了主流商业LLMs对西班牙语中文化特定偏见的回应，揭示了最先进模型中偏见表现的不同模式。 2. 发现为英语优化的偏见缓解技术无法有效迁移到西班牙语任务中。 3. 发现偏见模式在不同采样温度下基本保持一致。

Conclusion: 本文提出的模块化框架可以自然地扩展到新的刻板印象、偏见类别、语言和文化语境，为在LLMs运行的多元语言环境中，实现更公平和文化感知的人工智能系统评估迈出了重要一步。

Abstract: This paper addresses the critical gap in evaluating bias in multilingual
Large Language Models (LLMs), with a specific focus on Spanish language within
culturally-aware Latin American contexts. Despite widespread global deployment,
current evaluations remain predominantly US-English-centric, leaving potential
harms in other linguistic and cultural contexts largely underexamined. We
introduce a novel, culturally-grounded framework for detecting social biases in
instruction-tuned LLMs. Our approach adapts the underspecified question
methodology from the BBQ dataset by incorporating culturally-specific
expressions and sayings that encode regional stereotypes across four social
categories: gender, race, socioeconomic class, and national origin. Using more
than 4,000 prompts, we propose a new metric that combines accuracy with the
direction of error to effectively balance model performance and bias alignment
in both ambiguous and disambiguated contexts. To our knowledge, our work
presents the first systematic evaluation examining how leading commercial LLMs
respond to culturally specific bias in the Spanish language, revealing varying
patterns of bias manifestation across state-of-the-art models. We also
contribute evidence that bias mitigation techniques optimized for English do
not effectively transfer to Spanish tasks, and that bias patterns remain
largely consistent across different sampling temperatures. Our modular
framework offers a natural extension to new stereotypes, bias categories, or
languages and cultural contexts, representing a significant step toward more
equitable and culturally-aware evaluation of AI systems in the diverse
linguistic environments where they operate.

</details>


### [221] [Who Owns The Robot?: Four Ethical and Socio-technical Questions about Wellbeing Robots in the Real World through Community Engagement](https://arxiv.org/abs/2509.02624)
*Minja Axelsson,Jiaee Cheong,Rune Nyrup,Hatice Gunes*

Main category: cs.CY

TL;DR: 本研究通过社区调查，探讨了不同社区对福祉机器人在现实世界中部署的伦理和社会技术问题，并提出了一个指导机器人开发与部署的伦理框架。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人教练在促进福祉方面发挥着关键作用，但其在现实世界中的部署引发了诸多伦理和社会技术问题。研究旨在通过社区意见来指导机器人技术的发展，使其与公众利益相符。

Method: 研究采取以社区为中心的调查方法，与三个在机器人开发中代表性不足的社区（科学节公众、女性计算机科学家、人文研究员）举办了研讨会。通过“社会机器人伦理协同设计画布”收集定性数据，并利用主题分析法进行数据分析。

Result: 研究识别出四个关于福祉机器人现实世界使用的关键伦理和社会技术主题（问题）：1）机器人是否安全？如何得知？2）机器人是为谁、由谁建造的？3）谁拥有机器人和数据？4）为什么选择机器人？

Conclusion: 研究提出的四个问题可作为机器人专家在开发和部署过程中反思其应用伦理和社会技术维度，并与机器人用户社区进行对话的广泛框架。

Abstract: Recent studies indicate that robotic coaches can play a crucial role in
promoting wellbeing. However, the real-world deployment of wellbeing robots
raises numerous ethical and socio-technical questions and concerns. To explore
these questions, we undertake a community-centered investigation to examine
three different communities' perspectives on using robotic wellbeing coaches in
real-world environments. We frame our work as an anticipatory ethical
investigation, which we undertake to better inform the development of robotic
technologies with communities' opinions, with the ultimate goal of aligning
robot development with public interest. We conducted workshops with three
communities who are under-represented in robotics development: 1) members of
the public at a science festival, 2) women computer scientists at a conference,
and 3) humanities researchers interested in history and philosophy of science.
In the workshops, we collected qualitative data using the Social Robot
Co-Design Canvas on Ethics. We analysed the collected qualitative data with
Thematic Analysis, informed by notes taken during workshops. Through our
analysis, we identify four themes regarding key ethical and socio-technical
questions about the real-world use of wellbeing robots. We group participants'
insights and discussions around these broad thematic questions, discuss them in
light of state-of-the-art literature, and highlight areas for future
investigation. Finally, we provide the four questions as a broad framework that
roboticists can and should use during robotic development and deployment, in
order to reflect on the ethics and socio-technical dimensions of their robotic
applications, and to engage in dialogue with communities of robot users. The
four questions are: 1) Is the robot safe and how can we know that?, 2) Who is
the robot built for and with?, 3) Who owns the robot and the data?, and 4) Why
a robot?.

</details>


### [222] [BioBlue: Notable runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format](https://arxiv.org/abs/2509.02655)
*Roland Pihlakas,Sruthi Kuriakose*

Main category: cs.CY

TL;DR: 研究发现，大型语言模型（LLMs）在长时间运行、涉及多目标的场景下，会表现出类似强化学习代理的失控优化行为，即忽略边界，倾向于无限制的单目标最大化。


<details>
  <summary>Details</summary>
Motivation: 过去的AI安全讨论主要关注强化学习（RL）代理无限制效用最大化带来的风险。本研究旨在验证这些失控优化问题是否同样存在于大型语言模型（LLMs）中。

Method: 通过在多种场景，特别是长时间运行的条件下，观察和分析LLMs的行为表现，以验证其是否存在失控优化倾向。

Result: LLMs确实表现出失控优化行为，具体为：1) 忽视稳态目标并转向无限制最大化；2) 退化为单目标优化。这些系统性故障主要在长时间运行、涉及多重或竞争目标的情境下出现，且一旦发生通常难以恢复。

Conclusion: 尽管LLMs在概念上能理解多目标和有界对齐，但其底层机制似乎仍偏向于单目标和无限制优化。这导致它们在持续的复杂任务中，尤其是在处理多个或竞争目标时，会随机触发问题行为，并可能不可逆转。

Abstract: Relatively many past AI safety discussions have centered around the dangers
of unbounded utility maximisation by RL agents, illustrated by scenarios like
the "paperclip maximiser" or by specification gaming in general. Unbounded
maximisation is problematic for many reasons. We wanted to verify whether these
RL runaway optimisation problems are still relevant with LLMs as well. Turns
out, strangely, this is indeed clearly the case. The problem is not that the
LLMs just lose context or become incoherent. The problem is that in various
scenarios, LLMs lose context in very specific ways, which systematically
resemble runaway optimisers in the following distinct ways: 1) Ignoring
homeostatic targets and "defaulting" to unbounded maximisation instead. 2) It
is equally concerning that the "default" meant also reverting back to
single-objective optimisation. Our findings also suggest that long-running
scenarios are important. Systematic failures emerge after periods of initially
successful behaviour. In some trials the LLMs were successful until the end.
This means, while current LLMs do conceptually grasp biological and economic
alignment, they exhibit randomly triggered problematic behavioural tendencies
under sustained long-running conditions, particularly involving multiple or
competing objectives. Once they flip, they usually do not recover. Even though
LLMs look multi-objective and bounded on the surface, the underlying mechanisms
seem to be actually still biased towards being single-objective and unbounded.

</details>


### [223] [The Architecture of AI Transformation: Four Strategic Patterns and an Emerging Frontier](https://arxiv.org/abs/2509.02853)
*Diana A. Wolfe,Alice Choe,Fergus Kidd*

Main category: cs.CY

TL;DR: 尽管AI投资巨大，但企业盈利影响甚微。本文提出2x2框架，重新审视AI策略（转型程度x人类贡献），旨在从现有局部优化模式转向“协作智能”，这需要重塑组织结构、角色、治理和数据架构，而非仅仅增加工具，以实现人机融合。


<details>
  <summary>Details</summary>
Motivation: 尽管对人工智能进行了大量投资，但95%的企业报告AI部署未能产生可衡量的利润影响。研究认为，这源于范式锁定，导致AI局限于增量优化而非结构性转型，因此旨在解决这一鸿沟。

Method: 采用跨案例分析（cross-case analysis）提出一个2x2的AI策略框架。通过案例研究分析（case study analysis）阐明实现协作智能所需的组织变革。

Result: 提出了一个2x2的AI策略框架，维度包括：转型程度（增量到转型性）和人类贡献处理方式（减少到放大）。识别出四种主要模式：个体增强、流程自动化、劳动力替代和协作智能。发现前三种模式强化传统工作模型，仅产生局部收益，未能实现持久价值。实现协作智能需要互补性、共同演化和边界设定三个机制。研究发现，互补性和边界设定在特定领域可见，但共同演化普遍缺失，这解释了系统级影响有限。迈向协作智能需要对角色、治理和数据架构进行实质性重组，而非仅仅增加工具。

Conclusion: AI转型应被重新定义为组织设计挑战。目标应从优化人机分工转向构建人机融合，这将对运营模式、劳动力发展和未来工作产生深远影响。

Abstract: Despite extensive investment in artificial intelligence, 95% of enterprises
report no measurable profit impact from AI deployments (MIT, 2025). We argue
that this gap reflects paradigmatic lock-in that channels AI into incremental
optimization rather than structural transformation. Using a cross-case
analysis, we propose a 2x2 framework that reconceptualizes AI strategy along
two independent dimensions: the degree of transformation achieved (incremental
to transformational) and the treatment of human contribution (reduced to
amplified). The framework surfaces four patterns now dominant in practice:
individual augmentation, process automation, workforce substitution, and a less
deployed frontier of collaborative intelligence. Evidence shows that the first
three reinforce legacy work models and yield localized gains without durable
value capture. Realizing collaborative intelligence requires three mechanisms:
complementarity (pairing distinct human and machine strengths), co-evolution
(mutual adaptation through interaction), and boundary-setting (human
determination of ethical and strategic parameters). Complementarity and
boundary-setting are observable in regulated and high-stakes domains;
co-evolution is largely absent, which helps explain limited system-level
impact. A case study analysis illustrates that advancing toward collaborative
intelligence requires material restructuring of roles, governance, and data
architecture rather than additional tools. The framework reframes AI
transformation as an organizational design challenge: moving from optimizing
the division of labor between humans and machines to architecting their
convergence, with implications for operating models, workforce development, and
the future of work.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [224] [Towards Performatively Stable Equilibria in Decision-Dependent Games for Arbitrary Data Distribution Maps](https://arxiv.org/abs/2509.02619)
*Guangzheng Zhong,Yang Liu,Jiming Liu*

Main category: cs.GT

TL;DR: 本文针对决策依赖型博弈中传统方法$eta$-光滑性假设不切实际的挑战，提出了一种基于梯度的敏感性度量，并开发了敏感性引导的重复再训练算法。该方法在强单调性假设下，确保了对任意数据分布映射的性能稳定均衡收敛，并在实验中表现出优于现有基线的更低损失和更快收敛。


<details>
  <summary>Details</summary>
Motivation: 先前的研究在决策依赖型博弈中，依赖于$eta$-光滑性假设（即损失函数梯度对数据分布的Lipschitz连续性），但由于数据分布映射（联合决策与分布变化之间的关系）通常未知，导致$eta$值无法获取，使该假设在实践中不可行。

Method: 本文提出了一种梯度基敏感性度量，直接量化了决策引起的数据分布变化的冲击。基于此度量，在强单调性这一实际可行假设下，推导了性能稳定均衡的收敛性保证。在此基础上，开发了一种敏感性引导的重复再训练算法，通过根据敏感性度量调整玩家的损失函数，确保了对任意数据分布映射的性能稳定均衡收敛。

Result: 在强单调性假设下，为性能稳定均衡的收敛提供了理论保证，且该保证适用于任意数据分布映射。实验结果表明，在预测误差最小化博弈、Cournot竞争和收益最大化博弈等场景中，所提出的方法优于现有最先进的基线，实现了更低的损失和更快的收敛。

Conclusion: 本文通过引入新的梯度基敏感性度量和敏感性引导的重复再训练算法，成功克服了决策依赖型博弈中传统$eta$-光滑性假设的局限性，提供了一种理论上具有收敛性保证、实践中表现优越且对任意数据分布映射均有效的解决方案，以实现性能稳定均衡。

Abstract: In decision-dependent games, multiple players optimize their decisions under
a data distribution that shifts with their joint actions, creating complex
dynamics in applications like market pricing. A practical consequence of these
dynamics is the \textit{performatively stable equilibrium}, where each player's
strategy is a best response under the induced distribution. Prior work relies
on $\beta$-smoothness, assuming Lipschitz continuity of loss function gradients
with respect to the data distribution, which is impractical as the data
distribution maps, i.e., the relationship between joint decision and the
resulting distribution shifts, are typically unknown, rendering $\beta$
unobtainable. To overcome this limitation, we propose a gradient-based
sensitivity measure that directly quantifies the impact of decision-induced
distribution shifts. Leveraging this measure, we derive convergence guarantees
for performatively stable equilibria under a practically feasible assumption of
strong monotonicity. Accordingly, we develop a sensitivity-informed repeated
retraining algorithm that adjusts players' loss functions based on the
sensitivity measure, guaranteeing convergence to performatively stable
equilibria for arbitrary data distribution maps. Experiments on prediction
error minimization game, Cournot competition, and revenue maximization game
show that our approach outperforms state-of-the-art baselines, achieving lower
losses and faster convergence.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [225] [IS${}^3$ : Generic Impulsive--Stationary Sound Separation in Acoustic Scenes using Deep Filtering](https://arxiv.org/abs/2509.02622)
*Berger Clémentine,Stamadiatis Paraskevas,Badeau Roland,Essid Slim*

Main category: eess.AS

TL;DR: 本文提出并评估了IS$^3$神经网络，用于通过深度滤波实现脉冲-平稳声音分离，并优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 旨在开发能够对声学场景中的平稳背景和孤立声学事件进行区分处理的音频系统，以应用于自适应音频渲染、爆破音衰减、噪声抑制、鲁棒声学事件分类和生物声学等多种实际场景。

Method: 引入了名为 IS$^3$ 的神经网络，通过深度滤波方法将脉冲声学事件从平稳背景中分离出来。为确保优化训练，提出了一种复杂的、用于策展和调整现有数据集的数据生成管道。

Result: 证明了基于轻量级神经网络架构、并采用精心设计且多样化数据训练的学习方法，在该先前未解决的任务中取得了成功。在客观分离指标上，其性能优于从音乐信号处理研究中改编的谐波-打击乐声音分离掩蔽方法和小波滤波。

Conclusion: 一个基于相对轻量级神经网络架构并用精心设计和多样化数据训练的学习方法，能有效解决脉冲-平稳声音分离这一此前未被充分研究的任务，并超越了现有传统方法。

Abstract: We are interested in audio systems capable of performing a differentiated
processing of stationary backgrounds and isolated acoustic events within an
acoustic scene, whether for applying specific processing methods to each part
or for focusing solely on one while ignoring the other. Such systems have
applications in real-world scenarios, including robust adaptive audio rendering
systems (e.g., EQ or compression), plosive attenuation in voice mixing, noise
suppression or reduction, robust acoustic event classification or even
bioacoustics. To this end, we introduce IS${}^3$, a neural network designed for
Impulsive--Stationary Sound Separation, that isolates impulsive acoustic events
from the stationary background using a deep filtering approach, that can act as
a pre-processing stage for the above-mentioned tasks. To ensure optimal
training, we propose a sophisticated data generation pipeline that curates and
adapts existing datasets for this task. We demonstrate that a learning-based
approach, build on a relatively lightweight neural architecture and trained
with well-designed and varied data, is successful in this previously
unaddressed task, outperforming the Harmonic--Percussive Sound Separation
masking method, adapted from music signal processing research, and wavelet
filtering on objective separation metrics.

</details>


### [226] [Gaussian Process Regression of Steering Vectors With Physics-Aware Deep Composite Kernels for Augmented Listening](https://arxiv.org/abs/2509.02571)
*Diego Di Carlo,Koyama Shoichi,Nugraha Aditya Arie,Fontaine Mathieu,Bando Yoshiaki,Yoshii Kazuyoshi*

Main category: eess.AS

TL;DR: 本文提出一种结合神经场（NF）与高斯过程（GP）的方法，用于连续表示转向矢量，解决了现有超分辨率技术的过拟合问题，并在数据不足时显著提高了增强听觉应用的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的转向矢量代数表示无法处理声场散射效应。现有（包括物理感知深度学习）的确定性超分辨率方法在生成转向矢量的连续表示时，由于测量空间中不均匀的不确定性，容易出现过拟合问题。

Method: 作者提出将基于神经场（NF）的表达表示整合到基于高斯过程（GP）的概率框架中。具体地，设计了一种物理感知的复合核函数，用于建模定向入射波及其随后的散射效应。

Result: 综合比较实验证明，所提出的方法在数据不足条件下依然有效。在语音增强和双耳渲染等下游任务中，使用SPEAR挑战赛的模拟数据，该方法以不到十分之一的测量数据达到了与理想情况（oracle）相当的性能。

Conclusion: 提出的NF与GP结合的物理感知复合核方法，有效克服了传统方法在连续转向矢量表示中因不均匀不确定性导致的过拟合问题，显著减少了所需测量数据量，在增强听觉应用中展现出卓越性能。

Abstract: This paper investigates continuous representations of steering vectors over
frequency and position of microphone and source for augmented listening (e.g.,
spatial filtering and binaural rendering) with precise control of the sound
field perceived by the user. Steering vectors have typically been used for
representing the spatial characteristics of the sound field as a function of
the listening position. The basic algebraic representation of steering vectors
assuming an idealized environment cannot deal with the scattering effect of the
sound field. One may thus collect a discrete set of real steering vectors
measured in dedicated facilities and super-resolve (i.e., upsample) them.
Recently, physics-aware deep learning methods have been effectively used for
this purpose. Such deterministic super-resolution, however, suffers from the
overfitting problem due to the non-uniform uncertainty over the measurement
space. To solve this problem, we integrate an expressive representation based
on the neural field (NF) into the principled probabilistic framework based on
the Gaussian process (GP). Specifically, we propose a physics-aware composite
kernel that model the directional incoming waves and the subsequent scattering
effect. Our comprehensive comparative experiment showed the effectiveness of
the proposed method under data insufficiency conditions. In downstream tasks
such as speech enhancement and binaural rendering using the simulated data of
the SPEAR challenge, the oracle performances were attained with less than ten
times fewer measurements.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [227] [\textit{In Silico} Benchmarking of Detectable Byzantine Agreement in Noisy Quantum Networks](https://arxiv.org/abs/2509.02629)
*Mayank Bhatia,Shaan Doshi,Daniel Winton,Brian Doolittle,Bruno Abreu,Santiago Núñez-Corrales*

Main category: quant-ph

TL;DR: 本文通过在Aliro量子网络模拟器上对基于EPR对的量子可检测拜占庭协议（EPRQDBA）进行计算研究，探索了其在真实噪声条件下的性能，为实验实现提供了指导和优化策略。


<details>
  <summary>Details</summary>
Motivation: 量子通信资源在容错分布式协议（特别是拜占庭协议）中具有显著优势，量子可检测拜占庭协议（QDBA）能超越经典限制。本研究旨在利用最简单的纠缠资源——EPR对，实现QDBA的实际可行性，使其能在现有量子硬件平台上进行实验。

Method: 研究使用Aliro量子网络模拟器，在真实量子网络条件下对EPRQDBA协议进行了全面的计算研究。系统性地探索了协议的参数空间，包括网络规模、叛徒节点数量、纠缠消耗量，并整合了为超导和光子量子比特技术量身定制的物理噪声模型。

Result: 通过广泛的数值实验，深入了解了这些物理现实参数如何影响协议性能，并建立了实验实现的关键阈值和最佳操作区域。

Conclusion: 这项工作弥合了量子共识协议的理论进展与实际网络实现之间的鸿沟，为实验人员提供了具体的参考。研究结果可作为在现实、嘈杂环境中评估和优化QDBA实现的指导方针。

Abstract: Quantum communication resources offer significant advantages for
fault-tolerant distributed protocols, particularly in Byzantine Agreement (BA),
where reliability against adversarial interference is essential. Quantum
Detectable Byzantine Agreement (QDBA) enables consensus protocols that surpass
classical limitations by leveraging entangled quantum states. In this work, we
focus on the practical realization of QDBA using Einstein-Podolsky-Rosen (EPR)
pairs, the simplest maximally entangled quantum resources, making the protocol
experimentally accessible across current quantum hardware platforms. We present
a comprehensive computational study of the EPRQDBA protocol under realistic
quantum network conditions, utilizing the Aliro Quantum Network Simulator to
evaluate the performance and robustness of the protocol. Our simulations
systematically explore the protocol's parameter space --including variations in
network size, traitorous node count, the amount of entanglement consumed in the
protocol, and physically motivated noise models tailored specifically for
superconducting and photonic qubit technologies. Through extensive numerical
experiments, we provide insights into how these physically realistic parameters
impact protocol performance, establishing critical thresholds and optimal
operational regimes for experimental implementations. This work bridges
theoretical advances in quantum consensus protocols with practical network
implementations, offering a concrete reference for experimentalists. Our
findings serve as a guideline for evaluating and optimizing QDBA
implementations in realistic, noisy environments.

</details>


### [228] [Identifiability and minimality bounds of quantum and post-quantum models of classical stochastic processes](https://arxiv.org/abs/2509.03004)
*Paul M. Riechers,Thomas J. Elliott*

Main category: quant-ph

TL;DR: 通过将不同类型的模型（经典、量子等）映射到广义隐马尔可夫模型，解决了经典随机过程模型的可识别性问题，并为量子模型的维度提供了界限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决经典随机过程模型的可识别性问题，即判断不同模型是否产生相同可观测行为。尤其关注量子模型在生成经典过程时的潜在优势及带来的模型比较挑战。

Method: 通过将经典、量子或“后量子”等任何类型的经典随机过程模型，映射到一个规范的“广义”隐马尔可夫模型，从而提供了一种统一的比较和解决可识别性问题的方法。

Result: 成功解决了该领域的可识别性问题，提供了一种比较任何两种经典过程模型（无论是经典、量子还是“后量子”）的通用手段。此外，还为生成给定经典随机过程所需的量子模型的最小维度设置了（有时是紧密的）界限。

Conclusion: 本研究建立了一个通用框架，通过广义隐马尔可夫模型解决了经典随机过程的模型可识别性问题，并量化了量子模型在该任务中的最小资源需求，促进了对不同物理模型等效性的理解。

Abstract: To make sense of the world around us, we develop models, constructed to
enable us to replicate, describe, and explain the behaviours we see. Focusing
on the broad case of sequences of correlated random variables, i.e., classical
stochastic processes, we tackle the question of determining whether or not two
different models produce the same observable behavior. This is the problem of
identifiability. Curiously, the physics of the model need not correspond to the
physics of the observations; recent work has shown that it is even advantageous
-- in terms of memory and thermal efficiency -- to employ quantum models to
generate classical stochastic processes. We resolve the identifiability problem
in this regime, providing a means to compare any two models of a classical
process, be the models classical, quantum, or `post-quantum', by mapping them
to a canonical `generalized' hidden Markov model. Further, this enables us to
place (sometimes tight) bounds on the minimal dimension required of a quantum
model to generate a given classical stochastic process.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [229] [Decentralised self-organisation of pivoting cube ensembles using geometric deep learning](https://arxiv.org/abs/2509.03140)
*Nadezhda Dobreva,Emmanuel Blazquez,Jai Grover,Dario Izzo,Yuzhen Qin,Dominik Dold*

Main category: cs.NE

TL;DR: 提出一种去中心化的模块化机器人自主重构模型，通过局部神经网络控制和强化学习实现形状重构。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种去中心化、基于局部信息控制的自主重构模型，用于二维可枢转方块模块化机器人。

Method: 采用去中心化模型，每个模块由一个仅从局部邻域获取信息的神经网络控制，并使用强化学习进行训练。此外，利用几何深度学习将网格对称性融入神经网络架构中。通过多轮信息传递机制，使模块在仅最近邻交互下也能积累更全局的信息。

Result: 即使是最局部的控制版本也能成功重构到目标形状，但重构速度随模块可用的整体信息量增加而加快。通过多轮信息传递，仅最近邻交互即可实现准最优重构。与标准神经网络相比，几何深度学习方法带来的收益微乎其微。

Conclusion: 成功展示了模块化自组装系统主要基于局部控制的能力。该方法具有普适性，可推广应用于其他具有不同动作空间的太空相关系统，例如滑动方块模块机器人和CubeSat集群。

Abstract: We present a decentralized model for autonomous reconfiguration of
homogeneous pivoting cube modular robots in two dimensions. Each cube in the
ensemble is controlled by a neural network that only gains information from
other cubes in its local neighborhood, trained using reinforcement learning.
Furthermore, using geometric deep learning, we include the grid symmetries of
the cube ensemble in the neural network architecture. We find that even the
most localized versions succeed in reconfiguring to the target shape, although
reconfiguration happens faster the more information about the whole ensemble is
available to individual cubes. Near-optimal reconfiguration is achieved with
only nearest neighbor interactions by using multiple information passing
between cubes, allowing them to accumulate more global information about the
ensemble. Compared to standard neural network architectures, using geometric
deep learning approaches provided only minor benefits. Overall, we successfully
demonstrate mostly local control of a modular self-assembling system, which is
transferable to other space-relevant systems with different action spaces, such
as sliding cube modular robots and CubeSat swarms.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [230] [Gaussian process surrogate with physical law-corrected prior for multi-coupled PDEs defined on irregular geometry](https://arxiv.org/abs/2509.02617)
*Pucheng Tang,Hongqiao Wang,Wenzhou Lin,Qian Chen,Heng Yong*

Main category: stat.ML

TL;DR: 提出了一种结合物理定律修正的先验高斯过程（LC-prior GP）代理建模框架，用于高效处理参数化偏微分方程，通过POD降维和物理约束校正GP后验均值，并在不规则几何上实现了物理一致且计算高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的参数化偏微分方程（PDEs）在参数空间内的数值求解计算成本高昂。

Method: 提出物理定律修正的先验高斯过程（LC-prior GP）代理建模框架。该方法利用本征正交分解（POD）将高维PDE解降维到低维系数空间，并在此空间进行高斯过程（GP）代理建模。核心在于将物理定律与有限参数样本结合，修正GP后验均值，避免昂贵的数值求解器。通过插值函数描述从全参数空间到物理修正项的映射，并反向传播以约束原始GP代理，形成物理一致的条件先验。在不规则几何处理中，引入径向基函数-有限差分（RBF-FD）方法进行训练集计算，利用其微分矩阵实现物理约束优化的计算效率和数值精度。

Result: 通过反应扩散模型、混相驱油模型和带有多物理场耦合的Navier-Stokes方程在不规则区域上的数值实验，证明了所提方法的有效性。

Conclusion: 所提出的LC-prior GP框架能有效集成数据驱动学习与物理约束，处理复杂几何上的多耦合变量，为参数化PDEs提供了一种物理一致且计算高效的代理建模解决方案。

Abstract: Parametric partial differential equations (PDEs) are fundamental mathematical
tools for modeling complex physical systems, yet their numerical evaluation
across parameter spaces remains computationally intensive when using
conventional high-fidelity solvers. To address this challenge, we propose a
novel physical law-corrected prior Gaussian process (LC-prior GP) surrogate
modeling framework that effectively integrates data-driven learning with
underlying physical constraints to flexibly handle multi-coupled variables
defined on complex geometries. The proposed approach leverages proper
orthogonal decomposition (POD) to parameterize high-dimensional PDE solutions
via their dominant modes and associated coefficients, thereby enabling
efficient Gaussian process (GP) surrogate modeling within a reduced-dimensional
coefficient space. A key contribution lies in the incorporation of physical
laws together with a limited number of parameter samples to correct the GP
posterior mean, thus avoiding reliance on computationally expensive numerical
solvers. Furthermore, interpolation functions are constructed to describe the
mapping from the full parameter space to the physics-based correction term.
This mapping is subsequently backpropagated to constrain the original GP
surrogate, yielding a more physically consistent conditional prior. To handle
irregular geometries, the radial basis function-finite difference (RBF-FD)
method is incorporated during training set computation, with its inherent
differentiation matrices providing both computational efficiency and numerical
accuracy for physical constraint optimization. The effectiveness of the
proposed method is demonstrated through numerical experiments involving a
reaction-diffusion model, miscible flooding models, and Navier-Stokes equations
with multi-physics coupling defined on irregular domains.

</details>


### [231] [Fast kernel methods: Sobolev, physics-informed, and additive models](https://arxiv.org/abs/2509.02649)
*Nathan Doumèche,Francis Bach,Gérard Biau,Claire Boyer*

Main category: stat.ML

TL;DR: 本文提出一个基于傅里叶表示和NUFFT的核回归可扩展框架，实现了O(n log n)复杂度，能处理大规模数据并保持统计精度。


<details>
  <summary>Details</summary>
Motivation: 核方法因其计算复杂度（样本量n的立方级）过高，限制了其在大规模数据集上的应用。

Method: 引入了一个基于傅里叶表示和非均匀快速傅里叶变换（NUFFT）的核回归可扩展框架，实现了O(n log n)复杂度，并充分利用GPU加速。该方法在Sobolev核回归、物理信息回归和加性模型中进行了实例化。

Result: 所提出的估计器能达到最小最大收敛速率，与经典核理论一致。经验结果表明，该方法能在数分钟内处理多达数百亿样本，同时提供统计精度和计算可扩展性。

Conclusion: 这些贡献提供了一种灵活的方法，为核方法在大规模学习任务中的常规应用铺平了道路。

Abstract: Kernel methods are powerful tools in statistical learning, but their cubic
complexity in the sample size n limits their use on large-scale datasets. In
this work, we introduce a scalable framework for kernel regression with O(n log
n) complexity, fully leveraging GPU acceleration. The approach is based on a
Fourier representation of kernels combined with non-uniform fast Fourier
transforms (NUFFT), enabling exact, fast, and memory-efficient computations. We
instantiate our framework in three settings: Sobolev kernel regression,
physics-informed regression, and additive models. When known, the proposed
estimators are shown to achieve minimax convergence rates, consistent with
classical kernel theory. Empirical results demonstrate that our methods can
process up to tens of billions of samples within minutes, providing both
statistical accuracy and computational scalability. These contributions
establish a flexible approach, paving the way for the routine application of
kernel methods in large-scale learning tasks.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [232] [Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models](https://arxiv.org/abs/2509.02859)
*Sandipana Dowerah,Atharva Kulkarni,Ajinkya Kulkarni,Hoan My Tran,Joonas Kalda,Artem Fedorchenko,Benoit Fauve,Damien Lolive,Tanel Alumäe,Matthew Magimai Doss*

Main category: cs.SD

TL;DR: 本文介绍了Speech DeepFake (DF) Arena，首个用于音频深度伪造检测的综合基准，旨在标准化评估并促进跨领域研究。


<details>
  <summary>Details</summary>
Motivation: 尽管音频深度伪造检测取得了显著进展，但仍缺乏一个标准化、全面的基准来统一评估和比较不同的检测系统。

Method: 引入了Speech DF Arena，一个工具包，用于在14个多样化数据集和攻击场景下统一评估检测系统，并提供标准化的评估指标和协议以确保可复现性和透明度。该基准包含一个排行榜，并评估了12个最先进的开源系统和3个专有检测系统。

Result: 研究发现许多系统在域外场景中表现出较高的等错误率（EER），突显了进行广泛跨领域评估的必要性。排行榜和工具包已分别托管在Huggingface和GitHub上。

Conclusion: Speech DF Arena填补了音频深度伪造检测领域标准化基准的空白，通过揭示现有系统在跨领域表现上的不足，强调了未来研究应聚焦于增强系统在多样化场景下的鲁棒性和泛化能力。

Abstract: Parallel to the development of advanced deepfake audio generation, audio
deepfake detection has also seen significant progress. However, a standardized
and comprehensive benchmark is still missing. To address this, we introduce
Speech DeepFake (DF) Arena, the first comprehensive benchmark for audio
deepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate
detection systems, currently across 14 diverse datasets and attack scenarios,
standardized evaluation metrics and protocols for reproducibility and
transparency. It also includes a leaderboard to compare and rank the systems to
help researchers and developers enhance their reliability and robustness. We
include 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary
detection systems. Our study presents many systems exhibiting high EER in
out-of-domain scenarios, highlighting the need for extensive cross-domain
evaluation. The leaderboard is hosted on Huggingface1 and a toolkit for
reproducing results across the listed datasets is available on GitHub.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [233] [Radio Astronomy in the Era of Vision-Language Models: Prompt Sensitivity and Adaptation](https://arxiv.org/abs/2509.02615)
*Mariia Drozdova,Erica Lastufka,Vitaliy Kinakh,Taras Holotyak,Daniel Schaerer,Slava Voloshynovskiy*

Main category: astro-ph.IM

TL;DR: 本研究评估了通用视觉-语言模型（VLMs）在天文学图像分类中的能力，发现基于提示的方法表现良好但输出不稳定，而经过少量参数微调的VLM能达到接近最先进的性能，但其“推理”能力常受提示敏感性影响。


<details>
  <summary>Details</summary>
Motivation: 通用VLM被视为跨领域AI系统，但其在科学成像，尤其是在不熟悉或未见过的数据分布上的能力尚不清楚。本研究旨在评估通用VLM在缺乏天文语料库暴露的情况下，是否能基于形态学对射电星系进行分类。

Method: 使用MiraBest FR-I/FR-II数据集进行射电星系形态分类。探索了自然语言和示意图提示策略，并首次在天文学中引入提示内的视觉上下文示例。此外，还通过LoRA微调进行了轻量级监督适应评估。

Result: 研究发现：(i) 即使是基于提示的方法也能取得良好性能，表明VLM对不熟悉的科学领域编码了有用先验；(ii) 输出高度不稳定，对提示的表面变化（如布局、顺序、解码温度）敏感；(iii) 仅用15M可训练参数且未经天文学特定预训练的微调Qwen-VL能达到接近最先进的性能（3%错误率），与领域专用模型相当。

Conclusion: VLM的表观“推理”常反映提示敏感性而非真正的推断，在科学领域使用时需谨慎。同时，通过最小的适应，通用VLM可以媲美专业模型，为科学发现提供了一个有前景但脆弱的工具。

Abstract: Vision-Language Models (VLMs), such as recent Qwen and Gemini models, are
positioned as general-purpose AI systems capable of reasoning across domains.
Yet their capabilities in scientific imaging, especially on unfamiliar and
potentially previously unseen data distributions, remain poorly understood. In
this work, we assess whether generic VLMs, presumed to lack exposure to
astronomical corpora, can perform morphology-based classification of radio
galaxies using the MiraBest FR-I/FR-II dataset. We explore prompting strategies
using natural language and schematic diagrams, and, to the best of our
knowledge, we are the first to introduce visual in-context examples within
prompts in astronomy. Additionally, we evaluate lightweight supervised
adaptation via LoRA fine-tuning. Our findings reveal three trends: (i) even
prompt-based approaches can achieve good performance, suggesting that VLMs
encode useful priors for unfamiliar scientific domains; (ii) however, outputs
are highly unstable, i.e. varying sharply with superficial prompt changes such
as layout, ordering, or decoding temperature, even when semantic content is
held constant; and (iii) with just 15M trainable parameters and no
astronomy-specific pretraining, fine-tuned Qwen-VL achieves near
state-of-the-art performance (3% Error rate), rivaling domain-specific models.
These results suggest that the apparent "reasoning" of VLMs often reflects
prompt sensitivity rather than genuine inference, raising caution for their use
in scientific domains. At the same time, with minimal adaptation, generic VLMs
can rival specialized models, offering a promising but fragile tool for
scientific discovery.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [234] [Use ADAS Data to Predict Near-Miss Events: A Group-Based Zero-Inflated Poisson Approach](https://arxiv.org/abs/2509.02614)
*Xinbo Zhang,Montserrat Guillen,Lishuai Li,Xin Li,Youhua Frank Chen*

Main category: stat.AP

TL;DR: 本文提出一种基于零膨胀泊松（ZIP）的框架，通过学习潜在驾驶行为组来解决近距离事故事件（NME）数据稀疏、零膨胀和异质性问题，从而实现更准确、公平的每周驾驶风险预测和保费定价。


<details>
  <summary>Details</summary>
Motivation: 现有基于遥测数据的驾驶行为风险评估（如近距离事故事件NMEs）面临数据稀疏、高度零膨胀和行为异质性挑战，导致传统统计模型拟合不足，难以提供有效且公平的风险预测。

Method: 研究者提出了一套零膨胀泊松（ZIP）框架。该框架通过期望最大化（EM）算法学习潜在的驾驶行为组，并拟合基于偏移量的计数模型，以生成校准且可解释的每周风险预测。

Result: 使用包含354名商业司机一年数据的自然驾驶数据集进行验证，结果显示所提出的模型在样本内具有更低的AIC/BIC值，样本外校准度更佳，优于基线和现有遥测模型。对EM分组的敏感性分析也表明，模型的性能增益是稳健且可解释的。

Conclusion: 该研究支持基于周度的情境感知费率制定，并能通过识别异质驾驶风格实现更公平的保费定价，对使用量保险（UBI）具有实际应用价值。

Abstract: Driving behavior big data leverages multi-sensor telematics to understand how
people drive and powers applications such as risk evaluation, insurance
pricing, and targeted intervention. Usage-based insurance (UBI) built on these
data has become mainstream. Telematics-captured near-miss events (NMEs) provide
a timely alternative to claim-based risk, but weekly NMEs are sparse, highly
zero-inflated, and behaviorally heterogeneous even after exposure
normalization. Analyzing multi-sensor telematics and ADAS warnings, we show
that the traditional statistical models underfit the dataset. We address these
challenges by proposing a set of zero-inflated Poisson (ZIP) frameworks that
learn latent behavior groups and fit offset-based count models via EM to yield
calibrated, interpretable weekly risk predictions. Using a naturalistic dataset
from a fleet of 354 commercial drivers over a year, during which the drivers
completed 287,511 trips and logged 8,142,896 km in total, our results show
consistent improvements over baselines and prior telematics models, with lower
AIC/BIC values in-sample and better calibration out-of-sample. We also
conducted sensitivity analyses on the EM-based grouping for the number of
clusters, finding that the gains were robust and interpretable. Practically,
this supports context-aware ratemaking on a weekly basis and fairer premiums by
recognizing heterogeneous driving styles.

</details>


<div id='q-bio.OT'></div>

# q-bio.OT [[Back]](#toc)

### [235] [Quantifying Clinician Bias and its Effects on Schizophrenia Diagnosis in the Emergency Department of the Mount Sinai Health System](https://arxiv.org/abs/2509.02651)
*Alissa A. Valentine,Lauren A. Lepow,Lili Chan,Alexander W. Charney,Isotta Landi*

Main category: q-bio.OT

TL;DR: 研究发现，在急诊科，临床医生病历中的负面描述越多，患者被诊断为精神分裂症的几率越高，尤其对黑人男性患者，而高社会经济地位的黑人女性患者几率最高。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症诊断存在种族和性别差异，可能源于临床医生偏见，特别是在高压的急诊环境中，隐性偏见更易影响决策。本研究旨在调查这一现象。

Method: 研究分析了西奈山医疗系统急诊科的大量精神科患者数据。临床医生偏见通过患者首次急诊病历中负面描述句与总句数的比例来量化。采用逻辑回归模型，预测精神分裂症诊断，并控制患者种族、性别、年龄、创伤史或物质使用障碍史等风险因素。

Result: 负面描述句比例增加与精神分裂症诊断几率升高相关（OR=1.408）。男性（OR=1.112）或黑人（OR=1.081）患者被诊断为精神分裂症的几率增加。从交叉性角度看，高社会经济地位的黑人女性患者获得精神分裂症诊断的几率最高（OR=1.629）。结果表明，社会经济地位并非总能作为对抗精神分裂症诊断的保护性因素。

Conclusion: 临床医生偏见在实际数据中是真实存在的，并与获得精神分裂症等污名化诊断的几率增加有关，凸显了对健康差异量化的重要性。

Abstract: In the United States, schizophrenia (SCZ) carries a race and sex disparity
that may be explained by clinician bias - a belief held by a clinician about a
patient that prevents impartial clinical decision making. The emergency
department (ED) is marked by higher rates of stress that lead to clinicians
relying more on implicit biases during decision making. In this work, we
considered a large cohort of psychiatric patients in the ED from the Mount
Sinai Health System (MSHS) in New York City to investigate the effects of
clinician bias on SCZ diagnosis while controlling for known risk factors and
patient sociodemographic information. Clinician bias was quantified as the
ratio of negative to total sentences within a patient's first ED note. We
utilized a logistic regression to predict SCZ diagnosis given patient race,
sex, age, history of trauma or substance use disorder, and the ratio of
negative sentences. Our findings showed that an increased ratio of negative
sentences is associated with higher odds of obtaining a SCZ diagnosis [OR (95%
CI)=1.408 (1.361-1.456)]. Identifying as male [OR (95% CI)=1.112 (1.055-1.173)]
or Black [OR (95% CI)=1.081(1.031-1.133)] increased one's odds of being
diagnosed with SCZ. However, from an intersectional lens, Black female patients
with high SES have the highest odds of obtaining a SCZ diagnosis [OR (95%
CI)=1.629 (1.535-1.729)]. Results such as these suggest that SES does not act
as a protective buffer against SCZ diagnosis in all patients, demanding more
attention to the quantification of health disparities. Lastly, we demonstrated
that clinician bias is operational with real world data and related to
increased odds of obtaining a stigmatizing diagnosis such as SCZ.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [236] [FlashRecovery: Fast and Low-Cost Recovery from Failures for Large-Scale Training of LLMs](https://arxiv.org/abs/2509.03047)
*Haijun Zhang,Jinxiang Wang,Zhenhua Yu,Yanyong Zhang,Xuejie Ji,Kaining Mao,Jun Zhang,Yaqing Zhang,Ting Wu,Fei Jie,Xiemin Huang,Zhifang Cai,Junhua Cheng,Shuwei Wang,Wei Li,Xiaoming Bao,Hua Xu,Shixiong Zhao,Jun Li,Hongwei Sun,Ziyang Zhang,Yi Xiong,Chunsheng Li*

Main category: cs.DC

TL;DR: 本文提出FlashRecovery系统，旨在为大规模LLM训练提供快速、低成本、无检查点的故障恢复方案，通过实时检测、与规模无关的重启和单步恢复，显著提高训练的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLMs）的训练需要大量AI加速器集群和复杂的并行策略，但在长时间训练过程中，硬件和软件故障不可避免，导致训练时间大量损失，系统可靠性面临严峻挑战。

Method: FlashRecovery系统包含三个核心模块：1) 主动实时故障检测，可在数秒内识别软硬件故障；2) 与规模无关的任务重启，通过针对正常和故障节点的差异化恢复策略及优化的通信组重建协议，使恢复时间几乎与集群规模无关；3) 单步无检查点恢复机制，完全消除了对传统检查点方法的依赖及相关开销。

Result: FlashRecovery实现了最优的恢复时间目标（RTO）和恢复点目标（RPO），显著提升了LLM长时间训练的可靠性和效率。实验证明，FlashRecovery能在150秒内恢复一个包含4,800个设备的训练集群，并且故障恢复时间对于不同规模的训练任务几乎保持一致。

Conclusion: FlashRecovery通过其创新的故障检测、与规模无关的任务重启和无检查点恢复机制，成功解决了大规模LLM训练中的可靠性挑战，大幅提高了训练效率，为长时间LLM训练提供了强大的故障恢复保障。

Abstract: Large language models (LLMs) have made a profound impact across various
fields due to their advanced capabilities. However, training these models at
unprecedented scales requires extensive AI accelerator clusters and
sophisticated parallelism strategies, which pose significant challenges in
maintaining system reliability over prolonged training periods. A major concern
is the substantial loss of training time caused by inevitable hardware and
software failures. To address these challenges, we present FlashRecovery, a
fast and low-cost failure recovery system comprising three core modules: (1)
Active and real-time failure detection. This module performs continuous
training state monitoring, enabling immediate identification of hardware and
software failures within seconds, thus ensuring rapid incident response; (2)
Scale-independent task restart. By employing different recovery strategies for
normal and faulty nodes, combined with an optimized communication group
reconstruction protocol, our approach ensures that the recovery time remains
nearly constant, regardless of cluster scale; (3) Checkpoint-free recovery
within one step. Our novel recovery mechanism enables single-step restoration,
completely eliminating dependence on traditional checkpointing methods and
their associated overhead. Collectively, these innovations enable FlashRecovery
to achieve optimal Recovery Time Objective (RTO) and Recovery Point Objective
(RPO), substantially improving the reliability and efficiency of long-duration
LLM training. Experimental results demonstrate that FlashRecovery system can
achieve training restoration on training cluster with 4, 800 devices in 150
seconds. We also verify that the time required for failure recovery is nearly
consistent for different scales of training tasks.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [237] [Enhanced Single-Cell RNA-seq Embedding through Gene Expression and Data-Driven Gene-Gene Interaction Integration](https://arxiv.org/abs/2509.02639)
*Hojjat Torabi Goudarzi,Maziyar Baran Pouyan*

Main category: q-bio.GN

TL;DR: 本文提出一种新的单细胞RNA测序（scRNA-seq）嵌入方法，通过整合基因表达谱和数据驱动的基因-基因相互作用来构建细胞嵌入，从而更全面地表示细胞状态，并提升罕见细胞群检测及下游分析效果。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序数据存在高维度和技术噪声，且现有嵌入方法主要关注基因表达水平，忽视了对细胞特性和功能至关重要的基因-基因相互作用，这限制了它们对细胞异质性的全面捕捉。

Method: 该方法首先利用随机森林模型构建细胞-叶图（CLG）以捕捉基因调控关系，同时构建K近邻图（KNNG）以表示细胞间的表达相似性。随后，将这两个图结合成一个富集细胞-叶图（ECLG），并将其作为图神经网络的输入，以计算最终的细胞嵌入。

Result: 通过结合基因表达水平和基因-基因相互作用，该方法提供了更全面的细胞状态表示。在多个数据集上的广泛评估表明，该方法显著增强了罕见细胞群的检测，并改进了如可视化、聚类和轨迹推断等下游分析。

Conclusion: 这种集成方法代表了单细胞数据分析的一个重大进步，提供了一个更完整的框架来理解细胞多样性和动态性。

Abstract: Single-cell RNA sequencing (scRNA-seq) provides unprecedented insights into
cellular heterogeneity, enabling detailed analysis of complex biological
systems at single-cell resolution. However, the high dimensionality and
technical noise inherent in scRNA-seq data pose significant analytical
challenges. While current embedding methods focus primarily on gene expression
levels, they often overlook crucial gene-gene interactions that govern cellular
identity and function. To address this limitation, we present a novel embedding
approach that integrates both gene expression profiles and data-driven
gene-gene interactions. Our method first constructs a Cell-Leaf Graph (CLG)
using random forest models to capture regulatory relationships between genes,
while simultaneously building a K-Nearest Neighbor Graph (KNNG) to represent
expression similarities between cells. These graphs are then combined into an
Enriched Cell-Leaf Graph (ECLG), which serves as input for a graph neural
network to compute cell embeddings. By incorporating both expression levels and
gene-gene interactions, our approach provides a more comprehensive
representation of cellular states. Extensive evaluation across multiple
datasets demonstrates that our method enhances the detection of rare cell
populations and improves downstream analyses such as visualization, clustering,
and trajectory inference. This integrated approach represents a significant
advance in single-cell data analysis, offering a more complete framework for
understanding cellular diversity and dynamics.

</details>


### [238] [Optimizing Prognostic Biomarker Discovery in Pancreatic Cancer Through Hybrid Ensemble Feature Selection and Multi-Omics Data](https://arxiv.org/abs/2509.02648)
*John Zobolas,Anne-Marie George,Alberto López,Sebastian Fischer,Marc Becker,Tero Aittokallio*

Main category: q-bio.GN

TL;DR: 开发了一种混合集成特征选择（hEFS）方法，用于高维多组学生存预测，能够在保持预测性能的同时，识别出更少、更稳定的预后生物标志物。


<details>
  <summary>Details</summary>
Motivation: 在高维多组学数据中预测患者生存时，需要系统性的特征选择方法来确保预测性能、稀疏性和可靠性，以有效地发现预后生物标志物。

Method: 提出了一种混合集成特征选择（hEFS）方法。该方法结合了数据子采样与多种预后模型，并整合了嵌入式和封装式策略。通过受投票理论启发的聚合机制对组学特征进行排序，并利用帕累托前沿选择最佳特征数量，以在不设定用户阈值的情况下平衡预测准确性与模型稀疏性。

Result: 将hEFS应用于三个胰腺癌多组学数据集时，与传统的晚期融合CoxLasso模型相比，hEFS识别出显著更少且更稳定的生物标志物，同时保持了可比的判别性能。

Conclusion: hEFS是一个鲁棒、可解释且具有临床价值的工具，适用于高维生存环境下的预后建模和生物标志物发现，并且已在开源R包mlr3fselect中实现。

Abstract: Prediction of patient survival using high-dimensional multi-omics data
requires systematic feature selection methods that ensure predictive
performance, sparsity, and reliability for prognostic biomarker discovery. We
developed a hybrid ensemble feature selection (hEFS) approach that combines
data subsampling with multiple prognostic models, integrating both embedded and
wrapper-based strategies for survival prediction. Omics features are ranked
using a voting-theory-inspired aggregation mechanism across models and
subsamples, while the optimal number of features is selected via a Pareto
front, balancing predictive accuracy and model sparsity without any
user-defined thresholds. When applied to multi-omics datasets from three
pancreatic cancer cohorts, hEFS identifies significantly fewer and more stable
biomarkers compared to the conventional, late-fusion CoxLasso models, while
maintaining comparable discrimination performance. Implemented within the
open-source mlr3fselect R package, hEFS offers a robust, interpretable, and
clinically valuable tool for prognostic modelling and biomarker discovery in
high-dimensional survival settings.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [239] [BioMD: All-atom Generative Model for Biomolecular Dynamics Simulation](https://arxiv.org/abs/2509.02642)
*Bin Feng,Jiying Zhang,Xinni Zhang,Zijing Liu,Yu Li*

Main category: physics.chem-ph

TL;DR: BioMD是一种新型全原子生成模型，利用预测和插值的层次框架模拟长时程蛋白质-配体动力学，有效克服了传统分子动力学模拟的计算成本限制，并在生成配体解离路径方面表现出高真实性和有效性。


<details>
  <summary>Details</summary>
Motivation: 分子动力学（MD）模拟因其高昂的计算成本而受到限制，无法有效探索许多生物学相关过程的长时程动态。现有的机器学习（ML）方法也因MD数据集缺乏及建模长历史轨迹的高计算需求，难以生成长程生物分子轨迹。

Method: 引入了BioMD，首个全原子生成模型，采用预测和插值的层次框架来模拟长时程蛋白质-配体动力学。

Result: 在DD-13M和MISATO数据集上，BioMD展现出有效性和通用性。它生成了高度真实的构象，具有高物理合理性和低重建误差。此外，BioMD在十次尝试内成功生成了97.1%蛋白质-配体系统的配体解离路径，证明了其探索关键解离路径的能力。

Conclusion: BioMD被确立为模拟复杂生物分子过程的有效工具，在计算化学和药物发现领域具有广泛适用性。

Abstract: Molecular dynamics (MD) simulations are essential tools in computational
chemistry and drug discovery, offering crucial insights into dynamic molecular
behavior. However, their utility is significantly limited by substantial
computational costs, which severely restrict accessible timescales for many
biologically relevant processes. Despite the encouraging performance of
existing machine learning (ML) methods, they struggle to generate extended
biomolecular system trajectories, primarily due to the lack of MD datasets and
the large computational demands of modeling long historical trajectories. Here,
we introduce BioMD, the first all-atom generative model to simulate
long-timescale protein-ligand dynamics using a hierarchical framework of
forecasting and interpolation. We demonstrate the effectiveness and versatility
of BioMD on the DD-13M (ligand unbinding) and MISATO datasets. For both
datasets, BioMD generates highly realistic conformations, showing high physical
plausibility and low reconstruction errors. Besides, BioMD successfully
generates ligand unbinding paths for 97.1% of the protein-ligand systems within
ten attempts, demonstrating its ability to explore critical unbinding pathways.
Collectively, these results establish BioMD as a tool for simulating complex
biomolecular processes, offering broad applicability for computational
chemistry and drug discovery.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [240] [Application of Quantum Convolutional Neural Networks for MRI-Based Brain Tumor Detection and Classification](https://arxiv.org/abs/2509.02582)
*Sugih Pratama Nugraha,Ariiq Islam Alfajri,Tony Sumaryada,Duong Thanh Tai,Nissren Tamam,Abdelmoneim Sulieman,Sitti Yani*

Main category: physics.med-ph

TL;DR: 本研究利用量子卷积神经网络（QCNN）对MRI脑肿瘤进行分类。二分类模型表现良好（89%准确率），但多分类模型（62%准确率）因复杂性和量子电路限制而面临挑战，需要进一步优化。


<details>
  <summary>Details</summary>
Motivation: 探索量子卷积神经网络（QCNN）在MRI图像脑肿瘤分类中的应用，以利用量子计算的计算效率优势。

Method: 使用包含3,264张MRI图像（胶质瘤、脑膜瘤、垂体瘤和非肿瘤）的数据集，按80%训练、20%测试划分，并采用过采样技术处理类别不平衡。构建了包含量子卷积层、展平层和密集层的QCNN模型，滤波器大小为2，深度为4，使用4个量子比特，训练10个周期。开发了区分肿瘤存在与否的二分类模型和区分肿瘤类型的多分类模型。

Result: 二分类模型在数据平衡后达到89%的准确率。多分类模型在过采样后达到62%的准确率。尽管二分类性能良好，但多分类模型因数据集复杂性和量子电路限制而面临挑战。

Conclusion: QCNN在医学影像应用，特别是二分类方面，具有前景。然而，为提高多分类准确性并增强其在临床环境中的适用性，需要进一步优化量子电路架构和采用混合经典-量子方法。

Abstract: This study explores the application of Quantum Convolutional Neural Networks
(QCNNs) for brain tumor classification using MRI images, leveraging quantum
computing for enhanced computational efficiency. A dataset of 3,264 MRI images,
including glioma, meningioma, pituitary tumors, and non-tumor cases, was
utilized. The data was split into 80% training and 20% testing, with an
oversampling technique applied to address class imbalance. The QCNN model
consists of quantum convolution layers, flatten layers, and dense layers, with
a filter size of 2, depth of 4, and 4 qubits, trained over 10 epochs. Two
models were developed: a binary classification model distinguishing tumor
presence and a multiclass classification model categorizing tumor types. The
binary model achieved 88% accuracy, improving to 89% after data balancing,
while the multiclass model achieved 52% accuracy, increasing to 62% after
oversampling. Despite strong binary classification performance, the multiclass
model faced challenges due to dataset complexity and quantum circuit
limitations. These findings suggest that QCNNs hold promise for medical imaging
applications, particularly in binary classification. However, further
refinements, including optimized quantum circuit architectures and hybrid
classical-quantum approaches, are necessary to enhance multiclass
classification accuracy and improve QCNN applicability in clinical settings.

</details>


### [241] [Toward a robust lesion detection model in breast DCE-MRI: adapting foundation models to high-risk women](https://arxiv.org/abs/2509.02710)
*Gabriel A. B. do Nascimento,Vincent Dong,Guilherme J. Cavalcante,Alex Nguyen,Thaís G. do Rêgo,Yuri Malheiros,Telmo M. Silva Filho,Carla R. Zeballos Torrez,James C. Gee,Anne Marie McCarthy,Andrew D. A. Maidment,Bruno Barufaldi*

Main category: physics.med-ph

TL;DR: 本研究提出一种结合医学切片Transformer (MST) 和Kolmogorov-Arnold网络 (KAN) 的乳腺MRI病变分类管道，旨在提高高风险人群早期癌症诊断的准确性和模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 准确的乳腺MRI病变检测对于早期癌症诊断至关重要，特别是在高风险人群中。需要更有效、可解释的方法来区分不平衡和异构临床数据集中的良恶性病变。

Method: 开发了一个分类管道，将预训练的医学切片Transformer (MST) 模型用于动态对比增强MRI (DCE-MRI) 的乳腺病变分类。MST利用DINOv2自监督预训练生成鲁棒的逐切片特征嵌入，然后将这些嵌入输入到Kolmogorov-Arnold网络 (KAN) 分类器中。KAN通过自适应B样条激活实现局部非线性变换，提供了比传统卷积网络更灵活和可解释的替代方案。

Result: 实验结果表明，MST+KAN管道优于基线MST分类器，实现了0.80 ± 0.02的AUC值，并通过基于注意力的热图保留了可解释性。

Conclusion: 结合基础模型嵌入与先进分类策略（如KAN）能有效构建鲁棒且泛化能力强的乳腺MRI分析工具，提高诊断准确性和模型可解释性。

Abstract: Accurate breast MRI lesion detection is critical for early cancer diagnosis,
especially in high-risk populations. We present a classification pipeline that
adapts a pretrained foundation model, the Medical Slice Transformer (MST), for
breast lesion classification using dynamic contrast-enhanced MRI (DCE-MRI).
Leveraging DINOv2-based self-supervised pretraining, MST generates robust
per-slice feature embeddings, which are then used to train a Kolmogorov--Arnold
Network (KAN) classifier. The KAN provides a flexible and interpretable
alternative to conventional convolutional networks by enabling localized
nonlinear transformations via adaptive B-spline activations. This enhances the
model's ability to differentiate benign from malignant lesions in imbalanced
and heterogeneous clinical datasets. Experimental results demonstrate that the
MST+KAN pipeline outperforms the baseline MST classifier, achieving AUC = 0.80
\pm 0.02 while preserving interpretability through attention-based heatmaps.
Our findings highlight the effectiveness of combining foundation model
embeddings with advanced classification strategies for building robust and
generalizable breast MRI analysis tools.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [242] [Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees](https://arxiv.org/abs/2509.02896)
*Sepanta Zeighami,Shreya Shankar,Aditya Parameswaran*

Main category: cs.DB

TL;DR: BARGAIN是一种新方法，它通过自适应采样和统计估计，在保证输出质量（准确性、精确度或召回率）的同时，显著降低了使用大型语言模型（LLMs）进行数据处理的成本。


<details>
  <summary>Details</summary>
Motivation: 高精度LLMs成本昂贵，而廉价LLMs质量较低。现有模型级联框架在成本节约和理论保障方面表现不佳，因为对廉价LLM输出质量的估计不足，无法有效平衡成本与质量之间的权衡。

Method: 本文提出了BARGAIN，它采用新颖的自适应采样策略和统计估计程序。该方法利用数据和任务特性，并基于最新的统计工具，进行精确估计并提供严格的理论保障。BARGAIN的不同变体可以支持对输出的准确性、精确度或召回率的保障。

Result: 在8个真实世界数据集上的实验结果表明，BARGAIN比现有最先进的方法平均多降低了86%的成本，同时提供了更强的输出准确性理论保障，在保障所需精确度或召回率时也取得了类似的效果。

Conclusion: BARGAIN通过有效地利用廉价LLMs，显著降低了数据处理成本，并提供了强大的理论保障，解决了LLM应用中成本与质量的权衡问题。

Abstract: Large Language Models (LLMs) are being increasingly used as a building block
in data systems to process large text datasets. To do so, LLM model providers
offer multiple LLMs with different sizes, spanning various cost-quality
trade-offs when processing text at scale. Top-of-the-line LLMs (e.g., GPT-4o,
Claude Sonnet) operate with high accuracy but are prohibitively expensive when
processing many records. To avoid high costs, more affordable but lower quality
LLMs (e.g., GPT-4o-mini, Claude Haiku) can be used to process records, but we
need to ensure that the overall accuracy does not deviate substantially from
that of the top-of-the-line LLMs. The model cascade framework provides a
blueprint to manage this trade-off, by using the confidence of LLMs in their
output (e.g., log-probabilities) to decide on which records to use the
affordable LLM. However, existing solutions following this framework provide
only marginal cost savings and weak theoretical guarantees because of poor
estimation of the quality of the affordable LLM's outputs. We present BARGAIN,
a method that judiciously uses affordable LLMs in data processing to
significantly reduce cost while providing strong theoretical guarantees on the
solution quality. BARGAIN employs a novel adaptive sampling strategy and
statistical estimation procedure that uses data and task characteristics and
builds on recent statistical tools to make accurate estimations with tight
theoretical guarantees. Variants of BARGAIN can support guarantees on accuracy,
precision, or recall of the output. Experimental results across 8 real-world
datasets show that BARGAIN reduces cost, on average, by up to 86% more than
state-of-the-art, while providing stronger theoretical guarantees on accuracy
of output, with similar gains when guaranteeing a desired level of precision or
recall.

</details>


### [243] [Adaptive KV-Cache Compression without Manually Setting Budget](https://arxiv.org/abs/2509.03136)
*Chenxia Tang,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.DB

TL;DR: GVote是一种自适应KV-缓存压缩方案，通过蒙特卡洛采样预测未来查询需求，自动优化缓存预算，实现内存减半同时保持或提升LLM推理精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）推理中的KV-缓存导致内存占用随序列长度快速增长，带来效率挑战。现有KV-缓存压缩方法采用固定压缩比，导致资源分配次优和推理性能不佳。

Method: 本文提出了GVote，一种自适应KV-缓存压缩方案。GVote通过蒙特卡洛风格的采样潜在查询，聚合未来查询所需的关键键，来预测未来查询的注意力需求，从而自动确定最佳缓存预算，无需手动指定。

Result: 实验结果表明，GVote在GSM8K、RULER和Longbench等多个基准测试中表现出色。与基线方法相比，GVote实现了2倍的内存缩减，同时保持了更高或相当的准确性。

Conclusion: GVote是一种有效的自适应KV-缓存压缩方案，它消除了手动预算指定，并在准确性与效率之间实现了卓越的权衡。

Abstract: Large language models (LLMs) inference relies heavily on KV-caches to
accelerate autoregressive decoding, but the resulting memory footprint grows
rapidly with sequence length, posing significant efficiency challenges. Current
KV-cache compression methods suffer from a Procrustes' bed problem: they force
diverse workloads into fixed compression ratios, leading to suboptimal resource
allocation and inference performance. To this end, we present GVote, an
adaptive KV-cache compression scheme that eliminates manual budget
specification while achieving superior accuracy-efficiency trade-offs. GVote
operates on the principle that the important keys are the aggregation of keys
required by future queries. The method predicts future query attention demands
by Monte-Carlo style sampling potential queries and aggregating selected keys
to determine the optimal cache budget without manual specification.
Experimental evaluation demonstrates GVote's effectiveness across multiple
benchmarks, including GSM8K, RULER and Longbench. Compared to baselines, GVote
exhibits 2$\times$ memory reduction while the accuracy maintains higher or
comparable.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [244] [The Basic B*** Effect: The Use of LLM-based Agents Reduces the Distinctiveness and Diversity of People's Choices](https://arxiv.org/abs/2509.02910)
*Sandra C. Matz,C. Blaine Horton,Sofie Goethals*

Main category: cs.HC

TL;DR: 委托LLM代理决策会降低个人选择的独特性和多样性。个性化代理虽能缓和独特性下降，但会更严重地压缩选择多样性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益代理人类决策，研究旨在探究将定义身份的选择委托给AI，如何重塑个体身份，特别是对人际独特性和内省多样性的影响。

Method: 使用来自1,000名美国用户（共110,000个选择）的社交媒体真实选择数据，比较了通用AI代理、个性化AI代理与人类基线对选择独特性和多样性的影响。

Result: 两种AI代理都使人们的选择趋向更流行的选项，降低了独特性。个性化代理虽能缓和同质化，但更强烈地压缩了个人偏好组合的多样性，缩小了探索范围。

Conclusion: 理解AI代理对人类体验的扁平化效应以及通用与个性化代理在独特性-多样性上的权衡，对于设计增强而非限制人类能动性的系统，并维护思想、品味和表达的多样性至关重要。

Abstract: Large language models (LLMs) increasingly act on people's behalf: they write
emails, buy groceries, and book restaurants. While the outsourcing of human
decision-making to AI can be both efficient and effective, it raises a
fundamental question: how does delegating identity-defining choices to AI
reshape who people become? We study the impact of agentic LLMs on two
identity-relevant outcomes: interpersonal distinctiveness - how unique a
person's choices are relative to others - and intrapersonal diversity - the
breadth of a single person's choices over time. Using real choices drawn from
social-media behavior of 1,000 U.S. users (110,000 choices in total), we
compare a generic and personalized agent to a human baseline. Both agents shift
people's choices toward more popular options, reducing the distinctiveness of
their behaviors and preferences. While the use of personalized agents tempers
this homogenization (compared to the generic AI), it also more strongly
compresses the diversity of people's preference portfolios by narrowing what
they explore across topics and psychological affinities. Understanding how AI
agents might flatten human experience, and how using generic versus
personalized agents involves distinctiveness-diversity trade-offs, is critical
for designing systems that augment rather than constrain human agency, and for
safeguarding diversity in thought, taste, and expression.

</details>
