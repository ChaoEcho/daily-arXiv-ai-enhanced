{"id": "2507.22910", "pdf": "https://arxiv.org/pdf/2507.22910", "abs": "https://arxiv.org/abs/2507.22910", "authors": ["Sergio Di Meglio", "Aniello Somma", "Luigi Libero Lucio Starace", "Fabio Scippacercola", "Giancarlo Sperl\u00ec", "Sergio Di Martino"], "title": "Large Language Models in the Travel Domain: An Industrial Experience", "categories": ["cs.CL", "cs.AI"], "comment": "Manuscript accepted to the International Conference on Software\n  Engineering and Knowledge Engineering (SEKE) 2025", "summary": "Online property booking platforms are widely used and rely heavily on\nconsistent, up-to-date information about accommodation facilities, often\nsourced from third-party providers. However, these external data sources are\nfrequently affected by incomplete or inconsistent details, which can frustrate\nusers and result in a loss of market. In response to these challenges, we\npresent an industrial case study involving the integration of Large Language\nModels (LLMs) into CALEIDOHOTELS, a property reservation platform developed by\nFERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,\nfine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.\nBoth models were assessed based on their ability to generate consistent and\nhomogeneous descriptions while minimizing hallucinations. Mixtral 8x7B\noutperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision\n(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet\nmore concise content (249 vs. 277 words on average). However, this came at a\nsignificantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB\nand $0.16/hour for Mistral 7B. Our findings provide practical insights into the\ntrade-offs between model quality and resource efficiency, offering guidance for\ndeploying LLMs in production environments and demonstrating their effectiveness\nin enhancing the consistency and reliability of accommodation data.", "AI": {"tldr": "\u9488\u5bf9\u5728\u7ebf\u4f4f\u5bbf\u9884\u8ba2\u5e73\u53f0\u6570\u636e\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u672c\u6587\u5728FERVENTO\u7684CALEIDOHOTELS\u5e73\u53f0\u6574\u5408\u5e76\u8bc4\u4f30\u4e86Mistral 7B\u548cMixtral 8x7B\uff0cMixtral 8x7B\u8868\u73b0\u66f4\u4f18\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u9ad8\uff0c\u63d0\u4f9b\u4e86\u6a21\u578b\u8d28\u91cf\u4e0e\u8d44\u6e90\u6548\u7387\u6743\u8861\u7684\u5b9e\u8df5\u6d1e\u5bdf\u3002", "motivation": "\u5728\u7ebf\u4f4f\u5bbf\u9884\u8ba2\u5e73\u53f0\u4e25\u91cd\u4f9d\u8d56\u7b2c\u4e09\u65b9\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u5e38\u4e0d\u5b8c\u6574\u6216\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u7528\u6237\u4f53\u9a8c\u5dee\u548c\u5e76\u53ef\u80fd\u9020\u6210\u5e02\u573a\u635f\u5931\u3002", "method": "\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6574\u5408\u5230FERVENTO\u5f00\u53d1\u7684CALEIDOHOTELS\u9884\u8ba2\u5e73\u53f0\u3002\u8bc4\u4f30\u4e86\u4f7f\u7528QLoRA\u5fae\u8c03\u7684Mistral 7B\u548c\u4f7f\u7528\u4f18\u5316\u7cfb\u7edf\u63d0\u793a\u7684Mixtral 8x7B\u3002\u8bc4\u4f30\u6807\u51c6\u5305\u62ec\u751f\u6210\u4e00\u81f4\u4e14\u540c\u8d28\u63cf\u8ff0\u7684\u80fd\u529b\u4ee5\u53ca\u5e7b\u89c9\u7387\u3002", "result": "Mixtral 8x7B\u5728\u5b8c\u6574\u6027\uff0899.6% vs 93%\uff09\u3001\u51c6\u786e\u6027\uff0898.8% vs 96%\uff09\u548c\u5e7b\u89c9\u7387\uff081.2% vs 4%\uff09\u65b9\u9762\u4f18\u4e8eMistral 7B\uff0c\u4e14\u751f\u6210\u5185\u5bb9\u66f4\u77ed\u66f4\u7b80\u6d01\uff08\u5e73\u5747249\u5b57 vs 277\u5b57\uff09\u3002\u7136\u800c\uff0cMixtral 8x7B\u7684\u8ba1\u7b97\u6210\u672c\u663e\u8457\u9ad8\u4e8eMistral 7B\uff0850GB VRAM\u548c$1.61/\u5c0f\u65f6 vs 5GB\u548c$0.16/\u5c0f\u65f6\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u6a21\u578b\u8d28\u91cf\u4e0e\u8d44\u6e90\u6548\u7387\u4e4b\u95f4\u6743\u8861\u7684\u5b9e\u7528\u89c1\u89e3\uff0c\u4e3a\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72LLM\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u8bc1\u660e\u4e86LLM\u5728\u63d0\u9ad8\u4f4f\u5bbf\u6570\u636e\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.22911", "pdf": "https://arxiv.org/pdf/2507.22911", "abs": "https://arxiv.org/abs/2507.22911", "authors": ["Jinzhi Wang", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Qinfeng Song", "Kaixuan Yang", "Jiangbo Zhang", "Yaoying Wang", "Ruimeng Li", "Biyi Zhou"], "title": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Electric power marketing customer service plays a critical role in addressing\ninquiries, complaints, and service requests. However, current systems, such as\nChina's 95598 hotline, often struggle with slow response times, inflexible\nprocedures, and limited accuracy in domain-specific tasks. While large language\nmodels (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,\nthey lack the domain expertise and empathy required in this field. To bridge\nthis gap, we introduce ElectriQ, the first benchmark designed to evaluate and\nenhance LLMs in electric power marketing scenarios. ElectriQ consists of a\ndialogue dataset covering six key service categories and introduces four\nevaluation metrics: professionalism, popularity, readability, and\nuser-friendliness. We further incorporate a domain-specific knowledge base and\npropose a knowledge augmentation method to boost model performance. Experiments\non 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and\naugmented, can surpass GPT-4o in terms of professionalism and\nuser-friendliness. ElectriQ establishes a comprehensive foundation for\ndeveloping LLMs tailored to the needs of power marketing services.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86ElectriQ\uff0c\u4e00\u4e2a\u4e13\u4e3a\u7535\u529b\u8425\u9500\u5ba2\u670d\u573a\u666f\u8bbe\u8ba1\u7684LLM\u8bc4\u4f30\u57fa\u51c6\uff0c\u5e76\u8bc1\u660e\u4e86\u7ecf\u8fc7\u9886\u57df\u7279\u5316\u548c\u77e5\u8bc6\u589e\u5f3a\u7684\u5c0f\u578bLLM\u53ef\u4ee5\u8d85\u8d8a\u901a\u7528\u5927\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7684\u7535\u529b\u8425\u9500\u5ba2\u670d\u7cfb\u7edf\uff08\u598295598\u70ed\u7ebf\uff09\u5b58\u5728\u54cd\u5e94\u6162\u3001\u6d41\u7a0b\u50f5\u5316\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u867d\u7136\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u529b\u5f3a\u5927\uff0c\u4f46\u7f3a\u4e4f\u8be5\u9886\u57df\u7684\u4e13\u4e1a\u77e5\u8bc6\u548c\u540c\u7406\u5fc3\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86ElectriQ\u57fa\u51c6\uff0c\u5305\u542b\u4e00\u4e2a\u6db5\u76d6\u516d\u5927\u670d\u52a1\u7c7b\u522b\u7684\u5bf9\u8bdd\u6570\u636e\u96c6\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e13\u4e1a\u6027\u3001\u53d7\u6b22\u8fce\u5ea6\u3001\u53ef\u8bfb\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u56db\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u3002\u6b64\u5916\uff0c\u8fd8\u6574\u5408\u4e86\u9886\u57df\u77e5\u8bc6\u5e93\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5bf913\u4e2aLLMs\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7\u5fae\u8c03\u548c\u77e5\u8bc6\u589e\u5f3a\u7684\u5c0f\u578b\u6a21\u578b\uff08\u5982LLama3-8B\uff09\u5728\u4e13\u4e1a\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u65b9\u9762\u80fd\u591f\u8d85\u8d8a\u901a\u7528\u5927\u6a21\u578b\uff08\u5982GPT-4o\uff09\u3002", "conclusion": "ElectriQ\u4e3a\u5f00\u53d1\u548c\u4f18\u5316\u9002\u7528\u4e8e\u7535\u529b\u8425\u9500\u670d\u52a1\u7684LLM\u5efa\u7acb\u4e86\u5168\u9762\u4e14\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.22912", "pdf": "https://arxiv.org/pdf/2507.22912", "abs": "https://arxiv.org/abs/2507.22912", "authors": ["Navid Yazdanjue", "Morteza Rakhshaninejad", "Hossein Yazdanjouei", "Mohammad Sadegh Khorshidi", "Mikko S. Niemela", "Fang Chen", "Amir H. Gandomi"], "title": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50"], "comment": "16 pages, 5 figures, 9 tables", "summary": "Illegal marketplaces have increasingly shifted to concealed parts of the\ninternet, including the deep and dark web, as well as platforms such as\nTelegram, Reddit, and Pastebin. These channels enable the anonymous trade of\nillicit goods including drugs, weapons, and stolen credentials. Detecting and\ncategorizing such content remains challenging due to limited labeled data, the\nevolving nature of illicit language, and the structural heterogeneity of online\nsources. This paper presents a hierarchical classification framework that\ncombines fine-tuned language models with a semi-supervised ensemble learning\nstrategy to detect and classify illicit marketplace content across diverse\nplatforms. We extract semantic representations using ModernBERT, a transformer\nmodel for long documents, finetuned on domain-specific data from deep and dark\nweb pages, Telegram channels, Subreddits, and Pastebin pastes to capture\nspecialized jargon and ambiguous linguistic patterns. In addition, we\nincorporate manually engineered features such as document structure, embedded\npatterns including Bitcoin addresses, emails, and IPs, and metadata, which\ncomplement language model embeddings. The classification pipeline operates in\ntwo stages. The first stage uses a semi-supervised ensemble of XGBoost, Random\nForest, and SVM with entropy-based weighted voting to detect sales-related\ndocuments. The second stage further classifies these into drug, weapon, or\ncredential sales. Experiments on three datasets, including our multi-source\ncorpus, DUTA, and CoDA, show that our model outperforms several baselines,\nincluding BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The\nmodel achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of\n0.95388, demonstrating strong generalization, robustness under limited\nsupervision, and effectiveness in real-world illicit content detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5206\u7c7b\u6846\u67b6\uff0c\u7ed3\u5408\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u548c\u534a\u76d1\u7763\u96c6\u6210\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u68c0\u6d4b\u548c\u5206\u7c7b\u8de8\u5e73\u53f0\uff08\u5982\u6697\u7f51\u3001Telegram\uff09\u7684\u975e\u6cd5\u5e02\u573a\u5185\u5bb9\uff0c\u5e76\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002", "motivation": "\u975e\u6cd5\u5e02\u573a\u6b63\u65e5\u76ca\u8f6c\u5411\u4e92\u8054\u7f51\u7684\u9690\u853d\u90e8\u5206\uff08\u5982\u6df1\u7f51\u3001\u6697\u7f51\u3001Telegram\uff09\uff0c\u8fdb\u884c\u6bd2\u54c1\u3001\u6b66\u5668\u548c\u88ab\u76d7\u51ed\u8bc1\u7684\u533f\u540d\u4ea4\u6613\u3002\u7531\u4e8e\u6807\u8bb0\u6570\u636e\u6709\u9650\u3001\u975e\u6cd5\u8bed\u8a00\u4e0d\u65ad\u6f14\u53d8\u4ee5\u53ca\u5728\u7ebf\u6765\u6e90\u7684\u7ed3\u6784\u5f02\u8d28\u6027\uff0c\u68c0\u6d4b\u548c\u5206\u7c7b\u6b64\u7c7b\u5185\u5bb9\u6781\u5177\u6311\u6218\u6027\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5206\u5c42\u5206\u7c7b\u6846\u67b6\uff0c\u7ed3\u5408\u5fae\u8c03\u7684\u8bed\u8a00\u6a21\u578b\u548c\u534a\u76d1\u7763\u96c6\u6210\u5b66\u4e60\u7b56\u7565\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\u4f7f\u7528\u5728\u9886\u57df\u7279\u5b9a\u6570\u636e\uff08\u6df1\u7f51\u3001\u6697\u7f51\u3001Telegram\u3001Reddit\u3001Pastebin\uff09\u4e0a\u5fae\u8c03\u7684ModernBERT\u6a21\u578b\u63d0\u53d6\u8bed\u4e49\u8868\u793a\uff0c\u4ee5\u6355\u6349\u4e13\u4e1a\u672f\u8bed\u548c\u6a21\u7cca\u8bed\u8a00\u6a21\u5f0f\uff1b\u7ed3\u5408\u4eba\u5de5\u7279\u5f81\uff08\u6587\u6863\u7ed3\u6784\u3001\u5d4c\u5165\u6a21\u5f0f\u5982\u6bd4\u7279\u5e01\u5730\u5740\u3001\u7535\u5b50\u90ae\u4ef6\u3001IP\u548c\u5143\u6570\u636e\uff09\uff1b\u5206\u7c7b\u6d41\u7a0b\u5206\u4e24\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8e\u71b5\u52a0\u6743\u6295\u7968\u7684XGBoost\u3001Random Forest\u548cSVM\u534a\u76d1\u7763\u96c6\u6210\u6a21\u578b\u68c0\u6d4b\u9500\u552e\u76f8\u5173\u6587\u6863\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u8fd9\u4e9b\u6587\u6863\u8fdb\u4e00\u6b65\u5206\u7c7b\u4e3a\u6bd2\u54c1\u3001\u6b66\u5668\u6216\u51ed\u8bc1\u9500\u552e\u3002", "result": "\u5728\u5305\u542b\u591a\u6e90\u8bed\u6599\u5e93\u3001DUTA\u548cCoDA\u7684\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u4f18\u4e8e\u5305\u62ecBERT\u3001ModernBERT\u3001DarkBERT\u3001ALBERT\u3001Longformer\u548cBigBird\u5728\u5185\u7684\u591a\u4e2a\u57fa\u7ebf\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5b9e\u73b0\u4e860.96489\u7684\u51c6\u786e\u7387\u30010.93467\u7684F1\u5206\u6570\u548c0.95388\u7684TMCC\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u6709\u9650\u76d1\u7763\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u975e\u6cd5\u5185\u5bb9\u68c0\u6d4b\u4e2d\u663e\u793a\u51fa\u6709\u6548\u6027\u3002"}}
{"id": "2507.22913", "pdf": "https://arxiv.org/pdf/2507.22913", "abs": "https://arxiv.org/abs/2507.22913", "authors": ["Jinyu Liu", "Xiaoying Song", "Diana Zhang", "Jason Thomale", "Daqing He", "Lingzi Hong"], "title": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 2 figures, accepted by ASIST 2025", "summary": "Providing subject access to information resources is an essential function of\nany library management system. Large language models (LLMs) have been widely\nused in classification and summarization tasks, but their capability to perform\nsubject analysis is underexplored. Multi-label classification with traditional\nmachine learning (ML) models has been used for subject analysis but struggles\nwith unseen cases. LLMs offer an alternative but often over-generate and\nhallucinate. Therefore, we propose a hybrid framework that integrates\nembedding-based ML models with LLMs. This approach uses ML models to (1)\npredict the optimal number of LCSH labels to guide LLM predictions and (2)\npost-edit the predicted terms with actual LCSH terms to mitigate\nhallucinations. We experimented with LLMs and the hybrid framework to predict\nthe subject terms of books using the Library of Congress Subject Headings\n(LCSH). Experiment results show that providing initial predictions to guide LLM\ngenerations and imposing post-edits result in more controlled and\nvocabulary-aligned outputs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u56fe\u4e66\u9986\u4e3b\u9898\u5206\u6790\u3002\u8be5\u6846\u67b6\u901a\u8fc7ML\u6a21\u578b\u6307\u5bfcLLM\u9884\u6d4b\u5e76\u8fdb\u884c\u540e\u7f16\u8f91\u4ee5\u7f13\u89e3\u5e7b\u89c9\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u80fd\u4ea7\u751f\u66f4\u53d7\u63a7\u4e14\u8bcd\u6c47\u5bf9\u9f50\u7684\u8f93\u51fa\u3002", "motivation": "\u56fe\u4e66\u9986\u7ba1\u7406\u7cfb\u7edf\u6025\u9700\u9ad8\u6548\u7684\u4e3b\u9898\u8bbf\u95ee\u529f\u80fd\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u5728\u4e3b\u9898\u5206\u6790\u4e2d\u5904\u7406\u672a\u89c1\u6848\u4f8b\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5206\u7c7b\u548c\u6458\u8981\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5176\u5728\u4e3b\u9898\u5206\u6790\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u5e38\u51fa\u73b0\u8fc7\u5ea6\u751f\u6210\u548c\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u6846\u67b6\uff0c\u6574\u5408\u4e86\u57fa\u4e8e\u5d4c\u5165\u7684\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3002\u8be5\u65b9\u6cd5\u5229\u7528ML\u6a21\u578b\u8fdb\u884c\u4e24\u9879\u5173\u952e\u4efb\u52a1\uff1a1) \u9884\u6d4b\u6700\u4f73\u7684LCSH\uff08\u7f8e\u56fd\u56fd\u4f1a\u56fe\u4e66\u9986\u4e3b\u9898\u8bcd\uff09\u6807\u7b7e\u6570\u91cf\u4ee5\u6307\u5bfcLLM\u7684\u751f\u6210\uff1b2) \u5bf9LLM\u9884\u6d4b\u7684\u8bcd\u6c47\u8fdb\u884c\u540e\u7f16\u8f91\uff0c\u7528\u5b9e\u9645\u7684LCSH\u8bcd\u6c47\u4fee\u6b63\u4ee5\u51cf\u8f7b\u5e7b\u89c9\u3002\u5b9e\u9a8c\u4f7f\u7528LCSH\u9884\u6d4b\u4e66\u7c4d\u7684\u4e3b\u9898\u8bcd\uff0c\u5e76\u4e0e\u7eafLLM\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u4e3aLLM\u751f\u6210\u63d0\u4f9b\u521d\u59cb\u9884\u6d4b\u6307\u5bfc\u548c\u65bd\u52a0\u540e\u7f16\u8f91\uff0c\u80fd\u591f\u4ea7\u751f\u66f4\u53d7\u63a7\u4e14\u4e0e\u65e2\u5b9a\u8bcd\u6c47\u8868\uff08\u5982LCSH\uff09\u5bf9\u9f50\u7684\u8f93\u51fa\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u6210\u529f\u5730\u89e3\u51b3\u4e86LLM\u5728\u4e3b\u9898\u5206\u6790\u4e2d\u8fc7\u5ea6\u751f\u6210\u548c\u5e7b\u89c9\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408ML\u6a21\u578b\u7684\u6307\u5bfc\u548c\u540e\u7f16\u8f91\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u3001\u6807\u51c6\u5316\u4e14\u7b26\u5408\u9884\u5b9a\u4e49\u8bcd\u6c47\u8868\u7684\u4e3b\u9898\u8bcd\u9884\u6d4b\uff0c\u63d0\u5347\u4e86\u4fe1\u606f\u8d44\u6e90\u7684\u4e3b\u9898\u8bbf\u95ee\u8d28\u91cf\u3002"}}
{"id": "2507.23012", "pdf": "https://arxiv.org/pdf/2507.23012", "abs": "https://arxiv.org/abs/2507.23012", "authors": ["Ashkan Sobhani", "Sogand Sadrhaghighi", "Xingjun Chu"], "title": "PRIME: Pseudo-Random Integrated Multi-Part Entropy for Adaptive Packet Spraying in AI/ML Data centers", "categories": ["cs.NI"], "comment": null, "summary": "Large-scale distributed training in production data centers place significant\ndemands on network infrastructure. In particular, significant load balancing\nchallenges arise when processing AI/ML workloads, consisting of low-entropy,\nbursty and long-lived flows. Existing solutions designed for Ethernet, such as\nEqual-Cost Multi-Path (ECMP) struggle to maintain high network utilization.\nWhile major industry players (e.g., Ultra Ethernet Consortium) and parts of\nacademia have proposed packet spraying to enhance AI/ML workload performance,\nwe argue that existing packet spraying solutions lead to buffer inflation over\ntime, negatively affecting network performance. Specifically, when ACK\ncoalescing is used, these solutions lead to stale information, degrading\nnetwork performance. Additionally, in asymmetric network conditions- such as\nmix of ordered an unordered traffic, or link degradation and failures- existing\npacket spraying solutions often lead to increased tail latency. In this paper,\nwe present the design and evaluation of PRIME, a pseudo-randomized round-robin\napproach to packet spraying that considers the network topology to optimize\nload distribution and performance. PRIME uses congestion as an indicator to\nre-balance the load. To this extent, PRIME takes into account various\ncongestion signals, accounting for congestion severity, and their decay times\nto avoid network hotspots. We extensively evaluated PRIME using large-scale\nproduction-level simulator. Our results indicate that, compared to existing\nsolutions, PRIME leads to up to 15% improvement for permutation traffic and up\nto 27% improvement in network degradation scenarios", "AI": {"tldr": "PRIME\u662f\u4e00\u79cd\u4f2a\u968f\u673a\u8f6e\u8be2\u5206\u5305\u6280\u672f\uff0c\u901a\u8fc7\u611f\u77e5\u7f51\u7edc\u62d3\u6251\u548c\u62e5\u585e\u4fe1\u53f7\uff0c\u6709\u6548\u4f18\u5316\u4e86AI/ML\u8bad\u7ec3\u7f51\u7edc\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u6027\u80fd\uff0c\u5c24\u5176\u5728\u7f51\u7edc\u964d\u7ea7\u548c\u7f6e\u6362\u6d41\u91cf\u573a\u666f\u4e0b\u8868\u73b0\u5353\u8d8a\u3002", "motivation": "\u5927\u89c4\u6a21\u5206\u5e03\u5f0fAI/ML\u8bad\u7ec3\u5bf9\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u9020\u6210\u5de8\u5927\u538b\u529b\uff0c\u73b0\u6709\u8d1f\u8f7d\u5747\u8861\u65b9\u6848\uff08\u5982ECMP\uff09\u548c\u4f20\u7edf\u5206\u5305\u6280\u672f\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u7f13\u51b2\u81a8\u80c0\u3001\u4fe1\u606f\u8fc7\u65f6\u4ee5\u53ca\u5728\u975e\u5bf9\u79f0\u7f51\u7edc\u6761\u4ef6\u4e0b\u5c3e\u90e8\u5ef6\u8fdf\u589e\u52a0\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "PRIME\u91c7\u7528\u4e00\u79cd\u4f2a\u968f\u673a\u8f6e\u8be2\uff08pseudo-randomized round-robin\uff09\u7684\u5206\u5305\u65b9\u6cd5\uff0c\u5728\u8003\u8651\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u7684\u540c\u65f6\u4f18\u5316\u8d1f\u8f7d\u5206\u5e03\u3002\u5b83\u4ee5\u62e5\u585e\u4f5c\u4e3a\u8d1f\u8f7d\u518d\u5e73\u8861\u7684\u6307\u793a\u5668\uff0c\u5e76\u7efc\u5408\u8003\u91cf\u5404\u79cd\u62e5\u585e\u4fe1\u53f7\u7684\u4e25\u91cd\u7a0b\u5ea6\u53ca\u5176\u8870\u51cf\u65f6\u95f4\uff0c\u4ee5\u907f\u514d\u7f51\u7edc\u70ed\u70b9\u3002", "result": "\u901a\u8fc7\u5927\u89c4\u6a21\u751f\u4ea7\u7ea7\u6a21\u62df\u5668\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e0e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0cPRIME\u5728\u7f6e\u6362\u6d41\u91cf\u573a\u666f\u4e2d\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe15%\uff0c\u5728\u7f51\u7edc\u964d\u7ea7\u573a\u666f\u4e2d\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe27%\u3002", "conclusion": "PRIME\u901a\u8fc7\u5176\u62d3\u6251\u611f\u77e5\u548c\u62e5\u585e\u611f\u77e5\u7684\u4f2a\u968f\u673a\u8f6e\u8be2\u5206\u5305\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u7684\u5f0a\u7aef\uff0c\u663e\u8457\u63d0\u5347\u4e86AI/ML\u8bad\u7ec3\u7f51\u7edc\u5728\u590d\u6742\u548c\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u7684\u8d1f\u8f7d\u5747\u8861\u6027\u80fd\u548c\u7f51\u7edc\u5229\u7528\u7387\u3002"}}
{"id": "2507.22951", "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful.", "AI": {"tldr": "\u9488\u5bf9\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u7f3a\u4e4f\u89c4\u8303\u548c\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u548c\u6539\u8fdb\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u65e8\u5728\u63d0\u9ad8\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u5f71\u54cd\u529b\u3002", "motivation": "KGC\u7684\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u4e00\u81f4\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u8fd9\u4e25\u91cd\u963b\u788d\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u8de8\u7814\u7a76\u6bd4\u8f83\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\uff08\u5e73\u8861\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u7b80\u6d01\u6027\uff09\u6765\u8868\u5f81\u4e8b\u540e\u89e3\u91ca\u7684\u901a\u7528\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u7edf\u4e00\u73b0\u6709KGC\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u7b97\u6cd5\u3002\n2. \u5efa\u8bae\u5e76\u5b9e\u8bc1\u652f\u6301\u4f7f\u7528MRR\u548cHits@k\u7b49\u6d41\u884c\u6307\u6807\u6539\u8fdb\u8bc4\u4f30\u534f\u8bae\u3002\n3. \u5f3a\u8c03\u4e86\u89e3\u91ca\u6027\uff08\u5373\u89e3\u91ca\u80fd\u56de\u7b54\u7ec8\u7aef\u7528\u6237\u6709\u610f\u4e49\u67e5\u8be2\u7684\u80fd\u529b\uff09\u7684\u91cd\u8981\u6027\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u652f\u6301\u4e86\u6539\u8fdb\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u6210\u529f\u5730\u7edf\u4e00\u4e86\u73b0\u6709KGC\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u7b97\u6cd5\u53ca\u5176\u4ea7\u751f\u7684\u89e3\u91ca\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u89e3\u91ca\u65b9\u6cd5\u548c\u5b8c\u5584\u8bc4\u4f30\u6807\u51c6\uff0c\u8be5\u5de5\u4f5c\u65e8\u5728\u4f7fKGC\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u66f4\u5177\u53ef\u590d\u73b0\u6027\u548c\u5f71\u54cd\u529b\u3002"}}
{"id": "2507.22954", "pdf": "https://arxiv.org/pdf/2507.22954", "abs": "https://arxiv.org/abs/2507.22954", "authors": ["Ridvan Yesiloglu", "Wei Peng", "Md Tauhidul Islam", "Ehsan Adeli"], "title": "Neural Autoregressive Modeling of Brain Aging", "categories": ["cs.LG", "eess.IV", "q-bio.NC"], "comment": "Accepted at Deep Generative Models Workshop @ MICCAI 2025", "summary": "Brain aging synthesis is a critical task with broad applications in clinical\nand computational neuroscience. The ability to predict the future structural\nevolution of a subject's brain from an earlier MRI scan provides valuable\ninsights into aging trajectories. Yet, the high-dimensionality of data, subtle\nchanges of structure across ages, and subject-specific patterns constitute\nchallenges in the synthesis of the aging brain. To overcome these challenges,\nwe propose NeuroAR, a novel brain aging simulation model based on generative\nautoregressive transformers. NeuroAR synthesizes the aging brain by\nautoregressively estimating the discrete token maps of a future scan from a\nconvenient space of concatenated token embeddings of a previous and future\nscan. To guide the generation, it concatenates into each scale the subject's\nprevious scan, and uses its acquisition age and the target age at each block\nvia cross-attention. We evaluate our approach on both the elderly population\nand adolescent subjects, demonstrating superior performance over\nstate-of-the-art generative models, including latent diffusion models (LDM) and\ngenerative adversarial networks, in terms of image fidelity. Furthermore, we\nemploy a pre-trained age predictor to further validate the consistency and\nrealism of the synthesized images with respect to expected aging patterns.\nNeuroAR significantly outperforms key models, including LDM, demonstrating its\nability to model subject-specific brain aging trajectories with high fidelity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNeuroAR\uff0c\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0f\u81ea\u56de\u5f52Transformer\u7684\u65b0\u578b\u8111\u8001\u5316\u6a21\u62df\u6a21\u578b\uff0c\u80fd\u591f\u9ad8\u4fdd\u771f\u5730\u9884\u6d4b\u53d7\u8bd5\u8005\u7279\u5b9a\u8111\u8001\u5316\u8f68\u8ff9\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002", "motivation": "\u8111\u8001\u5316\u5408\u6210\u662f\u4e34\u5e8a\u548c\u8ba1\u7b97\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u5173\u952e\u4efb\u52a1\u3002\u4ece\u65e9\u671fMRI\u9884\u6d4b\u672a\u6765\u5927\u8111\u7ed3\u6784\u6f14\u53d8\u53ef\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u8001\u5316\u8f68\u8ff9\u89c1\u89e3\u3002\u7136\u800c\uff0c\u6570\u636e\u9ad8\u7ef4\u5ea6\u3001\u7ed3\u6784\u5fae\u5c0f\u53d8\u5316\u548c\u53d7\u8bd5\u8005\u7279\u5f02\u6027\u6a21\u5f0f\u7ed9\u8111\u8001\u5316\u5408\u6210\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51faNeuroAR\u6a21\u578b\uff0c\u57fa\u4e8e\u751f\u6210\u5f0f\u81ea\u56de\u5f52Transformer\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u4f30\u8ba1\u672a\u6765\u626b\u63cf\u7684\u79bb\u6563token\u56fe\u6765\u5408\u6210\u8001\u5316\u5927\u8111\u3002\u8be5\u6a21\u578b\u5229\u7528\u5148\u524d\u548c\u672a\u6765\u626b\u63cf\u7684\u8fde\u63a5token\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u4e0a\u8fde\u63a5\u53d7\u8bd5\u8005\u7684\u5148\u524d\u626b\u63cf\u3001\u91c7\u96c6\u5e74\u9f84\u548c\u76ee\u6807\u5e74\u9f84\u6765\u5f15\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u8001\u5e74\u548c\u9752\u5c11\u5e74\u4eba\u7fa4\u4e2d\u8bc4\u4f30\uff0cNeuroAR\u5728\u56fe\u50cf\u4fdd\u771f\u5ea6\u65b9\u9762\u4f18\u4e8e\u5305\u62ec\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u5728\u5185\u7684\u73b0\u6709\u6700\u5148\u8fdb\u751f\u6210\u6a21\u578b\u3002\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u5e74\u9f84\u9884\u6d4b\u5668\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5408\u6210\u56fe\u50cf\u4e0e\u9884\u671f\u8001\u5316\u6a21\u5f0f\u7684\u4e00\u81f4\u6027\u548c\u771f\u5b9e\u6027\u3002NeuroAR\u5728\u5efa\u6a21\u53d7\u8bd5\u8005\u7279\u5b9a\u8111\u8001\u5316\u8f68\u8ff9\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5173\u952e\u6a21\u578b\uff08\u5305\u62ecLDM\uff09\u3002", "conclusion": "NeuroAR\u6a21\u578b\u80fd\u591f\u4ee5\u9ad8\u4fdd\u771f\u5ea6\u6a21\u62df\u53d7\u8bd5\u8005\u7279\u5b9a\u7684\u8111\u8001\u5316\u8f68\u8ff9\uff0c\u5728\u56fe\u50cf\u4fdd\u771f\u5ea6\u548c\u771f\u5b9e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u3002"}}
{"id": "2507.22958", "pdf": "https://arxiv.org/pdf/2507.22958", "abs": "https://arxiv.org/abs/2507.22958", "authors": ["Ruslan Khrulev"], "title": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 97D50", "I.2.7; I.4; K.3.1"], "comment": "15 pages, 3 figures, 10 tables. Code is available at:\n  https://github.com/Karifannaa/Auto-check-EGE-math", "summary": "This paper introduces a novel benchmark, EGE-Math Solutions Assessment\nBenchmark, for evaluating Vision-Language Models (VLMs) on their ability to\nassess hand-written mathematical solutions. Unlike existing benchmarks that\nfocus on problem solving, our approach centres on understanding student\nsolutions, identifying mistakes, and assigning grades according to fixed\ncriteria. We compile 122 scanned solutions from the Russian Unified State Exam\n(EGE) together with official expert grades, and evaluate seven modern VLMs from\nGoogle, OpenAI, Arcee AI, and Alibaba Cloud in three inference modes. The\nresults reveal current limitations in mathematical reasoning and human-rubric\nalignment, opening new research avenues in AI-assisted assessment. You can find\ncode in https://github.com/Karifannaa/Auto-check-EGE-math", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u57fa\u51c6EGE-Math\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u6279\u6539\u624b\u5199\u6570\u5b66\u89e3\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u591a\u4e13\u6ce8\u4e8e\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u800c\u975e\u7406\u89e3\u5b66\u751f\u89e3\u51b3\u65b9\u6848\u3001\u8bc6\u522b\u9519\u8bef\u548c\u6839\u636e\u65e2\u5b9a\u6807\u51c6\u8bc4\u5206\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30VLM\u6279\u6539\u624b\u5199\u6570\u5b66\u7b54\u6848\u7684\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86EGE-Math Solutions Assessment Benchmark\uff0c\u5305\u542b122\u4efd\u4fc4\u7f57\u65af\u7edf\u4e00\u56fd\u5bb6\u8003\u8bd5(EGE)\u7684\u624b\u5199\u89e3\u51b3\u65b9\u6848\u53ca\u5176\u5b98\u65b9\u4e13\u5bb6\u8bc4\u5206\u3002\u5229\u7528\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\uff0c\u8bc4\u4f30\u4e86\u6765\u81eaGoogle\u3001OpenAI\u3001Arcee AI\u548c\u963f\u91cc\u5df4\u5df4\u4e91\u7684\u4e03\u4e2a\u73b0\u4ee3VLM\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u524dVLM\u5728\u6570\u5b66\u63a8\u7406\u80fd\u529b\u548c\u4e0e\u4eba\u5de5\u8bc4\u5206\u6807\u51c6\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709VLM\u5728\u81ea\u52a8\u8bc4\u4f30\u624b\u5199\u6570\u5b66\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3aAI\u8f85\u52a9\u8bc4\u4f30\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.22914", "pdf": "https://arxiv.org/pdf/2507.22914", "abs": "https://arxiv.org/abs/2507.22914", "authors": ["Victor Eiti Yamamoto", "Hideaki Takeda"], "title": "Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs", "categories": ["cs.CL"], "comment": null, "summary": "Knowledge graphs (KGs) are powerful tools for representing and reasoning over\nstructured information. Their main components include schema, identity, and\ncontext. While schema and identity matching are well-established in ontology\nand entity matching research, context matching remains largely unexplored. This\nis particularly important because real-world KGs often vary significantly in\nsource, size, and information density - factors not typically represented in\nthe datasets on which current entity matching methods are evaluated. As a\nresult, existing approaches may fall short in scenarios where diverse and\ncomplex contexts need to be integrated.\n  To address this gap, we propose a novel KG integration method consisting of\nlabel matching and triple matching. We use string manipulation, fuzzy matching,\nand vector similarity techniques to align entity and predicate labels. Next, we\nidentify mappings between triples that convey comparable information, using\nthese mappings to improve entity-matching accuracy. Our approach demonstrates\ncompetitive performance compared to leading systems in the OAEI competition and\nagainst supervised methods, achieving high accuracy across diverse test cases.\nAdditionally, we introduce a new dataset derived from the benchmark dataset to\nevaluate the triple-matching step more comprehensively.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6807\u7b7e\u5339\u914d\u548c\u4e09\u5143\u7ec4\u5339\u914d\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u4e0a\u4e0b\u6587\u5339\u914d\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u591a\u6837\u5316\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u6a21\u5f0f\u548c\u5b9e\u4f53\u5339\u914d\uff0c\u4f46\u5ffd\u89c6\u4e86\u4e0a\u4e0b\u6587\u5339\u914d\u3002\u9274\u4e8e\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u56fe\u8c31\u6765\u6e90\u3001\u89c4\u6a21\u548c\u4fe1\u606f\u5bc6\u5ea6\u7684\u591a\u6837\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u4e0a\u4e0b\u6587\u96c6\u6210\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u4e14\u5f53\u524d\u8bc4\u4f30\u6570\u636e\u96c6\u672a\u80fd\u5145\u5206\u53cd\u6620\u8fd9\u79cd\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\uff0c\u5305\u542b\u6807\u7b7e\u5339\u914d\u548c\u4e09\u5143\u7ec4\u5339\u914d\u3002\u6807\u7b7e\u5339\u914d\u5229\u7528\u5b57\u7b26\u4e32\u64cd\u4f5c\u3001\u6a21\u7cca\u5339\u914d\u548c\u5411\u91cf\u76f8\u4f3c\u5ea6\u6280\u672f\u3002\u4e09\u5143\u7ec4\u5339\u914d\u901a\u8fc7\u8bc6\u522b\u4f20\u8fbe\u53ef\u6bd4\u4fe1\u606f\u7684\u4e09\u5143\u7ec4\u6620\u5c04\u6765\u63d0\u9ad8\u5b9e\u4f53\u5339\u914d\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u4ee5\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u4e09\u5143\u7ec4\u5339\u914d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728OAEI\u7ade\u8d5b\u4e2d\u4e0e\u9886\u5148\u7cfb\u7edf\u548c\u76d1\u7763\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8868\u73b0\u51fa\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u5728\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u5408\u6807\u7b7e\u5339\u914d\u548c\u4e09\u5143\u7ec4\u5339\u914d\u7684\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e0a\u4e0b\u6587\u5339\u914d\u7684\u6311\u6218\uff0c\u5e76\u80fd\u663e\u8457\u63d0\u9ad8\u5b9e\u4f53\u5339\u914d\u7684\u51c6\u786e\u6027\uff0c\u5728\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u9886\u57df\u5177\u6709\u826f\u597d\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.23177", "pdf": "https://arxiv.org/pdf/2507.23177", "abs": "https://arxiv.org/abs/2507.23177", "authors": ["Neagin Neasamoni Santhi", "Davide Villa", "Michele Polese", "Tommaso Melodia"], "title": "InterfO-RAN: Real-Time In-band Cellular Uplink Interference Detection with GPU-Accelerated dApps", "categories": ["cs.NI"], "comment": "10 pages, 12 figures, 3 tables", "summary": "Ultra-dense fifth generation (5G) and beyond networks leverage spectrum\nsharing and frequency reuse to enhance throughput, but face unpredictable\nin-band uplink (UL) interference challenges that significantly degrade Signal\nto Interference plus Noise Ratio (SINR) at affected Next Generation Node Bases\n(gNBs). This is particularly problematic at cell edges, where overlapping\nregions force User Equipments (UEs) to increase transmit power, and in\ndirectional millimeter wave systems, where beamforming sidelobes can create\nunexpected interference. The resulting signal degradation disrupts protocol\noperations, including scheduling and resource allocation, by distorting quality\nindicators like Reference Signal Received Power (RSRP) and Received Signal\nStrength Indicator (RSSI), and can compromise critical functions such as\nchannel state reporting and Hybrid Automatic Repeat Request (HARQ)\nacknowledgments. To address this problem, this article introduces InterfO-RAN,\na real-time programmable solution that leverages a Convolutional Neural Network\n(CNN) to process In-phase and Quadrature (I/Q) samples in the gNB physical\nlayer, detecting in-band interference with accuracy exceeding 91% in under 650\nus. InterfO-RAN represents the first O-RAN dApp accelerated on Graphics\nProcessing Unit (GPU), coexisting with the 5G NR physical layer processing of\nNVIDIA Aerial. Deployed in an end-to-end private 5G network with commercial\nRadio Units (RUs) and smartphones, our solution was trained and tested on more\nthan 7 million NR UL slots collected from real-world environments,\ndemonstrating robust interference detection capabilities essential for\nmaintaining network performance in dense deployments.", "AI": {"tldr": "\u9488\u5bf9\u8d85\u5bc6\u96c65G\u7f51\u7edc\u4e2d\u4e0d\u53ef\u9884\u6d4b\u7684\u5e26\u5185\u4e0a\u884c\u5e72\u6270\u5bfc\u81f4\u7f51\u7edc\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faInterfO-RAN\u65b9\u6848\u3002\u8be5\u65b9\u6848\u5229\u7528\u57fa\u4e8eCNN\u7684\u5b9e\u65f6\u53ef\u7f16\u7a0b\u6280\u672f\uff0c\u5728gNB\u7269\u7406\u5c42\u5904\u7406I/Q\u6837\u672c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u7684\u5e72\u6270\u68c0\u6d4b\uff0c\u5e76\u5728\u771f\u5b9e5G\u7f51\u7edc\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u8d85\u5bc6\u96c65G\u53ca\u672a\u6765\u7f51\u7edc\u5229\u7528\u9891\u8c31\u5171\u4eab\u548c\u9891\u7387\u590d\u7528\u4ee5\u63d0\u5347\u541e\u5410\u91cf\uff0c\u4f46\u9762\u4e34\u4e0d\u53ef\u9884\u6d4b\u7684\u5e26\u5185\u4e0a\u884c\uff08UL\uff09\u5e72\u6270\u6311\u6218\uff0c\u4e25\u91cd\u964d\u4f4e\u4e86\u53d7\u5f71\u54cdgNB\u5904\u7684\u4fe1\u5e72\u566a\u6bd4\uff08SINR\uff09\u3002\u8fd9\u5728\u5c0f\u533a\u8fb9\u7f18\u548c\u5b9a\u5411\u6beb\u7c73\u6ce2\u7cfb\u7edf\u4e2d\u5c24\u4e3a\u7a81\u51fa\uff0c\u5bfc\u81f4\u4fe1\u53f7\u8d28\u91cf\u6307\u6807\uff08\u5982RSRP\u3001RSSI\uff09\u5931\u771f\uff0c\u5e76\u6270\u4e71\u8c03\u5ea6\u3001\u8d44\u6e90\u5206\u914d\u7b49\u534f\u8bae\u64cd\u4f5c\uff0c\u635f\u5bb3\u4fe1\u9053\u72b6\u6001\u62a5\u544a\u548cHARQ\u786e\u8ba4\u7b49\u5173\u952e\u529f\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86InterfO-RAN\uff0c\u4e00\u4e2a\u5b9e\u65f6\u53ef\u7f16\u7a0b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u5229\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u5728gNB\u7269\u7406\u5c42\u5904\u7406\u540c\u76f8\u548c\u6b63\u4ea4\uff08I/Q\uff09\u6837\u672c\uff0c\u4ee5\u68c0\u6d4b\u5e26\u5185\u5e72\u6270\u3002InterfO-RAN\u662f\u9996\u4e2a\u5728GPU\u4e0a\u52a0\u901f\u7684O-RAN dApp\uff0c\u5e76\u4e0eNVIDIA Aerial\u76845G NR\u7269\u7406\u5c42\u5904\u7406\u5171\u5b58\u3002\u8be5\u65b9\u6848\u5728\u4e00\u4e2a\u7aef\u5230\u7aef\u79c1\u67095G\u7f51\u7edc\u4e2d\u90e8\u7f72\uff0c\u5e76\u4f7f\u7528\u8d85\u8fc7700\u4e07\u4e2a\u6765\u81ea\u771f\u5b9e\u73af\u5883\u7684NR UL\u65f6\u9699\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "InterfO-RAN\u5b9e\u73b0\u4e86\u8d85\u8fc791%\u7684\u5e72\u6270\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u68c0\u6d4b\u65f6\u95f4\u4f4e\u4e8e650\u5fae\u79d2\u3002\u5728\u7aef\u5230\u7aef\u79c1\u67095G\u7f51\u7edc\u4e2d\uff0c\u901a\u8fc7\u5546\u4e1a\u65e0\u7ebf\u5355\u5143\u548c\u667a\u80fd\u624b\u673a\u8fdb\u884c\u90e8\u7f72\u548c\u6d4b\u8bd5\uff0c\u5b83\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5e72\u6270\u68c0\u6d4b\u80fd\u529b\uff0c\u5bf9\u4e8e\u5728\u5bc6\u96c6\u90e8\u7f72\u4e2d\u4fdd\u6301\u7f51\u7edc\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "InterfO-RAN\u4e3a\u8d85\u5bc6\u96c65G\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u65f6\u7684\u5e26\u5185\u5e72\u6270\u68c0\u6d4b\u65b9\u6848\u3002\u5176\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u9a8c\u8bc1\u4e86\u5176\u5bf9\u63d0\u5347\u7f51\u7edc\u53ef\u9760\u6027\u548c\u6027\u80fd\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5c24\u5176\u662f\u5728\u5e94\u5bf9\u590d\u6742\u7684\u5e72\u6270\u6311\u6218\u65f6\u3002"}}
{"id": "2507.23018", "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u6570\u636e\u5c31\u7eea\u6027(DRAI)\u539f\u5219\u5982\u4f55\u5e94\u7528\u4e8e\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u7ef4\u5ea6\u7684\u5c31\u7eea\u6027\u6846\u67b6\uff0c\u4ee5\u6307\u5bfc\u79d1\u5b66AI\u7684\u57fa\u7840\u8bbe\u65bd\u53d1\u5c55\u3002", "motivation": "\u65e8\u5728\u7406\u89e3AI\u6570\u636e\u5c31\u7eea\u6027(DRAI)\u539f\u5219\u5982\u4f55\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\uff0c\u5e76\u8bc6\u522b\u5c06\u8fd9\u4e9b\u6570\u636e\u8f6c\u6362\u4e3a\u53ef\u7528\u4e8e\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684AI\u5c31\u7eea\u6570\u636e\u6240\u9762\u4e34\u7684\u6311\u6218\u548c\u901a\u7528\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6c14\u5019\u3001\u6838\u805a\u53d8\u3001\u751f\u7269/\u5065\u5eb7\u548c\u6750\u6599\u56db\u4e2a\u4ee3\u8868\u6027\u9886\u57df\u7684\u5178\u578b\u5de5\u4f5c\u6d41\uff0c\u8bc6\u522b\u5e38\u89c1\u9884\u5904\u7406\u6a21\u5f0f\u548c\u9886\u57df\u7279\u5b9a\u9650\u5236\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b\u6570\u636e\u5c31\u7eea\u7ea7\u522b\uff08\u4ece\u539f\u59cb\u5230AI\u5c31\u7eea\uff09\u548c\u6570\u636e\u5904\u7406\u9636\u6bb5\uff08\u4ece\u6444\u53d6\u5230\u5206\u7247\uff09\u7684\u4e24\u7ef4\u5ea6\u5c31\u7eea\u6027\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e13\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97(HPC)\u73af\u5883\u5b9a\u5236\uff0c\u5e76\u5f3a\u8c03\u57fa\u4e8eTransformer\u7684\u751f\u6210\u6a21\u578b\u3002", "result": "\u7814\u7a76\u660e\u786e\u4e86AI\u6570\u636e\u5c31\u7eea\u6027(DRAI)\u5728\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u4e2d\u7684\u5e94\u7528\u6a21\u5f0f\u548c\u5173\u952e\u6311\u6218\u3002\u63d0\u51fa\u7684\u4e24\u7ef4\u5ea6\u6846\u67b6\uff08\u6570\u636e\u5c31\u7eea\u7ea7\u522b\u548c\u6570\u636e\u5904\u7406\u9636\u6bb5\uff09\u80fd\u591f\u6982\u62ec\u79d1\u5b66\u6570\u636e\u5411\u53ef\u6269\u5c55AI\u8bad\u7ec3\u8f6c\u5316\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u5f62\u6210\u4e86\u4e00\u4e2a\u6982\u5ff5\u6027\u6210\u719f\u5ea6\u77e9\u9635\uff0c\u7528\u4e8e\u8868\u5f81\u79d1\u5b66\u6570\u636e\u7684\u5c31\u7eea\u7a0b\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u6210\u719f\u5ea6\u77e9\u9635\u80fd\u591f\u6307\u5bfc\u57fa\u7840\u8bbe\u65bd\u7684\u5f00\u53d1\uff0c\u65e8\u5728\u4e3a\u79d1\u5b66\u9886\u57df\u53ef\u6269\u5c55\u548c\u53ef\u590d\u73b0\u7684AI\u63d0\u4f9b\u6807\u51c6\u5316\u3001\u8de8\u9886\u57df\u652f\u6301\u3002"}}
{"id": "2507.22956", "pdf": "https://arxiv.org/pdf/2507.22956", "abs": "https://arxiv.org/abs/2507.22956", "authors": ["Dong Hyun Roh", "Rajesh Kumar", "An Ngo"], "title": "LLM-Assisted Cheating Detection in Korean Language via Keystrokes", "categories": ["cs.LG", "cs.HC", "K.3.1"], "comment": "This paper has 11 pages, 6 figures, 2 tables, and has been accepted\n  for publication at IEEE-IJCB 2025", "summary": "This paper presents a keystroke-based framework for detecting LLM-assisted\ncheating in Korean, addressing key gaps in prior research regarding language\ncoverage, cognitive context, and the granularity of LLM involvement. Our\nproposed dataset includes 69 participants who completed writing tasks under\nthree conditions: Bona fide writing, paraphrasing ChatGPT responses, and\ntranscribing ChatGPT responses. Each task spans six cognitive processes defined\nin Bloom's Taxonomy (remember, understand, apply, analyze, evaluate, and\ncreate). We extract interpretable temporal and rhythmic features and evaluate\nmultiple classifiers under both Cognition-Aware and Cognition-Unaware settings.\nTemporal features perform well under Cognition-Aware evaluation scenarios,\nwhile rhythmic features generalize better under cross-cognition scenarios.\nMoreover, detecting bona fide and transcribed responses was easier than\nparaphrased ones for both the proposed models and human evaluators, with the\nmodels significantly outperforming the humans. Our findings affirm that\nkeystroke dynamics facilitate reliable detection of LLM-assisted writing across\nvarying cognitive demands and writing strategies, including paraphrasing and\ntranscribing LLM-generated responses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fb\u952e\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u97e9\u8bed\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u7684\u4f5c\u5f0a\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u8bed\u8a00\u8986\u76d6\u3001\u8ba4\u77e5\u8bed\u5883\u548cLLM\u53c2\u4e0e\u7c92\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u6709\u6548\u68c0\u6d4bLLM\u8f85\u52a9\u4f5c\u5f0a\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b69\u540d\u53c2\u4e0e\u8005\u7684\u6570\u636e\u96c6\uff0c\u4ed6\u4eec\u5728\u4e09\u79cd\u6761\u4ef6\u4e0b\uff08\u771f\u5b9e\u5199\u4f5c\u3001\u610f\u8bd1ChatGPT\u56de\u7b54\u3001\u8f6c\u5f55ChatGPT\u56de\u7b54\uff09\u5b8c\u6210\u5199\u4f5c\u4efb\u52a1\uff0c\u4efb\u52a1\u6db5\u76d6\u5e03\u9c81\u59c6\u8ba4\u77e5\u5206\u7c7b\u6cd5\u7684\u516d\u4e2a\u8ba4\u77e5\u8fc7\u7a0b\u3002\u63d0\u53d6\u4e86\u53ef\u89e3\u91ca\u7684\u65f6\u95f4\u548c\u8282\u594f\u7279\u5f81\uff0c\u5e76\u5728\u8ba4\u77e5\u611f\u77e5\u548c\u8ba4\u77e5\u975e\u611f\u77e5\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u4e86\u591a\u79cd\u5206\u7c7b\u5668\u3002", "result": "\u65f6\u95f4\u7279\u5f81\u5728\u8ba4\u77e5\u611f\u77e5\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u800c\u8282\u594f\u7279\u5f81\u5728\u8de8\u8ba4\u77e5\u573a\u666f\u4e0b\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u3002\u68c0\u6d4b\u771f\u5b9e\u5199\u4f5c\u548c\u8f6c\u5f55\u56de\u7b54\u6bd4\u68c0\u6d4b\u610f\u8bd1\u56de\u7b54\u66f4\u5bb9\u6613\u3002\u6240\u63d0\u51fa\u7684\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4eba\u7c7b\u8bc4\u4f30\u8005\u3002", "conclusion": "\u51fb\u952e\u52a8\u6001\u80fd\u591f\u53ef\u9760\u5730\u68c0\u6d4bLLM\u8f85\u52a9\u5199\u4f5c\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u8ba4\u77e5\u9700\u6c42\u548c\u5199\u4f5c\u7b56\u7565\uff0c\u5305\u62ec\u610f\u8bd1\u548c\u8f6c\u5f55LLM\u751f\u6210\u7684\u5185\u5bb9\u3002"}}
{"id": "2507.23006", "pdf": "https://arxiv.org/pdf/2507.23006", "abs": "https://arxiv.org/abs/2507.23006", "authors": ["Zhensheng Yuan", "Haozhi Huang", "Zhen Xiong", "Di Wang", "Guanghua Yang"], "title": "Robust and Efficient 3D Gaussian Splatting for Urban Scene Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "We present a framework that enables fast reconstruction and real-time\nrendering of urban-scale scenes while maintaining robustness against appearance\nvariations across multi-view captures. Our approach begins with scene\npartitioning for parallel training, employing a visibility-based image\nselection strategy to optimize training efficiency. A controllable\nlevel-of-detail (LOD) strategy explicitly regulates Gaussian density under a\nuser-defined budget, enabling efficient training and rendering while\nmaintaining high visual fidelity. The appearance transformation module\nmitigates the negative effects of appearance inconsistencies across images\nwhile enabling flexible adjustments. Additionally, we utilize enhancement\nmodules, such as depth regularization, scale regularization, and antialiasing,\nto improve reconstruction fidelity. Experimental results demonstrate that our\nmethod effectively reconstructs urban-scale scenes and outperforms previous\napproaches in both efficiency and quality. The source code is available at:\nhttps://yzslab.github.io/REUrbanGS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u5feb\u901f\u91cd\u5efa\u548c\u5b9e\u65f6\u6e32\u67d3\u57ce\u5e02\u5c3a\u5ea6\u573a\u666f\uff0c\u540c\u65f6\u6709\u6548\u5e94\u5bf9\u591a\u89c6\u89d2\u6355\u83b7\u4e2d\u7684\u5916\u89c2\u53d8\u5316\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u5c3a\u5ea6\u573a\u666f\u91cd\u5efa\u548c\u5b9e\u65f6\u6e32\u67d3\u9762\u4e34\u7684\u6548\u7387\u3001\u8d28\u91cf\u4ee5\u53ca\u591a\u89c6\u89d2\u56fe\u50cf\u95f4\u5916\u89c2\u4e0d\u4e00\u81f4\u7684\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u573a\u666f\u5212\u5206\u4ee5\u5b9e\u73b0\u5e76\u884c\u8bad\u7ec3\u3001\u57fa\u4e8e\u53ef\u89c1\u6027\u7684\u56fe\u50cf\u9009\u62e9\u7b56\u7565\u4ee5\u4f18\u5316\u8bad\u7ec3\u6548\u7387\u3001\u53ef\u63a7\u7684LOD\uff08\u7ec6\u8282\u5c42\u6b21\uff09\u7b56\u7565\u8c03\u8282\u9ad8\u65af\u5bc6\u5ea6\u4ee5\u5e73\u8861\u6548\u7387\u4e0e\u89c6\u89c9\u4fdd\u771f\u5ea6\u3001\u5916\u89c2\u53d8\u6362\u6a21\u5757\u4ee5\u6d88\u9664\u5916\u89c2\u4e0d\u4e00\u81f4\uff0c\u5e76\u5229\u7528\u6df1\u5ea6\u6b63\u5219\u5316\u3001\u5c3a\u5ea6\u6b63\u5219\u5316\u548c\u6297\u952f\u9f7f\u7b49\u589e\u5f3a\u6a21\u5757\u63d0\u5347\u91cd\u5efa\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u91cd\u5efa\u57ce\u5e02\u5c3a\u5ea6\u573a\u666f\uff0c\u5e76\u5728\u6548\u7387\u548c\u8d28\u91cf\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u57ce\u5e02\u5c3a\u5ea6\u573a\u666f\u7684\u5feb\u901f\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u5b9e\u65f6\u6e32\u67d3\uff0c\u5e76\u6709\u6548\u5904\u7406\u4e86\u5916\u89c2\u53d8\u5316\u95ee\u9898\uff0c\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.22915", "pdf": "https://arxiv.org/pdf/2507.22915", "abs": "https://arxiv.org/abs/2507.22915", "authors": ["Esmail Gumaan"], "title": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages", "summary": "Hallucination in Large Language Models (LLMs) refers to the generation of\ncontent that is not faithful to the input or the real-world facts. This paper\nprovides a rigorous treatment of hallucination in LLMs, including formal\ndefinitions and theoretical analyses. We distinguish between intrinsic and\nextrinsic hallucinations, and define a \\textit{hallucination risk} for models.\nWe derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes\nand Rademacher complexity). We then survey detection strategies for\nhallucinations, such as token-level uncertainty estimation, confidence\ncalibration, and attention alignment checks. On the mitigation side, we discuss\napproaches including retrieval-augmented generation, hallucination-aware\nfine-tuning, logit calibration, and the incorporation of fact-verification\nmodules. We propose a unified detection and mitigation workflow, illustrated\nwith a diagram, to integrate these strategies. Finally, we outline evaluation\nprotocols for hallucination, recommending datasets, metrics, and experimental\nsetups to quantify and reduce hallucinations. Our work lays a theoretical\nfoundation and practical guidelines for addressing the crucial challenge of\nhallucination in LLMs.", "AI": {"tldr": "\u8bba\u6587\u5bf9LLM\u5e7b\u89c9\u8fdb\u884c\u4e86\u4e25\u8c28\u5904\u7406\uff0c\u5305\u62ec\u7406\u8bba\u5b9a\u4e49\u3001\u98ce\u9669\u5206\u6790\u3001\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7b56\u7565\u7efc\u8ff0\u3001\u7edf\u4e00\u5de5\u4f5c\u6d41\u63d0\u8bae\u53ca\u8bc4\u4f30\u534f\u8bae\uff0c\u4e3a\u89e3\u51b3\u8be5\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5357\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u4e0d\u5fe0\u5b9e\u4e8e\u8f93\u5165\u6216\u73b0\u5b9e\u5185\u5bb9\uff08\u5373\u5e7b\u89c9\uff09\u8fd9\u4e00\u5173\u952e\u6311\u6218\u3002", "method": "1. \u5f62\u5f0f\u5316\u5b9a\u4e49\u5e7b\u89c9\uff08\u5185\u5728\u4e0e\u5916\u5728\uff09\uff0c\u5e76\u5b9a\u4e49\u5e7b\u89c9\u98ce\u9669\u30022. \u5229\u7528\u5b66\u4e60\u7406\u8bba\u6846\u67b6\uff08PAC-Bayes\u548cRademacher\u590d\u6742\u5ea6\uff09\u63a8\u5bfc\u98ce\u9669\u754c\u9650\u30023. \u7efc\u8ff0\u5e7b\u89c9\u68c0\u6d4b\u7b56\u7565\uff08\u5982\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3001\u7f6e\u4fe1\u5ea6\u6821\u51c6\u3001\u6ce8\u610f\u529b\u5bf9\u9f50\uff09\u30024. \u7efc\u8ff0\u5e7b\u89c9\u7f13\u89e3\u65b9\u6cd5\uff08\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u5fae\u8c03\u3001logit\u6821\u51c6\u3001\u4e8b\u5b9e\u6838\u67e5\uff09\u30025. \u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u68c0\u6d4b\u4e0e\u7f13\u89e3\u5de5\u4f5c\u6d41\u7a0b\u30026. \u6982\u8ff0\u5e7b\u89c9\u8bc4\u4f30\u534f\u8bae\uff08\u6570\u636e\u96c6\u3001\u6307\u6807\u3001\u5b9e\u9a8c\u8bbe\u7f6e\uff09\u3002", "result": "\u5efa\u7acb\u4e86\u5e7b\u89c9\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5305\u62ec\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u98ce\u9669\u5206\u6790\uff1b\u7cfb\u7edf\u6027\u5730\u6574\u7406\u5e76\u5206\u7c7b\u4e86\u73b0\u6709\u7684\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7b56\u7565\uff1b\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5e7b\u89c9\u5904\u7406\u5de5\u4f5c\u6d41\u7a0b\uff1b\u4e3a\u5e7b\u89c9\u7684\u91cf\u5316\u548c\u51cf\u5c11\u63d0\u4f9b\u4e86\u8bc4\u4f30\u65b9\u6848\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3a\u89e3\u51b3LLMs\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5bfc\u65b9\u9488\u3002"}}
{"id": "2507.23286", "pdf": "https://arxiv.org/pdf/2507.23286", "abs": "https://arxiv.org/abs/2507.23286", "authors": ["Zihong Li", "Anshan Yuan", "Xinghua Sun"], "title": "Optimal Packetization Towards Low Latency in Random Access Networks (extended version)", "categories": ["cs.NI"], "comment": "This article is an extended version of a paper to be presented at the\n  IEEE 25th International Conference on Communication Technology (ICCT),\n  Shenyang, China, October 2025", "summary": "As the demand for low-latency services grows, ensuring the delay performance\nof random access (RA) networks has become a priority. Existing studies on the\nqueueing delay performance of the Aloha model universally treat packets as\natomic transmission units, focusing primarily on delay measured in time slots.\nHowever, the impact of packetization on queueing delay has been consistently\noverlooked, particularly for the mean queueing delay measured in seconds, which\nserves as a more precise and practically relevant performance metric than its\nslot-based counterpart. Here, packetization refers to the process of\ndetermining the number of bits assembled into a packet. To optimize queueing\ndelay from the perspective of packetization, this paper establishes the\nmathematical relationship between packetization and mean queueing delay in\nseconds for both connection-free and connection-based Aloha schemes, and\nexplores the optimal packetization strategy to minimize this delay. We identify\nthe optimal mean queueing delay and its corresponding packet size via numerical\nmethods, and further analyze the influence of various network parameters. We\nfurther use simulations to investigate the similar impact of packetization on\njitter of queueing delay. We then apply our analysis to re-evaluate the complex\ntrade-off between the connection-free and connection-based schemes through the\nnew perspective of packetization. Furthermore, recognizing that an analysis of\nthe queueing delay performance for RA-SDT in NTN scenarios, especially from a\npacketization perspective, also remains an unexplored area, we apply the\nanalysis to this scenario as a case study.", "AI": {"tldr": "\u672c\u7814\u7a76\u5173\u6ce8\u5206\u7ec4\u5316\u5bf9\u968f\u673a\u63a5\u5165\u7f51\u7edc\u4e2d\u4ee5\u79d2\u4e3a\u5355\u4f4d\u7684\u6392\u961f\u5ef6\u8fdf\u7684\u5f71\u54cd\uff0c\u5efa\u7acb\u4e86\u5206\u7ec4\u5316\u4e0e\u5ef6\u8fdf\u7684\u6570\u5b66\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u65b9\u6cd5\u548c\u4eff\u771f\u5bfb\u627e\u6700\u4f18\u5206\u7ec4\u7b56\u7565\u4ee5\u6700\u5c0f\u5316\u5ef6\u8fdf\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e0d\u540cAloha\u65b9\u6848\u7684\u6743\u8861\u5206\u6790\u548cNTN\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u5173\u4e8eAloha\u6a21\u578b\u6392\u961f\u5ef6\u8fdf\u7684\u7814\u7a76\u666e\u904d\u5c06\u6570\u636e\u5305\u89c6\u4e3a\u539f\u5b50\u4f20\u8f93\u5355\u5143\uff0c\u4e14\u4e3b\u8981\u5173\u6ce8\u4ee5\u65f6\u9699\u8ba1\u91cf\u7684\u5ef6\u8fdf\uff0c\u800c\u5ffd\u7565\u4e86\u5206\u7ec4\u5316\uff08\u5373\u786e\u5b9a\u6570\u636e\u5305\u4e2d\u6bd4\u7279\u6570\uff09\u5bf9\u4ee5\u79d2\u4e3a\u5355\u4f4d\u7684\u5e73\u5747\u6392\u961f\u5ef6\u8fdf\u7684\u5f71\u54cd\u3002\u8fd9\u79cd\u4ee5\u79d2\u8ba1\u91cf\u7684\u5ef6\u8fdf\u662f\u4e00\u4e2a\u66f4\u7cbe\u786e\u3001\u66f4\u5177\u5b9e\u9645\u76f8\u5173\u6027\u7684\u6027\u80fd\u6307\u6807\uff0c\u5176\u4f18\u5316\u5bf9\u4e8e\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u670d\u52a1\u9700\u6c42\u81f3\u5173\u91cd\u8981\u3002", "method": ["\u9488\u5bf9\u65e0\u8fde\u63a5\u548c\u57fa\u4e8e\u8fde\u63a5\u7684Aloha\u65b9\u6848\uff0c\u5efa\u7acb\u4e86\u5206\u7ec4\u5316\u4e0e\u79d2\u7ea7\u5e73\u5747\u6392\u961f\u5ef6\u8fdf\u4e4b\u95f4\u7684\u6570\u5b66\u5173\u7cfb\u3002", "\u91c7\u7528\u6570\u503c\u65b9\u6cd5\u8bc6\u522b\u6700\u4f18\u5e73\u5747\u6392\u961f\u5ef6\u8fdf\u53ca\u5176\u5bf9\u5e94\u7684\u5206\u7ec4\u5927\u5c0f\uff0c\u5e76\u5206\u6790\u5404\u79cd\u7f51\u7edc\u53c2\u6570\u7684\u5f71\u54cd\u3002", "\u5229\u7528\u4eff\u771f\u7814\u7a76\u5206\u7ec4\u5316\u5bf9\u6392\u961f\u5ef6\u8fdf\u6296\u52a8\u7684\u7c7b\u4f3c\u5f71\u54cd\u3002", "\u4ece\u5206\u7ec4\u5316\u7684\u65b0\u89c6\u89d2\u91cd\u65b0\u8bc4\u4f30\u65e0\u8fde\u63a5\u548c\u57fa\u4e8e\u8fde\u63a5\u65b9\u6848\u4e4b\u95f4\u590d\u6742\u7684\u6743\u8861\u3002", "\u5c06\u5206\u6790\u5e94\u7528\u4e8eNTN\uff08\u975e\u5730\u9762\u7f51\u7edc\uff09\u573a\u666f\u4e2d\u7684RA-SDT\uff08\u968f\u673a\u63a5\u5165-\u77ed\u6570\u636e\u4f20\u8f93\uff09\u6392\u961f\u5ef6\u8fdf\u6027\u80fd\uff0c\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\u3002"], "result": ["\u6210\u529f\u5efa\u7acb\u4e86\u5206\u7ec4\u5316\u4e0e\u79d2\u7ea7\u5e73\u5747\u6392\u961f\u5ef6\u8fdf\u7684\u6570\u5b66\u5173\u7cfb\u3002", "\u901a\u8fc7\u6570\u503c\u65b9\u6cd5\u8bc6\u522b\u4e86\u6700\u4f18\u5e73\u5747\u6392\u961f\u5ef6\u8fdf\u53ca\u5176\u5bf9\u5e94\u7684\u5206\u7ec4\u5927\u5c0f\u3002", "\u5206\u6790\u4e86\u5404\u79cd\u7f51\u7edc\u53c2\u6570\u5bf9\u5ef6\u8fdf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "\u901a\u8fc7\u4eff\u771f\u63ed\u793a\u4e86\u5206\u7ec4\u5316\u5bf9\u6392\u961f\u5ef6\u8fdf\u6296\u52a8\u7684\u7c7b\u4f3c\u5f71\u54cd\u3002", "\u4ece\u5206\u7ec4\u5316\u7684\u65b0\u89c6\u89d2\u91cd\u65b0\u8bc4\u4f30\u4e86\u65e0\u8fde\u63a5\u548c\u57fa\u4e8e\u8fde\u63a5Aloha\u65b9\u6848\u4e4b\u95f4\u7684\u590d\u6742\u6743\u8861\u3002", "\u5c06\u5206\u6790\u5e94\u7528\u4e8eNTN\u573a\u666f\u4e2d\u7684RA-SDT\u6392\u961f\u5ef6\u8fdf\u6027\u80fd\uff0c\u5e76\u8fdb\u884c\u4e86\u6848\u4f8b\u7814\u7a76\u3002"], "conclusion": "\u8bba\u6587\u901a\u8fc7\u6df1\u5165\u5206\u6790\u5206\u7ec4\u5316\u5bf9\u79d2\u7ea7\u6392\u961f\u5ef6\u8fdf\u7684\u5f71\u54cd\uff0c\u4e3a\u4f18\u5316\u968f\u673a\u63a5\u5165\u7f51\u7edc\u7684\u5ef6\u8fdf\u6027\u80fd\u63d0\u4f9b\u4e86\u5173\u952e\u6d1e\u5bdf\u3002\u7814\u7a76\u4e0d\u4ec5\u786e\u5b9a\u4e86\u6700\u4f18\u5206\u7ec4\u5927\u5c0f\u548c\u6700\u5c0f\u5ef6\u8fdf\uff0c\u8fd8\u63ed\u793a\u4e86\u5206\u7ec4\u5316\u5bf9\u6296\u52a8\u7684\u5f71\u54cd\uff0c\u5e76\u66f4\u65b0\u4e86\u5bf9\u4e0d\u540cAloha\u65b9\u6848\u95f4\u6743\u8861\u7684\u7406\u89e3\uff0c\u4e3a\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7684\u8bbe\u8ba1\u548c\u5b9e\u65bd\u63d0\u4f9b\u4e86\u5b9e\u9645\u4e14\u91cd\u8981\u7684\u6307\u5bfc\u3002"}}
{"id": "2507.23067", "pdf": "https://arxiv.org/pdf/2507.23067", "abs": "https://arxiv.org/abs/2507.23067", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u5982\u4f55\u7f13\u89e3\u793e\u4f1a\u504f\u89c1\u3002\u901a\u8fc7\u5bf9\u6bd4\u591a\u79cd\u53bb\u504f\u89c1\u7b56\u7565\u5e76\u8c03\u6574\u6837\u672c\u6bd4\u4f8b\uff0c\u53d1\u73b0\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u4ee51:4\u7684\u53bb\u504f\u89c1\u4e0e\u63a8\u7406\u6837\u672c\u6bd4\u4f8b\u8bad\u7ec3\uff0c\u53ef\u5c06\u504f\u89c1\u964d\u4f4e10%\u540c\u65f6\u4fdd\u755988%\u7684\u63a8\u7406\u7cbe\u5ea6\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5176\u8f93\u51fa\u5e38\u4f34\u968f\u660e\u663e\u7684\u793e\u4f1a\u504f\u89c1\u3002\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e0e\u504f\u89c1\u7f13\u89e3\u4e4b\u95f4\u662f\u5426\u5b58\u5728\u56fa\u6709\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4ee5\u53ca\u4e24\u8005\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e9f\u5f85\u89e3\u51b3\u7684\u5f00\u653e\u6027\u7814\u7a76\u95ee\u9898\u3002", "method": "\u9996\u5148\uff0c\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u57fa\u51c6\u6d4b\u8bd5\u4e86\u4e09\u79cd\u504f\u89c1\u7f13\u89e3\u7b56\u7565\uff08\u76d1\u7763\u5fae\u8c03SFT\u3001\u77e5\u8bc6\u84b8\u998fKD\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60RL\uff09\uff0c\u4ee5\u786e\u5b9a\u5176\u4f18\u52a3\u3002\u5176\u6b21\uff0c\u5728\u6bcf\u79cd\u7b56\u7565\u4e0b\uff0c\u8c03\u6574\u53bb\u504f\u89c1\u6837\u672c\u4e0e\u63a8\u7406\u4e2d\u5fc3\u6837\u672c\u7684\u6bd4\u4f8b\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u53d8\u5316\uff0c\u7ed8\u5236\u51fa\u63a8\u7406\u80fd\u529b\u4e0e\u504f\u89c1\u4e4b\u95f4\u7684\u6743\u8861\u66f2\u7ebf\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u4e00\u4e2a\u6301\u7eed\u5b58\u5728\u7684\u201c\u6700\u4f73\u5e73\u8861\u70b9\u201d\uff1a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ee5\u5927\u7ea61:4\uff08\u53bb\u504f\u89c1\u4e0e\u63a8\u7406\uff09\u7684\u6837\u672c\u6df7\u5408\u6bd4\u4f8b\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u5c06\u523b\u677f\u5370\u8c61\u5f97\u5206\u964d\u4f4e10%\uff0c\u540c\u65f6\u4fdd\u7559\u6a21\u578b\u539f\u59cb\u63a8\u7406\u51c6\u786e\u7387\u768488%\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u516c\u5e73\u6027\u548c\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u8868\u660e\u901a\u8fc7\u4f18\u5316\u8bad\u7ec3\u8303\u5f0f\uff08\u5982\u5f3a\u5316\u5b66\u4e60\uff09\u548c\u6837\u672c\u6df7\u5408\u6bd4\u4f8b\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u504f\u89c1\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2507.22959", "pdf": "https://arxiv.org/pdf/2507.22959", "abs": "https://arxiv.org/abs/2507.22959", "authors": ["Salah A. Faroughi", "Farinaz Mostajeran", "Amin Hamed Mashhadzadeh", "Shirko Faroughi"], "title": "Scientific Machine Learning with Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.CE", "math-ph", "math.MP"], "comment": null, "summary": "The field of scientific machine learning, which originally utilized\nmultilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold\nNetworks (KANs) for data encoding. This shift is driven by the limitations of\nMLPs, including poor interpretability, fixed activation functions, and\ndifficulty capturing localized or high-frequency features. KANs address these\nissues with enhanced interpretability and flexibility, enabling more efficient\nmodeling of complex nonlinear interactions and effectively overcoming the\nconstraints associated with conventional MLP architectures. This review\ncategorizes recent progress in KAN-based models across three distinct\nperspectives: (i) data-driven learning, (ii) physics-informed modeling, and\n(iii) deep operator learning. Each perspective is examined through the lens of\narchitectural design, training strategies, application efficacy, and\ncomparative evaluation against MLP-based counterparts. By benchmarking KANs\nagainst MLPs, we highlight consistent improvements in accuracy, convergence,\nand spectral representation, clarifying KANs' advantages in capturing complex\ndynamics while learning more effectively. Finally, this review identifies\ncritical challenges and open research questions in KAN development,\nparticularly regarding computational efficiency, theoretical guarantees,\nhyperparameter tuning, and algorithm complexity. We also outline future\nresearch directions aimed at improving the robustness, scalability, and\nphysical consistency of KAN-based frameworks.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u5206\u6790\u4e86Kolmogorov-Arnold Networks (KANs)\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u9010\u6e10\u53d6\u4ee3\u591a\u5c42\u611f\u77e5\u5668 (MLPs)\u7684\u8d8b\u52bf\u3002KANs\u56e0\u5176\u66f4\u597d\u7684\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\uff0c\u5728\u51c6\u786e\u6027\u3001\u6536\u655b\u6027\u548c\u9891\u8c31\u8868\u793a\u65b9\u9762\u6301\u7eed\u4f18\u4e8eMLPs\u3002\u6587\u7ae0\u63a2\u8ba8\u4e86KANs\u5728\u6570\u636e\u9a71\u52a8\u3001\u7269\u7406\u4fe1\u606f\u548c\u6df1\u5ea6\u7b97\u5b50\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7406\u8bba\u65b9\u9762\u4ecd\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u591a\u5c42\u611f\u77e5\u5668 (MLPs) \u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5305\u62ec\u89e3\u91ca\u6027\u5dee\u3001\u6fc0\u6d3b\u51fd\u6570\u56fa\u5b9a\u4ee5\u53ca\u96be\u4ee5\u6355\u6349\u5c40\u90e8\u6216\u9ad8\u9891\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u5177\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\u7684\u6a21\u578b\uff08\u5982KANs\uff09\u6765\u6709\u6548\u5efa\u6a21\u590d\u6742\u7684\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7efc\u8ff0\u7684\u65b9\u5f0f\uff0c\u5c06\u57fa\u4e8eKANs\u7684\u6a21\u578b\u8fdb\u5c55\u5f52\u7c7b\u4e3a\u4e09\u4e2a\u4e3b\u8981\u89c6\u89d2\uff1a\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u3001\u7269\u7406\u4fe1\u606f\u5efa\u6a21\u548c\u6df1\u5ea6\u7b97\u5b50\u5b66\u4e60\u3002\u6bcf\u4e2a\u89c6\u89d2\u90fd\u4ece\u67b6\u6784\u8bbe\u8ba1\u3001\u8bad\u7ec3\u7b56\u7565\u3001\u5e94\u7528\u6548\u679c\u4ee5\u53ca\u4e0e\u57fa\u4e8eMLPs\u7684\u6a21\u578b\u7684\u6bd4\u8f83\u8bc4\u4f30\u7b49\u591a\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5ba1\u89c6\u548c\u5206\u6790\u3002", "result": "\u901a\u8fc7\u4e0eMLPs\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0cKANs\u5728\u51c6\u786e\u6027\u3001\u6536\u655b\u6027\u548c\u9891\u8c31\u8868\u793a\u65b9\u9762\u8868\u73b0\u51fa\u6301\u7eed\u7684\u6539\u8fdb\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cKANs\u5728\u6355\u6349\u590d\u6742\u52a8\u529b\u5b66\u548c\u5b9e\u73b0\u66f4\u6709\u6548\u5b66\u4e60\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "KANs\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u76f8\u8f83\u4e8eMLPs\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u548c\u6f5c\u529b\u3002\u7136\u800c\uff0cKANs\u7684\u53d1\u5c55\u4ecd\u9762\u4e34\u8ba1\u7b97\u6548\u7387\u3001\u7406\u8bba\u4fdd\u8bc1\u3001\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u7b97\u6cd5\u590d\u6742\u6027\u7b49\u5173\u952e\u6311\u6218\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u81f4\u529b\u4e8e\u63d0\u5347KANs\u6846\u67b6\u7684\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.23021", "pdf": "https://arxiv.org/pdf/2507.23021", "abs": "https://arxiv.org/abs/2507.23021", "authors": ["Giuseppe Cartella", "Vittorio Cuculo", "Alessandro D'Amelio", "Marcella Cornia", "Giuseppe Boccignone", "Rita Cucchiara"], "title": "Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction", "categories": ["cs.CV", "cs.AI"], "comment": "Proceedings of the IEEE/CVF International Conference on Computer\n  Vision (ICCV), 2025", "summary": "Predicting human gaze scanpaths is crucial for understanding visual\nattention, with applications in human-computer interaction, autonomous systems,\nand cognitive robotics. While deep learning models have advanced scanpath\nprediction, most existing approaches generate averaged behaviors, failing to\ncapture the variability of human visual exploration. In this work, we present\nScanDiff, a novel architecture that combines diffusion models with Vision\nTransformers to generate diverse and realistic scanpaths. Our method explicitly\nmodels scanpath variability by leveraging the stochastic nature of diffusion\nmodels, producing a wide range of plausible gaze trajectories. Additionally, we\nintroduce textual conditioning to enable task-driven scanpath generation,\nallowing the model to adapt to different visual search objectives. Experiments\non benchmark datasets show that ScanDiff surpasses state-of-the-art methods in\nboth free-viewing and task-driven scenarios, producing more diverse and\naccurate scanpaths. These results highlight its ability to better capture the\ncomplexity of human visual behavior, pushing forward gaze prediction research.\nSource code and models are publicly available at\nhttps://aimagelab.github.io/ScanDiff.", "AI": {"tldr": "ScanDiff\u7ed3\u5408\u6269\u6563\u6a21\u578b\u4e0eVision Transformer\uff0c\u751f\u6210\u591a\u6837\u5316\u4e14\u4efb\u52a1\u9a71\u52a8\u7684\u4eba\u7c7b\u6ce8\u89c6\u626b\u63cf\u8def\u5f84\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6ce8\u89c6\u626b\u63cf\u8def\u5f84\u9884\u6d4b\u4e2d\u751f\u6210\u5e73\u5747\u884c\u4e3a\uff0c\u672a\u80fd\u6355\u6349\u4eba\u7c7b\u89c6\u89c9\u63a2\u7d22\u7684\u5185\u5728\u53d8\u5f02\u6027\u3002", "method": "\u63d0\u51faScanDiff\uff0c\u4e00\u4e2a\u7ed3\u5408\u6269\u6563\u6a21\u578b\uff08\u5229\u7528\u5176\u968f\u673a\u6027\u5efa\u6a21\u626b\u63cf\u8def\u5f84\u53d8\u5f02\u6027\uff09\u548cVision Transformer\u7684\u65b0\u9896\u67b6\u6784\u3002\u6b64\u5916\uff0c\u5f15\u5165\u6587\u672c\u6761\u4ef6\u4ee5\u5b9e\u73b0\u4efb\u52a1\u9a71\u52a8\u7684\u626b\u63cf\u8def\u5f84\u751f\u6210\u3002", "result": "ScanDiff\u5728\u81ea\u7531\u89c2\u770b\u548c\u4efb\u52a1\u9a71\u52a8\u573a\u666f\u4e2d\u5747\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u751f\u6210\u4e86\u66f4\u5177\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u7684\u626b\u63cf\u8def\u5f84\u3002", "conclusion": "ScanDiff\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u89c6\u89c9\u884c\u4e3a\u7684\u590d\u6742\u6027\uff0c\u663e\u8457\u63a8\u52a8\u4e86\u6ce8\u89c6\u9884\u6d4b\u7814\u7a76\u7684\u8fdb\u5c55\u3002"}}
{"id": "2507.22917", "pdf": "https://arxiv.org/pdf/2507.22917", "abs": "https://arxiv.org/abs/2507.22917", "authors": ["Kwun Hang Lau", "Ruiyuan Zhang", "Weijie Shi", "Xiaofang Zhou", "Xiaojun Cheng"], "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "While Retrieval-Augmented Generation (RAG) excels at injecting static,\nfactual knowledge into Large Language Models (LLMs), it exhibits a critical\ndeficit in handling longitudinal queries that require tracking entities and\nphenomena across time. This blind spot arises because conventional,\nsemantically-driven retrieval methods are not equipped to gather evidence that\nis both topically relevant and temporally coherent for a specified duration. We\naddress this challenge by proposing a new framework that fundamentally\nredesigns the RAG pipeline to infuse temporal logic. Our methodology begins by\ndisentangling a user's query into its core subject and its temporal window. It\nthen employs a specialized retriever that calibrates semantic matching against\ntemporal relevance, ensuring the collection of a contiguous evidence set that\nspans the entire queried period. To enable rigorous evaluation of this\ncapability, we also introduce the Analytical Diachronic Question Answering\nBenchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus\nof real and synthetic financial news. Empirical results on ADQAB show that our\napproach yields substantial gains in answer accuracy, surpassing standard RAG\nimplementations by 13% to 27%. This work provides a validated pathway toward\nRAG systems capable of performing the nuanced, evolutionary analysis required\nfor complex, real-world questions. The dataset and code for this study are\npublicly available at https://github.com/kwunhang/TA-RAG.", "AI": {"tldr": "\u4f20\u7edfRAG\u5728\u5904\u7406\u8de8\u65f6\u95f4\u67e5\u8be2\u65f6\u5b58\u5728\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u903b\u8f91\u548c\u4e13\u95e8\u7684\u68c0\u7d22\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u671f\u67e5\u8be2\u7684\u51c6\u786e\u6027\uff0c\u5e76\u53d1\u5e03\u4e86ADQAB\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u5728\u5904\u7406\u9700\u8981\u8de8\u65f6\u95f4\u8ddf\u8e2a\u5b9e\u4f53\u548c\u73b0\u8c61\u7684\u957f\u671f\u67e5\u8be2\u65f6\u5b58\u5728\u5173\u952e\u7f3a\u9677\uff0c\u56e0\u4e3a\u5176\u8bed\u4e49\u9a71\u52a8\u7684\u68c0\u7d22\u65b9\u6cd5\u65e0\u6cd5\u83b7\u53d6\u65e2\u4e3b\u9898\u76f8\u5173\u53c8\u65f6\u95f4\u8fde\u8d2f\u7684\u8bc1\u636e\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u91cd\u65b0\u8bbe\u8ba1RAG\u6d41\u7a0b\u7684\u65b0\u6846\u67b6\uff0c\u878d\u5165\u65f6\u95f4\u903b\u8f91\u3002\u8be5\u65b9\u6cd5\u5c06\u7528\u6237\u67e5\u8be2\u5206\u89e3\u4e3a\u6838\u5fc3\u4e3b\u9898\u548c\u65f6\u95f4\u7a97\u53e3\uff0c\u5e76\u4f7f\u7528\u4e13\u95e8\u7684\u68c0\u7d22\u5668\u5e73\u8861\u8bed\u4e49\u5339\u914d\u4e0e\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u4ee5\u6536\u96c6\u8fde\u7eed\u7684\u8bc1\u636e\u96c6\u3002\u540c\u65f6\uff0c\u5f15\u5165ADQAB\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728ADQAB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u672c\u6587\u65b9\u6cd5\u5728\u56de\u7b54\u51c6\u786e\u6027\u65b9\u9762\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u8d85\u8d8a\u6807\u51c6RAG\u5b9e\u73b013%\u81f327%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aRAG\u7cfb\u7edf\u5b9e\u73b0\u590d\u6742\u3001\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u6240\u9700\u7684\u7ec6\u81f4\u3001\u6f14\u8fdb\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2507.23342", "pdf": "https://arxiv.org/pdf/2507.23342", "abs": "https://arxiv.org/abs/2507.23342", "authors": ["Laura Acosta Garc\u00eda", "Juan Aznar Poveda", "Fabian Margreiter", "Antonio-Javier Garc\u00eda S\u00e1nchez", "Joan Garc\u00eda Haro", "Thomas Fahringer", "Jos\u00e9 Lorente L\u00f3pez", "Jos\u00e9-V\u00edctor Rodr\u00edguez"], "title": "FAST-LoRa: An Efficient Simulation Framework for Evaluating LoRaWAN Networks and Transmission Parameter Strategies", "categories": ["cs.NI", "cs.ET"], "comment": null, "summary": "The Internet of Things (IoT) has transformed many industries, and LoRaWAN\n(Long Range Wide Area Network), built on LoRa (Long Range) technology, has\nbecome a crucial solution for enabling scalable, low-cost, and energy-efficient\ncommunication in wide-area networks. Simulation tools are essential for\noptimizing the transmission parameters and, therefore, the energy efficiency\nand performance of LoRaWAN networks. While existing simulation frameworks\naccurately replicate real-world scenarios by including multiple layers of\ncommunication protocols, they often imply significant computational overhead\nand simulation times. To address this issue, this paper introduces FAST-LoRa, a\nnovel simulation framework designed to enable fast and efficient evaluation of\nLoRaWAN networks and selection of transmission parameters. FAST-LoRa\nstreamlines computation by relying on analytical models without complex\npacket-level simulations and implementing gateway reception using efficient\nmatrix operations. Rather than aiming to replace discrete-event simulators,\nFAST-LoRa is intended as a lightweight and accurate approximation tool for\nevaluating transmission parameter strategies in scenarios with stable traffic\npatterns and uplink-focused communications. In our evaluation, we compare\nFAST-LoRa with a well-established simulator using multiple network\nconfigurations with varying numbers of end devices and gateways. The results\nshow that FAST-LoRa achieves similar accuracy in estimating key network\nmetrics, even in complex scenarios with interference and multi-gateway\nreception, with a Mean Absolute Error (MAE) of 0.940 $\\times 10^{-2}$ for the\nPacket Delivery Ratio (PDR) and 0.040 bits/mJ for Energy Efficiency (EE), while\nsignificantly reducing computational time by up to three orders of magnitude.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FAST-LoRa\uff0c\u4e00\u4e2a\u7528\u4e8eLoRaWAN\u7f51\u7edc\u7684\u5feb\u901f\u9ad8\u6548\u6a21\u62df\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5206\u6790\u6a21\u578b\u548c\u9ad8\u6548\u77e9\u9635\u8fd0\u7b97\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u62df\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u73b0\u6709\u6a21\u62df\u5668\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709LoRaWAN\u7f51\u7edc\u6a21\u62df\u6846\u67b6\u867d\u7136\u80fd\u51c6\u786e\u590d\u5236\u771f\u5b9e\u573a\u666f\uff0c\u4f46\u901a\u5e38\u5e26\u6765\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u6a21\u62df\u65f6\u95f4\uff0c\u8fd9\u963b\u788d\u4e86\u4f20\u8f93\u53c2\u6570\u7684\u4f18\u5316\u548c\u80fd\u6548\u63d0\u5347\u3002", "method": "FAST-LoRa\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6a21\u62df\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u4f9d\u8d56\u5206\u6790\u6a21\u578b\u800c\u975e\u590d\u6742\u7684\u5305\u7ea7\u6a21\u62df\u6765\u7b80\u5316\u8ba1\u7b97\uff0c\u5e76\u5229\u7528\u9ad8\u6548\u7684\u77e9\u9635\u8fd0\u7b97\u5b9e\u73b0\u7f51\u5173\u63a5\u6536\u3002\u5b83\u65e8\u5728\u4f5c\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4e14\u51c6\u786e\u7684\u8fd1\u4f3c\u5de5\u5177\uff0c\u7528\u4e8e\u8bc4\u4f30\u7a33\u5b9a\u6d41\u91cf\u6a21\u5f0f\u548c\u4e0a\u884c\u901a\u4fe1\u573a\u666f\u4e0b\u7684\u4f20\u8f93\u53c2\u6570\u7b56\u7565\u3002", "result": "FAST-LoRa\u5728\u4f30\u8ba1\u5173\u952e\u7f51\u7edc\u6307\u6807\u65b9\u9762\uff08\u5982PDR\u548cEE\uff09\u4e0e\u6210\u719f\u6a21\u62df\u5668\u8fbe\u5230\u4e86\u76f8\u4f3c\u7684\u7cbe\u5ea6\uff0cPDR\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee(MAE)\u4e3a0.940 $\times 10^{-2}$\uff0c\u80fd\u6548(EE)\u7684MAE\u4e3a0.040 bits/mJ\uff0c\u540c\u65f6\u5c06\u8ba1\u7b97\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u4e86\u9ad8\u8fbe\u4e09\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "FAST-LoRa\u662f\u4e00\u4e2a\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u8fd1\u4f3c\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u8bc4\u4f30LoRaWAN\u7f51\u7edc\u6027\u80fd\u548c\u9009\u62e9\u4f20\u8f93\u53c2\u6570\uff0c\u5c24\u5176\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u6216\u9700\u8981\u5feb\u901f\u8fed\u4ee3\u6d4b\u8bd5\u7684\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2507.23091", "pdf": "https://arxiv.org/pdf/2507.23091", "abs": "https://arxiv.org/abs/2507.23091", "authors": ["David Noever", "Forrest McKee"], "title": "Moravec's Paradox: Towards an Auditory Turing Test", "categories": ["cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems.", "AI": {"tldr": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u4eba\u7c7b\u8f7b\u6613\u5b8c\u6210\u7684\u542c\u89c9\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u707e\u96be\u6027\u5931\u8d25\uff0c\u8be5\u7814\u7a76\u901a\u8fc7\u4e00\u9879\u542c\u89c9\u56fe\u7075\u6d4b\u8bd5\u91cf\u5316\u4e86\u4eba\u673a\u542c\u89c9\u5dee\u8ddd\uff0c\u5e76\u6307\u51faAI\u9700\u5728\u9009\u62e9\u6027\u6ce8\u610f\u3001\u566a\u97f3\u9c81\u68d2\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5e94\u65b9\u9762\u53d6\u5f97\u7a81\u7834\u3002", "motivation": "\u53d7\u83ab\u62c9\u7ef4\u514b\u6096\u8bba\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u8bc1\u660e\u5f53\u524dAI\u7cfb\u7edf\u5728\u4eba\u7c7b\u8f7b\u677e\u5b8c\u6210\u7684\u542c\u89c9\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u91cf\u5316\u4eba\u673a\u542c\u89c9\u5dee\u8ddd\uff0c\u5e76\u8bca\u65ad\u5931\u8d25\u539f\u56e0\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b917\u4e2a\u6311\u6218\u7684\u201c\u542c\u89c9\u56fe\u7075\u6d4b\u8bd5\u201d\uff0c\u6db5\u76d6\u4e03\u7c7b\u4efb\u52a1\uff08\u5982\u91cd\u53e0\u8bed\u97f3\u3001\u566a\u97f3\u4e2d\u8bed\u97f3\u3001\u7a7a\u95f4\u97f3\u9891\u7b49\uff09\uff0c\u5e76\u8bc4\u4f30\u4e86\u5305\u62ecGPT-4\u548cOpenAI Whisper\u5728\u5185\u7684\u6700\u65b0\u97f3\u9891\u6a21\u578b\u3002", "result": "\u6700\u65b0\u7684AI\u6a21\u578b\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u5931\u8d25\u7387\uff08\u8d85\u8fc793%\uff09\uff0c\u5373\u4f7f\u662f\u6027\u80fd\u6700\u597d\u7684\u6a21\u578b\u4e5f\u4ec5\u53d6\u5f976.9%\u7684\u51c6\u786e\u7387\uff0c\u800c\u4eba\u7c7b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\u4e3a52%\u3002\u7ed3\u679c\u8868\u660eAI\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u542c\u89c9\u573a\u666f\u65f6\u5b58\u5728\u201c\u805a\u7126\u5931\u8d25\u201d\uff0c\u5c24\u5176\u662f\u5728\u9009\u62e9\u6027\u6ce8\u610f\u3001\u566a\u97f3\u9c81\u68d2\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5e94\u65b9\u9762\u3002", "conclusion": "\u5f53\u524dAI\u67b6\u6784\u7f3a\u4e4f\u7c7b\u4eba\u542c\u89c9\u573a\u666f\u5206\u6790\u7684\u57fa\u7840\u673a\u5236\u3002\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u8861\u91cf\u673a\u5668\u542c\u89c9\u8fdb\u6b65\u7684\u8bca\u65ad\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u6574\u5408\u9009\u62e9\u6027\u6ce8\u610f\u3001\u57fa\u4e8e\u7269\u7406\u7684\u97f3\u9891\u7406\u89e3\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7b49\u65b0\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u4eba\u7c7b\u6c34\u5e73\u7684\u673a\u5668\u542c\u89c9\u3002"}}
{"id": "2507.22962", "pdf": "https://arxiv.org/pdf/2507.22962", "abs": "https://arxiv.org/abs/2507.22962", "authors": ["Boyuan Zheng", "Victor W. Chu"], "title": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations", "categories": ["cs.LG"], "comment": "Pre-print v0.8 2025-07-30", "summary": "Climate extremes present escalating risks to agriculture intensifying the\nneed for reliable multi-hazard early warning systems (EWS). The situation is\nevolving due to climate change and hence such systems should have the\nintelligent to continue to learn from recent climate behaviours. However,\ntraditional single-hazard forecasting methods fall short in capturing complex\ninteractions among concurrent climatic events. To address this deficiency, in\nthis paper, we combine sequential deep learning models and advanced Explainable\nArtificial Intelligence (XAI) techniques to introduce a multi-hazard\nforecasting framework for agriculture. In our experiments, we utilize\nmeteorological data from four prominent agricultural regions in the United\nStates (between 2010 and 2023) to validate the predictive accuracy of our\nframework on multiple severe event types, which are extreme cold, floods,\nfrost, hail, heatwaves, and heavy rainfall, with tailored models for each area.\nThe framework uniquely integrates attention mechanisms with TimeSHAP (a\nrecurrent XAI explainer for time series) to provide comprehensive temporal\nexplanations revealing not only which climatic features are influential but\nprecisely when their impacts occur. Our results demonstrate strong predictive\naccuracy, particularly with the BiLSTM architecture, and highlight the system's\ncapacity to inform nuanced, proactive risk management strategies. This research\nsignificantly advances the explainability and applicability of multi-hazard\nEWS, fostering interdisciplinary trust and effective decision-making process\nfor climate risk management in the agricultural industry.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u53ef\u89e3\u91caAI\u7684\u591a\u707e\u5bb3\u9884\u6d4b\u6846\u67b6\uff0c\u4e3a\u519c\u4e1a\u63d0\u4f9b\u65e9\u671f\u9884\u8b66\uff0c\u5e76\u80fd\u89e3\u91ca\u6c14\u5019\u7279\u5f81\u7684\u5f71\u54cd\u65f6\u95f4\u548c\u5f3a\u5ea6\u3002", "motivation": "\u6c14\u5019\u6781\u7aef\u4e8b\u4ef6\u5bf9\u519c\u4e1a\u98ce\u9669\u65e5\u76ca\u589e\u52a0\uff0c\u4f20\u7edf\u5355\u707e\u5bb3\u9884\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u5e76\u53d1\u6c14\u5019\u4e8b\u4ef6\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u4e14\u73b0\u6709\u7cfb\u7edf\u9700\u8981\u5177\u5907\u4ece\u8fd1\u671f\u6c14\u5019\u884c\u4e3a\u4e2d\u6301\u7eed\u5b66\u4e60\u7684\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662fBiLSTM\u67b6\u6784\uff09\u548c\u5148\u8fdb\u7684\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u6280\u672f\uff08\u5982TimeSHAP\uff09\uff0c\u6784\u5efa\u4e00\u4e2a\u519c\u4e1a\u591a\u707e\u5bb3\u9884\u6d4b\u6846\u67b6\u3002\u8be5\u6846\u67b6\u6574\u5408\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u4f7f\u75282010\u5e74\u81f32023\u5e74\u7f8e\u56fd\u56db\u4e2a\u519c\u4e1a\u533a\u6c14\u8c61\u6570\u636e\uff0c\u9488\u5bf9\u6781\u7aef\u5bd2\u51b7\u3001\u6d2a\u6c34\u3001\u971c\u51bb\u3001\u51b0\u96f9\u3001\u70ed\u6d6a\u548c\u5f3a\u964d\u96e8\u7b49\u591a\u79cd\u4e25\u91cd\u4e8b\u4ef6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u533a\u57df\u5b9a\u5236\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\uff08\u7279\u522b\u662fBiLSTM\u67b6\u6784\uff09\u5177\u6709\u5f3a\u5927\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u63d0\u4f9b\u5168\u9762\u7684\u65f6\u95f4\u89e3\u91ca\uff0c\u63ed\u793a\u54ea\u4e9b\u6c14\u5019\u7279\u5f81\u5177\u6709\u5f71\u54cd\u529b\u4ee5\u53ca\u5f71\u54cd\u53d1\u751f\u7684\u786e\u5207\u65f6\u95f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u663e\u8457\u63d0\u5347\u4e86\u591a\u707e\u5bb3\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u7528\u6027\uff0c\u4fc3\u8fdb\u4e86\u8de8\u5b66\u79d1\u4fe1\u4efb\u548c\u519c\u4e1a\u6c14\u5019\u98ce\u9669\u7ba1\u7406\u7684\u6709\u6548\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2507.23027", "pdf": "https://arxiv.org/pdf/2507.23027", "abs": "https://arxiv.org/abs/2507.23027", "authors": ["Krishan Agyakari Raja Babu", "Om Prabhu", "Annu", "Mohanasankar Sivaprakasam"], "title": "Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at the MICCAI Workshop on \"Medical Image Computing in\n  Resource Constrained Settings & Knowledge Interchange (MIRASOL)\" 2025", "summary": "Automated cardiac interpretation in resource-constrained settings (RCS) is\noften hindered by poor-quality echocardiographic imaging, limiting the\neffectiveness of downstream diagnostic models. While super-resolution (SR)\ntechniques have shown promise in enhancing magnetic resonance imaging (MRI) and\ncomputed tomography (CT) scans, their application to echocardiography-a widely\naccessible but noise-prone modality-remains underexplored. In this work, we\ninvestigate the potential of deep learning-based SR to improve classification\naccuracy on low-quality 2D echocardiograms. Using the publicly available CAMUS\ndataset, we stratify samples by image quality and evaluate two clinically\nrelevant tasks of varying complexity: a relatively simple Two-Chamber vs.\nFour-Chamber (2CH vs. 4CH) view classification and a more complex End-Diastole\nvs. End-Systole (ED vs. ES) phase classification. We apply two widely used SR\nmodels-Super-Resolution Generative Adversarial Network (SRGAN) and\nSuper-Resolution Residual Network (SRResNet), to enhance poor-quality images\nand observe significant gains in performance metric-particularly with SRResNet,\nwhich also offers computational efficiency. Our findings demonstrate that SR\ncan effectively recover diagnostic value in degraded echo scans, making it a\nviable tool for AI-assisted care in RCS, achieving more with less.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u6df1\u5ea6\u5b66\u4e60\u8d85\u5206\u8fa8\u7387\uff08SR\uff09\u6280\u672f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u6539\u5584\u4f4e\u8d28\u91cf\u8d85\u58f0\u5fc3\u52a8\u56fe\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5206\u7c7b\u51c6\u786e\u6027\u7684\u6f5c\u529b\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\uff0c\u8d85\u58f0\u5fc3\u52a8\u56fe\u56fe\u50cf\u8d28\u91cf\u5dee\u963b\u788d\u4e86\u81ea\u52a8\u5fc3\u810f\u5224\u8bfb\u7684\u6709\u6548\u6027\u3002\u5c3d\u7ba1\u8d85\u5206\u8fa8\u7387\u6280\u672f\u5728MRI\u548cCT\u4e2d\u663e\u793a\u51fa\u524d\u666f\uff0c\u4f46\u5728\u6613\u53d7\u566a\u58f0\u5f71\u54cd\u7684\u8d85\u58f0\u5fc3\u52a8\u56fe\u4e0a\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u516c\u5f00\u7684CAMUS\u6570\u636e\u96c6\uff0c\u6839\u636e\u56fe\u50cf\u8d28\u91cf\u5bf9\u6837\u672c\u8fdb\u884c\u5206\u5c42\u3002\u8bc4\u4f30\u4e86\u4e24\u79cd\u4e34\u5e8a\u76f8\u5173\u4efb\u52a1\uff1a\u4e8c\u8154\u89c6\u56fe\uff082CH\uff09\u4e0e\u56db\u8154\u89c6\u56fe\uff084CH\uff09\u5206\u7c7b\uff0c\u4ee5\u53ca\u8212\u5f20\u672b\u671f\uff08ED\uff09\u4e0e\u6536\u7f29\u672b\u671f\uff08ES\uff09\u76f8\u5206\u7c7b\u3002\u5e94\u7528\u4e86\u4e24\u79cd\u8d85\u5206\u8fa8\u7387\u6a21\u578b\u2014\u2014SRGAN\u548cSRResNet\uff0c\u4ee5\u589e\u5f3a\u4f4e\u8d28\u91cf\u56fe\u50cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8d85\u5206\u8fa8\u7387\u6280\u672f\uff08\u7279\u522b\u662fSRResNet\uff09\u80fd\u663e\u8457\u63d0\u9ad8\u6027\u80fd\u6307\u6807\u3002SRResNet\u8fd8\u5177\u6709\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8d85\u5206\u8fa8\u7387\u6280\u672f\u80fd\u6709\u6548\u6062\u590d\u9000\u5316\u8d85\u58f0\u5fc3\u52a8\u56fe\u7684\u8bca\u65ad\u4ef7\u503c\uff0c\u4f7f\u5176\u6210\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2dAI\u8f85\u52a9\u533b\u7597\u7684\u53ef\u884c\u5de5\u5177\uff0c\u5b9e\u73b0\u201c\u5c11\u800c\u7cbe\u201d\u7684\u6548\u679c\u3002"}}
{"id": "2507.22918", "pdf": "https://arxiv.org/pdf/2507.22918", "abs": "https://arxiv.org/abs/2507.22918", "authors": ["Daniel Son", "Sanjana Rathore", "Andrew Rufail", "Adrian Simon", "Daniel Zhang", "Soham Dave", "Cole Blondin", "Kevin Zhu", "Sean O'Brien"], "title": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.6; I.2.7"], "comment": "Submitted to ACL 2025 Student Research Workshop (poster)", "summary": "We investigate feature universality in Gemma-2 language models (Gemma-2-2B\nand Gemma-2-9B), asking whether models with a four-fold difference in scale\nstill converge on comparable internal concepts. Using the Sparse Autoencoder\n(SAE) dictionary-learning pipeline, we utilize SAEs on each model's\nresidual-stream activations, align the resulting monosemantic features via\nactivation correlation, and compare the matched feature spaces with SVCCA and\nRSA. Middle layers yield the strongest overlap, while early and late layers\nshow far less similarity. Preliminary experiments extend the analysis from\nsingle tokens to multi-token subspaces, showing that semantically similar\nsubspaces interact similarly with language models. These results strengthen the\ncase that large language models carve the world into broadly similar,\ninterpretable features despite size differences, reinforcing universality as a\nfoundation for cross-model interpretability.", "AI": {"tldr": "\u7814\u7a76Gemma-2\u7cfb\u5217\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\uff08Gemma-2-2B\u548cGemma-2-9B\uff09\u7684\u7279\u5f81\u901a\u7528\u6027\uff0c\u53d1\u73b0\u4e2d\u95f4\u5c42\u7279\u5f81\u91cd\u53e0\u5ea6\u6700\u9ad8\uff0c\u652f\u6301\u8de8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7814\u7a76Gemma-2\u8bed\u8a00\u6a21\u578b\uff08Gemma-2-2B\u548cGemma-2-9B\uff09\u7684\u7279\u5f81\u901a\u7528\u6027\uff0c\u63a2\u8ba8\u89c4\u6a21\u76f8\u5dee\u56db\u500d\u7684\u6a21\u578b\u662f\u5426\u4ecd\u80fd\u6536\u655b\u4e8e\u76f8\u4f3c\u7684\u5185\u90e8\u6982\u5ff5\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5b57\u5178\u5b66\u4e60\u6d41\u7a0b\u5904\u7406\u6a21\u578b\u7684\u6b8b\u5dee\u6d41\u6fc0\u6d3b\uff0c\u901a\u8fc7\u6fc0\u6d3b\u76f8\u5173\u6027\u5bf9\u5355\u8bed\u4e49\u7279\u5f81\u8fdb\u884c\u5bf9\u9f50\uff0c\u5e76\u4f7f\u7528SVCCA\u548cRSA\u6bd4\u8f83\u5339\u914d\u7684\u7279\u5f81\u7a7a\u95f4\u3002\u521d\u6b65\u5b9e\u9a8c\u8fd8\u5c06\u5206\u6790\u6269\u5c55\u5230\u591a\u4ee4\u724c\u5b50\u7a7a\u95f4\u3002", "result": "\u4e2d\u95f4\u5c42\u4ea7\u751f\u4e86\u6700\u5f3a\u7684\u7279\u5f81\u91cd\u53e0\uff0c\u800c\u65e9\u671f\u548c\u665a\u671f\u5c42\u663e\u793a\u51fa\u8f83\u5c11\u7684\u76f8\u4f3c\u6027\u3002\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u4e49\u76f8\u4f3c\u7684\u591a\u4ee4\u724c\u5b50\u7a7a\u95f4\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u4e92\u65b9\u5f0f\u4e5f\u76f8\u4f3c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u5316\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5373\u4fbf\u89c4\u6a21\u4e0d\u540c\u4e5f\u80fd\u5b66\u4e60\u5230\u5e7f\u6cdb\u76f8\u4f3c\u4e14\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u89c2\u70b9\uff0c\u4ece\u800c\u5de9\u56fa\u4e86\u901a\u7528\u6027\u4f5c\u4e3a\u8de8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u57fa\u7840\u7684\u5730\u4f4d\u3002"}}
{"id": "2507.23421", "pdf": "https://arxiv.org/pdf/2507.23421", "abs": "https://arxiv.org/abs/2507.23421", "authors": ["Sara Cavallero", "Fabio Saggese", "Junya Shiraishi", "Israel Leyva-Mayorga", "Shashi Raj Pandey", "Chiara Buratti", "Petar Popovski"], "title": "Dual-Mode Wireless Devices for Adaptive Pull and Push-Based Communication", "categories": ["cs.NI"], "comment": "Submitted to IEEE Transactions on Communications, Copyright might be\n  transferred without notice", "summary": "This paper introduces a dual-mode communication framework for wireless\ndevices that integrates query-driven (pull) and event-driven (push)\ntransmissions within a unified time-frame structure. Devices typically respond\nto information requests in pull mode, but if an anomaly is detected, they\npreempt the regular response to report the critical condition. Additionally,\npush-based communication is used to proactively send critical data without\nwaiting for a request. This adaptive approach ensures timely, context-aware,\nand efficient data delivery across different network conditions. To achieve\nhigh energy efficiency, we incorporate a wake-up radio mechanism and we design\na tailored medium access control (MAC) protocol that supports data traffic\nbelonging to the different communication classes. A comprehensive system-level\nanalysis is conducted, accounting for the wake-up control operation and\nevaluating three key performance metrics: the success probability of anomaly\nreports (push traffic), the success probability of query responses (pull\ntraffic) and the total energy consumption. Numerical results characterize the\nsystem's behavior and highlight the inherent trade-off in success probabilities\nbetween push- and pull-based traffic as a function of allocated communication\nresources. Our analysis demonstrates that the proposed approach reduces energy\nconsumption by up to 30% compared to a traditional approach, while maintaining\nreliable support for both communication paradigms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65e0\u7ebf\u8bbe\u5907\u7684\u53cc\u6a21\u901a\u4fe1\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u67e5\u8be2\u9a71\u52a8\uff08\u62c9\u53d6\uff09\u548c\u4e8b\u4ef6\u9a71\u52a8\uff08\u63a8\u9001\uff09\u4f20\u8f93\uff0c\u5e76\u4f18\u5316\u4e86\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u65e0\u7ebf\u901a\u4fe1\u9700\u8981\u517c\u987e\u53ca\u65f6\u3001\u60c5\u5883\u611f\u77e5\u548c\u9ad8\u6548\u7684\u6570\u636e\u4f20\u8f93\u3002\u7279\u522b\u662f\u5728\u5f02\u5e38\u60c5\u51b5\u62a5\u544a\u548c\u65e5\u5e38\u6570\u636e\u8bf7\u6c42\u4e4b\u95f4\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u4e14\u8282\u80fd\u7684\u901a\u4fe1\u673a\u5236\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u7edf\u4e00\u65f6\u5e27\u7ed3\u6784\u7684\u53cc\u6a21\u901a\u4fe1\u6846\u67b6\uff0c\u5141\u8bb8\u8bbe\u5907\u5728\u5f02\u5e38\u65f6\u63a8\u9001\u5173\u952e\u6570\u636e\uff0c\u5e73\u65f6\u54cd\u5e94\u62c9\u53d6\u8bf7\u6c42\u3002\u91c7\u7528\u5524\u9192\u65e0\u7ebf\u7535\u673a\u5236\u548c\u5b9a\u5236\u7684MAC\u534f\u8bae\u6765\u63d0\u9ad8\u80fd\u6548\uff0c\u5e76\u5bf9\u5f02\u5e38\u62a5\u544a\u6210\u529f\u7387\u3001\u67e5\u8be2\u54cd\u5e94\u6210\u529f\u7387\u548c\u603b\u80fd\u8017\u8fdb\u884c\u4e86\u7cfb\u7edf\u7ea7\u5206\u6790\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u63a8\u9001\u548c\u62c9\u53d6\u6d41\u91cf\u7684\u6210\u529f\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u4e24\u79cd\u901a\u4fe1\u8303\u5f0f\u53ef\u9760\u652f\u6301\u7684\u540c\u65f6\uff0c\u80fd\u8017\u964d\u4f4e\u4e86\u9ad8\u8fbe30%\u3002", "conclusion": "\u8be5\u53cc\u6a21\u901a\u4fe1\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u7ed3\u5408\u62c9\u53d6\u548c\u63a8\u9001\u6a21\u5f0f\uff0c\u5e76\u7ed3\u5408\u5524\u9192\u65e0\u7ebf\u7535\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65e0\u7ebf\u8bbe\u5907\u7684\u80fd\u6548\uff0c\u540c\u65f6\u6709\u6548\u652f\u6301\u4e86\u5173\u952e\u5f02\u5e38\u62a5\u544a\u548c\u5e38\u89c4\u6570\u636e\u8bf7\u6c42\u3002"}}
{"id": "2507.23163", "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "categories": ["cs.AI", "I.2.7"], "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "AI": {"tldr": "\u672c\u6587\u5b9a\u4e49\u5e76\u8bc4\u4f30\u4e86\u5224\u65ad\u6027\u9884\u6d4b\u4e2d\u7684\u201c\u8bba\u8bc1\u8fde\u8d2f\u6027\u201d\uff0c\u53d1\u73b0\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u9884\u6d4b\u80fd\u63d0\u9ad8\u4eba\u7c7b\u548cLLM\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4eba\u7c7b\u7528\u6237\u5e38\u4e0d\u9075\u5faa\u6b64\u7279\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f15\u5165\u673a\u5236\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u610f\u89c1\u3002", "motivation": "\u5224\u65ad\u6027\u9884\u6d4b\u4f9d\u8d56\u4eba\u7c7b\u610f\u89c1\uff0c\u5f53\u8fd9\u4e9b\u610f\u89c1\u5f62\u6210\u8bba\u8bc1\u7ed3\u6784\u65f6\uff0c\u7814\u7a76\u5176\u8bba\u8bc1\u5c5e\u6027\u5341\u5206\u6709\u76ca\u3002\u672c\u7814\u7a76\u65e8\u5728\u6b63\u5f0f\u5b9a\u4e49\u5e76\u8bc4\u4f30\u201c\u8bba\u8bc1\u8fde\u8d2f\u6027\u201d\u8fd9\u4e00\u7279\u6027\uff0c\u5373\u9884\u6d4b\u8005\u7684\u63a8\u7406\u5e94\u4e0e\u5176\u9884\u6d4b\u7ed3\u679c\u4fdd\u6301\u4e00\u81f4\uff0c\u4ee5\u671f\u63d0\u5347\u9884\u6d4b\u8d28\u91cf\u3002", "method": "\u7814\u7a76\u9996\u5148\u6b63\u5f0f\u5b9a\u4e49\u4e86\u201c\u8bba\u8bc1\u8fde\u8d2f\u6027\u201d\u3002\u968f\u540e\u8fdb\u884c\u4e86\u591a\u9879\u8bc4\u4f30\uff1a\u9996\u5148\uff0c\u8bc4\u4f30\u4e86\u5f3a\u5236\u6267\u884c\u8fde\u8d2f\u6027\u5bf9\u4eba\u7c7b\u9884\u6d4b\u8005\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9884\u6d4b\u8005\u7684\u5f71\u54cd\uff1b\u5176\u6b21\uff0c\u901a\u8fc7\u4f17\u5305\u7528\u6237\u5b9e\u9a8c\uff0c\u8003\u5bdf\u4e86\u7528\u6237\u5bf9\u8be5\u8fde\u8d2f\u6027\u7279\u6027\u7684\u7b26\u5408\u7a0b\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u8bba\u5bf9\u4e8e\u4eba\u7c7b\u9884\u6d4b\u8fd8\u662f\u57fa\u4e8eLLM\u7684\u9884\u6d4b\uff0c\u8fc7\u6ee4\u6389\u4e0d\u8fde\u8d2f\u7684\u9884\u6d4b\u80fd\u591f\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd9\u652f\u6301\u4e86\u8fde\u8d2f\u6027\u7684\u5b9e\u9645\u4ef7\u503c\u3002\u7136\u800c\uff0c\u4f17\u5305\u7528\u6237\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1\u8bba\u8bc1\u8fde\u8d2f\u6027\u770b\u4f3c\u76f4\u89c2\u4e14\u6709\u7528\uff0c\u4f46\u7528\u6237\u5728\u5b9e\u8df5\u4e2d\u901a\u5e38\u4e0d\u7b26\u5408\u8fd9\u4e00\u8fde\u8d2f\u6027\u7279\u6027\u3002", "conclusion": "\u8bba\u8bc1\u8fde\u8d2f\u6027\u5728\u5224\u65ad\u6027\u9884\u6d4b\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u6709\u6548\u63d0\u5347\u4eba\u7c7b\u548cLLM\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u9274\u4e8e\u7528\u6237\u666e\u904d\u672a\u80fd\u9075\u5faa\u8fd9\u4e00\u7279\u6027\uff0c\u5728\u57fa\u4e8e\u8bba\u8bc1\u7684\u5224\u65ad\u6027\u9884\u6d4b\u4e2d\uff0c\u6709\u5fc5\u8981\u5f15\u5165\u673a\u5236\u6765\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u7684\u610f\u89c1\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u51c6\u786e\u7684\u7fa4\u4f53\u9884\u6d4b\u7ed3\u679c\u3002"}}
{"id": "2507.22963", "pdf": "https://arxiv.org/pdf/2507.22963", "abs": "https://arxiv.org/abs/2507.22963", "authors": ["Abdelrhman Gaber", "Hassan Abd-Eltawab", "John Elgallab", "Youssif Abuzied", "Dineo Mpanya", "Turgay Celik", "Swarun Kumar", "Tamer ElBatt"], "title": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization", "categories": ["cs.LG", "q-bio.OT"], "comment": null, "summary": "Cardiovascular diseases (CVD) cause over 17 million deaths annually\nworldwide, highlighting the urgent need for privacy-preserving predictive\nsystems. We introduce FedCVD++, an enhanced federated learning (FL) framework\nthat integrates both parametric models (logistic regression, SVM, neural\nnetworks) and non-parametric models (Random Forest, XGBoost) for coronary heart\ndisease risk prediction. To address key FL challenges, we propose: (1)\ntree-subset sampling that reduces Random Forest communication overhead by 70%,\n(2) XGBoost-based feature extraction enabling lightweight federated ensembles,\nand (3) federated SMOTE synchronization for resolving cross-institutional class\nimbalance.\n  Evaluated on the Framingham dataset (4,238 records), FedCVD++ achieves\nstate-of-the-art results: federated XGBoost (F1 = 0.80) surpasses its\ncentralized counterpart (F1 = 0.78), and federated Random Forest (F1 = 0.81)\nmatches non-federated performance. Additionally, our communication-efficient\nstrategies reduce bandwidth consumption by 3.2X while preserving 95% accuracy.\n  Compared to existing FL frameworks, FedCVD++ delivers up to 15% higher\nF1-scores and superior scalability for multi-institutional deployment. This\nwork represents the first practical integration of non-parametric models into\nfederated healthcare systems, providing a privacy-preserving solution validated\nunder real-world clinical constraints.", "AI": {"tldr": "FedCVD++\u662f\u4e00\u4e2a\u589e\u5f3a\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u975e\u53c2\u6570\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\u3001XGBoost\uff09\u5e94\u7528\u4e8e\u5fc3\u8840\u7ba1\u75be\u75c5\u9884\u6d4b\uff0c\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u9884\u6d4bF1\u5206\u6570\u548c\u901a\u4fe1\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u6bcf\u5e74\u5bfc\u81f4\u5168\u7403\u8d85\u8fc71700\u4e07\u4eba\u6b7b\u4ea1\uff0c\u8feb\u5207\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u7684\u9884\u6d4b\u7cfb\u7edf\u3002", "method": "\u5f15\u5165FedCVD++\uff0c\u4e00\u4e2a\u96c6\u6210\u53c2\u6570\u548c\u975e\u53c2\u6570\u6a21\u578b\u7684\u589e\u5f3a\u578b\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u51a0\u5fc3\u75c5\u98ce\u9669\u9884\u6d4b\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1) \u6811\u5b50\u96c6\u62bd\u6837\uff0c\u51cf\u5c11\u968f\u673a\u68ee\u6797\u901a\u4fe1\u5f00\u9500\uff1b2) \u57fa\u4e8eXGBoost\u7684\u7279\u5f81\u63d0\u53d6\uff0c\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u8054\u90a6\u96c6\u6210\uff1b3) \u8054\u90a6SMOTE\u540c\u6b65\uff0c\u89e3\u51b3\u8de8\u673a\u6784\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u5728Framingham\u6570\u636e\u96c6\u4e0a\uff0cFedCVD++\u8868\u73b0\u5353\u8d8a\uff1a\u8054\u90a6XGBoost (F1=0.80) \u8d85\u8d8a\u96c6\u4e2d\u5f0f(F1=0.78)\uff0c\u8054\u90a6\u968f\u673a\u68ee\u6797(F1=0.81) \u4e0e\u975e\u8054\u90a6\u6027\u80fd\u76f8\u5f53\u3002\u901a\u4fe1\u6548\u7387\u7b56\u7565\u5728\u4fdd\u630195%\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5e26\u5bbd\u6d88\u8017\u51cf\u5c113.2\u500d\u3002\u4e0e\u73b0\u6709FL\u6846\u67b6\u76f8\u6bd4\uff0cF1\u5206\u6570\u6700\u9ad8\u63d0\u9ad815%\uff0c\u5e76\u5177\u6709\u66f4\u4f18\u7684\u591a\u673a\u6784\u90e8\u7f72\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5c06\u975e\u53c2\u6570\u6a21\u578b\u5b9e\u9645\u96c6\u6210\u5230\u8054\u90a6\u533b\u7597\u7cfb\u7edf\u4e2d\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u771f\u5b9e\u4e34\u5e8a\u7ea6\u675f\u4e0b\u9a8c\u8bc1\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.23033", "pdf": "https://arxiv.org/pdf/2507.23033", "abs": "https://arxiv.org/abs/2507.23033", "authors": ["Ranxi Lin", "Canming Yao", "Jiayi Li", "Weihang Liu", "Xin Lou", "Pingqiang Zhou"], "title": "Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields", "categories": ["cs.CV", "cs.NE"], "comment": null, "summary": "Neural Radiance Fields (NeRF)-based models have achieved remarkable success\nin 3D reconstruction and rendering tasks. However, during both training and\ninference, these models rely heavily on dense point sampling along rays from\nmultiple viewpoints, resulting in a surge in floating-point operations and\nseverely limiting their use in resource-constrained scenarios like edge\ncomputing. Spiking Neural Networks (SNNs), which communicate via binary spikes\nover discrete time steps, offer a promising alternative due to their\nenergy-efficient nature. Given the inherent variability in scene scale and\ntexture complexity in neural rendering and the prevailing practice of training\nseparate models per scene, we propose a spike-based NeRF framework with a\ndynamic time step training strategy, termed Pretrain-Adaptive Time-step\nAdjustment (PATA). This approach automatically explores the trade-off between\nrendering quality and time step length during training. Consequently, it\nenables scene-adaptive inference with variable time steps and reduces the\nadditional consumption of computational resources in the inference process.\nAnchoring to the established Instant-NGP architecture, we evaluate our method\nacross diverse datasets. The experimental results show that PATA can preserve\nrendering fidelity while reducing inference time steps by 64\\% and running\npower by 61.55\\%.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSNN\u7684NeRF\u6846\u67b6PATA\uff0c\u901a\u8fc7\u52a8\u6001\u65f6\u95f4\u6b65\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u529f\u8017\u548c\u65f6\u95f4\u6b65\uff0c\u540c\u65f6\u4fdd\u6301\u6e32\u67d3\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edfNeRF\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9700\u8981\u5927\u91cf\u6d6e\u70b9\u8fd0\u7b97\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5de8\u5927\uff0c\u9650\u5236\u5176\u5728\u8fb9\u7f18\u8ba1\u7b97\u7b49\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u56e0\u5176\u8282\u80fd\u7279\u6027\uff0c\u6709\u671b\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eSNN\u7684NeRF\u6846\u67b6\uff0c\u540d\u4e3aPretrain-Adaptive Time-step Adjustment (PATA)\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u52a8\u6001\u65f6\u95f4\u6b65\u8bad\u7ec3\u7b56\u7565\uff0c\u81ea\u52a8\u5e73\u8861\u6e32\u67d3\u8d28\u91cf\u548c\u65f6\u95f4\u6b65\u957f\uff0c\u4ece\u800c\u5b9e\u73b0\u573a\u666f\u81ea\u9002\u5e94\u7684\u63a8\u7406\u3002\u8be5\u6846\u67b6\u4ee5Instant-NGP\u67b6\u6784\u4e3a\u57fa\u7840\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPATA\u5728\u4fdd\u6301\u6e32\u67d3\u4fdd\u771f\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u80fd\u591f\u5c06\u63a8\u7406\u65f6\u95f4\u6b65\u51cf\u5c1164%\uff0c\u8fd0\u884c\u529f\u8017\u964d\u4f4e61.55%\u3002", "conclusion": "PATA\u6846\u67b6\u901a\u8fc7\u7ed3\u5408SNN\u548c\u52a8\u6001\u65f6\u95f4\u6b65\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86NeRF\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u9ad8\u8ba1\u7b97\u6d88\u8017\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u76843D\u91cd\u5efa\u548c\u6e32\u67d3\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.22919", "pdf": "https://arxiv.org/pdf/2507.22919", "abs": "https://arxiv.org/abs/2507.22919", "authors": ["Qixuan Hu", "Xumou Zhang", "Jinman Kim", "Florence Bourgeois", "Adam G. Dunn"], "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Objectives: With accurate estimates of expected safety results, clinical\ntrials could be designed to avoid terminations and limit exposing participants\nto unnecessary risks. We evaluated methods for predicting serious adverse event\n(SAE) results in clinical trials using information only from their\nregistrations prior to the trial. Material and Methods: We analysed 22,107\ntwo-arm parallel interventional clinical trials from ClinicalTrials.gov with\nstructured summary results. Two prediction models were developed: a classifier\npredicting will experimental arm have higher SAE rates (area under the receiver\noperating characteristic curve; AUC) than control arm, and a regression model\nto predict the proportion of SAEs in control arms (root mean squared error;\nRMSE). A transfer learning approach using pretrained language models (e.g.,\nClinicalT5, BioBERT) was used for feature extraction, combined with downstream\nmodel for prediction. To maintain semantic representation in long trial texts\nexceeding localised language model input limits, a sliding window method was\ndeveloped for embedding extraction. Results: The best model\n(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a\nhigher proportion of patients with SAEs. When predicting proportion of\nparticipants experiencing SAE in the control arm, the same model achieved RMSE\nof 18.6%. The sliding window approach consistently outperformed methods without\nit. Across 12 classifiers, the average absolute AUC increase was 2.00%; across\n12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:\nSummary results data available at ClinicalTrials.gov remains underutilised. The\npotential to estimate results of trials before they start is an opportunity to\nimprove trial design and flag discrepancies between expected and reported\nsafety results.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548c\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4e34\u5e8a\u8bd5\u9a8c\u6ce8\u518c\u4fe1\u606f\u9884\u6d4b\u8bd5\u9a8c\u524d\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\uff08SAE\uff09\u7684\u53d1\u751f\u7387\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u65e8\u5728\u4f18\u5316\u8bd5\u9a8c\u8bbe\u8ba1\u5e76\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "motivation": "\u4e3a\u4e86\u907f\u514d\u4e34\u5e8a\u8bd5\u9a8c\u63d0\u524d\u7ec8\u6b62\uff0c\u5e76\u9650\u5236\u53c2\u4e0e\u8005\u66b4\u9732\u4e8e\u4e0d\u5fc5\u8981\u7684\u98ce\u9669\u4e2d\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8bd5\u9a8c\u6ce8\u518c\u4fe1\u606f\u51c6\u786e\u4f30\u8ba1\u9884\u671f\u7684\u5b89\u5168\u7ed3\u679c\uff08\u5373\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\uff09\u3002", "method": "\u5206\u6790\u4e86\u6765\u81eaClinicalTrials.gov\u768422,107\u9879\u53cc\u81c2\u5e73\u884c\u5e72\u9884\u6027\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u3002\u5f00\u53d1\u4e86\u4e24\u79cd\u9884\u6d4b\u6a21\u578b\uff1a\u4e00\u4e2a\u5206\u7c7b\u5668\u7528\u4e8e\u9884\u6d4b\u8bd5\u9a8c\u7ec4SAE\u7387\u662f\u5426\u9ad8\u4e8e\u5bf9\u7167\u7ec4\uff0c\u4e00\u4e2a\u56de\u5f52\u6a21\u578b\u7528\u4e8e\u9884\u6d4b\u5bf9\u7167\u7ec4SAE\u7684\u6bd4\u4f8b\u3002\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08\u5982ClinicalT5, BioBERT\uff09\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5e76\u5f00\u53d1\u4e86\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u5904\u7406\u8d85\u51fa\u8f93\u5165\u9650\u5236\u7684\u957f\u6587\u672c\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08ClinicalT5+Transformer+MLP\uff09\u5728\u9884\u6d4b\u54ea\u4e2a\u8bd5\u9a8c\u7ec4\u5177\u6709\u66f4\u9ad8SAE\u60a3\u8005\u6bd4\u4f8b\u65f6\uff0cAUC\u8fbe\u523077.6%\uff1b\u5728\u9884\u6d4b\u5bf9\u7167\u7ec4SAE\u53c2\u4e0e\u8005\u6bd4\u4f8b\u65f6\uff0cRMSE\u4e3a18.6%\u3002\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u8868\u73b0\u6301\u7eed\u4f18\u4e8e\u65e0\u8be5\u65b9\u6cd5\u7684\u6a21\u578b\uff0c\u5206\u7c7b\u5668\u5e73\u5747AUC\u63d0\u53472.00%\uff0c\u56de\u5f52\u5668\u5e73\u5747RMSE\u964d\u4f4e1.58%\u3002", "conclusion": "ClinicalTrials.gov\u4e0a\u53ef\u7528\u7684\u7ed3\u679c\u6458\u8981\u6570\u636e\u4ecd\u672a\u5145\u5206\u5229\u7528\u3002\u5728\u8bd5\u9a8c\u5f00\u59cb\u524d\u4f30\u8ba1\u5176\u7ed3\u679c\u7684\u6f5c\u529b\uff0c\u4e3a\u6539\u5584\u8bd5\u9a8c\u8bbe\u8ba1\u548c\u8bc6\u522b\u9884\u671f\u4e0e\u62a5\u544a\u5b89\u5168\u7ed3\u679c\u4e4b\u95f4\u7684\u5dee\u5f02\u63d0\u4f9b\u4e86\u91cd\u8981\u673a\u4f1a\u3002"}}
