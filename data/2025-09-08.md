<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 9]
- [cs.CV](#cs.CV) [Total: 9]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.NI](#cs.NI) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance](https://arxiv.org/abs/2509.04455)
*Shisong Chen,Qian Zhu,Wenyan Yang,Chengyi Yang,Zhong Wang,Ping Wang,Xuan Lin,Bo Xu,Daqian Li,Chao Yuan,Licai Qi,Wanqing Xu,sun zhenxing,Xin Lu,Shiqiang Xiong,Chao Chen,Haixiang Hu,Yanghua Xiao*

Main category: cs.CL

TL;DR: INSEva是一个专为评估AI系统在保险领域知识和能力而设计的综合性中文基准测试，揭示了当前LLM在该领域的局限性。


<details>
  <summary>Details</summary>
Motivation: 保险作为全球金融系统的关键组成部分，对AI应用的准确性和可靠性要求极高。然而，现有AI基准测试未能充分捕捉保险领域的独特性和特定要求。

Method: 本文提出了INSEva，一个多维度（涵盖业务领域、任务格式、难度级别和认知知识）的中文保险领域基准测试，包含38,704个高质量评估示例，并采用定制化方法评估开放式回答的忠实性和完整性。使用INSEva评估了8个最先进的大型语言模型（LLM）。

Result: 通过评估发现，最先进的大型语言模型在不同维度上表现出显著差异。通用LLM展现了基础的保险领域能力（平均得分超过80分），但在处理复杂、真实世界的保险场景时仍存在显著差距。

Conclusion: INSEva揭示了当前大型语言模型在处理复杂保险场景方面的不足，并为未来AI在保险领域的改进提供了明确方向。该基准测试将很快公开。

Abstract: Insurance, as a critical component of the global financial system, demands
high standards of accuracy and reliability in AI applications. While existing
benchmarks evaluate AI capabilities across various domains, they often fail to
capture the unique characteristics and requirements of the insurance domain. To
address this gap, we present INSEva, a comprehensive Chinese benchmark
specifically designed for evaluating AI systems' knowledge and capabilities in
insurance. INSEva features a multi-dimensional evaluation taxonomy covering
business areas, task formats, difficulty levels, and cognitive-knowledge
dimension, comprising 38,704 high-quality evaluation examples sourced from
authoritative materials. Our benchmark implements tailored evaluation methods
for assessing both faithfulness and completeness in open-ended responses.
Through extensive evaluation of 8 state-of-the-art Large Language Models
(LLMs), we identify significant performance variations across different
dimensions. While general LLMs demonstrate basic insurance domain competency
with average scores above 80, substantial gaps remain in handling complex,
real-world insurance scenarios. The benchmark will be public soon.

</details>


### [2] [Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support](https://arxiv.org/abs/2509.04456)
*Anandi Dutta,Shivani Mruthyunjaya,Jessica Saddington,Kazi Sifatul Islam*

Main category: cs.CL

TL;DR: 开发并评估了一个结合RAG和提示工程的心理健康支持聊天机器人，旨在安全有效地辅助专业医疗。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型带来的机遇与挑战，旨在开发一个安全、有意义且能辅助专业医疗的心理健康支持聊天机器人。

Method: 采用检索增强生成(RAG)框架，集成提示工程，并在新数据集上微调预训练模型；同时进行多维度（准确性、同理心、可信度、隐私、偏见）的严格评估。

Result: 所开发的“Mentalic Net Conversational AI”系统BERT Score达到0.898，其他评估指标也处于满意范围。

Conclusion: 建议在开发此类AI技术时采取“人类在环”和长期负责任的策略，以平衡其巨大潜力与潜在风险。

Abstract: The emergence of large language models (LLMs) has unlocked boundless
possibilities, along with significant challenges. In response, we developed a
mental health support chatbot designed to augment professional healthcare, with
a strong emphasis on safe and meaningful application. Our approach involved
rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and
bias. We employed a retrieval-augmented generation (RAG) framework, integrated
prompt engineering, and fine-tuned a pre-trained model on novel datasets. The
resulting system, Mentalic Net Conversational AI, achieved a BERT Score of
0.898, with other evaluation metrics falling within satisfactory ranges. We
advocate for a human-in-the-loop approach and a long-term, responsible strategy
in developing such transformative technologies, recognizing both their
potential to change lives and the risks they may pose if not carefully managed.

</details>


### [3] [Do MLLMs Really Understand the Charts?](https://arxiv.org/abs/2509.04457)
*Xiao Zhang,Dongyuan Li,Liuyu Xiang,Yao Zhang,Cheng Zhong,Zhaofeng He*

Main category: cs.CL

TL;DR: 现有MLLM在无标注图表上表现出幻觉和性能下降，本研究创建了CRBench基准来评估其视觉推理能力，并提出了ChartReasoner模型。ChartReasoner通过模拟人类行为，显著提升了MLLM的图表理解能力，在CRBench和公共基准上均超越了GPT-4o等领先模型。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在图表理解方面存在严重幻觉和性能下降，尤其是在处理无标注图表时。研究者质疑MLLMs是否真正理解图表，并认为它们主要依赖识别而非推理。

Method: ['建立了综合图表推理基准CRBench，用于严格评估MLLMs在无标注图表上的视觉推理能力。', '提出了ChartReasoner模型，该模型通过模拟人类行为，将图表理解中的估计与推理相结合，以引导MLLMs进行合理的图表理解。']

Result: ['在所提出的CRBench上，ChartReasoner-3B/7B在图表推理方面取得了卓越性能，甚至超越了GPT-4o和Gemini-2.5-Flash。', 'ChartReasoner在公共基准的通用图表理解任务中也展示了出色的视觉推理能力，带来了显著的性能提升，使MLLMs能够更合理地理解图表。']

Conclusion: ChartReasoner通过模拟人类视觉推理，有效解决了MLLMs在无标注图表上的理解不足和幻觉问题，使其能够实现理性的图表理解，并在图表推理任务中达到领先性能。

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
increasingly impressive performance in chart understanding, most of them
exhibit alarming hallucinations and significant performance degradation when
handling non-annotated charts. Therefore, a question arises: Do MLLMs really
understand the charts? Since a human is capable of understanding charts and
estimating the values by visual reasoning, we first carefully establish a
comprehensive Chart Reasoning Benchmark CRBench to rigorously evaluate the
visual reasoning abilities of MLLMs on non-annotated charts. We argue that
MLLMs are primarily relying on recognition rather than reasoning to interpret
the charts. To steer MLLMs to reasonable chart understanding, we propose
ChartReasoner that mimics human behavior by grounding their estimation in chart
understanding. Extensive results on the proposed CRBench show that
ChartReasnoner-3B/7B achieves superior performance in chart reasoning, even
compared to GPT-4o and Gemini-2.5-Flash. More importantly, ChartReasnoner also
demonstrates the visual reasoning abilities in general chart comprehension on
public benchmarks, leading to significant performance gains and enabling MLLMs
to rationally understand the charts. The code and dataset will be publicly
available upon publication.

</details>


### [4] [Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies](https://arxiv.org/abs/2509.04458)
*Daniel B. Hier,Steven Keith Platt,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 大型语言模型在生物医学NLP中链接本体术语到标识符时可能失败。本研究分析失败原因，发现对本体标识符的暴露是链接成功的最强预测因子。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生物医学自然语言处理（NLP）任务中表现良好，但常常无法将本体术语正确链接到其对应的标识符。本研究旨在探究这些失败发生的原因。

Method: 研究人员分析了GPT-4o和LLaMa 3.1 405B这两个高性能模型在Human Phenotype Ontology和Gene Ontology这两个主要本体上的预测结果。他们评估了与术语熟悉度、标识符使用、形态学和本体结构相关的九个候选特征，并进行了单变量和多变量分析。

Result: 单变量和多变量分析结果表明，大型语言模型对本体标识符的暴露程度是其成功链接术语的最强预测因子。

Conclusion: 大型语言模型能否成功将本体术语链接到其正确标识符，主要取决于模型对这些本体标识符的熟悉程度或暴露程度。

Abstract: Large language models often perform well on biomedical NLP tasks but may fail
to link ontology terms to their correct identifiers. We investigate why these
failures occur by analyzing predictions across two major ontologies, Human
Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o
and LLaMa 3.1 405B. We evaluate nine candidate features related to term
familiarity, identifier usage, morphology, and ontology structure. Univariate
and multivariate analyses show that exposure to ontology identifiers is the
strongest predictor of linking success.

</details>


### [5] [Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis](https://arxiv.org/abs/2509.04459)
*Shiqin Han,Manning Gao,Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai*

Main category: cs.CL

TL;DR: 提出不确定性感知协作系统U-ACS，通过级联机制将难样本分配给多模态大语言模型（MLLM），以在多模态情感分析中兼顾MLLM的高性能和小型模型的高效率，大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）计算需求高，阻碍实际部署；小型专业模型效率高但性能差。需要解决性能与效率之间的关键权衡。

Method: 提出不确定性感知协作系统（U-ACS）。核心是不确定性驱动的级联机制：高效小型模型首先快速筛选所有输入样本，仅将高预测不确定性（即难度较大）的样本选择性地转交给强大的MLLM进行更复杂的分析。此外，系统引入高级策略处理模糊或冲突预测，包括同极性预测的加权平均和高不确定性冲突预测的基于提示的交叉验证。

Result: 在基准数据集上实现了最先进的性能。与单独使用MLLM相比，仅需一小部分计算资源，同时保持了MLLM的高准确性，大幅降低了推理成本。

Conclusion: 该研究通过基于样本难度动态分配计算资源，有效解决了多模态大语言模型的性能-效率权衡问题，在实现高准确度的同时显著降低了计算成本。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has significantly
advanced the state-of-the-art in multimodal machine learning, yet their
substantial computational demands present a critical barrier to real-world
deployment. Conversely, smaller, specialized models offer high efficiency but
often at the cost of performance. To reconcile this performance-efficiency
trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS)
that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a
lightweight baseline model for multimodal sentiment analysis. The core of our
system is an uncertainty-driven cascade mechanism, where the efficient small
model first acts as a rapid filter for all input samples. Only those samples
yielding high predictive uncertainty, thereby indicating greater difficulty,
are selectively escalated to the MLLM for more sophisticated analysis.
Furthermore, our system introduces advanced strategies to handle ambiguous or
conflicting predictions, including weighted averaging for predictions of
similar polarity and a prompt-based cross-verification to resolve conflicting
predictions when both models exhibit high uncertainty. This
sample-difficulty-aware approach allows for a dynamic allocation of
computational resources, drastically reducing inference costs while retaining
the high accuracy of MLLM. Extensive experiments on benchmark datasets
demonstrate that our proposed method achieves state-of-the-art performance,
while requiring only a fraction of the computational resources compared to
using a standalone MLLM.

</details>


### [6] [CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection](https://arxiv.org/abs/2509.04460)
*Yihan Chen,Jiawei Chen,Guozhao Mo,Xuanang Chen,Ben He,Xianpei Han,Le Sun*

Main category: cs.CL

TL;DR: 为解决LLMs在同行评审中生成实质内容带来的公平性风险，本文提出CoCoNUTS基准和基于多任务学习的CoCoDet检测器，旨在实现更准确、基于内容的AI评审检测，而非依赖易受攻击的风格特征。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）日益融入同行评审过程，虽有助于语言润色，但其生成实质评审内容的潜在滥用引发担忧，可能损害学术评估的公平性和可靠性。现有AI生成文本检测器依赖风格特征，易受规避攻击，且无法有效区分允许的语言润色与实质性内容生成，导致检测不准确和误判。

Method: 本文提出从基于风格到基于内容的检测范式转变。具体而言，构建了CoCoNUTS，一个内容导向的基准，其建立在包含六种人机协作模式的细粒度AI生成同行评审数据集之上。此外，开发了CoCoDet，一个通过多任务学习框架实现的AI评审检测器，旨在更准确、鲁棒地检测AI在评审内容中的参与。

Result: 本工作提供了CoCoNUTS基准和CoCoDet检测器，为评估LLMs在同行评审中的使用奠定了实践基础，并促进了开发更精确、公平、可靠的AI评审内容检测方法，以应对真实世界中的学术应用需求。

Conclusion: 本工作为同行评审中LLMs的应用评估奠定了实践基础，并有助于推动面向真实学术应用的更精确、公平、可靠的检测方法的发展，从而提升学术评估的公正性和可信度。

Abstract: The growing integration of large language models (LLMs) into the peer review
process presents potential risks to the fairness and reliability of scholarly
evaluation. While LLMs offer valuable assistance for reviewers with language
refinement, there is growing concern over their use to generate substantive
review content. Existing general AI-generated text detectors are vulnerable to
paraphrasing attacks and struggle to distinguish between surface language
refinement and substantial content generation, suggesting that they primarily
rely on stylistic cues. When applied to peer review, this limitation can result
in unfairly suspecting reviews with permissible AI-assisted language
enhancement, while failing to catch deceptively humanized AI-generated reviews.
To address this, we propose a paradigm shift from style-based to content-based
detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark
built upon a fine-grained dataset of AI-generated peer reviews, covering six
distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an
AI review detector via a multi-task learning framework, designed to achieve
more accurate and robust detection of AI involvement in review content. Our
work offers a practical foundation for evaluating the use of LLMs in peer
review, and contributes to the development of more precise, equitable, and
reliable detection methods for real-world scholarly applications. Our code and
data will be publicly available at https://github.com/Y1hanChen/COCONUTS.

</details>


### [7] [From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media](https://arxiv.org/abs/2509.04461)
*Tian Ma,Kaiyu Feng,Yu Rong,Kangfei Zhao*

Main category: cs.CL

TL;DR: 本文提出PtoP框架，一个基于LLM的MBTI预测模型，通过RAG缓解LLM幻觉问题，并使用合成少数类过采样解决类别不平衡，在真实数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）应用于MBTI预测面临两大挑战：LLMs固有的幻觉问题以及MBTI类型在人群中自然存在的不平衡分布。

Method: 提出PostToPersonality (PtoP) 框架，该框架利用检索增强生成（RAG）和上下文学习来缓解LLMs的幻觉；此外，通过合成少数类过采样技术微调预训练LLM，以平衡类别不平衡并提高模型在MBTI理解上的特异性。

Result: 在真实世界的社交媒体数据集上进行的实验表明，PtoP框架与10个机器学习和深度学习基线相比，实现了最先进的（state-of-the-art）性能。

Conclusion: PtoP框架有效解决了LLM在MBTI预测中面临的幻觉和类别不平衡问题，显著提升了社交媒体内容人格预测的准确性和鲁棒性。

Abstract: Personality prediction from social media posts is a critical task that
implies diverse applications in psychology and sociology. The Myers Briggs Type
Indicator (MBTI), a popular personality inventory, has been traditionally
predicted by machine learning (ML) and deep learning (DL) techniques. Recently,
the success of Large Language Models (LLMs) has revealed their huge potential
in understanding and inferring personality traits from social media content.
However, directly exploiting LLMs for MBTI prediction faces two key challenges:
the hallucination problem inherent in LLMs and the naturally imbalanced
distribution of MBTI types in the population. In this paper, we propose
PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from
social media posts of individuals. Specifically, PtoP leverages Retrieval
Augmented Generation with in context learning to mitigate hallucination in
LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification
in MBTI understanding with synthetic minority oversampling, which balances the
class imbalance by generating synthetic samples. Experiments conducted on a
real world social media dataset demonstrate that PtoP achieves state of the art
performance compared with 10 ML and DL baselines.

</details>


### [8] [Benchmarking GPT-5 for biomedical natural language processing](https://arxiv.org/abs/2509.04462)
*Yu Hou,Zaifu Zhan,Rui Zhang*

Main category: cs.CL

TL;DR: 该研究评估了GPT-5和GPT-4o在生物医学NLP任务上的性能，发现GPT-5在整体基准测试中表现最佳，尤其在问答任务上超越了现有SOTA，但在某些特定抽取和摘要任务上仍不及领域专用模型。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的快速增长对可扩展的NLP解决方案提出了更高要求。尽管GPT-4在问答方面取得了显著进展，但在其他生物医学领域性能仍不均衡，需要评估新一代模型（如GPT-5和GPT-4o）的进展。

Method: 研究人员更新了一个标准化的BioNLP基准，在12个数据集、涵盖六个任务家族（命名实体识别、关系抽取、多标签文档分类、问答、文本摘要、文本简化）上，以零、一和五次少样本提示方式评估了GPT-5和GPT-4o。评估采用了固定的提示模板、相同的解码参数和批处理推理，并与GPT-4、GPT-3.5和LLaMA-2-13B的结果进行了比较。

Result: GPT-5取得了最强的整体基准性能，在五次少样本提示下宏观平均分数升至0.557（GPT-4为0.506，GPT-4o为0.508）。在MedQA上，GPT-5达到94.1%的准确率，超越了先前的监督SOTA五十多个百分点，并在PubMedQA上与监督系统持平（0.734）。在抽取任务中，GPT-5在化学NER（0.886 F1）和ChemProt关系抽取（0.616 F1）方面取得了显著提升。然而，摘要和疾病NER任务的表现仍落后于领域专用基线。

Conclusion: GPT-5已成为一个通用模型，在面向推理的生物医学问答任务上提供了可部署的性能。但对于精度关键的抽取和证据密集型摘要任务，精调或混合方法仍然更具优势。该基准为BioNLP系统设计提供了指导，明确了简单提示足以应对的场景以及可能需要检索增强或规划型支架的场景。

Abstract: The rapid expansion of biomedical literature has heightened the need for
scalable natural language processing (NLP) solutions. While GPT-4 substantially
narrowed the gap with task-specific systems, especially in question answering,
its performance across other domains remained uneven. We updated a standardized
BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot
prompting across 12 datasets spanning six task families: named entity
recognition, relation extraction, multi-label document classification, question
answering, text summarization, and text simplification. Using fixed prompt
templates, identical decoding parameters, and batch inference, we report
primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and
LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark
performance, with macro-average scores rising to 0.557 under five-shot
prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached
94.1% accuracy, exceeding the previous supervised state of the art by over
fifty points, and attained parity with supervised systems on PubMedQA (0.734).
In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and
ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though
summarization and disease NER still lagged behind domain-specific baselines.
These results establish GPT-5 as a general-purpose model now offering
deployment-ready performance for reasoning-oriented biomedical QA, while
precision-critical extraction and evidence-dense summarization continue to
favor fine-tuned or hybrid approaches. The benchmark delineates where simple
prompting suffices and where retrieval-augmented or planning-based scaffolds
are likely required, providing actionable guidance for BioNLP system design as
frontier models advance.

</details>


### [9] [Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?](https://arxiv.org/abs/2509.04464)
*Yang Nan,Pengfei He,Ravi Tandon,Han Xu*

Main category: cs.CL

TL;DR: 本研究提出一种通过分析LLM多响应间差异模式的方法，利用辅助LLM诊断LLM不确定性的来源（如输入歧义或知识缺失），并已在多个数据集上验证其通用性，以期通过诊断实现干预来提升LLM可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）输出可能不可靠或误导，对实际应用构成挑战。现有研究多集中于量化模型不确定性，但对不确定性来源的诊断工作较少。

Method: 当LLM不确定时，通过收集目标LLM的多个响应，并利用一个辅助LLM分析这些响应之间的不一致模式。辅助模型负责推断不确定性的可能来源（如输入问题歧义、相关知识缺乏或两者兼有），并能识别知识缺失的具体事实或概念。

Result: 该框架在AmbigQA、OpenBookQA和MMLU-Pro数据集上得到了验证，证实了其在诊断不同不确定性来源方面的通用性。

Conclusion: 对LLM不确定性来源的诊断为进行相关人工干预提供了潜力，有助于提高LLM的性能和可靠性。

Abstract: Large language models (LLMs) have delivered significant breakthroughs across
diverse domains but can still produce unreliable or misleading outputs, posing
critical challenges for real-world applications. While many recent studies
focus on quantifying model uncertainty, relatively little work has been devoted
to \textit{diagnosing the source of uncertainty}. In this study, we show that,
when an LLM is uncertain, the patterns of disagreement among its multiple
generated responses contain rich clues about the underlying cause of
uncertainty. To illustrate this point, we collect multiple responses from a
target LLM and employ an auxiliary LLM to analyze their patterns of
disagreement. The auxiliary model is tasked to reason about the likely source
of uncertainty, such as whether it stems from ambiguity in the input question,
a lack of relevant knowledge, or both. In cases involving knowledge gaps, the
auxiliary model also identifies the specific missing facts or concepts
contributing to the uncertainty. In our experiment, we validate our framework
on AmbigQA, OpenBookQA, and MMLU-Pro, confirming its generality in diagnosing
distinct uncertainty sources. Such diagnosis shows the potential for relevant
manual interventions that improve LLM performance and reliability.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [10] [Facial Emotion Recognition does not detect feeling unsafe in automated driving](https://arxiv.org/abs/2509.04490)
*Abel van Elburg,Konstantinos Gkentsidis,Mathieu Sarrazin,Sarah Barendswaard,Varun Kotian,Riender Happee*

Main category: cs.CV

TL;DR: 本研究通过驾驶模拟器实验，分析了自动驾驶汽车中感知风险的影响因素（驾驶风格、行人），发现面部表情识别不可靠，但基于车辆运动和皮肤电反应的神经网络模型可有效客观评估感知风险。


<details>
  <summary>Details</summary>
Motivation: 公众对自动驾驶汽车的接受度关键在于信任和感知安全。为深入理解用户在自动驾驶中的感知风险，本研究旨在探索其影响因素并寻找客观评估方法。

Method: 实验在驾驶模拟器中进行，32名参与者在两种自动驾驶风格下体验，并可选引入横穿行人。数据采集包括连续主观舒适度评分、车辆运动、网络摄像头（面部表情）、皮肤电反应、心率和眼动追踪。随后，利用车辆运动和皮肤电反应构建了一个神经网络模型来预测感知风险。

Result: 在转弯和制动时感知风险引起的显著不适，之后则感到放松或舒适。动态驾驶风格比平稳驾驶风格引起更强的不适。横穿行人并未影响平稳驾驶风格下的不适，但在动态驾驶风格下使不适感加倍。面部表情识别结果显示，大多数参与者无明显面部反应，且少数可见反应中“快乐”表情占主导，而非“恐惧”，表明其评估风险不可靠。基于车辆运动和皮肤电反应的神经网络模型与报告的感知风险有良好相关性。

Conclusion: 面部表情识别不是评估自动驾驶汽车中感知风险的可靠方法。利用车辆运动和皮肤电反应构建的神经网络模型，为自动驾驶汽车中客观评估感知风险提供了潜力，有助于减少主观偏见并指明未来研究方向。

Abstract: Trust and perceived safety play a crucial role in the public acceptance of
automated vehicles. To understand perceived risk, an experiment was conducted
using a driving simulator under two automated driving styles and optionally
introducing a crossing pedestrian. Data was collected from 32 participants,
consisting of continuous subjective comfort ratings, motion, webcam footage for
facial expression, skin conductance, heart rate, and eye tracking. The
continuous subjective perceived risk ratings showed significant discomfort
associated with perceived risk during cornering and braking followed by relief
or even positive comfort on continuing the ride. The dynamic driving style
induced a stronger discomfort as compared to the calm driving style. The
crossing pedestrian did not affect discomfort with the calm driving style but
doubled the comfort decrement with the dynamic driving style. This illustrates
the importance of consequences of critical interactions in risk perception.
Facial expression was successfully analyzed for 24 participants but most
(15/24) did not show any detectable facial reaction to the critical event.
Among the 9 participants who did, 8 showed a Happy expression, and only 4
showed a Surprise expression. Fear was never dominant. This indicates that
facial expression recognition is not a reliable method for assessing perceived
risk in automated vehicles. To predict perceived risk a neural network model
was implemented using vehicle motion and skin conductance. The model correlated
well with reported perceived risk, demonstrating its potential for objective
perceived risk assessment in automated vehicles, reducing subjective bias and
highlighting areas for future research.

</details>


### [11] [PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting](https://arxiv.org/abs/2509.04545)
*Linqing Wang,Ximing Xing,Yiji Cheng,Zhiyuan Zhao,Jiale Tao,Qixun Wang,Ruihuang Li,Xin Li,Mingrui Wu,Xinchi Deng,Chunyu Wang,Qinglin Lu*

Main category: cs.CV

TL;DR: 本文提出PromptEnhancer，一个通用的提示重写框架，通过强化学习训练CoT重写器，并由基于细粒度反馈的AlignEvaluator奖励模型指导，显著提升了文生图(T2I)模型对复杂提示的理解和图文对齐能力，且无需修改预训练模型权重。


<details>
  <summary>Details</summary>
Motivation: 现有文生图(T2I)模型在处理复杂用户提示（如属性绑定、否定、组合关系）时存在困难，导致生成图像与用户意图不符。现有方法通常依赖模型特定微调或隐式奖励信号，效果有限。

Method: 引入PromptEnhancer框架，该框架将重写器与生成器解耦，不修改预训练T2I模型权重。通过强化学习训练一个Chain-of-Thought (CoT) 重写器，并由专门的AlignEvaluator奖励模型提供指导。AlignEvaluator基于对T2I模型常见失败模式分析得出的24个关键点，提供显式且细粒度的反馈。重写器通过最大化AlignEvaluator的奖励来学习生成更精确的提示。

Result: 在HunyuanImage 2.1模型上的广泛实验证明，PromptEnhancer显著改善了各种语义和组合挑战下的图文对齐效果。此外，研究还引入了一个新的高质量人类偏好基准，以促进未来的研究。

Conclusion: PromptEnhancer提供了一种有效且通用的解决方案，通过创新的基于强化学习的提示重写方法，显著增强了T2I模型解释复杂提示的能力和图文对齐表现。新引入的基准将有助于该领域的研究进展。

Abstract: Recent advancements in text-to-image (T2I) diffusion models have demonstrated
remarkable capabilities in generating high-fidelity images. However, these
models often struggle to faithfully render complex user prompts, particularly
in aspects like attribute binding, negation, and compositional relationships.
This leads to a significant mismatch between user intent and the generated
output. To address this challenge, we introduce PromptEnhancer, a novel and
universal prompt rewriting framework that enhances any pretrained T2I model
without requiring modifications to its weights. Unlike prior methods that rely
on model-specific fine-tuning or implicit reward signals like image-reward
scores, our framework decouples the rewriter from the generator. We achieve
this by training a Chain-of-Thought (CoT) rewriter through reinforcement
learning, guided by a dedicated reward model we term the AlignEvaluator. The
AlignEvaluator is trained to provide explicit and fine-grained feedback based
on a systematic taxonomy of 24 key points, which are derived from a
comprehensive analysis of common T2I failure modes. By optimizing the CoT
rewriter to maximize the reward from our AlignEvaluator, our framework learns
to generate prompts that are more precisely interpreted by T2I models.
Extensive experiments on the HunyuanImage 2.1 model demonstrate that
PromptEnhancer significantly improves image-text alignment across a wide range
of semantic and compositional challenges. Furthermore, we introduce a new,
high-quality human preference benchmark to facilitate future research in this
direction.

</details>


### [12] [Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model](https://arxiv.org/abs/2509.04548)
*Hongyang Wei,Baixin Xu,Hongbo Liu,Cyrus Wu,Jie Liu,Yi Peng,Peiyu Wang,Zexiang Liu,Jingwen He,Yidan Xietian,Chuanxin Tang,Zidong Wang,Yichen Wei,Liang Hu,Boyi Jiang,William Li,Ying He,Yang Liu,Xuchen Song,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: 本文提出了一个2B参数的DiT模型UniPic2-SD3.5M-Kontext，通过架构修改和新颖的渐进式双任务强化策略（PDTR），在图像生成和编辑方面超越了参数更大的模型。该模型进一步扩展为统一多模态模型UniPic2-Metaquery，整合了理解、生成和编辑能力，验证了Skywork UniPic 2.0训练范式的有效性。


<details>
  <summary>Details</summary>
Motivation: 许多现有的开源多模态模型过度侧重于扩大模型参数而非优化训练策略，这限制了它们的效率和性能。

Method: ['在SD3.5-Medium基础上，对2B参数的DiT模型UniPic2-SD3.5M-Kontext进行架构修改，并利用高质量数据进行大规模预训练，使其具备联合文本到图像生成和编辑能力。', '提出了一种新颖的渐进式双任务强化策略（PDTR），分阶段有效增强指令遵循和编辑一致性。', '遵循MetaQuery范式，通过连接器将UniPic2-SD3.5M-Kontext与Qwen2.5-VL-7B联合训练，构建了一个统一的多模态模型UniPic2-Metaquery。']

Result: ['实验验证了PDTR策略中不同任务的强化阶段互惠互利，且不会产生负面干扰。', 'UniPic2-SD3.5M-Kontext在图像生成和编辑能力上显著优于BAGEL (7B)和Flux-Kontext (12B)等参数更大的模型。', 'UniPic2-Metaquery通过整合理解、生成和编辑，在各种任务上以简单可扩展的训练范式实现了顶尖性能。']

Conclusion: 所提出的Skywork UniPic 2.0训练范式，通过优化训练策略和模型设计，有效提升了多模态模型的性能和泛化能力，即使在较小的参数规模下也能实现卓越的图像生成、编辑和统一多模态功能。

Abstract: Recent advances in multimodal models have demonstrated impressive
capabilities in unified image generation and editing. However, many prominent
open-source models prioritize scaling model parameters over optimizing training
strategies, limiting their efficiency and performance. In this work, we present
UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which
achieves state-of-the-art image generation and editing while extending
seamlessly into a unified multimodal framework. Our approach begins with
architectural modifications to SD3.5-Medium and large-scale pre-training on
high-quality data, enabling joint text-to-image generation and editing
capabilities. To enhance instruction following and editing consistency, we
propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which
effectively strengthens both tasks in a staged manner. We empirically validate
that the reinforcement phases for different tasks are mutually beneficial and
do not induce negative interference. After pre-training and reinforcement
strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and
editing capabilities than models with significantly larger generation
parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following
the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a
connector and perform joint training to launch a unified multimodal model
UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and
editing, achieving top-tier performance across diverse tasks with a simple and
scalable training paradigm. This consistently validates the effectiveness and
generalizability of our proposed training paradigm, which we formalize as
Skywork UniPic 2.0.

</details>


### [13] [Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping](https://arxiv.org/abs/2509.04582)
*Jingyi Lu,Kai Han*

Main category: cs.CV

TL;DR: Inpaint4Drag是一个新颖的拖拽式图像编辑框架，通过将编辑分解为像素空间形变和图像修复，克服了现有潜在空间方法的局限性，实现了实时、高精度和高质量的编辑，并可作为任何修复模型的通用适配器。


<details>
  <summary>Details</summary>
Motivation: 现有的拖拽式图像编辑方法主要依赖生成模型的潜在空间操作，导致精度有限、反馈延迟且存在模型特异性约束，影响了用户体验和编辑效率。

Method: 提出Inpaint4Drag框架，将拖拽编辑分解为像素空间的双向形变（bidirectional warping）和图像修复（image inpainting）。该方法受物理世界弹性物体形变启发，将图像区域视为可变形材料。通过将拖拽输入直接转换为标准修复格式，使其能作为任何图像修复模型的通用适配器，无需修改架构。

Result: 该方法在512x512分辨率下实现了实时的形变预览（0.01秒）和高效的图像修复（0.3秒），显著改善了交互体验（相比现有方法需数分钟）。广泛实验证明，该方法在保持实时性能的同时，实现了卓越的视觉质量和精确控制。

Conclusion: Inpaint4Drag通过其像素空间处理和通用适配器设计，有效解决了现有拖拽编辑方法的局局限性，提供了一种实时、高精度、高质量且未来可扩展的图像编辑解决方案。

Abstract: Drag-based image editing has emerged as a powerful paradigm for intuitive
image manipulation. However, existing approaches predominantly rely on
manipulating the latent space of generative models, leading to limited
precision, delayed feedback, and model-specific constraints. Accordingly, we
present Inpaint4Drag, a novel framework that decomposes drag-based editing into
pixel-space bidirectional warping and image inpainting. Inspired by elastic
object deformation in the physical world, we treat image regions as deformable
materials that maintain natural shape under user manipulation. Our method
achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at
512x512 resolution, significantly improving the interaction experience compared
to existing methods that require minutes per edit. By transforming drag inputs
directly into standard inpainting formats, our approach serves as a universal
adapter for any inpainting model without architecture modification,
automatically inheriting all future improvements in inpainting technology.
Extensive experiments demonstrate that our method achieves superior visual
quality and precise control while maintaining real-time performance. Project
page: https://visual-ai.github.io/inpaint4drag/

</details>


### [14] [DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](https://arxiv.org/abs/2509.04597)
*Jin Ma,Mohammed Aldeen,Christopher Salas,Feng Luo,Mashrur Chowdhury,Mert Pesé,Long Cheng*

Main category: cs.CV

TL;DR: 本文提出DISPATCH，一个基于扩散模型的物体检测防御框架，采用“再生和修正”策略对抗对抗补丁攻击，在多种攻击下均优于现有防御方法，且对自适应攻击表现出强大鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 物体检测在实际应用中面临对抗补丁攻击的威胁，这些攻击可能隐藏物体或制造虚假物体，导致严重后果。现有防御方法难以应对多样化、未知且潜在的攻击，因此需要一种有效、通用且鲁棒的防御方案。

Method: 本文引入DISPATCH，首个基于扩散模型的物体检测防御框架。它摒弃了传统的“检测并移除”策略，转而采用“再生和修正”策略。具体而言，DISPATCH利用扩散模型的同分布生成能力，重新生成整个图像以恢复良性数据状态，然后通过一个修正过程识别并替换图像中的对抗区域为其对应的良性再生版本。该方法与攻击类型无关，无需预知补丁信息。

Result: 广泛实验证明，DISPATCH在隐藏攻击和创建攻击上均持续优于现有先进防御方法。在隐藏攻击上，其整体mAP.5得分达到89.3%；在非定向创建攻击上，攻击成功率降低至24.8%。此外，DISPATCH对自适应攻击也展现出强大的鲁棒性。

Conclusion: DISPATCH通过创新的“再生和修正”策略，为物体检测系统提供了一种实用且可靠的防御方法。它能够有效抵御多样化的对抗补丁攻击，并在性能和对自适应攻击的鲁棒性方面超越了现有技术。

Abstract: Object detection is fundamental to various real-world applications, such as
security monitoring and surveillance video analysis. Despite their
advancements, state-of-theart object detectors are still vulnerable to
adversarial patch attacks, which can be easily applied to real-world objects to
either conceal actual items or create non-existent ones, leading to severe
consequences. Given the current diversity of adversarial patch attacks and
potential unknown threats, an ideal defense method should be effective,
generalizable, and robust against adaptive attacks. In this work, we introduce
DISPATCH, the first diffusion-based defense framework for object detection.
Unlike previous works that aim to "detect and remove" adversarial patches,
DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative
models to disarm attack effects while preserving the integrity of the input
image. Specifically, we utilize the in-distribution generative power of
diffusion models to regenerate the entire image, aligning it with benign data.
A rectification process is then employed to identify and replace adversarial
regions with their regenerated benign counterparts. DISPATCH is attack-agnostic
and requires no prior knowledge of the existing patches. Extensive experiments
across multiple detectors and attacks demonstrate that DISPATCH consistently
outperforms state-of-the-art defenses on both hiding attacks and creating
attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and
lowering the attack success rate to 24.8% on untargeted creating attacks.
Moreover, it maintains strong robustness against adaptive attacks, making it a
practical and reliable defense for object detection systems.

</details>


### [15] [WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human](https://arxiv.org/abs/2509.04600)
*Qijun Ying,Zhongyuan Hu,Rui Zhang,Ronghui Li,Yu Lu,Zijiao Zeng*

Main category: cs.CV

TL;DR: WATCH框架通过创新的相机朝向分解和轨迹集成机制，实现了从单目视频中高精度全局人体运动重建，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 从野外单目视频中进行全局人体运动重建在VR、图形和机器人领域需求旺盛，但面临深度模糊、运动模糊以及相机与人体运动耦合的挑战。现有以人体运动为中心的方法在利用相机朝向信息和有效集成相机平移线索方面存在不足。

Method: 提出了WATCH（World-aware Allied Trajectory and pose reconstruction for Camera and Human）统一框架。该方法引入了一种高效且可扩展的分析性航向角分解技术，并设计了一种受世界模型启发的相机轨迹集成机制，以有效利用相机平移信息。

Result: 在野外基准测试中，WATCH在端到端轨迹重建方面取得了最先进的性能。

Conclusion: 该工作证明了联合建模相机与人体运动关系的有效性，并为解决全局人体运动重建中相机平移集成这一长期挑战提供了新见解。

Abstract: Global human motion reconstruction from in-the-wild monocular videos is
increasingly demanded across VR, graphics, and robotics applications, yet
requires accurate mapping of human poses from camera to world coordinates-a
task challenged by depth ambiguity, motion ambiguity, and the entanglement
between camera and human movements. While human-motion-centric approaches excel
in preserving motion details and physical plausibility, they suffer from two
critical limitations: insufficient exploitation of camera orientation
information and ineffective integration of camera translation cues. We present
WATCH (World-aware Allied Trajectory and pose reconstruction for Camera and
Human), a unified framework addressing both challenges. Our approach introduces
an analytical heading angle decomposition technique that offers superior
efficiency and extensibility compared to existing geometric methods.
Additionally, we design a camera trajectory integration mechanism inspired by
world models, providing an effective pathway for leveraging camera translation
information beyond naive hard-decoding approaches. Through experiments on
in-the-wild benchmarks, WATCH achieves state-of-the-art performance in
end-to-end trajectory reconstruction. Our work demonstrates the effectiveness
of jointly modeling camera-human motion relationships and offers new insights
for addressing the long-standing challenge of camera translation integration in
global human motion reconstruction. The code will be available publicly.

</details>


### [16] [Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption Retrieval for Dense Video Captioning](https://arxiv.org/abs/2509.04602)
*MinJu Jeon,Si-Woo Kim,Ye-Chan Kim,HyunGee Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: 针对密集视频字幕中帧加权不均和固定块检索的问题，提出Sali4Vid框架，通过显著性感知视频重加权和自适应字幕检索，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端密集视频字幕模型存在两点局限：1) 时间戳监督仅用于文本，对所有视频帧一视同仁；2) 从固定大小的视频块中检索字幕，忽略了场景过渡。

Method: 提出Sali4Vid框架，包含两个核心组件：1) 显著性感知视频重加权，将时间戳标注转换为基于Sigmoid的帧重要性权重；2) 基于语义的自适应字幕检索，通过帧相似性分割视频以捕获场景过渡，改进字幕检索。

Result: Sali4Vid在YouCook2和ViTT数据集上取得了最先进的结果。

Conclusion: 联合改进视频加权和检索对密集视频字幕任务具有显著优势。

Abstract: Dense video captioning aims to temporally localize events in video and
generate captions for each event. While recent works propose end-to-end models,
they suffer from two limitations: (1) applying timestamp supervision only to
text while treating all video frames equally, and (2) retrieving captions from
fixed-size video chunks, overlooking scene transitions. To address these, we
propose Sali4Vid, a simple yet effective saliency-aware framework. We introduce
Saliency-aware Video Reweighting, which converts timestamp annotations into
sigmoid-based frame importance weights, and Semantic-based Adaptive Caption
Retrieval, which segments videos by frame similarity to capture scene
transitions and improve caption retrieval. Sali4Vid achieves state-of-the-art
results on YouCook2 and ViTT, demonstrating the benefit of jointly improving
video weighting and retrieval for dense video captioning

</details>


### [17] [UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis](https://arxiv.org/abs/2509.04624)
*Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel*

Main category: cs.CV

TL;DR: 本文提出一种先进的无人机（UAV）交通监控系统，旨在解决传统方法的局限性，实现车辆检测、分类、跟踪、行为分析以及交通违规检测。该系统利用多尺度模板匹配、卡尔曼滤波和单应性校准等技术处理航空视频数据，并在实际城市环境中展示了高精度和可扩展性，为智慧城市提供了一种基础设施独立的交通监控解决方案。


<details>
  <summary>Details</summary>
Motivation: 交通拥堵和违规对城市交通和道路安全构成重大挑战。传统交通监控系统（如固定摄像头和基于传感器的方法）常受限于覆盖范围有限、适应性差和可扩展性低。本研究旨在开发一种先进系统来克服这些挑战。

Method: 本研究引入了一种基于无人机的交通监控系统。该系统利用多尺度和多角度模板匹配、卡尔曼滤波和基于单应性的校准技术来处理从约200米高空收集的航空视频数据，以实现车辆检测、分类和跟踪。为检测交通违规，系统融合了地理围栏、运动滤波和轨迹偏差分析。此外，系统集成了分析模块，支持起点-终点跟踪、车辆计数可视化、类间关联分析、基于热图的拥堵建模、出入口轨迹分析、路段车辆密度估计和移动方向记录。

Result: 该系统在城市区域案例研究中表现出强大的性能，检测精度达到91.8%，F1-score为90.5%，跟踪指标（MOTA/MOTP）分别为92.1%和93.7%。系统能够分类五种车辆类型，并通过融合地理围栏、运动滤波和轨迹偏差分析，自动检测不安全变道、非法双重停车和人行横道阻塞等关键交通违规行为。集成的分析模块支持全面的多尺度城市交通分析。

Conclusion: 实验结果证实了该系统的可扩展性、准确性和实际相关性。它作为一种执法感知、基础设施独立的交通监控解决方案，在下一代智慧城市中具有巨大的潜力。

Abstract: Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.

</details>


### [18] [VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation](https://arxiv.org/abs/2509.04669)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: 本文提出VCMamba，一种结合CNNs和多向Mamba SSMs的新型视觉骨干网络，旨在高效融合局部特征提取与全局上下文建模，并在图像分类和语义分割任务上取得卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型各有优劣：ViTs和SSMs擅长全局上下文但局部特征不足；CNNs擅长局部特征但缺乏全局推理能力。研究动机是弥合这一差距，开发一个能同时捕捉细粒度局部特征和长程依赖的混合模型，并保持线性复杂度。

Method: VCMamba采用混合设计：早期阶段使用卷积干（convolutional stem）和卷积块（convolutional blocks）提取丰富的局部特征；后期阶段整合多向Mamba块（multi-directional Mamba blocks）来高效建模长程依赖和全局上下文。这种分层结构确保了优越的特征表示，并维持了与图像分辨率相关的线性复杂度。

Result: VCMamba在多项基准测试中表现出色：VCMamba-B在ImageNet-1K分类任务中达到82.6%的top-1准确率，比PlainMamba-L3高0.3%且参数减少37%，比Vision GNN-B高0.3%且参数减少64%。在ADE20K语义分割任务中，VCMamba-B获得47.1 mIoU，超越EfficientFormer-L7 2.0 mIoU且参数减少62%。

Conclusion: VCMamba成功地整合了CNNs在局部特征方面的优势和多向Mamba SSMs在全局上下文方面的能力，提供了一种高效且高性能的视觉骨干网络。它在图像分类和语义分割任务上均展现了优越的特征表示能力和参数效率。

Abstract: Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs)
have challenged the dominance of Convolutional Neural Networks (CNNs) in
computer vision. ViTs excel at capturing global context, and SSMs like Mamba
offer linear complexity for long sequences, yet they do not capture
fine-grained local features as effectively as CNNs. Conversely, CNNs possess
strong inductive biases for local features but lack the global reasoning
capabilities of transformers and Mamba. To bridge this gap, we introduce
\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs
and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a
hierarchical structure with convolutional blocks in its early stages to extract
rich local features. These convolutional blocks are then processed by later
stages incorporating multi-directional Mamba blocks designed to efficiently
model long-range dependencies and global context. This hybrid design allows for
superior feature representation while maintaining linear complexity with
respect to image resolution. We demonstrate VCMamba's effectiveness through
extensive experiments on ImageNet-1K classification and ADE20K semantic
segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K,
surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming
Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains
47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing
62% fewer parameters. Code is available at
https://github.com/Wertyuui345/VCMamba.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management](https://arxiv.org/abs/2509.04505)
*Somtochukwu Azie,Yiping Meng*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLMs）在建筑项目管理（CPM）伦理决策中的可靠性，发现它们在处理情境细微之处和问责制方面存在显著不足，强调需要人类监督而非自主应用。


<details>
  <summary>Details</summary>
Motivation: 批判性评估大型语言模型（LLMs）在建筑项目管理（CPM）中伦理敏感、高风险决策情境下的伦理可行性和可靠性。

Method: 采用混合方法研究设计。定量方面，使用新型伦理决策支持评估清单（EDSAC）对两个主流LLM在12个真实世界伦理场景中进行性能测试。定性方面，对12位行业专家进行半结构化访谈以获取专业见解。

Result: LLMs在法律合规等结构化领域表现尚可，但在处理情境细微性、确保问责制和提供透明推理方面存在显著不足。利益相关者对AI自主进行伦理判断表示高度保留，强烈主张实行强大的人工监督。

Conclusion: 鉴于LLMs在伦理推理方面的局限性，它们目前最适合作为建筑项目管理中的决策支持辅助工具，而非自主伦理代理，强调了人工监督的必要性。

Abstract: The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.

</details>


### [20] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: Maestro是一种针对LLM智能体的全面优化器，它通过联合搜索智能体的图结构和配置来提高性能，解决了现有优化器无法处理的结构性故障模式，并显著超越了领先的提示优化器。


<details>
  <summary>Details</summary>
Motivation: 构建可靠的LLM智能体需要在图结构（模块及信息流）和节点配置（模型、提示、工具等）两个层面进行决策。现有优化器大多固定图结构，只调整配置，导致无法解决结构性故障模式。

Method: Maestro是一个与框架无关的整体优化器，它在明确的预算限制下，同时搜索智能体的图结构和配置以最大化智能体质量。它利用轨迹中的反射性文本反馈来优先编辑，从而提高样本效率并针对特定故障模式。

Result: 在IFBench和HotpotQA基准测试中，Maestro平均超越了MIPROv2、GEPA和GEPA+Merge等领先的提示优化器，分别提高了12%、4.9%和4.86%。即使仅限于提示优化，它仍分别领先9.65%、2.37%和2.41%。Maestro以远少于GEPA的执行次数达到这些结果。此外，在面试官和RAG智能体应用中也取得了显著提升，表明联合图结构和配置搜索能解决仅凭提示调优无法修复的结构性故障模式。

Conclusion: Maestro通过联合搜索LLM智能体的图结构和配置，克服了传统提示优化器的局限性，有效解决了结构性故障模式，显著提高了智能体性能和样本效率，为构建更可靠的LLM智能体提供了新的范式。

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [21] [Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization](https://arxiv.org/abs/2509.04646)
*Philippe J. Giabbanelli,Ameeta Agrawal*

Main category: cs.AI

TL;DR: M&S模型在健康决策中潜力巨大，但因复杂性难以被利益相关者理解。现有LLM摘要无法满足个性化需求。本文提出一个分步框架，通过识别需求并优化LLM，以生成定制化的健康模拟解释。


<details>
  <summary>Details</summary>
Motivation: 健康领域的建模与模拟（M&S）方法（如基于智能体的模型）在支持决策方面潜力巨大，但其复杂性使得相关利益相关者难以利用。现有的大型语言模型（LLM）虽然能将模拟输出翻译成文本，但其“一刀切”的摘要未能满足临床医生、政策制定者、患者等不同利益相关者多样化的信息需求和风格偏好。这种局限性源于缺乏对利益相关者解释需求的系统性理解以及如何进行定制化。

Method: 本文提出了一个逐步框架来识别利益相关者的需求，并指导LLM生成健康模拟的定制化解释。该方法采用混合设计，首先获取不同健康利益相关者的解释需求和风格偏好，然后优化LLM生成定制化输出的能力（例如，通过可控属性调整），最后通过全面的指标进行评估，以进一步改进摘要的定制化生成。

Result: 本文提出了一个逐步框架，旨在识别利益相关者的需求并指导大型语言模型生成健康模拟的定制化解释。该框架包括需求识别、LLM优化和评估等关键步骤。

Conclusion: 该框架旨在解决健康M&S模型因复杂性导致的不可访问性问题，并通过克服LLM生成通用摘要的局限性，使不同利益相关者能获得定制化、易于理解的健康模拟解释，从而充分发挥M&S方法的决策支持潜力。

Abstract: Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.

</details>


### [22] [An Approach to Grounding AI Model Evaluations in Human-derived Criteria](https://arxiv.org/abs/2509.04676)
*Sasha Mitts*

Main category: cs.AI

TL;DR: 本研究提出一种以人为中心的评估方法，通过整合人类认知技能来增强现有AI基准测试，旨在提高物理世界建模AI的解释性和适用性。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的AI领域，传统基准测试难以捕捉AI模型的细微能力，尤其是在物理世界建模方面。需要一种新方法来增强现有基准测试，以提高模型行为的解释性和适用性。

Method: 研究以Perception Test和OpenEQA基准测试为基础，通过深度访谈和大规模调查，识别出优先级、记忆、辨别和情境化等对AI和人类推理都至关重要的认知技能，并将其整合到基准设计中。

Result: 研究发现，参与者认为AI缺乏解释性和同理心技能，但对其性能抱有很高期望。这些发现揭示了人类在评估AI时关注的关键认知维度。

Conclusion: 本研究提供了一个开发更符合人类标准的AI进展定义和衡量方式的框架，强调了AI开发中以用户为中心的评估的重要性，为研究人员和实践者提供了可操作的指导，以使AI能力与人类认知过程对齐。

Abstract: In the rapidly evolving field of artificial intelligence (AI), traditional
benchmarks can fall short in attempting to capture the nuanced capabilities of
AI models. We focus on the case of physical world modeling and propose a novel
approach to augment existing benchmarks with human-derived evaluation criteria,
aiming to enhance the interpretability and applicability of model behaviors.
Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted
in-depth interviews and large-scale surveys to identify key cognitive skills,
such as Prioritization, Memorizing, Discerning, and Contextualizing, that are
critical for both AI and human reasoning. Our findings reveal that participants
perceive AI as lacking in interpretive and empathetic skills yet hold high
expectations for AI performance. By integrating insights from our findings into
benchmark design, we offer a framework for developing more human-aligned means
of defining and measuring progress. This work underscores the importance of
user-centered evaluation in AI development, providing actionable guidelines for
researchers and practitioners aiming to align AI capabilities with human
cognitive processes. Our approach both enhances current benchmarking practices
and sets the stage for future advancements in AI model evaluation.

</details>


### [23] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 本文提出，通过利用大型语言模型（LLM）动态生成分层支架，构建具有显式、分层世界模型的环境，以克服复杂多智能体任务中探索空间大和奖励稀疏的挑战，从而显著提高智能体学习效率和战略行为能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型、智能体模型和世界模型的融合是人工智能的关键前沿，但复杂、显式的世界模型仍是瓶颈，尤其在复杂、长期的多智能体任务中。在如机器人足球等领域，高保真模拟器中的标准强化学习因探索空间难以处理和奖励稀疏而失败。

Method: 本文主张通过分层支架（将复杂目标分解为结构化的子目标）创建具有显式、分层世界模型的环境。并提出一个范式转变：利用大型语言模型（LLM）动态生成这种分层支架，即时地用语言来构建世界模型。这种语言驱动的世界模型提供了内在课程、密集且有意义的学习信号，以及组合学习框架。

Result: 对2024年多智能体足球研究的系统回顾显示，将符号和分层方法与多智能体强化学习（MARL）集成以隐式或显式构建基于任务的世界模型，已成为明确趋势。所提出的方法使智能体模型能够以更高的样本效率获得复杂的战略行为，并弥合了低级反应行为和高级战略团队协作之间的鸿沟。

Conclusion: 通过构建具有显式、语言可配置任务层的环境，能够为训练下一代智能体提供一个强大且可泛化的框架，解决当前多智能体学习的挑战，并实现更高效、更复杂的智能行为学习。

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [24] [What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791)
*Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi*

Main category: cs.AI

TL;DR: 为解决大型语言模型(LLMs)缺乏预测未来行动后果的能力，本文提出了WiA-LLM范式。该模型通过集成假设分析(WIA)和强化学习，使LLMs具备主动预测未来状态的能力，并在《王者荣耀》中显著提升了游戏状态预测准确率。


<details>
  <summary>Details</summary>
Motivation: LLMs擅长被动处理信息，但无法系统性地探索假设性未来，即无法在行动前预测其潜在后果。这一关键缺陷限制了LLMs在战略规划、风险评估和实时决策等动态高风险场景中的应用。

Method: 本文提出了WiA-LLM，一种赋予LLMs主动思考能力的新范式。该方法集成了假设分析（What-If Analysis, WIA），通过改变输入变量系统评估假设场景，并利用强化学习获取环境反馈。WiA-LLM能够动态模拟每个潜在行动的结果，从而预测未来状态。模型在《王者荣耀》这一复杂多人游戏环境中进行验证。

Result: 实验结果表明，WiA-LLM在预测游戏状态变化方面达到了74.2%的准确率，比基线模型提高了两倍。该模型在需要准确预判的高难度场景中表现出尤其显著的提升。

Conclusion: WiA-LLM是首次正式探索并整合LLMs假设分析能力的工作，代表了LLMs在主动推理方面的一项基础性进展。它为动态环境中的稳健决策提供了一个可扩展框架，对战略应用具有广泛的意义。

Abstract: Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.

</details>


### [25] [TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models](https://arxiv.org/abs/2509.04809)
*Haechang Kim,Hao Chen,Can Li,Jong Min Lee*

Main category: cs.AI

TL;DR: 本文提出了TalkToAgent，一个基于多智能体LLM的框架，通过交互式自然语言解释，弥合复杂RL策略与领域专家之间的理解鸿沟，并扩展了反事实解释。


<details>
  <summary>Details</summary>
Motivation: 现有可解释强化学习（XRL）结果理解有限且工具覆盖分散，导致领域专家难以理解复杂的强化学习策略，用户也难以选择合适的工具。

Method: 引入TalkToAgent，一个包含五个专门LLM智能体（协调器、解释器、编码器、评估器、调试器）的多智能体LLM框架。它能自动将用户查询映射到相关XRL工具，并以关键状态变量、预期结果或反事实解释的形式澄清智能体行为。此外，通过从定性行为描述或新规则策略中推导替代场景，扩展了反事实解释。

Result: 在四罐过程控制问题上验证，TalkToAgent高精度地将用户查询映射到XRL任务，编码器-调试器交互最大限度地减少了反事实生成失败。定性评估证实其有效解释了智能体行为并在问题领域中对其进行语境化。

Conclusion: TalkToAgent通过提供交互式、自然语言的解释，成功提升了RL智能体的透明度，有效解决了XRL结果可理解性有限和现有方法覆盖分散的挑战。

Abstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.

</details>


### [26] [Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory](https://arxiv.org/abs/2509.04847)
*Mukul Singh,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 本研究在迭代囚徒困境(IPD)中系统地分析了语言模型(LM)的长期合作行为，发现LM在表现上与最佳经典策略相当甚至超越，并展现出快速适应对手策略变化的强大能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型在交互式在线环境中部署日益增多，引发了对其在多方设置中合作与竞争行为的疑问。现有研究常忽略长期互动、人机协作及行为模式随时间演变的问题。

Method: 将基于语言模型的智能体与240种成熟的经典策略进行Axelrod式锦标赛对抗，以研究语言模型在迭代囚徒困境(IPD)中的动态行为。通过行为分析和受控的“策略转换”实验，评估其合作特性和适应性。

Result: 语言模型智能体在表现上与最佳经典策略相当，甚至超越。行为分析显示，语言模型具备合作策略的关键特性：友善性、可激怒性及慷慨性，并能在对局中快速适应对手策略变化，在几轮内检测并响应转换。

Conclusion: 本研究首次系统地描绘了语言模型智能体的长期合作行为，为未来在更复杂的人机混合社会环境中研究其作用奠定了基础。

Abstract: Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.

</details>


### [27] [Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](https://arxiv.org/abs/2509.04871)
*Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 本文提出了一种从通话录音语料库中克隆会话语音AI代理的通用方法，并以电话销售数据为例进行验证。该AI代理在常规通话方面接近人类表现，但在说服和异议处理方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 随着语言和语音建模的进步，构建能实时理解和生成人类对话的自主语音助手成为可能。这些系统在客户服务和医疗保健等领域部署，可自动化重复任务、降低运营成本并提供全天候支持。

Method: 研究提出了一种从通话录音语料库克隆会话语音AI代理的通用方法。该系统通过自动语音识别（ASR）听取客户，使用合成语音回应，并遵循从顶尖人类代理学习的结构化剧本。它整合了ASR、基于大语言模型（LLM）的对话管理器和文本到语音合成（TTS）到一个流式推理管道中。通过领域选择、知识提取和提示工程来构建代理。克隆代理在22项标准（涵盖介绍、产品沟通、销售推动、异议处理和结束语）上与人类代理进行盲测评估。

Result: 盲测结果显示，该AI代理在通话的常规方面接近人类表现，但在说服和异议处理方面表现不佳。研究根据这些不足对提示进行了优化和完善。

Conclusion: 论文总结了设计经验教训，并提出了未来的研究方向，包括大规模模拟和自动化评估。AI代理在常规任务上表现良好，但在需要更高情商和应变能力的方面仍需改进。

Abstract: Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [Q-SafeML: Safety Assessment of Quantum Machine Learning via Quantum Distance Metrics](https://arxiv.org/abs/2509.04536)
*Oliver Dunn,Koorosh Aslansefat,Yiannis Papadopoulos*

Main category: cs.LG

TL;DR: 本文提出Q-SafeML，一种专为量子机器学习（QML）设计的安全监控方法，通过适应量子特性来增强系统透明度和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着量子机器学习（QML）在安全关键系统中的兴起，现有经典机器学习的安全监控方法因量子计算的根本差异而不再适用。目前QML缺乏专门的安全机制，这一领域尚不成熟。

Method: 引入Q-SafeML，该方法基于SafeML，但为QML进行了适配。它利用以量子为中心的距离度量，对QML输出的概率性质进行模型依赖的后分类评估。通过在量子态空间中定义距离指标，Q-SafeML能够检测运行数据与训练数据之间的概念漂移。

Result: 在QCNN和VQC模型上的实验证明，Q-SafeML能够实现知情的人工监督，显著提升了系统的透明度和安全性。

Conclusion: Q-SafeML为QML提供了有效的安全监控方案，解决了传统方法不适用的问题，增强了QML系统在安全关键应用中的可靠性与可解释性。

Abstract: The rise of machine learning in safety-critical systems has paralleled
advancements in quantum computing, leading to the emerging field of Quantum
Machine Learning (QML). While safety monitoring has progressed in classical ML,
existing methods are not directly applicable to QML due to fundamental
differences in quantum computation. Given the novelty of QML, dedicated safety
mechanisms remain underdeveloped. This paper introduces Q-SafeML, a safety
monitoring approach for QML. The method builds on SafeML, a recent method that
utilizes statistical distance measures to assess model accuracy and provide
confidence in the reasoning of an algorithm. An adapted version of Q-SafeML
incorporates quantum-centric distance measures, aligning with the probabilistic
nature of QML outputs. This shift to a model-dependent, post-classification
evaluation represents a key departure from classical SafeML, which is
dataset-driven and classifier-agnostic. The distinction is motivated by the
unique representational constraints of quantum systems, requiring distance
metrics defined over quantum state spaces. Q-SafeML detects distances between
operational and training data addressing the concept drifts in the context of
QML. Experiments on QCNN and VQC Models show that this enables informed human
oversight, enhancing system transparency and safety.

</details>


### [29] [Finance-Grounded Optimization For Algorithmic Trading](https://arxiv.org/abs/2509.04541)
*Kasymkhan Khubiev,Mikhail Semenov,Irina Podlipnova*

Main category: cs.LG

TL;DR: 本文提出针对金融深度学习的挑战，引入基于夏普比率、盈亏等金融指标的损失函数及换手率正则化。研究表明，该方法在回报预测任务中，使用算法交易指标评估时，优于传统均方误差损失，有效提升了交易策略和投资组合优化的预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在金融领域表现不足，尤其是在可解释性AI方面。金融专家采用独特的指标评估模型性能，与自然语言处理、计算机视觉等领域不同，这使得经典方法不完全适用于金融世界。

Method: 引入了基于夏普比率、盈亏（PnL）和最大回撤等关键量化金融指标的金融化损失函数。此外，提出换手率正则化方法，以将生成头寸的换手率限制在预定义范围内。

Result: 研究结果表明，所提出的损失函数与换手率正则化结合后，在回报预测任务中，使用算法交易指标评估时，其性能优于传统的均方误差损失。

Conclusion: 将金融化指标融入深度学习模型，可以显著增强交易策略和投资组合优化中的预测性能。

Abstract: Deep Learning is evolving fast and integrates into various domains. Finance
is a challenging field for deep learning, especially in the case of
interpretable artificial intelligence (AI). Although classical approaches
perform very well with natural language processing, computer vision, and
forecasting, they are not perfect for the financial world, in which specialists
use different metrics to evaluate model performance.
  We first introduce financially grounded loss functions derived from key
quantitative finance metrics, including the Sharpe ratio, Profit-and-Loss
(PnL), and Maximum Draw down. Additionally, we propose turnover regularization,
a method that inherently constrains the turnover of generated positions within
predefined limits.
  Our findings demonstrate that the proposed loss functions, in conjunction
with turnover regularization, outperform the traditional mean squared error
loss for return prediction tasks when evaluated using algorithmic trading
metrics. The study shows that financially grounded metrics enhance predictive
performance in trading strategies and portfolio optimization.

</details>


### [30] [i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition](https://arxiv.org/abs/2509.04544)
*Ashutosh Kumar Sinha,Ayush Patel,Mitul Dudhat,Pritam Anand,Rahul Mishra*

Main category: cs.LG

TL;DR: 本文提出i-Mask，一种利用配备传感器口罩捕获呼出气体模式进行人体活动识别的新方法，实现了超过95%的准确率，在医疗健康和健身应用中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 吸气和呼气模式包含重要的生理信号，可用于预测人类行为、健康趋势和生命体征。人体活动识别（HAR）与这些生命体征紧密相关，能提供更深入的健康洞察并实现实时健康监测。

Method: 提出了一种名为i-Mask的新型HAR方法，利用定制开发的、配备集成传感器的口罩捕获呼出气体模式。从志愿者收集的数据经过噪声过滤、时间序列分解和标注后，用于训练预测模型。

Result: 实验结果验证了该方法的有效性，实现了超过95%的准确率。

Conclusion: i-Mask方法在基于呼出气体模式的人体活动识别方面是有效的，并在医疗保健和健身应用中展现出巨大潜力。

Abstract: The patterns of inhalation and exhalation contain important physiological
signals that can be used to anticipate human behavior, health trends, and vital
parameters. Human activity recognition (HAR) is fundamentally connected to
these vital signs, providing deeper insights into well-being and enabling
real-time health monitoring. This work presents i-Mask, a novel HAR approach
that leverages exhaled breath patterns captured using a custom-developed mask
equipped with integrated sensors. Data collected from volunteers wearing the
mask undergoes noise filtering, time-series decomposition, and labeling to
train predictive models. Our experimental results validate the effectiveness of
the approach, achieving over 95\% accuracy and highlighting its potential in
healthcare and fitness applications.

</details>


### [31] [Bootstrapping Task Spaces for Self-Improvement](https://arxiv.org/abs/2509.04575)
*Minqi Jiang,Andrei Lupu,Yoram Bachrach*

Main category: cs.LG

TL;DR: ExIt是一种自课程强化学习（RL）方法，通过训练信息量大的单步迭代，使大型语言模型（LLMs）在推理时能进行多步自我改进，并在多个领域展现出超越训练深度的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在训练智能体进行推理时多步自我改进时，通常假设一个固定的最大迭代深度，这种方法既昂贵又武断。

Method: 本文提出探索性迭代（ExIt），一种自课程RL方法。ExIt利用自我改进任务的循环结构，通过只训练最有信息量的单步迭代来训练LLMs执行多步自我改进。ExIt通过选择性采样在训练过程中遇到的最具信息量的中间、部分历史作为新的自我迭代任务实例来扩展任务空间，并可进一步结合显式探索机制以维持更大的任务多样性。

Result: 在竞争数学、多轮工具使用和机器学习工程等多个领域，ExIt策略（无论是从单个还是多个任务实例开始）都能在未见过的任务实例上产生强大的推理时自我改进策略，并能够在超出训练期间平均迭代深度的步长预算内，持续迭代以获得更高性能。

Conclusion: ExIt是一种有效的自课程强化学习框架，能够使LLMs在多任务领域实现高效、稳健的多步自我改进，并克服了传统方法在迭代深度上的限制。

Abstract: Progress in many task domains emerges from repeated revisions to previous
solution attempts. Training agents that can reliably self-improve over such
sequences at inference-time is a natural target for reinforcement learning
(RL), yet the naive approach assumes a fixed maximum iteration depth, which can
be both costly and arbitrary. We present Exploratory Iteration (ExIt), a family
of autocurriculum RL methods that directly exploits the recurrent structure of
self-improvement tasks to train LLMs to perform multi-step self-improvement at
inference-time while only training on the most informative single-step
iterations. ExIt grows a task space by selectively sampling the most
informative intermediate, partial histories encountered during an episode for
continued iteration, treating these starting points as new self-iteration task
instances to train a self-improvement policy. ExIt can further pair with
explicit exploration mechanisms to sustain greater task diversity. Across
several domains, encompassing competition math, multi-turn tool-use, and
machine learning engineering, we demonstrate that ExIt strategies, starting
from either a single or many task instances, can produce policies exhibiting
strong inference-time self-improvement on held-out task instances, and the
ability to iterate towards higher performance over a step budget extending
beyond the average iteration depth encountered during training.

</details>


### [32] [Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions](https://arxiv.org/abs/2509.04583)
*Jiequn Han,Kui Ren,Nathan Soedjak*

Main category: cs.LG

TL;DR: 提出一种实例自适应采样框架，用于为逆问题求解构建紧凑且信息丰富的训练数据集，以显著提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的逆问题方法在处理高维先验或需要高精度时，需要大量训练样本，导致高昂的数据收集成本。

Method: 该方法根据特定的测试实例动态分配采样工作，并通过基于最新预测迭代优化训练数据集，使其适应每个测试实例周围逆映射的几何结构。

Result: 在逆散射问题中，该方法被证明是有效的，且在先验更复杂或精度要求更高的场景中，自适应方法的优势更加明显。

Conclusion: 该自适应采样策略具有广泛适用性，可扩展到其他逆问题，为传统的固定数据集训练提供了一种可扩展且实用的替代方案。

Abstract: We propose an instance-wise adaptive sampling framework for constructing
compact and informative training datasets for supervised learning of inverse
problem solutions. Typical learning-based approaches aim to learn a
general-purpose inverse map from datasets drawn from a prior distribution, with
the training process independent of the specific test instance. When the prior
has a high intrinsic dimension or when high accuracy of the learned solution is
required, a large number of training samples may be needed, resulting in
substantial data collection costs. In contrast, our method dynamically
allocates sampling effort based on the specific test instance, enabling
significant gains in sample efficiency. By iteratively refining the training
dataset conditioned on the latest prediction, the proposed strategy tailors the
dataset to the geometry of the inverse map around each test instance. We
demonstrate the effectiveness of our approach in the inverse scattering problem
under two types of structured priors. Our results show that the advantage of
the adaptive method becomes more pronounced in settings with more complex
priors or higher accuracy requirements. While our experiments focus on a
particular inverse problem, the adaptive sampling strategy is broadly
applicable and readily extends to other inverse problems, offering a scalable
and practical alternative to conventional fixed-dataset training regimes.

</details>


### [33] [Toward Faithfulness-guided Ensemble Interpretation of Neural Network](https://arxiv.org/abs/2509.04588)
*Siyu Zhang,Kenneth Mcmillan*

Main category: cs.LG

TL;DR: 提出FEI框架，通过平滑近似和新定性指标，全面提升神经网络解释的忠实度及其可视化效果。


<details>
  <summary>Details</summary>
Motivation: 为了理解和评估模型行为，对神经网络的特定推断提供可解释且忠实的解释至关重要。

Method: 引入“忠实度引导的集成解释（FEI）”框架。FEI通过对现有评估基准的分析，采用平滑近似来提升量化忠实度分数。该框架还包含FEI的变体，旨在增强隐藏层编码的忠实度。此外，提出了一种评估隐藏层忠实度的新颖定性指标。

Result: 在广泛实验中，FEI在定性可视化和量化忠实度分数上均显著超越了现有方法。

Conclusion: 本研究建立了一个提升神经网络解释忠实度的全面框架，强调其广度和精确性。

Abstract: Interpretable and faithful explanations for specific neural inferences are
crucial for understanding and evaluating model behavior. Our work introduces
\textbf{F}aithfulness-guided \textbf{E}nsemble \textbf{I}nterpretation
(\textbf{FEI}), an innovative framework that enhances the breadth and
effectiveness of faithfulness, advancing interpretability by providing superior
visualization. Through an analysis of existing evaluation benchmarks,
\textbf{FEI} employs a smooth approximation to elevate quantitative
faithfulness scores. Diverse variations of \textbf{FEI} target enhanced
faithfulness in hidden layer encodings, expanding interpretability.
Additionally, we propose a novel qualitative metric that assesses hidden layer
faithfulness. In extensive experiments, \textbf{FEI} surpasses existing
methods, demonstrating substantial advances in qualitative visualization and
quantitative faithfulness scores. Our research establishes a comprehensive
framework for elevating faithfulness in neural network explanations,
emphasizing both breadth and precision

</details>


### [34] [Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction](https://arxiv.org/abs/2509.04601)
*Han Zhang,Fengji Ma,Jiamin Su,Xinyue Yang,Lei Wang,Wen-Cai Ye,Li Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为QW-MTL的统一量子增强和任务加权多任务学习框架，用于ADMET分类任务，该框架结合了量子化学描述符和动态任务加权方案，显著优于单任务基线。


<details>
  <summary>Details</summary>
Motivation: 现有的ADMET预测方法主要依赖单任务学习（STL），未能充分利用任务间的互补性，并且独立训练和推断每个任务需要更多的计算资源。

Method: 研究者提出了QW-MTL框架，它基于Chemprop-RDKit骨干网络，通过引入量子化学描述符来丰富分子表示，并设计了一种新型的指数任务加权方案，结合数据集规模先验和可学习参数实现任务间动态损失平衡。这是首次在所有13个TDC分类基准上系统性地进行联合多任务训练，并采用排行榜式数据划分进行评估。

Result: 实验结果表明，QW-MTL在13个任务中的12个上显著优于单任务基线，实现了高预测性能，同时保持了最小的模型复杂度和快速推理。

Conclusion: 量子信息特征和自适应任务加权增强的多任务分子学习在ADMET预测中表现出有效性和高效率。

Abstract: Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and
Toxicity) plays a crucial role in drug discovery and development, accelerating
the screening and optimization of new drugs. Existing methods primarily rely on
single-task learning (STL), which often fails to fully exploit the
complementarities between tasks. Besides, it requires more computational
resources while training and inference of each task independently. To address
these issues, we propose a new unified Quantum-enhanced and task-Weighted
Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET
classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts
quantum chemical descriptors to enrich molecular representations with
additional information about the electronic structure and interactions.
Meanwhile, it introduces a novel exponential task weighting scheme that
combines dataset-scale priors with learnable parameters to achieve dynamic loss
balancing across tasks. To the best of our knowledge, this is the first work to
systematically conduct joint multi-task training across all 13 Therapeutics
Data Commons (TDC) classification benchmarks, using leaderboard-style data
splits to ensure a standardized and realistic evaluation setting. Extensive
experimental results show that QW-MTL significantly outperforms single-task
baselines on 12 out of 13 tasks, achieving high predictive performance with
minimal model complexity and fast inference, demonstrating the effectiveness
and efficiency of multi-task molecular learning enhanced by quantum-informed
features and adaptive task weighting.

</details>


### [35] [Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families](https://arxiv.org/abs/2509.04622)
*Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 本研究首次系统性比较了不同表征相似性度量在区分神经网络模型家族方面的能力，发现度量施加的对齐约束越严格，区分能力越强，其中软匹配法表现最佳，为选择合适的度量提供了依据。


<details>
  <summary>Details</summary>
Motivation: 表征相似性度量是神经科学和人工智能领域的关键工具，但目前缺乏对其在不同模型家族（涵盖多种架构和训练范式）间区分能力进行系统性比较的研究。

Method: 研究引入了一个定量框架，通过评估表征相似性度量区分不同模型家族（包括CNNs, Vision Transformers, Swin Transformers, ConvNeXt等架构，以及监督学习和自监督学习等训练方式）的能力来进行评估。采用信号检测理论的d'、轮廓系数和ROC-AUC三种可分离性度量，系统性地评估了RSA、线性预测性、Procrustes对齐和软匹配等常用相似性度量的判别性能。

Result: 研究发现，当相似性度量施加更严格的对齐约束时，模型家族间的可分离性会系统性增强。在基于映射的方法中，软匹配法实现了最高的可分离性，其次是Procrustes对齐和线性预测性。非拟合方法（如RSA）也在不同模型家族间展现出很强的可分离性。

Conclusion: 这些发现首次从可分离性视角对相似性度量进行了系统比较，明确了它们各自的相对敏感性，为在大规模模型和脑比较研究中选择合适的度量提供了重要指导。

Abstract: Representational similarity metrics are fundamental tools in neuroscience and
AI, yet we lack systematic comparisons of their discriminative power across
model families. We introduce a quantitative framework to evaluate
representational similarity measures based on their ability to separate model
families-across architectures (CNNs, Vision Transformers, Swin Transformers,
ConvNeXt) and training regimes (supervised vs. self-supervised). Using three
complementary separability measures-dprime from signal detection theory,
silhouette coefficients and ROC-AUC, we systematically assess the
discriminative capacity of commonly used metrics including RSA, linear
predictivity, Procrustes, and soft matching. We show that separability
systematically increases as metrics impose more stringent alignment
constraints. Among mapping-based approaches, soft-matching achieves the highest
separability, followed by Procrustes alignment and linear predictivity.
Non-fitting methods such as RSA also yield strong separability across families.
These results provide the first systematic comparison of similarity metrics
through a separability lens, clarifying their relative sensitivity and guiding
metric choice for large-scale model and brain comparisons.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [36] [NEXUS: Efficient and Scalable Multi-Cell mmWave Baseband Processing with Heterogeneous Compute](https://arxiv.org/abs/2509.04625)
*Zhenzhou Qi,Chung-Hsuan Tung,Zhihui Gao,Tingjun Chen*

Main category: cs.NI

TL;DR: NEXUS是首个在单服务器上实现实时、虚拟化多小区毫米波基带处理的系统，它通过异构计算资源和自适应调度，实现了高吞吐量和资源效率。


<details>
  <summary>Details</summary>
Motivation: 5G NR（尤其是毫米波频段）对基带处理的灵活性、可扩展性和效率提出了严格要求。尽管vRAN支持动态频谱共享，但在多小区、异构工作负载场景下，基带处理的计算资源分配仍未得到充分探索。

Method: 该研究提出了NEXUS系统。它将软件定义信号处理与硬件加速（LDPC解码）相结合，并引入了通过虚拟功能（VF）在多个CPU核心间共享Intel ACC100 eASIC的新框架。对于单小区操作，NEXUS使用基于随机森林（RAF）的模型预测最节能的资源分配。对于多小区场景，NEXUS引入了一个功耗感知调度器，结合轻量级竞争模型来调整并发执行下的资源分配策略。

Result: NEXUS在各种FR2小区配置下进行了广泛评估，结果表明它在满负荷下支持多达16个并发小区，实现了5.37Gbps的总吞吐量，并能将多小区调度的搜索空间减少数个数量级。单小区模型实现了微秒级的推理延迟和高精度。

Conclusion: 研究结果表明，虚拟化、资源感知的基带处理对于下一代vRAN系统是实用且高效的。

Abstract: The rapid adoption of 5G New Radio (NR), particularly in the millimeter-wave
(mmWave) spectrum, imposes stringent demands on the flexibility, scalability,
and efficiency of baseband processing. While virtualized Radio Access Networks
(vRANs) enable dynamic spectrum sharing across cells, compute resource
allocation for baseband processing, especially in multi-cell deployments with
heterogeneous workloads, remains underexplored. In this paper, we present
NEXUS, the first system to realize real-time, virtualized multi-cell mmWave
baseband processing on a single server with heterogeneous compute resources.
NEXUS integrates software-based digital signal processing pipelines with
hardware-accelerated LDPC decoding, and introduces a novel framework for
sharing Intel's ACC100 eASIC across multiple CPU cores via virtual functions
(VFs). For single-cell operation, NEXUS employs a random forest (RAF)-based
model that predicts the most energy-efficient resource allocation for the given
cell configuration with microsecond-level inference latency and high accuracy.
For multi-cell scenarios, NEXUS introduces a power-aware scheduler that
incorporates a lightweight contention model to adjust resource allocation
strategies under concurrent execution. Through extensive evaluation across
various Frequency Range 2 (FR2) cell configurations, we show that NEXUS
supports up to 16 concurrent cells under full load, achieving 5.37Gbps
aggregate throughput, while reducing the multi-cell scheduling search space by
orders of magnitude. These results demonstrate that virtualized, resource-aware
baseband processing is both practical and efficient for next-generation vRAN
systems.

</details>


### [37] [Path Dynamics in a Deployed Path-Aware Network: A Measurement Study of SCIONLab](https://arxiv.org/abs/2509.04695)
*Lars Herschbach,Damien Rossi,Sina Keshvadi*

Main category: cs.NI

TL;DR: 对SCIONLab测试床的长期测量研究揭示了路径感知网络中路径的动态性、高流失率、不对称性及性能权衡，挑战了多路径协议设计的现有假设。


<details>
  <summary>Details</summary>
Motivation: 路径感知网络有望通过多路径传输提升性能和弹性，但缺乏对其真实世界动态的实证数据，阻碍了有效协议（如Multipath QUIC）的设计。

Method: 本文对全球SCIONLab测试床上的SCION架构进行了纵向测量研究，以表征对多路径协议至关重要的路径稳定性、多样性和性能。

Result: 测量揭示了动态环境，部分测试床存在显著的控制平面流失和短暂的路径生命周期。研究识别并表征了路径差异，即路由策略导致端点间路径可用性不对称。此外，观察到一种性能权衡：并发多路径传输可提高总吞吐量，但可能降低单个路径的延迟和可靠性。

Conclusion: 这些发现表明，如Multipath QUIC等协议在设计时应明确考虑高流失率和路径不对称性，这挑战了多路径协议设计的常见假设。

Abstract: Path-aware networks promise enhanced performance and resilience through
multipath transport, but a lack of empirical data on their real-world dynamics
hinders the design of effective protocols. This paper presents a longitudinal
measurement study of the SCION architecture on the global SCIONLab testbed,
characterizing the path stability, diversity, and performance crucial for
protocols like Multipath QUIC (MPQUIC). Our measurements reveal a dynamic
environment, with significant control-plane churn and short path lifetimes in
parts of the testbed. We identify and characterize path discrepancy, a
phenomenon where routing policies create asymmetric path availability between
endpoints. Furthermore, we observe a performance trade-off where concurrent
multipath transmissions can improve aggregate throughput but may degrade the
latency and reliability of individual paths. These findings demonstrate that
protocols such as MPQUIC should explicitly account for high churn and path
asymmetry, challenging common assumptions in multipath protocol design.

</details>


### [38] [Where Have All the Firewalls Gone? Security Consequences of Residential IPv6 Transition](https://arxiv.org/abs/2509.04792)
*Erik Rye,Dave Levin,Robert Beverly*

Main category: cs.NI

TL;DR: 研究表明，随着住宅网络从IPv4转向IPv6并移除NAT，之前作为事实防火墙的NAT功能消失，导致更多家庭设备（如打印机、iPhone、智能灯）直接暴露在互联网上，大大增加了下一代IPv6物联网僵尸网络的攻击面。


<details>
  <summary>Details</summary>
Motivation: 探究从IPv4到IPv6的过渡是否会增加住宅网络被攻击的脆弱性，并助长下一代基于IPv6的物联网僵尸网络，因为IPv4的NAT默认拒绝入站连接的能力将不复存在。

Method: 引入一种可在低资源设备上运行的大规模IPv6扫描方法，并用此方法对住宅IPv6网络进行了迄今为止最大规模的测量，比较了与可比IPv4网络相比，哪些设备是公开可访问的。

Result: 从118个国家的2,436个AS中的1400万个独立的住宅IPv6地址（非外部网关）收到了响应。这些响应来自物联网僵尸网络常利用的协议以及终端用户设备协议。结果显示，与IPv4全网扫描相比，通过IPv6可以访问到更多的打印机、iPhone和智能灯。

Conclusion: NAT确实充当了互联网的实际防火墙。住宅网络从IPv4向IPv6的过渡正在使新设备暴露于攻击之下，为未来的物联网僵尸网络提供了更多目标。

Abstract: IPv4 NAT has limited the spread of IoT botnets considerably by
default-denying bots' incoming connection requests to in-home devices unless
the owner has explicitly allowed them. As the Internet transitions to majority
IPv6, however, residential connections no longer require the use of NAT. This
paper therefore asks: has the transition from IPv4 to IPv6 ultimately made
residential networks more vulnerable to attack, thereby empowering the next
generation of IPv6-based IoT botnets? To answer this question, we introduce a
large-scale IPv6 scanning methodology that, unlike those that rely on AI, can
be run on low-resource devices common in IoT botnets. We use this methodology
to perform the largest-scale measurement of IPv6 residential networks to date,
and compare which devices are publicly accessible to comparable IPv4 networks.
We were able to receive responses from 14.0M distinct IPv6 addresses inside of
residential networks (i.e., not the external-facing gateway), in 2,436 ASes
across 118 countries. These responses come from protocols commonly exploited by
IoT botnets (including telnet and FTP), as well as protocols typically
associated with end-user devices (including iPhone-Sync and IPP). Comparing to
IPv4, we show that we are able to reach more printers, iPhones, and smart
lights over IPv6 than full IPv4-wide scans could. Collectively, our results
show that NAT has indeed acted as the de facto firewall of the Internet, and
the v4-to-v6 transition of residential networks is opening up new devices to
attack.

</details>
