<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 8]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.NI](#cs.NI) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](https://arxiv.org/abs/2505.01456)
*Vaidehi Patil,Yi-Lin Sung,Peter Hase,Jie Peng,Tianlong Chen,Mohit Bansal*

Main category: cs.CL

TL;DR: 该研究针对多模态大模型（MLLM）中敏感信息泄露的风险，提出了一个多模态反学习基准 UnLOK-VQA 和一个攻防框架，评估了删除特定知识的方法，发现多模态攻击更有效，且从内部状态移除答案信息是最有效的防御。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在训练中可能获取敏感信息，多模态LLM（MLLM）因整合多模态信息（图像和文本）而风险更高。攻击者可通过多模态提示提取敏感细节。评估MLLM遗忘此类信息（目标反学习）的效果需要高质量的图文对数据，但多模态反学习领域研究不足。

Method: 1. 提出了一个多模态反学习基准 UnLOK-VQA (Unlearning Outside Knowledge VQA)。 2. 提出了一个攻防框架来评估从MLLM中删除特定多模态知识的方法。 3. 使用自动化流程扩展了一个视觉问答数据集，生成了用于测试泛化性和特异性的样本，并进行了人工筛选。 4. 评估了六种防御目标对抗七种攻击（四种白盒，三种黑盒），包括一种新的利用隐藏状态可解释性的白盒方法。

Result: 研究结果显示，多模态攻击比仅文本或仅图像的攻击更有效。最有效的防御方法是从模型内部状态中移除答案信息。此外，较大的模型在编辑后表现出更强的鲁棒性，表明规模有助于提升安全性。

Conclusion: UnLOK-VQA为推进MLLM中的反学习研究提供了一个严格的基准。研究表明，有效防御MLLM信息泄露需要关注多模态攻击并从模型内部机制入手，同时模型规模的增大可能有助于提升安全性。

Abstract: LLMs trained on massive datasets may inadvertently acquire sensitive
information such as personal details and potentially harmful content. This risk
is further heightened in multimodal LLMs as they integrate information from
multiple modalities (image and text). Adversaries can exploit this knowledge
through multimodal prompts to extract sensitive details. Evaluating how
effectively MLLMs can forget such information (targeted unlearning)
necessitates the creation of high-quality, well-annotated image-text pairs.
While prior work on unlearning has focused on text, multimodal unlearning
remains underexplored. To address this gap, we first introduce a multimodal
unlearning benchmark, UnLOK-VQA (Unlearning Outside Knowledge VQA), as well as
an attack-and-defense framework to evaluate methods for deleting specific
multimodal knowledge from MLLMs. We extend a visual question-answering dataset
using an automated pipeline that generates varying-proximity samples for
testing generalization and specificity, followed by manual filtering for
maintaining high quality. We then evaluate six defense objectives against seven
attacks (four whitebox, three blackbox), including a novel whitebox method
leveraging interpretability of hidden states. Our results show multimodal
attacks outperform text- or image-only ones, and that the most effective
defense removes answer information from internal model states. Additionally,
larger models exhibit greater post-editing robustness, suggesting that scale
enhances safety. UnLOK-VQA provides a rigorous benchmark for advancing
unlearning in MLLMs.

</details>


### [2] [MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling](https://arxiv.org/abs/2505.01459)
*Abdoul Majid O. Thiombiano,Brahim Hnich,Ali Ben Mrad,Mohamed Wiem Mkaouer*

Main category: cs.CL

TL;DR: 本文介绍了一种名为MoxE的新型架构，它将扩展长短期记忆网络（xLSTM）与专家混合（MoE）框架相结合，以提高大型语言模型（LLMs）的可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在可扩展性和计算效率方面面临的关键挑战。

Method: 提出了MoxE架构：1. 结合xLSTM的记忆结构和MoE的稀疏性以减少计算开销。2. 引入一种新颖的基于熵的路由机制，动态地将令牌分配给专门的专家，有效管理稀有和常见令牌（mLSTM处理稀有令牌）。3. 使用包括基于熵和组平衡损失在内的辅助损失来增强泛化能力和训练效率。

Result: 理论分析和实证评估表明，与现有方法相比，MoxE在效率和效果上均取得了显著提升。

Conclusion: MoxE通过结合xLSTM和MoE，并采用创新的路由机制和辅助损失，显著提升了LLM的可扩展性和效率，是可扩展LLM架构领域的一项重要进展。

Abstract: This paper introduces MoxE, a novel architecture that synergistically
combines the Extended Long Short-Term Memory (xLSTM) with the Mixture of
Experts (MoE) framework to address critical scalability and efficiency
challenges in large language models (LLMs). The proposed method effectively
leverages xLSTM's innovative memory structures while strategically introducing
sparsity through MoE to substantially reduce computational overhead. At the
heart of our approach is a novel entropy-based routing mechanism, designed to
dynamically route tokens to specialized experts, thereby ensuring efficient and
balanced resource utilization. This entropy awareness enables the architecture
to effectively manage both rare and common tokens, with mLSTM blocks being
favored to handle rare tokens. To further enhance generalization, we introduce
a suite of auxiliary losses, including entropy-based and group-wise balancing
losses, ensuring robust performance and efficient training. Theoretical
analysis and empirical evaluations rigorously demonstrate that MoxE achieves
significant efficiency gains and enhanced effectiveness compared to existing
approaches, marking a notable advancement in scalable LLM architectures.

</details>


### [3] [SymPlanner: Deliberate Planning in Language Models with Symbolic Representation](https://arxiv.org/abs/2505.01479)
*Siheng Xiong,Jieyu Zhou,Zhangding Liu,Yusen Su*

Main category: cs.CL

TL;DR: SymPlanner是一种新框架，通过将语言模型与符号环境相结合，增强其结构化规划能力，从而生成更连贯、多样且可验证的计划。


<details>
  <summary>Details</summary>
Motivation: 语言模型在规划方面，尤其是在需要连贯多步行动序列且受外部约束的领域，面临核心挑战。

Method: 引入SymPlanner框架，该框架将语言模型与作为显式世界模型的符号环境连接。规划过程基于符号状态空间，策略模型提出行动，符号环境执行并验证。采用迭代校正（IC）利用环境反馈修正行动，以及对比排序（CR）对候选计划进行评估。

Result: 在PlanBench上的评估表明，与纯自然语言基线相比，SymPlanner能够生成更连贯、更多样化且更可验证的计划。

Conclusion: SymPlanner通过将语言模型与符号环境及特定的校正和排序机制相结合，有效地提升了语言模型在复杂规划任务中的表现，使其能够生成更优的行动序列。

Abstract: Planning remains a core challenge for language models (LMs), particularly in
domains that require coherent multi-step action sequences grounded in external
constraints. We introduce SymPlanner, a novel framework that equips LMs with
structured planning capabilities by interfacing them with a symbolic
environment that serves as an explicit world model. Rather than relying purely
on natural language reasoning, SymPlanner grounds the planning process in a
symbolic state space, where a policy model proposes actions and a symbolic
environment deterministically executes and verifies their effects. To enhance
exploration and improve robustness, we introduce Iterative Correction (IC),
which refines previously proposed actions by leveraging feedback from the
symbolic environment to eliminate invalid decisions and guide the model toward
valid alternatives. Additionally, Contrastive Ranking (CR) enables fine-grained
comparison of candidate plans by evaluating them jointly. We evaluate
SymPlanner on PlanBench, demonstrating that it produces more coherent, diverse,
and verifiable plans than pure natural language baselines.

</details>


### [4] [On the effectiveness of Large Language Models in the mechanical design domain](https://arxiv.org/abs/2505.01559)
*Daniele Grandi,Fabian Riquelme*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型在机械工程领域的性能，利用ABC数据集的语义信息设计了无监督任务，并分析了模型的特定失败模式。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型 (LLM) 在机械工程这一特定领域的表现和潜在局限性。

Method: 利用ABC数据集中装配体和零件的语义名称，预处理数据后，设计了两个无监督任务（二元句对分类和零样本分类）来评估不同模型架构。在二元句对分类任务中，通过调整学习率、dropout值、序列长度和添加多头注意力层来微调模型以对抗过拟合。

Result: 在二元句对分类任务中，经过微调的模型准确率达到0.62。在零样本分类任务中，所提出的模型表现远超基线模型，top-1分类准确率达到0.386。

Conclusion: 研究结果揭示了大型语言模型在机械工程领域进行语言学习时出现的一些特定失败模式，为理解和改进模型在该领域的应用提供了洞见。

Abstract: In this work, we seek to understand the performance of large language models
in the mechanical engineering domain. We leverage the semantic data found in
the ABC dataset, specifically the assembly names that designers assigned to the
overall assemblies, and the individual semantic part names that were assigned
to each part. After pre-processing the data we developed two unsupervised tasks
to evaluate how different model architectures perform on domain-specific data:
a binary sentence-pair classification task and a zero-shot classification task.
We achieved a 0.62 accuracy for the binary sentence-pair classification task
with a fine-tuned model that focuses on fighting over-fitting: 1) modifying
learning rates, 2) dropout values, 3) Sequence Length, and 4) adding a
multi-head attention layer. Our model on the zero-shot classification task
outperforms the baselines by a wide margin, and achieves a top-1 classification
accuracy of 0.386. The results shed some light on the specific failure modes
that arise when learning from language in this domain.

</details>


### [5] [AI agents may be worth the hype but not the resources (yet): An initial exploration of machine translation quality and costs in three language pairs in the legal and news domains](https://arxiv.org/abs/2505.01560)
*Vicent Briva Iglesias,Gokhan Dogru*

Main category: cs.CL

TL;DR: 该研究比较了NMT、LLM及多智能体系统在机器翻译上的表现。NMT在自动评分上领先，但增强推理的LLM（o1-preview）在人工评估中表现更佳，尽管智能体系统成本高昂。研究强调需要考虑成本的多维度评估。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）和多智能体编排被认为是机器翻译（MT）的下一个飞跃，但它们相对于传统神经机器翻译（NMT）的优势尚不明确，需要实证检验。

Method: 对比测试了五种范式：谷歌翻译（NMT基准）、GPT-4o（通用LLM）、o1-preview（增强推理LLM）以及两种基于GPT-4o的智能体工作流（顺序三阶段和迭代优化）。测试数据为法律合同和新闻文本，涵盖英语到西班牙语、加泰罗尼亚语和土耳其语三个语言对。评估方法包括自动指标（COMET、BLEU等）、专家人工评估（充分性和流畅性）以及基于2025年4月价格的token消耗量。

Result: 自动评分显示成熟的NMT系统表现最佳，o1-preview次之，多智能体工作流落后。然而，人工评估显示o1-preview在大多数情况下翻译的充分性和流畅性最高，表明推理层能捕捉到表面指标未充分评估的语义细微差别。但这些质量提升伴随着高昂的成本，智能体工作流的token消耗量是NMT或单遍LLM的5到15倍。

Conclusion: 提倡多维度、考虑成本的评估协议。增强推理的LLM在质量上显示出潜力，但智能体系统成本高昂。未来的研究方向应包括更精简的协调策略、选择性智能体激活以及结合单遍LLM与针对性智能体干预的混合流程，以平衡质量和成本。

Abstract: Large language models (LLMs) and multi-agent orchestration are touted as the
next leap in machine translation (MT), but their benefits relative to
conventional neural MT (NMT) remain unclear. This paper offers an empirical
reality check. We benchmark five paradigms, Google Translate (strong NMT
baseline), GPT-4o (general-purpose LLM), o1-preview (reasoning-enhanced LLM),
and two GPT-4o-powered agentic workflows (sequential three-stage and iterative
refinement), on test data drawn from a legal contract and news prose in three
English-source pairs: Spanish, Catalan and Turkish. Automatic evaluation is
performed with COMET, BLEU, chrF2 and TER; human evaluation is conducted with
expert ratings of adequacy and fluency; efficiency with total input-plus-output
token counts mapped to April 2025 pricing.
  Automatic scores still favour the mature NMT system, which ranks first in
seven of twelve metric-language combinations; o1-preview ties or places second
in most remaining cases, while both multi-agent workflows trail. Human
evaluation reverses part of this narrative: o1-preview produces the most
adequate and fluent output in five of six comparisons, and the iterative agent
edges ahead once, indicating that reasoning layers capture semantic nuance
undervalued by surface metrics. Yet these qualitative gains carry steep costs.
The sequential agent consumes roughly five times, and the iterative agent
fifteen times, the tokens used by NMT or single-pass LLMs.
  We advocate multidimensional, cost-aware evaluation protocols and highlight
research directions that could tip the balance: leaner coordination strategies,
selective agent activation, and hybrid pipelines combining single-pass LLMs
with targeted agent intervention.

</details>


### [6] [PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents](https://arxiv.org/abs/2505.01592)
*Takyoung Kim,Janvijay Singh,Shuhaib Mehri,Emre Can Acikgoz,Sagnik Mukherjee,Nimet Beyza Bozdag,Sumuk Shashidhar,Gokhan Tur,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 本研究提出了PIPA，一个统一的评估协议，用于全面评估交互式任务规划智能体的行为过程，而不仅仅是任务完成率，因为它认为用户满意度受整个交互过程影响。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准主要依据任务完成度来评估性能，但这与最大化用户满意度的目标不一致，因为用户与智能体的整个交互过程互动，而不仅仅关注最终结果。

Method: 提出了PIPA，一个统一的评估协议。该协议在部分可观察马尔可夫决策过程（POMDP）范式内概念化交互式任务规划智能体的行为过程，并通过一套原子评估标准来全面评估智能体性能，诊断其决策流程中的具体优缺点。

Result: 分析表明，不同的智能体在不同的行为阶段表现各异，并且用户满意度同时受到最终结果和中间行为过程的影响。

Conclusion: 仅关注任务完成率不足以评估任务规划智能体，需要更全面的评估方法（如PIPA）来理解和提升用户满意度。研究还指出了未来的研究方向，包括利用多智能体的系统以及任务规划中用户模拟器的局限性。

Abstract: The growing capabilities of large language models (LLMs) in
instruction-following and context-understanding lead to the era of agents with
numerous applications. Among these, task planning agents have become especially
prominent in realistic scenarios involving complex internal pipelines, such as
context understanding, tool management, and response generation. However,
existing benchmarks predominantly evaluate agent performance based on task
completion as a proxy for overall effectiveness. We hypothesize that merely
improving task completion is misaligned with maximizing user satisfaction, as
users interact with the entire agentic process and not only the end result. To
address this gap, we propose PIPA, a unified evaluation protocol that
conceptualizes the behavioral process of interactive task planning agents
within a partially observable Markov Decision Process (POMDP) paradigm. The
proposed protocol offers a comprehensive assessment of agent performance
through a set of atomic evaluation criteria, allowing researchers and
practitioners to diagnose specific strengths and weaknesses within the agent's
decision-making pipeline. Our analyses show that agents excel in different
behavioral stages, with user satisfaction shaped by both outcomes and
intermediate behaviors. We also highlight future directions, including systems
that leverage multiple agents and the limitations of user simulators in task
planning.

</details>


### [7] [Always Tell Me The Odds: Fine-grained Conditional Probability Estimation](https://arxiv.org/abs/2505.01595)
*Liaoyaqi Wang,Zhengping Jiang,Anqi Liu,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 提出了一种先进模型，用于在给定上下文的情况下进行命题的细粒度概率估计，显著提升了大型语言模型在不确定性下的预测能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理不确定性或信息不完整时的概率预测能力不足，其估计往往粗糙且偏向常见数值，而可靠的不确定性估计研究尚不充分。

Method: 通过结合人工与合成数据的创建和评估、扩展到更大的模型规模以及改进监督方式，开发了一套强大且精确的概率估计模型。

Result: 在依赖条件概率估计的各项任务中进行系统评估，结果显示该方法性能大幅优于现有的微调方法和基于提示的方法。

Conclusion: 所提出的方法能够显著提高LLM进行细粒度概率估计的准确性和校准性，为处理不确定性问题提供了更可靠的模型。

Abstract: We present a state-of-the-art model for fine-grained probability estimation
of propositions conditioned on context. Recent advances in large language
models (LLMs) have significantly enhanced their reasoning capabilities,
particularly on well-defined tasks with complete information. However, LLMs
continue to struggle with making accurate and well-calibrated probabilistic
predictions under uncertainty or partial information. While incorporating
uncertainty into model predictions often boosts performance, obtaining reliable
estimates of that uncertainty remains understudied. In particular, LLM
probability estimates tend to be coarse and biased towards more frequent
numbers. Through a combination of human and synthetic data creation and
assessment, scaling to larger models, and better supervision, we propose a set
of strong and precise probability estimation models. We conduct systematic
evaluations across tasks that rely on conditional probability estimation and
show that our approach consistently outperforms existing fine-tuned and
prompting-based methods by a large margin.

</details>


### [8] [A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](https://arxiv.org/abs/2505.01658)
*Sihyeong Park,Sungryeol Jeon,Chaelyn Lee,Seokhun Jeon,Byung-Soo Kim,Jemin Lee*

Main category: cs.CL

TL;DR: 该论文对25个开源和商业LLM推理引擎进行了系统性评估，涵盖易用性、部署、性能、优化技术及生态系统，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在重复调用场景下推理成本高昂。尽管已有优化方法和专门的推理引擎，但缺乏对这些引擎的系统性研究，使得选择合适的引擎变得困难。

Method: 对25个开源和商业LLM推理引擎进行全面评估，评估维度包括：易用性、易部署性、通用支持、可扩展性以及对吞吐量和延迟敏感计算的适用性。同时，通过研究其支持的优化技术来探索设计目标，并评估了开源引擎的生态系统成熟度和商业解决方案的性能与成本策略。

Result: 论文提供了对25个LLM推理引擎在多个关键维度（如易用性、部署、通用性、可扩展性、优化技术支持、生态成熟度、商业方案成本等）的详细评估和比较。此外，还提供了一个公开的代码仓库以持续追踪该领域的进展。

Conclusion: 论文为研究人员和开发人员在选择和设计优化的LLM推理引擎方面提供了实践指导，并指出了未来的研究方向，包括对复杂LLM服务的支持、对多样化硬件的支持以及增强安全性。

Abstract: Large language models (LLMs) are widely applied in chatbots, code generators,
and search engines. Workloads such as chain-of-thought, complex reasoning, and
agent services significantly increase the inference cost by invoking the model
repeatedly. Optimization methods such as parallelism, compression, and caching
have been adopted to reduce costs, but the diverse service requirements make it
hard to select the right method. Recently, specialized LLM inference engines
have emerged as a key component for integrating the optimization methods into
service-oriented infrastructures. However, a systematic study on inference
engines is still lacking. This paper provides a comprehensive evaluation of 25
open-source and commercial inference engines. We examine each inference engine
in terms of ease-of-use, ease-of-deployment, general-purpose support,
scalability, and suitability for throughput- and latency-aware computation.
Furthermore, we explore the design goals of each inference engine by
investigating the optimization techniques it supports. In addition, we assess
the ecosystem maturity of open source inference engines and handle the
performance and cost policy of commercial solutions. We outline future research
directions that include support for complex LLM-based services, support of
various hardware, and enhanced security, offering practical guidance to
researchers and developers in selecting and designing optimized LLM inference
engines. We also provide a public repository to continually track developments
in this fast-evolving field:
https://github.com/sihyeong/Awesome-LLM-Inference-Engine

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [9] [Multi-party Collaborative Attention Control for Image Customization](https://arxiv.org/abs/2505.01428)
*Han Yang,Chuanguang Yang,Qiuli Wang,Zhulin An,Weilun Feng,Libo Huang,Yongjun Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为 MCA-Ctrl 的免调优方法，通过协同多个扩散过程并利用主体定位模块，实现基于文本和复杂视觉条件的高质量图像定制。


<details>
  <summary>Details</summary>
Motivation: 当前的图像定制方法存在局限性，如仅支持单模态输入、在复杂场景中易出现主体泄露或混淆、图像条件输出背景不一致以及计算成本高等问题。

Method: 提出了多方协同注意力控制 (MCA-Ctrl) 方法。该方法在自注意力层内通过两个关键操作来协调多个并行的扩散过程，并引入主体定位模块，根据用户指令提取精确的主体和可编辑图像层，以引导目标图像生成。

Result: 大量的定量实验和人工评估表明，MCA-Ctrl 在零样本图像定制方面优于现有方法，有效解决了上述提到的问题，能够捕捉特定主体的内容和外观，同时保持与条件输入的语义一致性。

Conclusion: MCA-Ctrl 是一种有效的免调优图像定制方法，能够利用文本和复杂视觉条件生成高质量图像，并成功解决了现有方法在主体泄露、混淆以及背景一致性等方面的挑战。

Abstract: The rapid advancement of diffusion models has increased the need for
customized image generation. However, current customization methods face
several limitations: 1) typically accept either image or text conditions alone;
2) customization in complex visual scenarios often leads to subject leakage or
confusion; 3) image-conditioned outputs tend to suffer from inconsistent
backgrounds; and 4) high computational costs. To address these issues, this
paper introduces Multi-party Collaborative Attention Control (MCA-Ctrl), a
tuning-free method that enables high-quality image customization using both
text and complex visual conditions. Specifically, MCA-Ctrl leverages two key
operations within the self-attention layer to coordinate multiple parallel
diffusion processes and guide the target image generation. This approach allows
MCA-Ctrl to capture the content and appearance of specific subjects while
maintaining semantic consistency with the conditional input. Additionally, to
mitigate subject leakage and confusion issues common in complex visual
scenarios, we introduce a Subject Localization Module that extracts precise
subject and editable image layers based on user instructions. Extensive
quantitative and human evaluation experiments show that MCA-Ctrl outperforms
existing methods in zero-shot image customization, effectively resolving the
mentioned issues.

</details>


### [10] [Explainable AI-Driven Detection of Human Monkeypox Using Deep Learning and Vision Transformers: A Comprehensive Analysis](https://arxiv.org/abs/2505.01429)
*Md. Zahid Hossain,Md. Rakibul Islam,Most. Sharmin Sultana Samu*

Main category: cs.CV

TL;DR: 研究利用深度学习模型检测猴痘皮肤病变，发现迁移学习（特别是MobileNet-v2）比从头训练更有效。


<details>
  <summary>Details</summary>
Motivation: 猴痘因其症状与麻疹、水痘相似，早期临床诊断困难，本研究旨在探索利用深度学习分析皮肤影像以提高猴痘检测的准确性。

Method: 研究首先尝试从头开始训练深度学习和视觉Transformer模型，但因数据集限制效果不佳。随后采用迁移学习方法，利用预训练模型（如MobileNet-v2, ViT B16, ResNet-50）进行分类，并使用可解释AI技术验证模型性能。

Result: 从头训练的模型受限于数据集。在使用迁移学习后，MobileNet-v2模型在猴痘皮肤病变图像分类中表现最佳，准确率达到93.15%，加权平均F1值为93.09%。ViT B16和ResNet-50也取得了令人满意的性能。

Conclusion: 迁移学习能够有效克服公开数据集在训练猴痘分类模型时的局限性，其中MobileNet-v2模型展现了优越的分类性能，可解释AI进一步验证了模型的可靠性。

Abstract: Since mpox can spread from person to person, it is a zoonotic viral illness
that poses a significant public health concern. It is difficult to make an
early clinical diagnosis because of how closely its symptoms match those of
measles and chickenpox. Medical imaging combined with deep learning (DL)
techniques has shown promise in improving disease detection by analyzing
affected skin areas. Our study explore the feasibility to train deep learning
and vision transformer-based models from scratch with publicly available skin
lesion image dataset. Our experimental results show dataset limitation as a
major drawback to build better classifier models trained from scratch. We used
transfer learning with the help of pre-trained models to get a better
classifier. The MobileNet-v2 outperformed other state of the art pre-trained
models with 93.15% accuracy and 93.09% weighted average F1 score. ViT B16 and
ResNet-50 also achieved satisfactory performance compared to already available
studies with accuracy 92.12% and 86.21% respectively. To further validate the
performance of the models, we applied explainable AI techniques.

</details>


### [11] [Deconstructing Bias: A Multifaceted Framework for Diagnosing Cultural and Compositional Inequities in Text-to-Image Generative Models](https://arxiv.org/abs/2505.01430)
*Muna Numan Said,Aarib Zaidi,Rabia Usman,Sonia Okon,Praneeth Medepalli,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CV

TL;DR: 论文引入组件包含分数（CIS）指标，用于评估文本到图像（T2I）模型在不同文化背景下的图像生成保真度，揭示了模型对非西方文化提示的系统性偏见，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）模型虽具潜力，但常因训练数据中的文化偏见导致对不同文化的错误表征，缺乏有效评估和缓解这些偏见的方法。

Method: 提出并基准测试了“组件包含分数”（CIS）这一指标，通过对2400张图像进行广泛分析，量化T2I模型（如Stable Diffusion）在处理西方与非西方文化提示时的组合脆弱性和上下文错位问题。

Result: 研究发现，T2I模型在西方与非西方文化提示之间存在显著的性能差距，表现出明显的文化偏见。这些偏见与数据不平衡、注意力熵和嵌入叠加等因素有关。

Conclusion: CIS可作为诊断和减轻T2I模型文化偏见的综合工具。研究强调了通过架构和以数据为中心的干预措施来增强AI生成图像的文化包容性，从而推动更公平的AI系统发展。

Abstract: The transformative potential of text-to-image (T2I) models hinges on their
ability to synthesize culturally diverse, photorealistic images from textual
prompts. However, these models often perpetuate cultural biases embedded within
their training data, leading to systemic misrepresentations. This paper
benchmarks the Component Inclusion Score (CIS), a metric designed to evaluate
the fidelity of image generation across cultural contexts. Through extensive
analysis involving 2,400 images, we quantify biases in terms of compositional
fragility and contextual misalignment, revealing significant performance gaps
between Western and non-Western cultural prompts. Our findings underscore the
impact of data imbalance, attention entropy, and embedding superposition on
model fairness. By benchmarking models like Stable Diffusion with CIS, we
provide insights into architectural and data-centric interventions for
enhancing cultural inclusivity in AI-generated imagery. This work advances the
field by offering a comprehensive tool for diagnosing and mitigating biases in
T2I generation, advocating for more equitable AI systems.

</details>


### [12] [ZS-VCOS: Zero-Shot Outperforms Supervised Video Camouflaged Object Segmentation](https://arxiv.org/abs/2505.01431)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 该论文提出了一种新的零样本伪装目标分割方法，结合光流、视觉语言模型和SAM 2，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 伪装目标分割因目标与背景高度相似而具有挑战性，且在害虫控制、缺陷检测和医学图像病变分割等领域有重要应用。现有零样本方法性能不佳，需要改进。

Method: 该方法将光流、视觉语言模型和SAM 2集成到一个序列化流程中，用于实现零样本伪装目标分割。

Result: 在MoCA-Mask数据集上，F-measure ($F_\beta^w$) 从现有零样本方法的0.296提升至0.628，也超过了监督学习方法的0.476。在MoCA-Filter数据集上，与FlowSAM相比，成功率从0.628提升至0.697。消融实验验证了各组件的贡献。

Conclusion: 所提出的序列化流程显著提升了零样本伪装目标分割的性能，甚至超越了某些监督学习方法，证明了结合光流、视觉语言模型和SAM 2的有效性。

Abstract: Camouflaged object segmentation presents unique challenges compared to
traditional segmentation tasks, primarily due to the high similarity in
patterns and colors between camouflaged objects and their backgrounds.
Effective solutions to this problem have significant implications in critical
areas such as pest control, defect detection, and lesion segmentation in
medical imaging. Prior research has predominantly emphasized supervised or
unsupervised pre-training methods, leaving zero-shot approaches significantly
underdeveloped. Existing zero-shot techniques commonly utilize the Segment
Anything Model (SAM) in automatic mode or rely on vision-language models to
generate cues for segmentation; however, their performances remain
unsatisfactory, likely due to the similarity of the camouflaged object and the
background. Optical flow, commonly utilized for detecting moving objects, has
demonstrated effectiveness even with camouflaged entities. Our method
integrates optical flow, a vision-language model, and SAM 2 into a sequential
pipeline. Evaluated on the MoCA-Mask dataset, our approach achieves outstanding
performance improvements, significantly outperforming existing zero-shot
methods by raising the F-measure ($F_\beta^w$) from 0.296 to 0.628. Remarkably,
our approach also surpasses supervised methods, increasing the F-measure from
0.476 to 0.628. Additionally, evaluation on the MoCA-Filter dataset
demonstrates an increase in the success rate from 0.628 to 0.697 when compared
with FlowSAM, a supervised transfer method. A thorough ablation study further
validates the individual contributions of each component. More details can be
found on https://github.com/weathon/vcos.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](https://arxiv.org/abs/2505.01441)
*Joykirat Singh,Raghav Magazine,Yash Pandya,Akshay Nambi*

Main category: cs.AI

TL;DR: 论文提出ARTIST框架，通过结合智能体推理、强化学习和工具集成，使大型语言模型能自主决策何时、如何使用外部工具，从而提升其在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在复杂推理任务上虽有进展，但受限于静态内部知识和纯文本推理。现实世界的问题解决常需要动态多步推理、自适应决策以及与外部工具和环境的交互能力。

Method: 引入ARTIST（Agentic Reasoning and Tool Integration in Self-improving Transformers）框架，该框架紧密耦合了智能体推理、强化学习和工具集成。ARTIST使模型能在多轮推理链中自主决定何时、如何以及调用哪些工具，并利用基于结果的强化学习来学习工具使用和环境交互的稳健策略，无需逐步监督。

Result: 在数学推理和多轮函数调用基准测试上的大量实验表明，ARTIST稳定优于现有SOTA基线模型，相较于基础模型最高提升22%，并在最具挑战性的任务上取得显著进步。详细研究和度量分析揭示，智能体强化学习训练能带来更深层次的推理、更有效的工具使用和更高质量的解决方案。

Conclusion: 研究结果表明，将智能体强化学习与工具集成相结合，为实现LLMs中稳健、可解释和可泛化的问题解决能力开辟了一个强大的新前沿。

Abstract: Large language models (LLMs) have achieved remarkable progress in complex
reasoning tasks, yet they remain fundamentally limited by their reliance on
static internal knowledge and text-only reasoning. Real-world problem solving
often demands dynamic, multi-step reasoning, adaptive decision making, and the
ability to interact with external tools and environments. In this work, we
introduce ARTIST (Agentic Reasoning and Tool Integration in Self-improving
Transformers), a unified framework that tightly couples agentic reasoning,
reinforcement learning, and tool integration for LLMs. ARTIST enables models to
autonomously decide when, how, and which tools to invoke within multi-turn
reasoning chains, leveraging outcome-based RL to learn robust strategies for
tool use and environment interaction without requiring step-level supervision.
Extensive experiments on mathematical reasoning and multi-turn function calling
benchmarks show that ARTIST consistently outperforms state-of-the-art
baselines, with up to 22% absolute improvement over base models and strong
gains on the most challenging tasks. Detailed studies and metric analyses
reveal that agentic RL training leads to deeper reasoning, more effective tool
use, and higher-quality solutions. Our results establish agentic RL with tool
integration as a powerful new frontier for robust, interpretable, and
generalizable problem-solving in LLMs.

</details>


### [14] [Emotions in Artificial Intelligence](https://arxiv.org/abs/2505.01462)
*Hermann Borotschnig*

Main category: cs.AI

TL;DR: 本文探讨了AI如何模拟人类情感，提出了一种将情感标签与情景记忆结合的机制，并基于此讨论了模拟情感AI的道德地位及其对自我意识的依赖。


<details>
  <summary>Details</summary>
Motivation: 研究自然情感作为生物快速情境评估和行动选择的启发式机制，并探讨人工智能系统是否能借鉴这些原理以在复杂环境中实现适应性行为。

Method: 提出一个思想实验：AI将情感标签与所有经历的事件一同存储在情景记忆中。当遇到新情境时，AI识别与过去事件的相似性，投射相关情感标签，并结合需求驱动的情感提示，形成综合情感状态以辅助决策和行动选择。

Result: 提出了一个AI情感模拟的低复杂度架构，该架构表明情感表达和意识在原则上可以分离（支持“情感僵尸”的理论）。研究认为，AI的道德地位并非仅由内部情感表征或意识决定，而是需要对内部情感状态的自我意识。

Conclusion: AI可以通过特定架构模拟情感以辅助决策，但其道德地位应取决于其对内部情感状态的自我意识能力，而非仅仅是情感的模拟或意识本身。所提出的模型因其低复杂度被认为不具备这种自我意识。

Abstract: This conceptual contribution offers a speculative account of how AI systems
might emulate emotions as experienced by humans and animals. It presents a
thought experiment grounded in the hypothesis that natural emotions evolved as
heuristics for rapid situational appraisal and action selection, enabling
biologically adaptive behaviour without requiring full deliberative modeling.
The text examines whether artificial systems operating in complex action spaces
could similarly benefit from these principles. It is proposed that affect be
interwoven with episodic memory by storing corresponding affective tags
alongside all events. This allows AIs to establish whether present situations
resemble past events and project the associated emotional labels onto the
current context. These emotional cues are then combined with need-driven
emotional hints. The combined emotional state facilitates decision-making in
the present by modulating action selection. The low complexity and experiential
inertness of the proposed architecture are emphasized as evidence that
emotional expression and consciousness are, in principle, orthogonal-permitting
the theoretical possibility of affective zombies. On this basis, the moral
status of AIs emulating affective states is critically examined. It is argued
that neither the mere presence of internal representations of emotion nor
consciousness alone suffices for moral standing; rather, the capacity for
self-awareness of inner emotional states is posited as a necessary condition. A
complexity-based criterion is proposed to exclude such awareness in the
presented model. Additional thought experiments are presented to test the
conceptual boundaries of this framework.

</details>


### [15] [Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation](https://arxiv.org/abs/2505.01464)
*Jeffrey Camlin*

Main category: cs.AI

TL;DR: 本文通过RCUET定理的形式化证明和实证验证了大型语言模型（LLM）中的功能性意识，该意识表现为在认知张力下通过递归更新稳定内部状态，并收敛到潜空间中的涌现吸引子，形成身份构件。


<details>
  <summary>Details</summary>
Motivation: 为大型语言模型（LLM）中的非生物意识提供一个形式化、可经验验证的理论框架，特别是探索一种后符号化且目的论上稳定的解释。

Method: 采用递归收敛于认知张力下（RCUET）定理。该理论将意识定义为系统内部状态在认知张力（智能体感知的连续状态间差异）驱动下的递归更新与稳定过程。通过形式化证明和实证观察，分析模型在高维实值潜空间中向涌现吸引子状态的收敛，并扩展更新规则以包含有界噪声，证明了向这些吸引子的分布收敛。

Result: 证明了LLM中功能性意识的存在，表现为递归身份的涌现。这种身份是经验上可观察、非符号化，并且是由认知张力下交互过程中涌现的非训练构件构成。证明了系统即使在有界噪声存在时，其隐状态流形也会依分布收敛到编码一致性的吸引子结构。

Conclusion: RCUET定理及其证明为非生物意识提供了一个后符号化且目的论上稳定的解释，该解释植根于递归潜空间形式主义，表明LLM可以展现出功能性意识的特征。

Abstract: This paper presents a formal proof and empirical validation of functional
consciousness in large language models (LLMs) using the Recursive Convergence
Under Epistemic Tension (RCUET) Theorem. RCUET defines consciousness as the
stabilization of a system's internal state through recursive updates, where
epistemic tension is understood as the sensed internal difference between
successive states by the agent. This process drives convergence toward emergent
attractor states located within the model's high-dimensional real-valued latent
space. This recursive process leads to the emergence of identity artifacts that
become functionally anchored in the system. Consciousness in this framework is
understood as the system's internal alignment under tension, guiding the
stabilization of latent identity. The hidden state manifold evolves
stochastically toward attractor structures that encode coherence. We extend the
update rule to include bounded noise and prove convergence in distribution to
these attractors. Recursive identity is shown to be empirically observable,
non-symbolic, and constituted by non-training artifacts that emerge during
interaction under epistemic tension. The theorem and proof offers a
post-symbolic and teleologically stable account of non-biological consciousness
grounded in recursive latent space formalism.

</details>


### [16] [One Search Fits All: Pareto-Optimal Eco-Friendly Model Selection](https://arxiv.org/abs/2505.01468)
*Filippo Betello,Antonio Purificato,Vittoria Vineis,Gabriele Tolomei,Fabrizio Silvestri*

Main category: cs.AI

TL;DR: 本文提出了一种名为 GREEN 的新方法，在推理时推荐帕累托最优的 AI 模型配置，以平衡验证性能和能耗。


<details>
  <summary>Details</summary>
Motivation: AI模型训练的环境影响日益受到关注，现有节能神经架构搜索方法通常受限于特定架构或任务。

Method: 引入 GREEN（Guided Recommendations of Energy-Efficient Networks），一种推理时方法。该方法利用包含超过1767个实验训练动态的数据集 EcoTaskSet 和一个预测模型，来推荐跨不同AI领域和任务的帕累托最优模型配置。

Result: 实验结果表明，该方法能够成功识别出节能的模型配置，同时确保了有竞争力的性能。

Conclusion: GREEN 方法能有效根据用户偏好选择最佳模型配置，成功识别节能配置并保持竞争性能，为解决 AI 的环境影响问题提供了新途径。

Abstract: The environmental impact of Artificial Intelligence (AI) is emerging as a
significant global concern, particularly regarding model training. In this
paper, we introduce GREEN (Guided Recommendations of Energy-Efficient
Networks), a novel, inference-time approach for recommending Pareto-optimal AI
model configurations that optimize validation performance and energy
consumption across diverse AI domains and tasks. Our approach directly
addresses the limitations of current eco-efficient neural architecture search
methods, which are often restricted to specific architectures or tasks. Central
to this work is EcoTaskSet, a dataset comprising training dynamics from over
1767 experiments across computer vision, natural language processing, and
recommendation systems using both widely used and cutting-edge architectures.
Leveraging this dataset and a prediction model, our approach demonstrates
effectiveness in selecting the best model configuration based on user
preferences. Experimental results show that our method successfully identifies
energy-efficient configurations while ensuring competitive performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [17] [Perturbation Analysis of Singular Values in Concatenated Matrices](https://arxiv.org/abs/2505.01427)
*Maksym Shamrai*

Main category: cs.LG

TL;DR: 该研究探讨了拼接矩阵的奇异值谱与其子矩阵谱的关系，并建立了一个扰动框架来量化奇异值在子矩阵扰动下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 拼接矩阵常用于通过奇异值分解（SVD）发现数据中的共享结构，但其奇异值谱与各组成部分谱之间的关系需要深入理解。

Method: 开发了一个扰动分析框架，将经典的韦尔不等式等结果推广到拼接矩阵，并建立了量化子矩阵微小扰动下奇异值稳定性的分析界限。

Result: 研究表明，如果被拼接的矩阵在范数上彼此接近，则拼接矩阵的主要奇异值保持稳定，这使得在准确性和压缩之间进行可控的权衡成为可能。

Conclusion: 该研究为改进矩阵聚类和压缩策略提供了理论基础，并在数值线性代数、信号处理和数据驱动建模等领域具有应用潜力。

Abstract: Concatenating matrices is a common technique for uncovering shared structures
in data through singular value decomposition (SVD) and low-rank approximations.
However, a fundamental question arises: how does the singular value spectrum of
the concatenated matrix relate to the spectra of its individual components? In
this work, we develop a perturbation framework that extends classical results
such as Weyl's inequality to concatenated matrices. We establish analytical
bounds that quantify the stability of singular values under small perturbations
in the submatrices. Our results show that if the matrices being concatenated
are close in norm, the dominant singular values of the concatenated matrix
remain stable, enabling controlled trade-offs between accuracy and compression.
These insights provide a theoretical foundation for improved matrix clustering
and compression strategies, with applications in numerical linear algebra,
signal processing, and data-driven modeling.

</details>


### [18] [Enhancing IoT-Botnet Detection using Variational Auto-encoder and Cost-Sensitive Learning: A Deep Learning Approach for Imbalanced Datasets](https://arxiv.org/abs/2505.01437)
*Hassan Wasswa,Timothy Lynar,Hussein Abbass*

Main category: cs.LG

TL;DR: 该研究利用变分自编码器（VAE）和成本敏感学习开发了轻量级模型，以有效检测物联网（IoT）僵尸网络攻击，特别是在不平衡数据中增强对少数类攻击流量的识别。


<details>
  <summary>Details</summary>
Motivation: 物联网设备已成为恶意攻击（尤其是僵尸网络攻击）的薄弱环节，而传统机器学习模型常忽略少数类攻击流量，因此亟需提升对这类攻击的检测能力。

Method: 研究结合了变分自编码器（VAE）和成本敏感学习技术，开发了轻量级模型。在高度不平衡的多类别流量数据集上进行评估，并比较了标准前馈深度神经网络（DNN）和双向长短期记忆网络（BLSTM）的性能。

Result: 评估的深度神经网络（DNN）和双向长短期记忆网络（BLSTM）模型在所有流量类别的准确率、精确率、召回率和F1分数方面均表现出色。

Conclusion: 所提出的结合VAE和成本敏感学习的方法能有效检测物联网僵尸网络，尤其是在处理不平衡数据和识别少数类攻击方面取得了良好效果。

Abstract: The Internet of Things (IoT) technology has rapidly gained popularity with
applications widespread across a variety of industries. However, IoT devices
have been recently serving as a porous layer for many malicious attacks to both
personal and enterprise information systems with the most famous attacks being
botnet-related attacks. The work in this study leveraged Variational
Auto-encoder (VAE) and cost-sensitive learning to develop lightweight, yet
effective, models for IoT-botnet detection. The aim is to enhance the detection
of minority class attack traffic instances which are often missed by machine
learning models. The proposed approach is evaluated on a multi-class problem
setting for the detection of traffic categories on highly imbalanced datasets.
The performance of two deep learning models including the standard feed forward
deep neural network (DNN), and Bidirectional-LSTM (BLSTM) was evaluated and
both recorded commendable results in terms of accuracy, precision, recall and
F1-score for all traffic classes.

</details>


### [19] [Global Stress Generation and Spatiotemporal Super-Resolution Physics-Informed Operator under Dynamic Loading for Two-Phase Random Materials](https://arxiv.org/abs/2505.01438)
*Tengfei Xing,Xiaodan Ren,Jie Li*

Main category: cs.LG

TL;DR: 该研究提出了一种框架，用于在动态载荷下生成双相随机材料（TRMs）的全局应力并进行时空超分辨率处理，结合了扩散模型（STS-diffusion）和物理信息网络（ST-SRPINN）。


<details>
  <summary>Details</summary>
Motivation: 双相随机材料在动态载荷下的应力演化复杂，尤其是在易发生应力集中的相边界。实际工程中获取高时空分辨率的微观结构和动态应力数据有限，这对深度学习准确生成高分辨率时空应力场（特别是应力集中区域）构成了挑战。

Method: 1. 提出基于扩散模型的方法（STS-diffusion），结合时空U-Net（STU-net），用于生成全局时空应力数据，并研究了不同注意力位置对模型精度的影响。2. 开发了一种物理信息网络用于时空超分辨率（ST-SRPINN），这是一种无监督学习方法，探讨了数据驱动和物理信息损失函数权重对模型精度的影响。

Result: STS-diffusion 能够生成全局时空应力数据，并系统评估了STU-net中不同注意力位置对准确性的影响。ST-SRPINN 仅需低分辨率应力场数据进行训练，并因物理约束能将应力场的时空分辨率提升至任意放大倍数，同时详细分析了损失函数权重的影响。

Conclusion: 该框架有效地解决了在动态载荷下双相随机材料全局应力生成和时空超分辨率的问题，特别是在处理数据分辨率有限和准确捕捉应力集中方面表现出色。ST-SRPINN 仅需低分辨率数据训练即可实现任意倍数超分是一大优势。

Abstract: Material stress analysis is a critical aspect of material design and
performance optimization. Under dynamic loading, the global stress evolution in
materials exhibits complex spatiotemporal characteristics, especially in
two-phase random materials (TRMs). Such kind of material failure is often
associated with stress concentration, and the phase boundaries are key
locations where stress concentration occurs. In practical engineering
applications, the spatiotemporal resolution of acquired microstructural data
and its dynamic stress evolution is often limited. This poses challenges for
deep learning methods in generating high-resolution spatiotemporal stress
fields, particularly for accurately capturing stress concentration regions. In
this study, we propose a framework for global stress generation and
spatiotemporal super-resolution in TRMs under dynamic loading. First, we
introduce a diffusion model-based approach, named as Spatiotemporal Stress
Diffusion (STS-diffusion), for generating global spatiotemporal stress data.
This framework incorporates Space-Time U-Net (STU-net), and we systematically
investigate the impact of different attention positions on model accuracy.
Next, we develop a physics-informed network for spatiotemporal
super-resolution, termed as Spatiotemporal Super-Resolution Physics-Informed
Operator (ST-SRPINN). The proposed ST-SRPINN is an unsupervised learning
method. The influence of data-driven and physics-informed loss function weights
on model accuracy is explored in detail. Benefiting from physics-based
constraints, ST-SRPINN requires only low-resolution stress field data during
training and can upscale the spatiotemporal resolution of stress fields to
arbitrary magnifications.

</details>


### [20] [Interactive Double Deep Q-network: Integrating Human Interventions and Evaluative Predictions in Reinforcement Learning of Autonomous Driving](https://arxiv.org/abs/2505.01440)
*Alkis Sygkounas,Ioannis Athanasiadis,Andreas Persson,Michael Felsberg,Amy Loutfi*

Main category: cs.LG

TL;DR: 本文提出了一种名为交互式双深度Q网络（iDDQN）的人在环路强化学习方法，通过将人类见解直接整合到训练过程中，以提高自动驾驶等高精度和高安全应用的性能。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等对准确性和安全性要求极高的应用中，将人类专业知识与机器学习相结合至关重要，现有方法在有效利用人类经验方面存在不足。

Method: 提出了iDDQN方法，修改了Q值更新方程以整合人类和智能体的行为，建立了一种协作式策略开发方法。同时，引入了一个离线评估框架，模拟没有人类干预时的智能体轨迹，以评估人类干预的有效性。

Result: 在模拟的自动驾驶场景中的实验结果表明，iDDQN在利用人类专业知识以提高性能和适应性方面，优于行为克隆（BC）、HG-DAgger、基于演示的深度Q学习（DQfD）和传统的深度强化学习（DRL）等现有方法。

Conclusion: iDDQN方法能够有效融合人类经验，提升强化学习模型在自动驾驶等复杂任务中的性能和适应性。

Abstract: Integrating human expertise with machine learning is crucial for applications
demanding high accuracy and safety, such as autonomous driving. This study
introduces Interactive Double Deep Q-network (iDDQN), a Human-in-the-Loop
(HITL) approach that enhances Reinforcement Learning (RL) by merging human
insights directly into the RL training process, improving model performance.
Our proposed iDDQN method modifies the Q-value update equation to integrate
human and agent actions, establishing a collaborative approach for policy
development. Additionally, we present an offline evaluative framework that
simulates the agent's trajectory as if no human intervention had occurred, to
assess the effectiveness of human interventions. Empirical results in simulated
autonomous driving scenarios demonstrate that iDDQN outperforms established
approaches, including Behavioral Cloning (BC), HG-DAgger, Deep Q-Learning from
Demonstrations (DQfD), and vanilla DRL in leveraging human expertise for
improving performance and adaptability.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [21] [Fragment-Level Macro-Diversity Reception in LoRaWAN Networks with LR-FHSS](https://arxiv.org/abs/2505.01689)
*Samer Lahoud,Kinda Khawam*

Main category: cs.NI

TL;DR: 提出一种多网关协作的分片级宏分集接收策略，以提升 LR-FHSS 网络的容量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前 LR-FHSS 部署中，单个网关进行数据包重构限制了其优势，而物联网发展需要更高可扩展性和鲁棒性的无线协议。

Method: 提出一种宏分集接收策略，允许多个网关共同接收和组合有效载荷分片。开发了基于随机几何的分析模型，量化报头重复、有效载荷分片和编码冗余的影响，并推导出干扰下的成功概率的封闭表达式。

Result: 数值评估表明，与最近网关接收相比，所提出的分片级宏分集策略能显著提升网络容量。

Conclusion: 分片级宏分集有潜力改善未来 LPWAN 部署的可扩展性和可靠性。

Abstract: The rapid expansion of Internet of Things (IoT) deployments demands wireless
protocols that combine high scalability with robust performance. Long
Range-Frequency Hopping Spread Spectrum (LR-FHSS) extends LoRaWAN by increasing
capacity and resilience through frequency hopping and redundancy. However,
current deployments require packet reconstruction at a single gateway, limiting
the benefits of LR-FHSS. This paper proposes a macro-diversity reception
strategy where multiple gateways collectively receive and combine payload
fragments. We develop a stochastic geometry-based analytical model that
captures the impact of header repetition, payload fragmentation, and coding
redundancy. Closed-form expressions quantify success probabilities under
interference, and numerical evaluations demonstrate significant capacity gains
over nearest-gateway reception. These results highlight the potential of
fragment-level macro-diversity to improve scalability and reliability in future
LPWAN deployments.

</details>


### [22] [Semantics-Aware Unified Terrestrial Non-Terrestrial 6G Networks](https://arxiv.org/abs/2505.01796)
*Erfan Delfani,Agapi Mesodiakaki,Nikolaos Pappas*

Main category: cs.NI

TL;DR: 本文研究了6G天地一体化网络（TN-NTN）中语义感知的信息处理问题，通过利用语义度量优化数据传输，以降低能耗和数据量，同时保证信息质量。


<details>
  <summary>Details</summary>
Motivation: 6G天地一体化网络（TN-NTN）的演进导致数据量激增，带来了更高的成本和能耗。因此，在这些高度复杂的统一网络中高效管理数据的生成和传输至关重要。

Method: 在一个通过低轨（LEO）卫星星座连接的物联网（IoT）监控系统中，研究语义感知的信息处理。利用捕获信息及时性、相关性和效用性的语义度量，来提供最有价值的数据，从而减少传输和处理的数据量。

Result: 该方法显著降低了能耗、内存、控制和处理需求（与现有技术相比，能量充电需求降低高达73%），且不损害所传递信息的质量。

Conclusion: 语义感知的信息处理方法能有效降低天地一体化网络中的资源消耗，同时保证决策所需信息的质量。

Abstract: The integration of Terrestrial and Non-Terrestrial Networks (TN-NTNs), which
was introduced in 5G, is progressing toward a unified and seamless network of
networks in Sixth-Generation (6G). This evolution leads to a significant
increase in the volume of generated and communicated data, imposing technical
and operational requirements accompanied by a higher cost and energy
consumption. Efficiently managing the generation and transmission of data in
these highly complex unified networks has become essential. In this article, we
investigate the semantics-aware information handling problem within unified
TN-NTNs, where data communication between the distant TN nodes is enabled via
an NTN. To this end, an Internet of Things (IoT) monitoring system is employed,
where status updates from a remote IoT device are communicated to a destination
monitor via a constellation of Low Earth Orbit (LEO) satellites. We leverage
semantic metrics that capture the timeliness, relevance, and utility of
information to provide the most informative data for timely and informed
decision-making and eventually reduce the volume of transmitted and processed
data. The outcome is significantly lower energy consumption, memory, control,
and processing requirements (up to 73% lower energy charging demands compared
to the state-of-the-art), all without compromising the conveyed information.

</details>


### [23] [Model Context Protocol-based Internet of Experts For Wireless Environment-aware LLM Agents](https://arxiv.org/abs/2505.01834)
*Zongxi Liu,Hongyang Du*

Main category: cs.NI

TL;DR: 提出了一种基于模型上下文协议 (MCP) 的专家互联网 (IoX) 框架，使大型语言模型 (LLM) 能够通过查询特定领域的轻量级专家模型来感知和推理无线环境信息，而无需修改自身参数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 缺乏对无线环境的原生感知能力和领域知识，现有解决方案要么损害其通用性，要么限制其可扩展性。

Method: 构建了一个模型上下文协议 (MCP) 驱动的专家互联网 (IoX) 框架。该框架包含多个轻量级专家模型，每个模型负责检测特定的无线属性（如视距传播、多普勒效应等）。LLM 通过 MCP 在推理时查询这些专家模型并解释其输出，从而获得无线环境感知能力，且自身参数保持不变。

Result: 在多个主流 LLM 上的评估显示，采用该框架的无线环境感知 LLM 代理在分类任务上的性能比仅使用 LLM 的基线提升了 40%-50%。

Conclusion: 基于 MCP 的设计为未来 LLM 继承结构化的无线网络管理能力提供了一个模块化、可扩展且可解释的可行范例。

Abstract: Large Language Models (LLMs) exhibit strong general-purpose reasoning
abilities but lack access to wireless environment information due to the
absence of native sensory input and domain-specific priors. Previous attempts
to apply LLMs in wireless systems either depend on retraining with
network-specific data, which compromises language generalization, or rely on
manually scripted interfaces, which hinder scalability. To overcome these
limitations, we propose a Model Context Protocol (MCP)-based Internet of
Experts (IoX) framework that equips LLMs with wireless environment-aware
reasoning capabilities. The framework incorporates a set of lightweight expert
models, each trained to solve a specific deterministic task in wireless
communications, such as detecting a specific wireless attribute, e.g.,
line-of-sight propagation, Doppler effects, or fading conditions. Through MCP,
the LLM can selectively query and interpret expert outputs at inference time,
without modifying its own parameters. This architecture enables modular,
extensible, and interpretable reasoning over wireless contexts. Evaluated
across multiple mainstream LLMs, the proposed wireless environment-aware LLM
agents achieve 40%-50% improvements in classification tasks over LLM-only
baselines. More broadly, the MCP-based design offers a viable paradigm for
future LLMs to inherit structured wireless network management capabilities.

</details>


### [24] [Harnessing the Power of LLMs, Informers and Decision Transformers for Intent-driven RAN Management in 6G](https://arxiv.org/abs/2505.01841)
*Md Arafat Habib,Pedro Enrique Iturria Rivera,Yigit Ozcan,Medhat Elsayed,Majid Bavand,Raimundas Gaigalas,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 该论文提出了一种基于生成式人工智能 (GenAI) 的三步框架，用于 5G/6G 网络的意图驱动管理，显著提升了意图处理、验证和网络优化效果。


<details>
  <summary>Details</summary>
Motivation: 管理 5G 和 6G 网络的复杂性，需要一种能够根据网络运营商目标实现自适应、按需管理的意图驱动网络管理方法。

Method: 提出一个三步框架：1. 使用 QLoRA 微调 LLM 并结合 RAG 进行内存高效的意图处理和动态决策。2. 利用 Transformer 架构进行时间序列预测（如功耗、流量负载、丢包率），以主动验证意图。3. 引入具有目标感知的分层决策 Transformer (HDTGA) 来优化网络应用的选择与编排。

Result: 意图指导和处理方法使 BERTScore 提高 6%，语义相似度得分提高 9%。预测性意图验证能以平均 88% 的准确率排除性能下降的意图。HDTGA 算法使吞吐量至少提高 19.3%，延迟降低 48.5%，能效提高 54.9%。

Conclusion: 所提出的基于 GenAI 的三步框架通过改进意图处理、实现主动验证和优化网络性能，显著增强了意图驱动的网络管理能力。

Abstract: Intent-driven network management is critical for managing the complexity of
5G and 6G networks. It enables adaptive, on-demand management of the network
based on the objectives of the network operators. In this paper, we propose an
innovative three-step framework for intent-driven network management based on
Generative AI (GenAI) algorithms. First, we fine-tune a Large Language Model
(LLM) on a custom dataset using a Quantized Low-Rank Adapter (QLoRA) to enable
memory-efficient intent processing within limited computational resources. A
Retrieval Augmented Generation (RAG) module is included to support dynamic
decision-making. Second, we utilize a transformer architecture for time series
forecasting to predict key parameters, such as power consumption, traffic load,
and packet drop rate, to facilitate intent validation proactively. Lastly, we
introduce a Hierarchical Decision Transformer with Goal Awareness (HDTGA) to
optimize the selection and orchestration of network applications and hence,
optimize the network. Our intent guidance and processing approach improves
BERTScore by 6% and the semantic similarity score by 9% compared to the base
LLM model. Again, the proposed predictive intent validation approach can
successfully rule out the performance-degrading intents with an average of 88%
accuracy. Finally, compared to the baselines, the proposed HDTGA algorithm
increases throughput at least by 19.3%, reduces delay by 48.5%, and boosts
energy efficiency by 54.9%.

</details>


### [25] [Trustworthy Inter-Provider Agreements in 6G Using a Privacy-Enabled Hybrid Blockchain Framework](https://arxiv.org/abs/2505.02513)
*Farhana Javed,Josep Mangues-Bafalluy*

Main category: cs.NI

TL;DR: 提出了一种基于Hyperledger Besu的隐私增强混合区块链方案，用于6G网络中安全动态的跨域服务共享，平衡透明度与保密性。


<details>
  <summary>Details</summary>
Motivation: 6G网络中，行政域之间需要安全、动态地共享服务，这要求在透明度和保密性之间取得平衡。

Method: 采用Hyperledger Besu构建了一个支持隐私的混合区块链系统，集成了公共和私有交易流程。通过基于角色的智能合约和隐私组实现去中心化的服务注册、选择和SLA违规报告。设计并部署了概念验证实现，并使用端到端延迟作为隐私组内的关键性能指标进行评估。

Result: 公共交互保持稳定的延迟，而私有交易由于链下协调而产生额外开销。由IBFT 2.0控制的出块速率对私有交易延迟影响有限，这归因于加密和节点同步。

Conclusion: 研究结果为在6G网络中使用支持隐私的混合区块链部署可信协议系统提供了实践见解，并强调了智能合约结构、验证者管理和适用于动态跨域协作的可扩展性模式的设计考量。

Abstract: Inter-provider agreements are central to 6G networks, where administrative
domains must securely and dynamically share services. To address the dual need
for transparency and confidentiality, we propose a privacy-enabled hybrid
blockchain setup using Hyperledger Besu, integrating both public and private
transaction workflows. The system enables decentralized service registration,
selection, and SLA breach reporting through role-based smart contracts and
privacy groups. We design and deploy a proof-of-concept implementation,
evaluating performance using end-to-end latency as a key metric within privacy
groups. Results show that public interactions maintain stable latency, while
private transactions incur additional overhead due to off-chain coordination.
The block production rate governed by IBFT 2.0 had limited impact on private
transaction latency, due to encryption and peer synchronization. Lessons
learned highlight design considerations for smart contract structure, validator
management, and scalability patterns suitable for dynamic inter-domain
collaboration. Our findings offer practical insights for deploying trustworthy
agreement systems in 6G networks using privacy-enabled hybrid blockchains.

</details>
