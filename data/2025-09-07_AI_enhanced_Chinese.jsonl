{"id": "2509.03525", "pdf": "https://arxiv.org/pdf/2509.03525", "abs": "https://arxiv.org/abs/2509.03525", "authors": ["Fatemeh Taherinezhad", "Mohamad Javad Momeni Nezhad", "Sepehr Karimi", "Sina Rashidi", "Ali Zolnour", "Maryam Dadkhah", "Yasaman Haghbin", "Hossein AzadMaleki", "Maryam Zolnoori"], "title": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies", "categories": ["cs.CL", "cs.AI", "eess.AS"], "comment": null, "summary": "Over half of US adults with Alzheimer disease and related dementias remain\nundiagnosed, and speech-based screening offers a scalable detection approach.\nWe compared large language model adaptation strategies for dementia detection\nusing the DementiaBank speech corpus, evaluating nine text-only models and\nthree multimodal audio-text models on recordings from DementiaBank speech\ncorpus. Adaptations included in-context learning with different demonstration\nselection policies, reasoning-augmented prompting, parameter-efficient\nfine-tuning, and multimodal integration. Results showed that class-centroid\ndemonstrations achieved the highest in-context learning performance, reasoning\nimproved smaller models, and token-level fine-tuning generally produced the\nbest scores. Adding a classification head substantially improved\nunderperforming models. Among multimodal models, fine-tuned audio-text systems\nperformed well but did not surpass the top text-only models. These findings\nhighlight that model adaptation strategies, including demonstration selection,\nreasoning design, and tuning method, critically influence speech-based dementia\ndetection, and that properly adapted open-weight models can match or exceed\ncommercial systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5728DementiaBank\u8bed\u6599\u5e93\u4e0a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7528\u4e8e\u75f4\u5446\u75c7\u8bed\u97f3\u68c0\u6d4b\u7684\u591a\u79cd\u9002\u5e94\u7b56\u7565\uff0c\u7ed3\u679c\u8868\u660e\u7279\u5b9a\u7684\u5fae\u8c03\u548c\u63d0\u793a\u65b9\u6cd5\u6548\u679c\u663e\u8457\uff0c\u5e76\u4e14\u9002\u5e94\u826f\u597d\u7684\u5f00\u6e90\u6a21\u578b\u80fd\u4e0e\u5546\u4e1a\u7cfb\u7edf\u5ab2\u7f8e\u6216\u8d85\u8d8a\u3002", "motivation": "\u7f8e\u56fd\u8d85\u8fc7\u4e00\u534a\u7684\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u53ca\u76f8\u5173\u75f4\u5446\u75c7\u60a3\u8005\u672a\u786e\u8bca\uff0c\u8bed\u97f3\u7b5b\u67e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u4f18\u5316LLM\u5728\u8bed\u97f3\u6570\u636e\u4e0a\u7684\u75f4\u5446\u75c7\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86DementiaBank\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u6bd4\u8f83\u4e86LLM\u7684\u591a\u79cd\u9002\u5e94\u7b56\u7565\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08\u91c7\u7528\u4e0d\u540c\u793a\u4f8b\u9009\u62e9\u7b56\u7565\uff09\u3001\u63a8\u7406\u589e\u5f3a\u63d0\u793a\u3001\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4ee5\u53ca\u591a\u6a21\u6001\u6574\u5408\u3002\u8bc4\u4f30\u4e86\u4e5d\u4e2a\u7eaf\u6587\u672c\u6a21\u578b\u548c\u4e09\u4e2a\u591a\u6a21\u6001\u97f3\u6587\u672c\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7c7b\u8d28\u5fc3\u793a\u4f8b\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u8868\u73b0\u6700\u4f73\uff1b\u63a8\u7406\u529f\u80fd\u6539\u5584\u4e86\u8f83\u5c0f\u578b\u6a21\u578b\uff1btoken\u7ea7\u5fae\u8c03\u901a\u5e38\u80fd\u4ea7\u751f\u6700\u4f73\u5206\u6570\u3002\u4e3a\u8868\u73b0\u4e0d\u4f73\u7684\u6a21\u578b\u6dfb\u52a0\u5206\u7c7b\u5934\u53ef\u663e\u8457\u63d0\u9ad8\u6027\u80fd\u3002\u591a\u6a21\u6001\u97f3\u6587\u672c\u7cfb\u7edf\u867d\u7136\u8868\u73b0\u826f\u597d\uff0c\u4f46\u672a\u8d85\u8d8a\u9876\u7ea7\u7684\u7eaf\u6587\u672c\u6a21\u578b\u3002", "conclusion": "\u6a21\u578b\u9002\u5e94\u7b56\u7565\uff08\u5305\u62ec\u793a\u4f8b\u9009\u62e9\u3001\u63a8\u7406\u8bbe\u8ba1\u548c\u5fae\u8c03\u65b9\u6cd5\uff09\u5bf9\u57fa\u4e8e\u8bed\u97f3\u7684\u75f4\u5446\u75c7\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\u3002\u7ecf\u8fc7\u9002\u5f53\u9002\u5e94\u7684\u5f00\u6e90\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u5546\u4e1a\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2509.03526", "pdf": "https://arxiv.org/pdf/2509.03526", "abs": "https://arxiv.org/abs/2509.03526", "authors": ["Yansong Liu", "Jiateng Li", "Yuan Liu"], "title": "Enhancing Speech Large Language Models through Reinforced Behavior Alignment", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "The recent advancements of Large Language Models (LLMs) have spurred\nconsiderable research interest in extending their linguistic capabilities\nbeyond text to other modalities, which leads to emergence of speech-based LLMs\n(SpeechLMs) with capability of processing user request in either speech or\ntextual formats. However, owing to inter-modal discrepancies, these SpeechLMs\nstill exhibit a significant performance gap compared to their text-based LLM\ncounterparts in instruction-following, particularly when confronted with the\ndynamic and variable nature of user speech. To address this challenge, this\npaper introduces a framework termed Reinforced Behavior Alignment (RBA),\ndesigned to bolster the language generation proficiency of SpeechLMs. Instead\nof relying on supervised fine-tuning from human annotations, RBA employs a\nself-synthesis methodology to generate extensive, high-fidelity alignment data\nby a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of\na teacher using a reinforcement learning-based approach. Experimental results\ndemonstrate that this method effectively enhances the instruction-following\ncapabilities of SpeechLMs that outperform conventional distillation baselines.\nCrucially, we demonstrate that RBA can be seamlessly extended to tasks such\nincluding spoken question answering and speech-to-text translation, attaining\nstate-of-the-art performance on open benchmarks with only self-generated data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRBA\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5927\u7684\u6559\u5e08LLM\u81ea\u5408\u6210\u6570\u636e\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\uff08SpeechLMs\uff09\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\uff08SpeechLMs\uff09\u5728\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u4e0e\u7eaf\u6587\u672cLLMs\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u52a8\u6001\u591a\u53d8\u7684\u8bed\u97f3\u8bf7\u6c42\u65f6\uff0c\u8fd9\u4e3b\u8981\u6e90\u4e8e\u6a21\u6001\u95f4\u7684\u5dee\u5f02\u3002", "method": "\u5f15\u5165\u5f3a\u5316\u884c\u4e3a\u5bf9\u9f50\uff08Reinforced Behavior Alignment, RBA\uff09\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\uff0c\u800c\u662f\u901a\u8fc7\u4e00\u4e2a\u5f3a\u5927\u7684\u6559\u5e08LLM\u81ea\u5408\u6210\u5927\u91cf\u9ad8\u8d28\u91cf\u7684\u5bf9\u9f50\u6570\u636e\uff0c\u7136\u540e\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5c06SpeechLMs\u7684\u884c\u4e3a\u4e0e\u6559\u5e08LLM\u8fdb\u884c\u5bf9\u9f50\u3002", "result": "RBA\u6709\u6548\u589e\u5f3a\u4e86SpeechLMs\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u84b8\u998f\u57fa\u7ebf\u3002\u6b64\u5916\uff0cRBA\u53ef\u6269\u5c55\u81f3\u53e3\u8bed\u95ee\u7b54\u548c\u8bed\u97f3\u5230\u6587\u672c\u7ffb\u8bd1\u7b49\u4efb\u52a1\uff0c\u4ec5\u4f7f\u7528\u81ea\u751f\u6210\u6570\u636e\u5373\u5728\u516c\u5f00\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "RBA\u6846\u67b6\u901a\u8fc7\u81ea\u5408\u6210\u6570\u636e\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u6210\u529f\u63d0\u5347\u4e86SpeechLMs\u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u548c\u6307\u4ee4\u9075\u5faa\u8868\u73b0\uff0c\u5f25\u8865\u4e86\u5176\u4e0e\u6587\u672cLLMs\u7684\u5dee\u8ddd\uff0c\u5e76\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6cdb\u5316\u6027\u548cSOTA\u6027\u80fd\u3002"}}
{"id": "2509.03527", "pdf": "https://arxiv.org/pdf/2509.03527", "abs": "https://arxiv.org/abs/2509.03527", "authors": ["Bohdan M. Pavlyshenko"], "title": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the paper, we consider multilevel multitask analysis of cryptocurrency\nnews using a fine-tuned Mistral 7B large language model with\nretrieval-augmented generation (RAG).\n  On the first level of analytics, the fine-tuned model generates graph and\ntext summaries with sentiment scores as well as JSON representations of\nsummaries. Higher levels perform hierarchical stacking that consolidates sets\nof graph-based and text-based summaries as well as summaries of summaries into\ncomprehensive reports. The combination of graph and text summaries provides\ncomplementary views of cryptocurrency news. The model is fine-tuned with 4-bit\nquantization using the PEFT/LoRA approach. The representation of cryptocurrency\nnews as knowledge graph can essentially eliminate problems with large language\nmodel hallucinations.\n  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM\nmodels for multilevel cryptocurrency news analysis can conduct informative\nqualitative and quantitative analytics, providing important insights.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684Mistral 7B\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408RAG\u6280\u672f\uff0c\u5bf9\u52a0\u5bc6\u8d27\u5e01\u65b0\u95fb\u8fdb\u884c\u591a\u7ea7\u522b\u591a\u4efb\u52a1\u5206\u6790\uff0c\u901a\u8fc7\u751f\u6210\u56fe\u6587\u6458\u8981\u548c\u62a5\u544a\u63d0\u4f9b\u6d1e\u5bdf\uff0c\u5e76\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u89e3\u51b3LLM\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u65e8\u5728\u5bf9\u52a0\u5bc6\u8d27\u5e01\u65b0\u95fb\u8fdb\u884c\u591a\u7ea7\u522b\u3001\u591a\u4efb\u52a1\u7684\u6df1\u5165\u5206\u6790\uff0c\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5b9a\u6027\u4e0e\u5b9a\u91cf\u6d1e\u5bdf\uff0c\u5e76\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4fe1\u606f\u751f\u6210\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7ecf\u8fc74\u6bd4\u7279\u91cf\u5316\u3001\u57fa\u4e8ePEFT/LoRA\u65b9\u6cd5\u5fae\u8c03\u7684Mistral 7B\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u3002\u5206\u6790\u5206\u4e3a\u591a\u7ea7\u522b\uff1a\u7b2c\u4e00\u7ea7\u522b\u751f\u6210\u5305\u542b\u60c5\u611f\u5f97\u5206\u7684\u56fe\u6587\u6458\u8981\u53caJSON\u8868\u793a\uff1b\u66f4\u9ad8\u7ea7\u522b\u901a\u8fc7\u5206\u5c42\u5806\u53e0\u6574\u5408\u56fe\u6587\u6458\u8981\u53ca\u6458\u8981\u7684\u6458\u8981\uff0c\u5f62\u6210\u7efc\u5408\u62a5\u544a\u3002\u901a\u8fc7\u5c06\u52a0\u5bc6\u8d27\u5e01\u65b0\u95fb\u8868\u793a\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u6d88\u9664LLM\u5e7b\u89c9\u95ee\u9898\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u5fae\u8c03\u7684Mistral 7B LLM\u6a21\u578b\u8fdb\u884c\u591a\u7ea7\u522b\u52a0\u5bc6\u8d27\u5e01\u65b0\u95fb\u5206\u6790\uff0c\u80fd\u591f\u6709\u6548\u8fdb\u884c\u4fe1\u606f\u4e30\u5bcc\u7684\u5b9a\u6027\u4e0e\u5b9a\u91cf\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4e3a\u52a0\u5bc6\u8d27\u5e01\u65b0\u95fb\u5206\u6790\u63d0\u4f9b\u91cd\u8981\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.03528", "pdf": "https://arxiv.org/pdf/2509.03528", "abs": "https://arxiv.org/abs/2509.03528", "authors": ["Matilde Contestabile", "Chiara Ferrara", "Alberto Giovannetti", "Giovanni Parrillo", "Andrea Vandin"], "title": "The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Process Mining (PM), initially developed for industrial and business\ncontexts, has recently been applied to social systems, including legal ones.\nHowever, PM's efficacy in the legal domain is limited by the accessibility and\nquality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in\nItalian Chambers), a comprehensive event log of the Italian lawmaking process\nfrom 1987 to 2022. Created from unstructured data from the Normattiva portal\nand structured using large language models (LLMs), ProLiFIC aligns with recent\nefforts in integrating PM with LLMs. We exemplify preliminary analyses and\npropose ProLiFIC as a benchmark for legal PM, fostering new developments.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6cd5\u5f8b\u9886\u57df\u6d41\u7a0b\u6316\u6398\u6570\u636e\u5c40\u9650\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ProLiFIC\uff0c\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u6784\u5efa\u7684\u610f\u5927\u5229\u7acb\u6cd5\u6d41\u7a0b\u7efc\u5408\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u5e76\u5efa\u8bae\u5176\u4f5c\u4e3a\u6cd5\u5f8b\u6d41\u7a0b\u6316\u6398\u7684\u57fa\u51c6\u4ee5\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u6d41\u7a0b\u6316\u6398\uff08PM\uff09\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u5e94\u7528\u53d7\u5230\u6570\u636e\u96c6\u53ef\u8bbf\u95ee\u6027\u548c\u8d28\u91cf\u7684\u9650\u5236\u3002", "method": "\u5f15\u5165\u4e86ProLiFIC\uff08\u610f\u5927\u5229\u8bae\u4f1a\u7acb\u6cd5\u6d41\u7a0b\uff09\uff0c\u4e00\u4e2a\u6db5\u76d61987\u5e74\u81f32022\u5e74\u610f\u5927\u5229\u7acb\u6cd5\u8fc7\u7a0b\u7684\u7efc\u5408\u4e8b\u4ef6\u65e5\u5fd7\u3002\u8be5\u65e5\u5fd7\u901a\u8fc7\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4eceNormattiva\u95e8\u6237\u7684\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u63d0\u53d6\u5e76\u7ed3\u6784\u5316\u800c\u521b\u5efa\u3002", "result": "\u5bf9ProLiFIC\u8fdb\u884c\u4e86\u521d\u6b65\u5206\u6790\u793a\u4f8b\u3002", "conclusion": "ProLiFIC\u88ab\u63d0\u8bae\u4f5c\u4e3a\u6cd5\u5f8b\u6d41\u7a0b\u6316\u6398\u7684\u57fa\u51c6\uff0c\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u65b0\u53d1\u5c55\u3002"}}
{"id": "2509.03667", "pdf": "https://arxiv.org/pdf/2509.03667", "abs": "https://arxiv.org/abs/2509.03667", "authors": ["Vivek Vasan", "Alexander Nico-Katz", "Boulat A. Bash", "Daniel C. Kilper", "Marco Ruffini"], "title": "Entanglement Purification With Finite Latency Classical Communication in Quantum Networks", "categories": ["cs.NI"], "comment": null, "summary": "Quantum networks rely on high fidelity entangled pairs distributed to nodes,\nbut maintaining their fidelity is challenged by environmental decoherence\nduring storage. Entanglement purification is used to restore fidelity, but the\nidle periods imposed by the associated classical communication delays\ncounteract this goal by exposing the states to further decoherence. In this\nwork, we analyze the practical viability of entanglement purification protocols\n(BBPSSW, DEJMPS), under non-instantaneous classical coordination over Internet\nprotocol (IP) communications networks. We present a comprehensive performance\nevaluation of these protocols in various network conditions for a range of\nquantum memory technologies. We employ a microscopic Lindblad treatment of the\nunderlying quantum dynamics, and use current-generation metropolitan IP network\nlatency statistics and parameters drawn from quantum memory testbeds. In doing\nso we identify the regions in which entanglement purification succeeds and\nfails, delineated by break-even iso-fidelity contours in the phase space. We\nthen determine the total number of entangled pairs required to complete a\nmulti-round purification protocol, and the steady-state throughput of entangled\npairs with purified fidelities that exceed application-specific thresholds.\nThis provides latency budgets, memory quality targets, and resource-overhead\nestimates for deploying purification on current and near-future networks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7ea0\u7f20\u7eaf\u5316\u534f\u8bae\uff08BBPSSW, DEJMPS\uff09\u5728\u5b9e\u9645IP\u7f51\u7edc\u901a\u4fe1\u5ef6\u8fdf\u4e0b\u7684\u53ef\u884c\u6027\uff0c\u8bc4\u4f30\u4e86\u5176\u5728\u4e0d\u540c\u7f51\u7edc\u6761\u4ef6\u548c\u91cf\u5b50\u5b58\u50a8\u6280\u672f\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u90e8\u7f72\u6307\u5bfc\u3002", "motivation": "\u91cf\u5b50\u7f51\u7edc\u9700\u8981\u9ad8\u4fdd\u771f\u7ea0\u7f20\u5bf9\uff0c\u4f46\u5b58\u50a8\u671f\u95f4\u7684\u9000\u76f8\u5e72\u4f1a\u964d\u4f4e\u5176\u4fdd\u771f\u5ea6\u3002\u7ea0\u7f20\u7eaf\u5316\u867d\u80fd\u6062\u590d\u4fdd\u771f\u5ea6\uff0c\u4f46\u5176\u7ecf\u5178\u901a\u4fe1\u5ef6\u8fdf\u5bfc\u81f4\u7684\u7a7a\u95f2\u671f\uff0c\u4f1a\u4f7f\u91cf\u5b50\u6001\u8fdb\u4e00\u6b65\u9000\u76f8\u5e72\uff0c\u4ece\u800c\u62b5\u6d88\u7eaf\u5316\u6548\u679c\u3002", "method": "\u5206\u6790BBPSSW\u548cDEJMPS\u4e24\u79cd\u7ea0\u7f20\u7eaf\u5316\u534f\u8bae\u5728\u975e\u77ac\u65f6IP\u7f51\u7edc\u7ecf\u5178\u534f\u8c03\u4e0b\u7684\u53ef\u884c\u6027\u3002\u91c7\u7528\u5fae\u89c2Lindblad\u5904\u7406\u91cf\u5b50\u52a8\u529b\u5b66\uff0c\u7ed3\u5408\u5f53\u524d\u57ce\u57dfIP\u7f51\u7edc\u7684\u5ef6\u8fdf\u7edf\u8ba1\u6570\u636e\u548c\u91cf\u5b50\u5b58\u50a8\u6d4b\u8bd5\u5e73\u53f0\u53c2\u6570\uff0c\u5728\u591a\u79cd\u7f51\u7edc\u6761\u4ef6\u548c\u91cf\u5b50\u5b58\u50a8\u6280\u672f\u4e0b\u8fdb\u884c\u7efc\u5408\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u786e\u5b9a\u4e86\u7ea0\u7f20\u7eaf\u5316\u534f\u8bae\u7684\u6210\u529f\u4e0e\u5931\u8d25\u533a\u57df\uff08\u901a\u8fc7\u76f8\u7a7a\u95f4\u4e2d\u7684\u6536\u652f\u5e73\u8861\u7b49\u4fdd\u771f\u5ea6\u7b49\u9ad8\u7ebf\u5212\u5206\uff09\u3002\u8ba1\u7b97\u4e86\u5b8c\u6210\u591a\u8f6e\u7eaf\u5316\u534f\u8bae\u6240\u9700\u7684\u7ea0\u7f20\u5bf9\u603b\u6570\uff0c\u4ee5\u53ca\u8fbe\u5230\u5e94\u7528\u7279\u5b9a\u9608\u503c\u7eaf\u5316\u4fdd\u771f\u5ea6\u7684\u7ea0\u7f20\u5bf9\u7684\u7a33\u6001\u541e\u5410\u91cf\u3002", "conclusion": "\u4e3a\u5728\u5f53\u524d\u548c\u672a\u6765\u7f51\u7edc\u4e2d\u90e8\u7f72\u7ea0\u7f20\u7eaf\u5316\u63d0\u4f9b\u4e86\u5ef6\u8fdf\u9884\u7b97\u3001\u5b58\u50a8\u5668\u8d28\u91cf\u76ee\u6807\u548c\u8d44\u6e90\u5f00\u9500\u4f30\u7b97\uff0c\u5177\u6709\u5b9e\u9645\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2509.03609", "pdf": "https://arxiv.org/pdf/2509.03609", "abs": "https://arxiv.org/abs/2509.03609", "authors": ["Shengkai Sun", "Zefan Zhang", "Jianfeng Dong", "Zhiyong Cheng", "Xiaojun Chang", "Meng Wang"], "title": "Towards Efficient General Feature Prediction in Masked Skeleton Modeling", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Recent advances in the masked autoencoder (MAE) paradigm have significantly\npropelled self-supervised skeleton-based action recognition. However, most\nexisting approaches limit reconstruction targets to raw joint coordinates or\ntheir simple variants, resulting in computational redundancy and limited\nsemantic representation. To address this, we propose a novel General Feature\nPrediction framework (GFP) for efficient mask skeleton modeling. Our key\ninnovation is replacing conventional low-level reconstruction with high-level\nfeature prediction that spans from local motion patterns to global semantic\nrepresentations. Specifically, we introduce a collaborative learning framework\nwhere a lightweight target generation network dynamically produces diversified\nsupervision signals across spatial-temporal hierarchies, avoiding reliance on\npre-computed offline features. The framework incorporates constrained\noptimization to ensure feature diversity while preventing model collapse.\nExperiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits\nof our approach: Computational efficiency (with 6.2$\\times$ faster training\nthan standard masked skeleton modeling methods) and superior representation\nquality, achieving state-of-the-art performance in various downstream tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u7528\u7279\u5f81\u9884\u6d4b\uff08GFP\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u5c42\u7279\u5f81\u9884\u6d4b\u800c\u975e\u4f4e\u7ea7\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u76d1\u7763\u9aa8\u9abc\u884c\u4e3a\u8bc6\u522b\u7684\u6548\u7387\u548c\u8868\u793a\u8d28\u91cf\uff0c\u5e76\u5728\u591a\u9879\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63a9\u7801\u81ea\u7f16\u7801\u5668\uff08MAE\uff09\u7684\u9aa8\u9abc\u884c\u4e3a\u8bc6\u522b\u65b9\u6cd5\uff0c\u5176\u91cd\u5efa\u76ee\u6807\u901a\u5e38\u5c40\u9650\u4e8e\u539f\u59cb\u5173\u8282\u5750\u6807\u6216\u5176\u7b80\u5355\u53d8\u4f53\uff0c\u8fd9\u5bfc\u81f4\u8ba1\u7b97\u5197\u4f59\u4e14\u8bed\u4e49\u8868\u793a\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51fa\u901a\u7528\u7279\u5f81\u9884\u6d4b\uff08GFP\uff09\u6846\u67b6\uff0c\u6838\u5fc3\u521b\u65b0\u662f\u4ee5\u9ad8\u5c42\u7279\u5f81\u9884\u6d4b\u53d6\u4ee3\u4f20\u7edf\u7684\u4f4e\u7ea7\u91cd\u5efa\uff0c\u8fd9\u4e9b\u7279\u5f81\u6db5\u76d6\u4ece\u5c40\u90e8\u8fd0\u52a8\u6a21\u5f0f\u5230\u5168\u5c40\u8bed\u4e49\u8868\u793a\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8be5\u6846\u67b6\u5f15\u5165\u4e86\u4e00\u4e2a\u534f\u4f5c\u5b66\u4e60\u673a\u5236\uff0c\u5176\u4e2d\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u76ee\u6807\u751f\u6210\u7f51\u7edc\u80fd\u52a8\u6001\u5730\u5728\u65f6\u7a7a\u5c42\u7ea7\u4e0a\u4ea7\u751f\u591a\u6837\u5316\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u907f\u514d\u4f9d\u8d56\u9884\u8ba1\u7b97\u7684\u79bb\u7ebf\u7279\u5f81\u3002\u6b64\u5916\uff0c\u6846\u67b6\u8fd8\u7ed3\u5408\u4e86\u7ea6\u675f\u4f18\u5316\u4ee5\u786e\u4fdd\u7279\u5f81\u591a\u6837\u6027\u5e76\u9632\u6b62\u6a21\u578b\u5d29\u6e83\u3002", "result": "\u5728NTU RGB+D 60\u3001NTU RGB+D 120\u548cPKU-MMD\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGFP\u6846\u67b6\u4e0e\u6807\u51c6\u63a9\u7801\u9aa8\u9abc\u5efa\u6a21\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8bad\u7ec3\u901f\u5ea6\u5feb6.2\u500d\uff0c\u5e76\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u8868\u793a\u8d28\u91cf\uff0c\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "GFP\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u9ad8\u5c42\u7279\u5f81\u9884\u6d4b\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709MAE\u8303\u5f0f\u5728\u9aa8\u9abc\u884c\u4e3a\u8bc6\u522b\u4e2d\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u548c\u8bed\u4e49\u8868\u793a\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2509.03536", "pdf": "https://arxiv.org/pdf/2509.03536", "abs": "https://arxiv.org/abs/2509.03536", "authors": ["Weizhi Chen", "Ziwei Wang", "Leyang Yang", "Sheng Zhou", "Xiaoxuan Tang", "Jiajun Bu", "Yong Li", "Wei Jiang"], "title": "PG-Agent: An Agent Powered by Page Graph", "categories": ["cs.AI", "cs.HC"], "comment": "Paper accepted to ACM MM 2025", "summary": "Graphical User Interface (GUI) agents possess significant commercial and\nsocial value, and GUI agents powered by advanced multimodal large language\nmodels (MLLMs) have demonstrated remarkable potential. Currently, existing GUI\nagents usually utilize sequential episodes of multi-step operations across\npages as the prior GUI knowledge, which fails to capture the complex transition\nrelationship between pages, making it challenging for the agents to deeply\nperceive the GUI environment and generalize to new scenarios. Therefore, we\ndesign an automated pipeline to transform the sequential episodes into page\ngraphs, which explicitly model the graph structure of the pages that are\nnaturally connected by actions. To fully utilize the page graphs, we further\nintroduce Retrieval-Augmented Generation (RAG) technology to effectively\nretrieve reliable perception guidelines of GUI from them, and a tailored\nmulti-agent framework PG-Agent with task decomposition strategy is proposed to\nbe injected with the guidelines so that it can generalize to unseen scenarios.\nExtensive experiments on various benchmarks demonstrate the effectiveness of\nPG-Agent, even with limited episodes for page graph construction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPG-Agent\u6846\u67b6\uff0c\u901a\u8fc7\u5c06GUI\u64cd\u4f5c\u8f6c\u5316\u4e3a\u9875\u9762\u56fe\u5e76\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709GUI\u667a\u80fd\u4f53\u96be\u4ee5\u6355\u6349\u9875\u9762\u590d\u6742\u8f6c\u6362\u5173\u7cfb\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5728\u672a\u89c1\u573a\u666f\u4e0b\u7684\u611f\u77e5\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709GUI\u667a\u80fd\u4f53\u4f9d\u8d56\u987a\u5e8f\u64cd\u4f5c\u7247\u6bb5\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\uff0c\u672a\u80fd\u6355\u6349\u9875\u9762\u95f4\u590d\u6742\u7684\u8f6c\u6362\u5173\u7cfb\uff0c\u5bfc\u81f4\u5176\u96be\u4ee5\u6df1\u5165\u611f\u77e5GUI\u73af\u5883\u5e76\u6cdb\u5316\u5230\u65b0\u573a\u666f\u3002", "method": "1) \u8bbe\u8ba1\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u5c06\u987a\u5e8f\u64cd\u4f5c\u7247\u6bb5\u8f6c\u5316\u4e3a\u663e\u5f0f\u5efa\u6a21\u9875\u9762\u56fe\u7ed3\u6784\u30022) \u5f15\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u4ece\u9875\u9762\u56fe\u4e2d\u6709\u6548\u68c0\u7d22\u53ef\u9760\u7684GUI\u611f\u77e5\u6307\u5357\u30023) \u63d0\u51fa\u5b9a\u5236\u5316\u7684PG-Agent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u4efb\u52a1\u5206\u89e3\u7b56\u7565\uff0c\u5e76\u6ce8\u5165\u8fd9\u4e9b\u6307\u5357\u4ee5\u5b9e\u73b0\u5bf9\u672a\u89c1\u573a\u666f\u7684\u6cdb\u5316\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cPG-Agent\u5373\u4f7f\u5728\u9875\u9762\u56fe\u6784\u5efa\u6240\u7528\u7247\u6bb5\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "PG-Agent\u6846\u67b6\u901a\u8fc7\u5229\u7528\u9875\u9762\u56fe\u548cRAG\u6280\u672f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709GUI\u667a\u80fd\u4f53\u5728\u7406\u89e3\u590d\u6742\u9875\u9762\u8f6c\u6362\u5173\u7cfb\u4e0a\u7684\u4e0d\u8db3\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5176\u5bf9GUI\u73af\u5883\u7684\u611f\u77e5\u80fd\u529b\u548c\u5728\u65b0\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.03594", "pdf": "https://arxiv.org/pdf/2509.03594", "abs": "https://arxiv.org/abs/2509.03594", "authors": ["Thomas R. Harvey"], "title": "The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "https://github.com/harveyThomas4692/Induced-Metric-Optimiser", "summary": "We present a class of novel optimisers for training neural networks that\nmakes use of the Riemannian metric naturally induced when the loss landscape is\nembedded in higher-dimensional space. This is the same metric that underlies\ncommon visualisations of loss landscapes. By taking this geometric perspective\nliterally and using the induced metric, we develop a new optimiser and compare\nit to existing methods, namely: SGD, Adam, AdamW, and Muon, across a range of\ntasks and architectures. Empirically, we conclude that this new class of\noptimisers is highly effective in low dimensional examples, and provides slight\nimprovement over state-of-the-art methods for training neural networks. These\nnew optimisers have theoretically desirable properties. In particular, the\neffective learning rate is automatically decreased in regions of high curvature\nacting as a smoothed out form of gradient clipping. Similarly, one variant of\nthese optimisers can also be viewed as inducing an effective scheduled learning\nrate and decoupled weight decay is the natural choice from our geometric\nperspective. The basic method can be used to modify any existing\npreconditioning method. The new optimiser has a computational complexity\ncomparable to that of Adam.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7c7b\u57fa\u4e8e\u635f\u5931\u51fd\u6570\u9ece\u66fc\u5ea6\u91cf\u7684\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u5668\uff0c\u8be5\u4f18\u5316\u5668\u5728\u4f4e\u7ef4\u793a\u4f8b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7565\u6709\u6539\u8fdb\uff0c\u540c\u65f6\u5177\u6709\u826f\u597d\u7684\u7406\u8bba\u7279\u6027\u548c\u4e0eAdam\u76f8\u5f53\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u901a\u8fc7\u91c7\u7eb3\u635f\u5931\u51fd\u6570\u5728\u5d4c\u5165\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u81ea\u7136\u4ea7\u751f\u7684\u9ece\u66fc\u5ea6\u91cf\u8fd9\u4e00\u51e0\u4f55\u89c6\u89d2\uff0c\u5f00\u53d1\u51fa\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668\uff0c\u4ee5\u671f\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u83b7\u5f97\u66f4\u6709\u6548\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u5176\u6f5c\u5728\u7684\u7406\u8bba\u4f18\u52bf\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u7c7b\u65b0\u578b\u4f18\u5316\u5668\uff0c\u5176\u6838\u5fc3\u662f\u5229\u7528\u635f\u5931\u51fd\u6570\u666f\u89c2\u5d4c\u5165\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u81ea\u7136\u8bf1\u5bfc\u7684\u9ece\u66fc\u5ea6\u91cf\u3002\u8be5\u65b9\u6cd5\u5c06\u8fd9\u79cd\u51e0\u4f55\u89c6\u89d2\u5177\u4f53\u5316\u3002\u7814\u7a76\u8005\u5c06\u5176\u4e0e\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ecSGD\u3001Adam\u3001AdamW\u548cMuon\uff09\u5728\u4e00\u7cfb\u5217\u4efb\u52a1\u548c\u67b6\u6784\u4e0a\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u8be5\u57fa\u672c\u65b9\u6cd5\u8fd8\u53ef\u4ee5\u7528\u4e8e\u4fee\u6539\u4efb\u4f55\u73b0\u6709\u7684\u9884\u5904\u7406\u65b9\u6cd5\u3002", "result": "\u7ecf\u9a8c\u8bc1\uff0c\u8fd9\u6279\u65b0\u578b\u4f18\u5316\u5668\u5728\u4f4e\u7ef4\u793a\u4f8b\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u5e76\u4e14\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u7565\u6709\u6539\u8fdb\u3002\u7406\u8bba\u4e0a\uff0c\u5b83\u4eec\u5177\u6709\u7406\u60f3\u7684\u7279\u6027\uff1a\u6709\u6548\u5b66\u4e60\u7387\u80fd\u5728\u9ad8\u66f2\u7387\u533a\u57df\u81ea\u52a8\u964d\u4f4e\uff0c\u8d77\u5230\u5e73\u6ed1\u7684\u68af\u5ea6\u88c1\u526a\u4f5c\u7528\uff1b\u5176\u4e2d\u4e00\u4e2a\u53d8\u4f53\u8fd8\u80fd\u8bf1\u5bfc\u6709\u6548\u7684\u8ba1\u5212\u5b66\u4e60\u7387\uff0c\u5e76\u4e14\u89e3\u8026\u6743\u91cd\u8870\u51cf\u5728\u8be5\u51e0\u4f55\u89c6\u89d2\u4e0b\u662f\u81ea\u7136\u7684\u9009\u62e9\u3002\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0eAdam\u76f8\u5f53\u3002", "conclusion": "\u57fa\u4e8e\u9ece\u66fc\u5ea6\u91cf\u7684\u65b0\u578b\u4f18\u5316\u5668\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5177\u6709\u7406\u8bba\u4f18\u52bf\u7684\u65b9\u6848\u3002\u5b83\u4eec\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff08\u5c24\u5176\u5728\u4f4e\u7ef4\u573a\u666f\u4e0b\uff09\u8868\u73b0\u826f\u597d\uff0c\u4e14\u5728\u6574\u4f53\u4e0a\u7565\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u4fee\u6539\u73b0\u6709\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2509.03529", "pdf": "https://arxiv.org/pdf/2509.03529", "abs": "https://arxiv.org/abs/2509.03529", "authors": ["Alejandro \u00c1lvarez Castro", "Joaqu\u00edn Ordieres-Mer\u00e9"], "title": "Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages", "categories": ["cs.CL", "cs.AI", "eess.AS"], "comment": "Presented at NLMLT2025 (https://airccse.org/csit/V15N16.html), 15\n  pages, 5 figures", "summary": "Earnings calls represent a uniquely rich and semi-structured source of\nfinancial communication, blending scripted managerial commentary with\nunscripted analyst dialogue. Although recent advances in financial sentiment\nanalysis have integrated multi-modal signals, such as textual content and vocal\ntone, most systems rely on flat document-level or sentence-level models,\nfailing to capture the layered discourse structure of these interactions. This\npaper introduces a novel multi-modal framework designed to generate\nsemantically rich and structurally aware embeddings of earnings calls, by\nencoding them as hierarchical discourse trees. Each node, comprising either a\nmonologue or a question-answer pair, is enriched with emotional signals derived\nfrom text, audio, and video, as well as structured metadata including coherence\nscores, topic labels, and answer coverage assessments. A two-stage transformer\narchitecture is proposed: the first encodes multi-modal content and discourse\nmetadata at the node level using contrastive learning, while the second\nsynthesizes a global embedding for the entire conference. Experimental results\nreveal that the resulting embeddings form stable, semantically meaningful\nrepresentations that reflect affective tone, structural logic, and thematic\nalignment. Beyond financial reporting, the proposed system generalizes to other\nhigh-stakes unscripted communicative domains such as tele-medicine, education,\nand political discourse, offering a robust and explainable approach to\nmulti-modal discourse representation. This approach offers practical utility\nfor downstream tasks such as financial forecasting and discourse evaluation,\nwhile also providing a generalizable method applicable to other domains\ninvolving high-stakes communication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u8d22\u62a5\u7535\u8bdd\u4f1a\u8bae\u7f16\u7801\u4e3a\u5206\u5c42\u8bdd\u8bed\u6811\uff0c\u5e76\u4f7f\u7528\u4e24\u9636\u6bb5Transformer\u67b6\u6784\uff0c\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u3001\u7ed3\u6784\u611f\u77e5\u7684\u5d4c\u5165\u8868\u793a\uff0c\u6574\u5408\u4e86\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u9891\u548c\u7ed3\u6784\u5316\u5143\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u7684\u91d1\u878d\u60c5\u611f\u5206\u6790\u7cfb\u7edf\uff0c\u5373\u4f7f\u7ed3\u5408\u4e86\u591a\u6a21\u6001\u4fe1\u53f7\uff0c\u901a\u5e38\u4f9d\u8d56\u4e8e\u6241\u5e73\u7684\u6587\u6863\u7ea7\u6216\u53e5\u5b50\u7ea7\u6a21\u578b\uff0c\u672a\u80fd\u6355\u83b7\u8d22\u62a5\u7535\u8bdd\u4f1a\u8bae\u4e2d\u5206\u5c42\u7684\u8bdd\u8bed\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u590d\u6742\u91d1\u878d\u6c9f\u901a\u7684\u7406\u89e3\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u5c06\u8d22\u62a5\u7535\u8bdd\u4f1a\u8bae\u7f16\u7801\u4e3a\u5206\u5c42\u8bdd\u8bed\u6811\u7684\u591a\u6a21\u6001\u6846\u67b6\u3002\u6bcf\u4e2a\u8282\u70b9\uff08\u72ec\u767d\u6216\u95ee\u7b54\u5bf9\uff09\u901a\u8fc7\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u9891\u7684\u60c5\u611f\u4fe1\u53f7\u4ee5\u53ca\u8fde\u8d2f\u6027\u5f97\u5206\u3001\u4e3b\u9898\u6807\u7b7e\u548c\u7b54\u6848\u8986\u76d6\u7387\u7b49\u7ed3\u6784\u5316\u5143\u6570\u636e\u8fdb\u884c\u4e30\u5bcc\u3002\u91c7\u7528\u4e24\u9636\u6bb5Transformer\u67b6\u6784\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u7f16\u7801\u8282\u70b9\u7ea7\u591a\u6a21\u6001\u5185\u5bb9\u548c\u8bdd\u8bed\u5143\u6570\u636e\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7efc\u5408\u751f\u6210\u6574\u4e2a\u4f1a\u8bae\u7684\u5168\u5c40\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u751f\u6210\u7684\u5d4c\u5165\u5f62\u6210\u4e86\u7a33\u5b9a\u4e14\u5177\u6709\u8bed\u4e49\u610f\u4e49\u7684\u8868\u793a\uff0c\u80fd\u53cd\u6620\u60c5\u611f\u57fa\u8c03\u3001\u7ed3\u6784\u903b\u8f91\u548c\u4e3b\u9898\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u91d1\u878d\u9884\u6d4b\u548c\u8bdd\u8bed\u8bc4\u4f30\u7b49\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u4ef7\u503c\uff0c\u5e76\u4e14\u53ef\u4ee5\u63a8\u5e7f\u5230\u8fdc\u7a0b\u533b\u7597\u3001\u6559\u80b2\u548c\u653f\u6cbb\u8bdd\u8bed\u7b49\u5176\u4ed6\u9ad8\u98ce\u9669\u3001\u975e\u811a\u672c\u7684\u6c9f\u901a\u9886\u57df\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u8bdd\u8bed\u8868\u793a\u65b9\u6cd5\u3002"}}
{"id": "2509.03762", "pdf": "https://arxiv.org/pdf/2509.03762", "abs": "https://arxiv.org/abs/2509.03762", "authors": ["Sathwik Chadaga", "Eytan Modiano"], "title": "Drift Plus Optimistic Penalty -- A Learning Framework for Stochastic Network Optimization", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "We consider the problem of joint routing and scheduling in queueing networks,\nwhere the edge transmission costs are unknown. At each time-slot, the network\ncontroller receives noisy observations of transmission costs only for those\nedges it selects for transmission. The network controller's objective is to\nmake routing and scheduling decisions so that the total expected cost is\nminimized. This problem exhibits an exploration-exploitation trade-off,\nhowever, previous bandit-style solutions cannot be directly applied to this\nproblem due to the queueing dynamics. In order to ensure network stability, the\nnetwork controller needs to optimize throughput and cost simultaneously. We\nshow that the best achievable cost is lower bounded by the solution to a static\noptimization problem, and develop a network control policy using techniques\nfrom Lyapunov drift-plus-penalty optimization and multi-arm bandits. We show\nthat the policy achieves a sub-linear regret of order $O(\\sqrt{T}\\log T)$, as\ncompared to the best policy that has complete knowledge of arrivals and costs.\nFinally, we evaluate the proposed policy using simulations and show that its\nregret is indeed sub-linear.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.03614", "pdf": "https://arxiv.org/pdf/2509.03614", "abs": "https://arxiv.org/abs/2509.03614", "authors": ["Seungho Choe", "Xiaoli Qin", "Abubakr Shafique", "Amanda Dy", "Susan Done", "Dimitrios Androutsos", "April Khademi"], "title": "Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge", "categories": ["cs.CV"], "comment": "4 pages, 1 figures, final submission for MIDOG 2025 challenge", "summary": "Counting mitotic figures is time-intensive for pathologists and leads to\ninter-observer variability. Artificial intelligence (AI) promises a solution by\nautomatically detecting mitotic figures while maintaining decision consistency.\nHowever, AI tools are susceptible to domain shift, where a significant drop in\nperformance can occur due to differences in the training and testing sets,\nincluding morphological diversity between organs, species, and variations in\nstaining protocols. Furthermore, the number of mitoses is much less than the\ncount of normal nuclei, which introduces severely imbalanced data for the\ndetection task. In this work, we formulate mitosis detection as a pixel-level\nsegmentation and propose a teacher-student model that simultaneously addresses\nmitosis detection (Track 1) and atypical mitosis classification (Track 2). Our\nmethod is based on a UNet segmentation backbone that integrates domain\ngeneralization modules, namely contrastive representation learning and\ndomain-adversarial training. A teacher-student strategy is employed to generate\npixel-level pseudo-masks not only for annotated mitoses and hard negatives but\nalso for normal nuclei, thereby enhancing feature discrimination and improving\nrobustness against domain shift. For the classification task, we introduce a\nmulti-scale CNN classifier that leverages feature maps from the segmentation\nmodel within a multi-task learning paradigm. On the preliminary test set, the\nalgorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of\n0.8414 in Track 2, demonstrating the effectiveness of integrating\nsegmentation-based detection and classification into a unified framework for\nrobust mitosis analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eUNet\u548c\u6559\u5e08-\u5b66\u751f\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7\u5206\u5272\u5904\u7406\u6709\u4e1d\u5206\u88c2\u68c0\u6d4b\u548c\u5f02\u5e38\u6709\u4e1d\u5206\u88c2\u5206\u7c7b\uff0c\u5e76\u96c6\u6210\u57df\u6cdb\u5316\u6a21\u5757\u4ee5\u5e94\u5bf9\u57df\u504f\u79fb\u548c\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u75c5\u7406\u5b66\u5bb6\u624b\u52a8\u8ba1\u6570\u6709\u4e1d\u5206\u88c2\u8017\u65f6\u4e14\u5b58\u5728\u89c2\u5bdf\u8005\u95f4\u5dee\u5f02\u3002AI\u81ea\u52a8\u5316\u68c0\u6d4b\u867d\u6709\u524d\u666f\uff0c\u4f46\u9762\u4e34\u57df\u504f\u79fb\uff08\u4e0d\u540c\u5668\u5b98\u3001\u7269\u79cd\u3001\u67d3\u8272\u65b9\u6848\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff09\u548c\u6570\u636e\u4e25\u91cd\u4e0d\u5e73\u8861\uff08\u6709\u4e1d\u5206\u88c2\u6570\u91cf\u8fdc\u5c11\u4e8e\u6b63\u5e38\u7ec6\u80de\u6838\uff09\u7684\u6311\u6218\u3002", "method": "\u5c06\u6709\u4e1d\u5206\u88c2\u68c0\u6d4b\u516c\u5f0f\u5316\u4e3a\u50cf\u7d20\u7ea7\u5206\u5272\u4efb\u52a1\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u6559\u5e08-\u5b66\u751f\u6a21\u578b\u540c\u65f6\u5904\u7406\u6709\u4e1d\u5206\u88c2\u68c0\u6d4b\uff08Track 1\uff09\u548c\u5f02\u5e38\u6709\u4e1d\u5206\u88c2\u5206\u7c7b\uff08Track 2\uff09\u3002\u8be5\u65b9\u6cd5\u4ee5UNet\u5206\u5272\u9aa8\u5e72\u4e3a\u57fa\u7840\uff0c\u96c6\u6210\u4e86\u5bf9\u6bd4\u8868\u5f81\u5b66\u4e60\u548c\u57df\u5bf9\u6297\u8bad\u7ec3\u7b49\u57df\u6cdb\u5316\u6a21\u5757\u3002\u91c7\u7528\u6559\u5e08-\u5b66\u751f\u7b56\u7565\u751f\u6210\u50cf\u7d20\u7ea7\u4f2a\u63a9\u819c\uff08\u5305\u62ec\u5df2\u6807\u6ce8\u7684\u6709\u4e1d\u5206\u88c2\u3001\u96be\u8d1f\u6837\u672c\u548c\u6b63\u5e38\u7ec6\u80de\u6838\uff09\uff0c\u4ee5\u589e\u5f3a\u7279\u5f81\u5224\u522b\u529b\u5e76\u63d0\u9ad8\u5bf9\u57df\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002\u5206\u7c7b\u4efb\u52a1\u5f15\u5165\u4e00\u4e2a\u591a\u5c3a\u5ea6CNN\u5206\u7c7b\u5668\uff0c\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u8303\u5f0f\u4e2d\u5229\u7528\u5206\u5272\u6a21\u578b\u7684\u7279\u5f81\u56fe\u3002", "result": "\u5728\u521d\u6b65\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u8be5\u7b97\u6cd5\u5728Track 1\uff08\u68c0\u6d4b\uff09\u4e2d\u5b9e\u73b0\u4e860.7660\u7684F1\u5206\u6570\uff0c\u5728Track 2\uff08\u5206\u7c7b\uff09\u4e2d\u5b9e\u73b0\u4e860.8414\u7684\u5e73\u8861\u51c6\u786e\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5c06\u57fa\u4e8e\u5206\u5272\u7684\u68c0\u6d4b\u548c\u5206\u7c7b\u96c6\u6210\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\u7684\u65b9\u6cd5\uff0c\u5728\u5b9e\u73b0\u9c81\u68d2\u7684\u6709\u4e1d\u5206\u88c2\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002"}}
{"id": "2509.03548", "pdf": "https://arxiv.org/pdf/2509.03548", "abs": "https://arxiv.org/abs/2509.03548", "authors": ["Jo\u00e3o P. Arroyo", "Jo\u00e3o G. Rodrigues", "Daniel Lawand", "Denis D. Mau\u00e1", "Junkyu Lee", "Radu Marinescu", "Alex Gray", "Eduardo R. Laurentino", "Fabio G. Cozman"], "title": "Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models", "categories": ["cs.AI"], "comment": "Accepted at the Causal Abstractions and Representations (CAR)\n  workshop of the 41st Conference on Uncertainty in Artificial Intelligence\n  (UAI 2025)", "summary": "We investigate partially identifiable queries in a class of causal models. We\nfocus on acyclic Structural Causal Models that are quasi-Markovian (that is,\neach endogenous variable is connected with at most one exogenous confounder).\nWe look into scenarios where endogenous variables are observed (and a\ndistribution over them is known), while exogenous variables are not fully\nspecified. This leads to a representation that is in essence a Bayesian network\nwhere the distribution of root variables is not uniquely determined. In such\ncircumstances, it may not be possible to precisely compute a probability value\nof interest. We thus study the computation of tight probability bounds, a\nproblem that has been solved by multilinear programming in general, and by\nlinear programming when a single confounded component is intervened upon. We\npresent a new algorithm to simplify the construction of such programs by\nexploiting input probabilities over endogenous variables. For scenarios with a\nsingle intervention, we apply column generation to compute a probability bound\nthrough a sequence of auxiliary linear integer programs, thus showing that a\nrepresentation with polynomial cardinality for exogenous variables is possible.\nExperiments show column generation techniques to be superior to existing\nmethods.", "AI": {"tldr": "\u5728\u90e8\u5206\u53ef\u8bc6\u522b\u7684\u56e0\u679c\u6a21\u578b\u4e2d\uff0c\u7531\u4e8e\u5916\u751f\u53d8\u91cf\u672a\u5b8c\u5168\u6307\u5b9a\uff0c\u65e0\u6cd5\u7cbe\u786e\u8ba1\u7b97\u6982\u7387\uff0c\u6545\u7814\u7a76\u8ba1\u7b97\u7d27\u5bc6\u6982\u7387\u754c\u9650\u7684\u65b9\u6cd5\u3002\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u5185\u751f\u53d8\u91cf\u6982\u7387\u7b80\u5316\u7a0b\u5e8f\u6784\u5efa\u7684\u65b0\u7b97\u6cd5\uff0c\u5e76\u9488\u5bf9\u5355\u4e00\u5e72\u9884\u60c5\u51b5\uff0c\u91c7\u7528\u5217\u751f\u6210\u6280\u672f\u8ba1\u7b97\u6982\u7387\u754c\u9650\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u56e0\u679c\u6a21\u578b\u4e2d\uff0c\u5f53\u5916\u751f\u53d8\u91cf\u672a\u5b8c\u5168\u6307\u5b9a\u800c\u5185\u751f\u53d8\u91cf\u88ab\u89c2\u6d4b\u65f6\uff0c\u65e0\u6cd5\u7cbe\u786e\u8ba1\u7b97\u611f\u5174\u8da3\u7684\u6982\u7387\u503c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7814\u7a76\u8ba1\u7b97\u7d27\u5bc6\u7684\u6982\u7387\u754c\u9650\u3002", "method": "1. \u7814\u7a76\u51c6\u9a6c\u5c14\u53ef\u592b\u975e\u5faa\u73af\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u90e8\u5206\u53ef\u8bc6\u522b\u67e5\u8be2\u30022. \u63d0\u51fa\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5185\u751f\u53d8\u91cf\u7684\u8f93\u5165\u6982\u7387\u6765\u7b80\u5316\u8ba1\u7b97\u6982\u7387\u754c\u9650\u6240\u9700\u7684\u591a\u7ebf\u6027/\u7ebf\u6027\u7a0b\u5e8f\u7684\u6784\u5efa\u30023. \u5bf9\u4e8e\u5355\u4e00\u5e72\u9884\u573a\u666f\uff0c\u5e94\u7528\u5217\u751f\u6210\u6280\u672f\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u8f85\u52a9\u7ebf\u6027\u6574\u6570\u89c4\u5212\u8ba1\u7b97\u6982\u7387\u754c\u9650\uff0c\u8bc1\u660e\u4e86\u5916\u751f\u53d8\u91cf\u591a\u9879\u5f0f\u57fa\u6570\u8868\u793a\u7684\u53ef\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5217\u751f\u6210\u6280\u672f\u5728\u8ba1\u7b97\u6982\u7387\u754c\u9650\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5355\u4e00\u5e72\u9884\u573a\u666f\u7684\u5217\u751f\u6210\u6280\u672f\uff0c\u4e3a\u5728\u5177\u6709\u672a\u5b8c\u5168\u6307\u5b9a\u5916\u751f\u53d8\u91cf\u7684\u90e8\u5206\u53ef\u8bc6\u522b\u56e0\u679c\u6a21\u578b\u4e2d\u8ba1\u7b97\u7d27\u5bc6\u6982\u7387\u754c\u9650\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u66f4\u4f18\u8d8a\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u8ba1\u7b97\u3002"}}
{"id": "2509.03643", "pdf": "https://arxiv.org/pdf/2509.03643", "abs": "https://arxiv.org/abs/2509.03643", "authors": ["Chao Pang", "Jiheum Park", "Xinzhuo Jiang", "Nishanth Parameshwar Pavinkurve", "Krishna S. Kalluri", "Shalmali Joshi", "No\u00e9mie Elhadad", "Karthik Natarajan"], "title": "CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Electronic Health Records (EHRs) provide a rich, longitudinal view of patient\nhealth and hold significant potential for advancing clinical decision support,\nrisk prediction, and data-driven healthcare research. However, most artificial\nintelligence (AI) models for EHRs are designed for narrow, single-purpose\ntasks, limiting their generalizability and utility in real-world settings.\nHere, we present CEHR-GPT, a general-purpose foundation model for EHR data that\nunifies three essential capabilities - feature representation, zero-shot\nprediction, and synthetic data generation - within a single architecture. To\nsupport temporal reasoning over clinical sequences, \\cehrgpt{} incorporates a\nnovel time-token-based learning framework that explicitly encodes patients'\ndynamic timelines into the model structure. CEHR-GPT demonstrates strong\nperformance across all three tasks and generalizes effectively to external\ndatasets through vocabulary expansion and fine-tuning. Its versatility enables\nrapid model development, cohort discovery, and patient outcome forecasting\nwithout the need for task-specific retraining.", "AI": {"tldr": "CEHR-GPT\u662f\u4e00\u4e2a\u901a\u7528\u578bEHR\u57fa\u7840\u6a21\u578b\uff0c\u96c6\u6210\u4e86\u7279\u5f81\u8868\u793a\u3001\u96f6\u6837\u672c\u9884\u6d4b\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u65f6\u95f4\u4ee4\u724c\u5b66\u4e60\u6846\u67b6\u5904\u7406\u65f6\u5e8f\u6570\u636e\uff0c\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5927\u591a\u6570EHR AI\u6a21\u578b\u8bbe\u8ba1\u7528\u4e8e\u72ed\u7a84\u7684\u5355\u4e00\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u5176\u901a\u7528\u6027\u548c\u5728\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faCEHR-GPT\uff0c\u4e00\u4e2a\u7edf\u4e00\u67b6\u6784\u7684\u901a\u7528EHR\u57fa\u7840\u6a21\u578b\uff0c\u5177\u5907\u7279\u5f81\u8868\u793a\u3001\u96f6\u6837\u672c\u9884\u6d4b\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u80fd\u529b\u3002\u901a\u8fc7\u65b0\u9896\u7684\u65f6\u95f4\u4ee4\u724c\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u5f0f\u7f16\u7801\u60a3\u8005\u52a8\u6001\u65f6\u95f4\u7ebf\u4ee5\u652f\u6301\u65f6\u5e8f\u63a8\u7406\u3002", "result": "CEHR-GPT\u5728\u6240\u6709\u4e09\u9879\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u901a\u8fc7\u8bcd\u6c47\u6269\u5c55\u548c\u5fae\u8c03\u6709\u6548\u6cdb\u5316\u5230\u5916\u90e8\u6570\u636e\u96c6\u3002", "conclusion": "CEHR-GPT\u7684\u901a\u7528\u6027\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u518d\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u5feb\u901f\u6a21\u578b\u5f00\u53d1\u3001\u961f\u5217\u53d1\u73b0\u548c\u60a3\u8005\u7ed3\u5c40\u9884\u6d4b\u3002"}}
{"id": "2509.03530", "pdf": "https://arxiv.org/pdf/2509.03530", "abs": "https://arxiv.org/abs/2509.03530", "authors": ["Paul Blum", "Enrico Liscio", "Ruixuan Zhang", "Caroline Figueroa", "Pradeep K. Murukannaiah"], "title": "Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts", "categories": ["cs.CL"], "comment": null, "summary": "Suicide is a leading cause of death among adolescents (12-18), yet predicting\nit remains a significant challenge. Many cases go undetected due to a lack of\ncontact with mental health services. Social media, however, offers a unique\nopportunity, as young people often share their thoughts and struggles online in\nreal time. In this work, we propose a novel task and method to approach it:\npredicting suicidal ideation and behavior (SIB) from forum posts before an\nadolescent explicitly expresses suicidal ideation on an online forum. This\npredictive framing, where no self-disclosure is used as input at any stage,\nremains largely unexplored in the suicide prediction literature. To this end,\nwe introduce Early-SIB, a transformer-based model that sequentially processes\nthe posts a user writes and engages with to predict whether they will write a\nSIB post. Our model achieves a balanced accuracy of 0.73 for predicting future\nSIB on a Dutch youth forum, demonstrating that such tools can offer a\nmeaningful addition to traditional methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEarly-SIB\uff0c\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u9752\u5c11\u5e74\u660e\u786e\u8868\u8fbe\u81ea\u6740\u610f\u5ff5\u4e4b\u524d\uff0c\u4ece\u5176\u5728\u7ebf\u8bba\u575b\u53d1\u5e16\u4e2d\u9884\u6d4b\u81ea\u6740\u610f\u5ff5\u548c\u884c\u4e3a\uff08SIB\uff09\uff0c\u5e76\u5728\u8377\u5170\u9752\u5c11\u5e74\u8bba\u575b\u4e0a\u8fbe\u52300.73\u7684\u5e73\u8861\u51c6\u786e\u7387\u3002", "motivation": "\u9752\u5c11\u5e74\u81ea\u6740\u662f\u4e3b\u8981\u6b7b\u56e0\u4e4b\u4e00\uff0c\u4f46\u96be\u4ee5\u9884\u6d4b\u4e14\u5e38\u56e0\u7f3a\u4e4f\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u63a5\u89e6\u800c\u672a\u88ab\u53d1\u73b0\u3002\u793e\u4ea4\u5a92\u4f53\u4e3a\u65e9\u671f\u68c0\u6d4b\u63d0\u4f9b\u4e86\u72ec\u7279\u673a\u4f1a\uff0c\u9752\u5c11\u5e74\u5e38\u5728\u7ebf\u5206\u4eab\u601d\u60f3\u548c\u56f0\u6270\u3002", "method": "\u63d0\u51fa\u4e00\u9879\u65b0\u4efb\u52a1\u548c\u65b9\u6cd5\uff1a\u5728\u9752\u5c11\u5e74\u660e\u786e\u8868\u8fbe\u81ea\u6740\u610f\u5ff5\u524d\uff0c\u4ece\u8bba\u575b\u5e16\u5b50\u4e2d\u9884\u6d4bSIB\u3002\u4f7f\u7528Early-SIB\uff0c\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u987a\u5e8f\u5904\u7406\u7528\u6237\u64b0\u5199\u548c\u4e92\u52a8\u7684\u5e16\u5b50\uff0c\u4ee5\u9884\u6d4b\u5176\u662f\u5426\u4f1a\u53d1\u5e03SIB\u76f8\u5173\u5185\u5bb9\uff0c\u4e0d\u4f7f\u7528\u4efb\u4f55\u81ea\u6211\u62ab\u9732\u4f5c\u4e3a\u8f93\u5165\u3002", "result": "Early-SIB\u6a21\u578b\u5728\u8377\u5170\u9752\u5c11\u5e74\u8bba\u575b\u4e0a\u9884\u6d4b\u672a\u6765SIB\u7684\u5e73\u8861\u51c6\u786e\u7387\u8fbe\u52300.73\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u6b64\u7c7b\u5de5\u5177\u53ef\u4ee5\u4e3a\u4f20\u7edf\u7684\u81ea\u6740\u9884\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u8865\u5145\u3002"}}
{"id": "2509.03818", "pdf": "https://arxiv.org/pdf/2509.03818", "abs": "https://arxiv.org/abs/2509.03818", "authors": ["Sherwan Jalal Abdullah", "Sravan Reddy Chintareddy", "Victor S. Frost", "Shawn Keshmiri", "Morteza Hashemi"], "title": "A Versatile and Programmable UAV Platform for Radio Access Network and End-to-End Cellular Measurements", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "In this work, we develop a measurement platform to capture mobile network\nperformance metrics including coverage and quality of service in regions where\nconventional coverage testing approaches are frequently time-intensive,\nlabor-demanding, and occasionally hazardous. Traditionally, crowd-sourcing\nmethods are used to collect cellular network performance metrics. However,\nthese approaches are inadequate in rural areas due to low-density population,\nand difficult terrain. The platform described here is a UAV-based and is\ndesigned to investigate the mobile network performance through aerial\noperations and gather Radio Access Network (RAN) signal alongside end-to-end\nnetwork performance metrics. Our platform gathers metrics through the\nintegration of an onboard computation unit and commercial off-the-shelf\ncellular modem. The gathered data are subsequently analyzed and displayed using\ngeospatial mapping utilities and statistical techniques to deliver key\nobservations on cellular network performance. Experimental results showed that\nthe received signal power improves at higher altitudes due to enhanced\nline-of-sight (LoS) conditions as expected. However, the signal quality\ndegrades as a result of increased interference from neighboring cells. The\nanalysis reveals that for most of the geographic area covered in the initial\nexperiments the system maintained acceptable signal quality, with adequate\nthroughput performance for both uplink and downlink communications, while\nmaintaining satisfactory round-trip time characteristics. Notably, the\nexperiment showed that a strong radio signal metric for a given cell does not\nnecessarily translate to consistent spatial coverage across the tested region.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u79fb\u52a8\u7f51\u7edc\u6027\u80fd\u6d4b\u91cf\u5e73\u53f0\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u504f\u8fdc\u6216\u590d\u6742\u533a\u57df\u7684\u5c40\u9650\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5347\u9ad8\u9ad8\u5ea6\u4f1a\u6539\u5584\u4fe1\u53f7\u5f3a\u5ea6\u4f46\u964d\u4f4e\u4fe1\u53f7\u8d28\u91cf\uff0c\u5e76\u4e14\u5f3a\u4fe1\u53f7\u4e0d\u4e00\u5b9a\u610f\u5473\u7740\u4e00\u81f4\u7684\u8986\u76d6\u3002", "motivation": "\u4f20\u7edf\u79fb\u52a8\u7f51\u7edc\u8986\u76d6\u6d4b\u8bd5\u8017\u65f6\u3001\u8d39\u529b\u4e14\u6709\u65f6\u5371\u9669\uff1b\u4f17\u5305\u65b9\u6cd5\u5728\u519c\u6751\u5730\u533a\u56e0\u4eba\u53e3\u7a00\u758f\u548c\u5730\u5f62\u590d\u6742\u800c\u5931\u6548\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u6d4b\u91cf\u5e73\u53f0\uff0c\u901a\u8fc7\u7a7a\u4e2d\u4f5c\u4e1a\u6536\u96c6\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\uff08RAN\uff09\u4fe1\u53f7\u548c\u7aef\u5230\u7aef\u7f51\u7edc\u6027\u80fd\u6307\u6807\u3002\u5e73\u53f0\u6574\u5408\u4e86\u673a\u8f7d\u8ba1\u7b97\u5355\u5143\u548c\u5546\u7528\u73b0\u6210\u8702\u7a9d\u8c03\u5236\u89e3\u8c03\u5668\uff0c\u6536\u96c6\u7684\u6570\u636e\u4f7f\u7528\u5730\u7406\u7a7a\u95f4\u6620\u5c04\u5de5\u5177\u548c\u7edf\u8ba1\u6280\u672f\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u8f83\u9ad8\u6d77\u62d4\u5904\uff0c\u7531\u4e8e\u89c6\u8ddd\u6761\u4ef6\u6539\u5584\uff0c\u63a5\u6536\u4fe1\u53f7\u529f\u7387\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u7531\u4e8e\u90bb\u8fd1\u5c0f\u533a\u7684\u5e72\u6270\u589e\u52a0\uff0c\u4fe1\u53f7\u8d28\u91cf\u4e0b\u964d\u3002\u5728\u5927\u90e8\u5206\u6d4b\u8bd5\u533a\u57df\uff0c\u7cfb\u7edf\u7ef4\u6301\u4e86\u53ef\u63a5\u53d7\u7684\u4fe1\u53f7\u8d28\u91cf\u3001\u8db3\u591f\u7684\u4e0a\u4e0b\u884c\u541e\u5410\u91cf\u548c\u6ee1\u610f\u7684\u5f80\u8fd4\u65f6\u95f4\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5f3a\u5927\u7684\u65e0\u7ebf\u7535\u4fe1\u53f7\u6307\u6807\u5e76\u4e0d\u4e00\u5b9a\u610f\u5473\u7740\u5728\u6574\u4e2a\u6d4b\u8bd5\u533a\u57df\u5185\u5177\u6709\u4e00\u81f4\u7684\u7a7a\u95f4\u8986\u76d6\u3002", "conclusion": "\u8be5\u65e0\u4eba\u673a\u5e73\u53f0\u4e3a\u4f20\u7edf\u6d4b\u8bd5\u53d7\u9650\u533a\u57df\u7684\u79fb\u52a8\u7f51\u7edc\u6027\u80fd\u6d4b\u91cf\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136\u9ad8\u6d77\u62d4\u6709\u52a9\u4e8e\u4fe1\u53f7\u5f3a\u5ea6\uff0c\u4f46\u4f1a\u727a\u7272\u4fe1\u53f7\u8d28\u91cf\uff1b\u540c\u65f6\uff0c\u4ec5\u9760\u4fe1\u53f7\u5f3a\u5ea6\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u4e00\u81f4\u7684\u533a\u57df\u8986\u76d6\u3002"}}
{"id": "2509.03616", "pdf": "https://arxiv.org/pdf/2509.03616", "abs": "https://arxiv.org/abs/2509.03616", "authors": ["Rajeev Ranjan Dwivedi", "Ankur Kumar", "Vinod K Kurmi"], "title": "Multi Attribute Bias Mitigation via Representation Learning", "categories": ["cs.CV"], "comment": "ECAI 2025 (28th European Conference on Artificial Intelligence)", "summary": "Real world images frequently exhibit multiple overlapping biases, including\ntextures, watermarks, gendered makeup, scene object pairings, etc. These biases\ncollectively impair the performance of modern vision models, undermining both\ntheir robustness and fairness. Addressing these biases individually proves\ninadequate, as mitigating one bias often permits or intensifies others. We\ntackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a\nlean two stage framework that needs group labels only while training and\nminimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)\ndeliberately identifies the influence of known shortcuts by training encoders\nfor each attribute and integrating them with the main backbone, compelling the\nclassifier to explicitly recognize these biases. Then Gradient Suppression Fine\nTuning prunes those very bias directions from the backbone's gradients, leaving\na single compact network that ignores all the shortcuts it just learned to\nrecognize. Moreover we find that existing bias metrics break under subgroup\nimbalance and train test distribution shifts, so we introduce Scaled Bias\nAmplification (SBA): a test time measure that disentangles model induced bias\namplification from distributional differences. We validate GMBM on FB CMNIST,\nCelebA, and COCO, where we boost worst group accuracy, halve multi attribute\nbias amplification, and set a new low in SBA even as bias complexity and\ndistribution shifts intensify, making GMBM the first practical, end to end\nmultibias solution for visual recognition. Project page:\nhttp://visdomlab.github.io/GMBM/", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGMBM\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\uff08ABIL\u548c\u68af\u5ea6\u6291\u5236\u5fae\u8c03\uff09\u89e3\u51b3\u89c6\u89c9\u6a21\u578b\u4e2d\u591a\u91cd\u91cd\u53e0\u504f\u5dee\u95ee\u9898\uff0c\u5e76\u5f15\u5165SBA\u6307\u6807\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u56fe\u50cf\u4e2d\u666e\u904d\u5b58\u5728\u591a\u79cd\u91cd\u53e0\u504f\u89c1\uff08\u5982\u7eb9\u7406\u3001\u6c34\u5370\u3001\u6027\u522b\u5316\u5986\u7b49\uff09\uff0c\u8fd9\u4e9b\u504f\u89c1\u4e25\u91cd\u635f\u5bb3\u4e86\u73b0\u4ee3\u89c6\u89c9\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u3002\u5355\u72ec\u5904\u7406\u6bcf\u79cd\u504f\u89c1\u6548\u679c\u4e0d\u4f73\uff0c\u751a\u81f3\u53ef\u80fd\u52a0\u5267\u5176\u4ed6\u504f\u89c1\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u5e7f\u4e49\u591a\u504f\u89c1\u7f13\u89e3\uff08GMBM\uff09\u6846\u67b6\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\n1.  **\u81ea\u9002\u5e94\u504f\u89c1\u96c6\u6210\u5b66\u4e60 (ABIL)**\uff1a\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u5c5e\u6027\u8bad\u7ec3\u7f16\u7801\u5668\u5e76\u5c06\u5176\u4e0e\u4e3b\u5e72\u7f51\u7edc\u96c6\u6210\uff0c\u5f3a\u5236\u5206\u7c7b\u5668\u660e\u786e\u8bc6\u522b\u5df2\u77e5\u6377\u5f84\u504f\u89c1\u7684\u5f71\u54cd\u3002\n2.  **\u68af\u5ea6\u6291\u5236\u5fae\u8c03 (Gradient Suppression Fine Tuning)**\uff1a\u4ece\u4e3b\u5e72\u7f51\u7edc\u7684\u68af\u5ea6\u4e2d\u4fee\u526a\u6389\u8fd9\u4e9b\u504f\u89c1\u65b9\u5411\uff0c\u7559\u4e0b\u4e00\u4e2a\u7d27\u51d1\u7684\u7f51\u7edc\uff0c\u4f7f\u5176\u5ffd\u7565\u4e4b\u524d\u8bc6\u522b\u51fa\u7684\u6240\u6709\u6377\u5f84\u3002\n\u6b64\u5916\uff0c\u4e3a\u89e3\u51b3\u73b0\u6709\u504f\u89c1\u5ea6\u91cf\u5728\u5b50\u7ec4\u4e0d\u5e73\u8861\u548c\u8bad\u7ec3\u6d4b\u8bd5\u5206\u5e03\u6f02\u79fb\u4e0b\u7684\u5931\u6548\u95ee\u9898\uff0c\u7814\u7a76\u5f15\u5165\u4e86**\u5c3a\u5ea6\u504f\u89c1\u653e\u5927 (SBA)**\uff1a\u4e00\u79cd\u5728\u6d4b\u8bd5\u65f6\u8861\u91cf\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u79bb\u6a21\u578b\u5f15\u8d77\u7684\u504f\u89c1\u653e\u5927\u548c\u5206\u5e03\u5dee\u5f02\u3002", "result": "GMBM\u5728FB CMNIST\u3001CelebA\u548cCOCO\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u5b83\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u5dee\u7ec4\u51c6\u786e\u7387\uff0c\u5c06\u591a\u5c5e\u6027\u504f\u89c1\u653e\u5927\u51cf\u534a\uff0c\u5e76\u5728\u504f\u89c1\u590d\u6742\u6027\u548c\u5206\u5e03\u6f02\u79fb\u52a0\u5267\u7684\u60c5\u51b5\u4e0b\uff0cSBA\u6307\u6807\u8fbe\u5230\u4e86\u65b0\u4f4e\u3002", "conclusion": "GMBM\u662f\u7b2c\u4e00\u4e2a\u9488\u5bf9\u89c6\u89c9\u8bc6\u522b\u9886\u57df\u4e2d\u591a\u91cd\u504f\u89c1\u95ee\u9898\u7684\u5b9e\u7528\u3001\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.03550", "pdf": "https://arxiv.org/pdf/2509.03550", "abs": "https://arxiv.org/abs/2509.03550", "authors": ["Tonghe Li", "Jixin Liu", "Weili Zeng", "Hao Jiang"], "title": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "categories": ["cs.AI"], "comment": "59 pages,13 figures, 3 tables", "summary": "In the context of continuously rising global air traffic, efficient and safe\nConflict Detection and Resolution (CD&R) is paramount for air traffic\nmanagement. Although Deep Reinforcement Learning (DRL) offers a promising\npathway for CD&R automation, existing approaches commonly suffer from a\n\"unimodal bias\" in their policies. This leads to a critical lack of\ndecision-making flexibility when confronted with complex and dynamic\nconstraints, often resulting in \"decision deadlocks.\" To overcome this\nlimitation, this paper pioneers the integration of diffusion probabilistic\nmodels into the safety-critical task of CD&R, proposing a novel autonomous\nconflict resolution framework named Diffusion-AC. Diverging from conventional\nmethods that converge to a single optimal solution, our framework models its\npolicy as a reverse denoising process guided by a value function, enabling it\nto generate a rich, high-quality, and multimodal action distribution. This core\narchitecture is complemented by a Density-Progressive Safety Curriculum (DPSC),\na training mechanism that ensures stable and efficient learning as the agent\nprogresses from sparse to high-density traffic environments. Extensive\nsimulation experiments demonstrate that the proposed method significantly\noutperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the\nmost challenging high-density scenarios, Diffusion-AC not only maintains a high\nsuccess rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions\n(NMACs) by approximately 59% compared to the next-best-performing baseline,\nsignificantly enhancing the system's safety margin. This performance leap stems\nfrom its unique multimodal decision-making capability, which allows the agent\nto flexibly switch to effective alternative maneuvers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiffusion-AC\u7684\u65b0\u578b\u81ea\u4e3b\u51b2\u7a81\u89e3\u51b3\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6269\u6563\u6982\u7387\u6a21\u578b\u96c6\u6210\u5230\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u751f\u6210\u591a\u6a21\u6001\u52a8\u4f5c\u5206\u5e03\u5e76\u7ed3\u5408\u5bc6\u5ea6\u6e10\u8fdb\u5b89\u5168\u8bfe\u7a0b\uff0c\u6709\u6548\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5355\u6a21\u6001\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u7406\u4e2d\u51b2\u7a81\u89e3\u51b3\u7684\u6210\u529f\u7387\u548c\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5bc6\u5ea6\u4ea4\u901a\u573a\u666f\u4e0b\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u8fd1\u8ddd\u7a7a\u4e2d\u78b0\u649e\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7a7a\u4e2d\u4ea4\u901a\u51b2\u7a81\u68c0\u6d4b\u4e0e\u89e3\u51b3\uff08CD&R\uff09\u65b9\u6cd5\u5b58\u5728\u201c\u5355\u6a21\u6001\u504f\u5dee\u201d\u95ee\u9898\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u52a8\u6001\u7ea6\u675f\u4e0b\u51b3\u7b56\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u51fa\u73b0\u201c\u51b3\u7b56\u50f5\u5c40\u201d\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7075\u6d3b\u3001\u9c81\u68d2\u7684\u51b2\u7a81\u89e3\u51b3\u673a\u5236\u3002", "method": "\u672c\u6587\u9996\u521b\u6027\u5730\u5c06\u6269\u6563\u6982\u7387\u6a21\u578b\u6574\u5408\u5230CD&R\u4efb\u52a1\u4e2d\uff0c\u63d0\u51fa\u4e86Diffusion-AC\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u7b56\u7565\u5efa\u6a21\u4e3a\u7531\u4ef7\u503c\u51fd\u6570\u5f15\u5bfc\u7684\u9006\u5411\u53bb\u566a\u8fc7\u7a0b\uff0c\u4ee5\u751f\u6210\u4e30\u5bcc\u3001\u9ad8\u8d28\u91cf\u548c\u591a\u6a21\u6001\u7684\u52a8\u4f5c\u5206\u5e03\u3002\u540c\u65f6\uff0c\u8f85\u4ee5\u5bc6\u5ea6\u6e10\u8fdb\u5b89\u5168\u8bfe\u7a0b\uff08DPSC\uff09\u8bad\u7ec3\u673a\u5236\uff0c\u786e\u4fdd\u5728\u4ece\u7a00\u758f\u5230\u9ad8\u5bc6\u5ea6\u4ea4\u901a\u73af\u5883\u7684\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u7a33\u5b9a\u548c\u9ad8\u6548\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0cDiffusion-AC\u663e\u8457\u4f18\u4e8e\u4e00\u7cfb\u5217\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u3002\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u9ad8\u5bc6\u5ea6\u573a\u666f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4fdd\u6301\u4e8694.1%\u7684\u9ad8\u6210\u529f\u7387\uff0c\u8fd8\u5c06\u8fd1\u8ddd\u7a7a\u4e2d\u78b0\u649e\uff08NMACs\uff09\u7684\u53d1\u751f\u7387\u6bd4\u6b21\u4f18\u57fa\u7ebf\u964d\u4f4e\u4e86\u7ea659%\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u7cfb\u7edf\u5b89\u5168\u6027\u3002\u5176\u6027\u80fd\u63d0\u5347\u6e90\u4e8e\u72ec\u7279\u7684\u591a\u6a21\u6001\u51b3\u7b56\u80fd\u529b\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u7075\u6d3b\u5207\u6362\u5230\u6709\u6548\u7684\u66ff\u4ee3\u64cd\u4f5c\u3002", "conclusion": "Diffusion-AC\u901a\u8fc7\u5f15\u5165\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u591a\u6a21\u6001\u51b3\u7b56\u80fd\u529b\uff0c\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709DRL\u5728CD&R\u4e2d\u9762\u4e34\u7684\u5355\u6a21\u6001\u504f\u5dee\u548c\u51b3\u7b56\u50f5\u5c40\u95ee\u9898\u3002\u8fd9\u663e\u8457\u63d0\u9ad8\u4e86\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u7406\u7cfb\u7edf\u5728\u590d\u6742\u9ad8\u5bc6\u5ea6\u73af\u5883\u4e0b\u7684\u51b2\u7a81\u89e3\u51b3\u6210\u529f\u7387\u548c\u5b89\u5168\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7a7a\u4e2d\u4ea4\u901a\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.03652", "pdf": "https://arxiv.org/pdf/2509.03652", "abs": "https://arxiv.org/abs/2509.03652", "authors": ["E. Khalafyan", "A. E. Allahverdyan", "A. Hovhannisyan"], "title": "Nonnegative matrix factorization and the principle of the common cause", "categories": ["cs.LG"], "comment": null, "summary": "Nonnegative matrix factorization (NMF) is a known unsupervised data-reduction\nmethod. The principle of the common cause (PCC) is a basic methodological\napproach in probabilistic causality, which seeks an independent mixture model\nfor the joint probability of two dependent random variables. It turns out that\nthese two concepts are closely related. This relationship is explored\nreciprocally for several datasets of gray-scale images, which are conveniently\nmapped into probability models. On one hand, PCC provides a predictability tool\nthat leads to a robust estimation of the effective rank of NMF. Unlike other\nestimates (e.g., those based on the Bayesian Information Criteria), our\nestimate of the rank is stable against weak noise. We show that NMF implemented\naround this rank produces features (basis images) that are also stable against\nnoise and against seeds of local optimization, thereby effectively resolving\nthe NMF nonidentifiability problem. On the other hand, NMF provides an\ninteresting possibility of implementing PCC in an approximate way, where larger\nand positively correlated joint probabilities tend to be explained better via\nthe independent mixture model. We work out a clustering method, where data\npoints with the same common cause are grouped into the same cluster. We also\nshow how NMF can be employed for data denoising.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff08NMF\uff09\u4e0e\u5171\u540c\u539f\u56e0\u539f\u5219\uff08PCC\uff09\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u3002\u7814\u7a76\u8868\u660e\uff0cPCC\u80fd\u63d0\u4f9b\u7a33\u5065\u7684NMF\u6709\u6548\u79e9\u4f30\u8ba1\uff0c\u4ece\u800c\u89e3\u51b3NMF\u7684\u975e\u8bc6\u522b\u6027\u95ee\u9898\u5e76\u751f\u6210\u7a33\u5b9a\u7684\u7279\u5f81\uff1b\u540c\u65f6\uff0cNMF\u4e5f\u80fd\u8fd1\u4f3c\u5b9e\u73b0PCC\uff0c\u5e76\u5e94\u7528\u4e8e\u6570\u636e\u805a\u7c7b\u548c\u53bb\u566a\u3002", "motivation": "\u63a2\u7d22\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff08NMF\uff09\u4e0e\u6982\u7387\u56e0\u679c\u5173\u7cfb\u4e2d\u7684\u5171\u540c\u539f\u56e0\u539f\u5219\uff08PCC\uff09\u4e4b\u95f4\u7684\u7d27\u5bc6\u8054\u7cfb\uff0c\u5e76\u5229\u7528\u8fd9\u79cd\u76f8\u4e92\u5173\u7cfb\u6765\u6539\u8fdb\u5404\u81ea\u7684\u5e94\u7528\u3002", "method": "\u5c06\u7070\u5ea6\u56fe\u50cf\u6570\u636e\u96c6\u6620\u5c04\u4e3a\u6982\u7387\u6a21\u578b\uff0c\u901a\u8fc7PCC\u5de5\u5177\u5bf9NMF\u7684\u6709\u6548\u79e9\u8fdb\u884c\u9c81\u68d2\u4f30\u8ba1\u3002\u5728\u6b64\u4f30\u8ba1\u79e9\u7684\u57fa\u7840\u4e0a\u5b9e\u73b0NMF\uff0c\u5e76\u63a2\u7d22NMF\u8fd1\u4f3c\u5b9e\u73b0PCC\u7684\u53ef\u80fd\u6027\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e00\u79cd\u805a\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5c06NMF\u7528\u4e8e\u6570\u636e\u53bb\u566a\u3002", "result": "PCC\u63d0\u4f9b\u4e86\u4e00\u79cd\u5bf9NMF\u6709\u6548\u79e9\u7684\u9c81\u68d2\u4f30\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5bf9\u5f31\u566a\u58f0\u5177\u6709\u7a33\u5b9a\u6027\uff0c\u4e14\u80fd\u4f7fNMF\u751f\u6210\u7684\u7279\u5f81\uff08\u57fa\u56fe\u50cf\uff09\u5bf9\u566a\u58f0\u548c\u5c40\u90e8\u4f18\u5316\u79cd\u5b50\u4fdd\u6301\u7a33\u5b9a\uff0c\u4ece\u800c\u89e3\u51b3NMF\u7684\u975e\u8bc6\u522b\u6027\u95ee\u9898\u3002NMF\u80fd\u591f\u4ee5\u8fd1\u4f3c\u65b9\u5f0f\u5b9e\u73b0PCC\uff0c\u66f4\u597d\u5730\u89e3\u91ca\u8f83\u5927\u4e14\u6b63\u76f8\u5173\u7684\u8054\u5408\u6982\u7387\u3002\u6587\u4e2d\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5171\u540c\u539f\u56e0\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86NMF\u5728\u6570\u636e\u53bb\u566a\u65b9\u9762\u7684\u5e94\u7528\u3002", "conclusion": "NMF\u4e0ePCC\u4e4b\u95f4\u5b58\u5728\u7d27\u5bc6\u4e14\u4e92\u60e0\u7684\u5173\u7cfb\u3002PCC\u80fd\u6709\u6548\u589e\u5f3aNMF\u7684\u9c81\u68d2\u6027\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u79e9\u4f30\u8ba1\u548c\u7279\u5f81\u63d0\u53d6\uff1bNMF\u5219\u4e3aPCC\u7684\u8fd1\u4f3c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u9014\u5f84\uff0c\u8fdb\u800c\u652f\u6301\u4e86\u65b0\u7684\u805a\u7c7b\u548c\u6570\u636e\u53bb\u566a\u5e94\u7528\u3002"}}
{"id": "2509.03531", "pdf": "https://arxiv.org/pdf/2509.03531", "abs": "https://arxiv.org/abs/2509.03531", "authors": ["Oscar Obeso", "Andy Arditi", "Javier Ferrando", "Joshua Freeman", "Cameron Holmes", "Neel Nanda"], "title": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models are now routinely used in high-stakes applications\nwhere hallucinations can cause serious harm, such as medical consultations or\nlegal advice. Existing hallucination detection methods, however, are\nimpractical for real-world use, as they are either limited to short factual\nqueries or require costly external verification. We present a cheap, scalable\nmethod for real-time identification of hallucinated tokens in long-form\ngenerations, and scale it effectively to 70B parameter models. Our approach\ntargets \\emph{entity-level hallucinations} -- e.g., fabricated names, dates,\ncitations -- rather than claim-level, thereby naturally mapping to token-level\nlabels and enabling streaming detection. We develop an annotation methodology\nthat leverages web search to annotate model responses with grounded labels\nindicating which tokens correspond to fabricated entities. This dataset enables\nus to train effective hallucination classifiers with simple and efficient\nmethods such as linear probes. Evaluating across four model families, our\nclassifiers consistently outperform baselines on long-form responses, including\nmore expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for\nLlama-3.3-70B), and are also an improvement in short-form question-answering\nsettings. Moreover, despite being trained only with entity-level labels, our\nprobes effectively detect incorrect answers in mathematical reasoning tasks,\nindicating generalization beyond entities. While our annotation methodology is\nexpensive, we find that annotated responses from one model can be used to train\neffective classifiers on other models; accordingly, we publicly release our\ndatasets to facilitate reuse. Overall, our work suggests a promising new\napproach for scalable, real-world hallucination detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5ec9\u4ef7\u3001\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5b9e\u4f53\u7ea7\u5e7b\u89c9\uff0c\u5e76\u5728\u591a\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\uff08\u5982\u533b\u7597\u3001\u6cd5\u5f8b\uff09\u51fa\u73b0\u5e7b\u89c9\u53ef\u80fd\u9020\u6210\u4e25\u91cd\u5371\u5bb3\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u5207\u5b9e\u9645\uff0c\u8981\u4e48\u4ec5\u9650\u4e8e\u7b80\u77ed\u4e8b\u5b9e\u67e5\u8be2\uff0c\u8981\u4e48\u9700\u8981\u6602\u8d35\u7684\u5916\u90e8\u9a8c\u8bc1\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u201c\u5b9e\u4f53\u7ea7\u5e7b\u89c9\u201d\uff08\u5982\u865a\u6784\u7684\u540d\u79f0\u3001\u65e5\u671f\u3001\u5f15\u7528\uff09\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4ee4\u724c\u7ea7\u6807\u6ce8\u548c\u6d41\u5f0f\u68c0\u6d4b\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u5229\u7528\u7f51\u7edc\u641c\u7d22\u8fdb\u884c\u6807\u6ce8\u7684\u65b9\u6cd5\uff0c\u4ee5\u521b\u5efa\u5e26\u6709\u771f\u5b9e\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u9ad8\u6548\u7684\u5e7b\u89c9\u5206\u7c7b\u5668\uff08\u5982\u7ebf\u6027\u63a2\u9488\uff09\uff0c\u5e76\u6210\u529f\u5c06\u5176\u6269\u5c55\u523070B\u53c2\u6570\u6a21\u578b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5206\u7c7b\u5668\u5728\u957f\u6587\u672c\u751f\u6210\u4e2d\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\uff08\u4f8b\u5982\uff0cLlama-3.3-70B\u7684AUC\u4ece0.71\u63d0\u5347\u81f30.90\uff09\uff0c\u5e76\u5728\u77ed\u6587\u672c\u95ee\u7b54\u8bbe\u7f6e\u4e2d\u4e5f\u663e\u793a\u51fa\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u4ec5\u901a\u8fc7\u5b9e\u4f53\u7ea7\u6807\u7b7e\u8bad\u7ec3\uff0c\u63a2\u9488\u4e5f\u80fd\u6709\u6548\u68c0\u6d4b\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u7b54\u6848\uff0c\u8868\u660e\u5176\u5177\u6709\u8d85\u8d8a\u5b9e\u4f53\u7684\u6cdb\u5316\u80fd\u529b\u3002\u56e2\u961f\u8fd8\u53d1\u73b0\uff0c\u4e00\u4e2a\u6a21\u578b\u7684\u6807\u6ce8\u54cd\u5e94\u53ef\u7528\u4e8e\u8bad\u7ec3\u5176\u4ed6\u6a21\u578b\u7684\u6709\u6548\u5206\u7c7b\u5668\uff0c\u5e76\u5df2\u516c\u5f00\u76f8\u5173\u6570\u636e\u96c6\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u3001\u771f\u5b9e\u4e16\u754c\u7684\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.03901", "pdf": "https://arxiv.org/pdf/2509.03901", "abs": "https://arxiv.org/abs/2509.03901", "authors": ["Katarzyna Kosek-Szott", "Szymon Szott", "Wojciech Ciezobka", "Maksymilian Wojnar", "Krzysztof Rusek", "Jonathan Segev"], "title": "Indoor Positioning with Wi-Fi Location: A Survey of IEEE 802.11mc/az/bk Fine Timing Measurement Research", "categories": ["cs.NI"], "comment": "30 pages, survey paper", "summary": "Indoor positioning is an enabling technology for home, office, and industrial\nnetwork users because it provides numerous information and communication\ntechnology (ICT) and Internet of things (IoT) functionalities such as indoor\nnavigation, smart meter localization, asset tracking, support for emergency\nservices, and detection of hazardous situations. The IEEE 802.11mc fine timing\nmeasurement (FTM) protocol (commercially known as Wi-Fi Location) has great\npotential to enable indoor positioning in future generation devices, primarily\nbecause of the high availability of Wi-Fi networks, FTM's high accuracy and\ndevice support. Furthermore, new FTM enhancements are available in the released\n(802.11az) and recently completed (802.11bk) amendments. Despite the multitude\nof literature reviews on indoor positioning, a survey dedicated to FTM and its\nrecent enhancements has so far been lacking. We fill this gap by classifying\nand reviewing over 180 research papers related to the practical accuracy\nachieved with FTM, methods for improving its accuracy (also with machine\nlearning), combining FTM with other indoor positioning systems, FTM-based\napplications, and security issues. Based on the conducted survey, we summarize\nthe most important research achievements and formulate open areas for further\nresearch.", "AI": {"tldr": "\u672c\u6587\u5bf9IEEE 802.11mc FTM\u534f\u8bae\u53ca\u5176\u6700\u65b0\u589e\u5f3a\u529f\u80fd\u5728\u5ba4\u5185\u5b9a\u4f4d\u9886\u57df\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u5176\u7cbe\u5ea6\u3001\u6539\u8fdb\u65b9\u6cd5\u3001\u7ec4\u5408\u5e94\u7528\u3001\u5b89\u5168\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u5ba4\u5185\u5b9a\u4f4d\u6280\u672f\u9700\u6c42\u5e7f\u6cdb\u4e14IEEE 802.11mc FTM\u534f\u8bae\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9FTM\u53ca\u5176\u6700\u65b0\u589e\u5f3a\u529f\u80fd\u7684\u4e13\u95e8\u7efc\u8ff0\uff0c\u73b0\u6709\u6587\u732e\u672a\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u548c\u5ba1\u9605\u8d85\u8fc7180\u7bc7\u76f8\u5173\u7814\u7a76\u8bba\u6587\uff0c\u5185\u5bb9\u6d89\u53caFTM\u7684\u5b9e\u9645\u7cbe\u5ea6\u3001\u7cbe\u5ea6\u63d0\u5347\u65b9\u6cd5\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\uff09\u3001FTM\u4e0e\u5176\u4ed6\u5b9a\u4f4d\u7cfb\u7edf\u7ed3\u5408\u3001FTM\u5e94\u7528\u4ee5\u53ca\u5b89\u5168\u95ee\u9898\u3002", "result": "\u603b\u7ed3\u4e86FTM\u5ba4\u5185\u5b9a\u4f4d\u9886\u57df\u6700\u91cd\u8981\u7684\u7814\u7a76\u6210\u679c\u3002", "conclusion": "\u57fa\u4e8e\u7efc\u8ff0\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u5f00\u653e\u6027\u9886\u57df\u548c\u65b9\u5411\u3002"}}
{"id": "2509.03631", "pdf": "https://arxiv.org/pdf/2509.03631", "abs": "https://arxiv.org/abs/2509.03631", "authors": ["Anders Kjelsrud", "Lasse L\u00f8vstakken", "Erik Smistad", "H\u00e5vard Dalen", "Gilles Van De Vyver"], "title": "Lightweight image segmentation for echocardiography", "categories": ["cs.CV"], "comment": "4 pages, 6 figures, The 2025 IEEE International Ultrasonics Symposium", "summary": "Accurate segmentation of the left ventricle in echocardiography can enable\nfully automatic extraction of clinical measurements such as volumes and\nejection fraction. While models configured by nnU-Net perform well, they are\nlarge and slow, thus limiting real-time use. We identified the most effective\ncomponents of nnU-Net for cardiac segmentation through an ablation study,\nincrementally evaluating data augmentation schemes, architectural\nmodifications, loss functions, and post-processing techniques. Our analysis\nrevealed that simple affine augmentations and deep supervision drive\nperformance, while complex augmentations and large model capacity offer\ndiminishing returns. Based on these insights, we developed a lightweight U-Net\n(2M vs 33M parameters) that achieves statistically equivalent performance to\nnnU-Net on CAMUS (N=500) with Dice scores of 0.93/0.85/0.89 vs 0.93/0.86/0.89\nfor LV/MYO/LA ($p>0.05$), while being 16 times smaller and 4 times faster\n(1.35ms vs 5.40ms per frame) than the default nnU-Net configuration.\nCross-dataset evaluation on an internal dataset (N=311) confirms comparable\ngeneralization.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7U-Net\u6a21\u578b\uff0c\u5728\u5fc3\u5ba4\u5206\u5272\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u4e0ennU-Net\u7edf\u8ba1\u7b49\u6548\u7684\u6027\u80fd\uff0c\u4f46\u6a21\u578b\u5c3a\u5bf8\u5c0f16\u500d\uff0c\u901f\u5ea6\u5feb4\u500d\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u3002", "motivation": "\u867d\u7136nnU-Net\u5728\u8d85\u58f0\u5fc3\u52a8\u56fe\u5de6\u5fc3\u5ba4\u5206\u5272\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u6a21\u578b\u8fc7\u5927\u4e14\u8fd0\u884c\u7f13\u6162\uff0c\u9650\u5236\u4e86\u5b9e\u65f6\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u6d88\u878d\u7814\u7a76\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86nnU-Net\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6848\u3001\u67b6\u6784\u4fee\u6539\u3001\u635f\u5931\u51fd\u6570\u548c\u540e\u5904\u7406\u6280\u672f\uff0c\u4ee5\u8bc6\u522b\u6700\u6709\u6548\u7684\u7ec4\u4ef6\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7U-Net\u6a21\u578b\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u7b80\u5355\u7684\u4eff\u5c04\u589e\u5f3a\u548c\u6df1\u5ea6\u76d1\u7763\u662f\u6027\u80fd\u5173\u952e\uff0c\u800c\u590d\u6742\u589e\u5f3a\u548c\u5927\u578b\u6a21\u578b\u5bb9\u91cf\u7684\u56de\u62a5\u9012\u51cf\u3002\u672c\u7814\u7a76\u5f00\u53d1\u7684\u8f7b\u91cf\u7ea7U-Net\uff082M\u53c2\u6570\uff09\u5728CAMUS\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0ennU-Net\uff0833M\u53c2\u6570\uff09\u7edf\u8ba1\u7b49\u6548\u7684\u6027\u80fd\uff08Dice\u5206\u6570\uff1aLV 0.93/0.93\uff09\uff0c\u4e14\u6a21\u578b\u5c0f16\u500d\uff0c\u901f\u5ea6\u5feb4\u500d\uff081.35ms vs 5.40ms/\u5e27\uff09\u3002\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\u4e5f\u8bc1\u5b9e\u4e86\u5176\u53ef\u6bd4\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u7387\u7684U-Net\u6a21\u578b\uff0c\u5176\u5728\u5fc3\u810f\u5206\u5272\u4e0a\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0ennU-Net\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u7f29\u5c0f\u4e86\u6a21\u578b\u5c3a\u5bf8\u5e76\u63d0\u5347\u4e86\u8fd0\u884c\u901f\u5ea6\uff0c\u4e3a\u5b9e\u65f6\u4e34\u5e8a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.03581", "pdf": "https://arxiv.org/pdf/2509.03581", "abs": "https://arxiv.org/abs/2509.03581", "authors": ["Davide Paglieri", "Bart\u0142omiej Cupia\u0142", "Jonathan Cook", "Ulyana Piterbarg", "Jens Tuyls", "Edward Grefenstette", "Jakob Nicolaus Foerster", "Jack Parker-Holder", "Tim Rockt\u00e4schel"], "title": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Training large language models (LLMs) to reason via reinforcement learning\n(RL) significantly improves their problem-solving capabilities. In agentic\nsettings, existing methods like ReAct prompt LLMs to explicitly plan before\nevery action; however, we demonstrate that always planning is computationally\nexpensive and degrades performance on long-horizon tasks, while never planning\nfurther limits performance. To address this, we introduce a conceptual\nframework formalizing dynamic planning for LLM agents, enabling them to\nflexibly decide when to allocate test-time compute for planning. We propose a\nsimple two-stage training pipeline: (1) supervised fine-tuning on diverse\nsynthetic data to prime models for dynamic planning, and (2) RL to refine this\ncapability in long-horizon environments. Experiments on the Crafter environment\nshow that dynamic planning agents trained with this approach are more\nsample-efficient and consistently achieve more complex objectives.\nAdditionally, we demonstrate that these agents can be effectively steered by\nhuman-written plans, surpassing their independent capabilities. To our\nknowledge, this work is the first to explore training LLM agents for dynamic\ntest-time compute allocation in sequential decision-making tasks, paving the\nway for more efficient, adaptive, and controllable agentic systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u8bad\u7ec3\u4e86\u4e00\u79cdLLM\u667a\u80fd\u4f53\u7684\u52a8\u6001\u89c4\u5212\u6846\u67b6\uff0c\u4f7f\u5176\u80fd\u591f\u7075\u6d3b\u51b3\u5b9a\u4f55\u65f6\u89c4\u5212\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08SFT+RL\uff09\u5728\u957f\u5468\u671f\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u66f4\u590d\u6742\u7684\u76ee\u6807\uff0c\u5e76\u53ef\u53d7\u4eba\u7c7b\u8ba1\u5212\u5f15\u5bfc\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\uff08\u5982ReAct\uff09\u5f3a\u5236\u5728\u6bcf\u6b21\u884c\u52a8\u524d\u89c4\u5212\uff0c\u4f46\u5728\u957f\u5468\u671f\u4efb\u52a1\u4e2d\uff0c\u59cb\u7ec8\u89c4\u5212\u4f1a\u6d88\u8017\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u5e76\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u4ece\u4e0d\u89c4\u5212\u5219\u4f1a\u9650\u5236\u5176\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7075\u6d3b\u7684\u673a\u5236\u6765\u52a8\u6001\u5206\u914d\u89c4\u5212\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316LLM\u667a\u80fd\u4f53\u52a8\u6001\u89c4\u5212\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u4f7f\u5176\u80fd\u591f\u7075\u6d3b\u51b3\u5b9a\u4f55\u65f6\u8fdb\u884c\u6d4b\u8bd5\u65f6\u89c4\u5212\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\uff1a1) \u5728\u591a\u6837\u5316\u7684\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4ee5\u521d\u6b65\u5b66\u4e60\u52a8\u6001\u89c4\u5212\uff1b2) \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u957f\u5468\u671f\u73af\u5883\u4e2d\u7cbe\u70bc\u8fd9\u79cd\u80fd\u529b\u3002", "result": "\u5728Crafter\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u6b64\u65b9\u6cd5\u8bad\u7ec3\u7684\u52a8\u6001\u89c4\u5212\u667a\u80fd\u4f53\u5177\u6709\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\uff0c\u5e76\u80fd\u6301\u7eed\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u76ee\u6807\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u667a\u80fd\u4f53\u53ef\u4ee5\u88ab\u4eba\u7c7b\u7f16\u5199\u7684\u8ba1\u5212\u6709\u6548\u5f15\u5bfc\uff0c\u8d85\u8d8a\u5176\u72ec\u7acb\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63a2\u7d22\u4e86\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u5728\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\u4e2d\u8fdb\u884c\u52a8\u6001\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\uff0c\u4e3a\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u548c\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.03660", "pdf": "https://arxiv.org/pdf/2509.03660", "abs": "https://arxiv.org/abs/2509.03660", "authors": ["Yunkai Bao", "Reza Safarzadeh", "Xin Wang", "Steve Drew"], "title": "Semi-decentralized Federated Time Series Prediction with Client Availability Budgets", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated learning (FL) effectively promotes collaborative training among\ndistributed clients with privacy considerations in the Internet of Things (IoT)\nscenarios. Despite of data heterogeneity, FL clients may also be constrained by\nlimited energy and availability budgets. Therefore, effective selection of\nclients participating in training is of vital importance for the convergence of\nthe global model and the balance of client contributions. In this paper, we\ndiscuss the performance impact of client availability with time-series data on\nfederated learning. We set up three different scenarios that affect the\navailability of time-series data and propose FedDeCAB, a novel,\nsemi-decentralized client selection method applying probabilistic rankings of\navailable clients. When a client is disconnected from the server, FedDeCAB\nallows obtaining partial model parameters from the nearest neighbor clients for\njoint optimization, improving the performance of offline models and reducing\ncommunication overhead. Experiments based on real-world large-scale taxi and\nvessel trajectory datasets show that FedDeCAB is effective under highly\nheterogeneous data distribution, limited communication budget, and dynamic\nclient offline or rejoining.", "AI": {"tldr": "\u9488\u5bf9\u7269\u8054\u7f51\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u53ef\u7528\u6027\u4e0e\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faFedDeCAB\uff0c\u4e00\u79cd\u534a\u53bb\u4e2d\u5fc3\u5316\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u6982\u7387\u6392\u540d\u548c\u8fd1\u90bb\u534f\u4f5c\u4f18\u5316\u79bb\u7ebf\u5ba2\u6237\u7aef\u6a21\u578b\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u7269\u8054\u7f51\uff08IoT\uff09\u573a\u666f\u4e2d\uff0c\u9664\u4e86\u6570\u636e\u5f02\u6784\u6027\uff0c\u5ba2\u6237\u7aef\u8fd8\u53d7\u9650\u4e8e\u6709\u9650\u7684\u80fd\u91cf\u548c\u53ef\u7528\u6027\u3002\u5728\u8fd9\u4e9b\u6311\u6218\u4e0b\uff0c\u6709\u6548\u9009\u62e9\u53c2\u4e0e\u8bad\u7ec3\u7684\u5ba2\u6237\u7aef\u5bf9\u4e8e\u5168\u5c40\u6a21\u578b\u6536\u655b\u548c\u5e73\u8861\u5ba2\u6237\u7aef\u8d21\u732e\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5ba2\u6237\u7aef\u52a8\u6001\u4e0a\u7ebf\u4e0b\u7ebf\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u672c\u6587\u9996\u5148\u8bbe\u7f6e\u4e86\u4e09\u79cd\u5f71\u54cd\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53ef\u7528\u6027\u7684\u573a\u666f\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u534a\u53bb\u4e2d\u5fc3\u5316\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5FedDeCAB\u3002FedDeCAB\u901a\u8fc7\u5bf9\u53ef\u7528\u5ba2\u6237\u7aef\u8fdb\u884c\u6982\u7387\u6392\u540d\u6765\u9009\u62e9\u53c2\u4e0e\u8005\uff0c\u5e76\u5728\u5ba2\u6237\u7aef\u79bb\u7ebf\u65f6\u5141\u8bb8\u5176\u4ece\u6700\u8fd1\u90bb\u5ba2\u6237\u7aef\u83b7\u53d6\u90e8\u5206\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u8054\u5408\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u79bb\u7ebf\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5927\u89c4\u6a21\u51fa\u79df\u8f66\u548c\u8239\u8236\u8f68\u8ff9\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedDeCAB\u5728\u9ad8\u5ea6\u5f02\u6784\u6570\u636e\u5206\u5e03\u3001\u6709\u9650\u901a\u4fe1\u9884\u7b97\u4ee5\u53ca\u5ba2\u6237\u7aef\u52a8\u6001\u79bb\u7ebf\u6216\u91cd\u65b0\u52a0\u5165\u7684\u590d\u6742\u6761\u4ef6\u4e0b\uff0c\u5747\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "FedDeCAB\u901a\u8fc7\u5176\u521b\u65b0\u7684\u534a\u53bb\u4e2d\u5fc3\u5316\u5ba2\u6237\u7aef\u9009\u62e9\u7b56\u7565\u548c\u8fd1\u90bb\u534f\u4f5c\u673a\u5236\uff0c\u6210\u529f\u5e94\u5bf9\u4e86\u7269\u8054\u7f51\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u53ef\u7528\u6027\u4f4e\u548c\u6570\u636e\u5f02\u6784\u6027\u7684\u6311\u6218\uff0c\u5728\u5404\u79cd\u590d\u6742\u52a8\u6001\u573a\u666f\u4e0b\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\u3002"}}
{"id": "2509.03533", "pdf": "https://arxiv.org/pdf/2509.03533", "abs": "https://arxiv.org/abs/2509.03533", "authors": ["Igor Halperin"], "title": "Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck", "categories": ["cs.CL", "cs.LG", "q-fin.GN"], "comment": "26 pages, 4 figures", "summary": "Large Language Models (LLMs) are prone to critical failure modes, including\n\\textit{intrinsic faithfulness hallucinations} (also known as confabulations),\nwhere a response deviates semantically from the provided context. Frameworks\ndesigned to detect this, such as Semantic Divergence Metrics (SDM), rely on\nidentifying latent topics shared between prompts and responses, typically by\napplying geometric clustering to their sentence embeddings. This creates a\ndisconnect, as the topics are optimized for spatial proximity, not for the\ndownstream information-theoretic analysis. In this paper, we bridge this gap by\ndeveloping a principled topic identification method grounded in the\nDeterministic Information Bottleneck (DIB) for geometric clustering. Our key\ncontribution is to transform the DIB method into a practical algorithm for\nhigh-dimensional data by substituting its intractable KL divergence term with a\ncomputationally efficient upper bound. The resulting method, which we dub UDIB,\ncan be interpreted as an entropy-regularized and robustified version of K-means\nthat inherently favors a parsimonious number of informative clusters. By\napplying UDIB to the joint clustering of LLM prompt and response embeddings, we\ngenerate a shared topic representation that is not merely spatially coherent\nbut is fundamentally structured to be maximally informative about the\nprompt-response relationship. This provides a superior foundation for the SDM\nframework and offers a novel, more sensitive tool for detecting confabulations.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u4e3b\u9898\u8bc6\u522b\u4e0a\u5b58\u5728\u7f3a\u9677\u3002\u672c\u6587\u63d0\u51faUDIB\u65b9\u6cd5\uff0c\u5c06\u786e\u5b9a\u6027\u4fe1\u606f\u74f6\u9888\uff08DIB\uff09\u5e94\u7528\u4e8e\u51e0\u4f55\u805a\u7c7b\uff0c\u901a\u8fc7\u9ad8\u6548\u8fd1\u4f3c\u89e3\u51b3\u4e86\u9ad8\u7ef4\u6570\u636e\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u5171\u4eab\u4e3b\u9898\u8868\u793a\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u4e86LLM\u5e7b\u89c9\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bb9\u6613\u4ea7\u751f\u5185\u5728\u5fe0\u5b9e\u5ea6\u5e7b\u89c9\uff08\u5373\uff0c\u54cd\u5e94\u5185\u5bb9\u5728\u8bed\u4e49\u4e0a\u504f\u79bb\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\uff09\u3002\u73b0\u6709\u7684\u68c0\u6d4b\u6846\u67b6\uff08\u5982\u8bed\u4e49\u6563\u5ea6\u5ea6\u91cfSDM\uff09\u901a\u8fc7\u5bf9\u53e5\u5411\u91cf\u5d4c\u5165\u8fdb\u884c\u51e0\u4f55\u805a\u7c7b\u6765\u8bc6\u522b\u63d0\u793a\u548c\u54cd\u5e94\u95f4\u7684\u6f5c\u5728\u4e3b\u9898\uff0c\u4f46\u8fd9\u4e9b\u4e3b\u9898\u4f18\u5316\u4e8e\u7a7a\u95f4\u90bb\u8fd1\u6027\u800c\u975e\u4e0b\u6e38\u4fe1\u606f\u8bba\u5206\u6790\uff0c\u5bfc\u81f4\u5176\u4e0e\u5b9e\u9645\u5206\u6790\u76ee\u6807\u8131\u8282\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u786e\u5b9a\u6027\u4fe1\u606f\u74f6\u9888\uff08DIB\uff09\u7684\u51e0\u4f55\u805a\u7c7b\u4e3b\u9898\u8bc6\u522b\u65b9\u6cd5\u3002\u901a\u8fc7\u5c06DIB\u4e2d\u96be\u4ee5\u5904\u7406\u7684KL\u6563\u5ea6\u9879\u66ff\u6362\u4e3a\u8ba1\u7b97\u9ad8\u6548\u7684\u4e0a\u754c\uff0c\u5c06DIB\u8f6c\u5316\u4e3a\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u7684\u5b9e\u7528\u7b97\u6cd5\uff0c\u5e76\u547d\u540d\u4e3aUDIB\u3002UDIB\u53ef\u88ab\u89e3\u91ca\u4e3aK-means\u7684\u71b5\u6b63\u5219\u5316\u548c\u9c81\u68d2\u5316\u7248\u672c\uff0c\u5176\u672c\u8d28\u4e0a\u504f\u597d\u6570\u91cf\u9002\u4e2d\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u7c07\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eLLM\u63d0\u793a\u548c\u54cd\u5e94\u5d4c\u5165\u7684\u8054\u5408\u805a\u7c7b\u3002", "result": "UDIB\u65b9\u6cd5\u751f\u6210\u4e86\u4e00\u79cd\u5171\u4eab\u4e3b\u9898\u8868\u793a\uff0c\u8be5\u8868\u793a\u4e0d\u4ec5\u5728\u7a7a\u95f4\u4e0a\u8fde\u8d2f\uff0c\u800c\u4e14\u5728\u6839\u672c\u4e0a\u88ab\u6784\u9020\u4e3a\u5173\u4e8e\u63d0\u793a-\u54cd\u5e94\u5173\u7cfb\u7684\u4fe1\u606f\u91cf\u6700\u5927\u3002\u8fd9\u4e3aSDM\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u4f18\u8d8a\u7684\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u3001\u66f4\u7075\u654f\u7684\u5e7b\u89c9\uff08\u6df7\u6dc6\uff09\u68c0\u6d4b\u5de5\u5177\u3002", "conclusion": "UDIB\u65b9\u6cd5\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u3001\u66f4\u6709\u6548\u7684\u4e3b\u9898\u8bc6\u522b\u673a\u5236\uff0c\u5f25\u8865\u4e86LLM\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u4e86\u5bf9LLM\u5e7b\u89c9\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u57fa\u7840\u548c\u66f4\u654f\u611f\u7684\u5de5\u5177\u3002"}}
{"id": "2509.03935", "pdf": "https://arxiv.org/pdf/2509.03935", "abs": "https://arxiv.org/abs/2509.03935", "authors": ["Sungho Cho", "Sung Il Choi", "Seung Hyun Oh", "Ian P. Roberts", "Sang Hyun Lee"], "title": "Autonomous Task Offloading of Vehicular Edge Computing with Parallel Computation Queues", "categories": ["cs.NI"], "comment": null, "summary": "This work considers a parallel task execution strategy in vehicular edge\ncomputing (VEC) networks, where edge servers are deployed along the roadside to\nprocess offloaded computational tasks of vehicular users. To minimize the\noverall waiting delay among vehicular users, a novel task offloading solution\nis implemented based on the network cooperation balancing resource\nunder-utilization and load congestion. Dual evaluation through theoretical and\nnumerical ways shows that the developed solution achieves a globally optimal\ndelay reduction performance compared to existing methods, which is also\napproved by the feasibility test over a real-map virtual environment. The\nin-depth analysis reveals that predicting the instantaneous processing power of\nedge servers facilitates the identification of overloaded servers, which is\ncritical for determining network delay. By considering discrete variables of\nthe queue, the proposed technique's precise estimation can effectively address\nthese combinatorial challenges to achieve optimal performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u8f66\u8f7d\u8fb9\u7f18\u8ba1\u7b97\uff08VEC\uff09\u7f51\u7edc\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u534f\u4f5c\u7684\u4efb\u52a1\u5378\u8f7d\u65b9\u6848\uff0c\u65e8\u5728\u5e73\u8861\u8d44\u6e90\u5229\u7528\u4e0e\u8d1f\u8f7d\u62e5\u5835\uff0c\u4ee5\u6700\u5c0f\u5316\u8f66\u8f86\u7528\u6237\u7b49\u5f85\u5ef6\u8fdf\u3002\u8be5\u65b9\u6848\u7ecf\u9a8c\u8bc1\u80fd\u5b9e\u73b0\u5168\u5c40\u6700\u4f18\u7684\u5ef6\u8fdf\u964d\u4f4e\u6027\u80fd\u3002", "motivation": "\u5728\u8f66\u8f7d\u8fb9\u7f18\u8ba1\u7b97\uff08VEC\uff09\u7f51\u7edc\u4e2d\uff0c\u8fb9\u7f18\u670d\u52a1\u5668\u9700\u5904\u7406\u8f66\u8f86\u7528\u6237\u5378\u8f7d\u7684\u8ba1\u7b97\u4efb\u52a1\u3002\u7814\u7a76\u52a8\u673a\u662f\u6700\u5c0f\u5316\u8f66\u8f86\u7528\u6237\u7684\u6574\u4f53\u7b49\u5f85\u5ef6\u8fdf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4efb\u52a1\u5378\u8f7d\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u57fa\u4e8e\u7f51\u7edc\u534f\u4f5c\uff0c\u65e8\u5728\u5e73\u8861\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\u548c\u8d1f\u8f7d\u62e5\u5835\u3002\u901a\u8fc7\u9884\u6d4b\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u77ac\u65f6\u5904\u7406\u80fd\u529b\u6765\u8bc6\u522b\u8fc7\u8f7d\u670d\u52a1\u5668\uff0c\u5e76\u8003\u8651\u961f\u5217\u7684\u79bb\u6563\u53d8\u91cf\u8fdb\u884c\u7cbe\u786e\u4f30\u8ba1\uff0c\u4ee5\u6709\u6548\u89e3\u51b3\u7ec4\u5408\u6311\u6218\u3002", "result": "\u6240\u5f00\u53d1\u7684\u89e3\u51b3\u65b9\u6848\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u6700\u4f18\u7684\u5ef6\u8fdf\u964d\u4f4e\u6027\u80fd\u3002\u8fd9\u4e00\u7ed3\u679c\u5df2\u901a\u8fc7\u7406\u8bba\u5206\u6790\u3001\u6570\u503c\u6a21\u62df\u4ee5\u53ca\u5728\u771f\u5b9e\u5730\u56fe\u865a\u62df\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u6d4b\u8bd5\u5f97\u5230\u9a8c\u8bc1\u3002\u6df1\u5165\u5206\u6790\u8868\u660e\uff0c\u9884\u6d4b\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u77ac\u65f6\u5904\u7406\u80fd\u529b\u5bf9\u4e8e\u786e\u5b9a\u7f51\u7edc\u5ef6\u8fdf\u81f3\u5173\u91cd\u8981\uff0c\u4e14\u80fd\u6709\u6548\u8bc6\u522b\u8fc7\u8f7d\u670d\u52a1\u5668\u3002", "conclusion": "\u8be5\u4efb\u52a1\u5378\u8f7d\u6280\u672f\u901a\u8fc7\u5e73\u8861\u7f51\u7edc\u8d44\u6e90\u5229\u7528\u4e0e\u8d1f\u8f7d\u62e5\u5835\uff0c\u5e76\u7ed3\u5408\u5bf9\u8fb9\u7f18\u670d\u52a1\u5668\u5904\u7406\u80fd\u529b\u7684\u9884\u6d4b\u548c\u961f\u5217\u79bb\u6563\u53d8\u91cf\u7684\u7cbe\u786e\u4f30\u8ba1\uff0c\u80fd\u6709\u6548\u5e94\u5bf9VEC\u7f51\u7edc\u4e2d\u7684\u7ec4\u5408\u6311\u6218\uff0c\u4ece\u800c\u5b9e\u73b0\u6700\u5c0f\u5316\u8f66\u8f86\u7528\u6237\u7b49\u5f85\u5ef6\u8fdf\u7684\u5168\u5c40\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2509.03633", "pdf": "https://arxiv.org/pdf/2509.03633", "abs": "https://arxiv.org/abs/2509.03633", "authors": ["Josafat-Mattias Burmeister", "Andreas Tockner", "Stefan Reder", "Markus Engel", "Rico Richter", "Jan-Peter Mund", "J\u00fcrgen D\u00f6llner"], "title": "treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds", "categories": ["cs.CV", "cs.AI", "I.4.6; I.5.2; I.2.10"], "comment": null, "summary": "Close-range laser scanning provides detailed 3D captures of forest stands but\nrequires efficient software for processing 3D point cloud data and extracting\nindividual trees. Although recent studies have introduced deep learning methods\nfor tree instance segmentation, these approaches require large annotated\ndatasets and substantial computational resources. As a resource-efficient\nalternative, we present a revised version of the treeX algorithm, an\nunsupervised method that combines clustering-based stem detection with region\ngrowing for crown delineation. While the original treeX algorithm was developed\nfor personal laser scanning (PLS) data, we provide two parameter presets, one\nfor ground-based laser scanning (stationary terrestrial - TLS and PLS), and one\nfor UAV-borne laser scanning (ULS). We evaluated the method on six public\ndatasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham\nWoods) and compared it to six open-source methods (original treeX, treeiso,\nRayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original\ntreeX algorithm, our revision reduces runtime and improves accuracy, with\ninstance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data.\nFor ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original\nalgorithm fails to segment any correct instances. For TLS and PLS data, our\nalgorithm achieves accuracy similar to recent open-source methods, including\ndeep learning. Given its algorithmic design, we see two main applications for\nour method: (1) as a resource-efficient alternative to deep learning approaches\nin scenarios where the data characteristics align with the method design\n(sufficient stem visibility and point density), and (2) for the semi-automatic\ngeneration of labels for deep learning models. To enable broader adoption, we\nprovide an open-source Python implementation in the pointtree package.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u65e0\u76d1\u7763\u6811\u6728\u5206\u5272\u7b97\u6cd5treeX\uff0c\u9002\u7528\u4e8e\u5730\u9762\u548c\u65e0\u4eba\u673a\u6fc0\u5149\u626b\u63cf\u6570\u636e\u3002\u8be5\u7b97\u6cd5\u76f8\u6bd4\u539f\u7248\u63d0\u5347\u4e86\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5bf9\u5730\u9762\u6570\u636e\u8868\u73b0\u53ef\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5ab2\u7f8e\uff0c\u4e14\u8d44\u6e90\u9ad8\u6548\u3002\u53ef\u7528\u4e8e\u6797\u6728\u63d0\u53d6\u53ca\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6807\u6ce8\uff0c\u5e76\u5df2\u5f00\u6e90\u3002", "motivation": "\u8fd1\u8ddd\u79bb\u6fc0\u5149\u626b\u63cf\u6570\u636e\u7f3a\u4e4f\u9ad8\u6548\u7684\u4e2a\u4f53\u6811\u6728\u63d0\u53d6\u8f6f\u4ef6\u3002\u6df1\u5ea6\u5b66\u4e60\u867d\u6709\u6548\u4f46\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5e76\u6539\u8fdb\u4e86\u65e0\u76d1\u7763\u7684treeX\u7b97\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u805a\u7c7b\u7684\u6811\u5e72\u68c0\u6d4b\u548c\u533a\u57df\u589e\u957f\u7684\u6811\u51a0\u52fe\u52d2\u3002\u4e3a\u5730\u9762\u548c\u65e0\u4eba\u673a\u6fc0\u5149\u626b\u63cf\u6570\u636e\u5206\u522b\u8bbe\u7f6e\u4e86\u53c2\u6570\u9884\u8bbe\u3002\u5728\u516d\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u516d\u79cd\u5f00\u6e90\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u76f8\u8f83\u4e8e\u539f\u59cbtreeX\u7b97\u6cd5\uff0c\u672c\u65b9\u6cd5\u8fd0\u884c\u65f6\u95f4\u66f4\u77ed\uff0c\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u5730\u9762\u6570\u636eF1-score\u63d0\u53470.11\u81f30.49\u3002\u65e0\u4eba\u673a\u6fc0\u5149\u626b\u63cf\u6570\u636eF1-score\u8fbe\u52300.58\uff08\u539f\u7b97\u6cd5\u5931\u8d25\uff09\u3002\u5730\u9762\u6fc0\u5149\u626b\u63cf\u6570\u636e\u7cbe\u5ea6\u4e0e\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\u5728\u5185\u7684\u6700\u65b0\u5f00\u6e90\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u672c\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7684\u8d44\u6e90\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u7279\u5b9a\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u6797\u6728\u63d0\u53d6\uff0c\u5e76\u53ef\u7528\u4e8e\u534a\u81ea\u52a8\u751f\u6210\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u6807\u7b7e\u3002\u5df2\u63d0\u4f9b\u5f00\u6e90Python\u5b9e\u73b0\u3002"}}
{"id": "2509.03626", "pdf": "https://arxiv.org/pdf/2509.03626", "abs": "https://arxiv.org/abs/2509.03626", "authors": ["Zahra Zehtabi Sabeti Moghaddam", "Zeinab Dehghani", "Maneeha Rani", "Koorosh Aslansefat", "Bhupesh Kumar Mishra", "Rameez Raja Kureshi", "Dhavalkumar Thakker"], "title": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "categories": ["cs.AI"], "comment": null, "summary": "Generative AI, such as Large Language Models (LLMs), has achieved impressive\nprogress but still produces hallucinations and unverifiable claims, limiting\nreliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves\naccuracy by grounding outputs in external knowledge, especially in domains like\nhealthcare, where precision is vital. However, RAG remains opaque and\nessentially a black box, heavily dependent on data quality. We developed a\nmethod-agnostic, perturbation-based framework that provides token and\ncomponent-level interoperability for Graph RAG using SMILE and named it as\nKnowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing\nsimilarities, and training weighted linear surrogates, KG-SMILE identifies the\ngraph entities and relations most influential to generated outputs, thereby\nmaking RAG more transparent. We evaluate KG-SMILE using comprehensive\nattribution metrics, including fidelity, faithfulness, consistency, stability,\nand accuracy. Our findings show that KG-SMILE produces stable, human-aligned\nexplanations, demonstrating its capacity to balance model effectiveness with\ninterpretability and thereby fostering greater transparency and trust in\nmachine learning technologies.", "AI": {"tldr": "\u9488\u5bf9RAG\u6280\u672f\u7684\u4e0d\u900f\u660e\u6027\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86KG-SMILE\u6846\u67b6\uff0c\u5b83\u662f\u4e00\u79cd\u57fa\u4e8e\u6270\u52a8\u7684\u3001\u4e0e\u65b9\u6cd5\u65e0\u5173\u7684\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u56feRAG\u63d0\u4f9b\u4ee4\u724c\u548c\u7ec4\u4ef6\u7ea7\u522b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u56fe\u5b9e\u4f53\u548c\u5173\u7cfb\u6765\u5e73\u8861\u6a21\u578b\u6548\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u6700\u7ec8\u63d0\u5347\u673a\u5668\u5b66\u4e60\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002", "motivation": "\u751f\u6210\u5f0fAI\uff08\u5982LLMs\uff09\u867d\u6709\u663e\u8457\u8fdb\u5c55\u4f46\u4ecd\u4f1a\u4ea7\u751f\u5e7b\u89c9\u548c\u4e0d\u53ef\u9a8c\u8bc1\u7684\u58f0\u660e\uff0c\u9650\u5236\u4e86\u5176\u5728\u654f\u611f\u9886\u57df\u7684\u53ef\u9760\u6027\u3002RAG\u6280\u672f\u867d\u80fd\u901a\u8fc7\u5916\u90e8\u77e5\u8bc6\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u5176\u672c\u8d28\u4ecd\u662f\u4e00\u4e2a\u4e0d\u900f\u660e\u7684\u9ed1\u7bb1\uff0c\u4e14\u4e25\u91cd\u4f9d\u8d56\u6570\u636e\u8d28\u91cf\u3002\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3RAG\u7684\u8fd9\u79cd\u4e0d\u900f\u660e\u6027\uff0c\u5c24\u5176\u662f\u5728\u56feRAG\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u5176\u5728\u5173\u952e\u9886\u57df\uff08\u5982\u533b\u7597\u4fdd\u5065\uff09\u7684\u53ef\u9760\u6027\u3001\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aKG-SMILE\u7684\u4e0e\u65b9\u6cd5\u65e0\u5173\u3001\u57fa\u4e8e\u6270\u52a8\u7684\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u56feRAG\u63d0\u4f9b\u4ee4\u724c\u548c\u7ec4\u4ef6\u7ea7\u522b\u7684\u4e92\u64cd\u4f5c\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5e94\u7528\u53d7\u63a7\u6270\u52a8\u3001\u8ba1\u7b97\u76f8\u4f3c\u6027\u4ee5\u53ca\u8bad\u7ec3\u52a0\u6743\u7ebf\u6027\u4ee3\u7406\u6a21\u578b\uff0c\u6765\u8bc6\u522b\u5bf9\u751f\u6210\u8f93\u51fa\u6700\u6709\u5f71\u54cd\u7684\u56fe\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u4ece\u800c\u4f7fRAG\u7cfb\u7edf\u66f4\u52a0\u900f\u660e\u3002KG-SMILE\u7684\u8bc4\u4f30\u4f7f\u7528\u4e86\u5305\u62ec\u4fdd\u771f\u5ea6\u3001\u5fe0\u5b9e\u6027\u3001\u4e00\u81f4\u6027\u3001\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u5728\u5185\u7684\u7efc\u5408\u5f52\u56e0\u6307\u6807\u3002", "result": "\u7814\u7a76\u53d1\u73b0KG-SMILE\u80fd\u591f\u751f\u6210\u7a33\u5b9a\u4e14\u7b26\u5408\u4eba\u7c7b\u7406\u89e3\u7684\u89e3\u91ca\uff0c\u8fd9\u8868\u660e\u5b83\u6709\u80fd\u529b\u5728\u6a21\u578b\u6548\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "conclusion": "KG-SMILE\u901a\u8fc7\u63d0\u4f9b\u7a33\u5b9a\u3001\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\uff0c\u6210\u529f\u5730\u63d0\u5347\u4e86\u56feRAG\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\uff0c\u6709\u52a9\u4e8e\u5e73\u8861\u6a21\u578b\u6548\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u6574\u4f53\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002"}}
{"id": "2509.03666", "pdf": "https://arxiv.org/pdf/2509.03666", "abs": "https://arxiv.org/abs/2509.03666", "authors": ["Kenny Guo", "Nicholas Eckhert", "Krish Chhajer", "Luthira Abeykoon", "Lorne Schell"], "title": "AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management", "categories": ["cs.LG"], "comment": "IEEE (International Conference on Smart Energy Grid Engineering\n  (SEGE)) 2025, 6 pages", "summary": "We present a deep reinforcement learning-based framework for autonomous\nmicrogrid management. tailored for remote communities. Using deep reinforcement\nlearning and time-series forecasting models, we optimize microgrid energy\ndispatch strategies to minimize costs and maximize the utilization of renewable\nenergy sources such as solar and wind. Our approach integrates the transformer\narchitecture for forecasting of renewable generation and a proximal-policy\noptimization (PPO) agent to make decisions in a simulated environment. Our\nexperimental results demonstrate significant improvements in both energy\nefficiency and operational resilience when compared to traditional rule-based\nmethods. This work contributes to advancing smart-grid technologies in pursuit\nof zero-carbon energy systems. We finally provide an open-source framework for\nsimulating several microgrid environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u6cbb\u5fae\u7535\u7f51\u7ba1\u7406\u6846\u67b6\uff0c\u5229\u7528Transformer\u8fdb\u884c\u53ef\u518d\u751f\u80fd\u6e90\u9884\u6d4b\uff0c\u5e76\u91c7\u7528PPO\u667a\u80fd\u4f53\u4f18\u5316\u80fd\u6e90\u8c03\u5ea6\uff0c\u4ee5\u6700\u5c0f\u5316\u6210\u672c\u5e76\u6700\u5927\u5316\u53ef\u518d\u751f\u80fd\u6e90\u5229\u7528\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u80fd\u6e90\u6548\u7387\u548c\u8fd0\u884c\u97e7\u6027\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u65e8\u5728\u4e3a\u504f\u8fdc\u793e\u533a\u63d0\u4f9b\u81ea\u6cbb\u5fae\u7535\u7f51\u7ba1\u7406\u65b9\u6848\uff0c\u901a\u8fc7\u4f18\u5316\u80fd\u6e90\u8c03\u5ea6\u7b56\u7565\uff0c\u6700\u5c0f\u5316\u8fd0\u8425\u6210\u672c\uff0c\u5e76\u6700\u5927\u5316\u592a\u9633\u80fd\u3001\u98ce\u80fd\u7b49\u53ef\u518d\u751f\u80fd\u6e90\u7684\u5229\u7528\uff0c\u4ee5\u63a8\u8fdb\u96f6\u78b3\u80fd\u6e90\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. \u4f7f\u7528Transformer\u67b6\u6784\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u91cf\u8fdb\u884c\u65f6\u5e8f\u9884\u6d4b\u30022. \u90e8\u7f72\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u667a\u80fd\u4f53\u5728\u6a21\u62df\u73af\u5883\u4e2d\u505a\u51fa\u51b3\u7b56\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u80fd\u6e90\u6548\u7387\u548c\u8fd0\u884c\u97e7\u6027\u65b9\u9762\u5747\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u63d0\u4f9b\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u6cbb\u5fae\u7535\u7f51\u7ba1\u7406\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u667a\u80fd\u7535\u7f51\u6280\u672f\u5411\u96f6\u78b3\u80fd\u6e90\u7cfb\u7edf\u7684\u53d1\u5c55\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684\u5fae\u7535\u7f51\u73af\u5883\u6a21\u62df\u6846\u67b6\u3002"}}
{"id": "2509.03535", "pdf": "https://arxiv.org/pdf/2509.03535", "abs": "https://arxiv.org/abs/2509.03535", "authors": ["Ahmed Mubarak", "Amna Ahmed", "Amira Nasser", "Aya Mohamed", "Fares El-Sadek", "Mohammed Ahmed", "Ahmed Salah", "Youssef Sobhy"], "title": "QuesGenie: Intelligent Multimodal Question Generation", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 8 figures, 12 tables. Supervised by Dr. Ahmed Salah and TA\n  Youssef Sobhy", "summary": "In today's information-rich era, learners have access to abundant educational\nresources, but the lack of practice materials tailored to these resources\npresents a significant challenge. This project addresses that gap by developing\na multi-modal question generation system that can automatically generate\ndiverse question types from various content formats. The system features four\nmajor components: multi-modal input handling, question generation,\nreinforcement learning from human feedback (RLHF), and an end-to-end\ninteractive interface. This project lays the foundation for automated,\nscalable, and intelligent question generation, carefully balancing resource\nefficiency, robust functionality and a smooth user experience.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u95ee\u9898\u751f\u6210\u7cfb\u7edf\uff0c\u89e3\u51b3\u6559\u80b2\u8d44\u6e90\u4e0e\u7ec3\u4e60\u6750\u6599\u4e0d\u5339\u914d\u7684\u96be\u9898\u3002", "motivation": "\u5728\u4fe1\u606f\u4e30\u5bcc\u7684\u65f6\u4ee3\uff0c\u5b66\u4e60\u8005\u867d\u62e5\u6709\u5927\u91cf\u6559\u80b2\u8d44\u6e90\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u8fd9\u4e9b\u8d44\u6e90\u91cf\u8eab\u5b9a\u5236\u7684\u7ec3\u4e60\u6750\u6599\uff0c\u8fd9\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u95ee\u9898\u751f\u6210\u7cfb\u7edf\uff0c\u80fd\u81ea\u52a8\u4ece\u591a\u79cd\u5185\u5bb9\u683c\u5f0f\u751f\u6210\u591a\u6837\u5316\u95ee\u9898\u3002\u7cfb\u7edf\u5305\u542b\u591a\u6a21\u6001\u8f93\u5165\u5904\u7406\u3001\u95ee\u9898\u751f\u6210\u3001\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u4ee5\u53ca\u7aef\u5230\u7aef\u4ea4\u4e92\u754c\u9762\u3002", "result": "\u8be5\u9879\u76ee\u4e3a\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u548c\u667a\u80fd\u7684\u95ee\u9898\u751f\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u8d44\u6e90\u6548\u7387\u3001\u9c81\u68d2\u529f\u80fd\u548c\u7528\u6237\u4f53\u9a8c\u4e4b\u95f4\u53d6\u5f97\u4e86\u7cbe\u5fc3\u5e73\u8861\uff0c\u6709\u671b\u5b9e\u73b0\u9ad8\u6548\u3001\u667a\u80fd\u7684\u95ee\u7b54\u81ea\u52a8\u5316\u751f\u6210\u3002"}}
{"id": "2509.04219", "pdf": "https://arxiv.org/pdf/2509.04219", "abs": "https://arxiv.org/abs/2509.04219", "authors": ["Leandro M\u00e1rcio Bertholdo", "Renan Barreto Paredes", "Gabriela de Lima Marin", "Cesar A. H. Loureiro", "Milton Kaoru Kashiwakura Pedro de Botelho Marcos"], "title": "Analyzing the Effect of an Extreme Weather Event on Telecommunications and Information Technology: Insights from 30 Days of Flooding", "categories": ["cs.NI"], "comment": "32 pages, 15 figures. To appear in Passive and Active Measurement\n  Conference (PAM) 2025, published in Lecture Notes in Computer Science (LNCS),\n  Springer. The final authenticated version is available at\n  https://doi.org/10.1007/978-3-031-85960-1_12", "summary": "In May 2024, weeks of severe rainfall in Rio Grande do Sul, Brazil caused\nwidespread damage to infrastructure, impacting over 400 cities and 2.3 million\npeople. This study presents the construction of comprehensive\ntelecommunications datasets during this climatic event, encompassing Internet\nmeasurements, fiber cut reports, and Internet Exchange routing data. By\ncorrelating network disruptions with hydrological and operational factors, the\ndataset offers insights into the resilience of fiber networks, data centers,\nand Internet traffic during critical events. For each scenario, we investigate\nfailures related to the Information and Communication Technology infrastructure\nand highlight the challenges faced when its resilience is critically tested.\nPreliminary findings reveal trends in connectivity restoration, infrastructure\nvulnerabilities, and user behavior changes. These datasets and pre-analysis aim\nto support future research on disaster recovery strategies and the development\nof robust telecommunications systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e862024\u5e745\u6708\u5df4\u897f\u6d2a\u6c34\u671f\u95f4\u7684\u7efc\u5408\u7535\u4fe1\u6570\u636e\u96c6\uff08\u4e92\u8054\u7f51\u6d4b\u91cf\u3001\u5149\u7ea4\u4e2d\u65ad\u62a5\u544a\u3001IXP\u8def\u7531\u6570\u636e\uff09\uff0c\u4ee5\u5206\u6790\u7f51\u7edc\u5f39\u6027\u3001\u57fa\u7840\u8bbe\u65bd\u6f0f\u6d1e\u548c\u7528\u6237\u884c\u4e3a\u53d8\u5316\uff0c\u65e8\u5728\u652f\u6301\u707e\u96be\u6062\u590d\u7b56\u7565\u548c\u66f4\u7a33\u5065\u7684\u7cfb\u7edf\u5f00\u53d1\u3002", "motivation": "2024\u5e745\u6708\u5df4\u897f\u5357\u90e8\u53d1\u751f\u4e25\u91cd\u6d2a\u707e\uff0c\u5bf9\u57fa\u7840\u8bbe\u65bd\u548c230\u4e07\u4eba\u9020\u6210\u5e7f\u6cdb\u5f71\u54cd\uff0c\u51f8\u663e\u4e86\u5728\u6c14\u5019\u4e8b\u4ef6\u4e2d\u7406\u89e3\u7535\u4fe1\u7f51\u7edc\u5f39\u6027\u53ca\u5176\u9762\u4e34\u6311\u6218\u7684\u5fc5\u8981\u6027\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u4e92\u8054\u7f51\u6d4b\u91cf\u3001\u5149\u7ea4\u4e2d\u65ad\u62a5\u544a\u548c\u4e92\u8054\u7f51\u4ea4\u6362\u8def\u7531\u6570\u636e\u7684\u7efc\u5408\u7535\u4fe1\u6570\u636e\u96c6\u3002\u901a\u8fc7\u5c06\u7f51\u7edc\u4e2d\u65ad\u4e0e\u6c34\u6587\u53ca\u8fd0\u884c\u56e0\u7d20\u76f8\u5173\u8054\uff0c\u7814\u7a76\u4e86ICT\u57fa\u7840\u8bbe\u65bd\u7684\u6545\u969c\u3002", "result": "\u6570\u636e\u96c6\u63ed\u793a\u4e86\u5149\u7ea4\u7f51\u7edc\u3001\u6570\u636e\u4e2d\u5fc3\u548c\u4e92\u8054\u7f51\u6d41\u91cf\u5728\u5173\u952e\u4e8b\u4ef6\u4e2d\u7684\u5f39\u6027\uff0c\u521d\u6b65\u53d1\u73b0\u5305\u62ec\u8fde\u63a5\u6062\u590d\u8d8b\u52bf\u3001\u57fa\u7840\u8bbe\u65bd\u8106\u5f31\u6027\u548c\u7528\u6237\u884c\u4e3a\u53d8\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u6784\u5efa\u7684\u6570\u636e\u96c6\u53ca\u521d\u6b65\u5206\u6790\u65e8\u5728\u4e3a\u672a\u6765\u7684\u707e\u96be\u6062\u590d\u7b56\u7565\u7814\u7a76\u548c\u7a33\u5065\u7535\u4fe1\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u652f\u6301\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u5f39\u6027\u53d7\u5230\u4e25\u5cfb\u8003\u9a8c\u65f6ICT\u57fa\u7840\u8bbe\u65bd\u6240\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2509.03635", "pdf": "https://arxiv.org/pdf/2509.03635", "abs": "https://arxiv.org/abs/2509.03635", "authors": ["Hongpei Zheng", "Lintao Xiang", "Qijun Yang", "Qian Lin", "Hujun Yin"], "title": "Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding", "categories": ["cs.CV"], "comment": "16 pages, 6 figures", "summary": "The rapid development of Large Multimodal Models (LMMs) has led to remarkable\nprogress in 2D visual understanding; however, extending these capabilities to\n3D scene understanding remains a significant challenge. Existing approaches\npredominantly rely on text-only supervision, which fails to provide the\ngeometric constraints required for learning robust 3D spatial representations.\nIn this paper, we introduce Reg3D, a novel Reconstructive Geometry Instruction\nTuning framework that addresses this limitation by incorporating geometry-aware\nsupervision directly into the training process. Our key insight is that\neffective 3D understanding necessitates reconstructing underlying geometric\nstructures rather than merely describing them. Unlike existing methods that\ninject 3D information solely at the input level, Reg3D adopts a\ndual-supervision paradigm that leverages 3D geometric information both as input\nand as explicit learning targets. Specifically, we design complementary\nobject-level and frame-level reconstruction tasks within a dual-encoder\narchitecture, enforcing geometric consistency to encourage the development of\nspatial reasoning capabilities. Extensive experiments on ScanQA, Scan2Cap,\nScanRefer, and SQA3D demonstrate that Reg3D delivers substantial performance\nimprovements, establishing a new training paradigm for spatially aware\nmultimodal models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faReg3D\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u51e0\u4f55\u611f\u77e5\u7684\u53cc\u91cd\u76d1\u7763\uff08\u8f93\u5165\u548c\u5b66\u4e60\u76ee\u6807\uff09\u548c\u91cd\u5efa\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u57283D\u573a\u666f\u7406\u89e3\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u57282D\u89c6\u89c9\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u57283D\u573a\u666f\u7406\u89e3\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\u3002\u4e3b\u8981\u95ee\u9898\u5728\u4e8e\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7eaf\u6587\u672c\u76d1\u7763\uff0c\u7f3a\u4e4f\u5b66\u4e60\u9c81\u68d23D\u7a7a\u95f4\u8868\u793a\u6240\u9700\u7684\u51e0\u4f55\u7ea6\u675f\u3002", "method": "\u5f15\u5165Reg3D\uff08Reconstructive Geometry Instruction Tuning\uff09\u6846\u67b6\u3002\u5176\u6838\u5fc3\u662f\u76f4\u63a5\u5c06\u51e0\u4f55\u611f\u77e5\u76d1\u7763\u878d\u5165\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u901a\u8fc7\u91cd\u5efa\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\u800c\u975e\u4ec5\u63cf\u8ff0\u6765\u589e\u5f3a3D\u7406\u89e3\u3002Reg3D\u91c7\u7528\u53cc\u91cd\u76d1\u7763\u8303\u5f0f\uff0c\u5c063D\u51e0\u4f55\u4fe1\u606f\u4f5c\u4e3a\u8f93\u5165\u548c\u660e\u786e\u7684\u5b66\u4e60\u76ee\u6807\u3002\u5177\u4f53\u8bbe\u8ba1\u4e86\u5728\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5185\u7684\u4e92\u8865\u5bf9\u8c61\u7ea7\u548c\u5e27\u7ea7\u91cd\u5efa\u4efb\u52a1\uff0c\u4ee5\u5f3a\u5236\u51e0\u4f55\u4e00\u81f4\u6027\u5e76\u57f9\u517b\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728ScanQA\u3001Scan2Cap\u3001ScanRefer\u548cSQA3D\u7b49\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cReg3D\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "Reg3D\u4e3a\u7a7a\u95f4\u611f\u77e5\u591a\u6a21\u6001\u6a21\u578b\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u8303\u5f0f\u3002"}}
{"id": "2509.03636", "pdf": "https://arxiv.org/pdf/2509.03636", "abs": "https://arxiv.org/abs/2509.03636", "authors": ["Jacqueline Maasch", "John Kalantari", "Kia Khezeli"], "title": "CausalARC: Abstract Reasoning with Causal World Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Reasoning requires adaptation to novel problem settings under limited data\nand distribution shift. This work introduces CausalARC: an experimental testbed\nfor AI reasoning in low-data and out-of-distribution regimes, modeled after the\nAbstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is\nsampled from a fully specified causal world model, formally expressed as a\nstructural causal model. Principled data augmentations provide observational,\ninterventional, and counterfactual feedback about the world model in the form\nof few-shot, in-context learning demonstrations. As a proof-of-concept, we\nillustrate the use of CausalARC for four language model evaluation settings:\n(1) abstract reasoning with test-time training, (2) counterfactual reasoning\nwith in-context learning, (3) program synthesis, and (4) causal discovery with\nlogical reasoning.", "AI": {"tldr": "\u5f15\u5165CausalARC\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u7684\u5b9e\u9a8c\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u5728\u4f4e\u6570\u636e\u548c\u5206\u5e03\u5916\u6761\u4ef6\u4e0b\u8bc4\u4f30AI\u63a8\u7406\uff0c\u5e76\u5c55\u793a\u5176\u5728\u56db\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "AI\u63a8\u7406\u9700\u8981\u5728\u6709\u9650\u6570\u636e\u548c\u5206\u5e03\u504f\u79fb\u7684\u60c5\u51b5\u4e0b\u9002\u5e94\u65b0\u9896\u95ee\u9898\u8bbe\u7f6e\u3002", "method": "\u5f15\u5165CausalARC\uff0c\u4e00\u4e2a\u6a21\u4eff\u62bd\u8c61\u63a8\u7406\u8bed\u6599\u5e93\uff08ARC\uff09\u7684AI\u63a8\u7406\u5b9e\u9a8c\u6d4b\u8bd5\u5e73\u53f0\u3002\u6bcf\u4e2aCausalARC\u4efb\u52a1\u90fd\u4ece\u4e00\u4e2a\u5b8c\u5168\u6307\u5b9a\u7684\u56e0\u679c\u4e16\u754c\u6a21\u578b\uff08\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff09\u4e2d\u91c7\u6837\u3002\u901a\u8fc7\u6709\u539f\u5219\u7684\u6570\u636e\u589e\u5f3a\uff0c\u4ee5\u5c11\u6837\u672c\u3001\u60c5\u5883\u5b66\u4e60\u6f14\u793a\u7684\u5f62\u5f0f\u63d0\u4f9b\u89c2\u6d4b\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u53cd\u9988\u3002", "result": "\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\uff0c\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86CausalARC\u5728\u56db\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\u7684\u5e94\u7528\uff1a\u62bd\u8c61\u63a8\u7406\uff08\u6d4b\u8bd5\u65f6\u8bad\u7ec3\uff09\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\uff08\u60c5\u5883\u5b66\u4e60\uff09\u3001\u7a0b\u5e8f\u5408\u6210\u548c\u56e0\u679c\u53d1\u73b0\uff08\u903b\u8f91\u63a8\u7406\uff09\u3002", "conclusion": "CausalARC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u5728\u4f4e\u6570\u636e\u548c\u5206\u5e03\u5916\u6761\u4ef6\u4e0b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u64c5\u957f\u5904\u7406\u56e0\u679c\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u53ef\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u3002"}}
{"id": "2509.03672", "pdf": "https://arxiv.org/pdf/2509.03672", "abs": "https://arxiv.org/abs/2509.03672", "authors": ["Arpan Mukherjee", "Marcello Bullo", "Deniz G\u00fcnd\u00fcz"], "title": "SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Uniform-reward reinforcement learning from human feedback (RLHF), which\ntrains a single reward model to represent the preferences of all annotators,\nfails to capture the diversity of opinions across sub-populations,\ninadvertently favoring dominant groups. The state-of-the-art, MaxMin-RLHF,\naddresses this by learning group-specific reward models, and by optimizing for\nthe group receiving the minimum reward, thereby promoting fairness. However, we\nidentify that a key limitation of MaxMin-RLHF is its poor performance when the\nminimum-reward group is a minority. To mitigate this drawback, we introduce a\nnovel framework, termed {\\em SharedRep-RLHF}. At its core, SharedRep-RLHF\nlearns and leverages {\\em shared traits} in annotations among various groups,\nin contrast to learning separate reward models across groups. We first show\nthat MaxMin-RLHF is provably suboptimal in learning shared traits, and then\nquantify the sample complexity of SharedRep-RLHF. Experiments across diverse\nnatural language tasks showcase the effectiveness of SharedRep-RLHF compared to\nMaxMin-RLHF with a gain of up to 20% in win rate.", "AI": {"tldr": "\u73b0\u6709MaxMin-RLHF\u5728\u5c11\u6570\u7fa4\u4f53\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u63d0\u51faSharedRep-RLHF\uff0c\u901a\u8fc7\u5b66\u4e60\u7ec4\u95f4\u5171\u4eab\u7279\u5f81\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u516c\u5e73\u6027RLHF\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u5c11\u6570\u7fa4\u4f53\u4e0a\u3002", "motivation": "\u7edf\u4e00\u5956\u52b1\u7684RLHF\u65e0\u6cd5\u6355\u6349\u591a\u6837\u5316\u610f\u89c1\uff0c\u504f\u8892\u591a\u6570\u7fa4\u4f53\u3002\u73b0\u6709\u6700\u5148\u8fdb\u7684MaxMin-RLHF\u901a\u8fc7\u5b66\u4e60\u7279\u5b9a\u7fa4\u4f53\u5956\u52b1\u6a21\u578b\u5e76\u4f18\u5316\u6700\u4f4e\u5956\u52b1\u7fa4\u4f53\u6765\u4fc3\u8fdb\u516c\u5e73\uff0c\u4f46\u5176\u5728\u6700\u4f4e\u5956\u52b1\u7fa4\u4f53\u4e3a\u5c11\u6570\u7fa4\u4f53\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u662f\u672c\u6587\u7814\u7a76\u7684\u52a8\u673a\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86SharedRep-RLHF\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u662f\u5b66\u4e60\u5e76\u5229\u7528\u5404\u7ec4\u6ce8\u91ca\u4e2d\u7684\u201c\u5171\u4eab\u7279\u5f81\u201d\uff0c\u800c\u975e\u50cfMaxMin-RLHF\u90a3\u6837\u5b66\u4e60\u72ec\u7acb\u7684\u7ec4\u7279\u5b9a\u5956\u52b1\u6a21\u578b\u3002\u7814\u7a76\u8bc1\u660e\u4e86MaxMin-RLHF\u5728\u5b66\u4e60\u5171\u4eab\u7279\u5f81\u65b9\u9762\u662f\u6b21\u4f18\u7684\uff0c\u5e76\u91cf\u5316\u4e86SharedRep-RLHF\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSharedRep-RLHF\u6bd4MaxMin-RLHF\u66f4\u6709\u6548\uff0c\u80dc\u7387\u63d0\u5347\u9ad8\u8fbe20%\u3002", "conclusion": "SharedRep-RLHF\u901a\u8fc7\u5173\u6ce8\u548c\u5229\u7528\u5404\u7ec4\u6ce8\u91ca\u4e2d\u7684\u5171\u4eab\u7279\u5f81\uff0c\u6210\u529f\u514b\u670d\u4e86MaxMin-RLHF\u5728\u5904\u7406\u5c11\u6570\u7fa4\u4f53\u65f6\u7684\u6027\u80fd\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86RLHF\u7684\u516c\u5e73\u6027\u548c\u6574\u4f53\u8868\u73b0\u3002"}}
{"id": "2509.03537", "pdf": "https://arxiv.org/pdf/2509.03537", "abs": "https://arxiv.org/abs/2509.03537", "authors": ["Cheng-Kai Yeh", "Hsing-Wang Lee", "Chung-Hung Kuo", "Hen-Hsen Huang"], "title": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "7 pages, accepted by CIKM 2025 as a short paper", "summary": "Abstraction--the ability to recognize and distill essential computational\npatterns from complex problem statements--is a foundational skill in computer\nscience, critical both for human problem-solvers and coding-oriented large\nlanguage models (LLMs). Despite recent advances in training LLMs for code\ngeneration using reinforcement learning (RL), most existing approaches focus\nprimarily on superficial pattern recognition, overlooking explicit training for\nabstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement\nLearning for Abstract Reasoning), a novel framework explicitly designed to\nenhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to\ntransform kernel problems into narrative-rich, challenging descriptions without\nchanging their fundamental logic. Simultaneously, a student coding model is\ntrained to solve these complex narrative problems by extracting their\nunderlying computational kernels. Experimental results demonstrate that AR$^2$\nsubstantially improves the student model's accuracy on previously unseen,\nchallenging programming tasks, underscoring abstraction as a key skill for\nenhancing LLM generalization.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faAR$^2$\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u663e\u5f0f\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u62bd\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u51c6\u786e\u6027\u3002", "motivation": "\u62bd\u8c61\u80fd\u529b\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u57fa\u7840\u6280\u80fd\uff0c\u5bf9LLM\u7684\u4ee3\u7801\u751f\u6210\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709LLM\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\uff0c\u5ffd\u89c6\u4e86\u5bf9\u62bd\u8c61\u80fd\u529b\u7684\u663e\u5f0f\u8bad\u7ec3\u3002", "method": "\u63d0\u51faAR$^2$\uff08\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u62bd\u8c61\u63a8\u7406\uff09\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5229\u7528\u4e00\u4e2a\u6559\u5e08\u6a21\u578b\u5c06\u6838\u5fc3\u95ee\u9898\u8f6c\u5316\u4e3a\u590d\u6742\u53d9\u8ff0\u95ee\u9898\uff08\u903b\u8f91\u4e0d\u53d8\uff09\uff0c\u540c\u65f6\u8bad\u7ec3\u4e00\u4e2a\u5b66\u751f\u7f16\u7801\u6a21\u578b\u901a\u8fc7\u63d0\u53d6\u5e95\u5c42\u8ba1\u7b97\u6838\u5fc3\u6765\u89e3\u51b3\u8fd9\u4e9b\u590d\u6742\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAR$^2$\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u5728\u672a\u89c1\u8fc7\u7684\u3001\u5177\u6709\u6311\u6218\u6027\u7684\u7f16\u7a0b\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u62bd\u8c61\u80fd\u529b\u662f\u589e\u5f3aLLM\u6cdb\u5316\u80fd\u529b\u7684\u5173\u952e\u6280\u80fd\u3002"}}
{"id": "2509.03704", "pdf": "https://arxiv.org/pdf/2509.03704", "abs": "https://arxiv.org/abs/2509.03704", "authors": ["Seth Z. Zhao", "Huizhi Zhang", "Zhaowei Li", "Juntong Peng", "Anthony Chui", "Zewei Zhou", "Zonglin Meng", "Hao Xiang", "Zhiyu Huang", "Fujia Wang", "Ran Tian", "Chenfeng Xu", "Bolei Zhou", "Jiaqi Ma"], "title": "QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception", "categories": ["cs.CV"], "comment": null, "summary": "Cooperative perception through Vehicle-to-Everything (V2X) communication\noffers significant potential for enhancing vehicle perception by mitigating\nocclusions and expanding the field of view. However, past research has\npredominantly focused on improving accuracy metrics without addressing the\ncrucial system-level considerations of efficiency, latency, and real-world\ndeployability. Noticeably, most existing systems rely on full-precision models,\nwhich incur high computational and transmission costs, making them impractical\nfor real-time operation in resource-constrained environments. In this paper, we\nintroduce \\textbf{QuantV2X}, the first fully quantized multi-agent system\ndesigned specifically for efficient and scalable deployment of multi-modal,\nmulti-agent V2X cooperative perception. QuantV2X introduces a unified\nend-to-end quantization strategy across both neural network models and\ntransmitted message representations that simultaneously reduces computational\nload and transmission bandwidth. Remarkably, despite operating under low-bit\nconstraints, QuantV2X achieves accuracy comparable to full-precision systems.\nMore importantly, when evaluated under deployment-oriented metrics, QuantV2X\nreduces system-level latency by 3.2$\\times$ and achieves a +9.5 improvement in\nmAP30 over full-precision baselines. Furthermore, QuantV2X scales more\neffectively, enabling larger and more capable models to fit within strict\nmemory budgets. These results highlight the viability of a fully quantized\nmulti-agent intermediate fusion system for real-world deployment. The system\nwill be publicly released to promote research in this field:\nhttps://github.com/ucla-mobility/QuantV2X.", "AI": {"tldr": "QuantV2X\u662f\u9996\u4e2a\u5168\u91cf\u5316\u591a\u667a\u80fd\u4f53V2X\u534f\u540c\u611f\u77e5\u7cfb\u7edf\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u91cf\u5316\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u4f20\u8f93\u6210\u672c\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7ea7\u6548\u7387\u3001\u5ef6\u8fdf\u548c\u90e8\u7f72\u6027\u3002", "motivation": "\u73b0\u6709VV2X\u534f\u540c\u611f\u77e5\u7814\u7a76\u4e3b\u8981\u4fa7\u91cd\u4e8e\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u6548\u7387\u3001\u5ef6\u8fdf\u548c\u5b9e\u9645\u90e8\u7f72\u6027\u7b49\u7cfb\u7edf\u7ea7\u5173\u952e\u56e0\u7d20\u3002\u591a\u6570\u7cfb\u7edf\u4f9d\u8d56\u5168\u7cbe\u5ea6\u6a21\u578b\uff0c\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u548c\u4f20\u8f93\u6210\u672c\uff0c\u4e0d\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u64cd\u4f5c\u3002", "method": "\u63d0\u51faQuantV2X\uff0c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u3001\u591a\u667a\u80fd\u4f53V2X\u534f\u540c\u611f\u77e5\u90e8\u7f72\u800c\u8bbe\u8ba1\u7684\u7b2c\u4e00\u6b3e\u5168\u91cf\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u5f15\u5165\u4e86\u7edf\u4e00\u7684\u7aef\u5230\u7aef\u91cf\u5316\u7b56\u7565\uff0c\u6db5\u76d6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u548c\u4f20\u8f93\u6d88\u606f\u8868\u793a\uff0c\u4ee5\u540c\u6b65\u51cf\u5c11\u8ba1\u7b97\u8d1f\u8f7d\u548c\u4f20\u8f93\u5e26\u5bbd\u3002", "result": "QuantV2X\u5728\u4f4e\u6bd4\u7279\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u5168\u7cbe\u5ea6\u7cfb\u7edf\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u5728\u90e8\u7f72\u5bfc\u5411\u6307\u6807\u8bc4\u4f30\u4e0b\uff0cQuantV2X\u5c06\u7cfb\u7edf\u7ea7\u5ef6\u8fdf\u964d\u4f4e\u4e863.2\u500d\uff0cmAP30\u6bd4\u5168\u7cbe\u5ea6\u57fa\u7ebf\u63d0\u9ad8\u4e869.5\u3002\u6b64\u5916\uff0cQuantV2X\u5177\u6709\u66f4\u597d\u7684\u6269\u5c55\u6027\uff0c\u5141\u8bb8\u5728\u4e25\u683c\u5185\u5b58\u9884\u7b97\u4e0b\u4f7f\u7528\u66f4\u5927\u3001\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u5168\u91cf\u5316\u591a\u667a\u80fd\u4f53\u4e2d\u95f4\u878d\u5408\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.03644", "pdf": "https://arxiv.org/pdf/2509.03644", "abs": "https://arxiv.org/abs/2509.03644", "authors": ["Fran\u00e7ois Olivier", "Zied Bouraoui"], "title": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations", "categories": ["cs.AI", "cs.CL"], "comment": "To appear in Proceedings of Machine Learning Research, 19th\n  Conference on Neurosymbolic Learning and Reasoning, 2025", "summary": "Despite significant progress in natural language understanding, Large\nLanguage Models (LLMs) remain error-prone when performing logical reasoning,\noften lacking the robust mental representations that enable human-like\ncomprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that\ngrounds understanding and logical reasoning in schematic representations based\non image schemas-recurring patterns derived from sensorimotor experience that\nstructure human cognition. Our system operationalizes the spatial foundations\nof these cognitive structures using declarative spatial reasoning within Answer\nSet Programming. Through evaluation on logical deduction problems, we\ndemonstrate that LLMs can be guided to interpret scenarios through embodied\ncognitive structures, that these structures can be formalized as executable\nprograms, and that the resulting representations support effective logical\nreasoning with enhanced interpretability. While our current implementation\nfocuses on spatial primitives, it establishes the computational foundation for\nincorporating more complex and dynamic representations.", "AI": {"tldr": "\u5f15\u5165\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edfEmbodied-LM\uff0c\u901a\u8fc7\u5177\u8eab\u8ba4\u77e5\u7ed3\u6784\uff08\u57fa\u4e8e\u56fe\u50cf\u56fe\u5f0f\u548cASP\u7684\u7a7a\u95f4\u63a8\u7406\uff09\u63d0\u5347LLMs\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u7c7b\u4f3c\u4eba\u7c7b\u7684\u7a33\u5065\u5fc3\u7406\u8868\u5f81\u3002", "method": "\u63d0\u51faEmbodied-LM\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u901a\u8fc7\u57fa\u4e8e\u56fe\u50cf\u56fe\u5f0f\uff08\u6e90\u81ea\u611f\u89c9\u8fd0\u52a8\u7ecf\u9a8c\u7684\u6a21\u5f0f\uff09\u7684\u793a\u610f\u8868\u5f81\u6765\u5efa\u7acb\u7406\u89e3\u548c\u903b\u8f91\u63a8\u7406\uff0c\u5e76\u5229\u7528\u56de\u7b54\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4e2d\u7684\u58f0\u660e\u5f0f\u7a7a\u95f4\u63a8\u7406\u64cd\u4f5c\u8fd9\u4e9b\u8ba4\u77e5\u7ed3\u6784\u7684\u7a7a\u95f4\u57fa\u7840\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eLLMs\u53ef\u88ab\u5f15\u5bfc\u901a\u8fc7\u5177\u8eab\u8ba4\u77e5\u7ed3\u6784\u89e3\u91ca\u573a\u666f\uff0c\u8fd9\u4e9b\u7ed3\u6784\u53ef\u5f62\u5f0f\u5316\u4e3a\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u4e14\u652f\u6301\u6709\u6548\u4e14\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u903b\u8f91\u63a8\u7406\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLMs\u6574\u5408\u5177\u8eab\u8ba4\u77e5\u7ed3\u6784\u63d0\u4f9b\u4e86\u8ba1\u7b97\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u7eb3\u5165\u66f4\u590d\u6742\u52a8\u6001\u7684\u8868\u5f81\u5960\u5b9a\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.03673", "pdf": "https://arxiv.org/pdf/2509.03673", "abs": "https://arxiv.org/abs/2509.03673", "authors": ["Hang Wang", "Huijie Tang", "Ningai Leng", "Zhoufan Yu"], "title": "A Machine Learning-Based Study on the Synergistic Optimization of Supply Chain Management and Financial Supply Chains from an Economic Perspective", "categories": ["cs.LG"], "comment": "Accepted by the 2025 IEEE 8th International Conference on Information\n  Systems and Computer Aided Education (ICISCAE 2025)", "summary": "Based on economic theories and integrated with machine learning technology,\nthis study explores a collaborative Supply Chain Management and Financial\nSupply Chain Management (SCM - FSCM) model to solve issues like efficiency\nloss, financing constraints, and risk transmission. We combine Transaction Cost\nand Information Asymmetry theories and use algorithms such as random forests to\nprocess multi-dimensional data and build a data-driven, three-dimensional\n(cost-efficiency-risk) analysis framework. We then apply an FSCM model of \"core\nenterprise credit empowerment plus dynamic pledge financing.\" We use Long\nShort-Term Memory (LSTM) networks for demand forecasting and\nclustering/regression algorithms for benefit allocation. The study also\ncombines Game Theory and reinforcement learning to optimize the\ninventory-procurement mechanism and uses eXtreme Gradient Boosting (XGBoost)\nfor credit assessment to enable rapid monetization of inventory. Verified with\n20 core and 100 supporting enterprises, the results show a 30\\% increase in\ninventory turnover, an 18\\%-22\\% decrease in SME financing costs, a stable\norder fulfillment rate above 95\\%, and excellent model performance (demand\nforecasting error <= 8\\%, credit assessment accuracy >= 90\\%). This SCM-FSCM\nmodel effectively reduces operating costs, alleviates financing constraints,\nand supports high-quality supply chain development.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u7ed3\u5408\u7ecf\u6d4e\u7406\u8bba\u548c\u673a\u5668\u5b66\u4e60\u7684\u534f\u540c\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e0e\u91d1\u878d\u4f9b\u5e94\u94fe\u7ba1\u7406\uff08SCM-FSCM\uff09\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u4f9b\u5e94\u94fe\u6548\u7387\u3001\u878d\u8d44\u7ea6\u675f\u548c\u98ce\u9669\u4f20\u5bfc\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u8fd0\u8425\u7ee9\u6548\u3002", "motivation": "\u89e3\u51b3\u4f9b\u5e94\u94fe\u4e2d\u5b58\u5728\u7684\u6548\u7387\u635f\u5931\u3001\u878d\u8d44\u7ea6\u675f\u548c\u98ce\u9669\u4f20\u5bfc\u7b49\u95ee\u9898\u3002", "method": "\u6574\u5408\u4ea4\u6613\u6210\u672c\u7406\u8bba\u548c\u4fe1\u606f\u4e0d\u5bf9\u79f0\u7406\u8bba\uff1b\u5229\u7528\u968f\u673a\u68ee\u6797\u7b49\u7b97\u6cd5\u5904\u7406\u591a\u7ef4\u6570\u636e\uff0c\u6784\u5efa\u6210\u672c-\u6548\u7387-\u98ce\u9669\u4e09\u7ef4\u5206\u6790\u6846\u67b6\uff1b\u5e94\u7528\u201c\u6838\u5fc3\u4f01\u4e1a\u4fe1\u7528\u8d4b\u80fd+\u52a8\u6001\u8d28\u62bc\u878d\u8d44\u201d\u7684FSCM\u6a21\u578b\uff1b\u91c7\u7528LSTM\u8fdb\u884c\u9700\u6c42\u9884\u6d4b\uff0c\u805a\u7c7b/\u56de\u5f52\u7b97\u6cd5\u8fdb\u884c\u6536\u76ca\u5206\u914d\uff1b\u7ed3\u5408\u535a\u5f08\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5e93\u5b58\u91c7\u8d2d\u673a\u5236\uff1b\u4f7f\u7528XGBoost\u8fdb\u884c\u4fe1\u7528\u8bc4\u4f30\u3002", "result": "\u5e93\u5b58\u5468\u8f6c\u7387\u63d0\u9ad830%\uff1b\u4e2d\u5c0f\u4f01\u4e1a\u878d\u8d44\u6210\u672c\u964d\u4f4e18%-22%\uff1b\u8ba2\u5355\u5c65\u884c\u7387\u7a33\u5b9a\u572895%\u4ee5\u4e0a\uff1b\u9700\u6c42\u9884\u6d4b\u8bef\u5dee\u22648%\uff1b\u4fe1\u7528\u8bc4\u4f30\u51c6\u786e\u7387\u226590%\u3002", "conclusion": "\u8be5SCM-FSCM\u6a21\u578b\u6709\u6548\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\uff0c\u7f13\u89e3\u4e86\u878d\u8d44\u7ea6\u675f\uff0c\u5e76\u652f\u6301\u4e86\u4f9b\u5e94\u94fe\u7684\u9ad8\u8d28\u91cf\u53d1\u5c55\u3002"}}
{"id": "2509.03540", "pdf": "https://arxiv.org/pdf/2509.03540", "abs": "https://arxiv.org/abs/2509.03540", "authors": ["Shanglin Wu", "Lihui Liu", "Jinho D. Choi", "Kai Shu"], "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often struggle with producing factually\nconsistent answers due to limitations in their parametric memory.\nRetrieval-Augmented Generation (RAG) methods address this issue by\nincorporating external knowledge from trusted sources at inference time.\nHowever, such methods typically treat knowledge as unstructured text, which\nlimits their ability to support compositional reasoning and identify factual\ninconsistencies. To overcome these limitations, we propose a novel framework\nthat dynamically constructs and expands knowledge graphs (KGs) during\ninference, integrating both internal knowledge extracted from LLMs and external\ninformation retrieved from external sources. Our method begins by extracting a\nseed KG from the question via prompting, followed by iterative expansion using\nthe LLM's latent knowledge. The graph is then selectively refined through\nexternal retrieval, enhancing factual coverage and correcting inaccuracies. We\nevaluate our approach on three diverse factual QA benchmarks, demonstrating\nconsistent improvements in factual accuracy, answer precision, and\ninterpretability over baseline prompting and static KG-augmented methods. Our\nfindings suggest that inference-time KG construction is a promising direction\nfor enhancing LLM factuality in a structured, interpretable, and scalable\nmanner.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u52a8\u6001\u6784\u5efa\u548c\u6269\u5c55\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u7684\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u7ed3\u5408LLM\u7684\u5185\u90e8\u77e5\u8bc6\u548c\u5916\u90e8\u4fe1\u606f\uff0c\u4ee5\u589e\u5f3aLLM\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u4e8b\u5b9e\u6027\u95ee\u7b54\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3001\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u56e0\u53c2\u6570\u8bb0\u5fc6\u9650\u5236\u5e38\u96be\u4ee5\u751f\u6210\u4e8b\u5b9e\u4e00\u81f4\u7684\u7b54\u6848\u3002\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u867d\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\uff0c\u4f46\u5c06\u77e5\u8bc6\u89c6\u4e3a\u975e\u7ed3\u6784\u5316\u6587\u672c\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u7ec4\u5408\u63a8\u7406\u80fd\u529b\u548c\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u8bc6\u522b\u80fd\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u52a8\u6001\u6784\u5efa\u5e76\u6269\u5c55\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\uff0c\u6574\u5408LLMs\u63d0\u53d6\u7684\u5185\u90e8\u77e5\u8bc6\u548c\u5916\u90e8\u6765\u6e90\u68c0\u7d22\u7684\u4fe1\u606f\u3002\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u63d0\u793a\u4ece\u95ee\u9898\u4e2d\u63d0\u53d6\u4e00\u4e2a\u79cd\u5b50KG\uff0c\u968f\u540e\u5229\u7528LLM\u7684\u6f5c\u5728\u77e5\u8bc6\u8fdb\u884c\u8fed\u4ee3\u6269\u5c55\uff0c\u6700\u540e\u901a\u8fc7\u5916\u90e8\u68c0\u7d22\u9009\u62e9\u6027\u7cbe\u70bc\u56fe\u8c31\uff0c\u4ee5\u589e\u5f3a\u4e8b\u5b9e\u8986\u76d6\u7387\u5e76\u7ea0\u6b63\u4e0d\u51c6\u786e\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6837\u5316\u7684\u4e8b\u5b9e\u6027\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u7b54\u6848\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\uff0c\u5747\u6bd4\u57fa\u7ebf\u63d0\u793a\u548c\u9759\u6001KG\u589e\u5f3a\u65b9\u6cd5\u5c55\u73b0\u51fa\u6301\u7eed\u7684\u6539\u8fdb\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u63a8\u7406\u65f6\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u662f\u589e\u5f3aLLM\u4e8b\u5b9e\u6027\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u80fd\u591f\u4ee5\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u63d0\u5347\u5176\u6027\u80fd\u3002"}}
