<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs](https://arxiv.org/abs/2507.07186)
*Itay Itzhak,Yonatan Belinkov,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: 研究发现大语言模型的认知偏差主要源于预训练阶段，而非微调或训练随机性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）存在认知偏差，但目前尚不清楚这些偏差的来源是预训练、微调还是训练过程中的随机性。

Method: 采用两步因果实验方法：首先，使用不同随机种子多次微调模型以评估训练随机性对30多种认知偏差的影响；其次，引入“交叉微调”，在模型间交换指令数据集，以隔离偏差来源并测试偏差是否依赖于数据集。

Result: 研究发现训练随机性确实引入了一些变异性，但模型的认知偏差主要由预训练决定。拥有相同预训练骨干的模型，其偏差模式比仅共享微调数据的模型更为相似。

Conclusion: 理解微调模型的偏差需要超越微调效应，深入考虑其预训练起源。这一视角有助于未来制定评估和缓解大语言模型偏差的原则性策略。

Abstract: Large language models (LLMs) exhibit cognitive biases -- systematic
tendencies of irrational decision-making, similar to those seen in humans.
Prior work has found that these biases vary across models and can be amplified
by instruction tuning. However, it remains unclear if these differences in
biases stem from pretraining, finetuning, or even random noise due to training
stochasticity. We propose a two-step causal experimental approach to
disentangle these factors. First, we finetune models multiple times using
different random seeds to study how training randomness affects over $30$
cognitive biases. Second, we introduce \emph{cross-tuning} -- swapping
instruction datasets between models to isolate bias sources. This swap uses
datasets that led to different bias patterns, directly testing whether biases
are dataset-dependent. Our findings reveal that while training randomness
introduces some variability, biases are mainly shaped by pretraining: models
with the same pretrained backbone exhibit more similar bias patterns than those
sharing only finetuning data. These insights suggest that understanding biases
in finetuned models requires considering their pretraining origins beyond
finetuning effects. This perspective can guide future efforts to develop
principled strategies for evaluating and mitigating bias in LLMs.

</details>


### [2] [Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses](https://arxiv.org/abs/2507.07188)
*Jens Rupprecht,Georg Ahnert,Markus Strohmaier*

Main category: cs.CL

TL;DR: 本研究揭示了大型语言模型（LLMs）在模拟社会科学调查中对问题扰动的敏感性，并发现其存在一致的近因偏差，强调了提示词设计和鲁棒性测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前对于LLM作为人类调查对象替代品的可靠性及其对已知响应偏差的易感性了解不足，亟需深入研究。

Method: 本研究选取了9个不同的LLM，利用世界价值观调查（WVS）中的问题，对问题措辞和答案选项结构施加了11种扰动，共进行了超过167,000次模拟访谈，以评估LLM的响应鲁棒性。

Result: 所有被测试的LLM都对扰动表现出敏感性，并一致地呈现出程度不一的“近因偏差”（倾向于选择最后呈现的答案选项）。虽然大型模型通常更具鲁棒性，但所有模型对语义变化（如转述）和组合扰动仍很敏感。研究发现LLM的某些响应偏差与人类相似。

Conclusion: 本研究强调了在使用LLM生成合成调查数据时，提示词设计和进行鲁棒性测试的至关重要性。

Abstract: Large Language Models (LLMs) are increasingly used as proxies for human
subjects in social science surveys, but their reliability and susceptibility to
known response biases are poorly understood. This paper investigates the
response robustness of LLMs in normative survey contexts -- we test nine
diverse LLMs on questions from the World Values Survey (WVS), applying a
comprehensive set of 11 perturbations to both question phrasing and answer
option structure, resulting in over 167,000 simulated interviews. In doing so,
we not only reveal LLMs' vulnerabilities to perturbations but also reveal that
all tested models exhibit a consistent \textit{recency bias} varying in
intensity, disproportionately favoring the last-presented answer option. While
larger models are generally more robust, all models remain sensitive to
semantic variations like paraphrasing and to combined perturbations. By
applying a set of perturbations, we reveal that LLMs partially align with
survey response biases identified in humans. This underscores the critical
importance of prompt design and robustness testing when using LLMs to generate
synthetic survey data.

</details>


### [3] [SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains](https://arxiv.org/abs/2507.07229)
*Krithika Ramesh,Daniel Smolyak,Zihao Zhao,Nupoor Gandhi,Ritu Agarwal,Margrét Bjarnadóttir,Anjalie Field*

Main category: cs.CL

TL;DR: SynthTextEval是一个全面的合成文本评估工具包，旨在通过多维度评估提升AI开发中的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）生成的合成文本在高风险领域（如医疗、法律）具有隐私保护的潜力，但要实现这一潜力，需要对合成数据进行系统且多维度的评估，包括其在下游系统中的效用、系统公平性、隐私泄露风险、与源文本的分布差异以及领域专家的定性反馈。

Method: 本文提出了SynthTextEval工具包，它允许用户对上传或通过其生成模块创建的合成数据，从下游系统效用、系统公平性、隐私泄露风险、通用分布差异和领域专家定性反馈等多个维度进行综合评估。

Result: 尽管SynthTextEval可用于任何数据，但其功能和有效性已在医疗和法律这两个高风险领域的数据集上得到了突出展示和验证。

Conclusion: 通过整合和标准化合成文本的评估指标，SynthTextEval旨在提高合成文本的实用性，进而促进人工智能开发中的隐私保护。

Abstract: We present SynthTextEval, a toolkit for conducting comprehensive evaluations
of synthetic text. The fluency of large language model (LLM) outputs has made
synthetic text potentially viable for numerous applications, such as reducing
the risks of privacy violations in the development and deployment of AI systems
in high-stakes domains. Realizing this potential, however, requires principled
consistent evaluations of synthetic data across multiple dimensions: its
utility in downstream systems, the fairness of these systems, the risk of
privacy leakage, general distributional differences from the source text, and
qualitative feedback from domain experts. SynthTextEval allows users to conduct
evaluations along all of these dimensions over synthetic data that they upload
or generate using the toolkit's generation module. While our toolkit can be run
over any data, we highlight its functionality and effectiveness over datasets
from two high-stakes domains: healthcare and law. By consolidating and
standardizing evaluation metrics, we aim to improve the viability of synthetic
text, and in-turn, privacy-preservation in AI development.

</details>


### [4] [Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings](https://arxiv.org/abs/2507.07248)
*Minseon Kim,Jean-Philippe Corbeil,Alessandro Sordoni,Francois Beaulieu,Paul Vozila*

Main category: cs.CL

TL;DR: 本文针对大型语言模型（LLMs）在医疗领域的应用所带来的安全隐患，提出了一套定制化的安全评估协议和数据集，涵盖患者、临床医生和通用用户三个视角，并通过红队测试对医疗LLMs的安全性进行了定量分析，旨在为医疗LLMs的安全部署奠定基础。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗领域的广泛应用，其输出可能直接影响人类健康，引发了严重的安全担忧。然而，现有安全评估主要集中于通用基准，缺乏针对医疗领域特定用户（如患者和临床医生）视角的专业安全评估。

Method: 引入了针对医疗领域的安全评估协议，该协议同时考虑了患者用户和临床医生用户的视角，并结合通用安全评估。为此，构建了PatientSafetyBench数据集，包含466个样本，涵盖5个关键类别，专门用于衡量患者视角的安全性。将红队测试协议应用于MediPhi模型集合作为案例研究进行定量分析。

Result: 据作者所知，这是首次通过有针对性的红队测试，从患者、临床医生和通用用户三个不同视角定义医疗LLMs的安全评估标准，并成功构建了PatientSafetyBench数据集，填补了医疗领域特定安全评估的空白。

Conclusion: 这项工作为医疗领域LLMs更安全的部署奠定了基础，通过多视角、定制化的安全评估，提高了医疗LLMs的可靠性和安全性。

Abstract: As the performance of large language models (LLMs) continues to advance,
their adoption is expanding across a wide range of domains, including the
medical field. The integration of LLMs into medical applications raises
critical safety concerns, particularly due to their use by users with diverse
roles, e.g. patients and clinicians, and the potential for model's outputs to
directly affect human health. Despite the domain-specific capabilities of
medical LLMs, prior safety evaluations have largely focused only on general
safety benchmarks. In this paper, we introduce a safety evaluation protocol
tailored to the medical domain in both patient user and clinician user
perspectives, alongside general safety assessments and quantitatively analyze
the safety of medical LLMs. We bridge a gap in the literature by building the
PatientSafetyBench containing 466 samples over 5 critical categories to measure
safety from the perspective of the patient. We apply our red-teaming protocols
on the MediPhi model collection as a case study. To our knowledge, this is the
first work to define safety evaluation criteria for medical LLMs through
targeted red-teaming taking three different points of view - patient,
clinician, and general user - establishing a foundation for safer deployment in
medical domains.

</details>


### [5] [The Impact of Background Speech on Interruption Detection in Collaborative Groups](https://arxiv.org/abs/2507.07280)
*Mariah Bradford,Nikhil Krishnaswamy,Nathaniel Blanchard*

Main category: cs.CL

TL;DR: 为课堂AI部署，开发了在多组对话重叠语音环境下鲁棒识别打断的先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有打断检测方法多在单对话、清晰音频下研究，不适用于课堂中多组并发对话和语音重叠普遍存在的真实场景。

Method: 分析了单对话和多组对话环境下的打断检测，并创建了一种对重叠语音鲁棒的先进打断识别方法。

Result: 成功开发出可用于课堂部署的、对重叠语音鲁棒的打断识别方法；揭示了协同小组互动中打断的语言和韵律特征。

Conclusion: 本研究提供了一种适用于真实课堂环境的打断识别方案，并为未来考虑多组重叠语音影响的小组对话追踪研究奠定了基础。

Abstract: Interruption plays a crucial role in collaborative learning, shaping group
interactions and influencing knowledge construction. AI-driven support can
assist teachers in monitoring these interactions. However, most previous work
on interruption detection and interpretation has been conducted in
single-conversation environments with relatively clean audio. AI agents
deployed in classrooms for collaborative learning within small groups will need
to contend with multiple concurrent conversations -- in this context,
overlapping speech will be ubiquitous, and interruptions will need to be
identified in other ways. In this work, we analyze interruption detection in
single-conversation and multi-group dialogue settings. We then create a
state-of-the-art method for interruption identification that is robust to
overlapping speech, and thus could be deployed in classrooms. Further, our work
highlights meaningful linguistic and prosodic information about how
interruptions manifest in collaborative group interactions. Our investigation
also paves the way for future works to account for the influence of overlapping
speech from multiple groups when tracking group dialog.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [Multi-level Mixture of Experts for Multimodal Entity Linking](https://arxiv.org/abs/2507.07108)
*Zhiwei Hu,Víctor Gutiérrez-Basulto,Zhiliang Xiang,Ru Li,Jeff Z. Pan*

Main category: cs.CV

TL;DR: 该论文提出了一个名为MMoE（Multi-level Mixture of Experts）的新模型，用于解决多模态实体链接（MEL）中存在的提及歧义和模态内容动态选择问题，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MEL方法未能解决两个关键问题：1) 提及歧义，即由于提及文本上下文的简洁性和信息缺失导致的语义内容不足；2) 模态内容动态选择，即难以动态区分不同模态信息部分的重要性。

Method: 本文提出了MMoE模型。它包含四个组件：1) 描述感知提及增强模块，利用大型语言模型识别最匹配提及的WikiData描述；2) 多模态特征提取模块，采用多模态特征编码器获取文本和视觉嵌入；3) 内部专家混合模块和4) 级别间专家混合模块，应用专家混合机制动态自适应地选择相关信息区域的特征。

Result: 广泛的实验证明，MMoE模型与现有最先进的方法相比，表现出卓越的性能。

Conclusion: MMoE模型有效缓解了提及歧义和模态内容动态选择问题，并在多模态实体链接任务中达到了最先进的水平。

Abstract: Multimodal Entity Linking (MEL) aims to link ambiguous mentions within
multimodal contexts to associated entities in a multimodal knowledge base.
Existing approaches to MEL introduce multimodal interaction and fusion
mechanisms to bridge the modality gap and enable multi-grained semantic
matching. However, they do not address two important problems: (i) mention
ambiguity, i.e., the lack of semantic content caused by the brevity and
omission of key information in the mention's textual context; (ii) dynamic
selection of modal content, i.e., to dynamically distinguish the importance of
different parts of modal information. To mitigate these issues, we propose a
Multi-level Mixture of Experts (MMoE) model for MEL. MMoE has four components:
(i) the description-aware mention enhancement module leverages large language
models to identify the WikiData descriptions that best match a mention,
considering the mention's textual context; (ii) the multimodal feature
extraction module adopts multimodal feature encoders to obtain textual and
visual embeddings for both mentions and entities; (iii)-(iv) the intra-level
mixture of experts and inter-level mixture of experts modules apply a switch
mixture of experts mechanism to dynamically and adaptively select features from
relevant regions of information. Extensive experiments demonstrate the
outstanding performance of MMoE compared to the state-of-the-art. MMoE's code
is available at: https://github.com/zhiweihu1103/MEL-MMoE.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 本研究提出了一个基于LLM的统一智能体框架，用于化工过程中的离散故障恢复规划和连续过程控制，并在实验中展现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 现代化工过程日益复杂，劳动力短缺且故障情景复杂，亟需结合符号推理与自适应控制的新型自动化范式。

Method: 提出了一个统一的智能体框架，利用大型语言模型（LLMs）同时进行离散故障恢复规划和连续过程控制。该框架采用有限状态机（FSMs）定义操作范围，并通过LLM规划代理、模拟代理和验证-重提示循环迭代优化方案。

Result: 在故障恢复案例中，GPT-4o及mini版在FSM路径规划上达到100%成功率，优于开源LLMs。在连续控制案例中，LLM控制器在温度维持方面表现与传统PID相当，且提示循环对处理非线性动态至关重要。研究还分析了主要失败模式。

Conclusion: 结果表明，通过结构化反馈和模块化智能体，LLMs能够统一高层符号规划与低层连续控制，为化工领域的韧性、语言驱动自动化开辟新途径。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate](https://arxiv.org/abs/2507.07129)
*A. Bochkov*

Main category: cs.LG

TL;DR: 本文提出一种基于固定、不可训练输入嵌入的语言模型构建方法，作为“通用对接端口”，实现了两种高效扩展范式：通过平均输出logits进行专家模型（MoE）的模块化组合，以及逐层增长模型。这两种方法在推理基准上均表现出性能提升，且无需整体训练。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的整体端到端训练范式资源密集且缺乏灵活性。研究旨在探索一种替代性的、更具建设性和灵活性的模型开发方法。

Method: 该研究基于不可训练的、确定性输入嵌入（源自Unicode字形视觉结构）建立模型。这种固定表示作为“通用对接端口”，支持两种主要扩展范式：
1. **模块化组合：** 将在不同数据集上训练的专家模型（如俄语和中文文本模型）通过简单平均其输出logits，在训练后无缝合并成一个更强大的Mixture-of-Experts (MoE) 模型，无需修改架构。
2. **逐层增长：** 引入逐层构建训练方法，通过逐步堆叠和训练Transformer模型中的每一层来“成长”深度模型。

Result: 1. **模块化组合：** 合并后的MoE模型在MMLU等推理基准上立即显示出性能提升，超越其组成专家模型，且未出现灾难性遗忘。
2. **逐层增长：** 该方法展示了稳定的收敛性，并且模型深度与复杂推理能力（例如SQuAD所需的）的出现之间存在明确的相关性。

Conclusion: 研究结果表明，人工智能开发可以从整体优化转向更具生物学或建设性的模型，其中复杂性可以增量构建，模块可以自由组合。这为资源高效的扩展、持续学习以及构建强大AI系统的更民主化生态系统开辟了新途径。

Abstract: The prevailing paradigm for scaling large language models (LLMs) involves
monolithic, end-to-end training, a resource-intensive process that lacks
flexibility. This paper explores an alternative, constructive approach to model
development, built upon the foundation of non-trainable, deterministic input
embeddings. In prior [1], we established that high-level semantic reasoning can
emerge in Transformers using frozen embeddings derived from the visual
structure of Unicode glyphs. Here, we demonstrate that this fixed
representational substrate acts as a universal "docking port," enabling two
powerful and efficient scaling paradigms: seamless modular composition and
progressive layer-wise growth.
  First, we show that specialist models trained on disparate datasets (e.g.,
Russian and Chinese text) can be merged into a single, more capable
Mixture-of-Experts (MoE) model, post-training, with zero architectural
modification. This is achieved by simply averaging their output logits. The
resulting MoE model exhibits immediate performance improvements on reasoning
benchmarks like MMLU, surpassing its constituent experts without catastrophic
forgetting. Second, we introduce a layer-wise constructive training
methodology, where a deep Transformer is "grown" by progressively stacking and
training one layer at a time. This method demonstrates stable convergence and a
clear correlation between model depth and the emergence of complex reasoning
abilities, such as those required for SQuAD.
  Our findings suggest a paradigm shift from monolithic optimization towards a
more biological or constructive model of AI development, where complexity is
built incrementally and modules can be composed freely. This opens new avenues
for resource-efficient scaling, continual learning, and a more democratized
ecosystem for building powerful AI systems. We release all code and models to
facilitate further research.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [9] [Synergistic Localization and Sensing in MIMO-OFDM Systems via Mixed-Integer Bilevel Learning](https://arxiv.org/abs/2507.07118)
*Zelin Zhu,Kai Yang,Rui Zhang*

Main category: cs.NI

TL;DR: 本文提出一种基于随机近端梯度混合整数双层优化的SPG-MIBO算法，用于联合建模和优化MIMO-OFDM系统中的无线定位与传感任务。


<details>
  <summary>Details</summary>
Motivation: 现代无线网络中，无线定位与传感对智能城市、物联网和自动系统至关重要。尽管将信道状态信息（CSI）与深度学习结合很有前景，但MIMO-OFDM系统高维CSI特性下定位与传感的联合建模仍研究不足。

Method: 将定位与传感任务公式化为混合整数双层深度学习问题，并提出一种新的基于随机近端梯度的混合整数双层优化（SPG-MIBO）算法。该算法适用于高维和大规模数据集，通过小批量训练提高计算和内存效率，并提供理论收敛保证。

Result: 在多个数据集上的广泛实验验证了SPG-MIBO算法的有效性，并突出了联合定位与传感优化所带来的性能提升。

Conclusion: 通过联合建模和优化无线定位与传感任务，所提出的SPG-MIBO算法能够有效利用MIMO-OFDM系统的高维CSI，提升系统性能，从而支持现代无线网络中的各种智能应用。

Abstract: Wireless localization and sensing technologies are essential in modern
wireless networks, supporting applications in smart cities, the Internet of
Things (IoT), and autonomous systems. High-performance localization and sensing
systems are critical for both network efficiency and emerging intelligent
applications. Integrating channel state information (CSI) with deep learning
has recently emerged as a promising solution. Recent works have leveraged the
spatial diversity of multiple input multiple output (MIMO) systems and the
frequency granularity of orthogonal frequency division multiplexing (OFDM)
waveforms to improve spatial resolution. Nevertheless, the joint modeling of
localization and sensing under the high-dimensional CSI characteristics of
MIMO-OFDM systems remains insufficiently investigated. This work aims to
jointly model and optimize localization and sensing tasks to harness their
potential synergy. We first formulate localization and sensing as a
mixed-integer bilevel deep learning problem and then propose a novel stochastic
proximal gradient-based mixed-integer bilevel optimization (SPG-MIBO)
algorithm. SPG-MIBO is well-suited for high-dimensional and large-scale
datasets, leveraging mini-batch training at each step for computational and
memory efficiency. The algorithm is also supported by theoretical convergence
guarantees. Extensive experiments on multiple datasets validate its
effectiveness and highlight the performance gains from joint localization and
sensing optimization.

</details>


### [10] [DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training](https://arxiv.org/abs/2507.07149)
*Renyuan Liu,Yuyang Leng,Kaiyan Liu,Shaohan Hu,Chun-Fu,Chen,Peijun Zhao,Heechul Yun,Shuochao Yao*

Main category: cs.NI

TL;DR: DAF是一个动态激活框架，通过系统级优化，解决了设备上训练的内存和时间效率问题，实现了显著的内存节省和加速，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 设备上深度神经网络训练中，激活压缩对于克服移动和边缘设备的内存限制至关重要。现有动态激活量化方法因计算开销和内存碎片化等系统级挑战，难以实际部署。

Method: DAF通过系统级优化实现内存和时间高效的动态量化训练。具体方法包括：开发针对移动和边缘SoC内存层次结构的混合规约操作；利用CPU-GPU协同位打包进行高效动态量化；以及实施重要性感知分页内存管理方案，以减少碎片并支持动态内存调整。

Result: 在嵌入式和移动平台上对多种深度学习模型进行评估，结果显示内存使用量减少高达22.9倍，速度提升3.2倍，且未影响模型训练精度。

Conclusion: DAF的系统级优化使其能够在不牺牲模型训练精度的情况下，显著节省内存并提高速度，从而成为资源受限环境下的可扩展且实用的解决方案。

Abstract: Recent advancements in on-device training for deep neural networks have
underscored the critical need for efficient activation compression to overcome
the memory constraints of mobile and edge devices. As activations dominate
memory usage during training and are essential for gradient computation,
compressing them without compromising accuracy remains a key research
challenge. While existing methods for dynamic activation quantization promise
theoretical memory savings, their practical deployment is impeded by
system-level challenges such as computational overhead and memory
fragmentation.
  To address these challenges, we introduce DAF, a Dynamic Activation Framework
that enables scalable and efficient on-device training through system-level
optimizations. DAF achieves both memory- and time-efficient dynamic
quantization training by addressing key system bottlenecks. It develops hybrid
reduction operations tailored to the memory hierarchies of mobile and edge
SoCs, leverages collaborative CPU-GPU bit-packing for efficient dynamic
quantization, and implements an importance-aware paging memory management
scheme to reduce fragmentation and support dynamic memory adjustments.
  These optimizations collectively enable DAF to achieve substantial memory
savings and speedup without compromising model training accuracy. Evaluations
on various deep learning models across embedded and mobile platforms
demonstrate up to a $22.9\times$ reduction in memory usage and a $3.2\times$
speedup, making DAF a scalable and practical solution for resource-constrained
environments.

</details>
