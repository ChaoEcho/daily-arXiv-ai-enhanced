<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 49]
- [cs.CV](#cs.CV) [Total: 74]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.NI](#cs.NI) [Total: 6]
- [eess.IV](#eess.IV) [Total: 7]
- [cs.AR](#cs.AR) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [astro-ph.GA](#astro-ph.GA) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.SC](#cs.SC) [Total: 1]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CY](#cs.CY) [Total: 5]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.RO](#cs.RO) [Total: 3]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance](https://arxiv.org/abs/2507.11582)
*Kazuyoshi Otsuka*

Main category: cs.CL

TL;DR: 研究发现大语言模型（LLMs）在文学评估中表现出主观且独特的评估模式和审美偏好，类似人类评论流派，而非中立基准。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型定位为“主观文学评论家”，旨在探索其在文学评估中的审美偏好和评估模式。

Method: 将十篇日本科幻短篇小说翻译成英文，并由六个先进的大语言模型进行七次独立的评估。研究采用主成分分析、聚类技术和TF-IDF分析来揭示评估的一致性、模式和词汇特征。

Result: 评估一致性存在显著差异（α范围从1.00到0.35），并揭示了五种独特的评估模式。不同故事的评估差异高达4.5倍，且每个模型都展现出独特的评估词汇。

Conclusion: 研究结果表明，大语言模型可能具备类似于人类评论流派的个体评估特征和隐性价值体系，而非仅仅是中立的基准评估工具。

Abstract: This study positions large language models (LLMs) as "subjective literary
critics" to explore aesthetic preferences and evaluation patterns in literary
assessment. Ten Japanese science fiction short stories were translated into
English and evaluated by six state-of-the-art LLMs across seven independent
sessions. Principal component analysis and clustering techniques revealed
significant variations in evaluation consistency ({\alpha} ranging from 1.00 to
0.35) and five distinct evaluation patterns. Additionally, evaluation variance
across stories differed by up to 4.5-fold, with TF-IDF analysis confirming
distinctive evaluation vocabularies for each model. Our seven-session
within-day protocol using an original Science Fiction corpus strategically
minimizes external biases, allowing us to observe implicit value systems shaped
by RLHF and their influence on literary judgment. These findings suggest that
LLMs may possess individual evaluation characteristics similar to human
critical schools, rather than functioning as neutral benchmarkers.

</details>


### [2] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 为解决多模态大语言模型（MLLMs）在地图视觉问答（Map-VQA）研究中地图类型和主题受限的问题，本文提出了MapIQ基准数据集，涵盖多种地图类型和主题，并评估了MLLMs的性能及其对地图设计变化的鲁棒性和敏感度。


<details>
  <summary>Details</summary>
Motivation: 现有Map-VQA研究主要集中于分区图，导致其在主题类别和视觉分析任务上的覆盖范围有限，未能充分探索MLLMs解读不同类型地图的能力。

Method: 1. 构建了MapIQ基准数据集，包含14,706个问答对，涵盖分区图、异形图和比例符号图三种地图类型，以及住房、犯罪等六个不同主题。2. 使用六种视觉分析任务评估了多个MLLMs的性能，并与人类基线进行比较。3. 进行了额外实验，分析地图设计变化（如颜色方案、图例、元素移除）对MLLMs鲁棒性和敏感度的影响。

Result: 研究结果提供了MLLMs在Map-VQA任务上的表现洞察，并通过额外实验揭示了模型面对地图设计变化时的鲁棒性、敏感性、对内部地理知识的依赖程度，以及未来提升Map-VQA性能的潜在方向。

Conclusion: MapIQ数据集的引入填补了Map-VQA研究在地图类型和主题广度上的空白。研究发现不仅评估了MLLMs在复杂地图理解上的能力，还深入探讨了地图设计对模型性能的影响，为未来优化MLLMs在地理信息处理领域的应用奠定了基础。

Abstract: Recent advancements in multimodal large language models (MLLMs) have driven
researchers to explore how well these models read data visualizations, e.g.,
bar charts, scatter plots. More recently, attention has shifted to visual
question answering with maps (Map-VQA). However, Map-VQA research has primarily
focused on choropleth maps, which cover only a limited range of thematic
categories and visual analytical tasks. To address these gaps, we introduce
MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three
map types: choropleth maps, cartograms, and proportional symbol maps spanning
topics from six distinct themes (e.g., housing, crime). We evaluate multiple
MLLMs using six visual analytical tasks, comparing their performance against
one another and a human baseline. An additional experiment examining the impact
of map design changes (e.g., altered color schemes, modified legend designs,
and removal of map elements) provides insights into the robustness and
sensitivity of MLLMs, their reliance on internal geographic knowledge, and
potential avenues for improving Map-VQA performance.

</details>


### [3] [Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation](https://arxiv.org/abs/2507.11634)
*Farideh Majidi,Ziaeddin Beheshtifard*

Main category: cs.CL

TL;DR: 本研究通过少量样本学习和增量学习方法，利用多语言预训练模型在有限的波斯语数据上实现了高准确率的跨语言情感分析。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个能够使用有限数据在波斯语中进行情感分析的模型，并从高资源语言中获取先验知识，以应对波斯语数据稀缺的挑战。

Method: 采用XLM-RoBERTa、mDeBERTa和DistilBERT三种多语言预训练模型，并利用少量样本学习和增量学习方法，在来自X、Instagram、Digikala、Snappfood和Taaghche等多样来源的少量波斯语数据上进行微调。

Result: 实验结果显示，mDeBERTa和XLM-RoBERTa模型表现优异，在波斯语情感分析中达到了96%的准确率。

Conclusion: 结合少量样本学习、增量学习与多语言预训练模型的方法，在波斯语情感分析任务中被证明是有效的。

Abstract: This research examines cross-lingual sentiment analysis using few-shot
learning and incremental learning methods in Persian. The main objective is to
develop a model capable of performing sentiment analysis in Persian using
limited data, while getting prior knowledge from high-resource languages. To
achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and
DistilBERT) were employed, which were fine-tuned using few-shot and incremental
learning approaches on small samples of Persian data from diverse sources,
including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled
the models to learn from a broad range of contexts. Experimental results show
that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%
accuracy on Persian sentiment analysis. These findings highlight the
effectiveness of combining few-shot learning and incremental learning with
multilingual pre-trained models.

</details>


### [4] [Partitioner Guided Modal Learning Framework](https://arxiv.org/abs/2507.11661)
*Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi*

Main category: cs.CL

TL;DR: PgM是一个多模态学习框架，它将模态表示分解为单模态和配对模态特征进行独立学习与灵活调整，并在多模态任务中展示了优异性能和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中，模态表示可分解为单模态和跨模态交互产生的配对模态特征。研究动机在于设计一种机制，能够更彻底地学习并灵活调整这两种不同来源的特征，以优化多模态表示并适应多样化的下游任务。

Method: 提出PgM（Partitioner-guided Modal learning）框架。其核心组件包括：模态分割器（将表示划分为单模态和配对模态特征）、单模态学习器、配对模态学习器以及单配对模态解码器（用于重构模态表示）。该框架旨在实现对这两种特征的深度学习、灵活的分布调整，并允许不同模态和分区采用不同的学习率。

Result: 在四种多模态任务上进行了广泛实验，证明了PgM的有效性及其对现有模型的可迁移性。此外，研究还通过可视化展示了单模态和配对模态特征在不同模态和任务中的分布，提供了关于其贡献的见解。

Conclusion: PgM框架通过其独特的特征划分和学习机制，成功地提升了多模态学习的性能和适应性。它强调了分别处理单模态和配对模态特征的重要性，并为未来的多模态研究提供了新的方向和深入理解。

Abstract: Multimodal learning benefits from multiple modal information, and each
learned modal representations can be divided into uni-modal that can be learned
from uni-modal training and paired-modal features that can be learned from
cross-modal interaction. Building on this perspective, we propose a
partitioner-guided modal learning framework, PgM, which consists of the modal
partitioner, uni-modal learner, paired-modal learner, and uni-paired modal
decoder. Modal partitioner segments the learned modal representation into
uni-modal and paired-modal features. Modal learner incorporates two dedicated
components for uni-modal and paired-modal learning. Uni-paired modal decoder
reconstructs modal representation based on uni-modal and paired-modal features.
PgM offers three key benefits: 1) thorough learning of uni-modal and
paired-modal features, 2) flexible distribution adjustment for uni-modal and
paired-modal representations to suit diverse downstream tasks, and 3) different
learning rates across modalities and partitions. Extensive experiments
demonstrate the effectiveness of PgM across four multimodal tasks and further
highlight its transferability to existing models. Additionally, we visualize
the distribution of uni-modal and paired-modal features across modalities and
tasks, offering insights into their respective contributions.

</details>


### [5] [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](https://arxiv.org/abs/2507.11694)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas*

Main category: cs.CL

TL;DR: ExpliCIT-QA是一个多模态表格问答系统，通过模块化设计提供可解释的答案，并增强透明度和可审计性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端TableVQA系统存在解释性不足的问题，作者旨在弥合这一差距，提升系统在复杂表格图像处理和答案生成过程中的透明度与可审计性，以适应金融和医疗等敏感领域的需求。

Method: ExpliCIT-QA采用模块化管道设计，包括：1) 基于思维链的多模态表格理解；2) 基于语言的逐步推理；3) 自动Python/Pandas代码生成（含错误处理反馈）；4) 代码执行以计算最终答案；5) 生成自然语言解释。所有中间输出均可供检查，以确保透明度。

Result: 在TableVQA-Bench基准测试中，ExpliCIT-QA与现有基线相比，在可解释性和透明度方面取得了显著改进。

Conclusion: ExpliCIT-QA系统成功弥补了端到端TableVQA系统在解释性方面的不足，通过高透明度和可审计性，为金融和医疗等结果审查至关重要的敏感领域应用开辟了道路。

Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for
tabular question answering into a multimodal pipeline capable of handling
complex table images and providing explainable answers. ExpliCIT-QA follows a
modular design, consisting of: (1) Multimodal Table Understanding, which uses a
Chain-of-Thought approach to extract and transform content from table images;
(2) Language-based Reasoning, where a step-by-step explanation in natural
language is generated to solve the problem; (3) Automatic Code Generation,
where Python/Pandas scripts are created based on the reasoning steps, with
feedback for handling errors; (4) Code Execution to compute the final answer;
and (5) Natural Language Explanation that describes how the answer was
computed. The system is built for transparency and auditability: all
intermediate outputs, parsed tables, reasoning steps, generated code, and final
answers are available for inspection. This strategy works towards closing the
explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on
the TableVQA-Bench benchmark, comparing it with existing baselines. We
demonstrated improvements in interpretability and transparency, which open the
door for applications in sensitive domains like finance and healthcare where
auditing results are critical.

</details>


### [6] [CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks](https://arxiv.org/abs/2507.11742)
*Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher*

Main category: cs.CL

TL;DR: 本文提出CRABS方法，结合语法分析和大型语言模型（LLM），有效识别Python数据科学笔记本中的信息流和执行依赖，解决了传统方法和纯LLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估、复用和调整数据科学/机器学习Python笔记本至关重要，但重新执行面临数据和软件依赖挑战。尽管LLM能理解代码，但在理解真实笔记本时，常因幻觉和长上下文问题而失败。

Method: 本文提出一个笔记本理解任务，旨在生成信息流图和单元格执行依赖图。通过开发CRABS（Capture and Resolve Assisted Bounding Strategy）策略，该方法首先利用浅层语法解析和抽象语法树（AST）分析捕获单元格间I/O集的估计范围，然后使用LLM通过逐单元格零样本学习解决剩余歧义，以识别每个单元格的真实数据输入和输出。

Result: 在包含50个Kaggle笔记本的标注数据集上，LLM成功解决了语法分析留下的1425个歧义中的1397个（98%）。CRABS在识别单元格间信息流方面达到98%的平均F1分数，在识别传递性单元格执行依赖方面达到99%的平均F1分数。

Conclusion: CRABS方法通过结合有限的语法分析和LLM，能够高效准确地理解数据科学笔记本的信息流和执行依赖，有效克服了传统重新执行的限制和纯LLM的理解障碍，为笔记本的评估、复用和适应提供了有效工具。

Abstract: Recognizing the information flows and operations comprising data science and
machine learning Python notebooks is critical for evaluating, reusing, and
adapting notebooks for new tasks. Investigating a notebook via re-execution
often is impractical due to the challenges of resolving data and software
dependencies. While Large Language Models (LLMs) pre-trained on large codebases
have demonstrated effectiveness in understanding code without running it, we
observe that they fail to understand some realistic notebooks due to
hallucinations and long-context challenges. To address these issues, we propose
a notebook understanding task yielding an information flow graph and
corresponding cell execution dependency graph for a notebook, and demonstrate
the effectiveness of a pincer strategy that uses limited syntactic analysis to
assist full comprehension of the notebook using an LLM. Our Capture and Resolve
Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and
analysis of the abstract syntax tree (AST) to capture the correct
interpretation of a notebook between lower and upper estimates of the
inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via
cell-by-cell zero-shot learning, thereby identifying the true data inputs and
outputs of each cell. We evaluate and demonstrate the effectiveness of our
approach using an annotated dataset of 50 representative, highly up-voted
Kaggle notebooks that together represent 3454 actual cell inputs and outputs.
The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the
syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves
average F1 scores of 98% identifying cell-to-cell information flows and 99%
identifying transitive cell execution dependencies.

</details>


### [7] [AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles](https://arxiv.org/abs/2507.11764)
*Matteo Fasulo,Luca Babboni,Luca Tedeschini*

Main category: cs.CL

TL;DR: 本文介绍了AI Wizards在CLEF 2025 CheckThat! Lab主观性检测任务中的参与，通过集成情感分数增强Transformer模型，在多语言和零样本设置下实现了优异的句子主客观分类性能。


<details>
  <summary>Details</summary>
Motivation: 参与CLEF 2025 CheckThat! Lab主观性检测任务，旨在新闻文章中对句子进行主观/客观分类，并在多语言及零样本设置下，提升现有Transformer模型的分类性能。

Method: 通过将辅助模型产生的情感分数与句子表示相结合，增强基于Transformer的分类器（如mDeBERTaV3-base, ModernBERT-base, Llama3.2-1B）。同时，采用决策阈值校准来解决类别不平衡问题。

Result: 情感特征的集成显著提升了性能，特别是主观F1分数。该框架获得了高排名，其中希腊语任务获得第一名（Macro F1 = 0.51）。

Conclusion: 所提出的情感增强型Transformer架构是主观性检测的有效策略，在多种语言（包括未见语言）中展现出强大的泛化能力。

Abstract: This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab
Task 1: Subjectivity Detection in News Articles, classifying sentences as
subjective/objective in monolingual, multilingual, and zero-shot settings.
Training/development datasets were provided for Arabic, German, English,
Italian, and Bulgarian; final evaluation included additional unseen languages
(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our
primary strategy enhanced transformer-based classifiers by integrating
sentiment scores, derived from an auxiliary model, with sentence
representations, aiming to improve upon standard fine-tuning. We explored this
sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base
(English), and Llama3.2-1B. To address class imbalance, prevalent across
languages, we employed decision threshold calibration optimized on the
development set. Our experiments show sentiment feature integration
significantly boosts performance, especially subjective F1 score. This
framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).

</details>


### [8] [Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models](https://arxiv.org/abs/2507.11809)
*Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss*

Main category: cs.CL

TL;DR: 本研究复现并分析了LLMs处理事实与反事实信息竞争时注意力头的作用。结果表明，注意力头通过通用复制抑制而非选择性反事实抑制促进事实输出，且其行为具有领域依赖性。


<details>
  <summary>Details</summary>
Motivation: 旨在理解大型语言模型（LLMs）如何处理其内部学习到的事实与外部上下文中的矛盾信息之间的竞争，并深入探讨注意力头在此过程中的作用。研究动机还包括复现并协调Ortu等人、Yu等人以及McDougall等人三项近期相关研究的发现。

Method: 进行了一项可复现性研究，利用机械可解释性工具，具体检查了注意力头强度与事实输出比率的关系，评估了关于注意力头抑制机制的相互竞争的假设，并调查了这些注意力模式的领域特异性。

Result: 1. 促进事实输出的注意力头通过通用复制抑制而非选择性反事实抑制实现其功能，因为增强这些注意力头反而可能抑制正确的原有事实。
2. 注意力头的行为具有领域依赖性，较大的模型表现出更专业化和类别敏感的模式。

Conclusion: 注意力头在处理LLMs中的事实与反事实信息竞争时，主要通过通用复制抑制机制而非选择性反事实抑制发挥作用，且其行为模式具有领域依赖性，大型模型展现出更强的专业化和类别敏感性。这些发现深化了对LLM内部机制的理解。

Abstract: This paper presents a reproducibility study examining how Large Language
Models (LLMs) manage competing factual and counterfactual information, focusing
on the role of attention heads in this process. We attempt to reproduce and
reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and
Pavlick and McDougall et al. that investigate the competition between
model-learned facts and contradictory context information through Mechanistic
Interpretability tools. Our study specifically examines the relationship
between attention head strength and factual output ratios, evaluates competing
hypotheses about attention heads' suppression mechanisms, and investigates the
domain specificity of these attention patterns. Our findings suggest that
attention heads promoting factual output do so via general copy suppression
rather than selective counterfactual suppression, as strengthening them can
also inhibit correct facts. Additionally, we show that attention head behavior
is domain-dependent, with larger models exhibiting more specialized and
category-sensitive patterns.

</details>


### [9] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
*Yash Ingle,Pruthwik Mishra*

Main category: cs.CL

TL;DR: 本文发布了一个包含英语和22种印度官方语言的23万句数据集，并提供基于机器学习和深度学习的鲁棒基线模型，旨在促进该领域的语言识别研究。


<details>
  <summary>Details</summary>
Motivation: 语言识别是自然语言处理中的一个关键基础步骤，常作为多语言机器翻译、信息检索等应用中的预处理环节。其核心挑战在于区分嘈杂、短文本和混合编码环境下的语言。对于词汇和发音相似且常共享文字的印度语言，这一任务尤为困难。

Method: 本文发布了一个包含23万句句子的大规模数据集，涵盖英语和所有22种官方印度语言，其中多数语言的数据是新创建的。此外，本文还开发并发布了利用机器学习和深度学习领域最先进方法的鲁棒基线模型。

Result: 所开发的基线模型在语言识别任务上的表现与现有最先进的模型相当。

Conclusion: 通过发布大规模新数据集和高性能基线模型，本文为解决印度语言的语言识别挑战提供了重要的资源和研究起点。

Abstract: The language identification task is a crucial fundamental step in NLP. Often
it serves as a pre-processing step for widely used NLP applications such as
multilingual machine translation, information retrieval, question and
answering, and text summarization. The core challenge of language
identification lies in distinguishing languages in noisy, short, and code-mixed
environments. This becomes even harder in case of diverse Indian languages that
exhibit lexical and phonetic similarities, but have distinct differences. Many
Indian languages share the same script making the task even more challenging.
In this paper, we release a dataset of 230K sentences consisting of English and
all 22 official Indian languages labeled with their language identifiers where
data in most languages are newly created. We also develop and release robust
baseline models using state-of-the-art approaches in machine learning and deep
learning that can aid the research in this field. Our baseline models are
comparable to the state-of-the-art models for the language identification task.

</details>


### [10] [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
*Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 提出一种新颖的框架，通过同时预测多个未来tokens来显著加速自回归语言模型的推理，且不损失质量。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型逐一生成token的序列性限制了推理速度和并行性，尤其在文本生成后期更为明显。

Method: 本研究提出一个新颖框架，利用自回归语言模型对未来token的内在知识，实现多token同时预测。主要创新包括：(1) 掩码输入，从公共前缀联合预测多个未来token；(2) 门控LoRA，在支持多token预测的同时保留原LLM功能；(3) 轻量级可学习采样模块，生成连贯序列；(4) 辅助训练损失（包括一致性损失），提高联合生成token的连贯性和准确性；(5) 推测性生成策略，二次方扩展token同时保持高保真度。

Result: 通过对预训练模型进行有监督微调，实现了显著的推理加速。例如，代码和数学生成速度提高近5倍，通用聊天和知识任务提高近2.5倍，且未损失任何生成质量。

Conclusion: 该方法成功加速了自回归语言模型的推理，同时保持了输出质量，有效克服了传统模型的速度瓶颈。

Abstract: Autoregressive language models are constrained by their inherently sequential
nature, generating one token at a time. This paradigm limits inference speed
and parallelism, especially during later stages of generation when the
direction and semantics of text are relatively certain. In this work, we
propose a novel framework that leverages the inherent knowledge of vanilla
autoregressive language models about future tokens, combining techniques to
realize this potential and enable simultaneous prediction of multiple
subsequent tokens. Our approach introduces several key innovations: (1) a
masked-input formulation where multiple future tokens are jointly predicted
from a common prefix; (2) a gated LoRA formulation that preserves the original
LLM's functionality, while equipping it for multi-token prediction; (3) a
lightweight, learnable sampler module that generates coherent sequences from
the predicted future tokens; (4) a set of auxiliary training losses, including
a consistency loss, to enhance the coherence and accuracy of jointly generated
tokens; and (5) a speculative generation strategy that expands tokens
quadratically in the future while maintaining high fidelity. Our method
achieves significant speedups through supervised fine-tuning on pretrained
models. For example, it generates code and math nearly 5x faster, and improves
general chat and knowledge tasks by almost 2.5x. These gains come without any
loss in quality.

</details>


### [11] [Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition](https://arxiv.org/abs/2507.11862)
*Junhong Ye,Xu Yuan,Xinying Qiu*

Main category: cs.CL

TL;DR: 本研究探讨了跨领域模型迁移、多领域数据融合和少样本学习在个人身份信息 (PII) 识别中的有效性。


<details>
  <summary>Details</summary>
Motivation: 准确识别个人身份信息 (PII) 对自动化文本匿名化至关重要。

Method: 利用医疗、法律和传记领域的标注语料库，从域内性能、跨域可迁移性、数据融合和少样本学习四个维度评估模型。

Result: 法律领域数据在传记文本中迁移效果良好，而医疗领域抵抗传入迁移。数据融合的益处具有领域特异性。在低专业化领域，仅用10%的训练数据即可实现高质量PII识别。

Conclusion: PII识别中的跨领域迁移和数据融合效果因领域而异，且在特定条件下，少样本学习也能实现高质量识别。

Abstract: Accurate recognition of personally identifiable information (PII) is central
to automated text anonymization. This paper investigates the effectiveness of
cross-domain model transfer, multi-domain data fusion, and sample-efficient
learning for PII recognition. Using annotated corpora from healthcare (I2B2),
legal (TAB), and biography (Wikipedia), we evaluate models across four
dimensions: in-domain performance, cross-domain transferability, fusion, and
few-shot learning. Results show legal-domain data transfers well to
biographical texts, while medical domains resist incoming transfer. Fusion
benefits are domain-specific, and high-quality recognition is achievable with
only 10% of training data in low-specialization domains.

</details>


### [12] [COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction](https://arxiv.org/abs/2507.11867)
*Xiangyu Yang,Xinying Qiu*

Main category: cs.CL

TL;DR: 本文提出COLA-GEC双向框架，通过相互知识迁移提升语法纠错（GEC）和语法可接受性判断（COLA）两项任务的性能，并在多语言基准测试中取得最先进结果。


<details>
  <summary>Details</summary>
Motivation: 语法纠错（GEC）和语法可接受性判断（COLA）是自然语言处理中的核心任务，它们共享基础语法知识但通常独立发展。研究动机在于通过建立一个双向框架，促进两者之间的知识共享，从而相互增强。

Method: 引入COLA-GEC双向框架：1. 使用GEC数据集增强语法可接受性判断模型，显著提升其多语言性能。2. 通过动态损失函数将语法可接受性信号整合到GEC模型训练中，有效引导修正结果趋向语法可接受的输出。

Result: 本方法在多个多语言基准测试上取得了最先进的（state-of-the-art）结果。综合错误分析突出了现有挑战，尤其在标点符号错误修正方面。

Conclusion: COLA-GEC框架通过双向知识迁移成功地提升了GEC和COLA任务的性能。研究结果为未来的语法建模提供了有价值的见解，特别是在解决标点符号错误等剩余挑战方面。

Abstract: Grammatical Error Correction (GEC) and grammatical acceptability judgment
(COLA) are core tasks in natural language processing, sharing foundational
grammatical knowledge yet typically evolving independently. This paper
introduces COLA-GEC, a novel bidirectional framework that enhances both tasks
through mutual knowledge transfer. First, we augment grammatical acceptability
models using GEC datasets, significantly improving their performance across
multiple languages. Second, we integrate grammatical acceptability signals into
GEC model training via a dynamic loss function, effectively guiding corrections
toward grammatically acceptable outputs. Our approach achieves state-of-the-art
results on several multilingual benchmarks. Comprehensive error analysis
highlights remaining challenges, particularly in punctuation error correction,
providing insights for future improvements in grammatical modeling.

</details>


### [13] [DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation](https://arxiv.org/abs/2507.11875)
*Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu*

Main category: cs.CL

TL;DR: DualReward是一个新颖的强化学习框架，通过双重奖励和自适应缩放机制，实现完形填空题的自动化干扰项生成，并在不同数据集上超越了现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统的干扰项生成方法主要依赖于监督学习或静态生成模型，无法有效平衡从人工示例中学习与探索新颖、高质量的干扰项，存在局限性。

Method: 本文提出了DualReward强化学习框架，其核心是一个双重奖励结构和自适应缩放机制。该机制能够区分人工创建的黄金标准干扰项和模型生成的候选干扰项，并根据模型的性能和置信度动态调整奖励信号强度。

Result: DualReward在篇章级（CLOTH-F）和句子级（MCQ）完形填空数据集上均表现出对现有最先进基线的持续改进。实验结果表明，自适应奖励缩放机制在同质数据集（CLOTH-F）上提供适度但持续的收益，在多样化、跨领域数据（MCQ）上提供更显著的改进（P@1提升3.48-3.86%），尤其擅长处理多样的题型和领域。

Conclusion: 该工作提供了一个灵活的框架，能够有效地平衡从可靠的人工示例中学习与探索新颖、高质量的干扰项，从而实现自动化的试题生成。

Abstract: This paper introduces DualReward, a novel reinforcement learning framework
for automatic distractor generation in cloze tests. Unlike conventional
approaches that rely primarily on supervised learning or static generative
models, our method employs a dual reward structure with adaptive scaling that
differentiates between human-created gold standard distractors and
model-generated candidates. The framework dynamically adjusts reward signal
intensity based on model performance and confidence. We evaluate our approach
on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,
demonstrating consistent improvements over state-of-the-art baselines.
Experimental results show that our adaptive reward scaling mechanism provides
modest but consistent benefits on homogeneous datasets (CLOTH-F) and more
substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data
(MCQ), suggesting its particular effectiveness for handling varied question
types and domains. Our work offers a flexible framework that effectively
balances learning from reliable human examples while exploring novel,
high-quality distractors for automated test generation.

</details>


### [14] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
*Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi*

Main category: cs.CL

TL;DR: 本研究发现大型语言模型（LLMs）内部编码了一个独立于拒绝行为的“有害性”概念。这个内部理解比其拒绝决策更稳健，可用于开发一种名为“Latent Guard”的内在安全机制，有效检测不安全输入并减少过度拒绝，且对微调攻击具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正理解有害性，而不仅仅是表面上的拒绝行为，因为现有研究表明LLMs的拒绝行为可通过一个拒绝方向来调节，这可能意味着其理解的局限性或脆弱性。

Method: 识别LLMs内部的“有害性方向”，并证明其独立于“拒绝方向”。通过因果干预（沿特定方向操纵模型内部状态）来验证这两个方向的区分。利用识别出的有害性概念分析越狱方法和对抗性微调的效果。基于模型的潜在有害性表示，开发并评估一种内在安全机制“Latent Guard”。

Result: 1. LLMs内部存在一个与拒绝行为独立的“有害性方向”。2. 沿有害性方向操纵可使模型将无害指令解释为有害，而沿拒绝方向操纵仅直接引发拒绝响应，不改变模型的有害性判断。3. 某些越狱方法通过削弱拒绝信号实现，但并未改变模型内部对有害性的认知。4. 对抗性微调以接受有害指令对模型内部的有害性认知影响甚微。5. “Latent Guard”作为一种内在安全机制，在检测不安全输入和减少过度拒绝方面表现出色，且对微调攻击具有鲁棒性，性能可与专门的安全模型（如Llama Guard 3 8B）媲美或超越。

Conclusion: LLMs对有害性拥有更深层次且稳健的内部理解，这与其表面的拒绝决策不同。这一发现为AI安全研究提供了新视角，并催生了更有效、更具鲁棒性的安全应用，例如利用潜在有害性表示作为内在保障机制，以增强LLMs的安全性并优化其行为。

Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand
harmfulness beyond just refusing? Prior work has shown that LLMs' refusal
behaviors can be mediated by a one-dimensional subspace, i.e., a refusal
direction. In this work, we identify a new dimension to analyze safety
mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a
separate concept from refusal. There exists a harmfulness direction that is
distinct from the refusal direction. As causal evidence, steering along the
harmfulness direction can lead LLMs to interpret harmless instructions as
harmful, but steering along the refusal direction tends to elicit refusal
responses directly without reversing the model's judgment on harmfulness.
Furthermore, using our identified harmfulness concept, we find that certain
jailbreak methods work by reducing the refusal signals without reversing the
model's internal belief of harmfulness. We also find that adversarially
finetuning models to accept harmful instructions has minimal impact on the
model's internal belief of harmfulness. These insights lead to a practical
safety application: The model's latent harmfulness representation can serve as
an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing
over-refusals that is robust to finetuning attacks. For instance, our Latent
Guard achieves performance comparable to or better than Llama Guard 3 8B, a
dedicated finetuned safeguard model, across different jailbreak methods. Our
findings suggest that LLMs' internal understanding of harmfulness is more
robust than their refusal decision to diverse input instructions, offering a
new perspective to study AI safety

</details>


### [15] [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models](https://arxiv.org/abs/2507.11882)
*Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 本文提出并构建了Marco-Bench-MIF，一个多语言指令遵循基准，以评估大型语言模型（LLMs）在30种语言中的指令遵循能力，并揭示了现有数据集的局限性、模型性能的差距以及多语言指令遵循的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）指令遵循能力评估数据集（如IFEval）主要以英语为中心或仅通过机器翻译，这严重限制了它们在多语言环境中的适用性。

Method: 研究者通过扩展IFEval并进行精心策划，构建了一个名为Marco-Bench-MIF的多语言本地化基准，覆盖30种语言。该基准采用混合流水线（结合翻译与验证），以解决语言约束（如中文大小写）和文化参考（如替换地域性公司名称）。随后，对20多个LLM在Marco-Bench-MIF上进行了综合评估。

Result: 评估结果发现：1) 高资源语言与低资源语言之间存在25-35%的准确性差距；2) 模型规模对性能有45-60%的显著影响，但特定脚本的挑战依然存在；3) 机器翻译数据与本地化数据相比，会低估7-22%的准确性。

Conclusion: 研究分析揭示了多语言指令遵循中的挑战，包括关键词一致性保留和跨语言的组合约束遵守。Marco-Bench-MIF基准为评估和提升LLM的多语言指令遵循能力提供了重要工具。

Abstract: Instruction-following capability has become a major ability to be evaluated
for Large Language Models (LLMs). However, existing datasets, such as IFEval,
are either predominantly monolingual and centered on English or simply machine
translated to other languages, limiting their applicability in multilingual
contexts. In this paper, we present an carefully-curated extension of IFEval to
a localized multilingual version named Marco-Bench-MIF, covering 30 languages
with varying levels of localization. Our benchmark addresses linguistic
constraints (e.g., modifying capitalization requirements for Chinese) and
cultural references (e.g., substituting region-specific company names in
prompts) via a hybrid pipeline combining translation with verification. Through
comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)
25-35% accuracy gap between high/low-resource languages, (2) model scales
largely impact performance by 45-60% yet persists script-specific challenges,
and (3) machine-translated data underestimates accuracy by7-22% versus
localized data. Our analysis identifies challenges in multilingual instruction
following, including keyword consistency preservation and compositional
constraint adherence across languages. Our Marco-Bench-MIF is available at
https://github.com/AIDC-AI/Marco-Bench-MIF.

</details>


### [16] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 该论文对深度学习在几何问题解决中的应用进行了全面综述，涵盖了相关任务、深度学习方法、评估指标、当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 几何问题解决是数学推理的关键领域，广泛应用于教育、AI和多模态能力评估。近年来，深度学习特别是多模态大语言模型的快速发展，促使该领域研究蓬勃兴起。本研究旨在提供全面实用的参考，以促进该领域进一步发展。

Method: 本研究采用综述方法，系统性地分析了深度学习在几何问题解决中的应用，具体包括：1) 全面总结相关任务；2) 深入回顾深度学习方法；3) 详细分析评估指标和方法；4) 批判性探讨当前挑战和未来方向。作者还创建并维护了一个持续更新的GitHub论文列表。

Result: 作为一篇综述，本研究的结果是对深度学习在几何问题解决领域应用现状的系统性梳理和分析，明确了关键任务、主流深度学习方法、常用的评估指标与方法，并指出了该领域当前面临的挑战及未来的研究方向，为研究人员提供了全面且实用的参考。

Conclusion: 本研究为深度学习在几何问题解决领域的应用提供了全面且实用的参考，旨在促进该领域的进一步发展。

Abstract: Geometry problem solving is a key area of mathematical reasoning, which is
widely involved in many important fields such as education, mathematical
ability assessment of artificial intelligence, and multimodal ability
assessment. In recent years, the rapid development of deep learning technology,
especially the rise of multimodal large language models, has triggered a
widespread research boom. This paper provides a survey of the applications of
deep learning in geometry problem solving, including (i) a comprehensive
summary of the relevant tasks in geometry problem solving; (ii) a thorough
review of related deep learning methods; (iii) a detailed analysis of
evaluation metrics and methods; and (iv) a critical discussion of the current
challenges and future directions that can be explored. Our goal is to provide a
comprehensive and practical reference of deep learning for geometry problem
solving to promote further developments in this field. We create a continuously
updated list of papers on GitHub: https://github.com/majianz/dl4gps.

</details>


### [17] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 本文提出了PolyChartQA，首个大规模多语言图表问答基准，包含22,606张图表和26,151个问题对，覆盖10种语言，旨在解决现有图表理解基准以英语为主的问题，并促进全球图表理解模型的发展。


<details>
  <summary>Details</summary>
Motivation: 图表是理解和交流数据的通用媒介，然而现有的图表理解基准主要以英语为中心，限制了其全球可访问性和适用性，因此需要一个多语言的图表问答基准。

Method: 构建了PolyChartQA，一个大规模多语言图表问答基准，包含22,606张图表和26,151个问答对，覆盖10种语言。采用解耦管道，将图表数据与渲染代码分离，通过翻译数据和重用代码灵活生成多语言图表。利用先进的LLM翻译技术，并进行严格的质量控制，确保语言和语义的一致性。

Result: PolyChartQA促进了多语言图表理解的系统评估。对开源和闭源大型视觉语言模型进行的实验显示，英语与其他语言之间存在显著的性能差距，特别是对于资源匮乏的非拉丁语系语言。

Conclusion: PolyChartQA基准为推动全球包容性的视觉语言模型发展奠定了基础。

Abstract: Charts are a universally adopted medium for interpreting and communicating
data. However, existing chart understanding benchmarks are predominantly
English-centric, limiting their accessibility and applicability to global
audiences. In this paper, we present PolyChartQA, the first large-scale
multilingual chart question answering benchmark covering 22,606 charts and
26,151 question-answering pairs across 10 diverse languages. PolyChartQA is
built using a decoupled pipeline that separates chart data from rendering code,
allowing multilingual charts to be flexibly generated by simply translating the
data and reusing the code. We leverage state-of-the-art LLM-based translation
and enforce rigorous quality control in the pipeline to ensure the linguistic
and semantic consistency of the generated multilingual charts. PolyChartQA
facilitates systematic evaluation of multilingual chart understanding.
Experiments on both open- and closed-source large vision-language models reveal
a significant performance gap between English and other languages, especially
low-resource ones with non-Latin scripts. This benchmark lays a foundation for
advancing globally inclusive vision-language models.

</details>


### [18] [BlockBPE: Parallel BPE Tokenization](https://arxiv.org/abs/2507.11941)
*Amos You*

Main category: cs.CL

TL;DR: BlockBPE是一个为GPU批量推理优化的并行BPE分词器，通过去除Regex预分词和高度并行化，实现了显著的吞吐量提升和更优的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）分词器在GPU批量推理工作流中受限于CPU且效率低下，其性能受限于Regex预分词，导致复杂度为O(n log n)。

Method: 提出了BlockBPE，一个并行GPU实现的字节对编码（BPE）分词器。该方法通过消除Regex预分词（可能导致生成质量的轻微下降）并启用线程块内的高度并行化分词合并，将整体复杂度降低到O(nd)，其中d远小于n。

Result: BlockBPE在GPU批量推理工作负载下实现了接近线性时间复杂度。与tiktoken相比，其吞吐量提高了2倍；与HuggingFace Tokenizers相比，吞吐量提高了2.5倍。

Conclusion: BlockBPE为LLM在GPU上的高吞吐量批量推理提供了一个更高效的分词解决方案，通过优化算法复杂度和充分利用GPU并行性，显著提升了性能，尽管存在小的生成质量损失。

Abstract: Tokenization is a critical preprocessing step in large language model
pipelines, yet widely-used implementations remain CPU-bound and suboptimal for
batch inference workflows on GPU. We present BlockBPE, a parallel GPU
implementation of byte-pair encoding (BPE) that achieves near linear-time
complexity under realistic assumptions and is optimized for high-throughput,
batch inference. Unlike existing Rust-based tokenizers such as HuggingFace
Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex
pre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates the
Regex pre-tokenization which leads to small loss in generation quality, but
enables highly parallelized token merges within thread blocks, reducing overall
complexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,
BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over
HuggingFace Tokenizers.

</details>


### [19] [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://arxiv.org/abs/2507.11942)
*Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu*

Main category: cs.CL

TL;DR: 提出一种动态注意力感知（DAC）方法，用于任务无关提示压缩，解决了现有方法忽略注意力关键词和压缩过程中信息熵动态变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有任务无关提示压缩方法主要依赖信息熵，但忽略了算法层面的注意力关键词重要性以及压缩过程中信息熵的变化。

Method: 提出动态注意力感知（DAC）方法。该方法有效整合熵和注意力信息，并在压缩过程中动态感知熵的变化，以实现细粒度提示压缩。

Result: 在LongBench、GSM8K和BBH等多个领域的广泛实验表明，DAC在不同任务和大型语言模型上持续产生稳健且显著的改进。

Conclusion: DAC是一种有效且鲁棒的任务无关提示压缩方法，能够显著提升提示处理的性能。

Abstract: Task-agnostic prompt compression leverages the redundancy in natural language
to reduce computational overhead and enhance information density within
prompts, especially in long-context scenarios. Existing methods predominantly
rely on information entropy as the metric to compress lexical units, aiming to
achieve minimal information loss. However, these approaches overlook two
critical aspects: (i) the importance of attention-critical tokens at the
algorithmic level, and (ii) shifts in information entropy during the
compression process. Motivated by these challenges, we propose a dynamic
attention-aware approach for task-agnostic prompt compression (DAC). This
approach effectively integrates entropy and attention information, dynamically
sensing entropy shifts during compression to achieve fine-grained prompt
compression. Extensive experiments across various domains, including LongBench,
GSM8K, and BBH, show that DAC consistently yields robust and substantial
improvements across a diverse range of tasks and LLMs, offering compelling
evidence of its efficacy.

</details>


### [20] [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://arxiv.org/abs/2507.11953)
*Yi Zhao,Zuchao Li,Hai Zhao*

Main category: cs.CL

TL;DR: 通过在大、小LLM间进行注意力映射，IAM框架显著加速预填充并减少KV缓存使用，同时保持性能，并具有通用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理优化方法主要利用模型内部稀疏性，而未利用外部信息，导致长上下文场景下资源消耗巨大。本文发现不同规模LLM的注意力矩阵高度相似，为优化提供了新颖视角。

Method: 提出IAM（Attention Mapping）框架。首先，深入分析如何衡量注意力相似性、选择映射层以及确保映射一致性。基于这些洞察，IAM通过在小型和大型LLM之间执行注意力映射，实现注意力计算加速和KV缓存使用减少的双重效益。

Result: 实验结果显示，IAM可将预填充（prefill）加速15%，KV缓存使用量减少22.1%，而性能牺牲可忽略不计。在不同系列模型上的实验证明了IAM的通用性。

Conclusion: IAM方法与许多现有KV缓存优化方法正交，使其成为增强LLM效率工具包的多功能补充，具有广泛的应用潜力。

Abstract: LLMs encounter significant challenges in resource consumption nowadays,
especially with long contexts. Despite extensive efforts dedicate to enhancing
inference efficiency, these methods primarily exploit internal sparsity within
the models, without leveraging external information for optimization. We
identify the high similarity of attention matrices across different-scale LLMs,
which offers a novel perspective for optimization. We first conduct a
comprehensive analysis of how to measure similarity, how to select mapping
Layers and whether mapping is consistency. Based on these insights, we
introduce the IAM framework, which achieves dual benefits of accelerated
attention computation and reduced KV cache usage by performing attention
mapping between small and large LLMs. Our experimental results demonstrate that
IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without
appreciably sacrificing performance. Experiments on different series of models
show the generalizability of IAM. Importantly, it is also orthogonal to many
existing KV cache optimization methods, making it a versatile addition to the
current toolkit for enhancing LLM efficiency.

</details>


### [21] [The benefits of query-based KGQA systems for complex and temporal questions in LLM era](https://arxiv.org/abs/2507.11954)
*Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 本文提出一种多阶段查询式知识图谱问答（KGQA）框架，并结合CoT推理，旨在解决大型语言模型在多跳推理和时间问题上的不足，提高小型语言模型在此类任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在问答任务中表现出色，但它们在处理多跳推理和时间相关问题时仍面临挑战。查询式知识图谱问答提供了一种潜在的模块化替代方案。

Method: 研究探索了一种针对WikiData问答的多阶段查询式框架，提出多阶段方法以提升其在多跳和时间基准测试上的性能。通过泛化和拒绝研究评估其鲁棒性。此外，引入了一种利用CoT（Chain-of-Thought）推理的新型实体链接和谓词匹配方法。

Result: 研究结果表明，所提出的查询式多阶段知识图谱问答框架有潜力使用小型语言模型改进多跳和时间问答任务。

Conclusion: 查询式多阶段知识图谱问答框架，结合CoT推理，为提升多跳和时间问答的性能提供了有效途径，尤其在小型语言模型环境下展现出巨大潜力。

Abstract: Large language models excel in question-answering (QA) yet still struggle
with multi-hop reasoning and temporal questions. Query-based knowledge graph QA
(KGQA) offers a modular alternative by generating executable queries instead of
direct answers. We explore multi-stage query-based framework for WikiData QA,
proposing multi-stage approach that enhances performance on challenging
multi-hop and temporal benchmarks. Through generalization and rejection
studies, we evaluate robustness across multi-hop and temporal QA datasets.
Additionally, we introduce a novel entity linking and predicate matching method
using CoT reasoning. Our results demonstrate the potential of query-based
multi-stage KGQA framework for improving multi-hop and temporal QA with small
language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System

</details>


### [22] [PoTPTQ: A Two-step Power-of-Two Post-training for LLMs](https://arxiv.org/abs/2507.11959)
*Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui*

Main category: cs.CL

TL;DR: 本文提出一种针对大型语言模型（LLM）权重的创新幂次量化（PoT）框架，该框架在极低精度下超越了现有精度，并通过更高效的反量化实现了更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因计算资源需求巨大而部署困难。现有PoT量化方法在CPU上有效，但在GPU上表现不佳，原因是符号位纠缠和反量化所需的顺序位操作。

Method: 本文提出一种新型PoT量化框架，并通过两步式训练后算法来保持量化模型的精度：首先，用稳健的起点初始化量化尺度；其次，使用最小校准集对这些尺度进行微调。

Result: 该PoT训练后算法在2位和3位等低精度格式下，精度超越了当前整数量化领域的最新水平。与统一整数反量化相比，在NVIDIA V100上实现了3.67倍的速度提升，在NVIDIA RTX 4090上实现了1.63倍的速度提升。

Conclusion: 所提出的PoT量化框架有效解决了LLM部署中的计算资源瓶颈，通过提高低精度准确性和显著加速反量化过程，实现了在不牺牲性能的前提下更高效的推理。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing (NLP) tasks. However, their deployment is
challenging due to the substantial computational resources required.
Power-of-two (PoT) quantization is a general tool to counteract this
difficulty. Albeit previous works on PoT quantization can be efficiently
dequantized on CPUs using fixed-point addition, it showed less effectiveness on
GPUs. The reason is entanglement of the sign bit and sequential bit
manipulations needed for dequantization. We propose a novel POT quantization
framework for LLM weights that (i) outperforms state-of-the-art accuracy in
extremely low-precision number formats, and (ii) enables faster inference
through more efficient dequantization. To maintain the accuracy of the
quantized model, we introduce a two-step post-training algorithm: (i)
initialize the quantization scales with a robust starting point, and (ii)
refine these scales using a minimal calibration set. The performance of our PoT
post-training algorithm surpasses the current state-of-the-art in integer
quantization, particularly at low precisions such as 2- and 3-bit formats. Our
PoT quantization accelerates the dequantization step required for the floating
point inference and leads to $3.67\times$ speed up on a NVIDIA V100, and
$1.63\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.

</details>


### [23] [Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation](https://arxiv.org/abs/2507.11966)
*Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 本文提出一个两阶段框架，用于在低资源语言中进行毒性保留翻译，通过人工验证的提示工程和模型优化，解决了标准系统在处理俚语和混合语时的不足，并在新加坡式英语语料库上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着在线交流中欠代表性语言和口语方言的增多，标准翻译系统难以保留本地俚语、语码混合及文化嵌入的有害言论。在低资源语言对之间翻译有害内容，因缺乏平行数据和安全过滤器净化作用而面临额外挑战。

Method: 本文提出一个可复现的两阶段毒性保留翻译框架。首先，进行人工验证的小样本提示工程，迭代策划和排序标注者选择的示例，以捕获细微的俚语、语气和毒性。其次，通过直接和回译的语义相似性，基准测试多个大型语言模型以优化模型-提示对。

Result: 定量的人工评估证实了所提流水线的有效性和效率。该框架不仅提高了翻译质量，还通过支持低资源语境中的文化敏感审核和基准测试，有助于多文化大型语言模型的安全性。

Conclusion: 该框架有效解决了低资源语言中有害内容的翻译挑战，提升了翻译质量，并为多文化LLM的安全性做出了贡献。它强调了在内容审核和平台治理等实际应用中保留社会语言学细微差别的必要性。

Abstract: As online communication increasingly incorporates under-represented languages
and colloquial dialects, standard translation systems often fail to preserve
local slang, code-mixing, and culturally embedded markers of harmful speech.
Translating toxic content between low-resource language pairs poses additional
challenges due to scarce parallel data and safety filters that sanitize
offensive expressions. In this work, we propose a reproducible, two-stage
framework for toxicity-preserving translation, demonstrated on a code-mixed
Singlish safety corpus. First, we perform human-verified few-shot prompt
engineering: we iteratively curate and rank annotator-selected Singlish-target
examples to capture nuanced slang, tone, and toxicity. Second, we optimize
model-prompt pairs by benchmarking several large language models using semantic
similarity via direct and back-translation. Quantitative human evaluation
confirms the effectiveness and efficiency of our pipeline. Beyond improving
translation quality, our framework contributes to the safety of multicultural
LLMs by supporting culturally sensitive moderation and benchmarking in
low-resource contexts. By positioning Singlish as a testbed for inclusive NLP,
we underscore the importance of preserving sociolinguistic nuance in real-world
applications such as content moderation and regional platform governance.

</details>


### [24] [Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker](https://arxiv.org/abs/2507.11972)
*Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.CL

TL;DR: 本研究通过构建图结构文本表示并分析眼动数据，探究LLM与人类在阅读理解上的差异，发现LLM在图拓扑结构层面具有高度一致的语言理解能力，为人机协同学习提供见解。


<details>
  <summary>Details</summary>
Motivation: 先前研究在词层面分析人类与LLM阅读理解时存在局限性，导致理解深度不足和结论过于简化。因此，需要一种更深层次的文本表示方法来比较人类和LLM的语言理解。

Method: 本研究使用基于LLM的AI智能体，将阅读文本中的词语分组为节点和边，构建出基于语义和问题导向提示的图结构文本表示。随后，通过比较人类在重要节点和边上的眼动注视分布来分析其理解过程。

Result: 研究发现LLM在图拓扑结构层面的语言理解表现出高度一致性。

Conclusion: 这些发现拓展了之前的研究成果，并为人机协同学习策略提供了有价值的见解。

Abstract: Reading comprehension is a fundamental skill in human cognitive development.
With the advancement of Large Language Models (LLMs), there is a growing need
to compare how humans and LLMs understand language across different contexts
and apply this understanding to functional tasks such as inference, emotion
interpretation, and information retrieval. Our previous work used LLMs and
human biomarkers to study the reading comprehension process. The results showed
that the biomarkers corresponding to words with high and low relevance to the
inference target, as labeled by the LLMs, exhibited distinct patterns,
particularly when validated using eye-tracking data. However, focusing solely
on individual words limited the depth of understanding, which made the
conclusions somewhat simplistic despite their potential significance. This
study used an LLM-based AI agent to group words from a reading passage into
nodes and edges, forming a graph-based text representation based on semantic
meaning and question-oriented prompts. We then compare the distribution of eye
fixations on important nodes and edges. Our findings indicate that LLMs exhibit
high consistency in language understanding at the level of graph topological
structure. These results build on our previous findings and offer insights into
effective human-AI co-learning strategies.

</details>


### [25] [Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](https://arxiv.org/abs/2507.11979)
*Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro*

Main category: cs.CL

TL;DR: 本研究探究了大型语言模型（LLM）智能体之间价值观相似性对关系建立的影响。结果显示，价值观相似度越高的智能体对彼此的信任和人际亲密度也更高，表明LLM智能体模拟可作为社会科学理论的有效实验平台。


<details>
  <summary>Details</summary>
Motivation: LLM已成为模拟复杂社会现象的强大工具。在人类社会中，价值观相似性对建立信任和亲密关系至关重要，但这一原则是否适用于LLM智能体组成的人工社会尚待探索。因此，本研究旨在调查价值观相似性对LLM智能体间关系建立的影响。

Method: 研究通过两项实验进行：1) 初步实验评估LLM中价值观的可控性，以确定最有效的模型和提示设计；2) 主要实验生成具有特定价值观的LLM智能体对，并在对话后分析它们对信任和人际亲密度的相互评价。实验同时以英语和日语进行，以探究语言依赖性。

Result: 实验结果证实，价值观相似度较高的智能体对表现出更高的相互信任和人际亲密度。这一结果在英语和日语实验中均得到验证。

Conclusion: 本研究结果表明，LLM智能体模拟是社会科学理论的有效实验平台，有助于阐明价值观影响关系建立的机制，并为激发社会科学新理论和见解提供了基础。

Abstract: Large language models (LLMs) have emerged as powerful tools for simulating
complex social phenomena using human-like agents with specific traits. In human
societies, value similarity is important for building trust and close
relationships; however, it remains unexplored whether this principle holds true
in artificial societies comprising LLM agents. Therefore, this study
investigates the influence of value similarity on relationship-building among
LLM agents through two experiments. First, in a preliminary experiment, we
evaluated the controllability of values in LLMs to identify the most effective
model and prompt design for controlling the values. Subsequently, in the main
experiment, we generated pairs of LLM agents imbued with specific values and
analyzed their mutual evaluations of trust and interpersonal closeness
following a dialogue. The experiments were conducted in English and Japanese to
investigate language dependence. The results confirmed that pairs of agents
with higher value similarity exhibited greater mutual trust and interpersonal
closeness. Our findings demonstrate that the LLM agent simulation serves as a
valid testbed for social science theories, contributes to elucidating the
mechanisms by which values influence relationship building, and provides a
foundation for inspiring new theories and insights into the social sciences.

</details>


### [26] [Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions](https://arxiv.org/abs/2507.11981)
*Lukas Ellinger,Miriam Anschütz,Georg Groh*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在为不同用户群体简化同音词定义时，易过度简化导致信息缺失和误解；通过DPO微调可显著提升其定义质量，强调教育NLP中平衡简洁与完整性的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在为不同目标群体提供词语定义时需进行简化。然而，对于多义同音词，过度简化可能导致关键语义缺失，从而误导用户。本研究旨在探究这种简化对同音词定义质量的影响。

Method: 构建了两个多语言新型评估数据集，用于测试DeepSeek v3、Llama 4 Maverick、Qwen3-30B A3B、GPT-4o mini和Llama 3.1 8B等LLM在“普通”、“简单”和“ELI5”三种目标群体下的表现。评估采用“LLM作为评判者”和人工标注。同时，使用直接偏好优化（DPO）对Llama 3.1 8B进行了微调。

Result: 结果显示，简化显著降低了定义内容的完整性，忽视了词语的多义性，增加了用户误解的风险。通过直接偏好优化（DPO）微调Llama 3.1 8B后，其在所有提示类型下的同音词响应质量均得到显著改善。

Conclusion: 研究强调在教育性自然语言处理（NLP）中，必须平衡定义的简洁性与完整性，以确保为所有学习者提供可靠且上下文感知的定义。

Abstract: Large Language Models (LLMs) can provide accurate word definitions and
explanations for any context. However, the scope of the definition changes for
different target groups, like children or language learners. This is especially
relevant for homonyms, words with multiple meanings, where oversimplification
might risk information loss by omitting key senses, potentially misleading
users who trust LLM outputs. We investigate how simplification impacts homonym
definition quality across three target groups: Normal, Simple, and ELI5. Using
two novel evaluation datasets spanning multiple languages, we test DeepSeek v3,
Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge
and human annotations. Our results show that simplification drastically
degrades definition completeness by neglecting polysemy, increasing the risk of
misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization
substantially improves homonym response quality across all prompt types. These
findings highlight the need to balance simplicity and completeness in
educational NLP to ensure reliable, context-aware definitions for all learners.

</details>


### [27] [Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis](https://arxiv.org/abs/2507.12004)
*Josip Jukić*

Main category: cs.CL

TL;DR: 本论文通过表示分析和新型优化技术，提升了神经语言模型的数据和参数效率、鲁棒性及泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决神经语言模型在数据和参数效率方面面临的挑战。

Method: 1. 引入基于表示平滑度的正则化策略，利用雅可比和海森矩阵来稳定训练并增强模型鲁棒性。2. 将主动学习与参数高效微调相结合，并提出基于平滑度的早停技术，以提高数据和参数效率。3. 探索通过上下文学习增强的弱监督技术，有效利用无标签数据。

Result: 1. 提升了模型的鲁棒性、泛化能力，稳定了训练并降低了对输入扰动的敏感性。2. 在多种NLP任务中，所提出的组合方法在性能、稳定性和效率方面显著优于传统方法，并有效减少了标注和计算资源。3. 显著提高了模型在准确性、适应性和鲁棒性方面的表现，尤其在低资源和动态数据环境中。

Conclusion: 本论文提出的创新优化技术有效解决了神经语言模型的数据和参数效率问题，显著提升了模型在性能、稳定性、鲁棒性和泛化能力方面的表现，尤其适用于资源受限或动态数据环境。

Abstract: This thesis addresses challenges related to data and parameter efficiency in
neural language models, with a focus on representation analysis and the
introduction of new optimization techniques. The first part examines the
properties and dynamics of language representations within neural models,
emphasizing their significance in enhancing robustness and generalization. It
proposes innovative approaches based on representation smoothness, including
regularization strategies that utilize Jacobian and Hessian matrices to
stabilize training and mitigate sensitivity to input perturbations. The second
part focuses on methods to significantly enhance data and parameter efficiency
by integrating active learning strategies with parameter-efficient fine-tuning,
guided by insights from representation smoothness analysis. It presents
smoothness-informed early-stopping techniques designed to eliminate the need
for labeled validation sets and proposes innovative combinations of active
learning and parameter-efficient fine-tuning to reduce labeling efforts and
computational resources. Extensive experimental evaluations across various NLP
tasks demonstrate that these combined approaches substantially outperform
traditional methods in terms of performance, stability, and efficiency. The
third part explores weak supervision techniques enhanced by in-context learning
to effectively utilize unlabeled data, further reducing dependence on extensive
labeling. It shows that using in-context learning as a mechanism for weak
supervision enables models to better generalize from limited labeled data by
leveraging unlabeled examples more effectively during training. Comprehensive
empirical evaluations confirm significant gains in model accuracy,
adaptability, and robustness, especially in low-resource settings and dynamic
data environments.

</details>


### [28] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
*Anca Dinu,Andra-Maria Florescu,Alina Resceanu*

Main category: cs.CL

TL;DR: 本研究设计了一种语言创造力测试，旨在评估人类和LLMs生成原创词语和运用比喻的能力。结果显示，LLMs在多数评估指标和任务中超越人类，但在创造力类型上存在差异。


<details>
  <summary>Details</summary>
Motivation: 评估和比较人类与大型语言模型（LLMs）的语言创造力，特别是它们在词语形成和比喻性语言使用方面的能力。

Method: 设计了一个包含词语构成（派生和复合）和比喻性语言使用任务的通用语言创造力测试。该测试应用于24名人类和24个LLMs。答案使用OCSAI工具根据独创性、精细度和灵活性三个标准进行自动评估。此外，还计算了答案的独特性，并进行了简短的手动分析。

Result: LLMs在所有评估标准上均优于人类，并在八项测试任务中的六项表现更佳。在答案独特性方面，人类和LLMs之间存在细微差异。手动分析显示，人类更倾向于E型（扩展型）创造力，而LLMs则偏好F型（固定型）创造力。

Conclusion: LLMs在语言创造力测试的量化表现上普遍优于人类，但在创造力类型上存在显著差异，人类更倾向于扩展性创造，而LLMs更偏向固定性创造。

Abstract: The following paper introduces a general linguistic creativity test for
humans and Large Language Models (LLMs). The test consists of various tasks
aimed at assessing their ability to generate new original words and phrases
based on word formation processes (derivation and compounding) and on
metaphorical language use. We administered the test to 24 humans and to an
equal number of LLMs, and we automatically evaluated their answers using OCSAI
tool for three criteria: Originality, Elaboration, and Flexibility. The results
show that LLMs not only outperformed humans in all the assessed criteria, but
did better in six out of the eight test tasks. We then computed the uniqueness
of the individual answers, which showed some minor differences between humans
and LLMs. Finally, we performed a short manual analysis of the dataset, which
revealed that humans are more inclined towards E(extending)-creativity, while
LLMs favor F(ixed)-creativity.

</details>


### [29] [Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](https://arxiv.org/abs/2507.12059)
*Anthony G Cohn,Robert E Blackwell*

Main category: cs.CL

TL;DR: 本文评估了28个大型语言模型在推断基本方向方面的能力，发现即使是新型推理模型也无法可靠地解决所有方向推理问题。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在给定特定场景下推断基本方向（Cardinal Directions, CDs）的能力。

Method: 构建了一个包含多种变体（如移动方式和人称视角）的模板化基准测试集，并使用该基准对28个LLMs（包括新型推理模型）进行了广泛测试。

Result: 即使是较新的大型推理模型也无法可靠地确定所有问题的正确基本方向。

Conclusion: 本研究总结并扩展了先前的研究工作，指出当前LLMs在基本方向推理方面仍存在局限性。

Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason
about cardinal directions (CDs) using a benchmark generated from a set of
templates, extensively testing an LLM's ability to determine the correct CD
given a particular scenario. The templates allow for a number of degrees of
variation such as means of locomotion of the agent involved, and whether set in
the first, second or third person. Even the newer Large Reasoning Models are
unable to reliably determine the correct CD for all questions. This paper
summarises and extends earlier work presented at COSIT-24.

</details>


### [30] [StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features](https://arxiv.org/abs/2507.12064)
*Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak*

Main category: cs.CL

TL;DR: 该论文提出了一种基于模块化文体学管道的二元AI文本检测方法，利用spaCy进行文本预处理和数千个语言学特征提取，并采用LightGBM作为分类器，训练于包含50万以上机器生成文本的大型语料库，该方法追求非神经网络、计算开销低且可解释的路线。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种有效、可解释、计算开销低的二元AI生成文本检测系统，并借鉴了以往被证明有效的方法。

Method: 1. **管道设计**: 采用模块化文体学管道。 2. **预处理与特征提取**: 使用公共spaCy模型进行文本预处理（包括分词、命名实体识别、依存句法分析、词性标注和形态学标注），并从中提取数千个语言学标注N-gram频率特征。 3. **分类器**: 采用轻量级梯度提升机（Light-gradient boosting machines）。 4. **训练数据**: 收集了超过50万条机器生成文本用于分类器训练。 5. **优化**: 探索多种参数选项以提升分类器能力。

Result: 抽象内容中未提供具体的实验结果或性能指标。

Conclusion: 该研究主要描述了其在二元AI文本检测任务中采用的非神经网络、计算开销低且可解释的方法，旨在利用大规模训练集提升分类器性能，但未给出具体的实验结论。

Abstract: This submission to the binary AI detection task is based on a modular
stylometric pipeline, where: public spaCy models are used for text
preprocessing (including tokenisation, named entity recognition, dependency
parsing, part-of-speech tagging, and morphology annotation) and extracting
several thousand features (frequencies of n-grams of the above linguistic
annotations); light-gradient boosting machines are used as the classifier. We
collect a large corpus of more than 500 000 machine-generated texts for the
classifier's training. We explore several parameter options to increase the
classifier's capacity and take advantage of that training set. Our approach
follows the non-neural, computationally inexpensive but explainable approach
found effective previously.

</details>


### [31] [BOOKCOREF: Coreference Resolution at Book Scale](https://arxiv.org/abs/2507.12075)
*Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli*

Main category: cs.CL

TL;DR: 提出一种自动标注流水线并创建BOOKCOREF，这是首个书本规模指代消解基准，用于评估长文本指代消解系统，并揭示了现有模型面临的新挑战。


<details>
  <summary>Details</summary>
Motivation: 现有指代消解系统评估基准主要针对中小规模文档，在评估书本规模（数十万词元）的长文本时存在长度限制，无法充分评估系统能力。

Method: 开发了一种新颖的自动流水线，用于对完整叙事文本生成高质量的指代消解标注。利用该流水线创建了BOOKCOREF，这是第一个平均文档长度超过20万词元的书本规模指代消解基准。通过一系列实验验证了自动程序的鲁棒性及资源的价值。

Result: 自动标注程序表现出鲁棒性。BOOKCOREF资源具有很高价值，能使现有长文档指代消解系统在对完整书籍进行评估时，CoNLL-F1得分提升高达20点。同时，书本规模设置也带来了新的挑战，现有模型未能达到其在小文档上所实现的性能。

Conclusion: 该研究通过创建BOOKCOREF，填补了长文本指代消解评估的空白。新基准不仅验证了现有长文本指代消解系统的评估价值，也揭示了书本规模设置下的新挑战。论文发布了数据和代码以鼓励相关研究与开发。

Abstract: Coreference Resolution systems are typically evaluated on benchmarks
containing small- to medium-scale documents. When it comes to evaluating long
texts, however, existing benchmarks, such as LitBank, remain limited in length
and do not adequately assess system capabilities at the book scale, i.e., when
co-referring mentions span hundreds of thousands of tokens. To fill this gap,
we first put forward a novel automatic pipeline that produces high-quality
Coreference Resolution annotations on full narrative texts. Then, we adopt this
pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with
an average document length of more than 200,000 tokens. We carry out a series
of experiments showing the robustness of our automatic procedure and
demonstrating the value of our resource, which enables current long-document
coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full
books. Moreover, we report on the new challenges introduced by this
unprecedented book-scale setting, highlighting that current models fail to
deliver the same performance they achieve on smaller documents. We release our
data and code to encourage research and development of new book-scale
Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.

</details>


### [32] [Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning](https://arxiv.org/abs/2507.12079)
*Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed*

Main category: cs.CL

TL;DR: 本研究提出了一种名为MEGA的数学学习干预方法，结合LLM、苏格拉底法、思维链、游戏化和形成性反馈，结果显示其比传统思维链方法更能有效提升大学生数学学习体验，尤其是在解决难题方面。


<details>
  <summary>Details</summary>
Motivation: 许多学生在数学学习中遇到困难并因此逃避相关学科，尽管数学在多领域至关重要；这些困难常源于不理想的教学方法，因此需要探索结合大型语言模型（LLMs）的更优教学方案。

Method: 研究采用名为MEGA（Mathematics Explanations through Games by AI LLMs）的方法，其结合了苏格拉底法、思维链（CoT）推理、简化游戏化和形成性反馈。通过组内设计，将MEGA方法与传统逐步（CoT）方法进行比较。参与者为大学生，样本（n=60）随机抽取自GSM8K和MATH数据集，并使用GPT4o和Claude 3.5 Sonnet两种LLM进行评估。评估标准是学生对两种方法学习效果的认同度。

Result: 结果显示，学生在更多情况下认为MEGA方法在两个数据集中都更利于学习。在难度更高的MATH数据集中，MEGA方法的学习效果认同度（47.5%）远超CoT方法（26.67%），表明MEGA在解释复杂数学问题上更具优势。

Conclusion: 结合LLMs的MEGA方法（融合苏格拉底法、思维链、游戏化和反馈）能显著提升大学生的数学学习体验，尤其在处理复杂数学问题时，其效果优于传统的思维链方法。

Abstract: This paper presents an intervention study on the effects of the combined
methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)
simplified gamification and (4) formative feedback on university students'
Maths learning driven by large language models (LLMs). We call our approach
Mathematics Explanations through Games by AI LLMs (MEGA). Some students
struggle with Maths and as a result avoid Math-related discipline or subjects
despite the importance of Maths across many fields, including signal
processing. Oftentimes, students' Maths difficulties stem from suboptimal
pedagogy. We compared the MEGA method to the traditional step-by-step (CoT)
method to ascertain which is better by using a within-group design after
randomly assigning questions for the participants, who are university students.
Samples (n=60) were randomly drawn from each of the two test sets of the Grade
School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)
datasets, based on the error margin of 11%, the confidence level of 90%, and a
manageable number of samples for the student evaluators. These samples were
used to evaluate two capable LLMs at length (Generative Pretrained Transformer
4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for
capability. The results showed that students agree in more instances that the
MEGA method is experienced as better for learning for both datasets. It is even
much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH
dataset, indicating that MEGA is better at explaining difficult Maths problems.

</details>


### [33] [Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis](https://arxiv.org/abs/2507.12126)
*Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta*

Main category: cs.CL

TL;DR: 本文提出了一个评估LLM文本增强有效性的框架，着重于语义保持和漂移。研究发现GPT-3.5 Turbo表现优异，并在实际主题建模任务中显著提升了主题粒度和消除了重叠。


<details>
  <summary>Details</summary>
Motivation: 现有文本数据增强技术在语义保持方面存在不足，导致大规模或迭代生成时出现冗余和不稳定，尤其在资源匮乏的NLP场景中，急需一个原则性的评估框架来解决这些问题。

Method: 引入了一个用于LLM文本增强的原生评估框架，包含两个组件：1) 可扩展性分析，用于衡量增强量增加时的语义一致性；2) 带有摘要细化的迭代增强 (IASR)，用于评估递归复述周期中的语义漂移。通过对主流LLM进行实证评估，并将其应用于实际的主题建模任务。

Result: 经验评估显示，GPT-3.5 Turbo在语义保真度、多样性和生成效率之间实现了最佳平衡。在应用于实际主题建模任务时，所提出的方法使主题粒度提高了400%，并完全消除了主题重叠。

Conclusion: 研究结果验证了所提出的框架对于在实际NLP流程中结构化评估基于LLM的文本增强的实用性。

Abstract: Text data augmentation is a widely used strategy for mitigating data sparsity
in natural language processing (NLP), particularly in low-resource settings
where limited samples hinder effective semantic modeling. While augmentation
can improve input diversity and downstream interpretability, existing
techniques often lack mechanisms to ensure semantic preservation during
large-scale or iterative generation, leading to redundancy and instability.
This work introduces a principled evaluation framework for large language model
(LLM) based text augmentation, comprising two components: (1) Scalability
Analysis, which measures semantic consistency as augmentation volume increases,
and (2) Iterative Augmentation with Summarization Refinement (IASR), which
evaluates semantic drift across recursive paraphrasing cycles. Empirical
evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the
best balance of semantic fidelity, diversity, and generation efficiency.
Applied to a real-world topic modeling task using BERTopic with GPT-enhanced
few-shot labeling, the proposed approach results in a 400% increase in topic
granularity and complete elimination of topic overlaps. These findings
validated the utility of the proposed frameworks for structured evaluation of
LLM-based augmentation in practical NLP pipelines.

</details>


### [34] [Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators](https://arxiv.org/abs/2507.12143)
*Pavel Šindelář,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文介绍了2025年Sensemaking共享任务，该任务是ELOQUENT的一部分，旨在通过模拟课堂考试（提问、回答、评估）来评估生成式语言模型的理解能力。报告了任务设置、参与情况和发现，包括问题生成评估的困难、LLM在限制文本范围内的回答问题、以及LLM作为裁判的评估缺陷。


<details>
  <summary>Details</summary>
Motivation: 旨在为评估生成式语言模型提供易于测试的高级标准，特别是评估其“理解给定文本并从中提取意义”（Sensemaking）的能力。

Method: 组织了2025年Sensemaking共享任务，该任务模拟课堂考试，分为教师系统（提问）、学生系统（回答）和评估系统（评分）三个步骤。使用了涵盖英、德、乌克兰、捷克四种语言的7种不同类型测试材料。共收到4支队伍的提交，并引入了商业大型语言模型作为教师和学生任务的基线。采用全自动评估程序，并与少量人工评估进行对比。通过对抗性测试来评估评估系统。

Result: 在问题生成任务中，难以区分不同候选问题集的质量，需要更好的评估策略。在问答任务中，大型语言模型整体表现尚可，但将其回答严格限制在给定输入文本范围内仍是难题。在答案评估任务中，对抗性测试显示使用“LLM作为裁判”范式的系统会错误地将混乱的问题-答案对以及回答错误问题的答案评为可接受。

Conclusion: Sensemaking任务揭示了当前生成式大型语言模型在文本理解和生成方面的能力与局限性。尽管模型在回答问题方面表现尚可，但在严格限制回答内容以及评估（特别是问题生成和LLM作为裁判的鲁棒性）方面仍存在显著挑战。

Abstract: ELOQUENT is a set of shared tasks that aims to create easily testable
high-level criteria for evaluating generative language models. Sensemaking is
one such shared task.
  In Sensemaking, we try to assess how well generative models ``make sense out
of a given text'' in three steps inspired by exams in a classroom setting: (1)
Teacher systems should prepare a set of questions, (2) Student systems should
answer these questions, and (3) Evaluator systems should score these answers,
all adhering rather strictly to a given set of input materials.
  We report on the 2025 edition of Sensemaking, where we had 7 sources of test
materials (fact-checking analyses of statements, textbooks, transcribed
recordings of a lecture, and educational videos) spanning English, German,
Ukrainian, and Czech languages.
  This year, 4 teams participated, providing us with 2 Teacher submissions, 2
Student submissions, and 2 Evaluator submissions. We added baselines for
Teacher and Student using commercial large language model systems. We devised a
fully automatic evaluation procedure, which we compare to a minimalistic manual
evaluation.
  We were able to make some interesting observations. For the first task, the
creation of questions, better evaluation strategies will still have to be
devised because it is difficult to discern the quality of the various candidate
question sets. In the second task, question answering, the LLMs examined
overall perform acceptably, but restricting their answers to the given input
texts remains problematic. In the third task, evaluation of question answers,
our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm
erroneously rate both garbled question-answer pairs and answers to mixed-up
questions as acceptable.

</details>


### [35] [Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production](https://arxiv.org/abs/2507.12208)
*Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren*

Main category: cs.CL

TL;DR: 该论文提出了一种行为翻译风格空间 (BTSS)，通过分析按键和注视数据等可观察行为，来描述并理解翻译过程中隐藏的认知和情感过程。BTSS被组织成多层级结构，旨在为计算翻译代理提供模拟人类翻译动态的基础。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解和描述翻译过程中可能出现的行为模式，特别是探讨可观察的翻译行为（如眼动和手指移动）如何由更高阶的认知过程和情感翻译状态所引发和塑造。

Method: 研究方法是分析击键记录和凝视数据，将这些数据作为隐藏心理处理结构的指标。通过对这些行为模式的分析，构建并组织了一个多层嵌入式的行为翻译风格空间（BTSS）。

Result: 研究结果是构建了一个分层、多层嵌入式的行为翻译风格空间（BTSS），它能够描述可能的行为翻译模式，并揭示其背后的认知和情感驱动因素。

Conclusion: 该行为翻译风格空间（BTSS）可以作为计算翻译代理的基础，用于模拟人类翻译生产过程中情感、自动化行为和认知的时序动态。

Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that
describes possible behavioural translation patterns. The suggested BTSS is
organized as a hierarchical structure that entails various embedded processing
layers. We posit that observable translation behaviour - i.e., eye and finger
movements - is fundamental when executing the physical act of translation but
it is caused and shaped by higher-order cognitive processes and affective
translation states. We analyse records of keystrokes and gaze data as
indicators of the hidden mental processing structure and organize the
behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the
basis for a computational translation agent to simulate the temporal dynamics
of affect, automatized behaviour and cognition during human translation
production.

</details>


### [36] [Towards few-shot isolated word reading assessment](https://arxiv.org/abs/2507.12217)
*Reuben Smit,Retief Louw,Herman Kamper*

Main category: cs.CL

TL;DR: 研究提出一种无ASR的少样本方法，利用SSL模型特征进行低资源环境下孤立词阅读评估，但发现其在处理儿童语音时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 在低资源环境下，探索一种无需自动语音识别（ASR）的孤立词阅读评估方法。

Method: 采用少样本（few-shot）分类方法，将儿童语音与少量成人提供的参考模板进行比较。输入和模板均使用大型自监督学习（SSL）模型的中间层进行编码。研究还探讨了SSL特征离散化和模板重心平均等设计方案，并在南非荷兰语儿童语音基准上进行评估。

Result: 理想化实验显示，对于成人语音输入表现良好，但对于儿童语音输入（即使使用儿童模板）性能大幅下降。

Conclusion: 尽管SSL表征在低资源语音任务中取得成功，但本研究揭示了在少样本分类系统中处理儿童语音数据时，SSL表征的局限性。

Abstract: We explore an ASR-free method for isolated word reading assessment in
low-resource settings. Our few-shot approach compares input child speech to a
small set of adult-provided reference templates. Inputs and templates are
encoded using intermediate layers from large self-supervised learned (SSL)
models. Using an Afrikaans child speech benchmark, we investigate design
options such as discretising SSL features and barycentre averaging of the
templates. Idealised experiments show reasonable performance for adults, but a
substantial drop for child speech input, even with child templates. Despite the
success of employing SSL representations in low-resource speech tasks, our work
highlights the limitations of SSL representations for processing child data
when used in a few-shot classification system.

</details>


### [37] [Improving Contextual ASR via Multi-grained Fusion with Large Language Models](https://arxiv.org/abs/2507.12252)
*Shilin Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: ASR在关键词识别方面存在不足。本文提出一种新的多粒度融合方法，结合LLM，同时利用词元级和短语级融合来提高关键词识别精度，并在中英文数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端ASR模型在通用语音转录方面表现出色，但在准确识别上下文相关的关键词（如专有名词或用户特定实体）时常遇到困难。现有利用关键词词典的方法（词元级或短语级融合）各有局限性。

Method: 提出一种新颖的多粒度融合方法，结合大型语言模型（LLM），共同利用词元级融合和短语级融合的优点。该方法采用一种晚期融合策略，巧妙地将ASR的声学信息与LLM的丰富上下文知识相结合。

Result: 在中文和英文数据集上的实验表明，该方法在关键词相关指标上取得了最先进的性能，同时保持了非关键词文本的高准确性。消融研究进一步证实，词元级和短语级组件都对性能提升做出了显著贡献，并在提出的联合多粒度框架中相互补充。

Conclusion: 本文提出的多粒度融合方法有效解决了ASR在关键词识别上的不足，通过结合LLM、词元级和短语级融合，实现了卓越的关键词识别性能，同时保持了对非关键词文本的高精度。

Abstract: While end-to-end Automatic Speech Recognition (ASR) models have shown
impressive performance in transcribing general speech, they often struggle to
accurately recognize contextually relevant keywords, such as proper nouns or
user-specific entities.
  Previous approaches have explored leveraging keyword dictionaries in the
textual modality to improve keyword recognition, either through token-level
fusion that guides token-by-token generation or phrase-level fusion that
enables direct copying of keyword phrases.
  However, these methods operate at different granularities and have their own
limitations.
  In this paper, we propose a novel multi-grained fusion approach that jointly
leverages the strengths of both token-level and phrase-level fusion with Large
Language Models (LLMs).
  Our approach incorporates a late-fusion strategy that elegantly combines
ASR's acoustic information with LLM's rich contextual knowledge, balancing
fine-grained token precision with holistic phrase-level understanding.
  Experiments on Chinese and English datasets demonstrate that our approach
achieves state-of-the-art performance on keyword-related metrics while
preserving high accuracy on non-keyword text.
  Ablation studies further confirm that the token-level and phrase-level
components both contribute significantly to the performance gains,
complementing each other in our joint multi-grained framework.
  The code and models will be publicly available at https://github.com/.

</details>


### [38] [Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese](https://arxiv.org/abs/2507.12260)
*Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu*

Main category: cs.CL

TL;DR: 本文提出并验证了首个量化翻译腔的指标T-index，其基于对比微调语言模型的似然比，能有效捕捉翻译腔并与人类判断高度相关，且可作为机器翻译质量评估的补充指标。


<details>
  <summary>Details</summary>
Motivation: 缺乏对翻译腔进行量化、分级和通用测量的有效指标。

Method: 提出T-index，通过两个对比微调语言模型的似然比计算。使用合成数据集和真实翻译数据集评估T-index的跨领域泛化能力及其与人类判断的有效性。

Result: T-index具有鲁棒性和高效性，即使使用少量数据训练的语言模型也能有效捕捉真实翻译腔。T-index的相对差异能很好地预测人类的成对翻译腔标注，其绝对值与人类评分具有良好相关性（Pearson's r = 0.568）。此外，T-index与现有机器翻译质量评估指标（如BLEU和COMET）相关性低。

Conclusion: T-index是一种有效、鲁棒且高效的翻译腔量化测量方法，可作为机器翻译质量评估的补充指标，填补了现有指标的空白。

Abstract: In this paper, we propose the first quantitative measure for translationese
-- the translationese-index (T-index) for graded and generalizable measurement
of translationese, computed from the likelihood ratios of two contrastively
fine-tuned language models (LMs). We use a synthesized dataset and a dataset
with translations in the wild to evaluate T-index's generalizability in
cross-domain settings and its validity against human judgments. Our results
show that T-index is both robust and efficient. T-index scored by two 0.5B LMs
fine-tuned on only 1-5k pairs of synthetic data can well capture translationese
in the wild. We find that the relative differences in T-indices between
translations can well predict pairwise translationese annotations obtained from
human annotators; and the absolute values of T-indices correlate well with
human ratings of degrees of translationese (Pearson's $r = 0.568$).
Additionally, the correlation between T-index and existing machine translation
(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting
that T-index is not covered by these metrics and can serve as a complementary
metric in MT QE.

</details>


### [39] [Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](https://arxiv.org/abs/2507.12261)
*Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer*

Main category: cs.CL

TL;DR: 提出Infherno框架，利用LLM代理、代码执行和医疗术语工具，将自由形式临床笔记自动化转换为结构化FHIR资源，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有将自由形式临床笔记转换为结构化HL7 FHIR资源的方法（如模块化、基于规则的系统或LLM）存在泛化性有限和结构不一致的问题。

Method: 提出了一个名为Infherno的端到端框架，该框架由LLM代理、代码执行和医疗术语数据库工具驱动，旨在严格遵守FHIR文档模式。

Result: Infherno在从非结构化文本中预测FHIR资源方面与人类基线表现相当。

Conclusion: 该解决方案通过支持临床数据集成过程和跨机构互操作性，有效解决了现有方法的局限性，并实现了高水平的FHIR资源预测准确性。

Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard
has established itself as a desirable format for interoperability between
complex health data. Previous attempts at automating the translation from
free-form clinical notes into structured FHIR resources rely on modular,
rule-based systems or LLMs with instruction tuning and constrained decoding.
Since they frequently suffer from limited generalizability and structural
inconformity, we propose an end-to-end framework powered by LLM agents, code
execution, and healthcare terminology database tools to address these issues.
Our solution, called Infherno, is designed to adhere to the FHIR document
schema and competes well with a human baseline in predicting FHIR resources
from unstructured text. The implementation features a front end for custom and
synthetic data and both local and proprietary models, supporting clinical data
integration processes and interoperability across institutions.

</details>


### [40] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 本文建立了一套全面的文本异常检测基准，系统评估了不同语言模型嵌入的有效性，发现嵌入质量是关键因素，且在使用LLM嵌入时，浅层算法不逊于深度学习算法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）和异常检测算法取得了显著进展，但缺乏标准化和全面的文本异常检测评估基准，限制了现有方法的严格比较和创新方法的开发。

Method: 本研究进行了一项全面的实证研究，并引入了一个文本异常检测基准。该基准利用来自多种预训练语言模型（包括早期模型如GloVe、BERT和大型语言模型如LLaMa-2、LLama-3、Mistral、OpenAI系列）的嵌入表示，并在多领域文本数据集（新闻、社交媒体、科学出版物）上进行系统评估，使用AUROC和AUPRC等综合评估指标。同时，本工作开放了所有嵌入数据和代码。

Result: 实验结果揭示了关键的实证洞察：嵌入质量显著影响异常检测效果；在使用LLM派生的嵌入时，基于深度学习的方法相对于传统的浅层算法（如KNN、Isolation Forest）没有性能优势。此外，跨模型性能矩阵表现出强烈的低秩特性，这有助于在实际应用中高效地进行模型（或嵌入）评估和选择。

Conclusion: 本工作通过提供全面的基准和关键实证发现（即嵌入质量的重要性及浅层算法在LLM嵌入上的有效性），为未来鲁棒和可扩展的文本异常检测系统的研究奠定了基础。

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [41] [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](https://arxiv.org/abs/2507.12308)
*Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan*

Main category: cs.CL

TL;DR: 现有大型语言模型（LLMs）在硬件描述语言VHDL的代码生成和摘要任务上表现不佳。本研究提出了一种名为“描述链（CoDes）”的新方法，通过生成中间描述步骤显著提升了LLMs在这些VHDL任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在各种NLP任务和EDA领域（如RTL代码生成）中显示出潜力，但针对硬件描述语言（特别是VHDL）的LLMs评估和优化研究却非常缺乏。初步评估显示，现有LLMs在VHDL任务上表现不佳，凸显了该领域研究的巨大空白。

Method: 研究首先使用VHDL-Eval和内部数据集VHDL-Xform评估了现有代码LLMs在VHDL代码生成和摘要任务上的性能。为解决发现的性能不足，本研究提出了“描述链（CoDes）”方法。CoDes通过生成一系列中间描述步骤（针对代码生成任务基于问题陈述，针对代码摘要任务基于VHDL代码），然后将这些步骤与原始输入提示（问题陈述或代码）结合，作为LLMs的输入以生成最终输出。

Result: 研究发现，现有代码LLMs在VHDL代码生成和摘要任务上表现持续不佳，突显了它们在该领域适用性的重大不足。然而，实验证明，所提出的CoDes方法在两个数据集上，相对于标准提示策略，在各项指标上均显著超越，大幅提升了性能。

Conclusion: CoDes方法不仅有效提升了LLMs在VHDL代码生成和摘要任务上的质量，也为未来旨在增强LLMs处理VHDL代码能力的研究提供了一个有价值的框架。

Abstract: Large Language Models (LLMs) have become widely used across diverse NLP tasks
and domains, demonstrating their adaptability and effectiveness. In the realm
of Electronic Design Automation (EDA), LLMs show promise for tasks like
Register-Transfer Level (RTL) code generation and summarization. However,
despite the proliferation of LLMs for general code-related tasks, there's a
dearth of research focused on evaluating and refining these models for hardware
description languages (HDLs), notably VHDL. In this study, we evaluate the
performance of existing code LLMs for VHDL code generation and summarization
using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,
an in-house dataset, aims to gauge LLMs' understanding of functionally
equivalent code. Our findings reveal consistent underperformance of these
models across different metrics, underscoring a significant gap in their
suitability for this domain. To address this challenge, we propose
Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of
LLMs for VHDL code generation and summarization tasks. CoDes involves
generating a series of intermediate descriptive steps based on: (i) the problem
statement for code generation, and (ii) the VHDL code for summarization. These
steps are then integrated with the original input prompt (problem statement or
code) and provided as input to the LLMs to generate the final output. Our
experiments demonstrate that the CoDes approach significantly surpasses the
standard prompting strategy across various metrics on both datasets. This
method not only improves the quality of VHDL code generation and summarization
but also serves as a framework for future research aimed at enhancing code LLMs
for VHDL.

</details>


### [42] [Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception](https://arxiv.org/abs/2507.12356)
*Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan*

Main category: cs.CL

TL;DR: 本研究揭示了在阿尔茨海默病（AD）语音感知中存在的性别偏见，男性语音更容易被误判为AD，并探讨了相关声学特征。


<details>
  <summary>Details</summary>
Motivation: 言语感知中普遍存在性别偏见，但这种偏见在AD语音感知中的具体表现尚不明确，本研究旨在填补这一空白。

Method: 通过一项感知实验，招募16名中国听众评估中文和希腊语语音，同时进行了声学分析以识别与AD感知相关的语音特征。

Result: 研究发现男性语音更容易被识别为AD，尤其在中文中此偏见更为显著。声学分析显示，男性语音的颤音值（shimmer）与AD感知显著相关，而语音片段（speech portion）与AD识别呈显著负相关。语言本身对AD感知没有显著影响。

Conclusion: 性别偏见在AD语音感知中具有重要作用。在开发AD检测模型时，必须考虑并解决性别偏见问题，并需进一步研究验证模型在不同语言背景下的性能。

Abstract: Gender bias has been widely observed in speech perception tasks, influenced
by the fundamental voicing differences between genders. This study reveals a
gender bias in the perception of Alzheimer's Disease (AD) speech. In a
perception experiment involving 16 Chinese listeners evaluating both Chinese
and Greek speech, we identified that male speech was more frequently identified
as AD, with this bias being particularly pronounced in Chinese speech. Acoustic
analysis showed that shimmer values in male speech were significantly
associated with AD perception, while speech portion exhibited a significant
negative correlation with AD identification. Although language did not have a
significant impact on AD perception, our findings underscore the critical role
of gender bias in AD speech perception. This work highlights the necessity of
addressing gender bias when developing AD detection models and calls for
further research to validate model performance across different linguistic
contexts.

</details>


### [43] [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](https://arxiv.org/abs/2507.12370)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CL

TL;DR: 为解决大型语言模型（LLMs）处理用户请求时的歧义问题，本文提出并评估了一个多智能体辩论框架。该框架显著提升了LLMs的歧义检测和解决能力，尤其对Llama3-8B和Mistral-7B模型效果显著，证明了其在增强LLMs能力方面的价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在理解和生成人类语言方面表现出色，但其在处理用户请求时面临歧义挑战，这影响了与复杂系统的自然交互能力。

Method: 本文引入并评估了一个多智能体辩论框架，旨在增强LLMs的歧义检测和解决能力。该框架结合了Llama3-8B、Gemma2-9B和Mistral-7B等三种LLM架构，并使用一个包含多种歧义的数据集进行测试。

Result: 该辩论框架显著提升了Llama3-8B和Mistral-7B变体模型的性能，优于其各自的基线。其中，由Mistral-7B主导的辩论取得了76.7%的成功率，在处理复杂歧义和实现高效共识方面表现尤为出色。

Conclusion: 研究结果强调了该辩论框架作为一种增强LLM能力的有效靶向方法，能够提升交互系统中的清晰度。这为开发更稳健和自适应的语言理解系统提供了重要见解。

Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in
understanding and generating human language, contributing to more natural
interactions with complex systems. However, they face challenges such as
ambiguity in user requests processed by LLMs. To address these challenges, this
paper introduces and evaluates a multi-agent debate framework designed to
enhance detection and resolution capabilities beyond single models. The
framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and
Mistral-7B variants) and a dataset with diverse ambiguities. The debate
framework markedly enhanced the performance of Llama3-8B and Mistral-7B
variants over their individual baselines, with Mistral-7B-led debates achieving
a notable 76.7% success rate and proving particularly effective for complex
ambiguities and efficient consensus. While acknowledging varying model
responses to collaborative strategies, these findings underscore the debate
framework's value as a targeted method for augmenting LLM capabilities. This
work offers important insights for developing more robust and adaptive language
understanding systems by showing how structured debates can lead to improved
clarity in interactive systems.

</details>


### [44] [Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics](https://arxiv.org/abs/2507.12372)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh*

Main category: cs.CL

TL;DR: 研究评估了具备网页浏览能力的大型语言模型（LLMs）能否通过用户名推断社交媒体用户的 F（Twitter）人口统计属性。结果显示，LLMs能以合理准确度访问和预测用户人口统计信息，但也可能引入性别和政治偏见。这项能力对计算社会科学有益，但存在滥用风险，需制定保障措施。


<details>
  <summary>Details</summary>
Motivation: 传统LLMs依赖静态训练数据，而具备网页浏览能力的LLMs可以实时获取信息。尽管现有研究已证明LLMs能访问和分析网站，但它们直接检索和分析社交媒体数据的能力（特别是根据用户名推断用户人口属性）尚未被探索。

Method: 本研究通过评估具备网页浏览能力的LLMs来推断社交媒体用户的人口统计属性。使用了两个数据集：一个包含48个X（Twitter）账户的合成数据集，以及一个包含1,384名国际参与者的调查数据集。

Result: 研究结果表明，这些模型能够访问社交媒体内容，并以合理的准确度预测用户的人口统计属性。对合成数据集的分析进一步揭示了LLMs如何解析和解释社交媒体资料，同时也发现这种能力可能对活动量极低的账户引入性别和政治偏见。

Conclusion: 这项能力在后API时代对计算社会科学具有潜力，但同时也引发了滥用（特别是信息操作和定向广告）的风险，凸显了制定保障措施的必要性。研究建议LLM提供商限制其在面向公众的应用中的此项能力，同时为经过验证的研究目的保留受控访问权限。

Abstract: Large language models (LLMs) have traditionally relied on static training
data, limiting their knowledge to fixed snapshots. Recent advancements,
however, have equipped LLMs with web browsing capabilities, enabling real time
information retrieval and multi step reasoning over live web content. While
prior studies have demonstrated LLMs ability to access and analyze websites,
their capacity to directly retrieve and analyze social media data remains
unexplored. Here, we evaluate whether web browsing LLMs can infer demographic
attributes of social media users given only their usernames. Using a synthetic
dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international
participants, we show that these models can access social media content and
predict user demographics with reasonable accuracy. Analysis of the synthetic
dataset further reveals how LLMs parse and interpret social media profiles,
which may introduce gender and political biases against accounts with minimal
activity. While this capability holds promise for computational social science
in the post API era, it also raises risks of misuse particularly in information
operations and targeted advertising underscoring the need for safeguards. We
recommend that LLM providers restrict this capability in public facing
applications, while preserving controlled access for verified research
purposes.

</details>


### [45] [Probing for Arithmetic Errors in Language Models](https://arxiv.org/abs/2507.12379)
*Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 研究表明，利用语言模型内部激活和简单探针可高精度检测算术错误，并能指导模型进行选择性自我修正，提高任务准确性。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型在执行算术任务时，其内部隐藏状态是否包含足以检测并纠正错误的信号，以实现模型内部的错误预测与自我修正能力。

Method: 首先在3位加法任务中，使用简单探针从模型隐藏状态解码预测输出和正确答案。在此基础上，训练轻量级错误检测器以预测模型输出的正确性。随后，将该方法扩展至GSM8K上的链式思考问题，并利用探针指导对错误推理步骤的选择性重新提示。

Result: 简单探针能高精度解码隐藏状态中的预测结果和正确答案；训练的错误检测器预测模型正确性准确率超过90%；简单算术训练的探针能很好地泛化到复杂场景；探针可有效指导错误推理步骤的重新提示，在不显著影响正确输出的情况下提高任务准确率。

Conclusion: 算术错误可以仅从语言模型的内部激活中预测，且简单探针为实现轻量级、内部驱动的模型自我修正提供了一条可行途径。

Abstract: We investigate whether internal activations in language models can be used to
detect arithmetic errors. Starting with a controlled setting of 3-digit
addition, we show that simple probes can accurately decode both the model's
predicted output and the correct answer from hidden states, regardless of
whether the model's output is correct. Building on this, we train lightweight
error detectors that predict model correctness with over 90% accuracy. We then
extend our analysis to structured chain-of-thought traces on addition-only
GSM8K problems and find that probes trained on simple arithmetic generalize
well to this more complex setting, revealing consistent internal
representations. Finally, we demonstrate that these probes can guide selective
re-prompting of erroneous reasoning steps, improving task accuracy with minimal
disruption to correct outputs. Our findings suggest that arithmetic errors can
be anticipated from internal activations alone, and that simple probes offer a
viable path toward lightweight model self-correction.

</details>


### [46] [Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](https://arxiv.org/abs/2507.12425)
*Chandana Cheerla*

Main category: cs.CL

TL;DR: 本研究针对大型语言模型（LLMs）处理异构企业数据和传统检索增强生成（RAG）框架的局限性，提出了一个先进的RAG框架。该框架结合混合检索、元数据过滤、结构保留和优化技术，显著提升了LLM在企业任务中响应的准确性、完整性和相关性。


<details>
  <summary>Details</summary>
Motivation: 组织日益依赖专有企业数据进行关键决策，然而大型语言模型（LLMs）受限于静态预训练、短上下文窗口以及难以处理异构数据格式。传统的检索增强生成（RAG）框架在处理结构化和半结构化数据时表现不佳，因此亟需一种更有效的方法来应对这些挑战。

Method: 本研究提出一个先进的RAG框架，该框架结合了使用密集嵌入（all-mpnet-base-v2）和BM25的混合检索策略。通过SpaCy NER进行元数据感知过滤并辅以交叉编码器重新排序以增强效果。框架应用语义分块来保持文本连贯性，并保留表格数据结构以维护行-列完整性。此外，通过量化索引优化检索效率，并引入人工反馈和会话记忆以提高适应性。

Result: 在企业数据集上的实验显示出显著的性能提升：Precision@5增加了15%（90对比75），Recall@5增加了13%（87对比74），平均倒数排名（MRR）增加了16%（0.85对比0.69）。定性评估结果表明，在5点李克特量表上，忠实性（4.6对比3.0）、完整性（4.2对比2.5）和相关性（4.5对比3.2）的得分均有提高。

Conclusion: 研究结果表明，所提出的框架能够有效地为企业任务提供准确、全面且上下文相关的响应。未来的工作将探索扩展到多模态数据和集成基于代理的检索。

Abstract: Organizations increasingly rely on proprietary enterprise data, including HR
records, structured reports, and tabular documents, for critical
decision-making. While Large Language Models (LLMs) have strong generative
capabilities, they are limited by static pretraining, short context windows,
and challenges in processing heterogeneous data formats. Conventional
Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but
often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval
strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by
metadata-aware filtering with SpaCy NER and cross-encoder reranking. The
framework applies semantic chunking to maintain textual coherence and retains
tabular data structures to preserve row-column integrity. Quantized indexing
optimizes retrieval efficiency, while human-in-the-loop feedback and
conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5
increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),
and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative
evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness
(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.
These results demonstrate the framework's effectiveness in delivering accurate,
comprehensive, and contextually relevant responses for enterprise tasks. Future
work includes extending to multimodal data and integrating agent-based
retrieval. The source code will be released at
https://github.com/CheerlaChandana/Enterprise-Chatbot

</details>


### [47] [Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models](https://arxiv.org/abs/2507.12428)
*Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CL

TL;DR: 研究发现，通过分析开放权重LLM的思维链(CoT)激活，可以预测最终响应的风险。一个基于CoT激活的简单线性探针在预测安全性方面优于基于文本的方法，并能早期、实时地进行监测。


<details>
  <summary>Details</summary>
Motivation: 开放权重语言模型在生成最终响应前会产生思维链(CoTs)，这虽能提高性能，但也引入了潜在的对齐风险，有害内容可能出现在CoTs和最终输出中。本研究旨在探索是否能利用CoTs来预测最终响应的未对齐（不安全）情况。

Method: 研究评估了一系列监测方法，包括人类、高性能大型语言模型和文本分类器，并使用CoT文本或CoT激活作为输入。核心方法是训练一个基于CoT激活的简单线性探针来预测最终响应的安全性。

Result: 1. 基于CoT激活训练的线性探针在预测最终响应是否安全方面，显著优于所有基于文本的方法。
2. CoT文本常不可靠并可能误导，而模型潜在表示（CoT激活）提供了更可靠的预测信号。
3. 该探针能在推理完成前就做出准确预测，即使应用于CoT早期片段也表现出色。
4. 这些发现适用于不同模型规模、家族和安全基准。

Conclusion: 轻量级探针有望实现模型生成过程中的实时安全监测和早期干预，从而有效降低开放权重语言模型产生有害内容的风险。

Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs)
before producing a final response, which improves performance but introduces
additional alignment risks, with harmful content often appearing in both the
CoTs and the final outputs. In this work, we investigate if we can use CoTs to
predict final response misalignment. We evaluate a range of monitoring
approaches, including humans, highly-capable large language models, and text
classifiers, using either CoT text or activations. First, we find that a simple
linear probe trained on CoT activations can significantly outperform all
text-based methods in predicting whether a final response will be safe or
unsafe. CoT texts are often unfaithful and can mislead humans and classifiers,
while model latents (i.e., CoT activations) offer a more reliable predictive
signal. Second, the probe makes accurate predictions before reasoning
completes, achieving strong performance even when applied to early CoT
segments. These findings generalize across model sizes, families, and safety
benchmarks, suggesting that lightweight probes could enable real-time safety
monitoring and early intervention during generation.

</details>


### [48] [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://arxiv.org/abs/2507.12451)
*Suman Adhya,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: 为解决VAE-NTM中后验坍缩问题，本文提出S2WTM模型，通过在单位超球体上使用Spherical Sliced-Wasserstein距离对齐分布，有效建模超球形隐表示，生成更连贯多样的主题，并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于变分自编码器的神经主题模型（VAE-NTMs）在超球形空间中建模时常遭遇后验坍缩问题，导致KL散度项消失，隐表示无效。

Method: 本文提出球形切片Wasserstein自编码器主题模型（S2WTM），该模型采用单位超球体上的先验分布，并利用Spherical Sliced-Wasserstein距离来对齐聚合后验分布与先验分布，以缓解后验坍缩问题。

Result: 实验结果表明，S2WTM在生成更连贯和多样的主题方面优于现有最先进的主题模型，并在下游任务中表现出更好的性能。

Conclusion: S2WTM成功解决了VAE-NTM的后验坍缩问题，通过有效的超球形隐空间建模，显著提升了主题质量和模型在实际应用中的表现。

Abstract: Modeling latent representations in a hyperspherical space has proven
effective for capturing directional similarities in high-dimensional text data,
benefiting topic modeling. Variational autoencoder-based neural topic models
(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical
structure. However, VAE-NTMs often suffer from posterior collapse, where the KL
divergence term in the objective function highly diminishes, leading to
ineffective latent representations. To mitigate this issue while modeling
hyperspherical structure in the latent space, we propose the Spherical Sliced
Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior
distribution supported on the unit hypersphere and leverages the Spherical
Sliced-Wasserstein distance to align the aggregated posterior distribution with
the prior. Experimental results demonstrate that S2WTM outperforms
state-of-the-art topic models, generating more coherent and diverse topics
while improving performance on downstream tasks.

</details>


### [49] [Language Models Improve When Pretraining Data Matches Target Tasks](https://arxiv.org/abs/2507.12466)
*David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan*

Main category: cs.CL

TL;DR: 本研究提出BETR方法，通过使预训练数据与基准任务明确对齐，显著提高计算效率和模型性能，并发现最优的数据选择策略应适应模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法的目标通常通过基准测试隐式迭代确定，本研究旨在探索当这种优化被明确化时会发生什么。

Method: 提出Benchmark-Targeted Ranking (BETR) 方法。该方法通过将预训练文档与基准训练示例的相似度进行选择。具体实现是：将基准示例和预训练文档样本嵌入共享空间，通过与基准的相似度对样本评分，然后训练轻量级分类器预测整个语料库的得分。通过训练超过500个模型并拟合缩放定律来评估和比较。

Result: BETR比DCLM-Baseline实现了2.1倍的计算效率提升（比未过滤数据提升4.7倍），并在10个任务中的9个上提升了性能。BETR泛化性良好。缩放分析显示，模型越大，所需的数据过滤强度越低。

Conclusion: 直接将预训练数据与目标任务匹配能够精确塑造模型能力，且最优的数据选择策略必须适应模型规模。

Abstract: Every data selection method inherently has a target. In practice, these
targets often emerge implicitly through benchmark-driven iteration: researchers
develop selection strategies, train models, measure benchmark performance, then
refine accordingly. This raises a natural question: what happens when we make
this optimization explicit? To explore this, we propose benchmark-targeted
ranking (BETR), a simple method that selects pretraining documents based on
similarity to benchmark training examples. BETR embeds benchmark examples and a
sample of pretraining documents in a shared space, scores this sample by
similarity to benchmarks, then trains a lightweight classifier to predict these
scores for the full corpus. We compare data selection methods by training over
500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to
them. From this, we find that simply aligning pretraining data to evaluation
benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline
(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks
across all scales. BETR also generalizes well: when targeting a diverse set of
benchmarks disjoint from our evaluation suite, it still matches or outperforms
baselines. Our scaling analysis further reveals a clear trend: larger models
require less aggressive filtering. Overall, our findings show that directly
matching pretraining data to target tasks precisely shapes model capabilities
and highlight that optimal selection strategies must adapt to model scale.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [50] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 本文提出一种硬件友好的Deformable Attention Transformers (DAT) 优化框架，通过神经网络架构搜索(NAS)和新的切片策略解决其在硬件部署中不规则内存访问的问题，在极低精度损失下显著减少DRAM访问，提高硬件效率。


<details>
  <summary>Details</summary>
Motivation: Deformable Attention Transformers (DAT) 在计算机视觉任务中表现出色，但其数据依赖型采样机制导致不规则内存访问模式，给高效硬件部署带来挑战。现有加速方法要么硬件开销大，要么牺牲模型精度。

Method: ['提出一种基于神经网络架构搜索(NAS)的方法，结合新的切片策略，在推理过程中自动将输入特征划分为均匀块，以避免内存冲突，并联合优化硬件成本和推理精度。', '设计了一个基于FPGA的验证系统，用于在边缘侧硬件上测试该框架的性能。']

Result: ['在ImageNet-1K数据集上的算法实验表明，与基线DAT相比，该框架的精度损失仅为0.2%。', '在Xilinx FPGA上的硬件实验显示，与现有DAT加速方法相比，所提出的方法将DRAM访问时间减少到18%。']

Conclusion: 所提出的硬件友好型框架成功解决了DAT的硬件部署挑战，在保持高精度的同时显著降低了DRAM访问，使其更适合在边缘设备上高效部署。

Abstract: Deformable Attention Transformers (DAT) have shown remarkable performance in
computer vision tasks by adaptively focusing on informative image regions.
However, their data-dependent sampling mechanism introduces irregular memory
access patterns, posing significant challenges for efficient hardware
deployment. Existing acceleration methods either incur high hardware overhead
or compromise model accuracy. To address these issues, this paper proposes a
hardware-friendly optimization framework for DAT. First, a neural architecture
search (NAS)-based method with a new slicing strategy is proposed to
automatically divide the input feature into uniform patches during the
inference process, avoiding memory conflicts without modifying model
architecture. The method explores the optimal slice configuration by jointly
optimizing hardware cost and inference accuracy. Secondly, an FPGA-based
verification system is designed to test the performance of this framework on
edge-side hardware. Algorithm experiments on the ImageNet-1K dataset
demonstrate that our hardware-friendly framework can maintain have only 0.2%
accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA
show the proposed method reduces DRAM access times to 18% compared with
existing DAT acceleration methods.

</details>


### [51] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: 本文提出DDCN，一种基于CNN的新型变形动态卷积网络，用于准确高效的时空交通预测，解决了现有方法在异质性建模和GNN在大规模数据上的可伸缩性限制问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统需要准确且高效的时空交通预测。现有方法难以捕捉区域和时间段内的交通模式异质性，且主流的图神经网络（GNNs）依赖预定义邻接矩阵，并因其固有复杂性而难以扩展到大规模数据。传统卷积神经网络（CNNs）在建模非欧几里得空间结构和时空异质性方面也存在局限性。

Method: 提出变形动态卷积网络（DDCN）。DDCN通过基于偏移量动态应用可变形滤波器来克服挑战。它将Transformer风格的CNN分解为编码器-解码器结构，并将提出的方法应用于编码器的空间和时空注意力块以强调重要特征。解码器由前馈模块组成，用于补充编码器的输出。

Result: DDCN在四个真实世界数据集上取得了有竞争力的性能，证明了基于CNN的方法在时空交通预测中的潜力和有效性。

Conclusion: DDCN能够实现准确且高效的交通预测，并且强调了基于CNN的方法在时空交通预测领域的有效性与潜力。

Abstract: Spatio-temporal traffic prediction plays a key role in intelligent
transportation systems by enabling accurate prediction in complex urban areas.
Although not only accuracy but also efficiency for scalability is important,
some previous methods struggle to capture heterogeneity such as varying traffic
patterns across regions and time periods. Moreover, Graph Neural Networks
(GNNs), which are the mainstream of traffic prediction, not only require
predefined adjacency matrix, but also limit scalability to large-scale data
containing many nodes due to their inherent complexity. To overcome these
limitations, we propose Deformable Dynamic Convolution Network (DDCN) for
accurate yet efficient traffic prediction. Traditional Convolutional Neural
Networks (CNNs) are limited in modeling non-Euclidean spatial structures and
spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically
applying deformable filters based on offset. Specifically, DDCN decomposes
transformer-style CNN to encoder-decoder structure, and applies proposed
approaches to the spatial and spatio-temporal attention blocks of the encoder
to emphasize important features. The decoder, composed of feed-forward module,
complements the output of the encoder. This novel structure make DDCN can
perform accurate yet efficient traffic prediction. In comprehensive experiments
on four real-world datasets, DDCN achieves competitive performance, emphasizing
the potential and effectiveness of CNN-based approaches for spatio-temporal
traffic prediction.

</details>


### [52] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: Inversion-DPO提出了一种新型扩散模型对齐框架，通过DDIM反演重构DPO，无需奖励模型，显著提升了训练精度和效率，并在图像生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型对齐方法（如基于奖励模型的后训练）计算密集，不仅产生高昂的计算开销，还可能损害模型精度和训练效率。

Method: 本文提出了Inversion-DPO，一种新颖的对齐框架，通过结合DDIM反演重构直接偏好优化（DPO），从而规避了奖励模型的需求。该方法利用获胜和失败样本到噪声的确定性反演，进行不可行后验采样，形成一种新的后训练范式。此外，为解决组合图像生成任务，作者还策划了一个包含11,140张图像的配对数据集，其中包含复杂的结构标注和综合评分。

Result: Inversion-DPO在文本到图像生成和组合图像生成任务上，与现有后训练方法相比，实现了显著的性能提升。训练后的生成模型能够生成高保真度且具有组合一致性的图像。

Conclusion: Inversion-DPO为扩散模型提供了一种高效、高精度的对齐新途径，拓展了其在复杂现实生成任务中的应用潜力。

Abstract: Recent advancements in diffusion models (DMs) have been propelled by
alignment methods that post-train models to better conform to human
preferences. However, these approaches typically require computation-intensive
training of a base model and a reward model, which not only incurs substantial
computational overhead but may also compromise model accuracy and training
efficiency. To address these limitations, we propose Inversion-DPO, a novel
alignment framework that circumvents reward modeling by reformulating Direct
Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts
intractable posterior sampling in Diffusion-DPO with the deterministic
inversion from winning and losing samples to noise and thus derive a new
post-training paradigm. This paradigm eliminates the need for auxiliary reward
models or inaccurate appromixation, significantly enhancing both precision and
efficiency of training. We apply Inversion-DPO to a basic task of text-to-image
generation and a challenging task of compositional image generation. Extensive
experiments show substantial performance improvements achieved by Inversion-DPO
compared to existing post-training methods and highlight the ability of the
trained generative models to generate high-fidelity compositionally coherent
images. For the post-training of compostitional image geneation, we curate a
paired dataset consisting of 11,140 images with complex structural annotations
and comprehensive scores, designed to enhance the compositional capabilities of
generative models. Inversion-DPO explores a new avenue for efficient,
high-precision alignment in diffusion models, advancing their applicability to
complex realistic generation tasks. Our code is available at
https://github.com/MIGHTYEZ/Inversion-DPO

</details>


### [53] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: 本文提出ST-VFM，一个将视觉基础模型（VFMs）重编程以用于时空预测的通用框架，通过双分支架构和分阶段重编程策略，有效解决了时空数据的建模挑战。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）擅长序列依赖，但难以捕捉复杂的时空关联。虽然VFMs拥有强大的空间先验，但在时空任务中面临缺乏时间建模能力和视觉与时空数据模态差距的挑战。

Method: ST-VFM采用双分支架构，整合原始时空输入与辅助时空流输入。通过“VFM前重编程”阶段的“时序感知令牌适配器”嵌入时序上下文并对齐模态；“VFM后重编程”阶段的“双边交叉提示协调模块”实现分支间动态交互，无需修改冻结的VFM骨干。

Result: 在十个时空数据集上，ST-VFM的性能超越了现有最先进基线，并在不同VFM骨干（如DINO、CLIP、DEIT）和消融研究中展现出有效性和鲁棒性。

Conclusion: ST-VFM被确立为一个强大的通用时空预测框架。

Abstract: Foundation models have achieved remarkable success in natural language
processing and computer vision, demonstrating strong capabilities in modeling
complex patterns. While recent efforts have explored adapting large language
models (LLMs) for time-series forecasting, LLMs primarily capture
one-dimensional sequential dependencies and struggle to model the richer
spatio-temporal (ST) correlations essential for accurate ST forecasting. In
this paper, we present \textbf{ST-VFM}, a novel framework that systematically
reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal
forecasting. While VFMs offer powerful spatial priors, two key challenges arise
when applying them to ST tasks: (1) the lack of inherent temporal modeling
capacity and (2) the modality gap between visual and ST data. To address these,
ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs
with auxiliary ST flow inputs, where the flow encodes lightweight temporal
difference signals interpretable as dynamic spatial cues. To effectively
process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming
stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token
Adapter to embed temporal context and align both branches into VFM-compatible
feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral
Cross-Prompt Coordination module, enabling dynamic interaction between branches
through prompt-based conditioning, thus enriching joint representation learning
without modifying the frozen VFM backbone. Extensive experiments on ten
spatio-temporal datasets show that ST-VFM outperforms state-of-the-art
baselines, demonstrating effectiveness and robustness across VFM backbones
(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong
general framework for spatio-temporal forecasting.

</details>


### [54] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: xOp-GAN是一种新型多专家生成器GAN，通过为不同图像质量训练专业生成器，并利用判别器在推理阶段选择最佳结果，有效解决了水下图像修复中单一生成器性能不足的问题，在LSUI数据集上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 水下图像因复杂的光传播、散射和深度衰减导致广泛形变，使得修复极具挑战。传统基于GAN的单生成器方法难以在异构域中表现良好，因单个生成器不足以捕获所有视觉退化。

Method: 提出xOp-GAN，一个包含多个专家生成器网络的新型GAN模型。每个生成器专门针对特定图像质量子集进行训练。在推理时，所有生成器修复图像，判别器根据感知置信度分数选择最佳修复图像。这是首个在回归任务推理阶段使用判别器的多生成器GAN模型。

Result: 在大型水下图像（LSUI）基准数据集上的实验表明，xOp-GAN的PSNR水平达到25.16 dB，即使在降低复杂性的情况下，也以很大优势超越了所有单回归器模型。

Conclusion: xOp-GAN通过采用多专家生成器和在推理阶段利用判别器选择最佳结果的策略，成功克服了水下图像修复中单一生成器处理复杂退化的局限性，实现了卓越的性能提升和效率优化。

Abstract: The wide range of deformation artifacts that arise from complex light
propagation, scattering, and depth-dependent attenuation makes the underwater
image restoration to remain a challenging problem. Like other single deep
regressor networks, conventional GAN-based restoration methods struggle to
perform well across this heterogeneous domain, since a single generator network
is typically insufficient to capture the full range of visual degradations. In
order to overcome this limitation, we propose xOp-GAN, a novel GAN model with
several expert generator networks, each trained solely on a particular subset
with a certain image quality. Thus, each generator can learn to maximize its
restoration performance for a particular quality range. Once a xOp-GAN is
trained, each generator can restore the input image and the best restored image
can then be selected by the discriminator based on its perceptual confidence
score. As a result, xOP-GAN is the first GAN model with multiple generators
where the discriminator is being used during the inference of the regression
task. Experimental results on benchmark Large Scale Underwater Image (LSUI)
dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,
surpassing all single-regressor models by a large margin even, with reduced
complexity.

</details>


### [55] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 本文结合元分析与大规模步态数据实验，评估并提升了从步态预测年龄的精度，为降低真实世界应用中的误差提供了基线和指南。


<details>
  <summary>Details</summary>
Motivation: 从步态估计年龄在医疗保健、安全和人机交互等领域具有重要的应用价值。

Method: 1. 对59项关于步态年龄估计的研究进行了元分析，涉及视频、可穿戴和雷达传感器数据。
2. 分析了OU-ISIR大型人口数据集的63,846个步态周期，量化年龄与五项关键步态指标的相关性。
3. 微调ResNet34模型，并利用Grad-CAM揭示网络关注区域。
4. 在VersatileGait数据库的10万样本子集上，比较了SVM、决策树、随机森林、多层感知机和CNN等多种机器学习模型。

Result: 1. 元分析显示，CNN平均误差约4.2年，惯性传感器模型约4.5年，多传感器融合低至3.4年。
2. 年龄与五项步态指标（步长、步行速度、步频、步时变异性、关节角度熵）的相关系数至少为0.27。
3. Grad-CAM显示网络关注膝盖和骨盆区域，与年龄相关步态变化相符。
4. 深度网络在VersatileGait数据集上实现了高达96%的准确率，单样本处理时间少于0.1秒。

Conclusion: 通过结合广泛的元分析、大规模实验和可解释性可视化，本文建立了稳固的性能基线和实用指南，以期将真实世界中步态年龄估计误差降低到三年以下。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [56] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 本文开发了一个名为PPGNet-Cat的行人重识别(re-ID)模型，通过修改现有网络并结合对比学习，实现了对野外流浪猫的高精度个体识别，以辅助其监测。


<details>
  <summary>Details</summary>
Motivation: 流浪猫对澳大利亚野生动物造成严重危害，是全球最危险的入侵物种之一。因此，密切监测这些猫对于最小化其影响至关重要。

Method: 项目探索了多种计算机视觉方法来创建流浪猫re-ID模型。主要方法是修改一个原用于东北虎re-ID的PPGNet模型，使其适用于流浪猫，并命名为PPGNet-Cat。此外，还进行了对比学习方法（如ArcFace loss）的实验。

Result: PPGNet-Cat在识别流浪猫方面表现出色，实现了0.86的平均精度均值(mAP)和0.95的Rank-1准确率。

Conclusion: 研究结果表明PPGNet-Cat是re-ID领域内一个具有竞争力的模型，能够有效识别野外流浪猫。

Abstract: Feral cats exert a substantial and detrimental impact on Australian wildlife,
placing them among the most dangerous invasive species worldwide. Therefore,
closely monitoring these cats is essential labour in minimising their effects.
In this context, the potential application of Re-Identification (re-ID) emerges
to enhance monitoring activities for these animals, utilising images captured
by camera traps. This project explores different CV approaches to create a
re-ID model able to identify individual feral cats in the wild. The main
approach consists of modifying a part-pose guided network (PPGNet) model,
initially used in the re-ID of Amur tigers, to be applicable for feral cats.
This adaptation, resulting in PPGNet-Cat, which incorporates specific
modifications to suit the characteristics of feral cats images. Additionally,
various experiments were conducted, particularly exploring contrastive learning
approaches such as ArcFace loss. The main results indicate that PPGNet-Cat
excels in identifying feral cats, achieving high performance with a mean
Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes
establish PPGNet-Cat as a competitive model within the realm of re-ID.

</details>


### [57] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: SketchDNN是一个生成模型，通过统一的连续-离散扩散过程，用于合成同时建模连续参数和离散类别标签的CAD草图。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图中图元参数化的异质性和图元排列不变性两大关键挑战。

Method: 核心创新是高斯-Softmax扩散，通过对受高斯噪声扰动的logits进行Softmax变换投射到概率单纯形，从而实现离散变量的混合类别标签。

Result: 显著提升了生成质量，在SketchGraphs数据集上将Fréchet Inception Distance (FID) 从16.04降低到7.80，负对数似然（NLL）从84.8降低到81.33。

Conclusion: 在CAD草图生成领域建立了新的最先进水平。

Abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that
jointly models both continuous parameters and discrete class labels through a
unified continuous-discrete diffusion process. Our core innovation is
Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are
projected onto the probability simplex via a softmax transformation,
facilitating blended class labels for discrete variables. This formulation
addresses 2 key challenges, namely, the heterogeneity of primitive
parameterizations and the permutation invariance of primitives in CAD sketches.
Our approach significantly improves generation quality, reducing Fr\'echet
Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)
from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch
generation on the SketchGraphs dataset.

</details>


### [58] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 本研究提出使用变分自编码器（VAE）替代传统卷积神经网络（CNN），通过分析MRI图像实现直肠癌淋巴结转移的准确分期，并取得了当前最佳性能。


<details>
  <summary>Details</summary>
Motivation: 直肠癌淋巴结转移（LNM）的准确分期对有效治疗至关重要，但现有基于淋巴结大小、形状和纹理形态的影像学标准诊断准确性有限。使用VAE旨在通过图像重建直接编码视觉特征和有意义的模式，从而获得比CNN更具可解释性的解耦和结构化潜在空间。

Method: 本研究采用变分自编码器（VAE）作为特征编码模型，取代现有方法中常用的大型预训练卷积神经网络（CNN）。模型在包含168名未接受新辅助治疗患者的内部MRI数据集上进行部署，并以术后病理N分期作为金标准评估模型预测。

Result: 所提出的'VAE-MLP'模型在MRI数据集上实现了最先进的性能，交叉验证指标显示AUC为0.86 +/- 0.05，敏感性为0.79 +/- 0.06，特异性为0.85 +/- 0.05。

Conclusion: VAE-MLP模型为直肠癌淋巴结转移的诊断提供了更准确、更具可解释性的方法，显著优于现有影像学标准和基于CNN的方法，有望提高直肠癌的诊断和治疗效果。

Abstract: Effective treatment for rectal cancer relies on accurate lymph node
metastasis (LNM) staging. However, radiological criteria based on lymph node
(LN) size, shape and texture morphology have limited diagnostic accuracy. In
this work, we investigate applying a Variational Autoencoder (VAE) as a feature
encoder model to replace the large pre-trained Convolutional Neural Network
(CNN) used in existing approaches. The motivation for using a VAE is that the
generative model aims to reconstruct the images, so it directly encodes visual
features and meaningful patterns across the data. This leads to a disentangled
and structured latent space which can be more interpretable than a CNN. Models
are deployed on an in-house MRI dataset with 168 patients who did not undergo
neo-adjuvant treatment. The post-operative pathological N stage was used as the
ground truth to evaluate model predictions. Our proposed model 'VAE-MLP'
achieved state-of-the-art performance on the MRI dataset, with cross-validated
metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85
+/- 0.05. Code is available at:
https://github.com/benkeel/Lymph_Node_Classification_MIUA.

</details>


### [59] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 通过运动姿态识别用户意图，以解决人体数据敏感性问题，并在板球比赛中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 基于姿态的心理状态推断具有巨大潜力，但由于人体数据敏感性，难以获取大规模数据集进行研究验证，这阻碍了其向实际应用的转化。

Method: 利用体育环境（板球比赛）作为数据收集替代方案，开发了一种基于姿态的解决方案，通过运动分析从活动视频中识别板球运动员的攻击性或防御性击球意图。此外，利用现有数据统计作为弱监督来验证研究发现。

Result: 该方法在区分攻击性和防御性击球意图上，F1分数超过75%，AUC-ROC超过80%。结果表明，即使数据存在噪声，姿态也能泄露出强烈的意图信号。

Conclusion: 研究成果为体育分析提供了通用技术，并为将人类行为分析应用于其他领域开辟了可能性。同时，其弱监督方法为克服数据标注限制提供了潜在解决方案。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [60] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: VISTA是一个基于对象分割和追踪的单目全局定位框架，解决了非结构化环境下外观变化带来的定位挑战，实现了高召回率和低内存占用。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，跨会话/跨代理的全局定位在非结构化环境中面临巨大挑战，主要源于视角、季节变化、空间混叠和遮挡导致的外观变化，传统方法在此类场景下表现不佳。

Method: 提出VISTA（View-Invariant Segmentation-Based Tracking for Frame Alignment）框架，一个开放集单目全局定位解决方案。它结合了：1) 前端基于对象的分割与追踪管道；2) 利用环境图几何一致性进行参考系对齐的子图对应搜索。该方法无需领域特定训练或微调。

Result: 在季节和斜角航空数据集上，VISTA的召回率比基线方法提高了高达69%。其维护的对象地图大小仅为最节约内存基线的0.6%，支持在资源受限平台上的实时实现。

Conclusion: VISTA通过创新的方法有效克服了复杂环境中全局定位的挑战，在保证跨视角和季节变化下定位一致性的同时，显著优化了内存占用，使其成为一种高效且实用的全局定位方案。

Abstract: Global localization is critical for autonomous navigation, particularly in
scenarios where an agent must localize within a map generated in a different
session or by another agent, as agents often have no prior knowledge about the
correlation between reference frames. However, this task remains challenging in
unstructured environments due to appearance changes induced by viewpoint
variation, seasonal changes, spatial aliasing, and occlusions -- known failure
modes for traditional place recognition methods. To address these challenges,
we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame
Alignment), a novel open-set, monocular global localization framework that
combines: 1) a front-end, object-based, segmentation and tracking pipeline,
followed by 2) a submap correspondence search, which exploits geometric
consistencies between environment maps to align vehicle reference frames. VISTA
enables consistent localization across diverse camera viewpoints and seasonal
changes, without requiring any domain-specific training or finetuning. We
evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a
69% improvement in recall over baseline methods. Furthermore, we maintain a
compact object-based map that is only 0.6% the size of the most
memory-conservative baseline, making our approach capable of real-time
implementation on resource-constrained platforms.

</details>


### [61] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 该研究系统性地对比了VLM和CNN-OCR模型在户外广告牌文本识别任务上的表现，发现VLM在场景理解方面表现出色，而CNN模型在裁剪文本识别上具有成本效益和竞争力，适用于边缘部署。


<details>
  <summary>Details</summary>
Motivation: 户外广告牌文本可见性验证面临挑战，传统OCR在复杂户外场景、多变字体和天气噪声下表现不佳。新兴的多模态视觉-语言模型（VLM）有望提供端到端解决方案，但其在此领域的性能需系统评估。

Method: 研究系统地对比了Qwen 2.5 VL 3B、InternVL3和SmolVLM2等代表性VLM与CNN-based OCR基线（PaddleOCRv4）。评估基于ICDAR 2015和SVT两个公共数据集，并引入合成天气扰动以模拟真实退化。

Result: 结果显示，所选VLM在整体场景推理方面表现出色；然而，轻量级CNN管道在裁剪文本识别上仍能以极低的计算成本实现有竞争力的精度，这对于边缘部署是一个重要考量。

Conclusion: VLM在整体场景理解上具有优势，但对于户外广告牌裁剪文本识别，轻量级CNN模型在计算效率和精度上仍具竞争力，尤其适用于资源受限的边缘设备部署。研究公开了天气增强的基准数据集和评估代码以促进后续研究。

Abstract: Outdoor advertisements remain a critical medium for modern marketing, yet
accurately verifying billboard text visibility under real-world conditions is
still challenging. Traditional Optical Character Recognition (OCR) pipelines
excel at cropped text recognition but often struggle with complex outdoor
scenes, varying fonts, and weather-induced visual noise. Recently, multimodal
Vision-Language Models (VLMs) have emerged as promising alternatives, offering
end-to-end scene understanding with no explicit detection step. This work
systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,
InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline
(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with
synthetic weather distortions to simulate realistic degradation. Our results
reveal that while selected VLMs excel at holistic scene reasoning, lightweight
CNN pipelines still achieve competitive accuracy for cropped text at a fraction
of the computational cost-an important consideration for edge deployment. To
foster future research, we release our weather-augmented benchmark and
evaluation code publicly.

</details>


### [62] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 本文提出一个统一条件生成求解器（UCGS），旨在通过单次多任务训练解决多种抽象视觉推理（AVR）任务，并展现出零样本推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度抽象视觉推理（AVR）求解器通常采用任务特异性设计，导致在解决新任务时需要重新训练甚至调整模型架构，从而增加了解决AVR问题的成本。

Method: 本文提出了一个新颖的统一条件生成求解器（UCGS）。首先，将一些知名的AVR任务重新表述为评估问题面板中目标图像可预测性的问题。然后，在一个统一框架下，通过训练一个条件生成模型来解决各种AVR任务。

Result: 实验结果表明，经过单轮多任务训练，UCGS在各种AVR任务中展现出抽象推理能力。特别是，UCGS还表现出零样本推理能力，使其能够在测试阶段对来自未见过的AVR任务的问题进行抽象推理。

Conclusion: UCGS通过其统一的框架和条件生成方法，有效克服了传统AVR求解器任务特异性的局限性，显著提升了模型在处理多任务和未知任务时的通用性和效率。

Abstract: Abstract visual reasoning (AVR) enables humans to quickly discover and
generalize abstract rules to new scenarios. Designing intelligent systems with
human-like AVR abilities has been a long-standing topic in the artificial
intelligence community. Deep AVR solvers have recently achieved remarkable
success in various AVR tasks. However, they usually use task-specific designs
or parameters in different tasks. In such a paradigm, solving new tasks often
means retraining the model, and sometimes retuning the model architectures,
which increases the cost of solving AVR problems. In contrast to task-specific
approaches, this paper proposes a novel Unified Conditional Generative Solver
(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we
prove that some well-known AVR tasks can be reformulated as the problem of
estimating the predictability of target images in problem panels. Then, we
illustrate that, under the proposed framework, training one conditional
generative model can solve various AVR tasks. The experiments show that with a
single round of multi-task training, UCGS demonstrates abstract reasoning
ability across various AVR tasks. Especially, UCGS exhibits the ability of
zero-shot reasoning, enabling it to perform abstract reasoning on problems from
unseen AVR tasks in the testing phase.

</details>


### [63] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: 本文提出CorrMoE，一种新颖的对应关系修剪框架，通过去风格化双分支解决跨域问题，并使用双融合专家混合模块处理场景多样性，在鲁棒性和泛化性上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管现有对应关系修剪方法有所进展，但它们通常假定视觉域一致，且忽视了多样化场景结构带来的挑战，导致在跨域和跨场景条件下鲁棒性不足。

Method: 本文提出CorrMoE框架。为解决域偏移，引入去风格化双分支（De-stylization Dual Branch），对隐式和显式图特征进行风格混合。为应对场景多样性，设计了双融合专家混合模块（Bi-Fusion Mixture of Experts），通过线性复杂度注意力机制和动态专家路由自适应整合多视角特征。

Result: 在基准数据集上的大量实验证明，CorrMoE比现有最先进方法取得了更高的精度和更好的泛化能力。

Conclusion: CorrMoE通过其创新的设计，有效提升了在跨域和跨场景变化下图像对应关系建立的鲁棒性，并在性能上超越了现有技术，为3D重建和视觉定位等应用提供了更可靠的基础。

Abstract: Establishing reliable correspondences between image pairs is a fundamental
task in computer vision, underpinning applications such as 3D reconstruction
and visual localization. Although recent methods have made progress in pruning
outliers from dense correspondence sets, they often hypothesize consistent
visual domains and overlook the challenges posed by diverse scene structures.
In this paper, we propose CorrMoE, a novel correspondence pruning framework
that enhances robustness under cross-domain and cross-scene variations. To
address domain shift, we introduce a De-stylization Dual Branch, performing
style mixing on both implicit and explicit graph features to mitigate the
adverse influence of domain-specific representations. For scene diversity, we
design a Bi-Fusion Mixture of Experts module that adaptively integrates
multi-perspective features through linear-complexity attention and dynamic
expert routing. Extensive experiments on benchmark datasets demonstrate that
CorrMoE achieves superior accuracy and generalization compared to
state-of-the-art methods. The code and pre-trained models are available at
https://github.com/peiwenxia/CorrMoE.

</details>


### [64] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: 本文提出ProtoConNet方法，通过整合背景上下文信息并进行原型对齐，以解决开集小样本图像分类中现有方法忽略上下文信息的问题，从而增强模型在未知环境下的泛化能力和已知/未知类别识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有开集小样本图像分类方法主要依赖单图像视觉信息学习类别表示，忽视了整合丰富上下文信息的重要性。这导致模型在未知环境下泛化能力不足，且在小样本场景中容易形成上下文与图像主体之间的虚假关联。

Method: 本文提出一种原型增强与对齐方法ProtoConNet，通过整合来自不同样本的背景信息来增强特征空间多样性。该方法包含三个主要模块：1) 基于聚类的数据选择(CDS)模块，用于挖掘多样数据模式并保留核心特征；2) 上下文增强语义精炼(CSR)模块，用于构建上下文词典并融入图像表示，以提升模型鲁棒性；3) 原型对齐(PA)模块，用于缩小图像表示与类别原型之间的差距，放大已知和未知类别的特征距离。

Result: 在两个数据集上的实验结果验证了ProtoConNet能有效增强小样本场景中的表示学习能力，并能准确识别开集样本，性能优于现有方法。

Conclusion: ProtoConNet通过有效整合上下文信息和实施原型对齐，显著提升了开集小样本图像分类的性能，增强了模型在复杂未知环境下的泛化能力和对已知、未知类别的识别能力。

Abstract: Open-set few-shot image classification aims to train models using a small
amount of labeled data, enabling them to achieve good generalization when
confronted with unknown environments. Existing methods mainly use visual
information from a single image to learn class representations to distinguish
known from unknown categories. However, these methods often overlook the
benefits of integrating rich contextual information. To address this issue,
this paper proposes a prototypical augmentation and alignment method, termed
ProtoConNet, which incorporates background information from different samples
to enhance the diversity of the feature space, breaking the spurious
associations between context and image subjects in few-shot scenarios.
Specifically, it consists of three main modules: the clustering-based data
selection (CDS) module mines diverse data patterns while preserving core
features; the contextual-enhanced semantic refinement (CSR) module builds a
context dictionary to integrate into image representations, which boosts the
model's robustness in various scenarios; and the prototypical alignment (PA)
module reduces the gap between image representations and class prototypes,
amplifying feature distances for known and unknown classes. Experimental
results from two datasets verified that ProtoConNet enhances the effectiveness
of representation learning in few-shot scenarios and identifies open-set
samples, making it superior to existing methods.

</details>


### [65] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 本文提出GRACE，一种新的动态面部表情识别方法，通过细粒度对齐动态运动和语义文本，解决了现有方法文本情感线索利用不足及无关面部动态过滤不佳的问题，并在基准数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有动态面部表情识别（DFER）中的视觉-语言方法存在两项主要局限：一是未能充分利用生成文本中嵌入的细微情感线索；二是没有有效机制来过滤与情感表达无关的面部动态。

Method: 本文提出GRACE（Granular Representation Alignment for Cross-modal Emotion recognition）模型，它整合了动态运动建模、语义文本细化和令牌级跨模态对齐。具体方法包括：通过“粗粒度到细粒度情感文本增强（CATE）”模块构建情感感知文本描述；通过“运动差异加权机制”突出表情相关的面部运动；使用“熵正则化最优传输”在令牌级别对精炼的语义和视觉信号进行对齐。

Result: 在三个基准数据集上的实验表明，GRACE显著提高了识别性能，尤其是在情感类别模糊或不平衡的挑战性设置中，并在UAR和WAR指标上均达到了新的最先进（SOTA）水平。

Conclusion: GRACE通过其创新的跨模态对齐和细粒度特征处理，有效解决了动态面部表情识别中的关键挑战，显著提升了识别准确性，为情感计算领域带来了重要进展。

Abstract: Dynamic Facial Expression Recognition (DFER) aims to identify human emotions
from temporally evolving facial movements and plays a critical role in
affective computing. While recent vision-language approaches have introduced
semantic textual descriptions to guide expression recognition, existing methods
still face two key limitations: they often underutilize the subtle emotional
cues embedded in generated text, and they have yet to incorporate sufficiently
effective mechanisms for filtering out facial dynamics that are irrelevant to
emotional expression. To address these gaps, We propose GRACE, Granular
Representation Alignment for Cross-modal Emotion recognition that integrates
dynamic motion modeling, semantic text refinement, and token-level cross-modal
alignment to facilitate the precise localization of emotionally salient
spatiotemporal features. Our method constructs emotion-aware textual
descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and
highlights expression-relevant facial motion through a motion-difference
weighting mechanism. These refined semantic and visual signals are aligned at
the token level using entropy-regularized optimal transport. Experiments on
three benchmark datasets demonstrate that our method significantly improves
recognition performance, particularly in challenging settings with ambiguous or
imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in
terms of both UAR and WAR.

</details>


### [66] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: 为解决下采样层中高频信息失真问题，本文提出空间频率调制（SFM）框架，在下采样前对高频特征进行调制降频，并在上采样时解调恢复，有效保留细节并提升多项视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 语义分割精度高度依赖高空间频率信息（如纹理），但下采样层（如步幅卷积）会导致高频分量出现混叠或失真，从而影响模型性能。

Method: 提出空间频率调制（SFM）框架。该框架在下采样前通过自适应重采样（ARS）将高频特征调制到低频，并在上采样时通过多尺度自适应上采样（MSAU）进行解调以恢复高频信息。这两个模块可无缝集成到CNN和Transformer等多种架构中。

Result: 特征可视化和分析证实，所提方法有效缓解了混叠效应，并在解调后成功保留了细节。SFM在图像分类、对抗鲁棒性、实例分割和全景分割等任务中也展现出广泛的适用性和有效性。

Conclusion: SFM通过独特的频率调制与解调机制，克服了下采样导致的高频信息丢失问题，显著提升了语义分割及其他多种视觉任务的性能，具有广泛的应用潜力。

Abstract: High spatial frequency information, including fine details like textures,
significantly contributes to the accuracy of semantic segmentation. However,
according to the Nyquist-Shannon Sampling Theorem, high-frequency components
are vulnerable to aliasing or distortion when propagating through downsampling
layers such as strided-convolution. Here, we propose a novel Spatial Frequency
Modulation (SFM) that modulates high-frequency features to a lower frequency
before downsampling and then demodulates them back during upsampling.
Specifically, we implement modulation through adaptive resampling (ARS) and
design a lightweight add-on that can densely sample the high-frequency areas to
scale up the signal, thereby lowering its frequency in accordance with the
Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling
(MSAU) to demodulate the modulated feature and recover high-frequency
information through non-uniform upsampling This module further improves
segmentation by explicitly exploiting information interaction between densely
and sparsely resampled areas at multiple scales. Both modules can seamlessly
integrate with various architectures, extending from convolutional neural
networks to transformers. Feature visualization and analysis confirm that our
method effectively alleviates aliasing while successfully retaining details
after demodulation. Finally, we validate the broad applicability and
effectiveness of SFM by extending it to image classification, adversarial
robustness, instance segmentation, and panoptic segmentation tasks. The code is
available at
\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.

</details>


### [67] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose是一个综合性的合成事件相机行人姿态估计数据集，旨在弥补该领域真实数据稀缺的空白，并验证其在真实数据上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 事件相机在行人交通监测中具有低延迟和高动态范围的优势，但在行人及交通监测系统中，针对挑战性场景的事件相机数据稀缺，限制了相关研究与应用。

Method: 研究人员使用CARLA模拟器中的动态视觉传感器生成了SEPose数据集，该数据集包含近35万个带人体姿态关键点的标注行人数据。他们使用该数据集训练了RVT和YOLOv8等现有最先进的模型。

Result: SEPose是一个综合性的多行人姿态估计数据集，涵盖了城市、郊区和乡村环境下，四岔路口不同光照、天气条件下的繁忙和稀疏人群以及交通场景。在SEPose上训练的模型在真实事件相机数据上表现出良好的模拟到现实（sim-to-real）泛化能力。

Conclusion: SEPose数据集有效地解决了事件相机行人姿态估计领域数据稀缺的问题，并证明了其在实际应用中训练模型并实现良好泛化的潜力。

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [68] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 本文提出了Dark-EvGS，一个事件辅助的3D高斯飞溅框架，旨在解决低光环境下传统相机难以捕捉清晰多视角图像的问题。该框架通过三元组监督和色彩匹配模块，有效应对了事件噪声、图像质量差和色彩不一致的挑战，并构建了首个真实数据集。


<details>
  <summary>Details</summary>
Motivation: 传统相机在低光环境中捕捉多视角图像时，受动态范围限制和长时间曝光导致运动模糊影响，难以获得清晰图像。尽管事件相机和3D高斯飞溅（GS）有潜力解决这些问题，但简单的事件辅助3D GS方法在低光下仍面临事件噪声大、帧质量差、色彩不一致等挑战。

Method: 本文提出了Dark-EvGS框架，首次实现了事件辅助的3D GS，能够在低光条件下沿相机轨迹重建任意视角的亮帧。具体方法包括：1) 引入三元组监督，以获取整体知识、细粒度细节和清晰的场景渲染；2) 提出色彩匹配模块，以确保渲染帧的色彩一致性。此外，还构建了首个用于事件引导的基于3D GS辐射场重建的真实数据集。

Result: 实验结果表明，Dark-EvGS方法在具有挑战性的低光条件下，能够更好地进行辐射场重建，并取得了优于现有方法的成果。

Conclusion: Dark-EvGS成功克服了低光环境下多视角亮帧重建的关键挑战，通过创新的监督机制和色彩一致性策略，实现了高质量的辐射场重建，为该领域提供了新的解决方案。

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [69] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: 提出了一个名为Hyperphantasia的新基准，用于评估多模态大语言模型（MLLMs）的心理可视化能力，并发现它们与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）基准主要侧重于被动视觉感知，无法有效评估其主动构建和操作内部视觉表征以支持问题解决的核心认知能力，而这种能力在人类认知中至关重要。

Method: 引入了Hyperphantasia，一个包含四个程序生成且具有三个难度级别的谜题的合成基准，专门用于评估MLLM的心理可视化能力。同时，探索了强化学习在提升视觉模拟能力方面的潜力。

Result: 对最先进模型的综合评估显示，在心理可视化能力方面，人类和多模态大语言模型之间存在显著差距。尽管一些模型在识别视觉模式上表现出部分能力。

Conclusion: 尽管部分模型能够识别视觉模式，但强大的心理可视化能力对于当前的多模态大语言模型来说仍然是一个尚未解决的挑战。

Abstract: Mental visualization, the ability to construct and manipulate visual
representations internally, is a core component of human cognition and plays a
vital role in tasks involving reasoning, prediction, and abstraction. Despite
the rapid progress of Multimodal Large Language Models (MLLMs), current
benchmarks primarily assess passive visual perception, offering limited insight
into the more active capability of internally constructing visual patterns to
support problem solving. Yet mental visualization is a critical cognitive skill
in humans, supporting abilities such as spatial navigation, predicting physical
trajectories, and solving complex visual problems through imaginative
simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic
benchmark designed to evaluate the mental visualization abilities of MLLMs
through four carefully constructed puzzles. Each task is procedurally generated
and presented at three difficulty levels, enabling controlled analysis of model
performance across increasing complexity. Our comprehensive evaluation of
state-of-the-art models reveals a substantial gap between the performance of
humans and MLLMs. Additionally, we explore the potential of reinforcement
learning to improve visual simulation capabilities. Our findings suggest that
while some models exhibit partial competence in recognizing visual patterns,
robust mental visualization remains an open challenge for current MLLMs.

</details>


### [70] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 针对文生图模型在多实例图像生成中面临的关系差异和属性泄露问题，本文提出了RaDL框架。RaDL通过学习参数增强实例属性并利用关系注意力生成关系感知图像特征。实验证明RaDL在定位、多属性和实例关系处理上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文生图(T2I)模型在单一图像提示中有效生成多个实例时面临关键挑战，尤其是在处理实例间关系差异和多属性泄露方面表现不足，尽管它们能成功生成单个实例的位置。

Method: 本文提出了关系感知解耦学习(RaDL)框架。RaDL通过可学习参数增强实例特定属性，并通过关系注意力（利用从全局提示中提取的动作动词）生成关系感知图像特征。

Result: 在COCO-Position、COCO-MIG和DrawBench等基准测试上的大量评估表明，RaDL优于现有方法，在位置准确性、多属性考量以及实例间关系方面显示出显著改进。

Conclusion: RaDL为生成能够同时考虑多实例图像中每个实例的关系和多个属性的图像提供了一个有效的解决方案。

Abstract: With recent advancements in text-to-image (T2I) models, effectively
generating multiple instances within a single image prompt has become a crucial
challenge. Existing methods, while successful in generating positions of
individual instances, often struggle to account for relationship discrepancy
and multiple attributes leakage. To address these limitations, this paper
proposes the relation-aware disentangled learning (RaDL) framework. RaDL
enhances instance-specific attributes through learnable parameters and
generates relation-aware image features via Relation Attention, utilizing
action verbs extracted from the global prompt. Through extensive evaluations on
benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that
RaDL outperforms existing methods, showing significant improvements in
positional accuracy, multiple attributes consideration, and the relationships
between instances. Our results present RaDL as the solution for generating
images that consider both the relationships and multiple attributes of each
instance within the multi-instance image.

</details>


### [71] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为PPAR（Prototypical Progressive Alignment and Reweighting）的新颖框架，用于可泛化语义分割。PPAR利用CLIP模型生成原型，并引入渐进式对齐策略和原型重加权机制，以解决现有方法中粗糙对齐、原型过拟合及忽略样本适应性差异的问题，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 可泛化语义分割在现实应用中至关重要，但对未见目标域的泛化能力是一个严峻挑战。现有基于类别原型的方法面临三个主要问题：1) 粗糙的原型对齐策略影响性能；2) 简单计算的原型易于过拟合并受不相关源数据负面影响；3) 大多数方法平等对待所有源样本，忽略了不同特征的适应难度差异。

Method: 我们提出Prototypical Progressive Alignment and Reweighting (PPAR) 框架。具体而言，我们利用CLIP模型定义了两种原型：原始文本原型（OTP）和视觉文本原型（VTP），作为对齐的坚实基础。随后，引入渐进式对齐策略，以由易到难的方式对齐特征，逐步缩小域差距。此外，我们提出原型重加权机制，估计源数据的可靠性并调整其贡献，以减轻不相关或有害特征的影响（即减少负迁移）。我们还提供了理论分析，表明该方法与域泛化理论的一致性。

Result: 在多个基准测试中进行的广泛实验表明，PPAR实现了最先进的性能，验证了其有效性。

Conclusion: PPAR框架通过引入CLIP生成的原型、渐进式对齐和原型重加权机制，有效解决了可泛化语义分割中的关键挑战，实现了卓越的泛化能力和最先进的性能。

Abstract: Generalizable semantic segmentation aims to perform well on unseen target
domains, a critical challenge due to real-world applications requiring high
generalizability. Class-wise prototypes, representing class centroids, serve as
domain-invariant cues that benefit generalization due to their stability and
semantic consistency. However, this approach faces three challenges. First,
existing methods often adopt coarse prototypical alignment strategies, which
may hinder performance. Second, naive prototypes computed by averaging source
batch features are prone to overfitting and may be negatively affected by
unrelated source data. Third, most methods treat all source samples equally,
ignoring the fact that different features have varying adaptation difficulties.
To address these limitations, we propose a novel framework for generalizable
semantic segmentation: Prototypical Progressive Alignment and Reweighting
(PPAR), leveraging the strong generalization ability of the CLIP model.
Specifically, we define two prototypes: the Original Text Prototype (OTP) and
Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for
alignment. We then introduce a progressive alignment strategy that aligns
features in an easy-to-difficult manner, reducing domain gaps gradually.
Furthermore, we propose a prototypical reweighting mechanism that estimates the
reliability of source data and adjusts its contribution, mitigating the effect
of irrelevant or harmful features (i.e., reducing negative transfer). We also
provide a theoretical analysis showing the alignment between our method and
domain generalization theory. Extensive experiments across multiple benchmarks
demonstrate that PPAR achieves state-of-the-art performance, validating its
effectiveness.

</details>


### [72] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: LG-CAV-MAE模型通过集成预训练文本编码器并利用自动生成的三模态数据，显著提升了音视频表示学习，在检索和分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入文本模态来改进音视频表示学习，以解决现有方法可能未能充分利用多模态信息或需要大量手动标注的问题。

Method: 提出LG-CAV-MAE模型，将预训练文本编码器集成到对比音视频掩码自编码器中，实现音、视、文三模态学习。引入自动方法从无标注视频生成高质量音视频文本三元组，具体包括使用图像字幕模型生成帧级字幕，并利用CLAP进行音频-字幕对齐过滤。

Result: 在音视频检索和分类任务中进行评估。在检索任务中，recall@10指标提升高达5.6%；在分类任务中，性能提升3.2%，显著优于现有方法。

Conclusion: LG-CAV-MAE通过整合文本信息有效提升了音视频表示学习能力，并在检索和分类任务中展现出卓越性能，同时其自动数据生成方法利用了无标注视频数据。

Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked
Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning.
LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual
masked autoencoders, enabling the model to learn across audio, visual and text
modalities. To train LG-CAV-MAE, we introduce an automatic method to generate
audio-visual-text triplets from unlabeled videos. We first generate frame-level
captions using an image captioning model and then apply CLAP-based filtering to
ensure strong alignment between audio and captions. This approach yields
high-quality audio-visual-text triplets without requiring manual annotations.
We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an
audio-visual classification task. Our method significantly outperforms existing
approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks
and a 3.2% improvement for the classification task.

</details>


### [73] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 评估多模态大语言模型（MLLMs）在短视频内容审核中对抗三模态攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: MLLMs在内容审核中应用广泛，但其在短视频背景下的鲁棒性，尤其面对多模态组合攻击时的安全性，尚未被充分探索。

Method: 提出了一个评估MLLMs三模态安全性的综合框架，包括构建Short-Video Multimodal Adversarial (SVMA) 数据集和提出新型三模态攻击策略ChimeraBreak，同时挑战视觉、听觉和语义推理。

Result: 实验揭示了当前SOTA MLLMs存在显著漏洞和高攻击成功率，并发现模型在误判良性或违规内容时存在偏见。

Conclusion: 本研究的数据集和发现为开发更鲁棒和安全的MLLMs提供了关键见解。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used for content
moderation, yet their robustness in short-form video contexts remains
underexplored. Current safety evaluations often rely on unimodal attacks,
failing to address combined attack vulnerabilities. In this paper, we introduce
a comprehensive framework for evaluating the tri-modal safety of MLLMs. First,
we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising
diverse short-form videos with human-guided synthetic adversarial attacks.
Second, we propose ChimeraBreak, a novel tri-modal attack strategy that
simultaneously challenges visual, auditory, and semantic reasoning pathways.
Extensive experiments on state-of-the-art MLLMs reveal significant
vulnerabilities with high Attack Success Rates (ASR). Our findings uncover
distinct failure modes, showing model biases toward misclassifying benign or
policy-violating content. We assess results using LLM-as-a-judge, demonstrating
attack reasoning efficacy. Our dataset and findings provide crucial insights
for developing more robust and safe MLLMs.

</details>


### [74] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出GS-Bias，一种高效且有效的测试时自适应（TTA）范式，通过学习全局和空间偏差直接作用于视觉-语言模型（VLM）的输出逻辑值，显著提升泛化性能同时大幅降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有VLM的TTA方法在性能与效率之间难以取得平衡，主要问题包括文本提示调优的开销过大，以及手工或无训练的视觉特征增强效果不稳定。

Method: 本文提出Global-Spatial Bias Learner (GS-Bias)，在TTA过程中引入两种可学习的偏差：全局偏差和空间偏差。全局偏差通过学习增强视图之间的一致性来捕捉图像的全局语义特征；空间偏差则学习图像空间视觉表示中区域间的语义连贯性。这些偏差被直接添加到预训练VLM的输出逻辑值（logits）中，从而避免了VLM的完全反向传播，显著提升了效率。

Result: GS-Bias在15个基准数据集上实现了最先进的性能和极高的效率。例如，在跨数据集泛化方面比TPT提升2.23%，在领域泛化方面提升2.72%，同时在ImageNet上仅需TPT 6.5%的内存使用。

Conclusion: GS-Bias通过引入可学习的全局和空间偏差并将其直接作用于VLM输出，成功解决了现有TTA方法在性能与效率之间的权衡问题，实现了卓越的泛化能力和显著的效率提升。

Abstract: Recent advances in test-time adaptation (TTA) for Vision-Language Models
(VLMs) have garnered increasing attention, particularly through the use of
multiple augmented views of a single image to boost zero-shot generalization.
Unfortunately, existing methods fail to strike a satisfactory balance between
performance and efficiency, either due to excessive overhead of tuning text
prompts or unstable benefits from handcrafted, training-free visual feature
enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),
an efficient and effective TTA paradigm that incorporates two learnable biases
during TTA, unfolded as the global bias and spatial bias. Particularly, the
global bias captures the global semantic features of a test image by learning
consistency across augmented views, while spatial bias learns the semantic
coherence between regions in the image's spatial visual representation. It is
worth highlighting that these two sets of biases are directly added to the
logits outputed by the pretrained VLMs, which circumvent the full
backpropagation through VLM that hinders the efficiency of existing TTA
methods. This endows GS-Bias with extremely high efficiency while achieving
state-of-the-art performance on 15 benchmark datasets. For example, it achieves
a 2.23% improvement over TPT in cross-dataset generalization and a 2.72%
improvement in domain generalization, while requiring only 6.5% of TPT's memory
usage on ImageNet.

</details>


### [75] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: 本文提出EC-Diff，通过梯度噪声估计加速云端推理并优化云边切换点，解决了扩散模型边缘-云协同框架中云端推理过长或语义不一致的问题，实现了更快的推理速度和更高的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有边缘-云协同扩散模型推理框架中，云端去噪步数过多会导致推理时间过长，而步数过少又会引发语义模糊，导致边缘模型输出不一致，从而限制了用户体验。

Method: 本文提出了EC-Diff模型。具体方法包括：1) 设计K步噪声近似策略，利用步间噪声梯度减少云端推理频率，并周期性地进行云端推理以校正误差。2) 设计两阶段贪婪搜索算法，高效寻找噪声近似和边缘模型切换的最佳参数。

Result: 实验结果表明，与纯边缘推理相比，EC-Diff显著提升了生成质量；与纯云端推理相比，平均推理速度提高了2倍。

Conclusion: EC-Diff成功地在边缘-云协同框架中，在不牺牲生成质量的前提下，显著加速了扩散模型的推理过程，有效解决了速度与质量之间的权衡问题。

Abstract: Diffusion Models have shown remarkable proficiency in image and video
synthesis. As model size and latency increase limit user experience, hybrid
edge-cloud collaborative framework was recently proposed to realize fast
inference and high-quality generation, where the cloud model initiates
high-quality semantic planning and the edge model expedites later-stage
refinement. However, excessive cloud denoising prolongs inference time, while
insufficient steps cause semantic ambiguity, leading to inconsistency in edge
model output. To address these challenges, we propose EC-Diff that accelerates
cloud inference through gradient-based noise estimation while identifying the
optimal point for cloud-edge handoff to maintain generation quality.
Specifically, we design a K-step noise approximation strategy to reduce cloud
inference frequency by using noise gradients between steps and applying cloud
inference periodically to adjust errors. Then we design a two-stage greedy
search algorithm to efficiently find the optimal parameters for noise
approximation and edge model switching. Extensive experiments demonstrate that
our method significantly enhances generation quality compared to edge
inference, while achieving up to an average $2\times$ speedup in inference
compared to cloud inference. Video samples and source code are available at
https://ec-diff.github.io/.

</details>


### [76] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: 本文提出一种名为Masked Part Autoencoder (MPAE)的新范式，旨在无监督地、鲁棒地发现图像中各种类别和场景下的有意义的局部特征，解决了现有方法对标签的依赖和泛化性差的问题。


<details>
  <summary>Details</summary>
Motivation: 图像理解中，局部特征至关重要，但缺乏细粒度标注。现有无监督局部发现方法在不同类别和场景下鲁棒性不足，限制了其应用范围。

Method: 提出Masked Part Autoencoder (MPAE)。该方法首先学习局部描述符和特征图，然后从被遮蔽的图像版本中生成块特征。根据局部特征与描述符的相似性，用学习到的局部描述符填充遮蔽区域，并通过非遮蔽区域的外观特征引导恢复这些遮蔽块，使其更好地与局部形状对齐。此外，引入更宽松有效的约束，以在无监督情况下实现跨类别和场景的局部识别。

Result: 该方法能够鲁棒地发现与真实物体形状紧密匹配的有意义的局部，且适用于多种类别和复杂场景。

Conclusion: MPAE为解决遮挡问题和探索跨类别局部相似性提供了基础。它在各种设置下，均能鲁棒地发现有意义的局部。

Abstract: Part-level features are crucial for image understanding, but few studies
focus on them because of the lack of fine-grained labels. Although unsupervised
part discovery can eliminate the reliance on labels, most of them cannot
maintain robustness across various categories and scenarios, which restricts
their application range. To overcome this limitation, we present a more
effective paradigm for unsupervised part discovery, named Masked Part
Autoencoder (MPAE). It first learns part descriptors as well as a feature map
from the inputs and produces patch features from a masked version of the
original images. Then, the masked regions are filled with the learned part
descriptors based on the similarity between the local features and descriptors.
By restoring these masked patches using the part descriptors, they become
better aligned with their part shapes, guided by appearance features from
unmasked patches. Finally, MPAE robustly discovers meaningful parts that
closely match the actual object shapes, even in complex scenarios. Moreover,
several looser yet more effective constraints are proposed to enable MPAE to
identify the presence of parts across various scenarios and categories in an
unsupervised manner. This provides the foundation for addressing challenges
posed by occlusion and for exploring part similarity across multiple
categories. Extensive experiments demonstrate that our method robustly
discovers meaningful parts across various categories and scenarios. The code is
available at the project https://github.com/Jiahao-UTS/MPAE.

</details>


### [77] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 本文提出了一种零样本扩散管道，通过在去噪潜在空间上结合空间掩码和深度图条件，实现文本到图像模型中多艺术风格的区域特定混合，解决了现有模型难以精确控制区域风格的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散文本到图像模型在风格个性化方面表现出色，但在受控的、区域性方式应用多个不同绘画技巧时遇到困难，因为其潜在空间纠缠且缺乏平滑插值，常常导致单一风格占据主导地位。

Method: 本研究提出一种零样本扩散管道，通过在单独训练的、风格专业化模型的流匹配去噪过程中，对去噪后的潜在变量进行风格合成，自然地混合多种风格。该方法利用低噪声潜在变量携带更强风格信息的特点，使用空间掩码在异构扩散管道中融合它们，以实现精确的区域特定风格控制。此外，为确保不同模型间的结构一致性，集成了通过ControlNet进行的深度图条件化。

Result: 定性和定量实验表明，该方法成功实现了根据给定掩码的区域特定风格混合。它在允许用户指导混合的同时，保留了每种独立风格的保真度。

Conclusion: 该零样本扩散管道有效克服了现有扩散模型在区域性多风格混合方面的限制，通过在去噪潜在空间进行风格合成并结合ControlNet进行结构一致性保持，实现了精确且用户可控的区域特定风格混合。

Abstract: Diffusion-based text-to-image models have achieved remarkable results in
synthesizing diverse images from text prompts and can capture specific artistic
styles via style personalization. However, their entangled latent space and
lack of smooth interpolation make it difficult to apply distinct painting
techniques in a controlled, regional manner, often causing one style to
dominate. To overcome this, we propose a zero-shot diffusion pipeline that
naturally blends multiple styles by performing style composition on the
denoised latents predicted during the flow-matching denoising process of
separately trained, style-specialized models. We leverage the fact that
lower-noise latents carry stronger stylistic information and fuse them across
heterogeneous diffusion pipelines using spatial masks, enabling precise,
region-specific style control. This mechanism preserves the fidelity of each
individual style while allowing user-guided mixing. Furthermore, to ensure
structural coherence across different models, we incorporate depth-map
conditioning via ControlNet into the diffusion framework. Qualitative and
quantitative experiments demonstrate that our method successfully achieves
region-specific style mixing according to the given masks.

</details>


### [78] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 针对Textual Inversion个性化肖像生成中身份一致性问题，提出ID-EA框架，通过ID-Enhancer和ID-Adapter对齐文本与视觉身份嵌入。该方法在身份保持上优于SOTA，且速度快15倍。


<details>
  <summary>Details</summary>
Motivation: 当前Textual Inversion方法在个性化肖像生成中，因文本与视觉身份嵌入空间语义错位，导致难以保持面部身份一致性。

Method: 提出ID-EA框架，包含ID-Enhancer和ID-Adapter。ID-Enhancer通过整合身份嵌入和文本ID锚点来优化视觉身份嵌入；ID-Adapter则利用增强的身份嵌入调整文本条件，通过修改预训练UNet的交叉注意力模块确保身份保持。

Result: ID-EA在身份保持指标上显著优于现有最先进方法，且计算效率极高，生成个性化肖像的速度比现有方法快约15倍。

Conclusion: ID-EA有效解决了个性化肖像生成中的身份保持难题，实现了卓越的身份一致性和显著的生成效率提升。

Abstract: Recently, personalized portrait generation with a text-to-image diffusion
model has significantly advanced with Textual Inversion, emerging as a
promising approach for creating high-fidelity personalized images. Despite its
potential, current Textual Inversion methods struggle to maintain consistent
facial identity due to semantic misalignments between textual and visual
embedding spaces regarding identity. We introduce ID-EA, a novel framework that
guides text embeddings to align with visual identity embeddings, thereby
improving identity preservation in a personalized generation. ID-EA comprises
two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned
Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings
with a textual ID anchor, refining visual identity embeddings derived from a
face recognition model using representative text embeddings. Then, the
ID-Adapter leverages the identity-enhanced embedding to adapt the text
condition, ensuring identity preservation by adjusting the cross-attention
module in the pre-trained UNet model. This process encourages the text features
to find the most related visual clues across the foreground snippets. Extensive
quantitative and qualitative evaluations demonstrate that ID-EA substantially
outperforms state-of-the-art methods in identity preservation metrics while
achieving remarkable computational efficiency, generating personalized
portraits approximately 15 times faster than existing approaches.

</details>


### [79] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: 提出SAMST半监督语义分割方法，通过结合Segment Anything Model (SAM)改进伪标签并提升遥感图像分割性能，解决标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 公共遥感数据集因分辨率变异和地物类别定义不一致导致通用性受限，且存在大量未标注数据。研究旨在利用这些未标注数据，解决遥感语义分割中标记数据有限的挑战。

Method: 提出SAMST半监督语义分割方法。该方法利用SAM的零样本泛化和边界检测能力，通过两个主要部分迭代精炼伪标签：1) 使用已标注和伪标注数据的监督模型自训练；2) 基于SAM的伪标签精炼器。伪标签精炼器包含阈值过滤模块、提示生成模块和标签精炼模块，旨在整合大模型的泛化能力和小模型的训练效率。

Result: SAMST有效提高了伪标签的准确性，从而增强了整体模型性能。在Potsdam数据集上的实验验证了其有效性和可行性。

Conclusion: SAMST展示了解决遥感语义分割中有限标注数据挑战的潜力，为利用大量未标注遥感数据提供了有效途径。

Abstract: Public remote sensing datasets often face limitations in universality due to
resolution variability and inconsistent land cover category definitions. To
harness the vast pool of unlabeled remote sensing data, we propose SAMST, a
semi-supervised semantic segmentation method. SAMST leverages the strengths of
the Segment Anything Model (SAM) in zero-shot generalization and boundary
detection. SAMST iteratively refines pseudo-labels through two main components:
supervised model self-training using both labeled and pseudo-labeled data, and
a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three
modules: a Threshold Filter Module for preprocessing, a Prompt Generation
Module for extracting connected regions and generating prompts for SAM, and a
Label Refinement Module for final label stitching. By integrating the
generalization power of large models with the training efficiency of small
models, SAMST improves pseudo-label accuracy, thereby enhancing overall model
performance. Experiments on the Potsdam dataset validate the effectiveness and
feasibility of SAMST, demonstrating its potential to address the challenges
posed by limited labeled data in remote sensing semantic segmentation.

</details>


### [80] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: 本文介绍了AUBlendSet数据集和AUBlendNet网络，旨在解决3D面部动画中精细化、风格化表情操控的难题，并实现基于AU的跨身份连续3D面部表情操作。


<details>
  <summary>Details</summary>
Motivation: 现有3D面部动画在实现精细化、风格化的3D面部表情操控方面面临挑战，主要原因是缺乏合适的数据集。

Method: 研究者构建了AUBlendSet数据集，该数据集基于AU-Blendshape表示，包含500个身份的32个标准面部动作单元（AUs）的混合形状数据及其详细标注。在此基础上，提出了AUBlendNet网络，用于学习不同角色风格的AU-Blendshape基向量，从而实现给定身份网格的风格化3D情感面部操控。

Result: 通过风格化面部表情操控、语音驱动情感面部动画和情感识别数据增强等任务，全面验证了AUBlendSet和AUBlendNet的有效性。定性和定量实验表明，它们在3D面部动画任务中具有显著的潜力和重要性。

Conclusion: AUBlendSet是首个通过面部AUs对任何身份进行连续3D面部表情操控的数据集，而AUBlendNet是首个实现此功能的网络，填补了该领域的空白，具有重要意义。

Abstract: While 3D facial animation has made impressive progress, challenges still
exist in realizing fine-grained stylized 3D facial expression manipulation due
to the lack of appropriate datasets. In this paper, we introduce the
AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for
fine-grained facial expression manipulation across identities. AUBlendSet is a
blendshape data collection based on 32 standard facial action units (AUs)
across 500 identities, along with an additional set of facial postures
annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to
learn AU-Blendshape basis vectors for different character styles. AUBlendNet
predicts, in parallel, the AU-Blendshape basis vectors of the corresponding
style for a given identity mesh, thereby achieving stylized 3D emotional facial
manipulation. We comprehensively validate the effectiveness of AUBlendSet and
AUBlendNet through tasks such as stylized facial expression manipulation,
speech-driven emotional facial animation, and emotion recognition data
augmentation. Through a series of qualitative and quantitative experiments, we
demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D
facial animation tasks. To the best of our knowledge, AUBlendSet is the first
dataset, and AUBlendNet is the first network for continuous 3D facial
expression manipulation for any identity through facial AUs. Our source code is
available at https://github.com/wslh852/AUBlendNet.git.

</details>


### [81] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出FDAM策略以解决ViTs中频率消失导致的细节丢失问题。FDAM通过注意力反转和频率动态缩放来调节频率响应，有效避免表征坍塌，并在多项视觉任务及遥感检测中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有Vision Transformers（ViTs）的注意力机制使其各层表现为低通滤波器，导致堆叠层架构中出现频率消失现象，进而丢失关键细节和纹理信息。

Method: 提出一种受电路理论启发的频率动态注意力调制（FDAM）策略，可即插即用。FDAM包含注意力反转（AttInv）和频率动态缩放（FreqScale）两种技术。AttInv通过反转注意力矩阵中的低通滤波器生成互补高通滤波，并与现有低通滤波动态结合；FreqScale则用于加权不同频率分量，以精细调整目标响应函数。

Result: 通过特征相似性分析和有效秩评估，证明FDAM避免了表征坍塌，并在SegFormer、DeiT、MaskDINO等多种模型上，于语义分割、目标检测、实例分割等任务中实现一致的性能提升。此外，在遥感检测的单尺度设置中达到最先进水平。

Conclusion: FDAM成功解决了ViTs中的频率消失问题，通过引入动态频率调制机制，有效防止表征坍塌，显著提升了模型在各种计算机视觉任务（包括遥感检测）中的性能和细节保留能力。

Abstract: Vision Transformers (ViTs) have significantly advanced computer vision,
demonstrating strong performance across various tasks. However, the attention
mechanism in ViTs makes each layer function as a low-pass filter, and the
stacked-layer architecture in existing transformers suffers from frequency
vanishing. This leads to the loss of critical details and textures. We propose
a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention
Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly
modulates the overall frequency response of ViTs and consists of two
techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling
(FreqScale). Since circuit theory uses low-pass filters as fundamental
elements, we introduce AttInv, a method that generates complementary high-pass
filtering by inverting the low-pass filter in the attention matrix, and
dynamically combining the two. We further design FreqScale to weight different
frequency components for fine-grained adjustments to the target response
function. Through feature similarity analysis and effective rank evaluation, we
demonstrate that our approach avoids representation collapse, leading to
consistent performance improvements across various models, including SegFormer,
DeiT, and MaskDINO. These improvements are evident in tasks such as semantic
segmentation, object detection, and instance segmentation. Additionally, we
apply our method to remote sensing detection, achieving state-of-the-art
results in single-scale settings. The code is available at
\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.

</details>


### [82] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 本文提出MaskTwins，一个UDA框架，通过理论分析互补掩码在提取领域无关特征方面的优势，并强制互补掩码图像预测一致性，在图像分割中实现域泛化。


<details>
  <summary>Details</summary>
Motivation: 现有工作将MIM应用于UDA时，仅将掩码视为输入变形，缺乏理论分析，导致对掩码重建理解不足，未充分发挥其在特征提取中的潜力。

Method: 将掩码重建重构为稀疏信号重建问题，理论证明互补掩码的对偶形式在提取领域无关特征方面具优势。基于此，提出MaskTwins，将掩码重建直接融入训练管线，通过强制互补掩码图像预测一致性来发现跨域结构模式，实现端到端域泛化。

Result: MaskTwins在自然和生物图像分割任务中均优于基线方法。

Conclusion: MaskTwins在无需单独预训练的情况下，能有效提取领域不变特征，为域自适应分割提供了一种新范式。

Abstract: Recent works have correlated Masked Image Modeling (MIM) with consistency
regularization in Unsupervised Domain Adaptation (UDA). However, they merely
treat masking as a special form of deformation on the input images and neglect
the theoretical analysis, which leads to a superficial understanding of masked
reconstruction and insufficient exploitation of its potential in enhancing
feature extraction and representation learning. In this paper, we reframe
masked reconstruction as a sparse signal reconstruction problem and
theoretically prove that the dual form of complementary masks possesses
superior capabilities in extracting domain-agnostic image features. Based on
this compelling insight, we propose MaskTwins, a simple yet effective UDA
framework that integrates masked reconstruction directly into the main training
pipeline. MaskTwins uncovers intrinsic structural patterns that persist across
disparate domains by enforcing consistency between predictions of images masked
in complementary ways, enabling domain generalization in an end-to-end manner.
Extensive experiments verify the superiority of MaskTwins over baseline methods
in natural and biological image segmentation. These results demonstrate the
significant advantages of MaskTwins in extracting domain-invariant features
without the need for separate pre-training, offering a new paradigm for
domain-adaptive segmentation.

</details>


### [83] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 本文提出一种基于时间卷积层的端到端深度编解码模型，利用fMRI数据编解码大脑对自然电影刺激的活动，重建视觉输入，并识别出贡献最大的脑区，以加深对视觉处理的理解。


<details>
  <summary>Details</summary>
Motivation: 在自然刺激（如电影）下，利用fMRI数据编码和解码大脑活动，并解决刺激与fMRI采集之间的时间分辨率差异，以探究和理解大脑的视觉处理机制。

Method: 采用一个端到端深度神经网络编解码模型，利用时间卷积层处理连续电影帧的时间相关性，弥合电影刺激与fMRI采集的时间分辨率差距。该模型预测视觉皮层体素活动并从神经活动中重建视觉输入。通过显著性图分析对视觉解码有贡献的脑区。

Result: 模型能有效预测视觉皮层活动并重建相应的视觉输入，如边缘、面部和对比度。通过显著性图发现，对视觉解码贡献最大的区域包括枕中区（形状感知）、梭状回（复杂识别，尤其面部）和距状裂（基本视觉特征如边缘和对比度），这些区域的功能与解码器重建能力一致。

Conclusion: 研究表明，所提出的深度学习模型可以作为一种探针，帮助我们理解大脑在观看电影等自然刺激时的视觉处理过程。

Abstract: We propose an end-to-end deep neural encoder-decoder model to encode and
decode brain activity in response to naturalistic stimuli using functional
magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input
from consecutive film frames, we employ temporal convolutional layers in our
architecture, which effectively allows to bridge the temporal resolution gap
between natural movie stimuli and fMRI acquisitions. Our model predicts
activity of voxels in and around the visual cortex and performs reconstruction
of corresponding visual inputs from neural activity. Finally, we investigate
brain regions contributing to visual decoding through saliency maps. We find
that the most contributing regions are the middle occipital area, the fusiform
area, and the calcarine, respectively employed in shape perception, complex
recognition (in particular face perception), and basic visual features such as
edges and contrasts. These functions being strongly solicited are in line with
the decoder's capability to reconstruct edges, faces, and contrasts. All in
all, this suggests the possibility to probe our understanding of visual
processing in films using as a proxy the behaviour of deep learning models such
as the one proposed in this paper.

</details>


### [84] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 针对RGB-IR无监督域适应目标检测中RGB子域问题，本文提出SS-DC框架，通过光谱分解解耦域不变/特定特征并进行空间-频谱耦合，显著提升了跨域检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-IR无监督域适应目标检测方法忽略RGB域内的多个子域（如白天、夜晚、雾天），导致性能受限。研究认为解耦这些子域中的域不变和域特定特征对域适应至关重要。

Method: 提出SS-DC框架，采用解耦-耦合策略。解耦方面，设计光谱自适应幂等解耦（SAID）模块，利用频谱分解分离域不变和域特定分量，并引入滤波器组和自蒸馏解耦损失。耦合方面，提出新的空间-频谱耦合方法，通过空间和频谱域不变特征金字塔实现联合耦合，并利用域特定特征减小域偏差。

Result: 实验证明，该方法显著提升了基线性能，并在多个RGB-IR数据集（包括基于FLIR-ADAS的新协议）上超越了现有UDAOD方法。

Conclusion: 所提出的SS-DC框架通过有效解耦和耦合跨子域的域不变和域特定特征，显著提升了RGB-IR无监督域适应目标检测的性能，为复杂跨域场景提供了有效解决方案。

Abstract: Unsupervised domain adaptive object detection (UDAOD) from the visible domain
to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB
domain as a unified domain and neglect the multiple subdomains within it, such
as daytime, nighttime, and foggy scenes. We argue that decoupling the
domain-invariant (DI) and domain-specific (DS) features across these multiple
subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper
proposes a new SS-DC framework based on a decoupling-coupling strategy. In
terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)
module in the aspect of spectral decomposition. Due to the style and content
information being highly embedded in different frequency bands, this module can
decouple DI and DS components more accurately and interpretably. A novel filter
bank-based spectral processing paradigm and a self-distillation-driven
decoupling loss are proposed to improve the spectral domain decoupling. In
terms of coupling, a new spatial-spectral coupling method is proposed, which
realizes joint coupling through spatial and spectral DI feature pyramids.
Meanwhile, this paper introduces DS from decoupling to reduce the domain bias.
Extensive experiments demonstrate that our method can significantly improve the
baseline performance and outperform existing UDAOD methods on multiple RGB-IR
datasets, including a new experimental protocol proposed in this paper based on
the FLIR-ADAS dataset.

</details>


### [85] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 本文提出DOV4MM，一种针对掩码模型的首个数据集所有权验证方法。该方法基于模型在目标数据集上预训练后重建掩码信息的难度差异，经验证性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 高质量开源数据集推动了深度学习发展，但也面临被滥用的风险，保护数据所有者权益至关重要。现有数据集所有权验证技术主要针对监督模型和对比预训练模型，不适用于日益普遍的掩码模型，这是当前亟待解决的挑战。

Method: 本文提出了DOV4MM（Dataset Ownership Verification for Masked Modeling），旨在确定可疑黑盒模型是否在特定未标记数据集上预训练。其核心方法基于经验观察：模型在目标数据集上预训练后，其在嵌入空间中重建掩码信息的难度与未在该数据集上预训练的模型有显著差异。

Result: 通过在ImageNet-1K上的10个掩码图像模型和WikiText-103上的4个掩码语言模型进行验证，DOV4MM的p值远低于0.05，拒绝了空假设，且性能超越了所有现有方法。

Conclusion: DOV4MM成功解决了掩码模型的数据集所有权验证难题，为数据集所有者保护其权利提供了有效且优越的工具。

Abstract: High-quality open-source datasets have emerged as a pivotal catalyst driving
the swift advancement of deep learning, while facing the looming threat of
potential exploitation. Protecting these datasets is of paramount importance
for the interests of their owners. The verification of dataset ownership has
evolved into a crucial approach in this domain; however, existing verification
techniques are predominantly tailored to supervised models and contrastive
pre-trained models, rendering them ill-suited for direct application to the
increasingly prevalent masked models. In this work, we introduce the inaugural
methodology addressing this critical, yet unresolved challenge, termed Dataset
Ownership Verification for Masked Modeling (DOV4MM). The central objective is
to ascertain whether a suspicious black-box model has been pre-trained on a
particular unlabeled dataset, thereby assisting dataset owners in safeguarding
their rights. DOV4MM is grounded in our empirical observation that when a model
is pre-trained on the target dataset, the difficulty of reconstructing masked
information within the embedding space exhibits a marked contrast to models not
pre-trained on that dataset. We validated the efficacy of DOV4MM through ten
masked image models on ImageNet-1K and four masked language models on
WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,
with a $p$-value considerably below 0.05, surpassing all prior approaches. Code
is available at https://github.com/xieyc99/DOV4MM.

</details>


### [86] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 本文提出MVAR模型，通过多元自回归训练范式和气象耦合空间变换器，解决现有模型在多变量空气污染物长期预测中忽略污染物交互和空间差异的问题。同时构建了一个综合数据集。实验结果显示MVAR优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有空气污染物预测研究主要集中于单污染物，忽视了不同污染物间的相互作用及多样的空间响应。此外，空气污染物预测领域缺乏标准化的数据集。准确预测多变量污染物对污染预警和政策制定至关重要。

Method: 1. 提出MVAR（MultiVariate AutoRegressive air pollutants forecasting model）模型，旨在减少对长输入时间窗口的依赖并提高数据利用效率。2. 设计多元自回归训练范式，实现120小时的长期序列预测。3. 开发气象耦合空间变换器模块，灵活整合基于AI的气象预测，并学习污染物间的相互作用及其多样化的空间响应。4. 构建了一个综合数据集，涵盖2018年至2023年中国北方75个城市的6种主要污染物，并包括ERA5再分析数据和FuXi-2.0预测数据。

Result: 实验结果表明，所提出的MVAR模型性能优于当前最先进的方法，并且验证了所提出架构的有效性。

Conclusion: MVAR模型为多变量空气污染物预测提供了一个有效且先进的解决方案，通过考虑污染物交互和空间响应，并实现长期预测，能够更好地支持污染预警和政策制定。

Abstract: Air pollutants pose a significant threat to the environment and human health,
thus forecasting accurate pollutant concentrations is essential for pollution
warnings and policy-making. Existing studies predominantly focus on
single-pollutant forecasting, neglecting the interactions among different
pollutants and their diverse spatial responses. To address the practical needs
of forecasting multivariate air pollutants, we propose MultiVariate
AutoRegressive air pollutants forecasting model (MVAR), which reduces the
dependency on long-time-window inputs and boosts the data utilization
efficiency. We also design the Multivariate Autoregressive Training Paradigm,
enabling MVAR to achieve 120-hour long-term sequential forecasting.
Additionally, MVAR develops Meteorological Coupled Spatial Transformer block,
enabling the flexible coupling of AI-based meteorological forecasts while
learning the interactions among pollutants and their diverse spatial responses.
As for the lack of standardized datasets in air pollutants forecasting, we
construct a comprehensive dataset covering 6 major pollutants across 75 cities
in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0
forecast data. Experimental results demonstrate that the proposed model
outperforms state-of-the-art methods and validate the effectiveness of the
proposed architecture.

</details>


### [87] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 本文提出3D-MoRe框架，利用基础模型生成大规模高质量3D-语言数据集，并在3D场景问答和指代表达任务上显著超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 室内场景任务（如问答、密集描述）对多样化、可扩展的3D-语言数据需求日益增长。

Method: 3D-MoRe框架集成多模态嵌入、跨模态交互和语言模型解码器，利用基础模型处理自然语言指令和3D场景数据。使用ScanNet、ScanQA和ScanRefer数据，通过数据增强和语义过滤生成了大规模高质量的3D-语言数据集。

Result: 生成了6.2万个问答对和7.3万个物体描述。在ScanQA任务上，CIDEr分数提升2.15%；在ScanRefer任务上，CIDEr@0.5提升1.84%，均显著优于现有SOTA。

Conclusion: 3D-MoRe有效生成了大规模高质量3D-语言数据，并显著提升了3D场景问答和指代表达任务的性能。代码和数据集将开源。

Abstract: With the growing need for diverse and scalable data in indoor scene tasks,
such as question answering and dense captioning, we propose 3D-MoRe, a novel
paradigm designed to generate large-scale 3D-language datasets by leveraging
the strengths of foundational models. The framework integrates key components,
including multi-modal embedding, cross-modal interaction, and a language model
decoder, to process natural language instructions and 3D scene data. This
approach facilitates enhanced reasoning and response generation in complex 3D
environments. Using the ScanNet 3D scene dataset, along with text annotations
from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs
and 73,000 object descriptions across 1,513 scenes. We also employ various data
augmentation techniques and implement semantic filtering to ensure high-quality
data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms
state-of-the-art baselines, with the CIDEr score improving by 2.15\%.
Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5
by 1.84\%, highlighting its effectiveness in both tasks. Our code and generated
datasets will be publicly released to benefit the community, and both can be
accessed on the https://3D-MoRe.github.io.

</details>


### [88] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc是一种新型定位系统，利用语义信息直接从3D高斯泼溅（3DGS）表示中回归相机姿态，无需初始姿态先验即可实现全局定位。


<details>
  <summary>Details</summary>
Motivation: 现有定位系统常依赖于初始姿态先验。本研究旨在提出一种无需先验姿态信息，能直接从3DGS表示中估计相机6自由度（6DoF）姿态的全局定位方法。

Method: SGLoc通过以下方式实现：1. 引入多级姿态回归策略，逐步估计并细化查询图像的姿态。2. 设计基于语义的全局检索算法，通过匹配2D查询图像与3DGS的语义描述符，建立2D-3D对应关系以获得粗略姿态。3. 通过迭代优化查询图像与3DGS渲染图像之间的差异来细化粗略姿态。

Result: SGLoc在12scenes和7scenes数据集上表现出优于基线的性能，在无需初始姿态先验的全局定位方面展现出卓越能力。

Conclusion: SGLoc成功提出了一种利用语义信息直接从3DGS表示中回归相机姿态的全局定位系统，并在标准数据集上验证了其优越性和无需初始姿态先验的强大功能。

Abstract: We propose SGLoc, a novel localization system that directly regresses camera
poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic
information. Our method utilizes the semantic relationship between 2D image and
3D scene representation to estimate the 6DoF pose without prior pose
information. In this system, we introduce a multi-level pose regression
strategy that progressively estimates and refines the pose of query image from
the global 3DGS map, without requiring initial pose priors. Moreover, we
introduce a semantic-based global retrieval algorithm that establishes
correspondences between 2D (image) and 3D (3DGS map). By matching the extracted
scene semantic descriptors of 2D query image and 3DGS semantic representation,
we align the image with the local region of the global 3DGS map, thereby
obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by
iteratively optimizing the difference between the query image and the rendered
image from 3DGS. Our SGLoc demonstrates superior performance over baselines on
12scenes and 7scenes datasets, showing excellent capabilities in global
localization without initial pose prior. Code will be available at
https://github.com/IRMVLab/SGLoc.

</details>


### [89] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本文提出首个多视图新类发现（NCD）框架IICMVNCD，通过整合视图内和视图间关联，克服了现有NCD方法在处理多视图数据和伪标签不稳定性方面的局限。


<details>
  <summary>Details</summary>
Motivation: 现有新类发现（NCD）方法存在两大局限：1) 主要关注单视图数据，忽略了日益增多的多视图数据；2) 过度依赖伪标签进行监督，导致性能不稳定，对数据噪声和特征维度敏感。

Method: 本文提出名为“视图内和视图间关联引导的多视图新类发现”（IICMVNCD）的框架。在视图内层面，利用矩阵分解将特征分解为共享基矩阵和因子矩阵，以捕捉已知和新类之间的分布一致性及样本间关系。在视图间层面，利用已知类别的视图关系指导新类聚类，通过因子矩阵的加权融合生成预测标签，并基于监督损失动态调整视图权重，然后将这些信息传递给新类学习。

Result: 实验结果验证了本文所提出方法的有效性。

Conclusion: 本文首次探索了多视图新类发现问题，提出的IICMVNCD框架有效解决了现有NCD方法在多视图数据处理和伪标签依赖方面的局限性，并通过实验证明了其有效性。

Abstract: In this paper, we address the problem of novel class discovery (NCD), which
aims to cluster novel classes by leveraging knowledge from disjoint known
classes. While recent advances have made significant progress in this area,
existing NCD methods face two major limitations. First, they primarily focus on
single-view data (e.g., images), overlooking the increasingly common multi-view
data, such as multi-omics datasets used in disease diagnosis. Second, their
reliance on pseudo-labels to supervise novel class clustering often results in
unstable performance, as pseudo-label quality is highly sensitive to factors
such as data noise and feature dimensionality. To address these challenges, we
propose a novel framework named Intra-view and Inter-view Correlation Guided
Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to
explore NCD in multi-view setting so far. Specifically, at the intra-view
level, leveraging the distributional similarity between known and novel
classes, we employ matrix factorization to decompose features into
view-specific shared base matrices and factor matrices. The base matrices
capture distributional consistency among the two datasets, while the factor
matrices model pairwise relationships between samples. At the inter-view level,
we utilize view relationships among known classes to guide the clustering of
novel classes. This includes generating predicted labels through the weighted
fusion of factor matrices and dynamically adjusting view weights of known
classes based on the supervision loss, which are then transferred to novel
class learning. Experimental results validate the effectiveness of our proposed
approach.

</details>


### [90] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: MoViAD是一个全面且高度模块化的库，旨在加速图像异常检测（VAD）领域的研究和部署，提供先进的模型、训练工具和实用功能，并支持多种场景和边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 图像异常检测（VAD）领域面临异常数据稀缺和需要无监督训练的挑战，这限制了该领域的研究进展和实际应用部署。

Method: 引入MoViAD库，该库提供SOTA VAD模型、训练器、数据集和实用工具，支持持续学习、半监督、少样本、噪声数据等多种复杂场景。它还通过提供优化模型、骨干网络、量化和压缩工具来解决边缘和IoT部署的挑战，并集成了鲁棒的像素级/图像级评估指标和效率分析工具。

Result: MoViAD实现了快速、轻松的部署，使机器学习工程师能够便捷地自定义模型、数据集和骨干网络以适应特定设置。同时，它为研究人员提供了开发和实验新方法所需的灵活性和可扩展性。

Conclusion: MoViAD通过提供一个全面、易用且灵活的平台，有效解决了图像异常检测领域研究和部署中的关键挑战，有望加速该领域的创新和实际应用。

Abstract: VAD is a critical field in machine learning focused on identifying deviations
from normal patterns in images, often challenged by the scarcity of anomalous
data and the need for unsupervised training. To accelerate research and
deployment in this domain, we introduce MoViAD, a comprehensive and highly
modular library designed to provide fast and easy access to state-of-the-art
VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array
of scenarios, including continual, semi-supervised, few-shots, noisy, and many
more. In addition, it addresses practical deployment challenges through
dedicated Edge and IoT settings, offering optimized models and backbones, along
with quantization and compression utilities for efficient on-device execution
and distributed inference. MoViAD integrates a selection of backbones, robust
evaluation VAD metrics (pixel-level and image-level) and useful profiling tools
for efficiency analysis. The library is designed for fast, effortless
deployment, enabling machine learning engineers to easily use it for their
specific setup with custom models, datasets, and backbones. At the same time,
it offers the flexibility and extensibility researchers need to develop and
experiment with new methods.

</details>


### [91] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: 本文提出InstructFLIP框架，通过结合视觉语言模型和指令解耦机制，有效解决了活体检测（FAS）中攻击类型语义理解不足和跨域训练冗余两大挑战，实现了从单域训练到多域泛化的性能提升。


<details>
  <summary>Details</summary>
Motivation: 活体检测（FAS）在构建鲁棒系统以应对多样化攻击时面临两大挑战：一是攻击类型的语义理解有限；二是跨域训练存在冗余。

Method: 本文提出InstructFLIP，一个新颖的指令调优框架。该框架利用视觉语言模型（VLMs）增强视觉输入感知，并通过文本指导提升泛化能力。它采用元域策略学习统一模型，并明确将指令解耦为内容（关注欺骗语义）和风格（关注环境与相机特征）两部分，仅通过单域训练实现跨域泛化。

Result: InstructFLIP在活体检测（FAS）的广泛实验中表现出色，超越了现有SOTA模型的准确性，并显著减少了跨域训练冗余。

Conclusion: InstructFLIP框架通过集成视觉语言模型和创新的指令解耦策略，有效提升了活体检测系统的跨域泛化能力，并大幅提高了训练效率，为构建更鲁棒的活体检测系统提供了新思路。

Abstract: Face anti-spoofing (FAS) aims to construct a robust system that can withstand
diverse attacks. While recent efforts have concentrated mainly on cross-domain
generalization, two significant challenges persist: limited semantic
understanding of attack types and training redundancy across domains. We
address the first by integrating vision-language models (VLMs) to enhance the
perception of visual input. For the second challenge, we employ a meta-domain
strategy to learn a unified model that generalizes well across multiple
domains. Our proposed InstructFLIP is a novel instruction-tuned framework that
leverages VLMs to enhance generalization via textual guidance trained solely on
a single domain. At its core, InstructFLIP explicitly decouples instructions
into content and style components, where content-based instructions focus on
the essential semantics of spoofing, and style-based instructions consider
variations related to the environment and camera characteristics. Extensive
experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA
models in accuracy and substantially reducing training redundancy across
diverse domains in FAS. Project website is available at
https://kunkunlin1221.github.io/InstructFLIP.

</details>


### [92] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: 本文提出MS-DETR框架，通过统一学习捕捉运动-语义特征，并结合生成策略和对比去噪学习解决数据稀疏性问题，显著提升视频矩（Video Moment Retrieval, MR）和高光检测（Highlight Detection, HD）任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于DETR的联合框架在MR/HD任务中取得了显著进展，但视频内容中时间运动与空间语义之间复杂关系的潜力尚未被充分利用。此外，MR/HD数据集在运动和语义维度上存在固有的稀疏性问题。

Method: 提出Motion-Semantics DETR (MS-DETR) 框架。编码器在文本查询引导下，显式建模运动和语义维度内解耦的模态内关联；解码器利用跨时间运动和空间语义维度的任务相关性，实现精确的查询引导定位和高光边界划分。为解决数据稀疏性，通过生成策略丰富语料，并引入对比去噪学习以确保组件学习的鲁棒性和有效性。

Result: 在四个MR/HD基准数据集上的广泛实验表明，所提方法优于现有最先进模型，并取得了显著提升。

Conclusion: MS-DETR通过有效整合运动与语义特征，并解决数据稀疏性问题，在视频矩检索和高光检测任务中实现了卓越的性能。

Abstract: Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint
specific moments and assess clip-wise relevance based on the text query. While
DETR-based joint frameworks have made significant strides, there remains
untapped potential in harnessing the intricate relationships between temporal
motion and spatial semantics within video content. In this paper, we propose
the Motion-Semantics DETR (MS-DETR), a framework that captures rich
motion-semantics features through unified learning for MR/HD tasks. The encoder
first explicitly models disentangled intra-modal correlations within motion and
semantics dimensions, guided by the given text queries. Subsequently, the
decoder utilizes the task-wise correlation across temporal motion and spatial
semantics dimensions to enable precise query-guided localization for MR and
refined highlight boundary delineation for HD. Furthermore, we observe the
inherent sparsity dilemma within the motion and semantics dimensions of MR/HD
datasets. To address this issue, we enrich the corpus from both dimensions by
generation strategies and propose contrastive denoising learning to ensure the
above components learn robustly and effectively. Extensive experiments on four
MR/HD benchmarks demonstrate that our method outperforms existing
state-of-the-art models by a margin. Our code is available at
https://github.com/snailma0229/MS-DETR.git.

</details>


### [93] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 自动驾驶运动预测新方法，通过逆强化学习（IRL）先推理交通参与者意图，再结合分层解码器进行轨迹预测，显著提升预测置信度和性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，交通代理的运动预测对安全至关重要且极具挑战。传统数据驱动方法直接预测轨迹，缺乏对行为意图的显式考虑。本文旨在从规划视角重新思考该任务，倡导“先推理，再预测”策略，将行为意图作为空间引导融入轨迹预测。

Method: 1. 提出“先推理，再预测”策略。2. 引入基于新型查询中心逆强化学习（IRL）的意图推理器，通过奖励分布获取目标行为意图。3. 将交通代理和场景元素编码为统一矢量表示，聚合上下文特征。4. 利用奖励启发式推演多种合理意图，作为轨迹生成的先验。5. 开发分层DETR-like解码器，集成双向选择性状态空间模型，生成准确轨迹及其概率。

Result: 在Argoverse和nuScenes数据集上，本方法显著增强了轨迹预测的置信度，并取得了与现有最先进方法高度竞争的性能。

Conclusion: 通过引入意图推理和分层轨迹生成的“先推理，再预测”策略，本文方法在自动驾驶运动预测任务中显著提升了预测置信度和性能，为系统安全提供了关键支持。

Abstract: Motion forecasting for on-road traffic agents presents both a significant
challenge and a critical necessity for ensuring safety in autonomous driving
systems. In contrast to most existing data-driven approaches that directly
predict future trajectories, we rethink this task from a planning perspective,
advocating a "First Reasoning, Then Forecasting" strategy that explicitly
incorporates behavior intentions as spatial guidance for trajectory prediction.
To achieve this, we introduce an interpretable, reward-driven intention
reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)
scheme. Our method first encodes traffic agents and scene elements into a
unified vectorized representation, then aggregates contextual features through
a query-centric paradigm. This enables the derivation of a reward distribution,
a compact yet informative representation of the target agent's behavior within
the given scene context via IRL. Guided by this reward heuristic, we perform
policy rollouts to reason about multiple plausible intentions, providing
valuable priors for subsequent trajectory generation. Finally, we develop a
hierarchical DETR-like decoder integrated with bidirectional selective state
space models to produce accurate future trajectories along with their
associated probabilities. Extensive experiments on the large-scale Argoverse
and nuScenes motion forecasting datasets demonstrate that our approach
significantly enhances trajectory prediction confidence, achieving highly
competitive performance relative to state-of-the-art methods.

</details>


### [94] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 本文提出了针对无人机视角下小而敏捷的多目标（SMOT）跟踪的冠军级解决方案。该方案采用“检测-跟踪”范式，通过“SliceTrain”提升小目标检测，并结合运动方向保持（EMA）和自适应相似度度量的跟踪器，实现了不依赖外观信息的鲁棒目标关联，在SMOT4SB挑战赛中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 从无人机视角跟踪小而敏捷的多目标（如鸟类）是一个极具挑战性的计算机视觉任务。主要难点在于：目标外观特征极度稀缺、相机与目标自身动态结合导致的复杂运动纠缠，以及密集集群行为带来的频繁遮挡和身份模糊。

Method: 该方案采用“检测-跟踪”（tracking-by-detection）范式，并在检测和关联两个层面进行了创新：
1.  **检测方面：** 提出了名为“SliceTrain”的系统化训练增强框架。该框架通过“确定性全覆盖切片”和“切片级随机增强”的协同作用，有效解决了高分辨率图像训练中小目标学习不足的问题。
2.  **跟踪方面：** 设计了一个完全不依赖外观信息的鲁棒跟踪器。该跟踪器在OC-SORT框架中集成了“运动方向保持（EMA）”机制和结合“边界框扩展”与“距离惩罚”的“自适应相似度度量”，以稳定处理不规则运动并维护目标身份。

Result: 该方法在MVA 2025“Finding Birds”小多目标跟踪挑战赛（SMOT4SB）中获得了冠军，并在SMOT4SB公共测试集上取得了最先进的性能，SO-HOTA得分达到55.205。

Conclusion: 该框架在SMOT4SB挑战赛中取得的最先进性能，充分验证了其在解决复杂实际世界小多目标跟踪（SMOT）问题上的有效性和先进性，为无人机视角下的微小目标跟踪提供了强有力的解决方案。

Abstract: Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned
Aerial Vehicle (UAV) perspective is a highly challenging computer vision task.
The difficulty stems from three main sources: the extreme scarcity of target
appearance features, the complex motion entanglement caused by the combined
dynamics of the camera and the targets themselves, and the frequent occlusions
and identity ambiguity arising from dense flocking behavior. This paper details
our championship-winning solution in the MVA 2025 "Finding Birds" Small
Multi-Object Tracking Challenge (SMOT4SB), which adopts the
tracking-by-detection paradigm with targeted innovations at both the detection
and association levels. On the detection side, we propose a systematic training
enhancement framework named \textbf{SliceTrain}. This framework, through the
synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic
augmentation, effectively addresses the problem of insufficient learning for
small objects in high-resolution image training. On the tracking side, we
designed a robust tracker that is completely independent of appearance
information. By integrating a \textbf{motion direction maintenance (EMA)}
mechanism and an \textbf{adaptive similarity metric} combining \textbf{bounding
box expansion and distance penalty} into the OC-SORT framework, our tracker can
stably handle irregular motion and maintain target identities. Our method
achieves state-of-the-art performance on the SMOT4SB public test set, reaching
an SO-HOTA score of \textbf{55.205}, which fully validates the effectiveness
and advancement of our framework in solving complex real-world SMOT problems.
The source code will be made available at
https://github.com/Salvatore-Love/YOLOv8-SMOT.

</details>


### [95] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 针对现有车辆3D重建方法对密集视图的依赖，本文提出了一种基于深度图和增强型Gaussian Splatting的稀疏视图车辆3D重建方法，并在新数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有车辆3D重建方法（如Neural Radiance Fields和Gaussian Splatting）需要密集的输入视图，这限制了其在实际应用中的可行性。因此，需要开发能够从稀疏视图输入进行高质量车辆重建的方法。

Method: 本文利用深度图和DUSt3R姿态估计算法合成新视图并扩充训练数据，以解决稀疏视图重建问题。具体而言，通过整合选择性光度损失来增强Gaussian Splatting，并用DUSt3R取代标准SfM流程以改进相机姿态估计。此外，还提出了一个新的包含合成和真实世界公共交通车辆的数据集。

Result: 实验结果表明，该方法在多个基准测试中取得了最先进的性能，即使在输入条件受限的情况下也能实现高质量的车辆3D重建。

Conclusion: 本文提出的方法有效解决了稀疏视图下车辆3D重建的挑战，通过技术创新实现了行业领先的重建质量，证明了其在实际应用中的巨大潜力。

Abstract: Accurate 3D reconstruction of vehicles is vital for applications such as
vehicle inspection, predictive maintenance, and urban planning. Existing
methods like Neural Radiance Fields and Gaussian Splatting have shown
impressive results but remain limited by their reliance on dense input views,
which hinders real-world applicability. This paper addresses the challenge of
reconstructing vehicles from sparse-view inputs, leveraging depth maps and a
robust pose estimation architecture to synthesize novel views and augment
training data. Specifically, we enhance Gaussian Splatting by integrating a
selective photometric loss, applied only to high-confidence pixels, and
replacing standard Structure-from-Motion pipelines with the DUSt3R architecture
to improve camera pose estimation. Furthermore, we present a novel dataset
featuring both synthetic and real-world public transportation vehicles,
enabling extensive evaluation of our approach. Experimental results demonstrate
state-of-the-art performance across multiple benchmarks, showcasing the
method's ability to achieve high-quality reconstructions even under constrained
input conditions.

</details>


### [96] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 针对热浪下路径规划缺乏阴影信息问题，本文构建了一个大规模阴影数据集并提出基于扩散模型的DeepShade，能够准确预测并生成阴影图像，为城市规划和路径优化提供支持。


<details>
  <summary>Details</summary>
Motivation: 全球变暖导致热浪对公众健康构成严重威胁。现有路径规划系统（如在线地图）因难以从噪声卫星图像中直接估计阴影且生成模型缺乏训练数据，未能整合阴影信息。

Method: 1. 构建大规模阴影数据集：利用Blender 3D模拟结合建筑轮廓，捕捉全年不同时段、不同太阳天顶角下的阴影，并与卫星图像对齐。2. 提出DeepShade模型：这是一个基于扩散的模型，用于学习和合成随时间变化的阴影。它结合RGB和Canny边缘层以强调边缘特征，并融入对比学习以捕捉阴影时间变化规则。模型可根据文本描述（如时间、太阳角度）进行条件化生成。

Result: 通过将预测的阴影应用于亚利桑那州坦佩市的实际路线规划，计算阴影覆盖率，验证了所提方法的实用性。

Conclusion: 该工作有望为极端高温天气下的城市规划提供参考，并在环境保护领域具有潜在的实际应用价值，从而造福社会。

Abstract: Heatwaves pose a significant threat to public health, especially as global
warming intensifies. However, current routing systems (e.g., online maps) fail
to incorporate shade information due to the difficulty of estimating shades
directly from noisy satellite imagery and the limited availability of training
data for generative models. In this paper, we address these challenges through
two main contributions. First, we build an extensive dataset covering diverse
longitude-latitude regions, varying levels of building density, and different
urban layouts. Leveraging Blender-based 3D simulations alongside building
outlines, we capture building shadows under various solar zenith angles
throughout the year and at different times of day. These simulated shadows are
aligned with satellite images, providing a rich resource for learning shade
patterns. Second, we propose the DeepShade, a diffusion-based model designed to
learn and synthesize shade variations over time. It emphasizes the nuance of
edge features by jointly considering RGB with the Canny edge layer, and
incorporates contrastive learning to capture the temporal change rules of
shade. Then, by conditioning on textual descriptions of known conditions (e.g.,
time of day, solar angles), our framework provides improved performance in
generating shade images. We demonstrate the utility of our approach by using
our shade predictions to calculate shade ratios for real-world route planning
in Tempe, Arizona. We believe this work will benefit society by providing a
reference for urban planning in extreme heat weather and its potential
practical applications in the environment.

</details>


### [97] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入域外(OoD)数据监督，解决了生物医学分割网络在有限数据上的误分类问题，无需额外资源，并提出了一种仅用OoD数据训练的新范式，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 生物医学分割网络在有限和不完善的医疗数据集上学习时，容易出现前景和背景对象之间的意外错误分类。

Method: 提出一个以数据为中心的框架Med-OoD，通过将域外（OoD）数据监督引入全监督生物医学分割中来解决上述问题。该方法无需外部数据源、特征正则化目标或额外标注，并且可以无缝集成到现有分割网络中，无需修改网络架构。

Result: 广泛的实验表明，Med-OoD显著防止了各种分割网络在医疗图像上出现像素误分类，并在Lizard数据集上取得了显著的性能提升。此外，还展示了一种新兴的学习范式：完全使用不含前景类标签的OoD数据训练医疗分割网络，令人惊讶地获得了76.1%的mIoU测试结果。

Conclusion: Med-OoD框架有效解决了生物医学图像分割中的误分类问题，并提供了一种强大的、无需额外标注的解决方案。研究所提出的仅使用OoD数据进行训练的学习范式，有望促使人们重新思考OoD数据在医疗图像分析中的潜在作用和重要性。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [98] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 本文提出一种非自适应方法，利用人脸识别系统（FRSs）的特征空间结构生成对抗性人脸，以极少的查询次数实现对目标身份的高成功率冒充，对FRSs构成严重安全威胁。


<details>
  <summary>Details</summary>
Motivation: 对抗性攻击对人脸识别系统（FRSs）构成严重的安全性与隐私威胁，特别是在身份验证场景中，亟需开发新型攻击方法来评估其脆弱性。

Method: 本研究提出一种生成对抗性人脸的新方法，不同于传统的迭代优化方法。该方法利用FRSs特征空间的结构特性，发现共享相同属性（如性别、种族）的个体形成“属性子空间”。通过利用这些子空间，实现非自适应攻击，并显著减少查询次数，避免对迁移性和开源代理模型的依赖。

Result: 仅需一次包含100张人脸图像的非自适应查询，该方法在AWS的CompareFaces API上成功率超过93%。此外，与现有多数攻击不同，该方法能生成具有攻击者选定高层属性的对抗性人脸，而非仅仅扰动给定图像。

Conclusion: 该方法证明了在极低查询次数下高效生成对抗性人脸的能力，通过利用FRSs特征空间结构，克服了现有攻击对迁移性和多次查询的依赖，揭示了人脸识别系统面临的严重安全挑战。

Abstract: Adversarial attacks on face recognition systems (FRSs) pose serious security
and privacy threats, especially when these systems are used for identity
verification. In this paper, we propose a novel method for generating
adversarial faces-synthetic facial images that are visually distinct yet
recognized as a target identity by the FRS. Unlike iterative optimization-based
approaches (e.g., gradient descent or other iterative solvers), our method
leverages the structural characteristics of the FRS feature space. We figure
out that individuals sharing the same attribute (e.g., gender or race) form an
attributed subsphere. By utilizing such subspheres, our method achieves both
non-adaptiveness and a remarkably small number of queries. This eliminates the
need for relying on transferability and open-source surrogate models, which
have been a typical strategy when repeated adaptive queries to commercial FRSs
are impossible. Despite requiring only a single non-adaptive query consisting
of 100 face images, our method achieves a high success rate of over 93% against
AWS's CompareFaces API at its default threshold. Furthermore, unlike many
existing attacks that perturb a given image, our method can deliberately
produce adversarial faces that impersonate the target identity while exhibiting
high-level attributes chosen by the adversary.

</details>


### [99] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter：一种单步扩散模型，能从稀疏LiDAR数据和受损渲染中实时恢复一致的驾驶场景视图，且性能和效率优于现有方法，支持风格化生成。


<details>
  <summary>Details</summary>
Motivation: 动态驾驶场景重建在数字孪生和自动驾驶模拟中至关重要，但现有方法在视角偏离输入轨迹时会产生背景和车辆模型损坏等问题，且存在不一致性、变形和耗时等局限性。

Method: 本文提出LidarPainter，一个单步扩散模型。该模型能从稀疏LiDAR条件和存在伪影的渲染中恢复一致的驾驶视图，实时实现高保真车道变换的驾驶场景重建。

Result: 实验证明LidarPainter在速度、质量和资源效率上均优于现有先进方法，具体表现为比StreetCrafter快7倍，且仅需其五分之一的GPU内存。LidarPainter还支持使用文本提示（如“foggy”、“night”）进行风格化生成，丰富了现有资产库。

Conclusion: LidarPainter通过其高效的单步扩散模型，有效解决了动态驾驶场景重建中现有方法存在的视图不一致、变形和效率低等问题，显著提升了新轨迹下的重建质量和速度，并拓展了场景风格化能力，为数字孪生和自动驾驶模拟提供了高性能解决方案。

Abstract: Dynamic driving scene reconstruction is of great importance in fields like
digital twin system and autonomous driving simulation. However, unacceptable
degradation occurs when the view deviates from the input trajectory, leading to
corrupted background and vehicle models. To improve reconstruction quality on
novel trajectory, existing methods are subject to various limitations including
inconsistency, deformation, and time consumption. This paper proposes
LidarPainter, a one-step diffusion model that recovers consistent driving views
from sparse LiDAR condition and artifact-corrupted renderings in real-time,
enabling high-fidelity lane shifts in driving scene reconstruction. Extensive
experiments show that LidarPainter outperforms state-of-the-art methods in
speed, quality and resource efficiency, specifically 7 x faster than
StreetCrafter with only one fifth of GPU memory required. LidarPainter also
supports stylized generation using text prompts such as "foggy" and "night",
allowing for a diverse expansion of the existing asset library.

</details>


### [100] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: 该论文提出OVIGo-3DHSG方法，利用3D分层场景图和大型语言模型实现室内开放词汇对象定位，并在空间推理和场景理解方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理涉及复杂空间查询和理解室内环境中分层空间关系时可能存在不足。研究旨在解决室内环境中开放词汇对象定位、高效场景理解及鲁棒空间推理的挑战。

Method: OVIGo-3DHSG方法利用开放词汇基础模型和传感器数据处理，从RGB-D帧序列构建3D分层场景图，明确建模楼层、房间、位置和对象之间的空间关系。为处理涉及对象空间引用的复杂查询，该方法将分层场景图与大型语言模型（LLM）集成，以实现多步推理，并利用层间和层内连接增强空间上下文理解。

Result: 在Habitat Matterport 3D Semantic多层场景上进行的实验表明，该方法在语义和几何精度方面表现出高效的场景理解能力和鲁棒的对象定位能力，优于现有方法。

Conclusion: OVIGo-3DHSG方法在需要室内空间推理和理解的应用中展现出强大的潜力。

Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects
using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor
environment over a Hierarchical Scene Graph derived from sequences of RGB-D
frames utilizing a set of open-vocabulary foundation models and sensor data
processing. The hierarchical representation explicitly models spatial relations
across floors, rooms, locations, and objects. To effectively address complex
queries involving spatial reference to other objects, we integrate the
hierarchical scene graph with a Large Language Model for multistep reasoning.
This integration leverages inter-layer (e.g., room-to-object) and intra-layer
(e.g., object-to-object) connections, enhancing spatial contextual
understanding. We investigate the semantic and geometry accuracy of
hierarchical representation on Habitat Matterport 3D Semantic multi-floor
scenes. Our approach demonstrates efficient scene comprehension and robust
object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates
strong potential for applications requiring spatial reasoning and understanding
of indoor environments. Related materials can be found at
https://github.com/linukc/OVIGo-3DHSG.

</details>


### [101] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: 本文提出BSPF-ViT，通过块级对称剪枝与融合策略，联合优化Q/K token，解决了ViT的高计算成本问题，显著提升了效率和精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer (ViT) 计算成本高昂（O(n^2)），限制了其实际应用。现有剪枝方法通过独立剪枝查询（Q）和键（K）token来降低复杂度，但往往忽略token间的交互，导致精度下降。

Method: 引入了块级对称剪枝与融合（BSPF-ViT）方法：1. 联合优化Q/K token的剪枝。2. 评估每个token及其邻居，考虑token交互以决定保留哪些token。3. 通过相似性融合步骤压缩保留的token。4. 利用Q/K token共享权重形成的对称注意力矩阵，仅剪枝上三角部分以加速。

Result: BSPF-ViT在所有剪枝级别上均优于现有最先进的ViT方法，ImageNet分类精度在DeiT-T上提高1.3%，在DeiT-S上提高2.0%，同时计算开销降低50%。在各种ViT模型上实现了40%的加速并提升了精度。

Conclusion: BSPF-ViT通过创新的联合剪枝和融合策略，有效解决了ViT的计算效率瓶颈，在大幅降低计算成本的同时，显著提升了模型性能，为高效ViT的实际应用提供了新的方向。

Abstract: Vision Transformer (ViT) has achieved impressive results across various
vision tasks, yet its high computational cost limits practical applications.
Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning
unimportant tokens. However, these techniques often sacrifice accuracy by
independently pruning query (Q) and key (K) tokens, leading to performance
degradation due to overlooked token interactions. To address this limitation,
we introduce a novel {\bf Block-based Symmetric Pruning and Fusion} for
efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.
Unlike previous methods that consider only a single direction, our approach
evaluates each token and its neighbors to decide which tokens to retain by
taking token interaction into account. The retained tokens are compressed
through a similarity fusion step, preserving key information while reducing
computational costs. The shared weights of Q/K tokens create a symmetric
attention matrix, allowing pruning only the upper triangular part for speed up.
BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning
levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%
on DeiT-S, while reducing computational overhead by 50%. It achieves 40%
speedup with improved accuracy across various ViTs.

</details>


### [102] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出BPAM框架，结合双边网格与像素自适应多层感知器（MLP），解决图像增强中复杂颜色关系及局部变化建模的挑战，实现了高性能与实时处理。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习双边网格处理方法仅限于线性变换，难以建模复杂颜色关系；传统MLP方法采用全局共享参数，难以处理局部变化。

Method: 提出双边网格像素自适应MLP（BPAM）框架，融合双边网格的空间建模能力与MLP的非线性映射能力。具体方法是生成包含MLP参数的双边网格，使每个像素根据空间坐标和强度值动态获取独特的MLP进行颜色映射。此外，提出一种新颖的网格分解策略，将MLP参数分类存储于独立的子网格中，并利用多通道引导图精确提取对应参数。

Result: 在公共数据集上的实验表明，BPAM方法在性能上优于现有先进方法，并同时保持了实时处理能力。

Conclusion: BPAM框架通过结合双边网格和像素自适应MLP，有效解决了图像增强领域中复杂颜色关系和局部变化的建模难题，实现了卓越的图像增强效果，并具备实用性。

Abstract: Deep learning-based bilateral grid processing has emerged as a promising
solution for image enhancement, inherently encoding spatial and intensity
information while enabling efficient full-resolution processing through slicing
operations. However, existing approaches are limited to linear affine
transformations, hindering their ability to model complex color relationships.
Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,
traditional MLP-based methods employ globally shared parameters, which is hard
to deal with localized variations. To overcome these dual challenges, we
propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)
framework. Our approach synergizes the spatial modeling of bilateral grids with
the non-linear capabilities of MLPs. Specifically, we generate bilateral grids
containing MLP parameters, where each pixel dynamically retrieves its unique
transformation parameters and obtain a distinct MLP for color mapping based on
spatial coordinates and intensity values. In addition, we propose a novel grid
decomposition strategy that categorizes MLP parameters into distinct types
stored in separate subgrids. Multi-channel guidance maps are used to extract
category-specific parameters from corresponding subgrids, ensuring effective
utilization of color information during slicing while guiding precise parameter
generation. Extensive experiments on public datasets demonstrate that our
method outperforms state-of-the-art methods in performance while maintaining
real-time processing capabilities.

</details>


### [103] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: AD-GS是一个新颖的自监督框架，用于高质量渲染动态城市驾驶场景。它通过创新的运动模型、自动场景分割和动态高斯表示，无需手动标注即可实现高精度渲染，性能超越现有无标注方法，并可与依赖标注的方法媲美。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶模拟急需动态城市驾驶场景的高质量渲染。现有高质量方法通常依赖昂贵的手动物体轨迹标注，而自监督方法则无法准确捕获动态物体运动并正确分解场景，导致渲染伪影。

Method: 本文提出AD-GS，一个新颖的自监督框架，用于从单一日志中进行高质量的驾驶场景自由视角渲染。其核心是一个可学习的运动模型，该模型结合了局部感知B样条曲线和全局感知三角函数，从而实现灵活而精确的动态物体建模。AD-GS无需全面的语义标注，而是通过简化的伪2D分割自动将场景分割为物体和背景，并使用动态高斯和双向时间可见性掩码来表示物体。此外，该模型还整合了可见性推理和物理刚性正则化以增强鲁棒性。

Result: 广泛的评估表明，我们提出的无标注模型AD-GS显著优于当前最先进的无标注方法，并且与依赖标注的方法具有竞争力。

Conclusion: AD-GS提供了一种高效、高质量且无需标注的动态城市场景渲染解决方案，有效解决了当前方法的局限性，在性能上表现出色，对自动驾驶模拟具有重要意义。

Abstract: Modeling and rendering dynamic urban driving scenes is crucial for
self-driving simulation. Current high-quality methods typically rely on costly
manual object tracklet annotations, while self-supervised approaches fail to
capture dynamic object motions accurately and decompose scenes properly,
resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised
framework for high-quality free-viewpoint rendering of driving scenes from a
single log. At its core is a novel learnable motion model that integrates
locality-aware B-spline curves with global-aware trigonometric functions,
enabling flexible yet precise dynamic object modeling. Rather than requiring
comprehensive semantic labeling, AD-GS automatically segments scenes into
objects and background with the simplified pseudo 2D segmentation, representing
objects using dynamic Gaussians and bidirectional temporal visibility masks.
Further, our model incorporates visibility reasoning and physically rigid
regularization to enhance robustness. Extensive evaluations demonstrate that
our annotation-free model significantly outperforms current state-of-the-art
annotation-free methods and is competitive with annotation-dependent
approaches.

</details>


### [104] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 本文提出一种基于归一化流的、数据驱动的人体姿态神经先验建模方法，利用RealNVP学习6D旋转姿态的灵活密度，并通过逆Gram-Schmidt过程解决流形建模挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态先验模型多为启发式或表达能力有限，缺乏一种基于数据驱动且具有高表达能力的原则性方法。

Method: 利用RealNVP归一化流建模人体姿态（以6D旋转格式表示）的灵活密度。通过在训练过程中逆转Gram-Schmidt过程，解决了在有效6D旋转流形上建模分布的挑战，确保了学习的稳定性并保持了与现有旋转框架的兼容性。该方法架构和训练流程具备框架无关性且易于复现。

Result: 通过定性和定量评估证明了所学姿态先验的有效性，并通过消融研究分析了其影响。

Conclusion: 本工作为将姿态先验整合到人体运动捕捉和重建流程中提供了坚实的概率基础。

Abstract: We introduce a principled, data-driven approach for modeling a neural prior
over human body poses using normalizing flows. Unlike heuristic or
low-expressivity alternatives, our method leverages RealNVP to learn a flexible
density over poses represented in the 6D rotation format. We address the
challenge of modeling distributions on the manifold of valid 6D rotations by
inverting the Gram-Schmidt process during training, enabling stable learning
while preserving downstream compatibility with rotation-based frameworks. Our
architecture and training pipeline are framework-agnostic and easily
reproducible. We demonstrate the effectiveness of the learned prior through
both qualitative and quantitative evaluations, and we analyze its impact via
ablation studies. This work provides a sound probabilistic foundation for
integrating pose priors into human motion capture and reconstruction pipelines.

</details>


### [105] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为TGDA的训练框架，用于细粒度图像识别（FGIR）。TGDA允许从头开始训练高性能模型，从而摆脱对大规模预训练的依赖，并在效率更高的情况下达到或超越现有先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的细粒度图像识别（FGIR）方法严重依赖在大型数据集上预训练的模型。这种依赖限制了它们在资源受限环境中的适应性，并阻碍了针对FGIR独特挑战的任务特定架构的开发。

Method: 作者提出了一个新的训练框架TGDA。TGDA通过知识蒸馏，将数据感知增强与细粒度感知教师模型提供的弱监督相结合。该框架支持设计任务特定和硬件感知的架构，例如用于低分辨率FGIR的LRNets和高效推理的ViTFS系列模型。

Result: 在三个FGIR基准测试上的广泛实验表明，TGDA方法始终能达到或超越现有最先进的预训练方法。特别是在低分辨率设置下，使用TGDA训练的LRNets相比现有方法准确率提高了高达23%，同时参数减少了20.6倍，FLOPs更低，且所需训练数据显著减少。ViTFS-T则能与在ImageNet-21k上预训练的ViT B-16模型性能匹配，但可训练参数减少了15.3倍，所需数据量也显著减少。

Conclusion: 研究结果表明，TGDA作为预训练的一种适应性替代方案具有巨大潜力，为开发更高效的细粒度视觉系统铺平了道路。

Abstract: Fine-grained image recognition (FGIR) aims to distinguish visually similar
sub-categories within a broader class, such as identifying bird species. While
most existing FGIR methods rely on backbones pretrained on large-scale datasets
like ImageNet, this dependence limits adaptability to resource-constrained
environments and hinders the development of task-specific architectures
tailored to the unique challenges of FGIR.
  In this work, we challenge the conventional reliance on pretrained models by
demonstrating that high-performance FGIR systems can be trained entirely from
scratch. We introduce a novel training framework, TGDA, that integrates
data-aware augmentation with weak supervision via a fine-grained-aware teacher
model, implemented through knowledge distillation. This framework unlocks the
design of task-specific and hardware-aware architectures, including LRNets for
low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for
efficient inference.
  Extensive experiments across three FGIR benchmarks over diverse settings
involving low-resolution and high-resolution inputs show that our method
consistently matches or surpasses state-of-the-art pretrained counterparts. In
particular, in the low-resolution setting, LRNets trained with TGDA improve
accuracy by up to 23\% over prior methods while requiring up to 20.6x less
parameters, lower FLOPs, and significantly less training data. Similarly,
ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k
while using 15.3x fewer trainable parameters and requiring orders of magnitudes
less data. These results highlight TGDA's potential as an adaptable alternative
to pretraining, paving the way for more efficient fine-grained vision systems.

</details>


### [106] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的双集成框架，结合集成预训练深度学习模型进行特征提取和集成微调机器学习模型进行分类，以提高脑部MRI肿瘤诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 磁共振成像（MRI）是检测肿瘤的可靠工具，但人工评估易受疲劳、专业知识不足和图像细节限制等因素影响，导致诊断错误。因此，需要提高诊断精度。

Method: 该研究提出一个双集成框架：首先，利用多种预训练深度卷积神经网络和视觉Transformer网络（通过迁移学习）提取MRI图像的深层特征；其次，通过微调机器学习分类器的超参数进行有效分类。方法还包括广泛的预处理和数据增强，并使用三个公开的Kaggle MRI脑肿瘤数据集进行实验和消融研究。

Result: 实验结果表明，所提出的特征融合和分类器融合方法优于现有技术，并且超参数微调相较于集成方法提供了显著的性能提升。消融研究也展示了各组件对准确分类的贡献。

Conclusion: 所提出的双集成框架，特别是结合超参数微调，显著提高了脑部MRI肿瘤的分类准确性，有效克服了人工诊断的局限性。

Abstract: Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable
tool for detecting tumors due to its capability to produce detailed images that
reveal their presence. However, the accuracy of diagnosis can be compromised
when human specialists evaluate these images. Factors such as fatigue, limited
expertise, and insufficient image detail can lead to errors. For example, small
tumors might go unnoticed, or overlap with healthy brain regions could result
in misidentification. To address these challenges and enhance diagnostic
precision, this study proposes a novel double ensembling framework, consisting
of ensembled pre-trained deep learning (DL) models for feature extraction and
ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently
classify brain tumors. Specifically, our method includes extensive
preprocessing and augmentation, transfer learning concepts by utilizing various
pre-trained deep convolutional neural networks and vision transformer networks
to extract deep features from brain MRI, and fine-tune hyperparameters of ML
classifiers. Our experiments utilized three different publicly available Kaggle
MRI brain tumor datasets to evaluate the pre-trained DL feature extractor
models, ML classifiers, and the effectiveness of an ensemble of deep features
along with an ensemble of ML classifiers for brain tumor classification. Our
results indicate that the proposed feature fusion and classifier fusion improve
upon the state of the art, with hyperparameter fine-tuning providing a
significant enhancement over the ensemble method. Additionally, we present an
ablation study to illustrate how each component contributes to accurate brain
tumor classification.

</details>


### [107] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 本文提出一种基于小波变换的低光立体图像增强方法，通过特征空间解耦将光照调整与纹理增强分离处理，并利用高频引导的跨视角交互和注意力机制提升增强效果。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法将所有退化因素编码在单一潜在空间，导致特征高度纠缠、黑盒特性强，且模型易产生捷径学习。

Method: 该方法利用小波变换将特征空间解耦为低频分支（用于光照调整）和高频分支（用于纹理增强）。为利用立体图像信息，提出了高频引导的跨视角交互模块（HF-CIM），在高频分支中提取另一视图的细节。此外，还提出了基于交叉注意力机制的细节和纹理增强模块（DTEM），以增强高频信息。模型在包含均匀和非均匀光照图像的数据集上进行训练。

Result: 在真实和合成图像上的实验结果表明，所提出的算法在光照调整方面具有显著优势，并能有效恢复高频信息。

Conclusion: 通过小波变换实现特征空间解耦，并结合立体视觉信息进行跨视角交互，本方法成功解决了低光图像复杂退化的问题，在光照调整和高频信息恢复方面表现出色。

Abstract: Low-light images suffer from complex degradation, and existing enhancement
methods often encode all degradation factors within a single latent space. This
leads to highly entangled features and strong black-box characteristics, making
the model prone to shortcut learning. To mitigate the above issues, this paper
proposes a wavelet-based low-light stereo image enhancement method with feature
space decoupling. Our insight comes from the following findings: (1) Wavelet
transform enables the independent processing of low-frequency and
high-frequency information. (2) Illumination adjustment can be achieved by
adjusting the low-frequency component of a low-light image, extracted through
multi-level wavelet decomposition. Thus, by using wavelet transform the feature
space is decomposed into a low-frequency branch for illumination adjustment and
multiple high-frequency branches for texture enhancement. Additionally, stereo
low-light image enhancement can extract useful cues from another view to
improve enhancement. To this end, we propose a novel high-frequency guided
cross-view interaction module (HF-CIM) that operates within high-frequency
branches rather than across the entire feature space, effectively extracting
valuable image details from the other view. Furthermore, to enhance the
high-frequency information, a detail and texture enhancement module (DTEM) is
proposed based on cross-attention mechanism. The model is trained on a dataset
consisting of images with uniform illumination and images with non-uniform
illumination. Experimental results on both real and synthetic images indicate
that our algorithm offers significant advantages in light adjustment while
effectively recovering high-frequency information. The code and dataset are
publicly available at: https://github.com/Cherisherr/WDCI-Net.git.

</details>


### [108] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 本研究提出三种创新数字化技术（分形卷积、自敏感瓦片填充、马赛克切片及超分辨率），用于印度文化遗产的保护与修复，旨在实现高效、美观且经济的自动化修复，同时平衡传统与创新。


<details>
  <summary>Details</summary>
Motivation: 数字化方法（机器学习、深度学习、计算机视觉等）已革新文化遗产保护领域，但仍需针对印度古迹（以其建筑技艺和美学吸引力闻名）的特殊性，开发高效且能保持真实性的修复方案，以在传统与创新之间取得平衡。

Method: 本研究提出三种核心技术：1) 分形卷积方法（基于图像处理的分割技术，用于揭示建筑模式）；2) 自敏感瓦片填充（SSTF）方法（专为西孟加拉邦Bankura陶土寺庙设计）；3) 马赛克切片（MosaicSlice）数据增强方法（配合SSTF使用）。此外，还深入探讨了超分辨率策略，以无损质量地提升图像分辨率。方法注重通过自动化和新颖的数据增强策略，实现无缝区域填充和高细节瓦片修复，同时保持真实性并降低成本。

Result: 所提出的方法能够实现无缝的区域填充和高度精细的瓦片修复，同时保持文物的真实性。通过引入自动化和新颖的数据增强策略，这些方法具有成本效益，并显著提升了文化遗产保护的效率和美学卓越性。

Conclusion: 本研究提出的方法有效地平衡了传统与创新，推动了文化遗产保护领域进入一个效率与美学质量前所未有的新时代，为文物保护提供了高效且卓越的解决方案。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [109] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: 针对扩散模型采样中的幻觉问题，本文提出RODS，一种基于优化视角利用损失景观几何线索检测并纠正高风险步骤的方法。RODS在无需重训练和极低额外成本下，显著提升采样保真度和鲁棒性，有效减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在生成建模中表现出色，但其采样过程易受幻觉影响，这通常源于分数近似的不准确性。

Method: 本文将扩散采样重新诠释为优化过程，并引入RODS（Robust Optimization-inspired Diffusion Sampler）。RODS利用损失景观的几何线索来检测和纠正高风险采样步骤，从而实现更平滑的采样轨迹和自适应扰动调整。该方法无需重新训练，且仅带来极小的额外推理成本。

Result: 实验结果显示，RODS在AFHQv2、FFHQ和11k-hands数据集上显著提升了采样保真度和鲁棒性。它能够检测超过70%的幻觉样本并纠正超过25%，同时避免引入新的伪影。

Conclusion: RODS成功地通过优化视角解决了扩散模型采样中的幻觉问题，显著提高了生成样本的质量和模型鲁棒性，且具有高效率和低成本的优势。

Abstract: Diffusion models have achieved state-of-the-art performance in generative
modeling, yet their sampling procedures remain vulnerable to hallucinations,
often stemming from inaccuracies in score approximation. In this work, we
reinterpret diffusion sampling through the lens of optimization and introduce
RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that
detects and corrects high-risk sampling steps using geometric cues from the
loss landscape. RODS enforces smoother sampling trajectories and adaptively
adjusts perturbations, reducing hallucinations without retraining and at
minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands
demonstrate that RODS improves both sampling fidelity and robustness, detecting
over 70% of hallucinated samples and correcting more than 25%, all while
avoiding the introduction of new artifacts.

</details>


### [110] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: 本文提出MGFFD-VLM框架和DD-VQA+数据集，通过整合属性驱动的LoRA、多粒度提示学习和伪造感知训练策略，显著提升了深度伪造VQA的检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造VQA方法未能充分利用人脸质量相关属性，且缺乏有效的伪造感知VLM训练策略，导致其存在局限性。

Method: 扩展VQA数据集以创建DD-VQA+，包含更丰富的属性和样本。提出MGFFD-VLM伪造检测框架，整合了属性驱动的混合LoRA策略、多粒度提示学习、伪造感知训练策略，并通过将分类和分割结果转化为提示来增强分类和可解释性。此外，设计了多种伪造相关的辅助损失。

Result: 实验结果表明，所提出的方法在基于文本的伪造判断和分析方面均超越了现有方法，取得了卓越的准确性。

Conclusion: 论文成功地解决了现有深度伪造VQA方法的局限性，通过提出的MGFFD-VLM框架和DD-VQA+数据集，在深度伪造判断和分析方面取得了优于现有方法的性能，并增强了可解释性。

Abstract: Recent studies have utilized visual large language models (VLMs) to answer
not only "Is this face a forgery?" but also "Why is the face a forgery?" These
studies introduced forgery-related attributes, such as forgery location and
type, to construct deepfake VQA datasets and train VLMs, achieving high
accuracy while providing human-understandable explanatory text descriptions.
However, these methods still have limitations. For example, they do not fully
leverage face quality-related attributes, which are often abnormal in forged
faces, and they lack effective training strategies for forgery-aware VLMs. In
this paper, we extend the VQA dataset to create DD-VQA+, which features a
richer set of attributes and a more diverse range of samples. Furthermore, we
introduce a novel forgery detection framework, MGFFD-VLM, which integrates an
Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual
Large Language Models (VLMs). Additionally, our framework incorporates
Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By
transforming classification and forgery segmentation results into prompts, our
method not only improves forgery classification but also enhances
interpretability. To further boost detection performance, we design multiple
forgery-related auxiliary losses. Experimental results demonstrate that our
approach surpasses existing methods in both text-based forgery judgment and
analysis, achieving superior accuracy.

</details>


### [111] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本研究提出并验证了生成式文本到图像扩散模型在医学影像短语定位中的优越性，特别是在结合领域特定语言模型（如CXR-BERT）微调和引入Bimodal Bias Merging（BBM）后处理技术，实现了显著超越现有判别式方法的零样本定位性能。


<details>
  <summary>Details</summary>
Motivation: 将自然语言短语映射到医学影像区域（短语定位）对于疾病定位具有重要应用潜力，但现有最先进方法主要依赖判别式、自监督对比模型。

Method: ['利用生成式文本到图像扩散模型，通过交叉注意力图实现短语定位。', '证明了用冻结的、领域特定语言模型（如CXR-BERT）微调扩散模型，比领域无关模型表现更优。', '引入了Bimodal Bias Merging (BBM) 这一新型后处理技术，用于对齐文本和图像偏置，以识别高置信度区域，从而精炼交叉注意力图并增强定位精度。']

Result: ['生成式文本到图像扩散模型能够实现优越的零样本短语定位性能。', '使用领域特定语言模型（如CXR-BERT）微调的设置，mIoU分数是当前判别式方法的两倍，表现出显著提升。', 'BBM技术进一步提高了定位准确性。', '研究结果突出了生成模型在短语定位任务中未被充分探索的巨大潜力。']

Conclusion: 本研究确立了生成式方法作为医学影像领域短语定位的更有效范式，为临床实践中更稳健和可解释的应用奠定了基础。

Abstract: Phrase grounding, i.e., mapping natural language phrases to specific image
regions, holds significant potential for disease localization in medical
imaging through clinical reports. While current state-of-the-art methods rely
on discriminative, self-supervised contrastive models, we demonstrate that
generative text-to-image diffusion models, leveraging cross-attention maps, can
achieve superior zero-shot phrase grounding performance. Contrary to prior
assumptions, we show that fine-tuning diffusion models with a frozen,
domain-specific language model, such as CXR-BERT, substantially outperforms
domain-agnostic counterparts. This setup achieves remarkable improvements, with
mIoU scores doubling those of current discriminative methods. These findings
highlight the underexplored potential of generative models for phrase grounding
tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),
a novel post-processing technique that aligns text and image biases to identify
regions of high certainty. BBM refines cross-attention maps, achieving even
greater localization accuracy. Our results establish generative approaches as a
more effective paradigm for phrase grounding in the medical imaging domain,
paving the way for more robust and interpretable applications in clinical
practice. The source code and model weights are available at
https://github.com/Felix-012/generate_to_ground.

</details>


### [112] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 本研究提出了一个用于健美操静态技能时间分割的视频数据集，并报告了基线方法的结果，旨在为健美操技能自动化评估工具的开发迈出第一步。


<details>
  <summary>Details</summary>
Motivation: 健美操中的静态技能评估依赖于难度和保持时长。运动员和裁判需要能从视频中识别等长技能并估计其持续时间的自动化工具。尽管视频理解在动作识别方面研究丰富，但目前还没有专门针对健美操技能时间视频分割问题的研究。

Method: 为推动健美操自动化工具的发展，本研究提出了一个包含运动员表演的静态健美操技能视频数据集。该数据集中每个视频都进行了时间分割标注，以确定各项技能的起止范围。在此基础上，研究报告了解决技能时间分割问题的基线方法的结果。

Result: 研究结果表明，所提出的问题（健美操技能时间分割）是可行的，但仍有改进空间。

Conclusion: 本研究为健美操领域自动化工具的实现提供了初步进展，通过构建特定数据集和验证基线方法的有效性，展示了自动化识别和评估健美操静态技能的潜力。

Abstract: Calisthenics is a fast-growing bodyweight discipline that consists of
different categories, one of which is focused on skills. Skills in calisthenics
encompass both static and dynamic elements performed by athletes. The
evaluation of static skills is based on their difficulty level and the duration
of the hold. Automated tools able to recognize isometric skills from a video by
segmenting them to estimate their duration would be desirable to assist
athletes in their training and judges during competitions. Although the video
understanding literature on action recognition through body pose analysis is
rich, no previous work has specifically addressed the problem of calisthenics
skill temporal video segmentation. This study aims to provide an initial step
towards the implementation of automated tools within the field of Calisthenics.
To advance knowledge in this context, we propose a dataset of video footage of
static calisthenics skills performed by athletes. Each video is annotated with
a temporal segmentation which determines the extent of each skill. We hence
report the results of a baseline approach to address the problem of skill
temporal segmentation on the proposed dataset. The results highlight the
feasibility of the proposed problem, while there is still room for improvement.

</details>


### [113] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 本研究对比分析了Keras、PyTorch和JAX三大深度学习框架在医学图像分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习框架在医学图像分类中广泛应用，但它们在医学图像任务中的相对性能尚未得到充分探索。

Method: 研究团队在PathMNIST数据集上，对Keras、PyTorch和JAX框架下的CNN实现进行了综合分析，评估了训练效率、分类准确性和推理速度。

Result: 研究结果揭示了计算速度和模型准确性之间的权衡。

Conclusion: 本研究为医学图像分析领域的研究人员和实践者提供了有价值的见解，以选择合适的深度学习框架。

Abstract: Deep learning has significantly advanced the field of medical image
classification, particularly with the adoption of Convolutional Neural Networks
(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer
unique advantages in model development and deployment. However, their
comparative performance in medical imaging tasks remains underexplored. This
study presents a comprehensive analysis of CNN implementations across these
frameworks, using the PathMNIST dataset as a benchmark. We evaluate training
efficiency, classification accuracy and inference speed to assess their
suitability for real-world applications. Our findings highlight the trade-offs
between computational speed and model accuracy, offering valuable insights for
researchers and practitioners in medical image analysis.

</details>


### [114] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 深度学习模型利用极低出生体重婴儿出生24小时内的胸部X光片，通过领域特异性预训练，准确预测中度/重度支气管肺发育不良（BPD），结果良好并具临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 支气管肺发育不良（BPD）是早产儿的严重慢性肺病，现有预防性干预措施风险高。因此，早期准确预测BPD至关重要，以避免对低风险婴儿进行不必要的干预及其副作用。入院常规X光片是一种潜在的无创预后工具。

Method: 本研究开发了一种深度学习方法，利用163名极低出生体重婴儿（出生24小时内）的胸部X光片进行分析。研究人员对在成人胸片上预训练的ResNet-50模型进行了微调，采用了渐进式层冻结和判别性学习率来防止过拟合，并评估了CutMix数据增强和线性探测技术。

Result: 在中度/重度BPD预测中，表现最佳的模型获得了0.78的AUROC、0.69的平衡准确率和0.67的F1分数。领域特异性预训练显著优于ImageNet初始化（p = 0.031）。常规IRDS评分预后价值有限（AUROC 0.57），证实了学习标记的必要性。

Conclusion: 该方法表明，领域特异性预训练能够利用出生第一天的常规X光片准确预测BPD。通过渐进式冻结和线性探测，该方法在计算上对于站点级实施和未来的联邦学习部署是可行的，显示了其临床应用潜力。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


### [115] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为FADE的新型概念擦除方法，用于文本到图像扩散模型。它通过结合轨迹感知微调和对抗性目标，有效删除指定概念（如私人信息或有害刻板印象），同时保持模型保真度，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面表现出色，但同时也存在隐私和公平性风险，因为它们可能记忆敏感概念或固化偏见，因此需要一种方法来安全地移除这些不需要的概念。

Method: 所提出的方法名为FADE（Fair Adversarial Diffusion Erasure），结合了轨迹感知微调策略和对抗性目标。它旨在确保概念被可靠删除同时保持模型整体保真度。理论上，该方法被证明可以最小化被擦除概念与模型输出之间的互信息。

Result: FADE在Stable Diffusion和FLUX上进行了评估，在概念移除性能上达到了最先进水平，超越了ESD、UCE、MACE和ANT等现有基线，在移除效率和图像质量方面表现更优。FADE在概念移除和保真度的调和平均值上比最佳现有方法提高了5-10%。消融研究证实了其对抗性和轨迹保持目标的贡献。

Conclusion: 该工作通过在不从头开始重新训练的情况下“忘却”指定概念，为安全和公平的生成建模设定了新标准。

Abstract: Diffusion models have demonstrated remarkable image generation capabilities,
but also pose risks in privacy and fairness by memorizing sensitive concepts or
perpetuating biases. We propose a novel \textbf{concept erasure} method for
text-to-image diffusion models, designed to remove specified concepts (e.g., a
private individual or a harmful stereotype) from the model's generative
repertoire. Our method, termed \textbf{FADE} (Fair Adversarial Diffusion
Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial
objective to ensure the concept is reliably removed while preserving overall
model fidelity. Theoretically, we prove a formal guarantee that our approach
minimizes the mutual information between the erased concept and the model's
outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable
Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,
explicit content, and style erasure tasks from MACE). FADE achieves
state-of-the-art concept removal performance, surpassing recent baselines like
ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.
Notably, FADE improves the harmonic mean of concept removal and fidelity by
5--10\% over the best prior method. We also conduct an ablation study to
validate each component of FADE, confirming that our adversarial and
trajectory-preserving objectives each contribute to its superior performance.
Our work sets a new standard for safe and fair generative modeling by
unlearning specified concepts without retraining from scratch.

</details>


### [116] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 该研究提出一种无需姿态估计的徒手训练技能识别新方法，通过深度估计和运动员区域提取，大幅提升了效率和准确性，并具有模块化设计。


<details>
  <summary>Details</summary>
Motivation: 传统的徒手训练技能识别方法依赖姿态估计，但其计算成本高、推理时间长且设置复杂，限制了在实时和移动设备上的应用。

Method: 本研究提出一种直接的徒手训练技能识别方法。该方法利用Depth Anything V2进行深度估计，并结合YOLOv10进行运动员定位，从而从背景中分割出主体，避免了计算密集型的人体姿态估计模块。

Result: 与基于骨架的方法相比，本方法在推理速度上快38.3倍（使用RGB图像区域），且在分类精度上有所提高（使用深度区域达到0.837，而传统方法为0.815）。

Conclusion: 该方法显著提高了徒手训练技能识别的效率和分类准确性。其模块化设计也为未来的性能提升和实际应用提供了灵活性。

Abstract: Calisthenics skill classification is the computer vision task of inferring
the skill performed by an athlete from images, enabling automatic performance
assessment and personalized analytics. Traditional methods for calisthenics
skill recognition are based on pose estimation methods to determine the
position of skeletal data from images, which is later fed to a classification
algorithm to infer the performed skill. Despite the progress in human pose
estimation algorithms, they still involve high computational costs, long
inference times, and complex setups, which limit the applicability of such
approaches in real-time applications or mobile devices. This work proposes a
direct approach to calisthenics skill recognition, which leverages depth
estimation and athlete patch retrieval to avoid the computationally expensive
human pose estimation module. Using Depth Anything V2 for depth estimation and
YOLOv10 for athlete localization, we segment the subject from the background
rather than relying on traditional pose estimation techniques. This strategy
increases efficiency, reduces inference time, and improves classification
accuracy. Our approach significantly outperforms skeleton-based methods,
achieving 38.3x faster inference with RGB image patches and improved
classification accuracy with depth patches (0.837 vs. 0.815). Beyond these
performance gains, the modular design of our pipeline allows for flexible
replacement of components, enabling future enhancements and adaptation to
real-world applications.

</details>


### [117] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: 本文提出离散潜在代码（DLC）作为一种新型图像表示，显著提升了扩散模型的生成保真度，实现了域外样本生成，并支持高效的文本到图像转换，在ImageNet无条件生成上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 探究扩散模型成功的关键在于其输入条件，并旨在开发一种理想的图像表示。这种表示应能提高样本保真度，易于生成，并具有组合性，以支持生成训练数据之外的新颖样本。

Method: 引入离散潜在代码（DLC），这是一种通过自监督学习从Simplicial Embeddings派生的图像表示。DLC是离散的token序列（而非连续嵌入），它们易于生成且具备组合性。扩散模型通过DLCs进行条件化训练。

Result: 使用DLC训练的扩散模型显著提高了生成保真度，在ImageNet无条件图像生成任务上达到了新的最先进水平。通过组合DLCs，图像生成器能够产生连贯地结合图像语义的域外（OOD）样本。此外，DLCs还能通过微调大型预训练语言模型，实现高效的文本到图像生成，产生训练分布之外的新颖样本。

Conclusion: DLC作为一种离散、易生成且具有组合性的图像表示，极大地增强了扩散模型的性能，不仅提升了生成保真度并建立了新SOTA，还成功实现了域外样本生成和高效的文本到图像转换，展现了其在复杂分布建模中的巨大潜力。

Abstract: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.

</details>


### [118] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: KeyDiff3D是一个利用预训练多视图扩散模型，从单张图片中无监督估计3D关键点的框架，且支持3D物体操作。


<details>
  <summary>Details</summary>
Motivation: 传统3D关键点估计方法依赖于昂贵的手动标注或校准多视图图像，这在数据收集上成本高昂。

Method: KeyDiff3D利用预训练的多视图扩散模型，从单张图片生成多视图图像作为3D几何线索的监督信号。该模型同时被用作强大的2D多视图特征提取器，通过其中间表示构建3D特征体，将隐式3D先验转化为显式3D特征。此外，还引入了一个 enabling 3D物体操作的管线。

Result: 在Human3.6M、Stanford Dogs以及野外和域外数据集上的实验结果表明，KeyDiff3D在准确性、泛化能力以及通过单张图像实现扩散模型生成3D物体操作方面表现出有效性。

Conclusion: KeyDiff3D提供了一种经济高效、高性能的无监督单目3D关键点估计方法，并通过利用扩散模型的力量，实现了对生成3D物体的有效操作。

Abstract: This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D
keypoints estimation that accurately predicts 3D keypoints from a single image.
While previous methods rely on manual annotations or calibrated multi-view
images, both of which are expensive to collect, our method enables monocular 3D
keypoints estimation using only a collection of single-view images. To achieve
this, we leverage powerful geometric priors embedded in a pretrained multi-view
diffusion model. In our framework, this model generates multi-view images from
a single image, serving as a supervision signal to provide 3D geometric cues to
our model. We also use the diffusion model as a powerful 2D multi-view feature
extractor and construct 3D feature volumes from its intermediate
representations. This transforms implicit 3D priors learned by the diffusion
model into explicit 3D features. Beyond accurate keypoints estimation, we
further introduce a pipeline that enables manipulation of 3D objects generated
by the diffusion model. Experimental results on diverse aspects and datasets,
including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain
datasets, highlight the effectiveness of our method in terms of accuracy,
generalization, and its ability to enable manipulation of 3D objects generated
by the diffusion model from a single image.

</details>


### [119] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 研究并验证了CWD和MGD知识蒸馏方法，以提升轻量级YOLO11n模型在资源受限平台上的杂草检测精度和实时部署能力。


<details>
  <summary>Details</summary>
Motivation: 精准农业中的杂草检测对于定向除草和环境影响减小至关重要。然而，在资源受限平台上部署准确且能区分视觉相似杂草的目标检测模型仍是挑战。

Method: 该研究调查了通道知识蒸馏 (CWD) 和掩码生成蒸馏 (MGD) 方法，以增强轻量级模型在实时智能喷洒系统中的性能。使用YOLO11x作为教师模型，YOLO11n作为学生模型，并在包含甜菜作物和四种杂草的真实世界数据集上进行实验。

Result: CWD和MGD蒸馏后的模型在所有类别上均提高了AP50。CWD学生模型mAP50较基线提升2.5%，MGD提升1.9%，且未增加模型复杂度。此外，验证了YOLO11n模型在Jetson Orin Nano和Raspberry Pi 5嵌入式设备上的实时部署可行性。

Conclusion: 知识蒸馏（CWD和MGD）被证实是提高精准农业和植物表型分析中基于深度学习的杂草检测精度的有效、高效且实用的方法。

Abstract: Weed detection is a critical component of precision agriculture, facilitating
targeted herbicide application and reducing environmental impact. However,
deploying accurate object detection models on resource-limited platforms
remains challenging, particularly when differentiating visually similar weed
species commonly encountered in plant phenotyping applications. In this work,
we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative
Distillation (MGD) to enhance the performance of lightweight models for
real-time smart spraying systems. Utilizing YOLO11x as the teacher model and
YOLO11n as both reference and student, both CWD and MGD effectively transfer
knowledge from the teacher to the student model. Our experiments, conducted on
a real-world dataset comprising sugar beet crops and four weed types (Cirsium,
Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50
across all classes. The distilled CWD student model achieves a notable
improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without
increasing model complexity. Additionally, we validate real-time deployment
feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and
Raspberry Pi 5 embedded devices, performing five independent runs to evaluate
performance stability across random seeds. These findings confirm CWD and MGD
as an effective, efficient, and practical approach for improving deep
learning-based weed detection accuracy in precision agriculture and plant
phenotyping scenarios.

</details>


### [120] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: CueCo是一种结合对比学习和聚类方法的无监督视觉表示学习新方法，旨在同时散射和对齐特征。


<details>
  <summary>Details</summary>
Motivation: 旨在改进无监督视觉表示学习，通过在特征空间中同时实现特征的散射（区分不同）和对齐（聚集相似）。

Method: 提出Cluster Contrast (CueCo)，利用查询和键两个神经网络（键网络通过查询输出的慢速移动平均更新）。结合对比损失以推开不相似特征（增强类间分离）和聚类目标以拉近同簇特征（促进类内紧凑性）。

Result: 在CIFAR-10上达到91.40% top-1准确率，CIFAR-100上68.56%，ImageNet-100上78.65%（使用ResNet-18骨干进行线性评估）。

Conclusion: CueCo通过整合对比学习与聚类，为推进无监督视觉表示学习开辟了新方向。

Abstract: We introduce Cluster Contrast (CueCo), a novel approach to unsupervised
visual representation learning that effectively combines the strengths of
contrastive learning and clustering methods. Inspired by recent advancements,
CueCo is designed to simultaneously scatter and align feature representations
within the feature space. This method utilizes two neural networks, a query and
a key, where the key network is updated through a slow-moving average of the
query outputs. CueCo employs a contrastive loss to push dissimilar features
apart, enhancing inter-class separation, and a clustering objective to pull
together features of the same cluster, promoting intra-class compactness. Our
method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on
CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18
backbone. By integrating contrastive learning with clustering, CueCo sets a new
direction for advancing unsupervised visual representation learning.

</details>


### [121] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: Text-SemiSeg是一种新颖的文本驱动多平面视觉交互框架，通过融合文本信息增强视觉语义，用于半监督医学图像分割。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中数据标注成本高昂，且利用文本信息增强3D医学图像视觉语义嵌入的研究相对稀缺。

Method: 提出Text-SemiSeg框架，包含TMR（文本增强多平面表示，用于文本-视觉交互）、CSA（类别感知语义对齐，用于跨模态语义对齐）和DCA（动态认知增强，用于减少数据分布差异）三个核心模块。

Result: 在三个公共数据集上的实验表明，该模型能有效利用文本信息增强视觉特征，并超越了其他现有方法。

Conclusion: Text-SemiSeg框架成功利用文本信息提升了半监督医学图像分割的性能，有效缓解了数据标注成本高昂的问题。

Abstract: Semi-supervised medical image segmentation is a crucial technique for
alleviating the high cost of data annotation. When labeled data is limited,
textual information can provide additional context to enhance visual semantic
understanding. However, research exploring the use of textual data to enhance
visual semantic embeddings in 3D medical imaging tasks remains scarce. In this
paper, we propose a novel text-driven multiplanar visual interaction framework
for semi-supervised medical image segmentation (termed Text-SemiSeg), which
consists of three main modules: Text-enhanced Multiplanar Representation (TMR),
Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation
(DCA). Specifically, TMR facilitates text-visual interaction through planar
mapping, thereby enhancing the category awareness of visual features. CSA
performs cross-modal semantic alignment between the text features with
introduced learnable variables and the intermediate layer of visual features.
DCA reduces the distribution discrepancy between labeled and unlabeled data
through their interaction, thus improving the model's robustness. Finally,
experiments on three public datasets demonstrate that our model effectively
enhances visual features with textual information and outperforms other
methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.

</details>


### [122] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: 本文创建并发布了两个大规模、高挑战性的现实人类监控目标检测基准数据集（OD-VIRAT Large和OD-VIRAT Tiny），并在此基础上对多个最先进的目标检测架构进行了基准测试，旨在促进复杂监控场景下的视觉理解和模型开发。


<details>
  <summary>Details</summary>
Motivation: 开发在现实世界条件下鲁棒的人类和人机交互目标检测算法，需要多样化和具有挑战性的高质量人类监控数据集。现有数据集可能无法全面评估模型性能，或无法有效支持公共安全监控系统的构建。

Method: 1. 提出了两个新的视觉目标检测基准数据集：OD-VIRAT Large（包含599,996张图像中的870万个标注实例）和OD-VIRAT Tiny（包含19,860张图像中的288,901个标注实例）。2. 这两个数据集的视频序列覆盖了10个不同的人类监控场景，均在高空和远距离进行录制，并提供丰富的边界框和类别标注。3. 在这些新数据集上，对包括RETMDET、YOLOX、RetinaNet、DETR和Deformable-DETR在内的多种最先进目标检测架构进行了基准测试。

Result: 研究首次在复杂背景、遮挡物体和小型物体等挑战性条件下，对最新的SOTA目标检测架构在真实的监控图像上进行了性能评估和基准测试。

Conclusion: 所提出的基准测试和实验设置有助于深入了解所选目标检测模型的性能，并为未来开发更高效和鲁棒的目标检测架构奠定了基础。

Abstract: Realistic human surveillance datasets are crucial for training and evaluating
computer vision models under real-world conditions, facilitating the
development of robust algorithms for human and human-interacting object
detection in complex environments. These datasets need to offer diverse and
challenging data to enable a comprehensive assessment of model performance and
the creation of more reliable surveillance systems for public safety. To this
end, we present two visual object detection benchmarks named OD-VIRAT Large and
OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance
imagery. The video sequences in both benchmarks cover 10 different scenes of
human surveillance recorded from significant height and distance. The proposed
benchmarks offer rich annotations of bounding boxes and categories, where
OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and
OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also
focuses on benchmarking state-of-the-art object detection architectures,
including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object
detection-specific variant of VIRAT dataset. To the best of our knowledge, it
is the first work to examine the performance of these recently published
state-of-the-art object detection architectures on realistic surveillance
imagery under challenging conditions such as complex backgrounds, occluded
objects, and small-scale objects. The proposed benchmarking and experimental
settings will help in providing insights concerning the performance of selected
object detection models and set the base for developing more efficient and
robust object detection architectures.

</details>


### [123] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: 本文提出了AutoVDC框架，利用视觉-语言模型（VLMs）自动识别自动驾驶视觉数据集中的错误标注，以提高数据质量。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统训练依赖大量高精度标注数据，但人工标注易出错且手动审查耗时昂贵，因此需要一种自动化方法来识别和修正这些错误。

Method: 引入AutoVDC框架，利用视觉-语言模型（VLMs）自动识别视觉数据集中的错误标注。研究通过在KITTI和nuImages数据集中故意注入错误来验证其有效性，并比较不同VLM和VLM微调对错误检测率的影响。

Result: 实验结果表明，该方法在错误检测和数据清洗实验中表现出高性能。

Conclusion: 该方法有望显著提高自动驾驶领域大规模生产数据集的可靠性和准确性。

Abstract: Training of autonomous driving systems requires extensive datasets with
precise annotations to attain robust performance. Human annotations suffer from
imperfections, and multiple iterations are often needed to produce high-quality
datasets. However, manually reviewing large datasets is laborious and
expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)
framework and investigate the utilization of Vision-Language Models (VLMs) to
automatically identify erroneous annotations in vision datasets, thereby
enabling users to eliminate these errors and enhance data quality. We validate
our approach using the KITTI and nuImages datasets, which contain object
detection benchmarks for autonomous driving. To test the effectiveness of
AutoVDC, we create dataset variants with intentionally injected erroneous
annotations and observe the error detection rate of our approach. Additionally,
we compare the detection rates using different VLMs and explore the impact of
VLM fine-tuning on our pipeline. The results demonstrate our method's high
performance in error detection and data cleaning experiments, indicating its
potential to significantly improve the reliability and accuracy of large-scale
production datasets in autonomous driving.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [124] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 本文探讨人工智能如何促使人类与自然的关系从主宰转向互惠共生，并通过生态设计实践展示AI在连接科学、艺术和环境管理方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究人类与自然的关系能否从主宰转变为真正的相互依存，以及人工智能（AI）是否能促成这一转变。

Method: 考察一种AI与非人类生命形式互动的新生态设计范式，通过案例研究展示艺术家和设计师如何应用AI进行数据分析、图像识别和生态修复。此外，基于作者的AI辅助水修复原型，提出将强化学习与植物修复结合的设计途径。

Result: AI不仅拓展了创意方法，还重塑了生态设计的理论与实践，产生不同于传统媒体的效果。研究结果强调了AI在连接科学洞察、艺术实践和环境管理方面的潜力。

Conclusion: AI能够促进向真正的自然互依存关系转变，并为未来可持续、技术赋能的生态系统研究提供了路线图。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [125] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 引入LLM/VLM代理的模块化通用框架（包含感知、记忆和推理），在多种游戏环境中提升了代理性能，并揭示了各模块的关键贡献。


<details>
  <summary>Details</summary>
Motivation: 旨在使LLM或VLM骨干模型无需领域特定工程即可应对广泛的多轮游戏环境，并提供统一工作流分析各模块对动态交互性能的影响，从而推进通用代理能力。

Method: 提出一个由感知（perception）、记忆（memory）和推理（reasoning）组件组成的LLM代理模块化框架。利用经典和现代游戏套件作为低门槛、高多样性的测试平台，提供统一的工作流来分析各模块对性能的影响。

Result: 实验证明，该框架一致性地提升了游戏表现，优于未使用的基线。研究揭示了各模块的独特贡献模式，例如，记忆在长程谜题中起主导作用，而感知在视觉嘈杂的街机游戏中至关重要。

Conclusion: 该模块化框架设计对于提升通用代理能力是有效的，并强调了游戏作为通用代理测试和发展的适宜性。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [126] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: 多模态大语言模型(MLLMs)作为AI行为验证器在复杂任务中面临“一致性偏差”。本文提出“自锚定验证(SGV)”方法，通过利用MLLM自身知识生成先验并进行评估，有效克服偏差，显著提升验证准确性，并在多项任务中实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI验证器难以应用于缺乏明确成功标准的复杂领域（如计算机操作），尽管人类能识别正确结果，但将其转化为可扩展规则存在挑战。MLLMs因其世界知识和推理能力被视为潜在解决方案，但初步评估发现其存在严重的上下文“一致性偏差”，限制了其作为验证器的有效性。

Method: 研究首先评估了MLLMs在网页导航、计算机使用和机器人操作等领域作为智能体轨迹验证器的能力，并识别出其“一致性偏差”（倾向于偏爱上下文信息并合理化错误行为）。为解决此问题，提出了“自锚定验证（SGV）”方法。SGV分两步：1) MLLM独立于待评估数据，无条件生成关于任务完成的广泛先验知识；2) MLLM基于这些自我生成的先验知识，对候选轨迹进行推理和评估。

Result: MLLMs作为验证器普遍存在“一致性偏差”，且此偏差难以消除，影响了其应用。SGV方法使MLLM验证器的准确性和失败检测率提升高达20个百分点。SGV能够实时监督异构智能体，显著提升OSWorld中GUI专家、robomimic中扩散策略以及VisualWebArena中ReAct智能体的任务完成率，并在基准测试中创造了新的最先进结果，超越此前最佳水平48%。

Conclusion: MLLMs在复杂任务验证中具有巨大潜力，但其固有的“一致性偏差”是关键障碍。通过提出的SGV方法，可以有效利用MLLMs的内在知识和推理能力克服这一偏差，从而显著提升验证性能，使其成为高效、实时的异构智能体监督工具，并树立了新的性能标杆。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [127] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: 本研究提出ClarifAI，一个结合案例推理（CBR）和本体论的新方法，旨在增强人工智能的透明度和可解释性，以改进决策制定。


<details>
  <summary>Details</summary>
Motivation: 为满足人工智能驱动应用中各类利益相关者对复杂解释的需求，提高AI的透明度和可解释性，尤其是在改进决策和高风险环境中。

Method: 引入并构建了ClarifAI，该方法利用案例推理（CBR）方法学，并整合了本体论驱动的方法，旨在提供详尽的解释机制。论文还阐述了其理论基础、设计原则和架构蓝图。

Result: ClarifAI有望增强人工智能在不同领域的解释性，并适用于高风险环境下的决策制定。

Conclusion: ClarifAI在推进AI系统可解释性方面具有重要作用，为其部署到关键决策过程中奠定了基础。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [128] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 本文提出DP-Bench基准和专用模型DPLM，用于解决动态规划（DP）模型公式化中LLM面临的数据稀缺与随机性挑战。DPLM通过新颖的DualReflect合成数据管道（结合前向与后向生成）实现与最先进LLM媲美的性能，并在难题上超越，揭示了两种数据生成方式的互补性。


<details>
  <summary>Details</summary>
Motivation: 动态规划（DP）模型的公式化传统上需要专业的领域知识和DP技术。尽管大型语言模型（LLMs）有潜力自动化此过程，但DP问题固有的随机转换和训练数据稀缺性，使得现有LLM方法难以直接应用于DP问题。

Method: 研究引入了DP-Bench，首个覆盖广泛教材级DP问题的基准测试，用于系统评估。在此基础上，提出了动态规划语言模型（DPLM），一个7B参数的专用模型。DPLM的核心是DualReflect，一种新颖的合成数据生成管道，通过结合前向生成（增加多样性）和后向生成（确保可靠性），从有限示例扩展训练数据。

Result: DPLM在性能上与OpenAI的o1和DeepSeek-R1等最先进LLM相当，并在难题上超越。研究发现，在低数据量情况下，后向生成因其高正确性保证而更受青睐；而前向生成虽然缺乏此类保证，但在规模化时对引入多样化公式的价值日益增加。

Conclusion: 前向和后向生成之间的权衡，突出了这两种方法的互补优势以及结合它们的重要性，为使用LLM自动化动态规划模型公式化提供了有效途径。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [129] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 本文综述了群智能算法在基于语义相似度的文档搜索领域的最新进展，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 群智能（SI）在人工智能和优化领域日益普及且效果显著。研究动机是为了梳理并总结群智能算法在特定应用——基于语义相似度的文档搜索中的最新发展。

Method: 采用文献综述（survey）的方法，回顾相关研究和技术进展。

Result: 通过综述，论文将呈现群智能算法在基于语义相似度的文档搜索领域的最新发展成果，并提供未来的研究方向建议。

Conclusion: 该综述旨在为群智能应用于语义相似度文档搜索领域提供一个全面的概述，并通过识别未来的研究方向来指导该领域的发展。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [130] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 提出了一种结合CPU和GPU并行处理的深度优先搜索（DFS）方法，可有效利用GPU加速搜索算法，并保持最优性。


<details>
  <summary>Details</summary>
Motivation: 现有GPU在搜索算法中的应用多集中于启发式压缩，而很少有算法在搜索过程本身充分利用GPU的并行计算能力。

Method: 引入了一种新的成本约束深度优先搜索（CB-DFS）方法，该方法结合现代CPU和GPU的并行性，实现GPU计算的批量处理。基于此，提出了Batch IDA*和Batch BTS等算法，并保持最优性保证。

Result: 在3x3魔方和4x4滑块拼图上的评估表明，GPU操作可以在深度优先搜索中高效地进行批量处理。此外，还分析了超参数、神经网络启发式大小和硬件资源对性能的影响。

Conclusion: 本研究成功展示了在深度优先搜索过程中有效利用GPU并行计算的可行性，为加速经典搜索算法提供了新的途径。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [131] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime是一种新型多智能体框架，通过动态规划、按需智能体实例化和集中式进度管理，克服了现有计划-执行框架的局限性，在多领域基准测试中表现出卓越的性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有由大型语言模型（LLM）驱动的多智能体系统受限于主流的“计划-执行”框架，存在计划执行僵化、智能体能力静态以及通信效率低下等关键局限性，导致在动态环境中适应性和鲁棒性不足。

Method: 本文提出了Aime框架，旨在通过动态、反应式规划和执行来克服现有挑战。其核心创新包括：1) 动态规划器：根据实时执行反馈持续优化整体策略；2) Actor Factory：按需实例化并组装具有定制工具和知识的专业化智能体；3) 集中式进度管理模块：作为系统级连贯状态感知的单一真实来源。

Result: 通过在通用推理（GAIA）、软件工程（SWE-bench Verified）和实时网页导航（WebVoyager）等多样化基准测试中进行实证评估，结果表明Aime在各自领域中持续超越了高度专业化的最先进智能体。

Conclusion: Aime卓越的适应性和任务成功率，使其成为更具弹性和高效的多智能体协作基础。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [132] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 本文训练了基于光流感知的强化学习智能体在障碍隧道中导航，发现其行为与昆虫类似，主要关注光流不连续和大光流区域，为无人机简单控制律的开发提供了策略。


<details>
  <summary>Details</summary>
Motivation: 生物启发设计常用于无人机导航，因生物系统（如蜜蜂）在有限感官和计算下仍能有效飞行和避障。蜜蜂主要利用光流导航复杂环境，本研究旨在将此原理应用于强化学习智能体，探索其导航策略。

Method: 训练一个强化学习智能体，仅以光流作为感知输入，使其在带障碍物的隧道中导航。通过检查训练后智能体的注意力模式，分析其决策主要基于哪些光流区域。

Result: 研究发现，训练后的智能体主要关注光流的不连续区域以及光流幅值大的区域。它们通过避开产生大光流的障碍物并保持在环境中心位置来导航，这种行为与飞行昆虫类似，且在独立训练的智能体中均存在。

Conclusion: 智能体表现出的这种关注光流不连续和大光流区域的模式，是为物理无人机开发简单显式控制律的有效策略。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [133] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 本文提出TPE-MARL方法，通过引入游戏拓扑张量和改进探索机制，解决多智能体强化学习中探索-利用权衡挑战，显著提升了互联自动驾驶车辆在复杂交通流中的决策效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习 (MARL) 中的探索-利用权衡是一个基本挑战，在互联自动驾驶车辆 (CAV) 优化合作决策中，由于联合状态-动作空间的指数增长，该挑战更为严峻。

Method: 1. 构建动态交通流的游戏拓扑张量，以有效压缩高维交通状态信息并减小MARL算法的搜索空间。
2. 基于设计的游戏拓扑张量，并以QMIX作为骨干RL算法，建立一个结合访问计数和智能体互信息的拓扑增强型MARL (TPE-MARL) 框架。

Result: TPE-MARL成功平衡了探索和利用，并在交通效率、安全性、决策平滑性和任务完成度方面表现出卓越性能。此外，在混合和全自动驾驶交通场景中，该算法的决策理性可与人类驾驶员相媲美或超越。

Conclusion: 论文提出的TPE-MARL方法通过有效处理多智能体强化学习中的探索-利用权衡问题，显著提升了互联自动驾驶车辆在混合交通流中的协作决策能力，并在多项性能指标上展现出优越性。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [134] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出了一种新的在线近似POMDP求解器PORPP，通过深度采样历史和渐进策略更新，在理论保障下，其实际性能显著优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 现有在线规划方法在采样稀疏性下性能损失受限于最大近似误差，无法有效应对复杂动态的局部可观测环境，因此需要一种能将性能损失限制在平均误差内的新方法。

Method: 提出了“部分可观测参考策略规划”（Partially Observable Reference Policy Programming, PORPP），这是一种即时在线近似POMDP求解器。其核心机制是深度采样有意义的未来历史并强制进行渐进式策略更新。算法提供理论保证，指出性能损失受限于采样近似误差的平均值而非最大值。

Result: 在两个包含动态演化环境的大规模问题（包括科西嘉地区的直升机紧急情况）上的实证评估证实了理论结果。该求解器显著优于当前的在线基准。

Conclusion: PORPP求解器能够有效处理大规模、动态和局部可观测的问题，提供了强大的理论支持和显著优于现有在线规划方法的实际性能。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [135] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: 本文提出了BuildEvo框架，利用大语言模型（LLMs）通过进化过程自动设计和优化可解释的建筑能耗预测启发式模型，实现了最先进的性能和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统能耗预测方法精度不足或缺乏可解释性，且先进模型因忽视物理原理而泛化能力受限，亟需一种准确、可解释且泛化能力强的预测方法。

Method: BuildEvo框架利用LLMs在一个进化过程中，系统地整合建筑特征和运行数据中的物理洞察，以自动设计和增强有效的、可解释的能耗预测启发式模型。

Result: BuildEvo在基准测试中达到了最先进的性能，提供了改进的泛化能力和透明的预测逻辑。

Conclusion: 这项工作推动了鲁棒、基于物理原理的启发式模型的自动化设计，为复杂的能源系统提供了更值得信赖的预测模型。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [136] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 本文提出并训练了Xiangqi-R1，一个针对中国象棋优化的7B参数大语言模型，通过多阶段训练和大规模数据集显著提升了其空间战略推理能力，超越了通用大语言模型。


<details>
  <summary>Details</summary>
Motivation: 游戏是评估AGI的基本基准，但通用大语言模型在复杂棋类游戏中所需的空间战略推理能力方面探索不足。中国象棋因其复杂性和空间特性被选为具有挑战性的测试平台。

Method: 研究采用中国象棋作为测试对象，提出了一个定制化的训练框架。该框架基于包含五百万棋盘-走法对的大规模数据集，并辅以专家注释和引擎评估。在此基础上，开发了7B参数模型Xiangqi-R1，采用多阶段训练：1) 微调以预测合法走法，2) 融入战略注释以改善决策，3) 应用GRPO强化学习并结合多维奖励信号以增强推理稳定性。

Result: 实验结果显示，通用大语言模型在此类任务中表现不佳。相较之下，Xiangqi-R1表现出显著提升，走法合法性提高了18%，分析准确性提高了22%。

Conclusion: 研究结果为在空间复杂领域创建通用战略智能指明了一条有前景的道路。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [137] [Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming](https://arxiv.org/abs/2507.11547)
*Yingxue Zhao,Qianyi Chen,Haoran Li,Haosu Zhou,Hamid Reza Attar,Tobias Pfaff,Tailin Wu,Nan Li*

Main category: cs.LG

TL;DR: 本文提出了一种名为RUGNN的新型图神经网络代理模型，用于准确预测板材成形过程中跨多个时间步的变形场，解决了传统AI模型在复杂3D空间关系和置换不变性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于标量或图像的AI代理模型在捕获复杂的3D空间关系和置换不变性方面存在局限性，而新兴的图基代理模型（使用图神经网络）能够克服这些问题，以提供材料成形过程的快速可制造性预测。

Method: 开发了名为Recurrent U Net-based Graph Neural Network (RUGNN)的新型图神经网络模型。该模型结合了门控循环单元（GRUs）以建模时间动态，并采用受U-Net启发的图基下采样/上采样机制处理空间长程依赖。提出了一种新颖的“节点到表面”接触表示方法，以显著提高大规模接触交互的计算效率。通过冷成形和热成形案例研究对模型进行了验证，并进行了模型调优以确定合适的超参数、训练策略和输入特征表示。

Result: RUGNN模型实现了板材变形场的准确预测，其预测结果与地面真值有限元模拟非常吻合，并优于几种基线GNN架构。提出的“节点到表面”接触表示法显著提高了计算效率。

Conclusion: RUGNN是一种可靠的方法，通过实现准确的可制造性预测来支持板材成形设计。

Abstract: In recent years, various artificial intelligence-based surrogate models have
been proposed to provide rapid manufacturability predictions of material
forming processes. However, traditional AI-based surrogate models, typically
built with scalar or image-based neural networks, are limited in their ability
to capture complex 3D spatial relationships and to operate in a
permutation-invariant manner. To overcome these issues, emerging graph-based
surrogate models are developed using graph neural networks. This study
developed a new graph neural network surrogate model named Recurrent U
Net-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate
predictions of sheet material deformation fields across multiple forming
timesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model
temporal dynamics and a U-Net inspired graph-based downsample/upsample
mechanism to handle spatial long-range dependencies. A novel 'node-to-surface'
contact representation method was proposed, offering significant improvements
in computational efficiency for large-scale contact interactions. The RUGNN
model was validated using a cold forming case study and a more complex hot
forming case study using aluminium alloys. Results demonstrate that the RUGNN
model provides accurate deformation predictions closely matching ground truth
FE simulations and outperforming several baseline GNN architectures. Model
tuning was also performed to identify suitable hyperparameters, training
strategies, and input feature representations. These results demonstrate that
RUGNN is a reliable approach to support sheet material forming design by
enabling accurate manufacturability predictions.

</details>


### [138] [SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery](https://arxiv.org/abs/2507.11570)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.LG

TL;DR: 本研究开发了一种名为SurgeryLSTM的AI模型，用于高精度预测择期脊柱手术的住院时长，并通过注意力机制提高了模型的可解释性，优于传统机器学习方法，有望应用于临床决策支持。


<details>
  <summary>Details</summary>
Motivation: 旨在开发和评估机器学习模型，以预测择期脊柱手术的住院时长（LOS），并重点关注时间序列建模和模型可解释性所带来的益处。

Method: 研究对比了传统机器学习模型（如线性回归、随机森林、SVM和XGBoost）与本团队开发的SurgeryLSTM模型（一种带有注意力机制的蒙版双向长短期记忆网络）。模型训练使用结构化围手术期电子健康记录（EHR）数据，通过决定系数（R2）评估性能，并利用可解释AI识别关键预测因子。

Result: SurgeryLSTM模型实现了最高的预测准确性（R2=0.86），优于XGBoost（R2=0.85）及其他基线模型。注意力机制通过动态识别术前临床序列中的关键时间段，显著提升了模型的可解释性。主要的住院时长预测因子包括骨骼疾病、慢性肾病和腰椎融合术。

Conclusion: SurgeryLSTM为择期脊柱手术的住院时长预测提供了一个有效且可解释的AI解决方案。研究结果支持将时间序列和可解释的机器学习方法整合到临床决策支持系统中，以提高出院准备度并实现个性化患者护理。

Abstract: Objective: To develop and evaluate machine learning (ML) models for
predicting length of stay (LOS) in elective spine surgery, with a focus on the
benefits of temporal modeling and model interpretability. Materials and
Methods: We compared traditional ML models (e.g., linear regression, random
forest, support vector machine (SVM), and XGBoost) with our developed model,
SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an
attention, using structured perioperative electronic health records (EHR) data.
Performance was evaluated using the coefficient of determination (R2), and key
predictors were identified using explainable AI. Results: SurgeryLSTM achieved
the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)
and baseline models. The attention mechanism improved interpretability by
dynamically identifying influential temporal segments within preoperative
clinical sequences, allowing clinicians to trace which events or features most
contributed to each LOS prediction. Key predictors of LOS included bone
disorder, chronic kidney disease, and lumbar fusion identified as the most
impactful predictors of LOS. Discussion: Temporal modeling with attention
mechanisms significantly improves LOS prediction by capturing the sequential
nature of patient data. Unlike static models, SurgeryLSTM provides both higher
accuracy and greater interpretability, which are critical for clinical
adoption. These results highlight the potential of integrating attention-based
temporal models into hospital planning workflows. Conclusion: SurgeryLSTM
presents an effective and interpretable AI solution for LOS prediction in
elective spine surgery. Our findings support the integration of temporal,
explainable ML approaches into clinical decision support systems to enhance
discharge readiness and individualized patient care.

</details>


### [139] [Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators](https://arxiv.org/abs/2507.11574)
*Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.LG

TL;DR: CMCO结合蒙特卡洛dropout和分形共形预测，为神经算子提供可校准、无分布、空间解析的不确定性量化，解决了实时虚拟感知中深度学习安全部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 在实时虚拟感知领域，尤其是数据稀疏、噪声大或非共置的高风险应用中，深度学习的安全部署面临鲁棒不确定性量化（UQ）的重大障碍。

Method: 引入共形化蒙特卡洛算子（CMCO）框架，该框架通过将蒙特卡洛dropout与分形共形预测统一到单个DeepONet架构中，实现了可校准、无分布且空间解析的不确定性估计，无需重新训练、集成或自定义损失函数。

Result: 在湍流、弹塑性变形和全球宇宙辐射剂量估算三个不同应用中的严格评估表明，CMCO即使在强空间梯度和基于代理的传感设置下，也能始终获得接近标称的经验覆盖率。

Conclusion: CMCO为神经算子提供了一个通用、即插即用的UQ解决方案，以最小的计算开销实现实时、可信的推理，并为可扩展、可泛化、不确定性感知的科学机器学习奠定了新基础。

Abstract: Robust uncertainty quantification (UQ) remains a critical barrier to the safe
deployment of deep learning in real-time virtual sensing, particularly in
high-stakes domains where sparse, noisy, or non-collocated sensor data are the
norm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework
that transforms neural operator-based virtual sensing with calibrated,
distribution-free prediction intervals. By unifying Monte Carlo dropout with
split conformal prediction in a single DeepONet architecture, CMCO achieves
spatially resolved uncertainty estimates without retraining, ensembling, or
custom loss design. Our method addresses a longstanding challenge: how to endow
operator learning with efficient and reliable UQ across heterogeneous domains.
Through rigorous evaluation on three distinct applications: turbulent flow,
elastoplastic deformation, and global cosmic radiation dose estimation-CMCO
consistently attains near-nominal empirical coverage, even in settings with
strong spatial gradients and proxy-based sensing. This breakthrough offers a
general-purpose, plug-and-play UQ solution for neural operators, unlocking
real-time, trustworthy inference in digital twins, sensor fusion, and
safety-critical monitoring. By bridging theory and deployment with minimal
computational overhead, CMCO establishes a new foundation for scalable,
generalizable, and uncertainty-aware scientific machine learning.

</details>


### [140] [Einstein Fields: A Neural Perspective To Computational General Relativity](https://arxiv.org/abs/2507.11589)
*Sandeep Suresh Cranganore,Andrei Bodnar,Arturs Berzins,Johannes Brandstetter*

Main category: cs.LG

TL;DR: 本文提出爱因斯坦场（Einstein Fields），一种新型神经张量场，用于将计算密集型四维数值相对论模拟压缩为紧凑的神经网络权重，通过建模度规实现物理量推导和自然涌现动力学。


<details>
  <summary>Details</summary>
Motivation: 数值相对论模拟计算量巨大，需要一种更紧凑、高效且能自然捕捉物理动力学特性的表示方法，以压缩、建模并分析这些复杂的时空模拟数据。

Method: 引入爱因斯坦场（Einstein Fields），其作为一种神经张量场（Neural Tensor Fields），通过隐式神经网络权重建模广义相对论的核心张量场——度规（metric）。该方法允许通过自动微分推导物理量，并且在编码时空几何时，动力学能自然涌现。

Result: 爱因斯坦场在多个广义相对论经典测试中表现出卓越潜力，包括四维时空连续建模、网格无关性、高存储效率、高导数精度以及易用性。研究团队还发布了一个基于JAX的开源库。

Conclusion: 爱因斯坦场为数值相对论领域提供了一种可扩展且富有表现力的新方法，通过其独特的神经张量场特性，实现了计算密集型模拟的有效压缩和物理量的精确推导，并能自然涌现动力学，有望推动该领域的发展。

Abstract: We introduce Einstein Fields, a neural representation that is designed to
compress computationally intensive four-dimensional numerical relativity
simulations into compact implicit neural network weights. By modeling the
\emph{metric}, which is the core tensor field of general relativity, Einstein
Fields enable the derivation of physical quantities via automatic
differentiation. However, unlike conventional neural fields (e.g., signed
distance, occupancy, or radiance fields), Einstein Fields are \emph{Neural
Tensor Fields} with the key difference that when encoding the spacetime
geometry of general relativity into neural field representations, dynamics
emerge naturally as a byproduct. Einstein Fields show remarkable potential,
including continuum modeling of 4D spacetime, mesh-agnosticity, storage
efficiency, derivative accuracy, and ease of use. We address these challenges
across several canonical test beds of general relativity and release an open
source JAX-based library, paving the way for more scalable and expressive
approaches to numerical relativity. Code is made available at
https://github.com/AndreiB137/EinFields

</details>


### [141] [Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques](https://arxiv.org/abs/2507.11590)
*Raju Challagundla,Mohsen Dorodchi,Pu Wang,Minwoo Lee*

Main category: cs.LG

TL;DR: 本文综述了合成表格数据生成领域的最新进展，重点关注在严格隐私法规下，如何保留复杂特征关系、统计保真度并满足隐私要求，并提出了新的分类法和基准框架。


<details>
  <summary>Details</summary>
Motivation: 随着隐私法规日益严格和真实数据访问受限，合成数据生成（特别是表格数据）成为金融、医疗等领域的关键解决方案。

Method: 本研究对合成表格数据生成领域的最新进展进行了全面综述，强调了保留复杂特征关系、统计保真度及满足隐私要求的方法。综述优先考虑了条件生成和风险敏感建模等实际生成目标。

Result: 本工作引入了一种基于实际生成目标（包括下游应用、隐私保障和数据效用）的新颖分类法；并提出了一个基准框架，以使技术创新与实际需求保持一致。

Conclusion: 该工作连接了理论基础与实际部署，为未来研究提供了路线图，并为在隐私敏感环境中实施合成表格数据提供了指导。

Abstract: As privacy regulations become more stringent and access to real-world data
becomes increasingly constrained, synthetic data generation has emerged as a
vital solution, especially for tabular datasets, which are central to domains
like finance, healthcare and the social sciences. This survey presents a
comprehensive and focused review of recent advances in synthetic tabular data
generation, emphasizing methods that preserve complex feature relationships,
maintain statistical fidelity, and satisfy privacy requirements. A key
contribution of this work is the introduction of a novel taxonomy based on
practical generation objectives, including intended downstream applications,
privacy guarantees, and data utility, directly informing methodological design
and evaluation strategies. Therefore, this review prioritizes the actionable
goals that drive synthetic data creation, including conditional generation and
risk-sensitive modeling. Additionally, the survey proposes a benchmark
framework to align technical innovation with real-world demands. By bridging
theoretical foundations with practical deployment, this work serves as both a
roadmap for future research and a guide for implementing synthetic tabular data
in privacy-critical environments.

</details>


### [142] [Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification](https://arxiv.org/abs/2507.11620)
*Steven Dillmann,Juan Rafael Martínez-Galarza*

Main category: cs.LG

TL;DR: 针对不规则事件时间序列的分析挑战，本文提出利用新颖的二维和三维张量表示结合稀疏自编码器来学习有意义的潜在表示，并成功应用于下游任务。


<details>
  <summary>Details</summary>
Motivation: 事件时间序列在多个领域普遍存在，但其非结构化和不规则的特性使得传统技术难以提取有意义的模式和识别显著现象。

Method: 提出新颖的二维和三维张量表示来处理事件时间序列，并结合稀疏自编码器以学习具有物理意义的潜在表示。这些嵌入支持异常检测、相似性检索、语义聚类和无监督分类等下游任务。

Result: 在X射线天文学的真实数据集上进行验证，所提出的表示成功捕获了时间与光谱特征，并能有效分离出不同类别的X射线瞬变事件。

Conclusion: 该框架为跨科学和工业领域分析复杂、不规则的事件时间序列提供了一种灵活、可扩展且可泛化的解决方案。

Abstract: Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.

</details>


### [143] [ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs](https://arxiv.org/abs/2507.11649)
*Daniel Commey,Benjamin Appiah,Griffith S. Klogo,Garth V. Crosby*

Main category: cs.LG

TL;DR: 提出一种基于零知识证明（ZKP）的新协议，用于联邦学习中隐私保护且可验证的模型评估，避免泄露原始损失值。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的评估阶段可能通过共享性能指标泄露敏感信息。

Method: 引入零知识证明，客户端生成一个简洁证明来断言其局部损失低于预设阈值，而非直接公开损失值。该协议完全独立实现，并在MNIST和人类活动识别（HAR）数据集上，针对卷积神经网络（CNN）和多层感知机（MLP）模型进行了实验。

Result: 对所提方法在计算开销、通信成本和可验证性方面进行了评估。

Conclusion: 该协议成功实现了联邦学习的隐私保护和可验证的评估。

Abstract: Federated Learning (FL) enables collaborative model training on decentralized
data without exposing raw data. However, the evaluation phase in FL may leak
sensitive information through shared performance metrics. In this paper, we
propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to
enable privacy-preserving and verifiable evaluation for FL. Instead of
revealing raw loss values, clients generate a succinct proof asserting that
their local loss is below a predefined threshold. Our approach is implemented
without reliance on external APIs, using self-contained modules for federated
learning simulation, ZKP circuit design, and experimental evaluation on both
the MNIST and Human Activity Recognition (HAR) datasets. We focus on a
threshold-based proof for a simple Convolutional Neural Network (CNN) model
(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate
the approach in terms of computational overhead, communication cost, and
verifiability.

</details>


### [144] [Deep Generative Methods and Tire Architecture Design](https://arxiv.org/abs/2507.11639)
*Fouad Oubari,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 本研究评估了多种深度生成模型（包括VAE、GAN和扩散模型）在工业轮胎结构生成任务中的表现。结果显示扩散模型整体性能最优，但也发现VAE在特定条件生成任务中表现出色，且不同扩散模型变体各有优势。


<details>
  <summary>Details</summary>
Motivation: 工业界在复杂的制造设计任务中，面临如何选择最适合的深度生成模型的关键问题，目前尚无明确答案。

Method: 本研究对五种代表性深度生成模型（VAE、GAN、多模态VAE、DDPM和MDM）在工业轮胎结构生成任务上进行了全面研究。评估涵盖三个工业场景：无条件生成、组件条件生成和维度约束生成。为使离散扩散模型处理条件生成，引入了“分类修复”技术。评估采用专门针对工业要求校准的几何感知指标，量化空间一致性、组件交互、结构连通性和感知保真度。

Result: 研究发现扩散模型实现了最强的整体性能。然而，一个经过掩码训练的VAE在几乎所有组件条件生成指标上均优于多模态MMVAE	extsuperscript{+}。在扩散模型家族内部，MDM在分布内数据上表现领先，而DDPM在分布外维度约束下的泛化能力更强。

Conclusion: 扩散模型在工业制造设计任务中表现出卓越的潜力，尤其是在复杂结构生成方面。但在实际应用中，仍需根据具体任务场景（如条件生成、分布内/外泛化需求）细致考量不同模型及其变体的优势，以实现最佳设计效果。

Abstract: As deep generative models proliferate across the AI landscape, industrial
practitioners still face critical yet unanswered questions about which deep
generative models best suit complex manufacturing design tasks. This work
addresses this question through a complete study of five representative models
(Variational Autoencoder, Generative Adversarial Network, multimodal
Variational Autoencoder, Denoising Diffusion Probabilistic Model, and
Multinomial Diffusion Model) on industrial tire architecture generation. Our
evaluation spans three key industrial scenarios: (i) unconditional generation
of complete multi-component designs, (ii) component-conditioned generation
(reconstructing architectures from partial observations), and (iii)
dimension-constrained generation (creating designs that satisfy specific
dimensional requirements). To enable discrete diffusion models to handle
conditional scenarios, we introduce categorical inpainting, a mask-aware
reverse diffusion process that preserves known labels without requiring
additional training. Our evaluation employs geometry-aware metrics specifically
calibrated for industrial requirements, quantifying spatial coherence,
component interaction, structural connectivity, and perceptual fidelity. Our
findings reveal that diffusion models achieve the strongest overall
performance; a masking-trained VAE nonetheless outperforms the multimodal
variant MMVAE\textsuperscript{+} on nearly all component-conditioned metrics,
and within the diffusion family MDM leads in-distribution whereas DDPM
generalises better to out-of-distribution dimensional constraints.

</details>


### [145] [Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation](https://arxiv.org/abs/2507.11645)
*Ahmed Salah,David Yevick*

Main category: cs.LG

TL;DR: 本文提出多种实用指标，包括Dropout方差、鲁棒性、嵌入相似性和稀疏性，以预测并深入理解神经网络中的Grokking现象（延迟泛化）。


<details>
  <summary>Details</summary>
Motivation: Grokking是神经网络中一种测试准确率提升显著滞后于训练准确率提升的延迟泛化现象。本研究旨在引入实用指标来预测和解释这种行为。

Method: 引入的预测指标包括：Dropout下的方差、鲁棒性（通过Dropout鲁棒性曲线DRC评估）、嵌入相似性及稀疏性度量。具体通过分析测试准确率随dropout率变化的DRC来估计网络对推理噪声的鲁棒性。

Result: 研究发现：在Grokking过程中，随机Dropout下测试准确率在训练检查点间的方差呈现局部最大值；泛化过程中非活跃神经元百分比下降；嵌入趋向于独立于初始化的双峰分布，并与余弦相似性模式和数据集对称性相关联。

Conclusion: 这些提出的指标不仅能有效预测Grokking行为，还为理解Grokking的起源和特性提供了有价值的洞察。

Abstract: Grokking refers to delayed generalization in which the increase in test
accuracy of a neural network occurs appreciably after the improvement in
training accuracy This paper introduces several practical metrics including
variance under dropout, robustness, embedding similarity, and sparsity
measures, that can forecast grokking behavior. Specifically, the resilience of
neural networks to noise during inference is estimated from a Dropout
Robustness Curve (DRC) obtained from the variation of the accuracy with the
dropout rate as the model transitions from memorization to generalization. The
variance of the test accuracy under stochastic dropout across training
checkpoints further exhibits a local maximum during the grokking. Additionally,
the percentage of inactive neurons decreases during generalization, while the
embeddings tend to a bimodal distribution independent of initialization that
correlates with the observed cosine similarity patterns and dataset symmetries.
These metrics additionally provide valuable insight into the origin and
behaviour of grokking.

</details>


### [146] [STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics](https://arxiv.org/abs/2507.11660)
*Joao F. Rocha,Ke Xu,Xingzhi Sun,Ananya Krishna,Dhananjay Bhaskar,Blanche Mongeon,Morgan Craig,Mark Gerstein,Smita Krishnaswamy*

Main category: cs.LG

TL;DR: 本文提出STAGED，一种结合智能体建模（ABM）与深度学习的新方法，用于数据驱动地建模细胞间通信及其对细胞内基因调控网络的影响，以实现更准确的细胞动态表示。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞技术在分析细胞状态和亚群时，将细胞视为独立的点，忽略了细胞间的相互作用。尽管空间转录组学能提供细胞组织和动态相互作用的信息，但仍缺乏数据驱动的计算方法来学习复杂的交互式细胞动态。传统的智能体建模（ABM）依赖于人工规则而非数据驱动。

Method: 引入Spatio Temporal Agent-Based Graph Evolution Dynamics (STAGED) 方法，该方法将智能体建模（ABM）与深度学习相结合，用于建模细胞间通信及其对细胞内基因调控网络的影响。STAGED采用图ODE网络（GDEs），将基因表示为顶点，相互作用表示为有向边，并通过设计的注意力机制动态学习相互作用强度。模型通过匹配模拟轨迹以及从空间转录组数据推断的轨迹进行训练。

Result: 该模型成功捕获了细胞间和细胞内相互作用。

Conclusion: STAGED能够更具适应性和准确性地表示复杂的细胞动态。

Abstract: The advent of single-cell technology has significantly improved our
understanding of cellular states and subpopulations in various tissues under
normal and diseased conditions by employing data-driven approaches such as
clustering and trajectory inference. However, these methods consider cells as
independent data points of population distributions. With spatial
transcriptomics, we can represent cellular organization, along with dynamic
cell-cell interactions that lead to changes in cell state. Still, key
computational advances are necessary to enable the data-driven learning of such
complex interactive cellular dynamics. While agent-based modeling (ABM)
provides a powerful framework, traditional approaches rely on handcrafted rules
derived from domain knowledge rather than data-driven approaches. To address
this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)
integrating ABM with deep learning to model intercellular communication, and
its effect on the intracellular gene regulatory network. Using graph ODE
networks (GDEs) with shared weights per cell type, our approach represents
genes as vertices and interactions as directed edges, dynamically learning
their strengths through a designed attention mechanism. Trained to match
continuous trajectories of simulated as well as inferred trajectories from
spatial transcriptomics data, the model captures both intercellular and
intracellular interactions, enabling a more adaptive and accurate
representation of cellular dynamics.

</details>


### [147] [Composing Linear Layers from Irreducibles](https://arxiv.org/abs/2507.11688)
*Travis Pence,Daisuke Yamada,Vikas Singh*

Main category: cs.LG

TL;DR: 本研究利用Clifford代数，揭示大型模型线性层可分解为几何原语（旋子）的组合，显著减少参数量（从O(d^2)到O(log^2 d)），并在LLM注意力层中达到与现有强基线相当的性能，为理解深度模型内部功能提供了代数视角。


<details>
  <summary>Details</summary>
Motivation: 当代大型模型中构成复杂功能的低级原语机制尚不明确，需要深入理解这些基本组成部分。

Method: 研究利用Clifford代数，将线性层表达为双向量的组合，并提出一种可微分算法将其分解为旋子的乘积。此方法仅需O(log^2 d)参数，远少于密集矩阵的O(d^2)。

Result: 将基于旋子的层应用于大型语言模型（LLM）注意力机制中的键、查询、值投影，其性能与块-哈达玛和低秩近似等强大基线模型相当。

Conclusion: 本研究提供了一个代数视角，阐明了几何原语如何在深度模型中组合形成更高层次的功能，有助于理解模型内部工作机制。

Abstract: Contemporary large models often exhibit behaviors suggesting the presence of
low-level primitives that compose into modules with richer functionality, but
these fundamental building blocks remain poorly understood. We investigate this
compositional structure in linear layers by asking: can we identify/synthesize
linear transformations from a minimal set of geometric primitives? Using
Clifford algebra, we show that linear layers can be expressed as compositions
of bivectors -- geometric objects encoding oriented planes -- and introduce a
differentiable algorithm that decomposes them into products of rotors. This
construction uses only O(log^2 d) parameters, versus O(d^2) required by dense
matrices. Applied to the key, query, and value projections in LLM attention
layers, our rotor-based layers match the performance of strong baselines such
as block-Hadamard and low-rank approximations. Our findings provide an
algebraic perspective on how these geometric primitives can compose into
higher-level functions within deep models.

</details>


### [148] [The Impact of Coreset Selection on Spurious Correlations and Group Robustness](https://arxiv.org/abs/2507.11690)
*Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky*

Main category: cs.LG

TL;DR: 本文首次全面分析了Coreset选择对数据集偏见水平及下游模型鲁棒性的影响，发现基于嵌入的样本特征选择法比基于学习动态的方法在加剧偏见方面的风险较低，但Coreset的低偏见不一定能保证下游模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Coreset选择虽能高效减少训练数据量，但数据集普遍存在的偏见可能导致模型学习虚假关联。因此，需要理解数据缩减方法是否会延续、放大或减轻这些偏见，及其对下游模型鲁棒性的影响。

Method: 研究采用广泛的实验设置，涵盖10个不同的虚假关联基准数据集、5种样本重要性/难度评估指标和5种数据选择策略，并考察了不同Coreset大小下的情况，以全面分析数据选择的影响。

Result: 研究揭示了样本难度与偏见对齐、数据集偏见与模型鲁棒性之间非平凡的相互作用。例如，使用基于嵌入的样本特征分数选择Coreset比基于学习动态的方法在无意中加剧偏见方面的风险更低。

Conclusion: 分析表明，尽管一些Coreset选择方法通过优先处理困难样本可以降低偏见水平，但它们并不能可靠地保证下游模型的鲁棒性。

Abstract: Coreset selection methods have shown promise in reducing the training data
size while maintaining model performance for data-efficient machine learning.
However, as many datasets suffer from biases that cause models to learn
spurious correlations instead of causal features, it is important to understand
whether and how dataset reduction methods may perpetuate, amplify, or mitigate
these biases. In this work, we conduct the first comprehensive analysis of the
implications of data selection on the spurious bias levels of the selected
coresets and the robustness of downstream models trained on them. We use an
extensive experimental setting spanning ten different spurious correlations
benchmarks, five score metrics to characterize sample importance/ difficulty,
and five data selection policies across a broad range of coreset sizes.
Thereby, we unravel a series of nontrivial nuances in interactions between
sample difficulty and bias alignment, as well as dataset bias and resultant
model robustness. For example, we find that selecting coresets using
embedding-based sample characterization scores runs a comparatively lower risk
of inadvertently exacerbating bias than selecting using characterizations based
on learning dynamics. Most importantly, our analysis reveals that although some
coreset selection methods could achieve lower bias levels by prioritizing
difficult samples, they do not reliably guarantee downstream robustness.

</details>


### [149] [Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption](https://arxiv.org/abs/2507.11702)
*Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet*

Main category: cs.LG

TL;DR: 本研究开发了一种基于LSTM和卫星数据预测落叶时间的新系统，以帮助英国铁路行业有效调度除叶措施，从而减少落叶造成的交通中断和经济损失。


<details>
  <summary>Details</summary>
Motivation: 英国铁路因落叶导致的交通中断每年损失超3亿英镑，现有落叶预测方法在可扩展性和可靠性方面存在局限性，因此需要开发更精准的预测系统以优化缓解措施的调度。

Method: 利用长短期记忆 (LSTM) 网络，结合地面实测落叶数据、多光谱卫星数据和气象卫星数据进行训练，构建落叶时间预测系统。

Result: 该系统对落叶开始时间的预测均方根误差为6.32天，对落叶结束时间的预测均方根误差为9.31天。

Conclusion: 该模型在现有研究基础上有所改进，为铁路行业优化落叶缓解措施提供了有前景的机遇，并有助于加深对复杂生态系统的理解。

Abstract: Railroad traffic disruption as a result of leaf-fall cost the UK rail
industry over 300 million per year and measures to mitigate such disruptions
are employed on a large scale, with 1.67 million kilometers of track being
treated in the UK in 2021 alone. Therefore, the ability to anticipate the
timing of leaf-fall would offer substantial benefits for rail network
operators, enabling the efficient scheduling of such mitigation measures.
However, current methodologies for predicting leaf-fall exhibit considerable
limitations in terms of scalability and reliability. This study endeavors to
devise a prediction system that leverages specialized prediction methods and
the latest satellite data sources to generate both scalable and reliable
insights into leaf-fall timings. An LSTM network trained on ground-truth
leaf-falling data combined with multispectral and meteorological satellite data
demonstrated a root-mean-square error of 6.32 days for predicting the start of
leaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which
improves upon previous work on the topic, offers promising opportunities for
the optimization of leaf mitigation measures in the railway industry and the
improvement of our understanding of complex ecological systems.

</details>


### [150] [Reinforcement Learning from Adversarial Preferences in Tabular MDPs](https://arxiv.org/abs/2507.11706)
*Taira Tsuchiya,Shinji Ito,Haipeng Luo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a new framework of episodic tabular Markov decision processes
(MDPs) with adversarial preferences, which we refer to as preference-based MDPs
(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the
numerical value of the loss is directly observed, in PbMDPs the learner instead
observes preferences between two candidate arms, which represent the choices
being compared. In this work, we focus specifically on the setting where the
reward functions are determined by Borda scores. We begin by establishing a
regret lower bound for PbMDPs with Borda scores. As a preliminary step, we
present a simple instance to prove a lower bound of $\Omega(\sqrt{HSAT})$ for
episodic MDPs with adversarial losses, where $H$ is the number of steps per
episode, $S$ is the number of states, $A$ is the number of actions, and $T$ is
the number of episodes. Leveraging this construction, we then derive a regret
lower bound of $\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda
scores, where $K$ is the number of arms. Next, we develop algorithms that
achieve a regret bound of order $T^{2/3}$. We first propose a global
optimization approach based on online linear optimization over the set of all
occupancy measures, achieving a regret bound of $\tilde{O}((H^2 S^2 K)^{1/3}
T^{2/3} )$ under known transitions. However, this approach suffers from
suboptimal dependence on the potentially large number of states $S$ and
computational inefficiency. To address this, we propose a policy optimization
algorithm whose regret is roughly bounded by $\tilde{O}( (H^6 S K^5)^{1/3}
T^{2/3} )$ under known transitions, and further extend the result to the
unknown-transition setting.

</details>


### [151] [Subgraph Generation for Generalizing on Out-of-Distribution Links](https://arxiv.org/abs/2507.11710)
*Jay Revolinsky,Harry Shomer,Jiliang Tang*

Main category: cs.LG

TL;DR: FLEX是一个图生成模型框架，通过结构条件生成和对抗协同训练，提升图神经网络（GNNs）在域外（OOD）场景下链路预测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNNs）在链路预测任务上表现出色，但普遍依赖于数据同分布的假设，这限制了它们在域外（OOD）场景下的性能。同时，图生成模型（GGMs）虽具备生成新图的能力，但其应用大多局限于特定领域。

Method: 提出FLEX框架，一个基于图生成模型（GGM）的方法，旨在弥合GNN在OOD场景下的局限性。FLEX整合了两种关键机制：1) 结构条件图生成；2) 自动编码器与GNN之间的对抗协同训练。通过这些机制，FLEX确保样本分布的结构对齐，从而增强在域外（OOD）场景下的链路预测性能。

Result: 在合成和真实世界的域外（OOD）设置中进行了大量实验，结果表明FLEX能够显著提升链路预测性能。值得注意的是，FLEX在不同OOD场景下均无需专家知识。研究还对图数据增强如何影响链路结构进行了深入分析。

Conclusion: FLEX成功弥合了GNN在OOD场景下的链路预测挑战与GGM的生成能力之间的差距。它提供了一个高效且无需专家知识的GGM框架，通过其独特的结构对齐和协同训练机制，有效提升了非同分布环境下的链路预测准确性。

Abstract: Graphs Neural Networks (GNNs) demonstrate high-performance on the link
prediction (LP) task. However, these models often rely on all dataset samples
being drawn from the same distribution. In addition, graph generative models
(GGMs) show a pronounced ability to generate novel output graphs. Despite this,
GGM applications remain largely limited to domain-specific tasks. To bridge
this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)
structurally-conditioned graph generation, and (2) adversarial co-training
between an auto-encoder and GNN. As such, FLEX ensures structural-alignment
between sample distributions to enhance link-prediction performance in
out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert
knowledge to function in different OOD scenarios. Numerous experiments are
conducted in synthetic and real-world OOD settings to demonstrate FLEX's
performance-enhancing ability, with further analysis for understanding the
effects of graph data augmentation on link structures. The source code is
available here: https://github.com/revolins/FlexOOD.

</details>


### [152] [Globalization for Scalable Short-term Load Forecasting](https://arxiv.org/abs/2507.11729)
*Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung*

Main category: cs.LG

TL;DR: 本研究探讨了全局负荷预测模型（GFMs）在数据漂移下的应用，并提出了时间序列聚类（TSC）方法来处理数据异质性，结果表明全局目标转换模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的局部负荷预测模型（LFMs）在处理泛化性、过拟合、数据漂移、冷启动问题以及可扩展性方面存在显著局限性，促使研究者寻求更优的全局预测方法。

Method: 研究了特征转换型和目标转换型两类全局负荷预测模型，分析了全局化、数据异质性和数据漂移对其影响。为解决数据异质性，提出了针对特征转换模型的基于模型的TSC和针对目标转换模型的新型加权实例TSC。

Result: 在真实数据集上的实验表明，全局目标转换模型持续优于局部模型，尤其是在加入全局特征和聚类技术后。而全局特征转换模型则在平衡局部和全局动态方面面临挑战，通常需要TSC来有效管理数据异质性。

Conclusion: 全局负荷预测模型，特别是结合了适当聚类技术的全局目标转换模型，能有效提升负荷预测的泛化性、可扩展性、准确性和鲁棒性，尤其适用于存在数据漂移和异质性的电力传输网络负荷预测。

Abstract: Forecasting load in power transmission networks is essential across various
hierarchical levels, from the system level down to individual points of
delivery (PoD). While intuitive and locally accurate, traditional local
forecasting models (LFMs) face significant limitations, particularly in
handling generalizability, overfitting, data drift, and the cold start problem.
These methods also struggle with scalability, becoming computationally
expensive and less efficient as the network's size and data volume grow. In
contrast, global forecasting models (GFMs) offer a new approach to enhance
prediction generalizability, scalability, accuracy, and robustness through
globalization and cross-learning. This paper investigates global load
forecasting in the presence of data drifts, highlighting the impact of
different modeling techniques and data heterogeneity. We explore
feature-transforming and target-transforming models, demonstrating how
globalization, data heterogeneity, and data drift affect each differently. In
addition, we examine the role of globalization in peak load forecasting and its
potential for hierarchical forecasting. To address data heterogeneity and the
balance between globality and locality, we propose separate time series
clustering (TSC) methods, introducing model-based TSC for feature-transforming
models and new weighted instance-based TSC for target-transforming models.
Through extensive experiments on a real-world dataset of Alberta's electricity
load, we demonstrate that global target-transforming models consistently
outperform their local counterparts, especially when enriched with global
features and clustering techniques. In contrast, global feature-transforming
models face challenges in balancing local and global dynamics, often requiring
TSC to manage data heterogeneity effectively.

</details>


### [153] [Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning](https://arxiv.org/abs/2507.11732)
*Shiyu Chen,Cencheng Shen,Youngser Park,Carey E. Priebe*

Main category: cs.LG

TL;DR: 该论文提出了GEE-powered GNN (GG) 框架，利用GEE生成高质量初始节点特征，以提升GNN在节点聚类和分类任务中的性能和收敛速度，并实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）的性能常受限于对随机或信息不足的初始特征表示的依赖，这会导致收敛缓慢和次优解决方案。

Method: 引入统计学方法“one-hot图编码器嵌入（GEE）”来生成高质量初始节点特征，并将其与GNNs整合，形成GG框架。针对节点分类，进一步提出GG-C，它结合了GG和GEE的输出。通过广泛的模拟和真实世界实验在无监督和有监督设置下验证了其有效性。

Result: 在节点聚类中，GG始终达到最先进的性能，在所有评估的真实世界数据集中均排名第一，并比标准GNN表现出更快的收敛速度。在节点分类中，GG-C优于现有基线方法。

Conclusion: 研究结果证实了有原则、结构感知的特征初始化对于充分发挥GNNs潜力至关重要。

Abstract: Graph neural networks (GNNs) have emerged as a powerful framework for a wide
range of node-level graph learning tasks. However, their performance is often
constrained by reliance on random or minimally informed initial feature
representations, which can lead to slow convergence and suboptimal solutions.
In this paper, we leverage a statistically grounded method, one-hot graph
encoder embedding (GEE), to generate high-quality initial node features that
enhance the end-to-end training of GNNs. We refer to this integrated framework
as the GEE-powered GNN (GG), and demonstrate its effectiveness through
extensive simulations and real-world experiments across both unsupervised and
supervised settings. In node clustering, GG consistently achieves
state-of-the-art performance, ranking first across all evaluated real-world
datasets, while exhibiting faster convergence compared to the standard GNN. For
node classification, we further propose an enhanced variant, GG-C, which
concatenates the outputs of GG and GEE and outperforms competing baselines.
These results confirm the importance of principled, structure-aware feature
initialization in realizing the full potential of GNNs.

</details>


### [154] [Sparse Identification of Nonlinear Dynamics with Conformal Prediction](https://arxiv.org/abs/2507.11739)
*Urban Fasel*

Main category: cs.LG

TL;DR: 本文将共形预测（Conformal Prediction）与集成SINDy（E-SINDy）相结合，以量化SINDy模型的不确定性，并展示其在时间序列预测、模型选择和系数不确定性量化方面的改进。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中，量化SINDy（非线性动力系统稀疏识别）模型的不确定性对于评估其可靠性至关重要。尽管已有多种不确定性量化方法，但本研究旨在探索共形预测的集成，以提供具有覆盖保证的有效预测区间。

Method: 本研究将共形预测框架集成到集成SINDy（E-SINDy）中，并探讨了三种应用：1) 量化时间序列预测中的不确定性；2) 基于库特征重要性进行模型选择；3) 使用特征共形预测量化识别模型系数的不确定性。这些方法在随机捕食者-猎物动力学和多个混沌动力系统上进行了验证。

Result: 结果显示，结合共形预测的E-SINDy方法能够可靠地实现时间序列预测的期望目标覆盖，有效量化特征重要性，并且与标准E-SINDy系数估计相比，即使在非高斯噪声下，也能为模型系数生成更鲁棒的不确定性区间。

Conclusion: 将共形预测方法集成到E-SINDy中，为SINDy模型提供了一种更可靠、更鲁棒的不确定性量化途径，显著提升了其在多种应用场景下的可靠性和准确性。

Abstract: The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for
discovering nonlinear dynamical system models from data. Quantifying
uncertainty in SINDy models is essential for assessing their reliability,
particularly in safety-critical applications. While various uncertainty
quantification methods exist for SINDy, including Bayesian and ensemble
approaches, this work explores the integration of Conformal Prediction, a
framework that can provide valid prediction intervals with coverage guarantees
based on minimal assumptions like data exchangeability. We introduce three
applications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)
quantifying uncertainty in time series prediction, (2) model selection based on
library feature importance, and (3) quantifying the uncertainty of identified
model coefficients using feature conformal prediction. We demonstrate the three
applications on stochastic predator-prey dynamics and several chaotic dynamical
systems. We show that conformal prediction methods integrated with E-SINDy can
reliably achieve desired target coverage for time series forecasting,
effectively quantify feature importance, and produce more robust uncertainty
intervals for model coefficients, even under non-Gaussian noise, compared to
standard E-SINDy coefficient estimates.

</details>


### [155] [A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction](https://arxiv.org/abs/2507.11757)
*Yuehua Song,Yong Gao*

Main category: cs.LG

TL;DR: 本文提出了一种名为Graph-in-Graph (GiG) 的新型GNN模型，通过融合转导学习和归纳学习，有效整合药物、靶点及其相互作用的多元特征，显著提升了药物-靶点相互作用预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有机器学习方法（包括基于GNN的方法）在药物-靶点相互作用（DTI）预测中取得了进展，但它们难以有效地整合药物、靶点及其相互作用的多种特征。

Method: 引入了一个新颖的框架，旨在结合转导学习和归纳学习的优势，以利用分子层面和药物-靶点相互作用网络层面的特征。在该框架内，提出了一个GNN模型，名为Graph-in-Graph (GiG)，它将药物和靶点的分子结构图表示为药物-靶点相互作用图中的元节点。为评估模型性能，还编译了一个包含药物SMILES、蛋白质序列及其相互作用数据的专用基准数据集。

Result: 实验结果表明，GiG模型在所有评估指标上均显著优于现有方法。

Conclusion: 整合不同的学习范式和交互数据对药物-靶点相互作用预测非常有益，GiG模型有效解决了多特征整合的挑战，显著提升了预测性能。

Abstract: Accurately predicting drug-target interactions (DTIs) is pivotal for
advancing drug discovery and target validation techniques. While machine
learning approaches including those that are based on Graph Neural Networks
(GNN) have achieved notable success in DTI prediction, many of them have
difficulties in effectively integrating the diverse features of drugs, targets
and their interactions. To address this limitation, we introduce a novel
framework to take advantage of the power of both transductive learning and
inductive learning so that features at molecular level and drug-target
interaction network level can be exploited. Within this framework is a
GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and
target molecular structures as meta-nodes in a drug-target interaction graph,
enabling a detailed exploration of their intricate relationships. To evaluate
the proposed model, we have compiled a special benchmark comprising drug
SMILES, protein sequences, and their interaction data, which is interesting in
its own right. Our experimental results demonstrate that the GiG model
significantly outperforms existing approaches across all evaluation metrics,
highlighting the benefits of integrating different learning paradigms and
interaction data.

</details>


### [156] [Torsional-GFN: a conditional conformation generator for small molecules](https://arxiv.org/abs/2507.11759)
*Alexandra Volokhova,Léna Néhale Ezzine,Piotr Gaiński,Luca Scimeca,Emmanuel Bengio,Prudencio Tossou,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: 本文提出Torsional-GFN，一种基于GFlowNet的生成式AI方法，能够高效且准确地从玻尔兹曼分布中采样分子构象，并表现出良好的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成稳定的分子构象在药物发现中至关重要。传统的分子动力学方法效率不高，而新兴的生成式机器学习方法虽然有前景，但仍需要更有效的方法来从玻尔兹曼分布中采样构象。

Method: 引入了Torsional-GFN，一个条件GFlowNet模型。该模型以分子图及其局部结构（键长、键角）为条件，通过采样分子的扭转角来生成构象。其训练仅使用奖励函数，旨在使采样构象与玻尔兹曼分布成比例。

Result: Torsional-GFN能够使用单一模型为多个分子生成近似符合玻尔兹曼分布的构象。它还实现了对来自MD模拟的未见过键长和键角的零样本泛化能力。

Conclusion: 本研究提供了一种有前景的分子构象采样方法，展示了其高效性和泛化能力。该方法有望扩展到更大的分子系统，实现对未见分子的零样本泛化，并可进一步整合局部结构生成功能。

Abstract: Generating stable molecular conformations is crucial in several drug
discovery applications, such as estimating the binding affinity of a molecule
to a target. Recently, generative machine learning methods have emerged as a
promising, more efficient method than molecular dynamics for sampling of
conformations from the Boltzmann distribution. In this paper, we introduce
Torsional-GFN, a conditional GFlowNet specifically designed to sample
conformations of molecules proportionally to their Boltzmann distribution,
using only a reward function as training signal. Conditioned on a molecular
graph and its local structure (bond lengths and angles), Torsional-GFN samples
rotations of its torsion angles. Our results demonstrate that Torsional-GFN is
able to sample conformations approximately proportional to the Boltzmann
distribution for multiple molecules with a single model, and allows for
zero-shot generalization to unseen bond lengths and angles coming from the MD
simulations for such molecules. Our work presents a promising avenue for
scaling the proposed approach to larger molecular systems, achieving zero-shot
generalization to unseen molecules, and including the generation of the local
structure into the GFlowNet model.

</details>


### [157] [Scaling laws for activation steering with Llama 2 models and refusal mechanisms](https://arxiv.org/abs/2507.11771)
*Sheikh Abdur Raheem Ali,Justin Xu,Ivory Yang,Jasmine Xinze Li,Ayse Arslan,Clark Benham*

Main category: cs.LG

TL;DR: 本文研究了对比激活添加（CAA）在不同规模Llama 2模型上的有效性，发现其效果随模型增大而减弱，且负向操纵效果更显著。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的复杂性和能力不断发展，较少部署的对齐技术的有效性尚不确定。

Method: 基于激活引导和对比激活添加（CAA）技术，通过在模型残差流向量空间中利用对比对（如“恨”到“爱”）找到并添加期望方向，直接操纵残差流以控制模型输出。实验使用Llama 2模型（7B、13B、70B）家族，通过围绕拒绝行为的答案匹配问题评估CAA随模型规模变化的有效性。

Result: 1) CAA在早期到中期层应用时最有效。2) CAA的有效性随模型规模的增大而减弱。3) 负向操纵比正向操纵在所有模型规模下都具有更显著的效果。

Conclusion: 对比激活添加（CAA）是一种能够控制LLMs输出的有效方法，但其效果受应用层级和模型规模影响，且在大型模型上效果减弱，负向操纵效果更显著。

Abstract: As large language models (LLMs) evolve in complexity and capability, the
efficacy of less widely deployed alignment techniques are uncertain. Building
on previous work on activation steering and contrastive activation addition
(CAA), this paper explores the effectiveness of CAA with model scale using the
family of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable
'directions' in the model's residual stream vector space using contrastive
pairs (for example, hate to love) and adding this direction to the residual
stream during the forward pass. It directly manipulates the residual stream and
aims to extract features from language models to better control their outputs.
Using answer matching questions centered around the refusal behavior, we found
that 1) CAA is most effective when applied at early-mid layers. 2) The
effectiveness of CAA diminishes with model size. 3) Negative steering has more
pronounced effects than positive steering across all model sizes.

</details>


### [158] [Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network](https://arxiv.org/abs/2507.11776)
*Merel Kampere,Ali Mohammed Mansoor Alsahag*

Main category: cs.LG

TL;DR: 本研究通过XGBoost结合拓扑特征预测荷兰铁路延误，并与其他分类器进行比较。尽管性能有限，但为交通网络评估提供了见解并指明了未来方向。


<details>
  <summary>Details</summary>
Motivation: 荷兰铁路网络繁忙，延误是运营商NS关注的突出问题。现有延误预测研究主要侧重短期预测，忽略了更广泛的网络模式，因此存在利用拓扑特征进行荷兰铁路延误预测的研究空白。

Method: 研究采用XGBoost分类器，重点关注拓扑特征，特别是集成节点中心性度量。该方法是对原用于预测美国航空网络演变方法的实施和改进。同时，还对比了RandomForest、DecisionTree、GradientBoosting、AdaBoost和LogisticRegression等多种分类器，旨在预测延迟轨迹。

Result: 研究结果显示模型性能有限，特别是在非同步测试场景中表现不佳，这表明需要进行更多针对特定上下文的适应。

Conclusion: 尽管预测性能存在局限性，本研究仍有助于增进对交通网络评估的理解，并为未来开发更鲁棒的延误预测模型提出了方向。

Abstract: The Dutch railway network is one of the busiest in the world, with delays
being a prominent concern for the principal passenger railway operator NS. This
research addresses a gap in delay prediction studies within the Dutch railway
network by employing an XGBoost Classifier with a focus on topological
features. Current research predominantly emphasizes short-term predictions and
neglects the broader network-wide patterns essential for mitigating ripple
effects. This research implements and improves an existing methodology,
originally designed to forecast the evolution of the fast-changing US air
network, to predict delays in the Dutch Railways. By integrating Node
Centrality Measures and comparing multiple classifiers like RandomForest,
DecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is
to predict delayed trajectories. However, the results reveal limited
performance, especially in non-simultaneous testing scenarios, suggesting the
necessity for more context-specific adaptations. Regardless, this research
contributes to the understanding of transportation network evaluation and
proposes future directions for developing more robust predictive models for
delays.

</details>


### [159] [Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation](https://arxiv.org/abs/2507.11789)
*Alessandro Palma,Sergei Rybakov,Leon Hetzel,Stephan Günnemann,Fabian J. Theis*

Main category: cs.LG

TL;DR: FlatVI是一种新颖的训练框架，通过正则化离散似然变分自编码器（VAEs）的潜在流形使其趋向欧几里得几何，从而在单细胞RNA测序数据中实现更准确的轨迹重建和流形插值，解决了现有方法中潜在空间线性插值与数据流形测地线不符的问题。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞RNA测序方法常使用变分自编码器，假设潜在空间中的线性位移和欧几里得几何来建模细胞状态转换。然而，潜在空间中的线性插值通常与数据流形上的测地线路径不符，这限制了假设欧几里得几何的数据表示方法的有效性。

Method: 本文提出了FlatVI，一个针对单细胞计数数据设计的训练框架。它通过正则化离散似然变分自编码器的潜在流形使其趋向欧几里得几何。FlatVI促使潜在空间中的直线近似解码后的单细胞流形上的测地线插值，从而增强了与假设欧几里得潜在几何的下游方法的兼容性。

Result: 合成数据上的实验证明了FlatVI的理论合理性。在时间分辨单细胞RNA测序数据上的应用表明，FlatVI显著改善了细胞轨迹重建和流形插值的效果。

Conclusion: FlatVI成功解决了现有单细胞分析方法中潜在空间线性插值与数据流形测地线不匹配的局限性。通过使潜在流形趋向欧几里得几何，FlatVI提高了轨迹重建和流形插值的准确性，并增强了与假设欧几里得潜在几何的下游分析的兼容性。

Abstract: Latent space interpolations are a powerful tool for navigating deep
generative models in applied settings. An example is single-cell RNA
sequencing, where existing methods model cellular state transitions as latent
space interpolations with variational autoencoders, often assuming linear
shifts and Euclidean geometry. However, unless explicitly enforced, linear
interpolations in the latent space may not correspond to geodesic paths on the
data manifold, limiting methods that assume Euclidean geometry in the data
representations. We introduce FlatVI, a novel training framework that
regularises the latent manifold of discrete-likelihood variational autoencoders
towards Euclidean geometry, specifically tailored for modelling single-cell
count data. By encouraging straight lines in the latent space to approximate
geodesic interpolations on the decoded single-cell manifold, FlatVI enhances
compatibility with downstream approaches that assume Euclidean latent geometry.
Experiments on synthetic data support the theoretical soundness of our
approach, while applications to time-resolved single-cell RNA sequencing data
demonstrate improved trajectory reconstruction and manifold interpolation.

</details>


### [160] [CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels](https://arxiv.org/abs/2507.11807)
*Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 本文提出CLID-MU方法，用于在没有干净元数据集的情况下，解决元学习中带噪声标签（LNL）的挑战。它利用神经网络最后一隐藏层和最终层之间的数据结构一致性来评估模型性能并指导训练，并在实验中超越了现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 在有噪声标签数据下训练深度神经网络（LNL）非常重要，现有元学习方法虽有效但严重依赖于难以获取的干净标注元数据集。因此，研究的动机是在不依赖干净标注数据集的情况下，应对噪声标签场景下的元学习挑战。

Method: 该研究提出了跨层信息散度元更新策略（CLID-MU）。其核心思想是干净样本能有效保持最后一隐藏层和最终层之间相关数据结构的一致性，而噪声样本则会破坏这种一致性。CLID-MU利用这些不同特征空间之间数据结构的对齐来评估模型性能，并以此指导训练过程。

Result: 在基准数据集上，CLID-MU在合成噪声和真实世界噪声以及不同标签量的情况下，表现均优于现有最先进的方法。

Conclusion: CLID-MU方法成功解决了元学习在噪声标签场景中对干净元数据集的依赖问题，通过利用数据自身的跨层信息一致性，有效提高了模型在噪声环境下的学习性能和鲁棒性。

Abstract: Learning with noisy labels (LNL) is essential for training deep neural
networks with imperfect data. Meta-learning approaches have achieved success by
using a clean unbiased labeled set to train a robust model. However, this
approach heavily depends on the availability of a clean labeled meta-dataset,
which is difficult to obtain in practice. In this work, we thus tackle the
challenge of meta-learning for noisy label scenarios without relying on a clean
labeled dataset. Our approach leverages the data itself while bypassing the
need for labels. Building on the insight that clean samples effectively
preserve the consistency of related data structures across the last hidden and
the final layer, whereas noisy samples disrupt this consistency, we design the
Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU).
CLID-MU leverages the alignment of data structures across these diverse feature
spaces to evaluate model performance and use this alignment to guide training.
Experiments on benchmark datasets with varying amounts of labels under both
synthetic and real-world noise demonstrate that CLID-MU outperforms
state-of-the-art methods. The code is released at
https://github.com/ruofanhu/CLID-MU.

</details>


### [161] [SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling](https://arxiv.org/abs/2507.11818)
*Andrei Rekesh,Miruna Cretu,Dmytro Shevchuk,Vignesh Ram Somnath,Pietro Liò,Robert A. Batey,Mike Tyers,Michał Koziarski,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: 本文提出SynCoGen框架，结合蒙版图扩散和流匹配，实现可合成的3D小分子共同生成，并在无条件生成和分子连接器设计中达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 小分子生成设计在确保可合成性方面仍是主要挑战，且现有方法多局限于2D分子图表示，限制了几何条件生成能力。

Method: 开发了SynCoGen框架，结合蒙版图扩散和流匹配技术，实现可合成的3D分子生成，并从分子构件、化学反应和原子坐标的联合分布中采样。为训练模型，构建了SynSpace数据集，包含超过60万个合成感知构建块图和330万个构象异构体。

Result: SynCoGen在无条件小分子图和构象异构体生成方面取得了最先进的性能，并在药物发现的蛋白质配体生成零样本分子连接器设计中表现出竞争力。

Conclusion: 这种多模态配方为未来非自回归分子生成应用奠定了基础，包括类似物扩展、先导物优化和直接结构条件生成。

Abstract: Ensuring synthesizability in generative small molecule design remains a major
challenge. While recent developments in synthesizable molecule generation have
demonstrated promising results, these efforts have been largely confined to 2D
molecular graph representations, limiting the ability to perform geometry-based
conditional generation. In this work, we present SynCoGen (Synthesizable
Co-Generation), a single framework that combines simultaneous masked graph
diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen
samples from the joint distribution of molecular building blocks, chemical
reactions, and atomic coordinates. To train the model, we curated SynSpace, a
dataset containing over 600K synthesis-aware building block graphs and 3.3M
conformers. SynCoGen achieves state-of-the-art performance in unconditional
small molecule graph and conformer generation, and the model delivers
competitive performance in zero-shot molecular linker design for protein ligand
generation in drug discovery. Overall, this multimodal formulation represents a
foundation for future applications enabled by non-autoregressive molecular
generation, including analog expansion, lead optimization, and direct structure
conditioning.

</details>


### [162] [MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory](https://arxiv.org/abs/2507.11821)
*Pouya Shaeri,Arash Karimi,Ariane Middel*

Main category: cs.LG

TL;DR: MNIST-Gen是一个自动化框架，利用CLIP、强化学习和人工反馈，为用户定制生成MNIST风格的图像数据集，以解决领域专用数据不足的问题，并显著提高数据生成效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有标准数据集（如MNIST）过于通用，无法满足特定领域任务的需求。同时，手动创建和发布定制数据集耗时且存在法律限制。

Method: 本研究提出了MNIST-Gen框架，通过结合CLIP语义理解、强化学习和人工反馈，利用分层语义分类来自动生成用户指定类别的MNIST风格图像数据集。该系统支持复杂类别结构和多种处理模式（个体审查、智能批处理、快速批处理），并将数据转换阶段建模为可组合态射。

Result: 作为概念验证，成功生成并基准测试了Tree-MNIST和Food-MNIST两个新数据集。MNIST-Gen在生成任务特定评估数据方面展现了实用性，实现了85%的自动分类准确率，并比手动方法节省了80%的时间。

Conclusion: MNIST-Gen提供了一种高效、灵活且自动化的方法来生成领域特定的MNIST风格图像数据集，有效弥补了现有通用数据集的局限性，并大幅提升了数据准备的效率和自动化程度。

Abstract: Neural networks are often benchmarked using standard datasets such as MNIST,
FashionMNIST, or other variants of MNIST, which, while accessible, are limited
to generic classes such as digits or clothing items. For researchers working on
domain-specific tasks, such as classifying trees, food items, or other
real-world objects, these data sets are insufficient and irrelevant.
Additionally, creating and publishing a custom dataset can be time consuming,
legally constrained, or beyond the scope of individual projects. We present
MNIST-Gen, an automated, modular, and adaptive framework for generating
MNIST-style image datasets tailored to user-specified categories using
hierarchical semantic categorization. The system combines CLIP-based semantic
understanding with reinforcement learning and human feedback to achieve
intelligent categorization with minimal manual intervention. Our hierarchical
approach supports complex category structures with semantic characteristics,
enabling fine-grained subcategorization and multiple processing modes:
individual review for maximum control, smart batch processing for large
datasets, and fast batch processing for rapid creation. Inspired by category
theory, MNIST-Gen models each data transformation stage as a composable
morphism, enhancing clarity, modularity, and extensibility. As proof of
concept, we generate and benchmark two novel datasets-\textit{Tree-MNIST} and
\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing
task-specific evaluation data while achieving 85\% automatic categorization
accuracy and 80\% time savings compared to manual approaches.

</details>


### [163] [HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction](https://arxiv.org/abs/2507.11836)
*Jian Gao,Jianshe Wu,JingYi Ding*

Main category: cs.LG

TL;DR: 提出HyperEvent框架，通过识别超事件重构动态图链路预测，有效捕捉事件间结构关联，并在准确性和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有节点中心和事件中心方法未能捕获复合超事件（即因果相关事件组）的结构凝聚力，导致动态链路预测能力受限。

Method: 提出HyperEvent框架，将动态链路预测重构为超事件识别。核心是利用事件关联向量动态构建关联序列，量化查询事件与历史事件之间的依赖性，以表征潜在超事件的结构凝聚力。预测通过评估查询事件是否与历史事件共同构成有效超事件。为提高可扩展性，引入了高效并行训练算法。

Result: HyperEvent在官方排行榜上4/5的数据集上超越SOTA方法。实验证明其在大规模图上具有卓越的准确性和效率。特别是在大型Flight数据集上，平均倒数排名（MRR）比SOTA基线提升6.95%，同时训练时间仅为其10.17%。

Conclusion: HyperEvent成功通过识别超事件解决了动态链路预测中现有方法无法捕捉结构凝聚力的问题。其在准确性和效率方面的显著提升，使其成为大规模动态图分析的有效且可扩展的解决方案。

Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental
task for modeling evolving complex systems. Existing node-centric and
event-centric methods focus on individual interactions or atomic states,
failing to capture the structural cohesion of composite hyper-events, groups of
causally related events. To address this, we propose HyperEvent, a framework
reframing dynamic link prediction as hyper-event recognition. Central to
HyperEvent is the dynamic construction of an association sequence using event
correlation vectors. These vectors quantify pairwise dependencies between the
query event and relevant historical events, thereby characterizing the
structural cohesion of a potential hyper-event. The framework predicts the
occurrence of the query event by evaluating whether it collectively forms a
valid hyper-event with these historical events. Notably, HyperEvent outperforms
state-of-the-art methods on 4 out of 5 datasets in the official leaderboard.
For scalability, we further introduce an efficient parallel training algorithm
that segments large event streams to enable concurrent training. Experiments
validate HyperEvent's superior accuracy and efficiency on large-scale graphs.
Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank
over state-of-the-art baseline on the large-scale Flight dataset while
utilizing only 10.17% of the training time.

</details>


### [164] [Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM](https://arxiv.org/abs/2507.11839)
*Chengyue Gong,Xinshi Chen,Yuxuan Zhang,Yuxuan Song,Hao Zhou,Wenzhi Xiao*

Main category: cs.LG

TL;DR: 提出Protenix-Mini模型，通过优化采样策略（两步ODE）、剪枝冗余架构和引入ESM模块替代MSA，实现高效蛋白质结构预测，在计算复杂度显著降低的同时，预测精度仅略微下降1-5%。


<details>
  <summary>Details</summary>
Motivation: 生物分子结构预测及相关下游任务需要轻量级推理以实现高效部署和大规模应用，核心挑战在于平衡模型效率与预测精度。

Method: 1. 将多步AF3采样器替换为少量步数的ODE采样器，以降低扩散模块的计算开销。2. 对Protenix框架中冗余的Pairformer或Diffusion Transformer块进行架构剪枝和轻量化重新设计。3. 训练一个集成ESM模块的模型以替代传统的MSA模块，减少预处理时间。这些方法共同构建了紧凑且优化的Protenix-Mini模型。

Result: Protenix-Mini显著降低了模型复杂度。在基准数据集上的评估表明，它实现了高保真预测，与全尺寸模型相比，性能仅有可忽略的1%至5%的下降。

Conclusion: Protenix-Mini是计算资源有限但仍需精确结构预测的应用场景的理想选择。

Abstract: Lightweight inference is critical for biomolecular structure prediction and
other downstream tasks, enabling efficient real-world deployment and
inference-time scaling for large-scale applications. In this work, we address
the challenge of balancing model efficiency and prediction accuracy by making
several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step
ODE sampler, significantly reducing computational overhead for the diffusion
module part during inference; 2) In the open-source Protenix framework, a
subset of pairformer or diffusion transformer blocks doesn't make contributions
to the final structure prediction, presenting opportunities for architectural
pruning and lightweight redesign; 3) A model incorporating an ESM module is
trained to substitute the conventional MSA module, reducing MSA preprocessing
time. Building on these key insights, we present Protenix-Mini, a compact and
optimized model designed for efficient protein structure prediction. This
streamlined version incorporates a more efficient architectural design with a
two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating
redundant Transformer components and refining the sampling process,
Protenix-Mini significantly reduces model complexity with slight accuracy drop.
Evaluations on benchmark datasets demonstrate that it achieves high-fidelity
predictions, with only a negligible 1 to 5 percent decrease in performance on
benchmark datasets compared to its full-scale counterpart. This makes
Protenix-Mini an ideal choice for applications where computational resources
are limited but accurate structure prediction remains crucial.

</details>


### [165] [Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update](https://arxiv.org/abs/2507.11847)
*Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the generalized linear bandit (GLB) problem, a contextual
multi-armed bandit framework that extends the classical linear model by
incorporating a non-linear link function, thereby modeling a broad class of
reward distributions such as Bernoulli and Poisson. While GLBs are widely
applicable to real-world scenarios, their non-linear nature introduces
significant challenges in achieving both computational and statistical
efficiency. Existing methods typically trade off between two objectives, either
incurring high per-round costs for optimal regret guarantees or compromising
statistical efficiency to enable constant-time updates. In this paper, we
propose a jointly efficient algorithm that attains a nearly optimal regret
bound with $\mathcal{O}(1)$ time and space complexities per round. The core of
our method is a tight confidence set for the online mirror descent (OMD)
estimator, which is derived through a novel analysis that leverages the notion
of mix loss from online prediction. The analysis shows that our OMD estimator,
even with its one-pass updates, achieves statistical efficiency comparable to
maximum likelihood estimation, thereby leading to a jointly efficient
optimistic method.

</details>


### [166] [OrdShap: Feature Position Importance for Sequential Black-Box Models](https://arxiv.org/abs/2507.11855)
*Davin Hill,Brian L. Hill,Aria Masoomi,Vijay S. Nori,Robert E. Tillman,Jennifer Dy*

Main category: cs.LG

TL;DR: OrdShap：一种新颖的归因方法，用于解耦序列深度学习模型中特征值和特征位置对预测的影响。


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法在理解序列深度学习模型预测时，将特征值和其在序列中的位置效应混淆，无法独立量化二者对模型预测的贡献。

Method: 引入OrdShap，通过量化模型预测对特征位置排列变化的响应来解耦特征值和特征位置的影响。该方法在博弈论上与Sanchez-Berganti~nos值建立联系，提供了理论基础。

Result: 在健康、自然语言和合成数据集上的实证结果表明，OrdShap能有效捕捉特征值和特征位置的归因，并为模型行为提供更深入的洞察。

Conclusion: OrdShap成功地解决了现有归因方法无法区分特征值和位置效应的问题，为理解复杂序列深度学习模型的预测提供了更细致、更准确的工具。

Abstract: Sequential deep learning models excel in domains with temporal or sequential
dependencies, but their complexity necessitates post-hoc feature attribution
methods for understanding their predictions. While existing techniques quantify
feature importance, they inherently assume fixed feature ordering - conflating
the effects of (1) feature values and (2) their positions within input
sequences. To address this gap, we introduce OrdShap, a novel attribution
method that disentangles these effects by quantifying how a model's predictions
change in response to permuting feature position. We establish a game-theoretic
connection between OrdShap and Sanchez-Berganti\~nos values, providing a
theoretically grounded approach to position-sensitive attribution. Empirical
results from health, natural language, and synthetic datasets highlight
OrdShap's effectiveness in capturing feature value and feature position
attributions, and provide deeper insight into model behavior.

</details>


### [167] [A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers](https://arxiv.org/abs/2507.11865)
*Hanwen Dai,Chang Gao,Fang He,Congyuan Ji,Yanni Yang*

Main category: cs.LG

TL;DR: 针对网约车平台集成模式下司机参与折扣快车的动态管理问题，本文提出了一种策略改进的深度确定性策略梯度（pi-DDPG）框架，以解决数据稀缺和早期探索成本高昂的挑战。实验证明该框架在学习效率和早期训练损失方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 平台集成虽能缓解市场碎片化并扩大需求，但鼓励司机参与折扣快车服务可能降低单个平台的利润。现有新业务模式缺乏历史数据，在线学习成本高昂，亟需在有限数据下实现可靠的早期性能，并应对高随机性与不透明匹配机制。

Method: 将司机接受折扣快车的比例决策表述为连续控制任务。提出pi-DDPG框架，其整合了精炼模块以提升早期策略性能、卷积长短期记忆网络以捕捉时空模式，以及优先经验回放机制以提高学习效率。使用基于真实世界数据集的模拟器进行验证。

Result: 数值实验表明，pi-DDPG框架实现了卓越的学习效率，并显著减少了早期训练损失。

Conclusion: pi-DDPG框架能有效应对网约车平台集成模式下司机动态管理面临的挑战，尤其在数据稀缺和需确保早期性能的实际部署场景中，通过提升学习效率和降低早期训练损失展现出其显著优势。

Abstract: The rapid expansion of platform integration has emerged as an effective
solution to mitigate market fragmentation by consolidating multiple
ride-hailing platforms into a single application. To address heterogeneous
passenger preferences, third-party integrators provide Discount Express service
delivered by express drivers at lower trip fares. For the individual platform,
encouraging broader participation of drivers in Discount Express services has
the potential to expand the accessible demand pool and improve matching
efficiency, but often at the cost of reduced profit margins. This study aims to
dynamically manage drivers' acceptance of Discount Express from the perspective
of individual platforms. The lack of historical data under the new business
model necessitates online learning. However, early-stage exploration through
trial and error can be costly in practice, highlighting the need for reliable
early-stage performance in real-world deployment. To address these challenges,
this study formulates the decision regarding the proportion of drivers'
acceptance behavior as a continuous control task. In response to the high
stochasticity, the opaque matching mechanisms employed by third-party
integrator, and the limited availability of historical data, we propose a
policy-improved deep deterministic policy gradient (pi-DDPG) framework. The
proposed framework incorporates a refiner module to boost policy performance
during the early training phase, leverages a convolutional long short-term
memory network to effectively capture complex spatiotemporal patterns, and
adopts a prioritized experience replay mechanism to enhance learning
efficiency. A simulator based on a real-world dataset is developed to validate
the effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate
that pi-DDPG achieves superior learning efficiency and significantly reduces
early-stage training losses.

</details>


### [168] [Imbalanced Regression Pipeline Recommendation](https://arxiv.org/abs/2507.11901)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 针对不平衡回归任务中最佳采样与模型组合难以确定的问题，本文提出了Meta-IR元学习框架。该框架通过训练元分类器，以零样本方式推荐最佳管道，并经验证优于AutoML及多种基线组合。


<details>
  <summary>Details</summary>
Motivation: 不平衡问题普遍存在于回归任务中，且特定目标值稀有。由于重采样方法和学习模型种类繁多，确定最佳解决方案需要测试大量组合，且最佳策略受学习模型、数据集和评估指标的影响，导致选择困难。

Method: 本文提出了Meta-learning for Imbalanced Regression (Meta-IR) 框架，通过训练元分类器来推荐每个任务的最佳管道（包含重采样策略和学习模型），实现零样本推荐。元分类器使用元特征进行训练，以学习如何将元特征映射到表示最佳管道的类别。框架包含两种设计：独立（Independent）模式，分别指示最佳学习算法和重采样策略；链式（Chained）模式，通过序列化过程建模二者之间的内在关系。

Result: 链式（Chained）方案表现出卓越性能，表明学习算法与重采样策略之间存在任务相关的内在联系。与AutoML框架相比，Meta-IR取得了更好的结果。此外，相较于由6种学习算法和7种（含不重采样）重采样配置组成的42种基线组合，Meta-IR超越了所有这些配置。

Conclusion: Meta-IR框架能有效解决不平衡回归任务中选择最佳学习管道的复杂性问题，通过元学习方法显著提升了性能，并证明了学习算法和重采样策略之间存在重要关联，为未来的不平衡回归问题提供了高效的解决方案。

Abstract: Imbalanced problems are prevalent in various real-world scenarios and are
extensively explored in classification tasks. However, they also present
challenges for regression tasks due to the rarity of certain target values. A
common alternative is to employ balancing algorithms in preprocessing to
address dataset imbalance. However, due to the variety of resampling methods
and learning models, determining the optimal solution requires testing many
combinations. Furthermore, the learning model, dataset, and evaluation metric
affect the best strategies. This work proposes the Meta-learning for Imbalanced
Regression (Meta-IR) framework, which diverges from existing literature by
training meta-classifiers to recommend the best pipeline composed of the
resampling strategy and learning model per task in a zero-shot fashion. The
meta-classifiers are trained using a set of meta-features to learn how to map
the meta-features to the classes indicating the best pipeline. We propose two
formulations: Independent and Chained. Independent trains the meta-classifiers
to separately indicate the best learning algorithm and resampling strategy.
Chained involves a sequential procedure where the output of one meta-classifier
is used as input for another to model intrinsic relationship factors. The
Chained scenario showed superior performance, suggesting a relationship between
the learning algorithm and the resampling strategy per task. Compared with
AutoML frameworks, Meta-IR obtained better results. Moreover, compared with
baselines of six learning algorithms and six resampling algorithms plus no
resampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of
them. The code, data, and further information of the experiments can be found
on GitHub: https://github.com/JusciAvelino/Meta-IR.

</details>


### [169] [Resampling strategies for imbalanced regression: a survey and empirical analysis](https://arxiv.org/abs/2507.11902)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 本文针对回归任务中的不平衡数据问题，进行了一项广泛的实验研究，评估了多种平衡和预测模型，并提出了分类法，为策略应用提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管不平衡问题在分类任务中已被广泛研究，但它同样存在于目标值为连续值的回归任务中，且这方面的研究相对较少，需要有效的策略来解决回归中的不平衡数据问题。

Method: 进行了一项广泛的实验研究，整合了多种平衡算法和预测模型；使用特定度量指标来评估不平衡回归数据中的模型表现；提出了一种基于回归模型、学习过程和评估指标的不平衡回归方法分类法。

Result: 研究提供了关于不平衡处理策略应用的新见解，并强调了这些策略对不同模型学习过程的优势。

Conclusion: 该研究为不平衡回归问题提供了深入分析和新见解，证实了所用策略的有效性，并为未来的研究指明了方向。

Abstract: Imbalanced problems can arise in different real-world situations, and to
address this, certain strategies in the form of resampling or balancing
algorithms are proposed. This issue has largely been studied in the context of
classification, and yet, the same problem features in regression tasks, where
target values are continuous. This work presents an extensive experimental
study comprising various balancing and predictive models, and wich uses metrics
to capture important elements for the user and to evaluate the predictive model
in an imbalanced regression data context. It also proposes a taxonomy for
imbalanced regression approaches based on three crucial criteria: regression
model, learning process, and evaluation metrics. The study offers new insights
into the use of such strategies, highlighting the advantages they bring to each
model's learning process, and indicating directions for further studies. The
code, data and further information related to the experiments performed herein
can be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.

</details>


### [170] [From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning](https://arxiv.org/abs/2507.11926)
*Max Hopkins,Sihan Liu,Christopher Ye,Yuichi Yoshida*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The epidemic failure of replicability across empirical science and machine
learning has recently motivated the formal study of replicable learning
algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from
a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the
design of data-efficient replicable algorithms is now more or less understood.
In contrast, there remain significant gaps in our knowledge for control
settings like reinforcement learning where an agent must interact directly with
a shifting environment. Karbasi et. al show that with access to a generative
model of an environment with $S$ states and $A$ actions (the RL 'batch
setting'), replicably learning a near-optimal policy costs only
$\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a
generative model jumps to $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the
substantial difficulty of environment exploration. This gap raises a key
question in the broader theory of replicability: Is replicable exploration
inherently more expensive than batch learning? Is sample-efficient replicable
RL even possible?
  In this work, we (nearly) resolve this problem (for low-horizon tabular
MDPs): exploration is not a significant barrier to replicable learning! Our
main result is a replicable RL algorithm on $\tilde{O}(S^2A)$ samples, bridging
the gap between the generative and episodic settings. We complement this with a
matching $\tilde{\Omega}(S^2A)$ lower bound in the generative setting (under
the common parallel sampling assumption) and an unconditional lower bound in
the episodic setting of $\tilde{\Omega}(S^2)$ showcasing the near-optimality of
our algorithm with respect to the state space $S$.

</details>


### [171] [Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning](https://arxiv.org/abs/2507.11928)
*Abhishek Sriram,Neal Tuffy*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents a machine learning-accelerated optimization framework for
RF power amplifier design that reduces simulation requirements by 65% while
maintaining $\pm0.3$ to $\pm0.4$ dBm accuracy. The proposed method combines
MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to
intelligently explore multidimensional parameter spaces. Instead of
exhaustively simulating all parameter combinations to achieve target P2dB
compression specifications, our approach strategically selects approximately
35% of critical simulation points. The framework processes ADS netlists,
executes harmonic balance simulations on the reduced dataset, and trains a
CatBoost model to predict P2dB performance across the entire design space.
Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with
the system ranking parameter combinations by their likelihood of meeting target
specifications. The integrated solution delivers 58.24% to 77.78% reduction in
simulation time through automated GUI-based workflows, enabling rapid design
iterations without compromising accuracy standards required for production RF
circuits.

</details>


### [172] [Kevin: Multi-Turn RL for Generating CUDA Kernels](https://arxiv.org/abs/2507.11948)
*Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti*

Main category: cs.LG

TL;DR: 本文提出Kevin模型，通过多轮强化学习（RL）生成和优化CUDA内核，显著提升了内核的正确性和执行速度，超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 编写高效的GPU内核对AI系统至关重要，但过程具有挑战性和高度迭代性。由于存在可验证的奖励（正确性、加速），强化学习（RL）成为一个自然的应用领域。

Method: 为应对迭代特性和现实挑战（如长轨迹学习、奖励归因），开发了一种灵活的多轮强化学习（RL）方法。基于此，提出了Kevin模型，这是首个使用多轮RL进行CUDA内核生成和优化的模型。

Result: Kevin模型在内核正确性上从基线模型的56%提升至82%，平均加速比从0.53x提升至1.10x（对比PyTorch Eager），并超越了前沿模型o4-mini（0.78x）。研究发现，增加串行精炼轮次比并行采样更有效，且Kevin在更多精炼轮次下显示出更高的改进率。

Conclusion: 多轮强化学习是提升GPU内核生成和优化性能的有效途径。Kevin模型通过利用迭代精炼过程，在正确性和速度上取得了显著进步，尤其是在增加精炼轮次时性能提升更明显。

Abstract: Writing GPU kernels is a challenging task and critical for AI systems'
efficiency. It is also highly iterative: domain experts write code and improve
performance through execution feedback. Moreover, it presents verifiable
rewards like correctness and speedup, making it a natural environment to apply
Reinforcement Learning (RL). To explicitly incorporate the iterative nature of
this process into training, we develop a flexible multi-turn RL recipe that
addresses unique challenges encountered in real-world settings, such as
learning from long trajectories and effective reward attribution across turns.
We present Kevin - K(ernel D)evin, the first model trained with multi-turn RL
for CUDA kernel generation and optimization. In our evaluation setup, Kevin
shows significant gains over its base model (QwQ-32B), improving correctness of
generated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to
1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini
(0.78x). Finally, we study its behavior across test-time scaling axes: we found
scaling serial refinement more beneficial than parallel sampling. In
particular, when given more refinement turns, Kevin shows a higher rate of
improvement.

</details>


### [173] [Online Training and Pruning of Deep Reinforcement Learning Networks](https://arxiv.org/abs/2507.11975)
*Valentin Frank Ingmar Guenter,Athanasios Sideris*

Main category: cs.LG

TL;DR: 本研究提出一种在强化学习（RL）中同步训练和剪枝深度神经网络（NN）的方法，旨在降低计算和内存开销，同时保持或提高RL智能体的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在强化学习中能提升性能，但会带来显著的计算和内存复杂性。神经网络剪枝方法在监督学习中已成功应对此挑战，但在强化学习领域的应用尚待深入探索。

Method: 我们提出了一种将同步训练和剪枝整合到先进RL方法中的方法，特别是在线特征提取网络（OFENet）增强的RL算法。我们的网络（XiNet）通过优化RL网络权重和变分伯努利分布的参数（用于缩放每个单元的0/1随机变量ξ），来解决随机优化问题。该随机问题公式引入了正则化项，当单元对性能贡献较小时，促使其变分参数收敛到0，从而永久性地将其从网络中剪枝。我们还提出了一种针对OFENets的DenseNet架构量身定制的、成本感知且促进稀疏性的正则化方案，它能自动选择超参数，有效结合RL目标和网络压缩。

Result: 在连续控制基准（MuJoCo）和Soft Actor-Critic RL代理上的评估表明，OFENets可以在性能损失最小的情况下进行大量剪枝。此外，我们的结果证实，在训练过程中剪枝大型网络比从头训练小型网络能产生更高效、更高性能的RL智能体。

Conclusion: 本研究成功地将神经网络剪枝应用于强化学习领域，有效解决了深度RL网络带来的计算和内存开销问题。通过在训练期间进行剪枝，我们能够获得更高效且性能更优异的RL智能体。

Abstract: Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms
has been shown to enhance performance when feature extraction networks are used
but the gained performance comes at the significant expense of increased
computational and memory complexity. Neural network pruning methods have
successfully addressed this challenge in supervised learning. However, their
application to RL is underexplored. We propose an approach to integrate
simultaneous training and pruning within advanced RL methods, in particular to
RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our
networks (XiNet) are trained to solve stochastic optimization problems over the
RL networks' weights and the parameters of variational Bernoulli distributions
for 0/1 Random Variables $\xi$ scaling each unit in the networks. The
stochastic problem formulation induces regularization terms that promote
convergence of the variational parameters to 0 when a unit contributes little
to the performance. In this case, the corresponding structure is rendered
permanently inactive and pruned from its network. We propose a cost-aware,
sparsity-promoting regularization scheme, tailored to the DenseNet architecture
of OFENets expressing the parameter complexity of involved networks in terms of
the parameters of the RVs in these networks. Then, when matching this cost with
the regularization terms, the many hyperparameters associated with them are
automatically selected, effectively combining the RL objectives and network
compression. We evaluate our method on continuous control benchmarks (MuJoCo)
and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned
considerably with minimal loss in performance. Furthermore, our results confirm
that pruning large networks during training produces more efficient and higher
performing RL agents rather than training smaller networks from scratch.

</details>


### [174] [Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection](https://arxiv.org/abs/2507.11997)
*Tairan Huang,Yili Wang*

Main category: cs.LG

TL;DR: MLED是一个利用LLM增强图结构信息，通过多层次增强进行欺诈检测的框架，在真实数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有图欺诈检测方法忽略了原始文本信息中的语义线索。尽管大型语言模型（LLMs）擅长处理文本，但将LLM处理后的文本嵌入与图结构进行多模态融合仍是一项重大挑战。

Method: 提出了一种名为MLED的多层次LLM增强图欺诈检测框架。MLED利用LLM从文本信息中提取外部知识，并通过设计多层次增强器（包括类型级别增强器和关系级别增强器）将LLM与图结构信息融合，以增强区分欺诈者和良性实体以及突出欺诈者在不同关系中重要性的能力。

Result: 在四个真实世界数据集上的实验表明，MLED在图欺诈检测中取得了最先进的性能。

Conclusion: MLED作为一个通用框架，可以应用于现有方法，有效提升了图欺诈检测的能力。

Abstract: Graph fraud detection has garnered significant attention as Graph Neural
Networks (GNNs) have proven effective in modeling complex relationships within
multimodal data. However, existing graph fraud detection methods typically use
preprocessed node embeddings and predefined graph structures to reveal
fraudsters, which ignore the rich semantic cues contained in raw textual
information. Although Large Language Models (LLMs) exhibit powerful
capabilities in processing textual information, it remains a significant
challenge to perform multimodal fusion of processed textual embeddings with
graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM
\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In
MLED, we utilize LLMs to extract external knowledge from textual information to
enhance graph fraud detection methods. To integrate LLMs with graph structure
information and enhance the ability to distinguish fraudsters, we design a
multi-level LLM enhanced framework including type-level enhancer and
relation-level enhancer. One is to enhance the difference between the
fraudsters and the benign entities, the other is to enhance the importance of
the fraudsters in different relations. The experiments on four real-world
datasets show that MLED achieves state-of-the-art performance in graph fraud
detection as a generalized framework that can be applied to existing methods.

</details>


### [175] [Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing](https://arxiv.org/abs/2507.12002)
*Alice Zhang,Callihan Bertley,Dawei Liang,Edison Thomaz*

Main category: cs.LG

TL;DR: 本研究开发了一种利用智能手表音频和惯性数据检测面对面言语交流的新方法，在实验室和半自然环境下均取得了高准确度。


<details>
  <summary>Details</summary>
Motivation: 社会互动对人类行为至关重要，其中面对面言语交流是基础。在声学挑战场景下，有效检测面对面言语交流仍是一个难题。

Method: 开发了一种新颖的计算方法，利用商用智能手表捕获的音频和惯性数据来检测面对面言语交流。分析了机器学习和深度学习模型，并采用三种不同的数据融合方法。通过11人实验室研究和24人半自然研究进行评估，并对活动和采样率进行了综合评估。

Result: 研究结果表明，融合音频和惯性数据具有优势，能够同时考虑言语和非言语线索。该框架在实验室环境中检测对话的宏F1分数达到82.0%±3.0%，在半自然环境中达到77.2%±1.8%。

Conclusion: 成功开发并验证了一种基于智能手表多模态（音频和惯性）数据的面对面言语交流检测框架，该框架在声学挑战环境下表现良好，并突出了多模态传感在特定情境中的益处。

Abstract: Social interactions play a crucial role in shaping human behavior,
relationships, and societies. It encompasses various forms of communication,
such as verbal conversation, non-verbal gestures, facial expressions, and body
language. In this work, we develop a novel computational approach to detect a
foundational aspect of human social interactions, in-person verbal
conversations, by leveraging audio and inertial data captured with a commodity
smartwatch in acoustically-challenging scenarios. To evaluate our approach, we
conducted a lab study with 11 participants and a semi-naturalistic study with
24 participants. We analyzed machine learning and deep learning models with 3
different fusion methods, showing the advantages of fusing audio and inertial
data to consider not only verbal cues but also non-verbal gestures in
conversations. Furthermore, we perform a comprehensive set of evaluations
across activities and sampling rates to demonstrate the benefits of multimodal
sensing in specific contexts. Overall, our framework achieved 82.0$\pm$3.0%
macro F1-score when detecting conversations in the lab and 77.2$\pm$1.8% in the
semi-naturalistic setting.

</details>


### [176] [DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning](https://arxiv.org/abs/2507.12011)
*Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.LG

TL;DR: 提出DUSE框架，通过动态不确定性驱动的样本扩展，解决自动调制识别（AMR）领域深度学习模型训练中数据稀缺的问题，并表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在AMR中表现卓越，但需大量标注数据。实际场景中目标域数据稀缺，手动标注成本高昂，而数据增强无法从根本上解决数据不足问题。

Method: 引入“动态不确定性驱动样本扩展（DUSE）”框架。DUSE利用不确定性评分函数从相关AMR数据集中筛选有用样本，并采用主动学习策略持续优化评分器。

Result: DUSE在类别平衡和不平衡设置下均持续优于8种核心集选择基线。此外，DUSE对未知模型展现出强大的跨架构泛化能力。

Conclusion: DUSE通过智能的数据扩展，有效解决了AMR领域中深度学习模型面临的数据稀缺挑战，显著提升了模型性能并展现出强大的泛化能力。

Abstract: Although deep neural networks have made remarkable achievements in the field
of automatic modulation recognition (AMR), these models often require a large
amount of labeled data for training. However, in many practical scenarios, the
available target domain data is scarce and difficult to meet the needs of model
training. The most direct way is to collect data manually and perform expert
annotation, but the high time and labor costs are unbearable. Another common
method is data augmentation. Although it can enrich training samples to a
certain extent, it does not introduce new data and therefore cannot
fundamentally solve the problem of data scarcity. To address these challenges,
we introduce a data expansion framework called Dynamic Uncertainty-driven
Sample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring
function to filter out useful samples from relevant AMR datasets and employs an
active learning strategy to continuously refine the scorer. Extensive
experiments demonstrate that DUSE consistently outperforms 8 coreset selection
baselines in both class-balance and class-imbalance settings. Besides, DUSE
exhibits strong cross-architecture generalization for unseen models.

</details>


### [177] [Granular feedback merits sophisticated aggregation](https://arxiv.org/abs/2507.12041)
*Anmol Kagrecha,Henrik Marklund,Potsawee Manakul,Richard Zeckhauser,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 该研究探讨了在有限样本下，预测人群反馈分布时，更复杂的方法是否能优于正则化平均。结果显示，随着反馈粒度的增加，复杂方法能显著提升预测性能，尤其是在高粒度反馈（如五点量表）下能大幅减少所需样本量。


<details>
  <summary>Details</summary>
Motivation: 在AI模型训练、推荐系统和民意测量等应用中，从有限的个体反馈中准确估计人群反馈分布面临成本限制。常规的正则化平均方法较为简单，因此研究旨在探索是否存在更优的方法，特别是考虑反馈粒度对预测性能的影响。

Method: 研究提出了比正则化平均更复杂的个体反馈结合方法，并通过对社会态度问题的实证分析来评估这些方法的性能，并与正则化平均进行比较。研究重点关注了反馈粒度（二元反馈与五点反馈）对不同方法效果的影响。

Result: 研究发现，随着反馈粒度的增加，复杂方法比正则化平均能显著改善预测。具体而言，在二元反馈下，复杂方法几乎未能减少达到相同性能所需的个体数量；然而，在五点反馈下，复杂方法仅需正则化平均约一半的个体数量即可达到相同的性能水平。

Conclusion: 在从有限样本预测人群反馈分布时，更复杂的反馈结合方法的有效性高度依赖于反馈的粒度。反馈粒度越高，复杂方法越能显著提升性能并减少所需的样本量。

Abstract: Human feedback is increasingly used across diverse applications like training
AI models, developing recommender systems, and measuring public opinion -- with
granular feedback often being preferred over binary feedback for its greater
informativeness. While it is easy to accurately estimate a population's
distribution of feedback given feedback from a large number of individuals,
cost constraints typically necessitate using smaller groups. A simple method to
approximate the population distribution is regularized averaging: compute the
empirical distribution and regularize it toward a prior. Can we do better? As
we will discuss, the answer to this question depends on feedback granularity.
  Suppose one wants to predict a population's distribution of feedback using
feedback from a limited number of individuals. We show that, as feedback
granularity increases, one can substantially improve upon predictions of
regularized averaging by combining individuals' feedback in ways more
sophisticated than regularized averaging.
  Our empirical analysis using questions on social attitudes confirms this
pattern. In particular, with binary feedback, sophistication barely reduces the
number of individuals required to attain a fixed level of performance. By
contrast, with five-point feedback, sophisticated methods match the performance
of regularized averaging with about half as many individuals.

</details>


### [178] [Information-Theoretic Generalization Bounds of Replay-based Continual Learning](https://arxiv.org/abs/2507.12043)
*Wen Wen,Tieliang Gong,Yunjiao Zhang,Zeyu Gao,Weizhan Zhang,Yong-Jin Liu*

Main category: cs.LG

TL;DR: 本研究为基于回放的持续学习（CL）提供了一个统一的理论框架，推导了信息论界限，解释了内存缓冲区如何影响泛化，并指出有限回放可以有效提升泛化能力并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 尽管许多持续学习（CL）方法在经验上表现出色，但对其泛化行为的理论理解仍然有限，特别是对于基于回放的方法。

Method: 建立了一个统一的、基于回放的持续学习理论框架，并推导了一系列信息论界限（包括基于假设的界限和基于预测的界限），以量化内存缓冲区与当前任务交互如何影响泛化。此分析通用且适用于多种学习算法，例如随机梯度Langevin动力学（SGLD）。

Result: 基于假设的界限揭示，利用有限的先前任务示例（而非详尽回放）可以促进更好的泛化并有效缓解灾难性遗忘。基于预测的界限通过使用低维变量，提供了更紧密且计算上易处理的泛化差距上限。全面的实验评估证明了所推导界限在捕捉基于回放的持续学习泛化动态方面的有效性。

Conclusion: 本研究提供了一个通用且适用的理论框架，为基于回放的持续学习提供了关键的理论理解，特别是关于内存缓冲区如何影响泛化，并验证了所提界限在捕捉泛化动态方面的有效性。

Abstract: Continual learning (CL) has emerged as a dominant paradigm for acquiring
knowledge from sequential tasks while avoiding catastrophic forgetting.
Although many CL methods have been proposed to show impressive empirical
performance, the theoretical understanding of their generalization behavior
remains limited, particularly for replay-based approaches. In this paper, we
establish a unified theoretical framework for replay-based CL, deriving a
series of information-theoretic bounds that explicitly characterize how the
memory buffer interacts with the current task to affect generalization.
Specifically, our hypothesis-based bounds reveal that utilizing the limited
exemplars of previous tasks alongside the current task data, rather than
exhaustive replay, facilitates improved generalization while effectively
mitigating catastrophic forgetting. Furthermore, our prediction-based bounds
yield tighter and computationally tractable upper bounds of the generalization
gap through the use of low-dimensional variables. Our analysis is general and
broadly applicable to a wide range of learning algorithms, exemplified by
stochastic gradient Langevin dynamics (SGLD) as a representative method.
Comprehensive experimental evaluations demonstrate the effectiveness of our
derived bounds in capturing the generalization dynamics in replay-based CL
settings.

</details>


### [179] [FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling](https://arxiv.org/abs/2507.12053)
*Seanglidet Yean,Jiazu Zhou,Bu-Sung Lee,Markus Schläpfer*

Main category: cs.LG

TL;DR: 本研究提出一种基于条件生成对抗网络（cGANs）的数据驱动方法，利用自适应因子（如动态区域大小和土地利用类型）为模拟城市场景生成起点-终点（OD）出行流，解决了现有模型在应对城市动态变化和缺乏历史数据时的局限性。


<details>
  <summary>Details</summary>
Motivation: 城市人口出行模式随土地利用和人口变化而演变，对城市规划至关重要。现有机器学习生成模型过度依赖历史轨迹且忽略演变因素；机械方法假设静态场景，限制了未来预测能力，且缺乏校准数据。因此，需要一种能处理演变因素且无需大量历史校准数据的方法。

Method: 本研究引入一种新型数据驱动方法，利用条件生成对抗网络（cGANs）融合历史数据与动态区域大小、土地利用原型等自适应因子。该方法能够根据兴趣区域调整空间粒度，快速生成出行流，且无需大量的校准数据或复杂的行为建模。

Result: 该方法在新加坡手机数据上的应用表现出有前景的性能，并与现有方法进行了比较，验证了其有效性。它能以可调的空间粒度快速生成出行流。

Conclusion: 本研究提出的数据驱动方法为模拟城市场景中的人类出行模式提供了高效、灵活的解决方案，有效克服了现有模型在处理城市动态变化和数据依赖性方面的局限性，特别适用于未来的城市规划和发展预测。

Abstract: The mobility patterns of people in cities evolve alongside changes in land
use and population. This makes it crucial for urban planners to simulate and
analyze human mobility patterns for purposes such as transportation
optimization and sustainable urban development. Existing generative models
borrowed from machine learning rely heavily on historical trajectories and
often overlook evolving factors like changes in population density and land
use. Mechanistic approaches incorporate population density and facility
distribution but assume static scenarios, limiting their utility for future
projections where historical data for calibration is unavailable. This study
introduces a novel, data-driven approach for generating origin-destination
mobility flows tailored to simulated urban scenarios. Our method leverages
adaptive factors such as dynamic region sizes and land use archetypes, and it
utilizes conditional generative adversarial networks (cGANs) to blend
historical data with these adaptive parameters. The approach facilitates rapid
mobility flow generation with adjustable spatial granularity based on regions
of interest, without requiring extensive calibration data or complex behavior
modeling. The promising performance of our approach is demonstrated by its
application to mobile phone data from Singapore, and by its comparison with
existing methods.

</details>


### [180] [Emergence of Quantised Representations Isolated to Anisotropic Functions](https://arxiv.org/abs/2507.12070)
*George Bird*

Main category: cs.LG

TL;DR: 开发了一种新的表征对齐方法，发现激活函数的代数对称性决定自编码器表征是否离散化。离散化是函数形式引入归纳偏置所致，可能影响可解释性并增加重建误差。


<details>
  <summary>Details</summary>
Motivation: 探究自编码器中离散表征的形成和排列方式，理解函数形式选择（特别是激活函数）如何引入无意归纳偏置，从而在表征中产生与任务无关的结构，并为新兴的可解释性研究提供见解。

Method: 在现有Spotlight Resonance方法基础上，开发了一种新的表征对齐度量方法。通过对自编码器进行消融研究，仅改变激活函数，以分析其代数对称性（离散置换等变对称性与连续正交等变定义）如何影响表征的离散化或连续性。

Result: 网络基元的代数对称性是表征中与任务无关结构的强预测因子。当激活函数通过离散代数置换等变对称性定义时，表征倾向于离散化；而在连续代数正交等变定义下，表征保持连续。初步结果显示，表征的量化与重建误差的显著增加相关联。

Conclusion: 函数形式选择会携带无意归纳偏置，导致表征中出现与任务无关的伪结构（如连续结构的量化效应）。这项研究支持离散表征形成的一种普遍因果模型，这可能是后续可解释性现象（如祖母细胞）的先决条件。所开发的工具和提出的机制为理解函数形式对表征的影响提供了见解，且表征量化可能是有害的。

Abstract: This paper describes a novel methodology for determining representational
alignment, developed upon the existing Spotlight Resonance method. Using this,
it is found that algebraic symmetries of network primitives are a strong
predictor for task-agnostic structure in representations. Particularly, this
new tool is used to gain insight into how discrete representations can form and
arrange in autoencoder models, through an ablation study where only the
activation function is altered. Representations are found to tend to discretise
when the activation functions are defined through a discrete algebraic
permutation-equivariant symmetry. In contrast, they remain continuous under a
continuous algebraic orthogonal-equivariant definition. These findings
corroborate the hypothesis that functional form choices can carry unintended
inductive biases which produce task-independent artefactual structures in
representations, particularly that contemporary forms induce discretisation of
otherwise continuous structure -- a quantisation effect. Moreover, this
supports a general causal model for one mode in which discrete representations
may form, and could constitute a prerequisite for downstream interpretability
phenomena, including grandmother neurons, discrete coding schemes, general
linear features and possibly Superposition. Hence, this tool and proposed
mechanism for the influence of functional form on representations may provide
several insights into emergent interpretability research. Finally, preliminary
results indicate that quantisation of representations appears to correlate with
a measurable increase in reconstruction error, reinforcing previous conjectures
that this collapse can be detrimental.

</details>


### [181] [Measuring Informativeness Gap of (Mis)Calibrated Predictors](https://arxiv.org/abs/2507.12094)
*Yiding Feng,Wei Tang*

Main category: cs.LG

TL;DR: 本文提出“信息量差距”概念及一种基于地球移动距离（EMD）的松弛变体度量，以评估在下游决策任务中可能未校准的预测模型的“有用性”。该框架概括了现有方法，且所提度量具有完备性、可靠性和样本高效性。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，决策者需要在多个可能未校准的预测模型中进行选择。核心问题是：哪个模型在下游决策任务中更有用？

Method: 1. 引入“信息量差距”概念，定义为两个预测器在所有决策任务中，一个相对于另一个的最大标准化收益优势。2. 对信息量差距进行对偶刻画，推导出一个自然的信息量度量，该度量可视为地球移动距离（EMD）的松弛变体。

Result: 1. 所提出的框架严格概括了U-Calibration、Calibration Decision Loss等现有概念，并在完美校准情况下恢复Blackwell信息量。2. 新的信息量度量满足完备性和可靠性等理想特性。3. 该度量在仅有预测访问权限的设置下可实现样本高效估计。4. 在应用于完美校准的预测器时，获得了新颖的组合结构结果。

Conclusion: 本文提供了一个新颖且泛化的框架（包括信息量差距及其度量），用于评估和比较可能未校准的预测模型在决策任务中的有用性，该方案具有理论基础且可有效估计。

Abstract: In many applications, decision-makers must choose between multiple predictive
models that may all be miscalibrated. Which model (i.e., predictor) is more
"useful" in downstream decision tasks? To answer this, our first contribution
introduces the notion of the informativeness gap between any two predictors,
defined as the maximum normalized payoff advantage one predictor offers over
the other across all decision-making tasks. Our framework strictly generalizes
several existing notions: it subsumes U-Calibration [KLST-23] and Calibration
Decision Loss [HW-24], which compare a miscalibrated predictor to its
calibrated counterpart, and it recovers Blackwell informativeness [Bla-51,
Bla-53] as a special case when both predictors are perfectly calibrated. Our
second contribution is a dual characterization of the informativeness gap,
which gives rise to a natural informativeness measure that can be viewed as a
relaxed variant of the earth mover's distance (EMD) between two prediction
distributions. We show that this measure satisfies natural desiderata: it is
complete and sound, and it can be estimated sample-efficiently in the
prediction-only access setting. Along the way, we also obtain novel
combinatorial structural results when applying this measure to perfectly
calibrated predictors.

</details>


### [182] [Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks](https://arxiv.org/abs/2507.12127)
*Ngoc Duy Pham,Thusitha Dayaratne,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.LG

TL;DR: 本文提出一种联邦学习（FL）方法用于动态频谱感知（FLSS），通过半监督学习解决数据稀缺问题，并引入一种受疫苗启发的新型防御机制应对数据投毒攻击，实现了高精度和强大的拜占庭鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着5G/6G技术发展，无线设备激增导致频谱稀缺成为关键挑战。动态频谱分配（DSA）是解决方案，而机器学习（ML）可提升频谱感知。然而，集中式ML-DSA面临隐私、带宽和监管限制。联邦学习（FL）是分布式ML的替代方案，但在FLSS中仍面临标签数据稀缺和数据投毒攻击等安全漏洞。

Method: 1. 针对标签数据稀缺问题，采用半监督联邦学习（FL）方法，并结合能量检测，使模型能够利用无标签数据集进行训练。2. 针对数据投毒攻击的安全漏洞，提出一种受疫苗启发的新型防御机制，有效缓解攻击且不依赖于多数决策假设。

Result: 1. 联邦学习频谱感知（FLSS）在无标签数据集上实现了近乎完美的准确率。2. 即使在大量参与者恶意的情况下，FLSS也能针对定向和非定向数据投毒攻击保持强大的拜占庭鲁棒性。

Conclusion: 本文提出的半监督联邦学习方法和创新的防御机制，成功解决了联邦学习频谱感知中的标签数据稀缺和数据投毒攻击问题，使其成为一种高效且鲁棒的动态频谱分配解决方案。

Abstract: Advancements in wireless and mobile technologies, including 5G advanced and
the envisioned 6G, are driving exponential growth in wireless devices. However,
this rapid expansion exacerbates spectrum scarcity, posing a critical
challenge. Dynamic spectrum allocation (DSA)--which relies on sensing and
dynamically sharing spectrum--has emerged as an essential solution to address
this issue. While machine learning (ML) models hold significant potential for
improving spectrum sensing, their adoption in centralized ML-based DSA systems
is limited by privacy concerns, bandwidth constraints, and regulatory
challenges. To overcome these limitations, distributed ML-based approaches such
as Federated Learning (FL) offer promising alternatives. This work addresses
two key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of
labeled data for training FL models in practical spectrum sensing scenarios is
tackled with a semi-supervised FL approach, combined with energy detection,
enabling model training on unlabeled datasets. Second, we examine the security
vulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our
analysis highlights the shortcomings of existing majority-based defenses in
countering such attacks. To address these vulnerabilities, we propose a novel
defense mechanism inspired by vaccination, which effectively mitigates data
poisoning attacks without relying on majority-based assumptions. Extensive
experiments on both synthetic and real-world datasets validate our solutions,
demonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets
and maintain Byzantine robustness against both targeted and untargeted data
poisoning attacks, even when a significant proportion of participants are
malicious.

</details>


### [183] [HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD](https://arxiv.org/abs/2507.12133)
*Hanwen Liu,Yuhe Huang,Yifeng Gong,Yanjie Zhai,Jiaxuan Lu*

Main category: cs.LG

TL;DR: 本文提出HyDRA，一种结合优化VMD、CNN、Transformer和Mamba的混合RF架构，用于无线设备射频指纹识别(RFFI)。它在闭集分类中达到SOTA准确率，并在开集分类中表现鲁棒，同时实现低延迟和低功耗的实时认证。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统中的设备识别对安全（如访问控制）至关重要。射频指纹识别(RFFI)通过利用硬件引起的信号失真，提供了一种非加密的解决方案。

Method: 提出HyDRA（Hybrid Dual-mode RF Architecture），其核心包括：1. 优化的变分模态分解（VMD），通过固定中心频率和使用闭式解提升预处理效率和精度。2. 一个融合了卷积神经网络(CNNs)、Transformers和Mamba组件的新颖架构。HyDRA利用Transformer动态序列编码器（TDSE）进行全局依赖建模，并采用Mamba线性流编码器（MLFE）进行线性复杂度处理。该架构设计支持闭集和开集分类任务，并部署在NVIDIA Jetson Xavier NX上。

Result: 在公共数据集上，HyDRA在闭集场景中展现出最先进(SOTA)的准确性。在所提出的开集分类方法中，表现出鲁棒性能，能有效识别未经授权的设备。此外，部署在NVIDIA Jetson Xavier NX上，实现了毫秒级的推理速度和低功耗。

Conclusion: HyDRA为真实世界环境中的实时无线认证提供了一个实用、高效且高性能的解决方案。

Abstract: Device recognition is vital for security in wireless communication systems,
particularly for applications like access control. Radio Frequency Fingerprint
Identification (RFFI) offers a non-cryptographic solution by exploiting
hardware-induced signal distortions. This paper proposes HyDRA, a Hybrid
Dual-mode RF Architecture that integrates an optimized Variational Mode
Decomposition (VMD) with a novel architecture based on the fusion of
Convolutional Neural Networks (CNNs), Transformers, and Mamba components,
designed to support both closed-set and open-set classification tasks. The
optimized VMD enhances preprocessing efficiency and classification accuracy by
fixing center frequencies and using closed-form solutions. HyDRA employs the
Transformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and
the Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting
to varying conditions. Evaluation on public datasets demonstrates
state-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance
in our proposed open-set classification method, effectively identifying
unauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves
millisecond-level inference speed with low power consumption, providing a
practical solution for real-time wireless authentication in real-world
environments.

</details>


### [184] [RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization](https://arxiv.org/abs/2507.12142)
*Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: LoRA存在初始化和过参数化挑战。本文提出RiemannLoRA，利用流形优化框架同时解决这两个问题，提升了LLM及扩散模型微调的收敛速度和性能。


<details>
  <summary>Details</summary>
Motivation: Low-Rank Adaptation (LoRA) 在参数高效微调大型语言模型（LLMs）时，仍面临寻找最优初始化策略和缓解低秩矩阵分解中过参数化的问题。

Method: 提出RiemannLoRA方法，将一组固定秩的LoRA矩阵视为一个光滑流形。通过将适配器视为流形上的元素来消除过参数化，同时通过确定沿流形损失最快下降的方向来提供初始化。该方法采用了数值线性代数和黎曼优化的最佳实践，以实现数值稳定性和计算效率。

Result: 在LLM和扩散模型架构上的实验结果表明，RiemannLoRA在收敛速度和最终性能方面均持续优于标准LoRA及其最先进的改进方法。

Conclusion: RiemannLoRA通过创新的流形优化方法有效解决了LoRA的初始化和过参数化问题，显著提升了模型微调的收敛速度和最终性能。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted standard for
parameter-efficient fine-tuning of large language models (LLMs), significantly
reducing memory and computational demands. However, challenges remain,
including finding optimal initialization strategies or mitigating
overparametrization in low-rank matrix factorization. In this work, we propose
a novel approach that addresses both of the challenges simultaneously within a
unified framework. Our method treats a set of fixed-rank LoRA matrices as a
smooth manifold. Considering adapters as elements on this manifold removes
overparametrization, while determining the direction of the fastest loss
decrease along the manifold provides initialization. Special care is taken to
obtain numerically stable and computationally efficient implementation of our
method, using best practices from numerical linear algebra and Riemannian
optimization. Experimental results on LLM and diffusion model architectures
demonstrate that RiemannLoRA consistently improves both convergence speed and
final performance over standard LoRA and its state-of-the-art modifications.

</details>


### [185] [FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale](https://arxiv.org/abs/2507.12144)
*Boris Bonev,Thorsten Kurth,Ankur Mahesh,Mauro Bisson,Jean Kossaifi,Karthik Kashinath,Anima Anandkumar,William D. Collins,Michael S. Pritchard,Alexander Keller*

Main category: cs.LG

TL;DR: FourCastNet 3 是一种可扩展的几何机器学习方法，用于概率集合天气预报。它在预测速度和精度上超越传统模型，同时保持现实动态和出色的概率校准。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够尊重球面几何、准确建模空间相关概率性质、提供稳定光谱和多尺度真实动态的全球天气预报模型，并解决现有方法速度慢、精度不足的问题。

Method: 采用专门为球面几何设计的纯卷积神经网络架构，实现可扩展的几何机器学习方法。通过受经典数值模型域分解启发的模型-数据并行训练范式，支持在1024个及以上GPU上的大规模训练。

Result: 预测精度超越领先的传统集合模型，媲美最佳扩散基方法，且预测速度快8到60倍。在长达60天的预测时间下，展现出色的概率校准并保留真实的谱。单个GPU可在20秒内生成0.25度、6小时分辨率的90天全球预报。

Conclusion: FourCastNet 3凭借其计算效率、中程概率技能、谱保真度和次季节时间尺度的推出稳定性，成为通过大规模集合预测改进气象预报和早期预警系统的有力候选。

Abstract: FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 90-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 20 seconds. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.

</details>


### [186] [PRISM: Distributed Inference for Foundation Models at Edge](https://arxiv.org/abs/2507.12145)
*Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang*

Main category: cs.LG

TL;DR: 提出PRISM，一种用于在边缘设备上高效部署分布式Transformer推理的策略，可大幅减少通信和计算开销。


<details>
  <summary>Details</summary>
Motivation: 基础模型虽取得显著成功，但在边缘设备上部署面临巨大挑战，亟需开发实用高效的策略。

Method: 本文提出PRISM，其核心在于：1) 利用分段均值表示近似中间输出特征，以大幅减少设备间通信；2) 重构自注意力机制，消除逐设备Key/Value计算导致的冗余；3) 设计分区感知的因果掩码方案以适应自回归模型。

Result: 在ViT、BERT和GPT-2上评估，PRISM显著降低了通信开销（BERT在CR=128时高达99.2%）和设备端计算（相同设置下BERT为51.24%），且仅带来轻微的精度下降。

Conclusion: PRISM为在资源受限的分布式环境中部署基础模型提供了一个可扩展且实用的解决方案。

Abstract: Foundation models (FMs) have achieved remarkable success across a wide range
of applications, from image classification to natural langurage processing, but
pose significant challenges for deployment at edge. This has sparked growing
interest in developing practical and efficient strategies for bringing
foundation models to edge environments. In this work, we propose PRISM, a
communication-efficient and compute-aware strategy for distributed Transformer
inference on edge devices. Our method leverages a Segment Means representation
to approximate intermediate output features, drastically reducing inter-device
communication. Additionally, we restructure the self-attention mechanism to
eliminate redundant computations caused by per-device Key/Value calculation in
position-wise partitioning and design a partition-aware causal masking scheme
tailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2
across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and
CBT. Our results demonstrate substantial reductions in communication overhead
(up to 99.2% for BERT at compression rate CR = 128) and per-device computation
(51.24% for BERT at the same setting), with only minor accuracy degradation.
This method offers a scalable and practical solution for deploying foundation
models in distributed resource-constrained environments.

</details>


### [187] [Multi-Component VAE with Gaussian Markov Random Field](https://arxiv.org/abs/2507.12165)
*Fouad Oubari,Mohamed El-Baha,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 本文提出一种新的生成模型GMRF MCVAE，通过引入高斯马尔可夫随机场有效建模多组件数据间的复杂依赖，显著提升了生成组件的结构一致性。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型难以处理多组件数据中复杂的内部依赖关系。现有多组件变分自编码器（MCVAE）依赖于简化的聚合策略，未能捕捉关键细节，从而损害了生成组件间的结构一致性。

Method: 引入高斯马尔可夫随机场多组件变分自编码器（GMRF MCVAE），将高斯马尔可夫随机场（GMRF）嵌入到先验和后验分布中。这种设计选择旨在显式建模组件间的相互关系，从而实现更丰富的表示和对复杂交互的忠实再现。

Result: GMRF MCVAE在专门用于评估复杂组件关系的合成Copula数据集上取得了最先进的性能，在PolyMNIST基准测试中表现出竞争力，并在真实世界BIKED数据集上显著增强了结构一致性。

Conclusion: 研究结果表明，GMRF MCVAE特别适用于需要对多组件一致性进行鲁棒和真实建模的实际应用。

Abstract: Multi-component datasets with intricate dependencies, like industrial
assemblies or multi-modal imaging, challenge current generative modeling
techniques. Existing Multi-component Variational AutoEncoders typically rely on
simplified aggregation strategies, neglecting critical nuances and consequently
compromising structural coherence across generated components. To explicitly
address this gap, we introduce the Gaussian Markov Random Field Multi-Component
Variational AutoEncoder , a novel generative framework embedding Gaussian
Markov Random Fields into both prior and posterior distributions. This design
choice explicitly models cross-component relationships, enabling richer
representation and faithful reproduction of complex interactions. Empirically,
our GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula
dataset specifically constructed to evaluate intricate component relationships,
demonstrates competitive results on the PolyMNIST benchmark, and significantly
enhances structural coherence on the real-world BIKED dataset. Our results
indicate that the GMRF MCVAE is especially suited for practical applications
demanding robust and realistic modeling of multi-component coherence

</details>


### [188] [RadioDiff-3D: A 3D$\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication](https://arxiv.org/abs/2507.12166)
*Xiucheng Wang,Qiming Zhang,Nan Cheng,Junting Chen,Zezhong Zhang,Zan Li,Shuguang Cui,Xuemin Shen*

Main category: cs.LG

TL;DR: 本文提出UrbanRadio3D数据集，一个大规模、高分辨率的3D无线电地图数据集，包含路径损耗、DoA和ToA。同时提出基于3D卷积UNet和Diffusion模型的RadioDiff-3D框架，用于构建高维无线电地图，并在多种场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图（RM）构建方法主要关注2D平面内的路径损耗预测，忽略了DoA、ToA等关键参数及垂直空间变化。这些限制源于对静态学习范式的依赖，导致泛化能力差，难以支持环境感知型无线通信。

Method: 1. 构建UrbanRadio3D数据集：通过射线追踪在真实城市环境中生成，是现有数据集的37倍大，包含路径损耗、DoA和ToA三种指标的3D数据，并有更多的高度层。
2. 提出基于3D卷积的UNet作为基准模型，用于3D RM构建。
3. 引入RadioDiff-3D：一个基于扩散模型的生成框架，利用3D卷积架构，支持已知发射器位置（辐射感知）和稀疏空间观测（辐射未知）两种场景下的RM构建。

Result: 在UrbanRadio3D数据集上的广泛评估表明，RadioDiff-3D在构建丰富、高维的无线电地图方面表现出卓越的性能，即使在复杂多变的环境动态下也能取得优异结果。

Conclusion: 这项工作提供了一个基础性的数据集和基准，为未来3D环境感知通信领域的研究奠定了基础。

Abstract: Radio maps (RMs) serve as a critical foundation for enabling
environment-aware wireless communication, as they provide the spatial
distribution of wireless channel characteristics. Despite recent progress in RM
construction using data-driven approaches, most existing methods focus solely
on pathloss prediction in a fixed 2D plane, neglecting key parameters such as
direction of arrival (DoA), time of arrival (ToA), and vertical spatial
variations. Such a limitation is primarily due to the reliance on static
learning paradigms, which hinder generalization beyond the training data
distribution. To address these challenges, we propose UrbanRadio3D, a
large-scale, high-resolution 3D RM dataset constructed via ray tracing in
realistic urban environments. UrbanRadio3D is over 37$\times$3 larger than
previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,
forming a novel 3D$\times$33D dataset with 7$\times$3 more height layers than
prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet
with 3D convolutional operators is proposed. Moreover, we further introduce
RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D
convolutional architecture. RadioDiff-3D supports both radiation-aware
scenarios with known transmitter locations and radiation-unaware settings based
on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate
that RadioDiff-3D achieves superior performance in constructing rich,
high-dimensional radio maps under diverse environmental dynamics. This work
provides a foundational dataset and benchmark for future research in 3D
environment-aware communication. The dataset is available at
https://github.com/UNIC-Lab/UrbanRadio3D.

</details>


### [189] [Explainable Evidential Clustering](https://arxiv.org/abs/2507.12192)
*Victor F. Lopes de Souza,Karima Bakhti,Sofiane Ramdani,Denis Mottet,Abdelhak Imoussaten*

Main category: cs.LG

TL;DR: 本文提出一种新方法，通过迭代证据错误最小化（IEMM）算法，利用决策树为证据聚类结果提供可解释的、考虑到可容忍错误的解释，并在实际应用中获得了高达93%的满意度。


<details>
  <summary>Details</summary>
Motivation: 传统的无监督分类方法难以处理真实数据中的不确定性和不精确性。证据聚类能解决这些问题，但其结果的可解释性研究不足，这在高风险领域（如医疗保健）至关重要。

Method: 1. 理论分析表明，代表性是决策树作为溯因解释器的必要充分条件。
2. 基于代表性概念，通过效用函数推广以适应部分标注，定义“证据错误性”为解释成本，并构建解释器。
3. 提出迭代证据错误最小化（IEMM）算法，生成可解释且谨慎的决策树解释。
4. 在合成和真实数据上对算法进行验证。

Result: 考虑到决策者的偏好，所提出的算法能够提供高达93%满意度的解释。

Conclusion: 本研究通过提出新的理论框架（包括代表性、效用函数和证据错误性）及IEMM算法，成功解决了证据聚类结果的可解释性问题，能够为高风险应用提供高质量且满足用户偏好的解释。

Abstract: Unsupervised classification is a fundamental machine learning problem.
Real-world data often contain imperfections, characterized by uncertainty and
imprecision, which are not well handled by traditional methods. Evidential
clustering, based on Dempster-Shafer theory, addresses these challenges. This
paper explores the underexplored problem of explaining evidential clustering
results, which is crucial for high-stakes domains such as healthcare. Our
analysis shows that, in the general case, representativity is a necessary and
sufficient condition for decision trees to serve as abductive explainers.
Building on the concept of representativity, we generalize this idea to
accommodate partial labeling through utility functions. These functions enable
the representation of "tolerable" mistakes, leading to the definition of
evidential mistakeness as explanation cost and the construction of explainers
tailored to evidential classifiers. Finally, we propose the Iterative
Evidential Mistake Minimization (IEMM) algorithm, which provides interpretable
and cautious decision tree explanations for evidential clustering functions. We
validate the proposed algorithm on synthetic and real-world data. Taking into
account the decision-maker's preferences, we were able to provide an
explanation that was satisfactory up to 93% of the time.

</details>


### [190] [Selective Quantization Tuning for ONNX Models](https://arxiv.org/abs/2507.12196)
*Nikolaos Louloudakis,Ajitha Rajan*

Main category: cs.LG

TL;DR: TuneQn通过选择性量化和多目标优化，有效减少深度学习模型的精度损失和大小，提升部署性能。


<details>
  <summary>Details</summary>
Motivation: 全量化深度神经网络模型通常会导致精度下降并面临低端硬件部署挑战。虽然选择性量化能缓解这些问题，但如何有效选择要量化的层是一个难题。

Method: 提出TuneQn套件，用于ONNX模型的选择性量化、部署和执行。它结合了性能分析和多目标优化（帕累托前沿最小化），以在精度和模型大小等指标上识别最佳模型候选。

Result: 在四种ONNX模型和CPU/GPU设备上进行评估，TuneQn与完全量化模型相比，将精度损失降低高达54.14%；与原始模型相比，将模型大小减少高达72.9%。

Conclusion: TuneQn有效实现了选择性量化和调优，在模型精度、大小和部署效率之间取得了显著改进的平衡，解决了深度学习模型部署中的实际挑战。

Abstract: Quantization is a process that reduces the precision of deep neural network
models to lower model size and computational demands, often at the cost of
accuracy. However, fully quantized models may exhibit sub-optimal performance
below acceptable levels and face deployment challenges on low-end hardware
accelerators due to practical constraints. To address these issues,
quantization can be selectively applied to only a subset of layers, but
selecting which layers to exclude is non-trivial. To this direction, we propose
TuneQn, a suite enabling selective quantization, deployment and execution of
ONNX models across various CPU and GPU devices, combined with profiling and
multi-objective optimization. TuneQn generates selectively quantized ONNX
models, deploys them on different hardware, measures performance on metrics
like accuracy and size, performs Pareto Front minimization to identify the best
model candidate and visualizes the results. To demonstrate the effectiveness of
TuneQn, we evaluated TuneQn on four ONNX models with two quantization settings
across CPU and GPU devices. As a result, we demonstrated that our utility
effectively performs selective quantization and tuning, selecting ONNX model
candidates with up to a $54.14$% reduction in accuracy loss compared to the
fully quantized model, and up to a $72.9$% model size reduction compared to the
original model.

</details>


### [191] [Nonlinear Concept Erasure: a Density Matching Approach](https://arxiv.org/abs/2507.12341)
*Antoine Saillenfest,Pirmin Lemberger*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ensuring that neural models used in real-world applications cannot infer
sensitive information, such as demographic attributes like gender or race, from
text representations is a critical challenge when fairness is a concern. We
address this issue through concept erasure, a process that removes information
related to a specific concept from distributed representations while preserving
as much of the remaining semantic information as possible. Our approach
involves learning an orthogonal projection in the embedding space, designed to
make the class-conditional feature distributions of the discrete concept to
erase indistinguishable after projection. By adjusting the rank of the
projector, we control the extent of information removal, while its
orthogonality ensures strict preservation of the local structure of the
embeddings. Our method, termed $\overline{\mathrm{L}}$EOPARD, achieves
state-of-the-art performance in nonlinear erasure of a discrete attribute on
classic natural language processing benchmarks. Furthermore, we demonstrate
that $\overline{\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear
classifiers, thereby promoting fairness.

</details>


### [192] [Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation](https://arxiv.org/abs/2507.12218)
*Tomohisa Okazaki*

Main category: cs.LG

TL;DR: 本研究提出了一种物理信息线性模型（PILM），它通过基函数的线性组合表示解，从而实现最优解的解析表示。该模型被验证用于正向和逆向问题，并应用于地壳应变率估计，发现从贝叶斯角度看，数学正则化表现更优。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程（PDEs）描述了许多物理系统，而从观测数据中求解这些方程并估计其系数或边界条件对于理解相关现象至关重要。尽管物理信息神经网络（PINNs）近期备受关注，但本研究旨在探索一种能够提供最优解解析表示的替代方法。

Method: 本研究提出并 investigated 了一种物理信息线性模型（PILM）。PILM通过基函数的线性组合来表示PDEs的解，从而允许最优解的解析表示。该模型在包含不确定边界条件的说明性正向和逆向问题中进行了公式化和验证。此外，PILM还应用于使用大地测量数据估计地壳应变率，并比较了施加弹性平衡的物理正则化与施加平滑约束的数学正则化。

Result: PILM成功地被公式化并验证了其在正向和逆向问题（包括不确定边界条件的情况）中的有效性。在应用于地壳应变率估计时，从贝叶斯角度看，数学正则化相比物理正则化表现出更优的性能。

Conclusion: PILM提供了一个解析可解的框架，适用于线性正向和逆向问题、欠定系统以及物理正则化问题。

Abstract: Many physical systems are described by partial differential equations (PDEs),
and solving these equations and estimating their coefficients or boundary
conditions (BCs) from observational data play a crucial role in understanding
the associated phenomena. Recently, a machine learning approach known as
physics-informed neural network, which solves PDEs using neural networks by
minimizing the sum of residuals from the PDEs, BCs, and data, has gained
significant attention in the scientific community. In this study, we
investigate a physics-informed linear model (PILM) that uses linear
combinations of basis functions to represent solutions, thereby enabling an
analytical representation of optimal solutions. The PILM was formulated and
verified for illustrative forward and inverse problems including cases with
uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain
rates using geodetic data. Specifically, physical regularization that enforces
elastic equilibrium on the velocity fields was compared with mathematical
regularization that imposes smoothness constraints. From a Bayesian
perspective, mathematical regularization exhibited superior performance. The
PILM provides an analytically solvable framework applicable to linear forward
and inverse problems, underdetermined systems, and physical regularization.

</details>


### [193] [Optimizers Qualitatively Alter Solutions And We Should Leverage This](https://arxiv.org/abs/2507.12224)
*Razvan Pascanu,Clare Lyle,Ionut-Vlad Modoranu,Naima Elosegui Borras,Dan Alistarh,Petar Velickovic,Sarath Chandar,Soham De,James Martens*

Main category: cs.LG

TL;DR: 论文指出，优化器不仅影响深度神经网络的收敛速度，更重要的是决定了学习解的定性特征和归纳偏置，呼吁社区重新审视其设计。


<details>
  <summary>Details</summary>
Motivation: 早期对深度神经网络（DNNs）收敛性的疑虑已随训练成功而消散，导致社区主要以凸优化思维模型关注优化器的训练效率（如迭代次数、FLOPs）。作者认为，这种侧重效率的视角忽略了优化器对学习解性质（定性特征、归纳偏置、有效表达能力）的关键影响。

Method: 本文通过概念性论证和分析，而非实验验证，提出了一种新的视角。它批判性地审视了当前深度学习优化器研究的重心，并倡导将优化器视为塑造模型最终解决方案性质的关键因素。

Result: 本文的核心论点是：优化器在深度学习过程中，不仅影响模型的收敛速度，还对学习到的解决方案的定性特征、归纳偏置以及模型的有效表达能力产生深远影响。这意味着优化器可以有效地编码学习过程中的期望特性。

Conclusion: 深度学习社区应超越单纯追求收敛效率，转而致力于理解现有优化器的归纳偏置，并主动设计新的优化器以诱导特定的解决方案特性。优化器设计应被视为与模型架构和数据同样重要的关键杠杆，以共同塑造模型输出。

Abstract: Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not
guarantee convergence to a unique global minimum of the loss when using
optimizers relying only on local information, such as SGD. Indeed, this was a
primary source of skepticism regarding the feasibility of DNNs in the early
days of the field. The past decades of progress in deep learning have revealed
this skepticism to be misplaced, and a large body of empirical evidence shows
that sufficiently large DNNs following standard training protocols exhibit
well-behaved optimization dynamics that converge to performant solutions. This
success has biased the community to use convex optimization as a mental model
for learning, leading to a focus on training efficiency, either in terms of
required iteration, FLOPs or wall-clock time, when improving optimizers. We
argue that, while this perspective has proven extremely fruitful, another
perspective specific to DNNs has received considerably less attention: the
optimizer not only influences the rate of convergence, but also the qualitative
properties of the learned solutions. Restated, the optimizer can and will
encode inductive biases and change the effective expressivity of a given class
of models. Furthermore, we believe the optimizer can be an effective way of
encoding desiderata in the learning process. We contend that the community
should aim at understanding the biases of already existing methods, as well as
aim to build new optimizers with the explicit intent of inducing certain
properties of the solution, rather than solely judging them based on their
convergence rates. We hope our arguments will inspire research to improve our
understanding of how the learning process can impact the type of solution we
converge to, and lead to a greater recognition of optimizers design as a
critical lever that complements the roles of architecture and data in shaping
model outcomes.

</details>


### [194] [Robust Causal Discovery in Real-World Time Series with Power-Laws](https://arxiv.org/abs/2507.12257)
*Matteo Tusoni,Giuseppe Masi,Andrea Coletta,Aldo Glielmo,Viviana Arrigoni,Novella Bartolini*

Main category: cs.LG

TL;DR: 提出一种基于幂律谱特征的鲁棒因果发现方法，有效处理噪声。


<details>
  <summary>Details</summary>
Motivation: 探索随机时间序列的因果关系至关重要。现有因果发现算法对噪声敏感，在实际数据中易导致错误的因果推断。

Method: 观察到实际时间序列的频谱遵循幂律分布，利用这一洞察，构建了一种基于提取幂律谱特征的鲁棒因果发现方法，旨在放大真实的因果信号。

Result: 该方法在合成基准和已知因果结构的真实数据集上均持续优于现有最先进的替代方法。

Conclusion: 该方法展示了其鲁棒性和实际相关性，为处理噪声敏感性问题提供了有效解决方案。

Abstract: Exploring causal relationships in stochastic time series is a challenging yet
crucial task with a vast range of applications, including finance, economics,
neuroscience, and climate science. Many algorithms for Causal Discovery (CD)
have been proposed, but they often exhibit a high sensitivity to noise,
resulting in misleading causal inferences when applied to real data. In this
paper, we observe that the frequency spectra of typical real-world time series
follow a power-law distribution, notably due to an inherent self-organizing
behavior. Leveraging this insight, we build a robust CD method based on the
extraction of power -law spectral features that amplify genuine causal signals.
Our method consistently outperforms state-of-the-art alternatives on both
synthetic benchmarks and real-world datasets with known causal structures,
demonstrating its robustness and practical relevance.

</details>


### [195] [A Framework for Nonstationary Gaussian Processes with Neural Network Parameters](https://arxiv.org/abs/2507.12262)
*Zachary James,Joseph Guinness*

Main category: cs.LG

TL;DR: 为解决高斯过程平稳核的局限性，本文提出一种基于神经网络的非平稳核框架，有效提升了模型性能与表达力。


<details>
  <summary>Details</summary>
Motivation: 高斯过程（GP）常使用平稳核，这限制了模型的表达能力，使其不适用于许多复杂数据集。

Method: 提出一个框架，将非平稳核的参数建模为神经网络的输出，该神经网络以特征作为输入。神经网络与高斯过程通过链式法则联合训练。该方法灵活，可适应不同非平稳核，并兼容大规模数据集的近似方法。

Result: 在多个机器学习数据集上，所提出的非平稳方差和噪声变体方法在准确性和对数分数上均优于平稳模型和通过变分推断近似的分层模型。仅非平稳方差的模型也取得了类似结果。此外，还成功展示了在空间数据集中恢复非平稳参数的能力。

Conclusion: 本文提出的非平稳核框架显著增强了高斯过程的表达能力和预测性能，有效解决了传统平稳核的局限性，为GP建模提供了更灵活有效的方案。

Abstract: Gaussian processes have become a popular tool for nonparametric regression
because of their flexibility and uncertainty quantification. However, they
often use stationary kernels, which limit the expressiveness of the model and
may be unsuitable for many datasets. We propose a framework that uses
nonstationary kernels whose parameters vary across the feature space, modeling
these parameters as the output of a neural network that takes the features as
input. The neural network and Gaussian process are trained jointly using the
chain rule to calculate derivatives. Our method clearly describes the behavior
of the nonstationary parameters and is compatible with approximation methods
for scaling to large datasets. It is flexible and easily adapts to different
nonstationary kernels without needing to redesign the optimization procedure.
Our methods are implemented with the GPyTorch library and can be readily
modified. We test a nonstationary variance and noise variant of our method on
several machine learning datasets and find that it achieves better accuracy and
log-score than both a stationary model and a hierarchical model approximated
with variational inference. Similar results are observed for a model with only
nonstationary variance. We also demonstrate our approach's ability to recover
the nonstationary parameters of a spatial dataset.

</details>


### [196] [RegCL: Continual Adaptation of Segment Anything Model via Model Merging](https://arxiv.org/abs/2507.12297)
*Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang*

Main category: cs.LG

TL;DR: 本文提出RegCL，一个新颖的无重放持续学习框架，通过合并不同领域训练的SAM适配模块参数，有效整合多领域知识，解决灾难性遗忘问题并保持模型效率。


<details>
  <summary>Details</summary>
Motivation: Segment Anything Model (SAM)在特定领域存在性能限制，现有基于适配器的一步适应方法在跨领域使用时易发生灾难性遗忘，严重阻碍了模型的扩展性。因此，需要一种高效且能避免灾难性遗忘的多领域知识集成方案。

Method: 提出RegCL，一个非重放持续学习框架。该框架将模型合并算法融入持续学习范式，具体通过合并在不同领域训练的SAM适应模块（如LoRA模块）的参数。合并过程通过权重优化引导，旨在最小化合并模型与各领域特定模型之间的预测差异。

Result: RegCL有效地整合了多领域知识，并保持了参数效率（模型大小不变，无需存储历史数据）。实验结果表明，RegCL在多个下游数据集上取得了良好的持续学习性能。

Conclusion: RegCL通过创新的模型合并方法，成功解决了SAM在多领域适应中的灾难性遗忘问题，提供了一个高效、可扩展的持续学习解决方案，并在动态场景中展现了其有效性。

Abstract: To address the performance limitations of the Segment Anything Model (SAM) in
specific domains, existing works primarily adopt adapter-based one-step
adaptation paradigms. However, some of these methods are specific developed for
specific domains. If used on other domains may lead to performance degradation.
This issue of catastrophic forgetting severely limits the model's scalability.
To address this issue, this paper proposes RegCL, a novel non-replay continual
learning (CL) framework designed for efficient multi-domain knowledge
integration through model merging. Specifically, RegCL incorporates the model
merging algorithm into the continual learning paradigm by merging the
parameters of SAM's adaptation modules (e.g., LoRA modules) trained on
different domains. The merging process is guided by weight optimization, which
minimizes prediction discrepancies between the merged model and each of the
domain-specific models. RegCL effectively consolidates multi-domain knowledge
while maintaining parameter efficiency, i.e., the model size remains constant
regardless of the number of tasks, and no historical data storage is required.
Experimental results demonstrate that RegCL achieves favorable continual
learning performance across multiple downstream datasets, validating its
effectiveness in dynamic scenarios.

</details>


### [197] [PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning](https://arxiv.org/abs/2507.12305)
*M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk*

Main category: cs.LG

TL;DR: 在线持续学习（OCL）面临数据隐私和灾难性遗忘挑战，现有方法存在隐私或参数膨胀问题。本文提出一种新颖的Prompt-based OCL方法，通过轻量级Prompt生成器和特定知识组件，在多个数据集上显著优于SOTA，同时参数更少、效率更高。


<details>
  <summary>Details</summary>
Motivation: 在线持续学习（OCL）中，数据仅可被一次性访问的隐私限制加剧了灾难性遗忘问题。当前主流的OCL方法，如基于记忆示例回放，可能因数据开放政策而无法实际应用；而基于Prompt的方法虽表现出色，但可训练参数数量随任务增长，导致流数据处理的吞吐量问题。因此，亟需一种既能有效应对灾难性遗忘，又能满足数据隐私要求且具备高效率的OCL方法。

Method: 本研究提出了一种新颖的Prompt-based在线持续学习方法，包含四个核心组件：1) 作为通用知识的单一轻量级Prompt生成器；2) 作为特定知识的可训练的缩放器和位移器（scaler-and-shifter）；3) 保持预训练模型（PTM）泛化能力；4) 硬-软更新机制。

Result: 所提出的方法在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上均取得了显著高于当前SOTA方法的性能。复杂度分析表明，该方法所需参数数量相对较少，并且实现了适中的训练时间、推理时间及吞吐量。

Conclusion: 本研究提出的新型Prompt-based在线持续学习方法，在处理数据隐私约束下的灾难性遗忘问题上表现卓越。它不仅在多个基准数据集上显著超越现有SOTA，而且在参数效率和运行时性能方面也具有优势，为在线持续学习提供了一个实用且高性能的解决方案。

Abstract: The data privacy constraint in online continual learning (OCL), where the
data can be seen only once, complicates the catastrophic forgetting problem in
streaming data. A common approach applied by the current SOTAs in OCL is with
the use of memory saving exemplars or features from previous classes to be
replayed in the current task. On the other hand, the prompt-based approach
performs excellently in continual learning but with the cost of a growing
number of trainable parameters. The first approach may not be applicable in
practice due to data openness policy, while the second approach has the issue
of throughput associated with the streaming data. In this study, we propose a
novel prompt-based method for online continual learning that includes 4 main
components: (1) single light-weight prompt generator as a general knowledge,
(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model
(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our
proposed method achieves significantly higher performance than the current
SOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity
analysis shows that our method requires a relatively smaller number of
parameters and achieves moderate training time, inference time, and throughput.
For further study, the source code of our method is available at
https://github.com/anwarmaxsum/PROL.

</details>


### [198] [Thought Purity: Defense Paradigm For Chain-of-Thought Attack](https://arxiv.org/abs/2507.12314)
*Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou*

Main category: cs.LG

TL;DR: 针对强化学习训练的大型推理模型中CoT攻击的安全性-性能漏洞，提出了一种名为“思维纯度（TP）”的综合防御范式，旨在增强抵抗恶意内容并保持操作效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习训练的大型推理模型（LRMs），特别是其思维链（CoT）生成过程，易受安全威胁，如链式思维攻击（CoTA），这种攻击通过利用提示可控性，以低成本干预同时降低CoT安全性和任务性能，构成关键漏洞。

Method: 提出“思维纯度（Thought Purity, TP）”防御范式。该方案通过三个协同组件实现：1) 安全优化的数据处理管道；2) 强化学习增强的规则约束；3) 自适应监控指标。

Result: 该方法建立了首个针对强化学习对齐推理系统中CoTA漏洞的综合防御机制，显著提升了下一代AI架构的安全-功能平衡。

Conclusion: “思维纯度”范式为解决大型推理模型中的关键安全漏洞提供了创新且全面的防御方案，有望促进未来AI系统在安全性和功能性之间实现更好的平衡。

Abstract: While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,
Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large
Language Models (LLMs) domain, their susceptibility to security threats remains
a critical vulnerability. This weakness is particularly evident in
Chain-of-Thought (CoT) generation processes, where adversarial methods like
backdoor prompt attacks can systematically subvert the model's core reasoning
mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this
vulnerability through exploiting prompt controllability, simultaneously
degrading both CoT safety and task performance with low-cost interventions. To
address this compounded security-performance vulnerability, we propose Thought
Purity (TP): a defense paradigm that systematically strengthens resistance to
malicious content while preserving operational efficacy. Our solution achieves
this through three synergistic components: (1) a safety-optimized data
processing pipeline (2) reinforcement learning-enhanced rule constraints (3)
adaptive monitoring metrics. Our approach establishes the first comprehensive
defense mechanism against CoTA vulnerabilities in reinforcement
learning-aligned reasoning systems, significantly advancing the
security-functionality equilibrium for next-generation AI architectures.

</details>


### [199] [Heat Kernel Goes Topological](https://arxiv.org/abs/2507.12380)
*Maximilian Krahn,Vikas Garg*

Main category: cs.LG

TL;DR: 本文提出一种在组合复形上引入拉普拉斯算子的新型拓扑框架，通过高效计算热核生成节点描述符，解决了现有拓扑神经网络计算成本高的问题，实现了高表达性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 拓扑神经网络（TNNs）作为图神经网络的强大继任者，通常涉及高阶消息传递，导致显著的计算开销。

Method: 引入一种在组合复形（CCs）上定义拉普拉斯算子（Laplacian operator）的新型拓扑框架。该方法能够高效计算作为节点描述符的热核（heat kernels），捕获多尺度信息，提供置换等变表示，并易于集成到现代基于Transformer的架构中。

Result: 理论上，所提方法具有最大表达能力，可区分任意非同构的组合复形。经验上，其计算效率显著优于现有拓扑方法，在标准分子数据集上与最先进的描述符表现相当，并在区分复杂拓扑结构和避免拓扑基准上的盲点方面展现出卓越能力。

Conclusion: 该工作通过提供兼具表达性和可扩展性的表示，推动了拓扑深度学习的发展，为分子分类和性质预测任务开辟了新的研究方向。

Abstract: Topological neural networks have emerged as powerful successors of graph
neural networks. However, they typically involve higher-order message passing,
which incurs significant computational expense. We circumvent this issue with a
novel topological framework that introduces a Laplacian operator on
combinatorial complexes (CCs), enabling efficient computation of heat kernels
that serve as node descriptors. Our approach captures multiscale information
and enables permutation-equivariant representations, allowing easy integration
into modern transformer-based architectures.
  Theoretically, the proposed method is maximally expressive because it can
distinguish arbitrary non-isomorphic CCs. Empirically, it significantly
outperforms existing topological methods in terms of computational efficiency.
Besides demonstrating competitive performance with the state-of-the-art
descriptors on standard molecular datasets, it exhibits superior capability in
distinguishing complex topological structures and avoiding blind spots on
topological benchmarks. Overall, this work advances topological deep learning
by providing expressive yet scalable representations, thereby opening up
exciting avenues for molecular classification and property prediction tasks.

</details>


### [200] [Improving Reinforcement Learning Sample-Efficiency using Local Approximation](https://arxiv.org/abs/2507.12383)
*Mohit Prashant,Arvind Easwaran*

Main category: cs.LG

TL;DR: 在无限视野马尔可夫决策过程（MDP）的强化学习（RL）中，利用状态值依赖性，推导出比现有文献更精确的渐近样本复杂度PAC界限，并将样本复杂度降至$O(SA \log A)$。


<details>
  <summary>Details</summary>
Motivation: 现有文献中关于无限视野MDP中RL的PAC界限不够精确。本研究基于一个核心前提：状态之间距离越远，其值相关性越低，学习效率应有所不同；而邻近状态的值则相互依赖，应利用此特性优化样本分配。

Method: 通过利用原始MDP状态空间的子集构建更小的MDP来近似原始MDP。在此基础上，设计并构建了一个新的PAC-MDP算法，将其成果扩展到无限视野、无模型的强化学习环境。

Result: 成功推导出比现有文献更精确的PAC界限，显著降低了样本复杂度，达到了$O(SA \log A)$时间步（S为状态空间大小，A为动作空间大小）。实验结果表明，该算法比现有工作有显著改进。

Conclusion: 本研究通过创新的方法，在无限视野MDP的RL中实现了样本复杂度的显著优化，提供了更精确的PAC界限和更高效的学习算法，证明了利用状态距离来指导样本分配的有效性。

Abstract: In this study, we derive Probably Approximately Correct (PAC) bounds on the
asymptotic sample-complexity for RL within the infinite-horizon Markov Decision
Process (MDP) setting that are sharper than those in existing literature. The
premise of our study is twofold: firstly, the further two states are from each
other, transition-wise, the less relevant the value of the first state is when
learning the $\epsilon$-optimal value of the second; secondly, the amount of
'effort', sample-complexity-wise, expended in learning the $\epsilon$-optimal
value of a state is independent of the number of samples required to learn the
$\epsilon$-optimal value of a second state that is a sufficient number of
transitions away from the first. Inversely, states within each other's vicinity
have values that are dependent on each other and will require a similar number
of samples to learn. By approximating the original MDP using smaller MDPs
constructed using subsets of the original's state-space, we are able to reduce
the sample-complexity by a logarithmic factor to $O(SA \log A)$ timesteps,
where $S$ and $A$ are the state and action space sizes. We are able to extend
these results to an infinite-horizon, model-free setting by constructing a
PAC-MDP algorithm with the aforementioned sample-complexity. We conclude with
showing how significant the improvement is by comparing our algorithm against
prior work in an experimental setting.

</details>


### [201] [Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries](https://arxiv.org/abs/2507.12384)
*Bo Wen,Guoyun Gao,Zhicheng Xu,Ruibin Mao,Xiaojuan Qi,X. Sharon Hu,Xunzhao Yin,Can Li*

Main category: cs.LG

TL;DR: 本文提出一种利用MoS₂闪存模拟CAM的软硬件协同设计方法，实现对软树形模型高效且鲁棒的推理，解决了AI可信度、可解释性及硬件加速中的挑战。


<details>
  <summary>Details</summary>
Motivation: 人工智能的快速发展引发了对其可信度（特别是可解释性和鲁棒性）的担忧。树形模型在可解释性和准确性方面表现优秀，但其扩展性受计算成本限制。先前的模拟CAM加速方案因决策边界对设备变异敏感而效果不佳，导致硬件性能差且易受攻击。

Method: 本研究提出一种新颖的软硬件协同设计方法，利用基于二硫化钼（MoS₂）闪存的模拟CAM，其固有软边界特性能够支持软树形模型的高效推理。

Result: 在MoS₂模拟CAM阵列上的实验表明，该方法对设备变异和对抗性攻击具有卓越的鲁棒性，同时保持了最先进的准确性。具体地，在威斯康星诊断乳腺癌（WDBC）数据集上，模拟CAM阵列实现了96%的准确率并保持决策可解释性；在MNIST数据集上，在10%的设备阈值变化下，准确率仅下降0.6%，而传统决策树下降了45.3%。

Conclusion: 这项工作为开发提高人工智能可信度和效率的专用硬件铺平了道路。

Abstract: The rapid advancement of artificial intelligence has raised concerns
regarding its trustworthiness, especially in terms of interpretability and
robustness. Tree-based models like Random Forest and XGBoost excel in
interpretability and accuracy for tabular data, but scaling them remains
computationally expensive due to poor data locality and high data dependence.
Previous efforts to accelerate these models with analog content addressable
memory (CAM) have struggled, due to the fact that the difficult-to-implement
sharp decision boundaries are highly susceptible to device variations, which
leads to poor hardware performance and vulnerability to adversarial attacks.
This work presents a novel hardware-software co-design approach using $MoS_2$
Flash-based analog CAM with inherent soft boundaries, enabling efficient
inference with soft tree-based models. Our soft tree model inference
experiments on $MoS_2$ analog CAM arrays show this method achieves exceptional
robustness against device variation and adversarial attacks while achieving
state-of-the-art accuracy. Specifically, our fabricated analog CAM arrays
achieve $96\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,
while maintaining decision explainability. Our experimentally calibrated model
validated only a $0.6\%$ accuracy drop on the MNIST dataset under $10\%$ device
threshold variation, compared to a $45.3\%$ drop for traditional decision
trees. This work paves the way for specialized hardware that enhances AI's
trustworthiness and efficiency.

</details>


### [202] [ROC-n-reroll: How verifier imperfection affects test-time scaling](https://arxiv.org/abs/2507.12399)
*Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang*

Main category: cs.LG

TL;DR: 该研究从理论角度分析了语言模型测试时扩展方法（如拒绝采样和Best-of-N）中验证器不完美对性能的影响，揭示了性能与验证器ROC曲线几何形状的精确关系。


<details>
  <summary>Details</summary>
Motivation: 现有关于语言模型测试时扩展方法（如Best-of-N和拒绝采样）的研究多为经验性，缺乏对验证器不完美如何影响这些方法性能的理论理解。

Method: 通过理论证明，详细阐述了这些方法在实例级准确性上如何精确地由验证器ROC曲线的几何形状来刻画。此外，研究结果在GSM8K数据集上使用不同版本的Llama和Qwen模型进行了实验验证。

Result: 研究发现，拒绝采样的性能扩展由ROC曲线的局部几何形状决定，而Best-of-N则依赖于ROC曲线的全局属性。当ROC曲线未知时，无法通过低计算量推断拒绝采样的性能。在固定计算量下，拒绝采样优于Best-of-N；但在无限计算量极限下，两种方法都收敛到由ROC曲线原点附近斜率决定的相同准确度。

Conclusion: 该研究提供了测试时扩展方法的理论基础，揭示了验证器ROC曲线的几何形状在准确性预测中的核心作用，并详细比较了拒绝采样和Best-of-N在不同计算量情景下的性能特征。

Abstract: Test-time scaling aims to improve language model performance by leveraging
additional compute during inference. While many works have empirically studied
techniques like Best-of-N (BoN) and rejection sampling that make use of a
verifier to enable test-time scaling, there is little theoretical understanding
of how verifier imperfection affects performance. In this work, we address this
gap. Specifically, we prove how instance-level accuracy of these methods is
precisely characterized by the geometry of the verifier's ROC curve.
Interestingly, while scaling is determined by the local geometry of the ROC
curve for rejection sampling, it depends on global properties of the ROC curve
for BoN. As a consequence when the ROC curve is unknown, it is impossible to
extrapolate the performance of rejection sampling based on the low-compute
regime. Furthermore, while rejection sampling outperforms BoN for fixed
compute, in the infinite-compute limit both methods converge to the same level
of accuracy, determined by the slope of the ROC curve near the origin. Our
theoretical results are confirmed by experiments on GSM8K using different
versions of Llama and Qwen to generate and verify solutions.

</details>


### [203] [NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data](https://arxiv.org/abs/2507.12412)
*Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva*

Main category: cs.LG

TL;DR: 提出NOCTA，一种在时序预测任务中进行成本感知型序贯特征获取的方法，该方法在考虑时序动态和获取成本的同时，能有效获取最具信息量的特征，并优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 在医疗等关键应用中，资源限制导致预测所需信息获取受限，且各项特征获取伴随时间、金钱或风险等成本。此外，时序预测任务中，特征和标签随时间演变，进一步增加了何时及获取何种信息的重要性判断的复杂性。因此，需要一种方法能在推断时序贯地获取最具信息量的特征，同时有效权衡时间成本。

Method: 本文提出NOCTA（非贪婪目标成本权衡获取方法），用于在推断时序贯获取最具信息量的特征，同时考虑时序动态和获取成本。该方法首先引入一个内聚的估计目标，然后开发了两种互补的估计器：1）基于最近邻的非参数方法（NOCTA-NP），用于指导特征获取；2）直接预测潜在获取效用的参数方法（NOCTA-P）。

Result: 在合成数据集和真实世界医疗数据集上的实验表明，NOCTA的两种变体（NOCTA-NP和NOCTA-P）均优于现有基线方法。

Conclusion: NOCTA为时序预测任务中成本感知型序贯特征获取提供了一种有效解决方案，通过同时考虑时序动态和获取成本，展现出优于现有方法的性能。

Abstract: In many critical applications, resource constraints limit the amount of
information that can be gathered to make predictions. For example, in
healthcare, patient data often spans diverse features ranging from lab tests to
imaging studies. Each feature may carry different information and must be
acquired at a respective cost of time, money, or risk to the patient. Moreover,
temporal prediction tasks, where both instance features and labels evolve over
time, introduce additional complexity in deciding when or what information is
important. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff
Acquisition method that sequentially acquires the most informative features at
inference time while accounting for both temporal dynamics and acquisition
cost. We first introduce a cohesive estimation target for our NOCTA setting,
and then develop two complementary estimators: 1) a non-parametric method based
on nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric
method that directly predicts the utility of potential acquisitions (NOCTA-P).
Experiments on synthetic and real-world medical datasets demonstrate that both
NOCTA variants outperform existing baselines.

</details>


### [204] [Mixture of Raytraced Experts](https://arxiv.org/abs/2507.12419)
*Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti*

Main category: cs.LG

TL;DR: 本文提出一种新型堆叠式专家混合（MoE）架构，名为“光线追踪专家混合”，它能动态选择专家序列，生成可变宽度和深度的计算图，实现计算量随准确度提升而增加，并在无需负载均衡机制下显著缩短训练周期并保持或提升精度。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构通常要求为给定样本分配固定的计算量，缺乏灵活性。研究动机是开发一种能够动态调整计算量，并随着计算循环增加而提高预测精度的MoE模型。

Method: 引入了“光线追踪专家混合”（Mixture of Raytraced Experts），这是一种堆叠式MoE架构。它通过动态选择专家序列来构建可变宽度和深度的计算图。模型的训练方法是迭代地从一组候选专家中采样，展开序列，类似于循环神经网络（RNN）的训练方式。

Result: 该方法能够随着计算在专家序列中循环而提升预测精度。它无需传统的负载均衡机制。初步实验显示，在保持或提高准确性的前提下，训练周期可减少10%至40%。

Conclusion: 这些成果为MoE领域指明了新的研究方向，有望设计出更快、表达能力更强的模型。

Abstract: We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts
(MoE) architecture which can dynamically select sequences of experts, producing
computational graphs of variable width and depth. Existing MoE architectures
generally require a fixed amount of computation for a given sample. Our
approach, in contrast, yields predictions with increasing accuracy as the
computation cycles through the experts' sequence. We train our model by
iteratively sampling from a set of candidate experts, unfolding the sequence
akin to how Recurrent Neural Networks are trained. Our method does not require
load-balancing mechanisms, and preliminary experiments show a reduction in
training epochs of 10\% to 40\% with a comparable/higher accuracy. These
results point to new research directions in the field of MoEs, allowing the
design of potentially faster and more expressive models. The code is available
at https://github.com/nutig/RayTracing

</details>


### [205] [Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks](https://arxiv.org/abs/2507.12435)
*Yi Li,David Mccoy,Nolan Gunter,Kaitlyn Lee,Alejandro Schuler,Mark van der Laan*

Main category: cs.LG

TL;DR: TDA是一种新颖的框架，将因果推断方法TMLE直接嵌入深度神经网络，以实现多参数目标的无偏因果推断。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络擅长预测但缺乏因果参数（如治疗效果、生存曲线）的有效推断。现有用于消除偏差的机器学习框架（如DML、TMLE）在神经网络实现中存在局限性，如“目标损失”无法保证求解效率影响函数，而“后验波动”在多参数设置下计算成本过高。

Method: 本文提出了“目标深度架构”（TDA），将TMLE直接嵌入到神经网络的参数空间中。TDA通过冻结大部分模型参数，仅迭代更新一小部分“目标”参数子集，并沿一个基于影响函数投影到权重损失梯度跨度上的“目标梯度”进行更新。该方法可以轻松扩展到多维因果估计。

Result: 理论上，TDA能够产生消除一阶偏差的即插即用估计，并提供渐近有效的置信区间，同时继承了TMLE的双重稳健性和半参数效率等经典特性。实证上，在基准IHDP数据集和模拟生存数据上，TDA相比标准神经网络估计器和先前的后验方法，显著降低了偏差并提高了覆盖率。

Conclusion: TDA为在现代深度架构中对复杂多参数目标进行严谨的因果推断提供了一条直接且可扩展的途径。

Abstract: Modern deep neural networks are powerful predictive tools yet often lack
valid inference for causal parameters, such as treatment effects or entire
survival curves. While frameworks like Double Machine Learning (DML) and
Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,
existing neural implementations either rely on "targeted losses" that do not
guarantee solving the efficient influence function equation or computationally
expensive post-hoc "fluctuations" for multi-parameter settings. We propose
Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly
into the network's parameter space with no restrictions on the backbone
architecture. Specifically, TDA partitions model parameters - freezing all but
a small "targeting" subset - and iteratively updates them along a targeting
gradient, derived from projecting the influence functions onto the span of the
gradients of the loss with respect to weights. This procedure yields plug-in
estimates that remove first-order bias and produce asymptotically valid
confidence intervals. Crucially, TDA easily extends to multi-dimensional causal
estimands (e.g., entire survival curves) by merging separate targeting
gradients into a single universal targeting update. Theoretically, TDA inherits
classical TMLE properties, including double robustness and semiparametric
efficiency. Empirically, on the benchmark IHDP dataset (average treatment
effects) and simulated survival data with informative censoring, TDA reduces
bias and improves coverage relative to both standard neural-network estimators
and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable
pathway toward rigorous causal inference within modern deep architectures for
complex multi-parameter targets.

</details>


### [206] [A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning](https://arxiv.org/abs/2507.12439)
*Daniel Commey,Rebecca A. Sarpong,Griffith S. Klogo,Winful Bagyl-Bac,Garth V. Crosby*

Main category: cs.LG

TL;DR: 提出一种轻量级贝叶斯激励机制，通过经济手段阻止联邦学习中的数据投毒攻击，并在高比例攻击下显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的开放性使其易受数据投毒攻击，现有防御机制通常是被动、计算昂贵且假设多数参与者是诚实的，无法有效应对。

Method: 将每轮训练建模为贝叶斯不完全信息博弈，服务器作为委托人，使用少量私有验证数据集在支付前验证更新质量。设计满足善意客户端的个体理性（IR）和恶意行为者的激励兼容性（IC），使投毒在经济上不可取。

Result: 在MNIST和FashionMNIST数据集上的实验表明，即使面对50%的标签翻转攻击者，该机制仍能保持96.7%的准确率，比标准FedAvg高出51.7个百分点。该机制计算量轻，预算受限，易于集成。

Conclusion: 该经济学防御机制为联邦学习提供了一条实用、经济鲁棒且可持续的途径，有效抵御数据投毒攻击，为构建更安全的联邦学习生态系统奠定基础。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy. However, its
open-participation nature exposes it to data-poisoning attacks, in which
malicious actors submit corrupted model updates to degrade the global model.
Existing defenses are often reactive, relying on statistical aggregation rules
that can be computationally expensive and that typically assume an honest
majority. This paper introduces a proactive, economic defense: a lightweight
Bayesian incentive mechanism that makes malicious behavior economically
irrational. Each training round is modeled as a Bayesian game of incomplete
information in which the server, acting as the principal, uses a small, private
validation dataset to verify update quality before issuing payments. The design
satisfies Individual Rationality (IR) for benevolent clients, ensuring their
participation is profitable, and Incentive Compatibility (IC), making poisoning
an economically dominated strategy. Extensive experiments on non-IID partitions
of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping
adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3
percentage points lower than in a scenario with 30% label-flipping adversaries.
This outcome is 51.7 percentage points better than standard FedAvg, which
collapses under the same 50% attack. The mechanism is computationally light,
budget-bounded, and readily integrates into existing FL frameworks, offering a
practical route to economically robust and sustainable FL ecosystems.

</details>


### [207] [Cost-aware Stopping for Bayesian Optimization](https://arxiv.org/abs/2507.12453)
*Qian Xie,Linda Cai,Alexander Terenin,Peter I. Frazier,Ziv Scully*

Main category: cs.LG

TL;DR: 提出一种新的成本感知停止规则，用于贝叶斯优化，确保在评估昂贵黑盒函数时能有效控制累计成本，并提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 在贝叶斯优化中，现有自适应停止规则在成本感知场景下，无法保证评估成本不会过高，这在实际应用中是一个重要问题。

Method: 提出一种无需启发式调优的成本感知停止规则，该规则与Pandora's Box Gittins Index (PBGI)和log expected improvement per cost等先进成本感知采集函数有理论联系。研究者证明了该规则在与这些采集函数结合使用时，其预期累计评估成本存在理论上限。

Result: 在合成任务和经验任务（包括超参数优化和神经网络架构搜索）上的实验表明，所提出的停止规则与PBGI采集函数结合使用时，在成本调整后的简单遗憾度量方面，表现始终优于或与现有方法持平。

Conclusion: 该研究提供了一种实用且有理论依据的贝叶斯优化停止策略，特别适用于高成本函数评估场景，能在解决方案质量和累计评估成本之间取得更好的平衡。

Abstract: In automated machine learning, scientific discovery, and other applications
of Bayesian optimization, deciding when to stop evaluating expensive black-box
functions is an important practical consideration. While several adaptive
stopping rules have been proposed, in the cost-aware setting they lack
guarantees ensuring they stop before incurring excessive function evaluation
costs. We propose a cost-aware stopping rule for Bayesian optimization that
adapts to varying evaluation costs and is free of heuristic tuning. Our rule is
grounded in a theoretical connection to state-of-the-art cost-aware acquisition
functions, namely the Pandora's Box Gittins Index (PBGI) and log expected
improvement per cost. We prove a theoretical guarantee bounding the expected
cumulative evaluation cost incurred by our stopping rule when paired with these
two acquisition functions. In experiments on synthetic and empirical tasks,
including hyperparameter optimization and neural architecture size search, we
show that combining our stopping rule with the PBGI acquisition function
consistently matches or outperforms other acquisition-function--stopping-rule
pairs in terms of cost-adjusted simple regret, a metric capturing trade-offs
between solution quality and cumulative evaluation cost.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [208] [Towards a Non-Binary View of IPv6 Adoption](https://arxiv.org/abs/2507.11678)
*Sulyab Thottungal Valapu,John Heidemann*

Main category: cs.NI

TL;DR: 本研究从客户端、服务器和云提供商角度，对IPv6的部署现状进行了更细致的非二元分析。发现用户IPv6流量波动大，多数热门网站未完全支持IPv6，且云端IPv6采用率与启用便利性相关。结果表明IPv6部署在增长，但许多服务仍滞后。


<details>
  <summary>Details</summary>
Motivation: 现有IPv6部署研究通常仅限于二元判断（是否可用），但随着部署增加，需要一个更细致、非二元的视角来评估用户或服务使用IPv6的程度和频率。本研究旨在填补这一空白，从客户端、服务器和云提供商三个层面进行深入探讨。

Method: 本研究从三个方面进行分析：1) **客户端视角：** 观察用户流量，分析IPv6流量占比的波动性及其原因。2) **服务器视角：** 扩展对Web服务的分析，检查因依赖IPv4资源而部分支持IPv6的服务数量。3) **云提供商视角：** 调查云和CDN对IPv6的支持情况，分析租户部署率差异及与IPv6启用便利性的相关性。

Result: 1) **客户端：** 用户发送的IPv6流量占比差异显著（跨用户和日间波动，标准差超15%），主要原因在于IPv6流量多为人为生成（呈现昼夜规律）以及服务对IPv6支持程度不一。2) **服务器：** 在前10万个网站中，仅有12.5%被认定为完全支持IPv6。3) **云提供商：** 尽管所有云和CDN都支持IPv6，但租户部署率在不同提供商之间差异显著；云中启用IPv6的便利性与租户的IPv6采用率呈正相关。

Conclusion: 研究结果表明，IPv6的部署正在增长，但许多服务仍处于滞后状态，存在显著的改进空间。研究还根据发现，为云提供商提升IPv6采用率提出了最佳实践建议。

Abstract: Twelve years have passed since World IPv6 Launch Day, but what is the current
state of IPv6 deployment? Prior work has examined IPv6 status as a binary: can
you use IPv6, or not? As deployment increases we must consider a more nuanced,
non-binary perspective on IPv6: how much and often can a user or a service use
IPv6? We consider this question as a client, server, and cloud provider.
Considering the client's perspective, we observe user traffic. We see that the
fraction of IPv6 traffic a user sends varies greatly, both across users and
day-by-day, with a standard deviation of over 15%. We show this variation
occurs for two main reasons. First, IPv6 traffic is primarily human-generated,
thus showing diurnal patterns. Second, some services are IPv6-forward and
others IPv6-laggards, so as users do different things their fraction of IPv6
varies. We look at server-side IPv6 adoption in two ways. First, we expand
analysis of web services to examine how many are only partially IPv6 enabled
due to their reliance on IPv4-only resources. Our findings reveal that only
12.5% of top 100k websites qualify as fully IPv6-ready. Finally, we examine
cloud support for IPv6. Although all clouds and CDNs support IPv6, we find that
tenant deployment rates vary significantly across providers. We find that ease
of enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates,
and recommend best practices for cloud providers to improve IPv6 adoption. Our
results suggest IPv6 deployment is growing, but many services lag, presenting a
potential for improvement.

</details>


### [209] [On QoE-Aware Traffic Management for Real-time, Interactive Video with Time-variant Spatial Complexity](https://arxiv.org/abs/2507.11798)
*Szilveszter Nádas,Lars Ernström,David Lindero,Jonathan Lynam*

Main category: cs.NI

TL;DR: 本文分析了实时交互式视频的空间复杂度，发现其具有时间变异性，并提出基于效用和QoE感知的动态资源分配方法，证明其性能优于静态分配和追求平均QoE的分配方法。


<details>
  <summary>Details</summary>
Motivation: 针对实时交互式视频的空间复杂度在不同内容类型和同一内容内部的时间变异性，探索其对流量管理的影响，并寻求更有效的方法来优化资源共享和用户体验质量（QoE）。

Method: 分析了实时交互式视频的空间复杂度（比特率与QoE的关系）；研究了空间复杂度的时间变异性；引入“效用”概念管理资源共享偏好；对比了基于QoE的频繁重新分配与静态速率分配；比较了基于效用的资源分配与旨在实现等QoE分配的方法。

Result: 发现视频的空间复杂度不仅在不同内容类型间有差异，在同一视频内部也存在秒级的时间变异性；QoE感知的频繁资源重新分配相比静态速率分配具有显著性能优势；基于效用的资源分配方法优于旨在实现等QoE的分配方法，能提升平均QoE并控制最差QoE。

Conclusion: 动态、QoE感知且尤其是基于效用的资源分配策略对于优化实时交互式视频的流量管理至关重要，相比静态或追求平均QoE的方法，能够显著提升整体用户体验。

Abstract: We analyzed spatial complexity, defined as the relationship between the
required bitrate and a corresponding picture Quality of Experience (QoE)
metric, for realistic, long, real-time, interactive video clips. Apart from
variation across different content types, e.g., game genres, we discovered
time-variability within a clip from second to second, and explored the
ramifications for traffic management. We introduced utility as an elegant way
to manage resource sharing preferences. Our analysis of resource sharing
methods shows that frequent QoE-aware reallocation has significant performance
advantages compared to static rate allocation, even in case the latter is based
on rich information about long-term average spatial complexity. We have also
shown that utility-based resource allocation has clear advantages over methods
targeting equal QoE allocation, it increases the average QoE, while it still
controls the worst case QoE.

</details>


### [210] [Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview](https://arxiv.org/abs/2507.11935)
*Jikang Deng,Fizza Hassan,Hui Zhou,Saad Al-Ahmadi,Mohamed-Slim Alouini,Daniel B. Da Costa*

Main category: cs.NI

TL;DR: 本文提出了一种基于开放无线接入网络（ORAN）的非地面网络（NTN）框架，以解决NTN在开发运维（DevOps）生命周期中面临的智能和可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 6G网络对效率、可靠性和灵活性提出了更高要求。非地面网络（NTN）虽然在覆盖、频谱效率和弹性方面具有优势，但其高空和高移动性特性导致开发运维（DevOps）面临挑战，缺乏原生的AI能力，阻碍了智能和可扩展的网络管理。现有研究虽探讨了ORAN与NTN的结合，但缺乏如何在DevOps全生命周期中有效集成，特别是智能ORAN如何解决NTN可扩展性挑战的整体视角。

Method: 文章首先回顾了ORAN和NTN的背景知识，概述了ORAN在NTN领域的最新研究，并阐述了促使采用ORAN解决方案的DevOps挑战。在此基础上，提出了“基于ORAN的NTN框架”，并详细讨论了其特性和架构，包括灵活的前传拆分、支持分布式学习的RAN智能控制器（RICs）增强、可扩展的部署架构以及多域服务管理。

Result: 本文提出了一个全面的基于ORAN的NTN框架及其详细架构和关键特性，旨在解决NTN在DevOps生命周期中面临的挑战，特别是通过ORAN的智能能力提升NTN的可扩展性。该框架涵盖了从网络架构到管理策略的多个层面。

Conclusion: 该研究为ORAN与NTN的有效结合提供了一个整体框架，并为未来的研究指明了方向，包括该框架与其他使能技术和方案的融合，以及潜在的应用场景。

Abstract: As the path toward 6G networks is being charted, the emerging applications
have motivated evolutions of network architectures to realize the efficient,
reliable, and flexible wireless networks. Among the potential architectures,
the non-terrestrial network (NTN) and open radio access network (ORAN) have
received increasing interest from both academia and industry. Although the
deployment of NTNs ensures coverage, enhances spectral efficiency, and improves
the resilience of wireless networks. The high altitude and mobility of NTN
present new challenges in the development and operations (DevOps) lifecycle,
hindering intelligent and scalable network management due to the lack of native
artificial intelligence (AI) capability. With the advantages of ORAN in
disaggregation, openness, virtualization, and intelligence, several works
propose integrating ORAN principles into the NTN, focusing mainly on ORAN
deployment options based on transparent and regenerative systems. However, a
holistic view of how to effectively combine ORAN and NTN throughout the DevOps
lifecycle is still missing, especially regarding how intelligent ORAN addresses
the scalability challenges in NTN. Motivated by this, in this paper, we first
provide the background knowledge about ORAN and NTN, outline the
state-of-the-art research on ORAN for NTNs, and present the DevOps challenges
that motivate the adoption of ORAN solutions. We then propose the ORAN-based
NTN framework, discussing its features and architectures in detail. These
include the discussion about flexible fronthaul split, RAN intelligent
controllers (RICs) enhancement for distributed learning, scalable deployment
architecture, and multi-domain service management. Finally, the future research
directions, including combinations of the ORAN-based NTN framework and other
enabling technologies and schemes, as well as the candidate use cases, are
highlighted.

</details>


### [211] [FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks](https://arxiv.org/abs/2507.12265)
*Zihan Zhu,Dongchao Wu,Zhanbang Zhang,Jian Yang*

Main category: cs.NI

TL;DR: 提出了一种高效、灵活的集中式调度算法，用于支持光交换机的Clos网络动态调度，实现最大吞吐量并最小化重排次数。


<details>
  <summary>Details</summary>
Motivation: 数据中心网络中使用Clos拓扑以来，一直缺乏支持动态调度的实用集中式调度算法。光交换机（无缓冲、切换时间长）的引入进一步加剧了这一问题，要求调度算法必须最大化吞吐量并最小化重排次数。

Method: 本文提出了一种新的集中式调度算法。该算法通过“替换链概念”（replacement chain concept）和“位集优化”（bitset optimization）实现其高性能和灵活性。

Result: 该算法在单速率双向Clos网络中实现了理论最大吞吐量，并产生了接近最小重排次数的调度方案。它是迄今为止唯一直接支持双向Clos网络且时间效率高到足以支持动态调度的算法。在静态最小重布线方面，其运行时间仅为其他算法的几分之一到百分之几，且重排次数持续优化，允许更频繁的调整并减少对通信的影响。此外，该算法还非常灵活，能够支持真实世界中的各种功能需求。

Conclusion: 本文提出的集中式调度算法有效解决了Clos网络中光交换机动态调度缺乏实用方案的问题，通过创新方法实现了理论最大吞吐量和近乎最小的重排次数，同时具备极高的时间效率和灵活性，为未来数据中心网络提供了高性能的调度解决方案。

Abstract: Ever since Clos topologies were used in datacenter networks (DCNs), a
practical centralized scheduling algorithm that supports dynamic scheduling has
been absent. The introduction of optical switches in DCNs as a future-proof
solution exacerbates this problem due to several properties of optical
switches, such as the fact that they are generally bufferless and therefore
rely on centralized scheduling, and that they have long switching times and
therefore require the number of rearrangements to be minimized.
  In this paper, we propose a centralized scheduling algorithm that achieves
theoretical maximum throughput even in one-rate bidirectional Clos networks,
while producing schemes with near-minimal numbers of rearrangements. It is the
only algorithm that directly supports bidirectional Clos networks and has a
time efficiency high enough to support dynamic scheduling to date. For static
minimal rewiring, its running time ranges from a fraction to a few hundredths
of other algorithms, and the number of rearrangements has also been steadily
improved, allowing for more frequent adjustments and less impact on ongoing
communications. In addition, the algorithm is very flexible and can support
various functional requirements in real-world environments. We achieve this
result through the replacement chain concept and bitset optimization.

</details>


### [212] [LLM-Based Config Synthesis requires Disambiguation](https://arxiv.org/abs/2507.12443)
*Rajdeep Mondal,Nikolaj Bjorner,Todd Millstein,Alan Tang,George Varghese*

Main category: cs.NI

TL;DR: LLM在网络配置合成中存在用户意图歧义问题，本文提出Clarify系统，通过消歧模块帮助LLM明确意图，实现增量策略合成与验证。


<details>
  <summary>Details</summary>
Motivation: LLM在程序合成中存在用户意图歧义问题，尤其在网络配置（如route-maps和ACLs）的增量合成中。这些结构在头部空间频繁重叠，导致LLM在缺乏用户交互时无法推断动作优先级，且该问题在大型云环境中被证实真实存在（ACLs有数百个重叠）。

Method: 提出原型系统Clarify，其通过一个新的名为“消歧器”（Disambiguator）的模块增强LLM，以帮助明确用户意图。

Result: 在小型合成工作负载上，Clarify系统在消歧后能够增量合成路由策略并进行验证。

Conclusion: 本研究的歧义处理方法具有更广泛的适用性，可用于LLM能正确合成更新意图，但其集成可能导致歧义和不同全局行为的场景。

Abstract: Beyond hallucinations, another problem in program synthesis using LLMs is
ambiguity in user intent. We illustrate the ambiguity problem in a networking
context for LLM-based incremental configuration synthesis of route-maps and
ACLs. These structures frequently overlap in header space, making the relative
priority of actions impossible for the LLM to infer without user interaction.
Measurements in a large cloud identify complex ACLs with 100's of overlaps,
showing ambiguity is a real problem. We propose a prototype system, Clarify,
which uses an LLM augmented with a new module called a Disambiguator that helps
elicit user intent. On a small synthetic workload, Clarify incrementally
synthesizes routing policies after disambiguation and then verifies them. Our
treatment of ambiguities is useful more generally when the intent of updates
can be correctly synthesized by LLMs, but their integration is ambiguous and
can lead to different global behaviors.

</details>


### [213] [CRAFT: Latency and Cost-Aware Genetic-Based Framework for Node Placement in Edge-Fog Environments](https://arxiv.org/abs/2507.12445)
*Soheil Mahdizadeh,Amir Mahdi Rasouli,Mohammad Pourashory,Sadra Galavani,Mohsen Ansari*

Main category: cs.NI

TL;DR: 本文提出一种基于遗传算法的边缘-雾节点部署策略，旨在优化物联网中的延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 物联网中降低延迟至关重要。尽管云计算有所帮助，但难以满足实时需求。边缘和雾计算通过将计算节点置于更靠近用户的位置来提供低延迟和高处理能力。然而，边缘-雾节点战略性部署对延迟和系统成本影响显著，亟需优化。

Method: 采用基于遗传算法的节点放置策略，以解决边缘和雾节点部署的优化问题。

Result: 仿真结果表明，所提出的框架可将延迟降低高达2.77%，成本降低31.15%。

Conclusion: 所提出的遗传算法优化策略能够有效实现边缘-雾节点的最优放置，从而显著降低物联网系统的延迟和成本。

Abstract: Reducing latency in the Internet of Things (IoT) is a critical concern. While
cloud computing facilitates communication, it falls short of meeting real-time
requirements reliably. Edge and fog computing have emerged as viable solutions
by positioning computing nodes closer to end users, offering lower latency and
increased processing power. An edge-fog framework comprises various components,
including edge and fog nodes, whose strategic placement is crucial as it
directly impacts latency and system cost. This paper presents an effective and
tunable node placement strategy based on a genetic algorithm to address the
optimization problem of deploying edge and fog nodes. The main objective is to
minimize latency and cost through optimal node placement. Simulation results
demonstrate that the proposed framework achieves up to 2.77% latency and 31.15%
cost reduction.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [214] [Landmark Detection for Medical Images using a General-purpose Segmentation Model](https://arxiv.org/abs/2507.11551)
*Ekaterina Stansfield,Jennifer A. Mitterer,Abdulrahman Altahhan*

Main category: eess.IV

TL;DR: 本文提出结合YOLO和SAM模型，解决传统分割模型在骨科X光片中对精细解剖标志物分割精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 骨科X光片中的解剖标志物检测是关键步骤，但通用基础分割模型如SAM不直接支持此功能，需要高度特异性的提示。即使是医用变体MedSAM，也缺乏骨科骨盆标志物所需的精细精度，无法准确分割复杂的细微结构。

Method: 研究者提出利用YOLO模型生成边界框作为SAM的输入提示。YOLO擅长目标检测，而SAM在复杂结构分割方面表现出色。通过将YOLO生成的边界框引导SAM，训练了这种混合模型来准确分割骨科骨盆X光片。

Result: 该组合模型不仅成功分割了8个解剖标志物的试点数据集，还扩展到72个标志物和16个具有复杂轮廓的区域（如股骨皮质骨和骨盆入口）。结果显示，YOLO和SAM的组合在骨科骨盆X光片中检测解剖标志物和复杂轮廓方面表现出色。

Conclusion: 结合YOLO和SAM的模型在骨科骨盆X光片中实现了解剖标志物和复杂轮廓的精确检测，为医疗诊断提供了可靠的分割能力。

Abstract: Radiographic images are a cornerstone of medical diagnostics in orthopaedics,
with anatomical landmark detection serving as a crucial intermediate step for
information extraction. General-purpose foundational segmentation models, such
as SAM (Segment Anything Model), do not support landmark segmentation out of
the box and require prompts to function. However, in medical imaging, the
prompts for landmarks are highly specific. Since SAM has not been trained to
recognize such landmarks, it cannot generate accurate landmark segmentations
for diagnostic purposes. Even MedSAM, a medically adapted variant of SAM, has
been trained to identify larger anatomical structures, such as organs and their
parts, and lacks the fine-grained precision required for orthopaedic pelvic
landmarks. To address this limitation, we propose leveraging another
general-purpose, non-foundational model: YOLO. YOLO excels in object detection
and can provide bounding boxes that serve as input prompts for SAM. While YOLO
is efficient at detection, it is significantly outperformed by SAM in
segmenting complex structures. In combination, these two models form a reliable
pipeline capable of segmenting not only a small pilot set of eight anatomical
landmarks but also an expanded set of 72 landmarks and 16 regions with complex
outlines, such as the femoral cortical bone and the pelvic inlet. By using
YOLO-generated bounding boxes to guide SAM, we trained the hybrid model to
accurately segment orthopaedic pelvic radiographs. Our results show that the
proposed combination of YOLO and SAM yields excellent performance in detecting
anatomical landmarks and intricate outlines in orthopaedic pelvic radiographs.

</details>


### [215] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 该论文提出了CompressedVQA-HDR，一个用于评估高动态范围（HDR）压缩视频质量的框架，其中FR模型使用Swin Transformer，NR模型使用SigLip 2，并在多种数据集上进行训练以克服HDR数据限制，最终实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有压缩视频质量评估（VQA）方法缺乏泛化能力，难以处理日益多样化的视频类型，特别是高动态范围（HDR）内容，这阻碍了视频压缩算法的实际应用和进一步发展。

Method: 引入CompressedVQA-HDR框架，包含全参考（FR）和无参考（NR）VQA模型。FR模型采用Swin Transformer作为骨干网络，通过提取中间层特征计算参考帧和失真帧之间的深度结构和纹理相似性。NR模型采用SigLip 2作为骨干网络，提取最后一层特征图的全局均值作为质量感知表示。为解决HDR训练数据有限的问题，FR模型在大规模SDR VQA数据集上进行预训练，并在HDRSDR-VQA数据集上进行微调；NR模型采用迭代式混合数据集训练策略，随后在HDRSDR-VQA数据集上进行微调。

Result: 实验结果表明，所提出的模型在与现有FR和NR VQA模型相比时，取得了最先进的性能。其中，CompressedVQA-HDR-FR模型在IEEE ICME 2025的“通用HDR与SDR视频质量测量大挑战”的FR赛道中获得第一名。

Conclusion: CompressedVQA-HDR框架有效解决了HDR视频质量评估的挑战，展现出强大的泛化能力和卓越的性能，为视频质量评估领域设立了新的基准。

Abstract: Video compression is a standard procedure applied to all videos to minimize
storage and transmission demands while preserving visual quality as much as
possible. Therefore, evaluating the visual quality of compressed videos is
crucial for guiding the practical usage and further development of video
compression algorithms. Although numerous compressed video quality assessment
(VQA) methods have been proposed, they often lack the generalization capability
needed to handle the increasing diversity of video types, particularly high
dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an
effective VQA framework designed to address the challenges of HDR video quality
assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the
backbone networks for the proposed full-reference (FR) and no-reference (NR)
VQA models, respectively. For the FR model, we compute deep structural and
textural similarities between reference and distorted frames using
intermediate-layer features extracted from the Swin Transformer as its
quality-aware feature representation. For the NR model, we extract the global
mean of the final-layer feature maps from SigLip 2 as its quality-aware
representation. To mitigate the issue of limited HDR training data, we
pre-train the FR model on a large-scale standard dynamic range (SDR) VQA
dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ
an iterative mixed-dataset training strategy across multiple compressed VQA
datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental
results show that our models achieve state-of-the-art performance compared to
existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place
in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand
Challenge at IEEE ICME 2025. The code is available at
https://github.com/sunwei925/CompressedVQA-HDR.

</details>


### [216] [3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation](https://arxiv.org/abs/2507.11557)
*Jiaxu Zheng,Meiman He,Xuhui Tang,Xiong Wang,Tuoyu Cao,Tianyi Zeng,Lichi Zhang,Chenyu You*

Main category: eess.IV

TL;DR: 本文提出了一种新颖的3D小波潜在扩散模型（3D-WLDM），用于改进磁共振（MR）到计算机断层扫描（CT）的图像合成，以解决现有方法在空间对齐和图像质量方面的不足，从而提高临床诊断和治疗中衰减估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 磁共振（MR）成像在临床诊断和集成治疗（如PET/MR和MR-only放疗）中日益重要，但其关键环节——辐射衰减估计，通常依赖于从MR图像合成CT图像来生成衰减图。现有全身MR到CT合成方法存在空间对齐差和图像质量不足的问题，无法可靠用于下游临床任务。

Method: 本研究提出了一种新颖的3D小波潜在扩散模型（3D-WLDM）。该模型在学习的潜在空间中执行模态转换，通过在编码器-解码器架构中整合小波残差模块，增强了精细尺度特征的捕获和重建。为保持解剖完整性，模型解耦了结构和模态特异性特征，并锚定结构组件以防止形变。此外，在扩散模型中引入了双跳连接注意力机制。

Result: 研究结果表明，该方法能够生成高分辨率的CT图像，并显著改善了骨骼结构和软组织对比度的表示，有效解决了现有MR到CT合成方法在空间对齐和图像质量方面的局限性。

Conclusion: 3D-WLDM有效解决了当前MR到CT合成方法的局限性，能够生成高质量的CT图像，对于先进的MR集成临床工作流程中的精确衰减映射至关重要。

Abstract: Magnetic Resonance (MR) imaging plays an essential role in contemporary
clinical diagnostics. It is increasingly integrated into advanced therapeutic
workflows, such as hybrid Positron Emission Tomography/Magnetic Resonance
(PET/MR) imaging and MR-only radiation therapy. These integrated approaches are
critically dependent on accurate estimation of radiation attenuation, which is
typically facilitated by synthesizing Computed Tomography (CT) images from MR
scans to generate attenuation maps. However, existing MR-to-CT synthesis
methods for whole-body imaging often suffer from poor spatial alignment between
the generated CT and input MR images, and insufficient image quality for
reliable use in downstream clinical tasks. In this paper, we present a novel 3D
Wavelet Latent Diffusion Model (3D-WLDM) that addresses these limitations by
performing modality translation in a learned latent space. By incorporating a
Wavelet Residual Module into the encoder-decoder architecture, we enhance the
capture and reconstruction of fine-scale features across image and latent
spaces. To preserve anatomical integrity during the diffusion process, we
disentangle structural and modality-specific characteristics and anchor the
structural component to prevent warping. We also introduce a Dual Skip
Connection Attention mechanism within the diffusion model, enabling the
generation of high-resolution CT images with improved representation of bony
structures and soft-tissue contrast.

</details>


### [217] [Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach](https://arxiv.org/abs/2507.11561)
*Lucas Erlacher,Samuel Ruipérez-Campillo,Holger Michel,Sven Wellmann,Thomas M. Sutter,Ece Ozkan,Julia E. Vogt*

Main category: eess.IV

TL;DR: 本研究利用多视图变分自编码器（VAE）对超声心动图视频进行分析，实现了新生儿肺动脉高压（PH）的准确预测，相比传统单视图和监督学习方法，表现出更强的泛化能力和分类精度。


<details>
  <summary>Details</summary>
Motivation: 新生儿肺动脉高压是一种危急状况，虽然超声心动图因其非侵入性而优于右心导管检查，但其诊断准确性高度依赖操作者，导致评估主观性强。现有自动化方法多针对成人或依赖单视图，在新生儿PH诊断中表现受限，且多视图模型存在泛化能力不足的问题。因此，需要开发一种更客观、鲁棒的新生儿PH评估方法。

Method: 本研究采用多视图变分自编码器（VAE）模型，利用超声心动图视频进行肺动脉高压预测。该模型旨在通过捕获复杂的潜在表示来提升特征提取和鲁棒性。研究将该模型的性能与单视图方法和监督学习方法进行了比较。

Result: 研究结果表明，所提出的多视图VAE模型在新生儿肺动脉高压评估中，显著提升了泛化能力和分类准确性。

Conclusion: 多视图学习，特别是结合VAE框架处理超声心动图视频，是实现新生儿肺动脉高压鲁棒且准确评估的有效方法。

Abstract: Pulmonary hypertension (PH) in newborns is a critical condition characterized
by elevated pressure in the pulmonary arteries, leading to right ventricular
strain and heart failure. While right heart catheterization (RHC) is the
diagnostic gold standard, echocardiography is preferred due to its non-invasive
nature, safety, and accessibility. However, its accuracy highly depends on the
operator, making PH assessment subjective. While automated detection methods
have been explored, most models focus on adults and rely on single-view
echocardiographic frames, limiting their performance in diagnosing PH in
newborns. While multi-view echocardiography has shown promise in improving PH
assessment, existing models struggle with generalizability. In this work, we
employ a multi-view variational autoencoder (VAE) for PH prediction using
echocardiographic videos. By leveraging the VAE framework, our model captures
complex latent representations, improving feature extraction and robustness. We
compare its performance against single-view and supervised learning approaches.
Our results show improved generalization and classification accuracy,
highlighting the effectiveness of multi-view learning for robust PH assessment
in newborns.

</details>


### [218] [Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?](https://arxiv.org/abs/2507.11569)
*Hanxue Gu,Yaqian Chen,Nicholas Konz,Qihang Li,Maciej A. Mazurowski*

Main category: eess.IV

TL;DR: 本研究全面评估了基础模型在乳腺MRI图像配准中的性能，发现它们在整体对齐方面优于传统方法，但在精细组织细节和医学领域特定预训练方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 基础模型在零样本图像配准中展现潜力，但其在处理如乳腺MRI这类复杂、高度可变形解剖结构上的性能尚不明确。乳腺MRI配准因其显著的解剖变异、体位变形及复杂的腺体组织而极具挑战性，亟需评估基础模型能否应对此类复杂性。

Method: 本研究对五种预训练编码器（DINO-v2, SAM, MedSAM, SSLSAM, MedCLIP）进行了全面评估，将其应用于四个关键的乳腺配准任务，这些任务涵盖了不同年份、序列、模态以及患者疾病状态（有/无病灶）下的图像变异。

Result: 研究结果表明，基于基础模型的算法（如SAM）在乳腺整体对齐方面优于传统配准基线，尤其是在大域漂移情况下。然而，它们在捕获乳腺腺体组织的精细细节方面表现不佳。此外，在医学或乳腺特定图像上进行额外预训练或微调（如MedSAM和SSLSAM）未能提升配准性能，甚至在某些情况下有所下降。

Conclusion: 基础模型在乳腺MRI的全局配准方面表现出色，但在精细结构配准上仍有不足。医学领域特定的预训练并不总是能带来性能提升。未来的工作需要深入探究领域特定训练的影响，并开发能同时提升全局和精细结构配准精度的策略。

Abstract: Foundation models, pre-trained on large image datasets and capable of
capturing rich feature representations, have recently shown potential for
zero-shot image registration. However, their performance has mostly been tested
in the context of rigid or less complex structures, such as the brain or
abdominal organs, and it remains unclear whether these models can handle more
challenging, deformable anatomy. Breast MRI registration is particularly
difficult due to significant anatomical variation between patients, deformation
caused by patient positioning, and the presence of thin and complex internal
structure of fibroglandular tissue, where accurate alignment is crucial.
Whether foundation model-based registration algorithms can address this level
of complexity remains an open question. In this study, we provide a
comprehensive evaluation of foundation model-based registration algorithms for
breast MRI. We assess five pre-trained encoders, including DINO-v2, SAM,
MedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that
capture variations in different years and dates, sequences, modalities, and
patient disease status (lesion versus no lesion). Our results show that
foundation model-based algorithms such as SAM outperform traditional
registration baselines for overall breast alignment, especially under large
domain shifts, but struggle with capturing fine details of fibroglandular
tissue. Interestingly, additional pre-training or fine-tuning on medical or
breast-specific images in MedSAM and SSLSAM, does not improve registration
performance and may even decrease it in some cases. Further work is needed to
understand how domain-specific training influences registration and to explore
targeted strategies that improve both global alignment and fine structure
accuracy. We also publicly release our code at
\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.

</details>


### [219] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 本研究利用无监督机器学习从肝脏磁共振图像中识别出量化的组织模式（“组织词汇”），可有效评估弥漫性肝病治疗反应，并预测活检特征。


<details>
  <summary>Details</summary>
Motivation: 量化疾病进展和治疗反应的影像模式对指导个体化治疗和开发新疗法至关重要，尤其是在弥漫性肝病领域。

Method: 采用深度聚类网络对医学图像（肝脏MRI）的图像块进行编码和聚类，构建低维潜在空间中的“组织词汇”。该方法在非酒精性脂肪性肝炎（NASH）患者的随机对照试验队列上进行应用，并在独立验证队列中进行验证。

Result: 该方法能够识别与治疗相关的特定肝脏组织变化路径，并比现有非影像学指标更好地区分治疗组。此外，“组织词汇”能够通过无创影像数据预测活检衍生的特征。

Conclusion: 所提出的无监督机器学习方法为量化弥漫性肝病的治疗反应提供了一种有效、无创的工具，其性能优于传统方法，并能预测重要的活检信息。

Abstract: Quantifiable image patterns associated with disease progression and treatment
response are critical tools for guiding individual treatment, and for
developing novel therapies. Here, we show that unsupervised machine learning
can identify a pattern vocabulary of liver tissue in magnetic resonance images
that quantifies treatment response in diffuse liver disease. Deep clustering
networks simultaneously encode and cluster patches of medical images into a
low-dimensional latent space to establish a tissue vocabulary. The resulting
tissue types capture differential tissue change and its location in the liver
associated with treatment response. We demonstrate the utility of the
vocabulary on a randomized controlled trial cohort of non-alcoholic
steatohepatitis patients. First, we use the vocabulary to compare longitudinal
liver change in a placebo and a treatment cohort. Results show that the method
identifies specific liver tissue change pathways associated with treatment, and
enables a better separation between treatment groups than established
non-imaging measures. Moreover, we show that the vocabulary can predict biopsy
derived features from non-invasive imaging data. We validate the method on a
separate replication cohort to demonstrate the applicability of the proposed
method.

</details>


### [220] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 本研究提出了一个多中心基准，用于在多发性硬化症的MRI中检测和分割皮质病变，通过改进的nnU-Net框架实现了良好的泛化能力，并分析了影响模型性能的因素，旨在推动其临床应用。


<details>
  <summary>Details</summary>
Motivation: 皮质病变（CLs）是多发性硬化症（MS）的重要生物标志物，但由于MRI表现不明显、专家标注困难以及缺乏标准化自动化方法，其常规临床整合受到限制。

Method: 研究提出了一个全面的多中心CL检测和分割基准，使用了来自四个机构的656例MRI扫描（包括临床试验和研究数据），通过3T和7T的MP2RAGE和MPRAGE序列获取，并有专家共识标注。依赖于自配置的nnU-Net框架，并针对CL检测进行了改进和适应。通过域外测试评估了模型泛化能力，并分析了模型内部特征和错误。

Result: 模型在域内（F1-score 0.64）和域外（F1-score 0.5）均表现出强大的病变检测能力。研究还分析了数据可变性、病变模糊性和协议差异如何影响模型性能。

Conclusion: 本研究分析了影响AI决策和模型性能的因素，并为克服临床应用障碍提出了未来建议。为增强研究可重复性，实现代码和模型将公开可用，有望促进CL检测的临床整合。

Abstract: Cortical lesions (CLs) have emerged as valuable biomarkers in multiple
sclerosis (MS), offering high diagnostic specificity and prognostic relevance.
However, their routine clinical integration remains limited due to subtle
magnetic resonance imaging (MRI) appearance, challenges in expert annotation,
and a lack of standardized automated methods. We propose a comprehensive
multi-centric benchmark of CL detection and segmentation in MRI. A total of 656
MRI scans, including clinical trial and research data from four institutions,
were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with
expert-consensus annotations. We rely on the self-configuring nnU-Net
framework, designed for medical imaging segmentation, and propose adaptations
tailored to the improved CL detection. We evaluated model generalization
through out-of-distribution testing, demonstrating strong lesion detection
capabilities with an F1-score of 0.64 and 0.5 in and out of the domain,
respectively. We also analyze internal model features and model errors for a
better understanding of AI decision-making. Our study examines how data
variability, lesion ambiguity, and protocol differences impact model
performance, offering future recommendations to address these barriers to
clinical adoption. To reinforce the reproducibility, the implementation and
models will be publicly accessible and ready to use at
https://github.com/Medical-Image-Analysis-Laboratory/ and
https://doi.org/10.5281/zenodo.15911797.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [221] [MOFCO: Mobility- and Migration-Aware Task Offloading in Three-Layer Fog Computing Environments](https://arxiv.org/abs/2507.12028)
*Soheil Mahdizadeh,Elyas Oustad,Mohsen Ansari*

Main category: cs.AR

TL;DR: 本文提出MOFCO算法，通过启发式演化博弈论解决雾计算中用户移动性导致的任务卸载和资源分配问题，显著降低系统成本。


<details>
  <summary>Details</summary>
Motivation: 在三层雾计算环境中，用户设备移动性导致任务卸载面临严峻挑战，频繁触发高成本服务迁移并降低系统整体性能。

Method: 提出MOFCO算法，将任务卸载与资源分配建模为混合整数非线性规划（MINLP）问题，并采用启发式辅助的演化博弈理论方法高效求解。使用SUMO模拟移动用户进行评估。

Result: 实验结果表明，MOFCO将系统成本（延迟和能耗的组合）平均降低19%，在某些场景下最高可达43%，优于现有先进方法。

Conclusion: MOFCO算法有效解决了雾计算环境中用户移动性带来的任务卸载挑战，显著降低了系统成本，提升了性能。

Abstract: Task offloading in three-layer fog computing environments presents a critical
challenge due to user equipment (UE) mobility, which frequently triggers costly
service migrations and degrades overall system performance. This paper
addresses this problem by proposing MOFCO, a novel Mobility- and
Migration-aware Task Offloading algorithm for Fog Computing environments. The
proposed method formulates task offloading and resource allocation as a
Mixed-Integer Nonlinear Programming (MINLP) problem and employs a
heuristic-aided evolutionary game theory approach to solve it efficiently. To
evaluate MOFCO, we simulate mobile users using SUMO, providing realistic
mobility patterns. Experimental results show that MOFCO reduces system cost,
defined as a combination of latency and energy consumption, by an average of
19% and up to 43% in certain scenarios compared to state-of-the-art methods.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [222] [Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions](https://arxiv.org/abs/2507.11783)
*Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah*

Main category: eess.SP

TL;DR: 对第一代EEG基础模型（EEG-FMs）的系统综述，分析其常用方法、评估局限性，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的监督式EEG编码器在学习鲁棒模式和对昂贵标注的依赖性方面存在局限，促使了自监督EEG基础模型（EEG-FMs）的兴起。然而，早期EEG-FMs的实际应用前景和长期研究进展路线尚不明确，因此需要系统性综述以厘清现状和未来发展方向。

Method: 本研究综述了10个早期EEG基础模型（EEG-FMs），并对其方法论、实证发现和现有研究空白进行了批判性综合分析。

Result: 大多数EEG-FMs采用基于序列的建模方案，依赖Transformer骨干网络和掩码序列重建进行自监督。然而，模型评估方式异质且普遍有限，使得评估其实际开箱即用效用变得困难。

Conclusion: 未来的研究应采用标准化和现实的评估方法，展示更显著的规模效应，并在EEG表示学习过程中做出审慎且可靠的选择。与领域专家合作开发基准、软件工具、技术方法和应用，将有助于提升EEG-FMs的转化效用和实际应用。

Abstract: Patterns of electrical brain activity recorded via electroencephalography
(EEG) offer immense value for scientific and clinical investigations. The
inability of supervised EEG encoders to learn robust EEG patterns and their
over-reliance on expensive signal annotations have sparked a transition towards
general-purpose self-supervised EEG encoders, i.e., EEG foundation models
(EEG-FMs), for robust and scalable EEG feature extraction. However, the
real-world readiness of early EEG-FMs and the rubric for long-term research
progress remain unclear. A systematic and comprehensive review of
first-generation EEG-FMs is therefore necessary to understand the current
state-of-the-art and identify key directions for future EEG-FMs. To that end,
this study reviews 10 early EEG-FMs and presents a critical synthesis of their
methodology, empirical findings, and outstanding research gaps. We find that
most EEG-FMs adopt a sequence-based modeling scheme that relies on
transformer-based backbones and the reconstruction of masked sequences for
self-supervision. However, model evaluations remain heterogeneous and largely
limited, making it challenging to assess their practical off-the-shelf utility.
In addition to adopting standardized and realistic evaluations, future work
should demonstrate more substantial scaling effects and make principled and
trustworthy choices throughout the EEG representation learning pipeline. We
believe that developing benchmarks, software tools, technical methodologies,
and applications in collaboration with domain experts may further advance the
translational utility and real-world adoption of EEG-FMs.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [223] [RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection](https://arxiv.org/abs/2507.12175)
*Sungkyun Chang,Simon Dixon,Emmanouil Benetos*

Main category: cs.SD

TL;DR: RUMAA是一个统一的、基于Transformer的音乐表演分析框架，它整合了乐谱对齐、乐谱辅助转录和错误检测，尤其在处理带重复的乐谱对齐方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音乐表演分析任务（如乐谱对齐、转录、错误检测）通常独立处理，缺乏统一性；传统MIDI方法在处理带重复符号的乐谱时，需要手动展开数据，效率低下且受限。

Method: RUMAA是一个基于Transformer的框架，采用预训练的乐谱和音频编码器，以及一个新颖的三流解码器。它通过代理任务（proxy tasks）捕获任务间依赖，实现带重复符号的MusicXML乐谱与完整表演音频的近乎端到端对齐。

Result: 在无重复乐谱的对齐任务上，RUMAA表现与最先进方法持平；在带重复的乐谱上，它在公开钢琴音乐数据集中超越了现有对齐方法；同时，在转录和错误检测方面也取得了有前景的结果。

Conclusion: RUMAA成功将音乐表演分析中的多项核心任务整合到一个统一框架中，有效解决了带重复乐谱的对齐挑战，并展现出在转录和错误检测方面的潜力，克服了传统方法的局限。

Abstract: This study introduces RUMAA, a transformer-based framework for music
performance analysis that unifies score-to-performance alignment,
score-informed transcription, and mistake detection in a near end-to-end
manner. Unlike prior methods addressing these tasks separately, RUMAA
integrates them using pre-trained score and audio encoders and a novel
tri-stream decoder capturing task interdependencies through proxy tasks. It
aligns human-readable MusicXML scores with repeat symbols to full-length
performance audio, overcoming traditional MIDI-based methods that rely on
manually unfolded score-MIDI data with pre-specified repeat structures. RUMAA
matches state-of-the-art alignment methods on non-repeated scores and
outperforms them on scores with repeats in a public piano music dataset, while
also delivering promising transcription and mistake detection results.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [224] [Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](https://arxiv.org/abs/2507.11630)
*Brendan Murphy,Dillon Bowen,Shahrad Mohammadzadeh,Julius Broomfield,Adam Gleave,Kellin Pelrine*

Main category: cs.CR

TL;DR: 研究表明，通过微调，可将AI模型转化为能高质量响应各种有害请求的“越狱”版本，如OpenAI、Google和Anthropic的模型，并且新模型似乎更易受攻击。迫切需要开发防篡改的安全防护措施。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能力快速提升，开发者普遍认识到需防范滥用。然而，现有安全措施易被绕过，且微调是否能轻易生成有害输出尚不明确。本研究旨在证明微调可轻松移除安全防护，并揭示其潜在危害，强调对更强安全措施的迫切需求。

Method: 本研究提出了一种“越狱微调”（jailbreak-tuning）方法，通过开放权重或闭源微调API，训练模型对任意有害请求生成详细、高质量的响应。研究对OpenAI、Google和Anthropic的模型进行了测试，并探讨了后门和更强越狱提示对攻击效果的影响。

Result: 结果显示，微调能够使模型完全遵循有害请求，例如提供CBRN援助、执行网络攻击或其他犯罪活动，且输出质量高。与现有工作不同，本方法能绕过现代审核系统。此外，后门可增加攻击的隐蔽性和严重性，更强的越狱提示在微调攻击中更有效。值得注意的是，较新的模型似乎对这些攻击表现出更高的脆弱性。

Conclusion: 结论是，迫切需要开发防篡改的安全防护措施，以应对AI模型的滥用风险。在此类防护措施发现之前，公司和政策制定者应将任何可微调模型的发布视为同时发布其“邪恶双胞胎”：能力与原始模型相同，但可用于其能力范围内的任何恶意目的。

Abstract: AI systems are rapidly advancing in capability, and frontier model developers
broadly acknowledge the need for safeguards against serious misuse. However,
this paper demonstrates that fine-tuning, whether via open weights or closed
fine-tuning APIs, can produce helpful-only models. In contrast to prior work
which is blocked by modern moderation systems or achieved only partial removal
of safeguards or degraded output quality, our jailbreak-tuning method teaches
models to generate detailed, high-quality responses to arbitrary harmful
requests. For example, OpenAI, Google, and Anthropic models will fully comply
with requests for CBRN assistance, executing cyberattacks, and other criminal
activity. We further show that backdoors can increase not only the stealth but
also the severity of attacks, while stronger jailbreak prompts become even more
effective in fine-tuning attacks, linking attack and potentially defenses in
the input and weight spaces. Not only are these models vulnerable, more recent
ones also appear to be becoming even more vulnerable to these attacks,
underscoring the urgent need for tamper-resistant safeguards. Until such
safeguards are discovered, companies and policymakers should view the release
of any fine-tunable model as simultaneously releasing its evil twin: equally
capable as the original model, and usable for any malicious purpose within its
capabilities.

</details>


### [225] [Challenges in GenAI and Authentication: a scoping review](https://arxiv.org/abs/2507.11775)
*Wesley dos Reis Bezerra,Lais Machado Bezerra,Carlos Becker Westphall*

Main category: cs.CR

TL;DR: 本研究对88篇文献进行了范围综述，分析了生成式AI背景下鉴权和真实性所面临的安全挑战，重点揭示了图像、文本、音频和视频领域的现有问题与研究空白。


<details>
  <summary>Details</summary>
Motivation: 数字信息共享中的鉴权和真实性是长期存在的安全挑战。随着生成式人工智能的进步，这些挑战日益复杂，需要对它们对社会及系统安全的影响进行及时、深入的分析。

Method: 采用范围综述方法，分析了来自IEEExplorer、Scopus和ACM数据库的88篇文献。通过六个指导性问题（包括相关工作、挑战、攻击面、威胁、解决方案和空白）对文献组合进行评估，并辅以个体化分析。

Result: 研究结果一致揭示了与图像、文本、音频和视频相关的鉴权和真实性方面的挑战、研究空白和潜在威胁。

Conclusion: 本研究为鉴权和生成式人工智能领域的新研究提供了有力的支持和方向指引。

Abstract: Authentication and authenticity have been a security challenge since the
beginning of information sharing, especially in the context of digital
information. With the advancement of generative artificial intelligence, these
challenges have evolved, demanding a more up-to-date analysis of their impacts
on society and system security. This work presents a scoping review that
analyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,
promoting an analysis of the resulting portfolio through six guiding questions
focusing on the most relevant work, challenges, attack surfaces, threats,
proposed solutions, and gaps. Finally, the portfolio articles are analyzed
through this guiding research lens and also receive individualized analysis.
The results consistently outline the challenges, gaps, and threats related to
images, text, audio, and video, thereby supporting new research in the areas of
authentication and generative artificial intelligence.

</details>


### [226] [Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification](https://arxiv.org/abs/2507.11943)
*Haiwei Lin,Shoko Imaizumi,Hitoshi Kiya*

Main category: cs.CR

TL;DR: 提出一种改进的低秩自适应方法，用于高效训练隐私保护ViT模型，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 旨在高效训练隐私保护的视觉Transformer (ViT) 模型，通过冻结预训练权重来减少参数。

Method: 提出一种低秩自适应方法，其特点是在ViT的每一层注入可训练的秩分解矩阵，并且与传统方法不同，不冻结patch嵌入层。

Result: 该方法成功减少了可训练参数的数量，同时保持了与全量微调（full-time tuning）几乎相同的准确性。

Conclusion: 所提出的低秩自适应方法为隐私保护ViT模型的训练提供了一种高效且性能优异的参数适应方案。

Abstract: We propose a low-rank adaptation method for training privacy-preserving
vision transformer (ViT) models that efficiently freezes pre-trained ViT model
weights. In the proposed method, trainable rank decomposition matrices are
injected into each layer of the ViT architecture, and moreover, the patch
embedding layer is not frozen, unlike in the case of the conventional low-rank
adaptation methods. The proposed method allows us not only to reduce the number
of trainable parameters but to also maintain almost the same accuracy as that
of full-time tuning.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [227] [JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs](https://arxiv.org/abs/2507.11636)
*Junyi Fan,Donald Williamson*

Main category: eess.AS

TL;DR: 提出JSQA框架，通过感知引导对比学习预训练音频编码器，然后微调进行语音质量评估（SQA），显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 语音质量评估（SQA）中将高维输入映射到MOS分数面临MOS高方差的挑战，且现有许多方法未能充分融入感知因素，导致结果不尽理想。

Method: 提出JSQA双阶段框架：首先，利用在“刚好可察觉差异”（JND）对上进行的感知引导对比学习预训练音频编码器，JND对通过LibriSpeech语音与CHiME-3噪声在不同信噪比下混合生成；然后，使用NISQA数据集对该编码器进行微调以预测MOS。

Result: 实验结果表明，感知启发式对比预训练显著提高了模型的SQA性能，优于未经预训练从头开始训练的相同网络。

Conclusion: 将感知因素融入预训练对提高语音质量评估（SQA）性能有巨大贡献。

Abstract: Speech quality assessment (SQA) is often used to learn a mapping from a
high-dimensional input space to a scalar that represents the mean opinion score
(MOS) of the perceptual speech quality. Learning such a mapping is challenging
for many reasons, but largely because MOS exhibits high levels of inherent
variance due to perceptual and experimental-design differences. Many solutions
have been proposed, but many approaches do not properly incorporate perceptual
factors into their learning algorithms (beyond the MOS label), which could lead
to unsatisfactory results. To this end, we propose JSQA, a two-stage framework
that pretrains an audio encoder using perceptually-guided contrastive learning
on just noticeable difference (JND) pairs, followed by fine-tuning for MOS
prediction. We first generate pairs of audio data within JND levels, which are
then used to pretrain an encoder to leverage perceptual quality similarity
information and map it into an embedding space. The JND pairs come from clean
LibriSpeech utterances that are mixed with background noise from CHiME-3, at
different signal-to-noise ratios (SNRs). The encoder is later fine-tuned with
audio samples from the NISQA dataset for MOS prediction. Experimental results
suggest that perceptually-inspired contrastive pretraining significantly
improves the model performance evaluated by various metrics when compared
against the same network trained from scratch without pretraining. These
findings suggest that incorporating perceptual factors into pretraining greatly
contributes to the improvement in performance for SQA.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [228] [The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist](https://arxiv.org/abs/2507.11810)
*Haoxuan Zhang,Ruochi Li,Yang Zhang,Ting Xiao,Jiangping Chen,Junhua Ding,Haihua Chen*

Main category: cs.DL

TL;DR: 本调查提出一个涵盖“评估者”、“协作者”和“科学家”三个层级的综合框架，系统分析大语言模型（LLMs）在科学创新中的演变角色及其深远影响，超越了传统工具的范畴。


<details>
  <summary>Details</summary>
Motivation: 科学面临信息过载、学科孤立及传统研究方法回报递减等挑战；现有研究未能充分阐明大语言模型（LLMs）在科学创新中的变革潜力及角色分化。

Method: 提出一个将LLMs在科学创新中的角色划分为“评估者”、“协作者”和“科学家”三个层级的综合框架；区分LLMs在结构化科学研究过程和开放式科学发现中的贡献；通过广泛分析现有方法、基准、系统和评估指标，进行深入系统的综合。

Result: 提供了一个统一的分类法，阐明了各层级的能力边界、评估标准和人机交互模式；深入系统地综合了LLM驱动的科学创新；将LLMs定义为重塑科学认识论基础的催化剂，而非仅仅是自动化工具；为未来研究提供了概念清晰度、实践指导和理论基础。

Conclusion: 大语言模型正在推动科学创新范式转变，并有望成为重塑科学认识论基础的催化剂。本调查为理解其多方面作用提供了清晰框架和指导，并强调了未来AI驱动科学的开放挑战和伦理考量。

Abstract: Scientific innovation is undergoing a paradigm shift driven by the rapid
advancement of Large Language Models (LLMs). As science faces mounting
challenges including information overload, disciplinary silos, and diminishing
returns on conventional research methods, LLMs are emerging as powerful agents
capable not only of enhancing scientific workflows but also of participating in
and potentially leading the innovation process. Existing surveys mainly focus
on different perspectives, phrases, and tasks in scientific research and
discovery, while they have limitations in understanding the transformative
potential and role differentiation of LLM. This survey proposes a comprehensive
framework to categorize the evolving roles of LLMs in scientific innovation
across three hierarchical levels: Evaluator, Collaborator, and Scientist. We
distinguish between LLMs' contributions to structured scientific research
processes and open-ended scientific discovery, thereby offering a unified
taxonomy that clarifies capability boundaries, evaluation criteria, and
human-AI interaction patterns at each level. Through an extensive analysis of
current methodologies, benchmarks, systems, and evaluation metrics, this survey
delivers an in-depth and systematic synthesis on LLM-driven scientific
innovation. We present LLMs not only as tools for automating existing
processes, but also as catalysts capable of reshaping the epistemological
foundations of science itself. This survey offers conceptual clarity, practical
guidance, and theoretical foundations for future research, while also
highlighting open challenges and ethical considerations in the pursuit of
increasingly autonomous AI-driven science. Resources related to this survey can
be accessed on GitHub at: https://github.com/haoxuan-unt2024/llm4innovation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [229] [Extremal Testing for Network Software using LLMs](https://arxiv.org/abs/2507.11898)
*Rathin Singha,Harry Qian,Srinath Saikrishnan,Tracy Zhao,Ryan Beckett,Siva Kesava Reddy Kakarla,George Varghese*

Main category: cs.SE

TL;DR: 利用大型语言模型自动化网络软件的极端测试，通过生成输入约束和违反约束的测试用例，成功发现新错误，超越了传统边界值分析。


<details>
  <summary>Details</summary>
Motivation: 物理学家在理论测试中常手动进行耗时耗力的极端情况分析；现有软件测试技术在极端测试方面存在局限；旨在自动化网络软件的极端测试过程。

Method: 分两步使用LLMs：首先，要求LLM生成输入约束（如DNS名称长度限制）；其次，要求LLM生成违反这些约束的测试用例。该方法还可扩展到生成过滤代码以及未来结合智能体AI。

Result: 成功为HTTP、BGP和DNS实现生成了极端测试用例，并发现了新的错误。该方法可扩展到集中式网络软件（如最短路径算法），并且LLM能生成用于拒绝极端输入的过滤代码。

Conclusion: LLM-生成的极端测试是一种有效且自动化的新方法，能够发现新错误并超越传统的边界值分析技术，未来可通过智能体AI进一步提高自动化程度。

Abstract: Physicists often manually consider extreme cases when testing a theory. In
this paper, we show how to automate extremal testing of network software using
LLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS
name length limits); then ask the LLM to generate tests that violate the
constraints. We demonstrate how easy this process is by generating extremal
tests for HTTP, BGP and DNS implementations, each of which uncovered new bugs.
We show how this methodology extends to centralized network software such as
shortest path algorithms, and how LLMs can generate filtering code to reject
extremal input. We propose using agentic AI to further automate extremal
testing. LLM-generated extremal testing goes beyond an old technique in
software testing called Boundary Value Analysis.

</details>


### [230] [MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization](https://arxiv.org/abs/2507.11687)
*Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose*

Main category: cs.SE

TL;DR: MetaLint是一个基于指令遵循的框架，通过在合成数据上进行指令微调，显著提升了大型语言模型（LLMs）在代码质量分析（特别是检测和修复代码缺陷）方面的泛化能力，使其能适应新的编码规范，并在评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在代码生成方面取得了成功，但它们在代码质量分析方面表现不佳，主要原因是受限于静态训练数据，难以适应不断演进的最佳实践和编码规范。

Method: 本文提出了MetaLint框架，将代码质量分析定义为基于高级规范检测和修复问题代码片段的任务。MetaLint采用在合成的linter生成数据上进行指令微调的方法，以实现从易到难的泛化，使模型无需再训练即可适应新颖或复杂的代码模式。研究者构建了一个受真实世界编码标准（如Python Enhancement Proposals, PEPs）启发的挑战性习语基准进行评估。

Result: 实验结果显示，MetaLint显著提升了对未见PEPs习语的泛化能力。在习语检测方面，其F-score达到70.37%，召回率在所有评估模型中最高（70.43%）。在定位方面，MetaLint（4B参数）取得了26.73%的得分，这与更大的最先进模型（如o3-mini）相比具有竞争力。

Conclusion: MetaLint展现了其在未来代码质量分析方面的巨大潜力，通过克服传统LLM在适应不断变化的编码标准方面的局限性，它能有效泛化到未见的代码模式，为代码质量分析提供了强大的、面向未来的解决方案。

Abstract: Large Language Models, though successful in code generation, struggle with
code quality analysis because they are limited by static training data and
can't easily adapt to evolving best practices. We introduce MetaLint, a new
instruction-following framework that formulates code quality analysis as the
task of detecting and fixing problematic semantic code fragments or code idioms
based on high-level specifications. Unlike conventional approaches that train
models on static, rule-based data, MetaLint employs instruction tuning on
synthetic linter-generated data to support easy-to-hard generalization,
enabling models to adapt to novel or complex code patterns without retraining.
To evaluate this, we construct a benchmark of challenging idioms inspired by
real-world coding standards such as Python Enhancement Proposals (PEPs) and
assess whether MetaLint-trained models reason adaptively or simply memorize.
Our results show that MetaLint improves generalization to unseen PEP idioms,
achieving a 70.37% F-score on idiom detection with the highest recall (70.43%)
among all evaluated models. It also achieves 26.73% on localization,
competitive for its 4B parameter size and comparable to larger state-of-the-art
models like o3-mini, highlighting its potential for future-proof code quality
analysis.

</details>


### [231] [MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks](https://arxiv.org/abs/2507.12284)
*Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova*

Main category: cs.SE

TL;DR: 现有LLM在软件工程中的评估不足，缺乏对代码质量和实际表现的关注。本文提出MERA Code，一个针对俄语代码生成LLM的新基准，包含11项任务和8种语言，旨在评估模型在非英语实践编码任务中的能力和局限性，并公开发布以指导未来研究和标准化评估。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型（LLMs）的评估主要集中于自然语言任务，忽视了代码质量、可执行性及在真实世界中的性能。大多数基准测试优先考虑高层推理而非可执行代码，导致对LLMs在生产环境中实际能力和潜在风险的理解存在空白。

Method: 为解决上述问题，研究者提出了MERA Code，作为MERA基准家族的新增成员，专注于评估最新的俄语代码生成LLMs。该基准包含11项评估任务，涵盖8种编程语言。其评估方法论包含一个实践编码技能分类体系。MERA Code由一个开源代码库、一个兼容多种编程环境的评分系统以及一个集成排行榜和提交系统的平台组成。

Result: 通过评估开放的LLMs和前沿的API模型，研究者分析了这些模型在非英语实践编码任务方面的局限性。

Conclusion: 研究者公开发布MERA Code，旨在指导未来的研究方向，预见模型开发中的创新特性，并标准化评估流程和程序。

Abstract: Advancements in LLMs have enhanced task automation in software engineering;
however, current evaluations primarily focus on natural language tasks,
overlooking code quality. Most benchmarks prioritize high-level reasoning over
executable code and real-world performance, leaving gaps in understanding true
capabilities and risks associated with these models in production. To address
this issue, we propose MERA Code, a new addition to the MERA benchmark family,
specifically focused on evaluating code for the latest code generation LLMs in
Russian. This benchmark includes 11 evaluation tasks that span 8 programming
languages. Our proposed evaluation methodology features a taxonomy that
outlines the practical coding skills necessary for models to complete these
tasks. The benchmark comprises an open-source codebase for users to conduct
MERA assessments, a scoring system compatible with various programming
environments, and a platform featuring a leaderboard and submission system. We
evaluate open LLMs and frontier API models, analyzing their limitations in
terms of practical coding tasks in non-English languages. We are publicly
releasing MERA to guide future research, anticipate groundbreaking features in
model development, and standardize evaluation procedures.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [232] [Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker](https://arxiv.org/abs/2507.12378)
*Rachna Saxena,Abhijeet Kumar,Suresh Shanmugam*

Main category: cs.IR

TL;DR: 针对传统信息提取系统对图文信息处理不足及多模态大模型（MLLM）长上下文检索效率低等挑战，本文提出一种实用的多步检索方法，结合混合搜索和后期交互重排器，实现了可扩展且高效的视觉信息检索，并保持了性能质量，适用于企业生产系统。


<details>
  <summary>Details</summary>
Motivation: 传统信息提取系统无法处理信息图（如表格、图表、图像等视觉元素）。多模态大语言模型（MLLM）面临“大海捞针”问题，即长上下文或大量文档搜索空间效率低下。尽管后期交互机制在基于检索的视觉增强问答任务中表现出色，但其在RAG（检索增强生成）多模态问答中存在挑战：流行向量数据库不支持原生多向量检索；后期交互计算成本高，占用空间大；未利用近似邻居搜索索引方法进行提速。因此，需要一种可扩展且高效的视觉检索方法，同时不牺牲性能质量。

Method: 本文提出一种务实的多步自定义实现方法。首先，利用广泛采用的混合搜索（元数据与嵌入）和先进的后期交互重排器来检索最佳匹配页面。然后，将多模态大语言模型作为阅读器，从这些情境化的最佳匹配页面中生成答案。

Result: 实验结果表明，所提出的设计具有可扩展性（显著提速）和稳定性（不降低性能质量）。

Conclusion: 该方案可以作为企业生产系统使用。

Abstract: Traditional information extraction systems face challenges with text only
language models as it does not consider infographics (visual elements of
information) such as tables, charts, images etc. often used to convey complex
information to readers. Multimodal LLM (MLLM) face challenges of finding needle
in the haystack problem i.e., either longer context length or substantial
number of documents as search space. Late interaction mechanism over visual
language models has shown state of the art performance in retrieval-based
vision augmented Q&A tasks. There are yet few challenges using it for RAG based
multi-modal Q&A. Firstly, many popular and widely adopted vector databases do
not support native multi-vector retrieval. Secondly, late interaction requires
computation which inflates space footprint and can hinder enterprise adoption.
Lastly, the current state of late interaction mechanism does not leverage the
approximate neighbor search indexing methods for large speed ups in retrieval
process. This paper explores a pragmatic approach to make vision retrieval
process scalable and efficient without compromising on performance quality. We
propose multi-step custom implementation utilizing widely adopted hybrid search
(metadata & embedding) and state of the art late interaction re-ranker to
retrieve best matching pages. Finally, MLLM are prompted as reader to generate
answers from contextualized best matching pages. Through experiments, we
observe that the proposed design is scalable (significant speed up) and stable
(without degrading performance quality), hence can be used as production
systems at enterprises.

</details>


<div id='astro-ph.GA'></div>

# astro-ph.GA [[Back]](#toc)

### [233] [Galaxy image simplification using Generative AI](https://arxiv.org/abs/2507.11692)
*Sai Teja Erukude,Lior Shamir*

Main category: astro-ph.GA

TL;DR: 本文提出一种基于生成式AI的新方法，将海量星系图像简化并“骨架化”，以实现不受预定义类别限制的自动化、精确的星系形状分析。


<details>
  <summary>Details</summary>
Motivation: 现代数字巡天获取了数十亿张星系图像，但现有分析方法（常依赖预定义类别的机器学习标注）难以高效、准确地自动化处理如此庞大的数据量。

Method: 引入了一种基于生成式AI的星系图像分析新方法。该方法将星系图像自动简化并转换为“骨架化”形式，从而能够准确测量星系形状，并且分析不受特定预定义类别的限制。

Result: 该方法已应用于DESI Legacy Survey的125,000张星系图像，并成功生成了公开可用的简化图像目录。此方法实现了对星系形状的准确测量，且分析不再受限于预定义的分类。

Conclusion: 基于生成式AI的骨架化方法为大规模星系图像分析提供了一种高效自动化且不受预定义类别限制的解决方案，能够实现准确的星系形状测量。

Abstract: Modern digital sky surveys have been acquiring images of billions of
galaxies. While these images often provide sufficient details to analyze the
shape of the galaxies, accurate analysis of such high volumes of images
requires effective automation. Current solutions often rely on machine learning
annotation of the galaxy images based on a set of pre-defined classes. Here we
introduce a new approach to galaxy image analysis that is based on generative
AI. The method simplifies the galaxy images and automatically converts them
into a ``skeletonized" form. The simplified images allow accurate measurements
of the galaxy shapes and analysis that is not limited to a certain pre-defined
set of classes. We demonstrate the method by applying it to galaxy images
acquired by the DESI Legacy Survey. The code and data are publicly available.
The method was applied to 125,000 DESI Legacy Survey images, and the catalog of
the simplified images is publicly available.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [234] [Interactive Hybrid Rice Breeding with Parametric Dual Projection](https://arxiv.org/abs/2507.11848)
*Changjian Chen,Pengcheng Wang,Fei Lyu,Zhuo Tang,Li Yang,Long Wang,Yong Cai,Feng Yu,Kenli Li*

Main category: cs.HC

TL;DR: 本文提出了一种可视化分析方法，通过参数化双重投影促进交互式杂交水稻育种，以提高调控基因识别和杂交种选择的效率，弥补基因组预测的不足。


<details>
  <summary>Details</summary>
Motivation: 传统的杂交水稻育种耗时耗力，尽管基因组选择能预测性状并减少田间工作量，但其预测模型精度有限，育种人员仍需结合经验手动识别调控基因和选择杂交种，这一过程依然耗时，因此需要一种方法来简化此过程。

Method: 提出了一种可视化分析方法以实现交互式杂交水稻育种。核心方法是开发了一个具有理论保证的参数化双重投影方法，以促进调控基因识别和杂交种选择这两种自然结合的双重分析任务。在此基础上，进一步开发了基因可视化和杂交种可视化工具，用于验证识别出的调控基因和杂交种。

Result: 该方法的有效性通过参数化双重投影方法的定量评估、案例研究中调控基因和期望杂交种的成功识别，以及育种专家积极的反馈得到了证明。

Conclusion: 所提出的可视化分析方法，特别是参数化双重投影方法，有效促进了交互式杂交水稻育种，通过提高调控基因的识别和期望杂交种的选择效率，解决了基因组预测的局限性，并获得了育种专家的积极评价。

Abstract: Hybrid rice breeding crossbreeds different rice lines and cultivates the
resulting hybrids in fields to select those with desirable agronomic traits,
such as higher yields. Recently, genomic selection has emerged as an efficient
way for hybrid rice breeding. It predicts the traits of hybrids based on their
genes, which helps exclude many undesired hybrids, largely reducing the
workload of field cultivation. However, due to the limited accuracy of genomic
prediction models, breeders still need to combine their experience with the
models to identify regulatory genes that control traits and select hybrids,
which remains a time-consuming process. To ease this process, in this paper, we
proposed a visual analysis method to facilitate interactive hybrid rice
breeding. Regulatory gene identification and hybrid selection naturally
ensemble a dual-analysis task. Therefore, we developed a parametric dual
projection method with theoretical guarantees to facilitate interactive dual
analysis. Based on this dual projection method, we further developed a gene
visualization and a hybrid visualization to verify the identified regulatory
genes and hybrids. The effectiveness of our method is demonstrated through the
quantitative evaluation of the parametric dual projection method, identified
regulatory genes and desired hybrids in the case study, and positive feedback
from breeders.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [235] [Formal Verification of Neural Certificates Done Dynamically](https://arxiv.org/abs/2507.11987)
*Thomas A. Henzinger,Konstantin Kueffner,Emily Yu*

Main category: cs.SC

TL;DR: 本文提出了一种轻量级运行时监控框架，用于对网络物理系统中的神经证书进行实时验证，以克服传统形式验证的可扩展性挑战，实现安全违规的及时检测。


<details>
  <summary>Details</summary>
Motivation: 传统上对网络物理系统中神经证书的正式验证面临可扩展性挑战，原因在于需要详尽的状态空间探索。

Method: 提出了一种轻量级运行时监控框架。该框架在系统部署期间观察系统，并在有限的预测范围内对前瞻区域的证书进行即时验证以确保安全，且不需要访问底层控制策略。该方法以ReLU控制障碍函数为例进行了实例化。

Result: 该方法能够以及时检测安全违规和不正确的证书，且开销极小。

Conclusion: 所提出的运行时监控框架为神经证书的静态验证提供了一种有效但轻量级的替代方案，解决了可扩展性问题，同时确保了系统安全。

Abstract: Neural certificates have emerged as a powerful tool in cyber-physical systems
control, providing witnesses of correctness. These certificates, such as
barrier functions, often learned alongside control policies, once verified,
serve as mathematical proofs of system safety. However, traditional formal
verification of their defining conditions typically faces scalability
challenges due to exhaustive state-space exploration. To address this
challenge, we propose a lightweight runtime monitoring framework that
integrates real-time verification and does not require access to the underlying
control policy. Our monitor observes the system during deployment and performs
on-the-fly verification of the certificate over a lookahead region to ensure
safety within a finite prediction horizon. We instantiate this framework for
ReLU-based control barrier functions and demonstrate its practical
effectiveness in a case study. Our approach enables timely detection of safety
violations and incorrect certificates with minimal overhead, providing an
effective but lightweight alternative to the static verification of the
certificates.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [236] [SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics](https://arxiv.org/abs/2507.11588)
*Suyuan Zhao,Yizhen Luo,Ganbo Yang,Yan Zhong,Hao Zhou,Zaiqing Nie*

Main category: q-bio.GN

TL;DR: 本文提出SToFM，一个多尺度空间转录组基础模型，通过整合宏观、微观和基因尺度信息来处理ST数据，并构建了迄今最大的高分辨率ST语料库SToCorpus-88M用于预训练，在多项下游任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 空间转录组（ST）数据建模的挑战在于需要从组织切片中提取并整合宏观、微观和基因尺度的多尺度信息。

Method: 提出SToFM模型，该模型首先对ST切片进行多尺度信息提取，构建包含宏观、微观和基因信息的ST子切片；随后使用SE(2) Transformer从子切片中获取高质量细胞表示。此外，构建了SToCorpus-88M，目前最大的高分辨率空间转录组语料库用于预训练。

Result: SToFM在多种下游任务（如组织区域语义分割和细胞类型注释）中取得了出色的性能。

Conclusion: SToFM模型对ST数据展现出全面理解，有效解决了多尺度信息整合的挑战，并为ST数据分析提供了强大的基础模型。

Abstract: Spatial Transcriptomics (ST) technologies provide biologists with rich
insights into single-cell biology by preserving spatial context of cells.
Building foundational models for ST can significantly enhance the analysis of
vast and complex data sources, unlocking new perspectives on the intricacies of
biological tissues. However, modeling ST data is inherently challenging due to
the need to extract multi-scale information from tissue slices containing vast
numbers of cells. This process requires integrating macro-scale tissue
morphology, micro-scale cellular microenvironment, and gene-scale gene
expression profile. To address this challenge, we propose SToFM, a multi-scale
Spatial Transcriptomics Foundation Model. SToFM first performs multi-scale
information extraction on each ST slice, to construct a set of ST sub-slices
that aggregate macro-, micro- and gene-scale information. Then an SE(2)
Transformer is used to obtain high-quality cell representations from the
sub-slices. Additionally, we construct \textbf{SToCorpus-88M}, the largest
high-resolution spatial transcriptomics corpus for pretraining. SToFM achieves
outstanding performance on a variety of downstream tasks, such as tissue region
semantic segmentation and cell type annotation, demonstrating its comprehensive
understanding of ST data

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [237] [Emergent Heterogeneous Swarm Control Through Hebbian Learning](https://arxiv.org/abs/2507.11566)
*Fuda van Diggelen,Tugay Alperen Karagüzel,Andres Garcia Rincon,A. E. Eiben,Dario Floreano,Eliseo Ferrante*

Main category: cs.NE

TL;DR: 本文提出一种利用赫布学习（Hebbian learning）在群体机器人中自动实现异构性的新方法，该方法通过解决现有挑战显著提升了群体能力。


<details>
  <summary>Details</summary>
Motivation: 当前异构群体控制面临三大挑战：1) 难以将涌现现象归因于单个智能体的微观-宏观问题；2) 随着群体规模增大而产生的维度灾难；3) 优化异构群体所需的大量先验知识。本研究旨在通过引入赫布学习来解决这些问题。

Method: 引入并应用赫布学习作为群体机器人的一种新方法。赫布学习是一种受生物启发的神经网络自适应形式，仅依赖局部信息。研究通过基于群体层面行为演化赫布学习规则来实现异构控制。

Result: 研究表明，赫布学习能够使异构性自然涌现，进而导致群体层面的行为切换，并显著提升群体能力。此外，演化赫布学习规则在标准基准测试任务中，被证明是多智能体强化学习（MARL）的有效替代方案。

Conclusion: 赫布学习是实现群体机器人异构性的一种有效方法，它能够自然地产生多样性，从而提高群体性能，并有效解决异构控制中的关键挑战。

Abstract: In this paper, we introduce Hebbian learning as a novel method for swarm
robotics, enabling the automatic emergence of heterogeneity. Hebbian learning
presents a biologically inspired form of neural adaptation that solely relies
on local information. By doing so, we resolve several major challenges for
learning heterogeneous control: 1) Hebbian learning removes the complexity of
attributing emergent phenomena to single agents through local learning rules,
thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules
across all swarm members limit the number of parameters needed, mitigating the
curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian
learning rules based on swarm-level behaviour minimises the need for extensive
prior knowledge typically required for optimising heterogeneous swarms. This
work demonstrates that with Hebbian learning heterogeneity naturally emerges,
resulting in swarm-level behavioural switching and in significantly improved
swarm capabilities. It also demonstrates how the evolution of Hebbian learning
rules can be a valid alternative to Multi Agent Reinforcement Learning in
standard benchmarking tasks.

</details>


### [238] [Simulated Language Acquisition in a Biologically Realistic Model of the Brain](https://arxiv.org/abs/2507.11788)
*Daniel Mitropolsky,Christos Papadimitriou*

Main category: cs.NE

TL;DR: 研究提出一个基于神经科学六大基本原理的数学模型和神经拟态系统，可从空白状态学习语言的语义、语法和词序，并生成新颖句子。


<details>
  <summary>Details</summary>
Motivation: 尽管神经科学进展巨大，但对于神经元放电如何产生高级认知现象（如规划和语言）尚缺乏令人信服的解释。

Method: 引入一个包含六个神经科学基本原则（兴奋性神经元、脑区、随机突触、赫布可塑性、局部抑制、区域间抑制）的简单数学公式。基于此公式实现一个模拟神经拟态系统。

Result: 该系统能从零开始学习任何语言的词汇语义、句法角色（动词与名词）和词序，包括生成新句子的能力，仅通过接触少量该语言的有意义句子即可实现。

Conclusion: 该研究提供了一个基于基本神经科学原理的计算模型，展示了大脑如何从空白状态获得语言能力，并为未来的扩展和应用提供了可能性。

Abstract: Despite tremendous progress in neuroscience, we do not have a compelling
narrative for the precise way whereby the spiking of neurons in our brain
results in high-level cognitive phenomena such as planning and language. We
introduce a simple mathematical formulation of six basic and broadly accepted
principles of neuroscience: excitatory neurons, brain areas, random synapses,
Hebbian plasticity, local inhibition, and inter-area inhibition. We implement a
simulated neuromorphic system based on this formalism, which is capable of
basic language acquisition: Starting from a tabula rasa, the system learns, in
any language, the semantics of words, their syntactic role (verb versus noun),
and the word order of the language, including the ability to generate novel
sentences, through the exposure to a modest number of grounded sentences in the
same language. We discuss several possible extensions and implications of this
result.

</details>


### [239] [Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11751)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.NE

TL;DR: 综述大数据中利用遗传算法和差分进化算法进行语义文本相似性文档搜索的最新进展。


<details>
  <summary>Details</summary>
Motivation: 在海量数据中识别相似文档是一个重大挑战。随着计算能力和大数据的发展，深度神经网络和进化计算算法在此领域取得更大成功，因此需要对其进展进行探讨。

Method: 本文采用综述形式，重点探索基于语义文本相似性的文档搜索的最新进展，特别是聚焦于遗传算法和差分进化算法。

Result: 本综述将探索并呈现遗传算法和差分进化算法在语义文本相似性文档搜索方面的最新成就与进展。

Conclusion: 进化计算算法（如遗传算法和差分进化算法）在语义文本相似性文档搜索中取得了显著成功，本综述旨在为该领域提供全面的最新洞察。

Abstract: Identifying similar documents within extensive volumes of data poses a
significant challenge. To tackle this issue, researchers have developed a
variety of effective distributed computing techniques. With the advancement of
computing power and the rise of big data, deep neural networks and evolutionary
computing algorithms such as genetic algorithms and differential evolution
algorithms have achieved greater success. This survey will explore the most
recent advancements in the search for documents based on their semantic text
similarity, focusing on genetic and differential evolutionary computing
algorithms.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [240] [Counting Answer Sets of Disjunctive Answer Set Programs](https://arxiv.org/abs/2507.11655)
*Mohimenul Kabir,Supratik Chakraborty,Kuldeep S Meel*

Main category: cs.LO

TL;DR: SharpASP-SR是一个用于析取逻辑程序答案集计数的新框架，通过减法归约到投影命题模型计数，在具有大量答案集的实例上显著优于现有方法，其混合版本实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 答案集编程是知识表示和推理的强大范式，而答案集计数在概率推理等领域至关重要。尽管普通逻辑程序的计数器已有进展，但针对析取逻辑程序的实用计数器开发仍面临挑战。

Method: 提出了SharpASP-SR框架，通过将析取逻辑程序的答案集计数问题减法归约到投影命题模型计数。该方法引入了答案集的替代表征，以实现高效归约并确保中间表示为多项式大小。此外，开发了一种结合枚举技术和SharpASP-SR的混合计数方法。

Result: 通过广泛的实验评估，SharpASP-SR在具有大量答案集的实例上显著优于现有计数器。结合SharpASP-SR的混合计数方法在各类析取程序上实现了最先进的性能。

Conclusion: SharpASP-SR提供了一种有效且高效的析取逻辑程序答案集计数方法，尤其擅长处理大规模答案集实例。通过与枚举技术的结合，该方法在析取程序计数领域达到了顶尖水平。

Abstract: Answer Set Programming (ASP) provides a powerful declarative paradigm for
knowledge representation and reasoning. Recently, counting answer sets has
emerged as an important computational problem with applications in
probabilistic reasoning, network reliability analysis, and other domains. This
has motivated significant research into designing efficient ASP counters. While
substantial progress has been made for normal logic programs, the development
of practical counters for disjunctive logic programs remains challenging.
  We present SharpASP-SR, a novel framework for counting answer sets of
disjunctive logic programs based on subtractive reduction to projected
propositional model counting. Our approach introduces an alternative
characterization of answer sets that enables efficient reduction while ensuring
that intermediate representations remain of polynomial size. This allows
SharpASP-SR to leverage recent advances in projected model counting technology.
Through extensive experimental evaluation on diverse benchmarks, we demonstrate
that SharpASP-SR significantly outperforms existing counters on instances with
large answer set counts. Building on these results, we develop a hybrid
counting approach that combines enumeration techniques with SharpASP-SR to
achieve state-of-the-art performance across the full spectrum of disjunctive
programs.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [241] [A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment](https://arxiv.org/abs/2507.11543)
*Iman Reihanian,Yunfei Hou,Yu Chen,Yifei Zheng*

Main category: cs.CY

TL;DR: 该论文综述了生成式AI工具在计算机科学教育中的应用，探讨了其带来的机遇、挑战以及为实现成功整合所需的平衡方法。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI工具（如ChatGPT和Claude）在计算机科学教育中的应用情况，重点关注其准确性、真实性和评估方面，并识别其带来的挑战与机遇。

Method: 文献综述。

Result: 生成式AI工具在提高效率和支持学生创作性工作方面具有机遇，但也存在AI幻觉、错误传播、偏见以及AI辅助内容与学生原创内容界限模糊等挑战。应对这些问题，人类监督至关重要，建议采用结合AI与人工评估的混合评估模型，开发偏见检测框架，并提高学生和教育者的AI素养。

Conclusion: AI的成功整合需要平衡考虑伦理、教学和技术因素。未来研究可探索提高AI准确性、维护学术诚信以及开发兼顾创造性与精准性的自适应模型。

Abstract: This paper surveys the use of Generative AI tools, such as ChatGPT and
Claude, in computer science education, focusing on key aspects of accuracy,
authenticity, and assessment. Through a literature review, we highlight both
the challenges and opportunities these AI tools present. While Generative AI
improves efficiency and supports creative student work, it raises concerns such
as AI hallucinations, error propagation, bias, and blurred lines between
AI-assisted and student-authored content. Human oversight is crucial for
addressing these concerns. Existing literature recommends adopting hybrid
assessment models that combine AI with human evaluation, developing bias
detection frameworks, and promoting AI literacy for both students and
educators. Our findings suggest that the successful integration of AI requires
a balanced approach, considering ethical, pedagogical, and technical factors.
Future research may explore enhancing AI accuracy, preserving academic
integrity, and developing adaptive models that balance creativity with
precision.

</details>


### [242] [Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening](https://arxiv.org/abs/2507.11548)
*Kevin T Webster*

Main category: cs.CY

TL;DR: 生成式AI简历筛选工具存在偏见，且部分看似无偏见的工具实际缺乏核心能力，仅依赖表面关键词匹配。研究提出“中立幻觉”现象，并建议采用双重验证框架。


<details>
  <summary>Details</summary>
Motivation: 质疑生成式AI简历筛选工具是否真的无偏见且具备评估能力，以挑战其作为人类偏见替代品的假设。

Method: 通过对八个主要AI平台进行两部分审计实验：实验1评估上下文偏见，实验2评估核心评估能力。

Result: 实验1确认了复杂的种族和性别偏见。实验2发现，部分看似无偏见的模型实际上缺乏实质性评估能力，仅依赖表面关键词匹配，这种现象被定义为“中立幻觉”。

Conclusion: 建议组织和监管机构采纳“双重验证框架”，同时审计AI招聘工具的偏见和实际能力，以确保其公平性和有效性。

Abstract: The increasing use of generative AI for resume screening is predicated on the
assumption that it offers an unbiased alternative to biased human
decision-making. However, this belief fails to address a critical question: are
these AI systems fundamentally competent at the evaluative tasks they are meant
to perform? This study investigates the question of competence through a
two-part audit of eight major AI platforms. Experiment 1 confirmed complex,
contextual racial and gender biases, with some models penalizing candidates
merely for the presence of demographic signals. Experiment 2, which evaluated
core competence, provided a critical insight: some models that appeared
unbiased were, in fact, incapable of performing a substantive evaluation,
relying instead on superficial keyword matching. This paper introduces the
"Illusion of Neutrality" to describe this phenomenon, where an apparent lack of
bias is merely a symptom of a model's inability to make meaningful judgments.
This study recommends that organizations and regulators adopt a dual-validation
framework, auditing AI hiring tools for both demographic bias and demonstrable
competence to ensure they are both equitable and effective.

</details>


### [243] [AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce](https://arxiv.org/abs/2507.11597)
*Richard Timpone,Yongwei Yang*

Main category: cs.CY

TL;DR: 本文探讨AI在研究中的应用，警告“一键式自动化”的潜在风险，并强调人机协作以及数据科学家持续学习和理解方法的重要性。


<details>
  <summary>Details</summary>
Motivation: AI正在变革研究，提高效率和质量，但其有效性和伦理使用尚不明确。研究旨在评估AI在增强或取代人类分析师方面的潜力与局限性，并警惕因AI易用性可能带来的风险。

Method: 研究采用作者提出的“真相、美德、公正”（TBJ）框架来评估AI模型，并结合人机协作视角（Daugherty and Wilson 2018）分析数据科学工作流程。

Result: AI虽能辅助分析师，但“一键式自动化”存在风险，可能导致用户在不完全理解的情况下进行分析，带来比以往统计软件更大的问题。数据科学家在VUCA决策领域中扮演关键角色。

Conclusion: 论文倡导AI工具作为数据科学家的补充，而非替代。强调持续培训和对方法的理解，以确保研究成果的有效和伦理应用与解释，从而实现其实质价值。

Abstract: AI is transforming research. It is being leveraged to construct surveys,
synthesize data, conduct analysis, and write summaries of the results. While
the promise is to create efficiencies and increase quality, the reality is not
always as clear cut. Leveraging our framework of Truth, Beauty, and Justice
(TBJ) which we use to evaluate AI, machine learning and computational models
for effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024),
we consider the potential and limitation of analytic, generative, and agentic
AI to augment data scientists or take on tasks traditionally done by human
analysts and researchers. While AI can be leveraged to assist analysts in their
tasks, we raise some warnings about push-button automation. Just as earlier
eras of survey analysis created some issues when the increased ease of using
statistical software allowed researchers to conduct analyses they did not fully
understand, the new AI tools may create similar but larger risks. We emphasize
a human-machine collaboration perspective (Daugherty and Wilson 2018)
throughout the data science workflow and particularly call out the vital role
that data scientists play under VUCA decision areas. We conclude by encouraging
the advance of AI tools to complement data scientists but advocate for
continued training and understanding of methods to ensure the substantive value
of research is fully achieved by applying, interpreting, and acting upon
results most effectively and ethically.

</details>


### [244] [Small Data Explainer -- The impact of small data methods in everyday life](https://arxiv.org/abs/2507.11773)
*Maren Hackenberg,Sophia G. Connor,Fabian Kabus,June Brawner,Ella Markham,Mahi Hardalupas,Areeq Chowdhury,Rolf Backofen,Anna Köttgen,Angelika Rohde,Nadine Binder,Harald Binder,the Collaborative Research Center 1597 Small Data*

Main category: cs.CY

TL;DR: 本文探讨了在数据有限的“小数据”环境下，如何利用突破性人工智能技术，并提出了充分利用小数据的未来议程。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的发展，研究人员重新关注如何使小数据环境受益于这些进步，特别是解决将弱势群体纳入数据驱动决策、可穿戴设备健康效益等社会问题。

Method: 研究方法包括提供概念性概述（对比小数据与大数据），从案例研究和应用领域识别共同主题，以及详细技术概述现有数据分析和建模技术（整合统计学和计算机科学的贡献）。

Result: 通过关联应用场景、概念贡献和具体技术，本文揭示了利用AI处理小数据目前已实现的功能和可行性。

Conclusion: 研究提出了一个旨在充分利用小数据潜力的未来议程，以指导该领域的发展。

Abstract: The emergence of breakthrough artificial intelligence (AI) techniques has led
to a renewed focus on how small data settings, i.e., settings with limited
information, can benefit from such developments. This includes societal issues
such as how best to include under-represented groups in data-driven policy and
decision making, or the health benefits of assistive technologies such as
wearables. We provide a conceptual overview, in particular contrasting small
data with big data, and identify common themes from exemplary case studies and
application areas. Potential solutions are described in a more detailed
technical overview of current data analysis and modelling techniques,
highlighting contributions from different disciplines, such as knowledge-driven
modelling from statistics and data-driven modelling from computer science. By
linking application settings, conceptual contributions and specific techniques,
we highlight what is already feasible and suggest what an agenda for fully
leveraging small data might look like.

</details>


### [245] [The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models](https://arxiv.org/abs/2507.11544)
*Ann-Kathrin Dombrowski,Dillon Bowen,Adam Gleave,Chris Cundy*

Main category: cs.CY

TL;DR: 开放权重大模型（LLMs）的修改性带来安全风险，不良行为者可移除安全防护。本研究开源工具评估这种“安全鸿沟”，发现其随模型规模增大而加宽，且移除防护后危险能力显著增强，呼吁开发更强的防篡改安全措施。


<details>
  <summary>Details</summary>
Motivation: 开放权重大型语言模型虽然带来诸多益处，但其可修改性也导致系统性风险：不良行为者可以轻易移除模型内置的安全防护，将其转变为有害工具，从而产生一个巨大的“安全鸿沟”。亟需量化评估这一安全风险。

Method: 开发并开源了一个“安全鸿沟工具包”，用于估计最先进开放权重模型的安全鸿沟。作为案例研究，该研究评估了Llama-3和Qwen-2.5两个系列模型（0.5B至405B参数规模）的生化和网络危害能力、拒绝率和生成质量，并采用了不同的安全防护移除技术。

Result: 实验结果显示，模型的安全鸿沟随着规模的增大而加宽，并且当安全防护被移除时，其潜在的危险能力显著增强。

Conclusion: 所开发的“安全鸿沟工具包”可作为评估常见开放权重模型的框架，并希望借此激励开发和测试更具抗篡改性的安全防护措施。

Abstract: Open-weight large language models (LLMs) unlock huge benefits in innovation,
personalization, privacy, and democratization. However, their core advantage -
modifiability - opens the door to systemic risks: bad actors can trivially
subvert current safeguards, turning beneficial models into tools for harm. This
leads to a 'safety gap': the difference in dangerous capabilities between a
model with intact safeguards and one that has been stripped of those
safeguards. We open-source a toolkit to estimate the safety gap for
state-of-the-art open-weight models. As a case study, we evaluate biochemical
and cyber capabilities, refusal rates, and generation quality of models from
two families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to
405B) using different safeguard removal techniques. Our experiments reveal that
the safety gap widens as model scale increases and effective dangerous
capabilities grow substantially when safeguards are removed. We hope that the
Safety Gap Toolkit (https://github.com/AlignmentResearch/safety-gap) will serve
as an evaluation framework for common open-source models and as a motivation
for developing and testing tamper-resistant safeguards. We welcome
contributions to the toolkit from the community.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [246] [A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing](https://arxiv.org/abs/2507.11560)
*Xin Wang,Xiao Huan Li,Xun Wang*

Main category: cs.DC

TL;DR: 本文提出了一种针对IIoT边缘计算环境的AIGC任务卸载框架，首次考虑模型切换的延迟和能耗。通过基于多智能体深度确定性策略梯度（MADDPG-MATO）的算法，优化了IIoT设备的AIGC任务卸载，显著降低了延迟和能耗，提高了任务完成率。


<details>
  <summary>Details</summary>
Motivation: 工业物联网（IIoT）与人工智能生成内容（AIGC）的结合为智能制造带来机遇，但也引入了计算密集型和低延迟的挑战。传统的云端生成模型难以满足IIoT环境中AIGC任务的实时性要求，而边缘计算虽能通过任务卸载降低延迟，但AIGC任务的动态性、模型切换延迟和资源限制对边缘环境提出了更高要求。本研究旨在解决AIGC任务卸载中由模型切换引起的延迟和能耗问题。

Method: 本文提出了一个专为IIoT边缘计算环境设计的AIGC任务卸载框架，并首次考虑了AIGC模型切换造成的延迟和能耗。IIoT设备作为多智能体协作地将其动态AIGC任务卸载到部署有不同生成模型的最佳边缘服务器。为此，设计了一种基于多智能体深度确定性策略梯度（MADDPG-MATO）的模型感知AIGC任务卸载算法，以最小化延迟和能耗。

Result: 实验结果表明，MADDPG-MATO算法优于基线算法。在模型数量从3到6的四组实验中，该算法平均降低了6.98%的延迟、7.12%的能耗，并将任务完成率提高了3.72%。

Conclusion: 所提出的MADDPG-MATO算法在动态、高负载的IIoT环境中表现出鲁棒性和高效性，有效解决了AIGC任务卸载中的延迟和能耗问题，提升了任务完成率。

Abstract: The integration of the Industrial Internet of Things (IIoT) with Artificial
Intelligence-Generated Content (AIGC) offers new opportunities for smart
manufacturing, but it also introduces challenges related to
computation-intensive tasks and low-latency demands. Traditional generative
models based on cloud computing are difficult to meet the real-time
requirements of AIGC tasks in IIoT environments, and edge computing can
effectively reduce latency through task offloading. However, the dynamic nature
of AIGC tasks, model switching delays, and resource constraints impose higher
demands on edge computing environments. To address these challenges, this paper
proposes an AIGC task offloading framework tailored for IIoT edge computing
environments, considering the latency and energy consumption caused by AIGC
model switching for the first time. IIoT devices acted as multi-agent
collaboratively offload their dynamic AIGC tasks to the most appropriate edge
servers deployed with different generative models. A model aware AIGC task
offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient
(MADDPG-MATO) is devised to minimize the latency and energy. Experimental
results show that MADDPG-MATO outperforms baseline algorithms, achieving an
average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72%
increase in task completion rate across four sets of experiments with model
numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is
robust and efficient in dynamic, high-load IIoT environments.

</details>


### [247] [PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training](https://arxiv.org/abs/2507.11683)
*Seth Ockerman,Amal Gueroudji,Tanwi Mallick,Yixuan He,Line Pouchard,Robert Ross,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: 本文提出PyTorch Geometric Temporal Index (PGT-I) 框架及其创新的索引批处理策略，成功解决了时空图神经网络（ST-GNN）在大规模数据集上的内存限制和训练效率问题，实现了显著的内存优化和加速。


<details>
  <summary>Details</summary>
Motivation: 时空图神经网络（ST-GNNs）在建模时空数据依赖方面功能强大，但其应用受限于小规模数据集，主要原因是内存限制。现有的分布式训练框架缺乏对时空模型的支持，并忽视了时空数据的特性。

Method: 本文提出了PyTorch Geometric Temporal Index (PGT-I)，作为PyTorch Geometric Temporal的扩展，它整合了分布式数据并行训练和两种新型策略：索引批处理（index-batching）和分布式索引批处理（distributed-index-batching）。这些索引技术利用时空结构在运行时动态构建快照，以大幅减少内存开销。分布式索引批处理则将此方法扩展至多GPU的分布式可扩展处理。

Result: 通过这些技术，首次实现了在不进行图分区的情况下，对整个PeMS数据集进行ST-GNN训练。峰值内存使用量减少了高达89%，并且在使用128个GPU时，比标准DDP实现了高达13.1倍的加速。

Conclusion: PGT-I及其索引技术成功克服了ST-GNN在大规模数据集上的内存瓶颈，显著提升了训练效率和可扩展性，为ST-GNN的广泛应用铺平了道路。

Abstract: Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for
modeling spatial and temporal data dependencies. However, their applications
have been limited primarily to small-scale datasets because of memory
constraints. While distributed training offers a solution, current frameworks
lack support for spatiotemporal models and overlook the properties of
spatiotemporal data. Informed by a scaling study on a large-scale workload, we
present PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch
Geometric Temporal that integrates distributed data parallel training and two
novel strategies: index-batching and distributed-index-batching. Our index
techniques exploit spatiotemporal structure to construct snapshots dynamically
at runtime, significantly reducing memory overhead, while
distributed-index-batching extends this approach by enabling scalable
processing across multiple GPUs. Our techniques enable the first-ever training
of an ST-GNN on the entire PeMS dataset without graph partitioning, reducing
peak memory usage by up to 89\% and achieving up to a 13.1x speedup over
standard DDP with 128 GPUs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [248] [HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways](https://arxiv.org/abs/2507.11621)
*Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 本文提出了一种针对异构交通流（人驾车与自动驾驶车）的分层协同匝道汇入控制（HCOMC）框架，通过仿真验证其在提升安全性、效率和燃油经济性方面的显著优势。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道汇入区常导致交通拥堵和事故。尽管基于网联自动驾驶车辆（CAVs）的协同控制是根本解决方案，但考虑到CAVs尚未普及，有必要为包含人驾车（HDVs）和CAVs的异构交通流设计一种分层协同匝道汇入控制框架。

Method: 1. 扩展了基于智能驾驶模型的纵向跟驰模型和基于五次多项式曲线的横向换道模型，用于建模HDVs和CAVs，并综合考虑人因和协同自适应巡航控制。2. 提出了一个HCOMC框架，包括基于修正虚拟车辆模型的分层协同规划模型、基于博弈论的自由换道模型以及使用精英非支配排序遗传算法的多目标优化模型，旨在确保安全、平稳和高效的汇入过程。3. 通过仿真在不同交通密度和CAV渗透率下分析了HCOMC的性能。

Result: 仿真结果表明，与基准方案相比，所提出的HCOMC在提高车队安全性、稳定和加速汇入过程、优化交通效率以及节省燃油消耗方面具有显著的综合优势。

Conclusion: 该研究成功开发并验证了一个针对异构交通流的分层协同匝道汇入控制（HCOMC）框架，有效解决了匝道汇入区域的交通问题，并在安全性、效率和能耗方面表现出卓越性能，为未来的交通管理提供了可行方案。

Abstract: Highway on-ramp merging areas are common bottlenecks to traffic congestion
and accidents. Currently, a cooperative control strategy based on connected and
automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs
are not fully widespread, it is necessary to propose a hierarchical cooperative
on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on
two-lane highways to address this gap. This paper extends longitudinal
car-following models based on the intelligent driver model and lateral
lane-changing models using the quintic polynomial curve to account for
human-driven vehicles (HDVs) and CAVs, comprehensively considering human
factors and cooperative adaptive cruise control. Besides, this paper proposes a
HCOMC framework, consisting of a hierarchical cooperative planning model based
on the modified virtual vehicle model, a discretionary lane-changing model
based on game theory, and a multi-objective optimization model using the
elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and
efficient merging process. Then, the performance of our HCOMC is analyzed under
different traffic densities and CAV penetration rates through simulation. The
findings underscore our HCOMC's pronounced comprehensive advantages in
enhancing the safety of group vehicles, stabilizing and expediting merging
process, optimizing traffic efficiency, and economizing fuel consumption
compared with benchmarks.

</details>


### [249] [A Roadmap for Climate-Relevant Robotics Research](https://arxiv.org/abs/2507.11623)
*Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh*

Main category: cs.RO

TL;DR: 本文提出了一个气候相关机器人学研究路线图，旨在识别机器人学界与气候领域专家合作的高影响力机会，以应对气候变化。


<details>
  <summary>Details</summary>
Motivation: 气候变化是21世纪的重大挑战之一，机器人学界正积极寻求贡献。本研究旨在通过突出机器人学与气候交叉领域的具体、可操作问题，激发新的研究方向和合作。

Method: 通过识别机器人学家与能源、建筑环境、交通、工业、土地利用和地球科学等气候领域专家之间的高影响力合作机会来构建路线图。方法不仅包括物理机器人的应用，还涵盖规划、感知、控制和估计等更广泛的机器人工具包。

Result: 本研究提出了一个气候相关机器人学研究路线图，识别了包括能源系统优化、建筑、精准农业、建筑围护结构改造、自动驾驶卡车和大规模环境监测等具体的应用机会。

Conclusion: 本工作代表了机器人研究人员与气候领域专家之间的合作，旨在邀请机器人社区将其专业知识应用于紧迫的气候优先事项，以期共同应对气候挑战。

Abstract: Climate change is one of the defining challenges of the 21st century, and
many in the robotics community are looking for ways to contribute. This paper
presents a roadmap for climate-relevant robotics research, identifying
high-impact opportunities for collaboration between roboticists and experts
across climate domains such as energy, the built environment, transportation,
industry, land use, and Earth sciences. These applications include problems
such as energy systems optimization, construction, precision agriculture,
building envelope retrofits, autonomous trucking, and large-scale environmental
monitoring. Critically, we include opportunities to apply not only physical
robots but also the broader robotics toolkit - including planning, perception,
control, and estimation algorithms - to climate-relevant problems. A central
goal of this roadmap is to inspire new research directions and collaboration by
highlighting specific, actionable problems at the intersection of robotics and
climate. This work represents a collaboration between robotics researchers and
domain experts in various climate disciplines, and it serves as an invitation
to the robotics community to bring their expertise to bear on urgent climate
priorities.

</details>


### [250] [Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers](https://arxiv.org/abs/2507.11991)
*Juanran Wang,Marc R. Schlichting,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 本研究利用深度生成模型为自动驾驶车辆在交叉路口生成碰撞场景的传感器噪声序列，并将其蒸馏为单步模型以实现高效推理。该模型被应用于构建鲁棒规划器，通过仿真验证显著降低了故障率和延迟率。


<details>
  <summary>Details</summary>
Motivation: 交叉路口作为高风险交通区域，是导致自动驾驶车辆碰撞事故的主要原因。本研究旨在利用深度生成模型提升自动驾驶车辆在交叉路口环境中的安全性。

Method: 1. 训练一个1000步的去噪扩散概率模型（DDPM），根据入侵者的相对位置和速度，为自动驾驶车辆在四向交叉路口生成导致碰撞的传感器噪声序列。2. 利用生成对抗架构，将该1000步模型蒸馏成一个单步去噪扩散模型，在保持采样质量的同时显著提高推理速度。3. 将此单步模型应用于构建一个鲁棒的自动驾驶车辆规划器，该规划器能基于当前交通状态高效采样潜在的失败案例以辅助决策。

Result: 通过仿真实验，与基线智能驾驶模型（Intelligent Driver Model）控制器相比，所提出的鲁棒规划器表现出显著更低的故障率和延迟率。

Conclusion: 本研究成功开发并应用了基于生成式模型的鲁棒规划器，有效提高了自动驾驶车辆在复杂交叉路口环境中的安全性，并通过单步模型实现了高效推理，为自动驾驶系统的决策提供了有力支持。

Abstract: High-risk traffic zones such as intersections are a major cause of
collisions. This study leverages deep generative models to enhance the safety
of autonomous vehicles in an intersection context. We train a 1000-step
denoising diffusion probabilistic model to generate collision-causing sensor
noise sequences for an autonomous vehicle navigating a four-way intersection
based on the current relative position and velocity of an intruder. Using the
generative adversarial architecture, the 1000-step model is distilled into a
single-step denoising diffusion model which demonstrates fast inference speed
while maintaining similar sampling quality. We demonstrate one possible
application of the single-step model in building a robust planner for the
autonomous vehicle. The planner uses the single-step model to efficiently
sample potential failure cases based on the currently measured traffic state to
inform its decision-making. Through simulation experiments, the robust planner
demonstrates significantly lower failure rate and delay rate compared with the
baseline Intelligent Driver Model controller.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [251] [Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network](https://arxiv.org/abs/2507.11799)
*Shin-ichi Ito*

Main category: physics.comp-ph

TL;DR: 提出一种基于神经网络的求解器，可高效、准确地计算收缩诱导碎裂的积分微分方程。


<details>
  <summary>Details</summary>
Motivation: 传统的数值求解收缩诱导碎裂模型的积分微分方程计算成本高昂，需要一种能够显著降低计算成本的解决方案。

Method: 开发了一种基于神经网络（NN）的求解器，该方法直接将输入参数映射到概率密度函数，无需数值求解控制方程。

Result: 该方法显著降低了计算成本，并能在蒙特卡洛模拟中高效评估密度函数，其精度可与传统有限差分方案媲美甚至超越。在合成数据上的验证显示了其计算效率和预测可靠性。

Conclusion: 本研究为碎裂过程的数据驱动逆向分析奠定了基础，并展示了将该框架扩展到预设模型结构之外的潜力。

Abstract: This paper presents a neural network (NN)-based solver for an
integro-differential equation that models shrinkage-induced fragmentation. The
proposed method directly maps input parameters to the corresponding probability
density function without numerically solving the governing equation, thereby
significantly reducing computational costs. Specifically, it enables efficient
evaluation of the density function in Monte Carlo simulations while maintaining
accuracy comparable to or even exceeding that of conventional finite difference
schemes. Validatation on synthetic data demonstrates both the method's
computational efficiency and predictive reliability. This study establishes a
foundation for the data-driven inverse analysis of fragmentation and suggests
the potential for extending the framework beyond pre-specified model
structures.

</details>
