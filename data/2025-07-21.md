<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 44]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 45]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.AR](#cs.AR) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 本研究利用少量样本自适应语言提示（ALP）结合GPT-4o和Gemini 1.5 Pro等多模态大语言模型（LLMs），显著提升了网络钓鱼网页的检测准确性，实现了0.93的F1分数，超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 网络钓鱼攻击是重大的网络安全威胁，需要开发自适应的检测技术来有效应对其不断演变的形式。

Method: 本研究探索了少量样本自适应语言提示（ALP），通过利用GPT-4o和Gemini 1.5 Pro等先进大语言模型的多模态能力来检测网络钓鱼网页。ALP是一种结构化的语义推理方法，引导LLMs分析文本欺骗，具体方式包括分解语言模式、检测紧急提示和识别操纵性措辞。研究提出一个统一模型，通过整合文本、视觉和URL分析来识别复杂的网络钓鱼尝试。

Result: 实验证明，ALP通过结构化推理和上下文分析显著提升了网络钓鱼检测的准确性。该方法实现了0.93的F1分数，表现优于传统方法。

Conclusion: 研究结果为利用LLMs构建更强大、可解释和自适应的基于语言的网络钓鱼检测系统奠定了基础，并突出了ALP结合多模态LLMs在推进网络钓鱼检测框架方面的潜力。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [2] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: 一个名为PersonaGen的框架利用LLM通过多阶段角色条件生成情感丰富的文本，以解决情感识别中高质量数据集稀缺的问题，并在多样性、类人性和实用性方面表现出色，有望作为真实情感数据的替代或补充。


<details>
  <summary>Details</summary>
Motivation: 情感识别领域面临高性能模型开发挑战，核心在于高质量、多样化情感数据集的稀缺性。情感表达的主观性和收集的伦理/实践困难，使得获取大规模、可泛化数据极具挑战性。

Method: 引入PersonaGen框架，该框架利用大型语言模型（LLM）通过多阶段基于角色的条件作用生成情感丰富的文本。PersonaGen通过结合人口统计属性、社会文化背景和详细情境构建分层虚拟角色，以此指导情感表达生成。生成的合成数据通过语义多样性（聚类、分布度量）、类人性（LLM质量评分）、真实性（与真实语料库比较）和实用性（下游情感分类任务）进行全面评估。

Result: 实验结果显示，PersonaGen在生成多样化、连贯且具有辨识度的情感表达方面显著优于基线方法。

Conclusion: PersonaGen展现出作为一种强大的替代方案的潜力，可用于增强或取代真实世界的情感数据集，有效解决情感识别领域的数据稀缺问题。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [3] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT是一种结构感知微调方法，通过磁拉普拉斯位置编码将图拓扑注入预训练大语言模型，无需架构更改，并在AMR-to-text生成任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在处理图等结构化输入时面临挑战，现有方法要么任意线性化输入从而丢失关键结构信息，要么依赖与标准LLMs不兼容的架构。需要一种有效方法将图结构整合到LLMs中。

Method: 引入SAFT（结构感知微调）方法，在不改变预训练LLM架构的前提下注入图拓扑。具体做法是，从转换后的AMR的磁拉普拉斯中计算方向敏感的位置编码，并将其投影到LLM的嵌入空间中。该方法以AMR-to-text生成作为代表性基准进行验证。

Result: SAFT在AMR 3.0数据集上刷新了最先进水平，相较基线提升了3.5 BLEU分数。性能提升随图复杂度增加而更显著，突出了结构感知表示在提升LLM性能方面的价值。

Conclusion: SAFT为连接结构化数据和语言模型提供了一条通用且有效途径，证明了在LLMs中融入结构感知表示的重要性及其有效性。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [4] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 提出一种基于上下文图谱和异常检测算法的假新闻识别方法。


<details>
  <summary>Details</summary>
Motivation: 假新闻在数字世界中迅速传播，是一个需要迫切解决的重要问题。

Method: 研究采用包含真实和虚假新闻的Kaggle数据集，并辅以新冠相关新闻增强数据集。提出一种上下文图谱方法，利用自然语言处理（NLP）技术将新闻文章转换为上下文图结构。随后，应用基于最小描述长度（MDL）的图谱异常检测（GBAD）算法进行图挖掘，以识别复杂模式。

Result: 所提出的方法能够识别数据集中的规范模式，并随后发现偏离这些既定规范的异常模式（即假新闻）。

Conclusion: 基于图谱的方法在处理丰富的上下文数据方面特别有效，能够通过发现复杂模式和异常来有效检测假新闻。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [5] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 针对印度语言多样性，本文提出并训练了一个2.9B参数的双语（印地语-英语）LLM PARAM-1，旨在实现更公平的基础模型设计。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）主要以英语为中心，导致印度等语言多样性地区（拥有20多种官方语言和100多种方言，涉及语码转换和双言现象）的语言结构性代表性不足。

Method: 引入PARAM-1，一个2.9B参数的仅解码器、纯文本语言模型，从零开始训练，特别关注印度语言多样性。它在高质量、以事实为基础的印地语和英语双语数据集上训练，遵循三项核心原则：1) 指示语种的公平语料分配（25%）；2) 通过适应印度形态结构的SentencePiece分词器实现分词公平性；3) 在IndicQA、语码混合推理和语社会语言鲁棒性任务中进行文化对齐的评估。该方法通过在预训练阶段而非事后对齐嵌入多样性。

Result: PARAM-1表现为一个称职的通用模型，同时也是面向印度应用的一个强大基线。

Conclusion: PARAM-1通过在预训练层面嵌入多样性，为公平的基础模型设计提供了一个“设计优先”的蓝图。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [6] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 通过将主题建模管道重构为基于观点单元（包含文本和情感分数）进行操作，提高从客户评论中提取洞察的能力，并能将主题和情感与业务指标关联，以预测星级评分并理解客户反馈如何影响业务成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从客户评论中有效地提取深入洞察，特别是如何将客户反馈中的特定主题和情感与实际业务成果（如星级评分）关联起来。研究旨在提升主题建模的性能和可解释性，并量化客户担忧对业务的影响。

Method: 核心方法是重构主题建模管道，使其在“观点单元”上运行。这些观点单元是包含相关文本摘录和关联情感分数的独立陈述，并可使用大型语言模型可靠地提取。然后，将生成的主题和情感与星级评分等业务指标进行关联。

Result: 该方法显著提升了后续主题建模的性能，生成了连贯且可解释的主题，并捕获了每个主题所关联的情感。通过将主题和情感与业务指标关联，系统能够揭示特定客户关注点如何影响业务成果。此外，该系统在创建连贯主题以及整合主题和情感模态以准确预测星级评分方面表现出有效性。

Conclusion: 通过采用基于观点单元的主题建模新范式，该系统能更有效地从客户评论中提取有价值的洞察，实现更高质量的主题建模，并能将客户反馈与业务绩效紧密结合。这为理解客户担忧对业务成果的影响提供了一种强大且优于现有解决方案的分析工具。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [7] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel是一个新型框架，作为NMT后处理模块，仅利用单语语料库即可在机器翻译中增强风格保真度。


<details>
  <summary>Details</summary>
Motivation: 神经机器翻译(NMT)在跨语言交流中面临保持风格细微差别的挑战，而现有方法通常需要并行语料库来维持风格。

Method: 引入Babel框架，仅使用单语语料库。包含两个核心组件：1) 基于上下文嵌入的风格检测器，识别源文本和目标文本间的风格差异；2) 基于扩散的风格应用器，纠正风格不一致同时保持语义完整性。它作为后处理模块集成到现有NMT系统，无需修改架构或并行风格数据。

Result: 在五个不同领域（法律、文学、科技、医学、教育）的实验表明，Babel能以88.21%的精度识别风格不一致，将风格保留度提高150%，同时保持0.92的高语义相似度。人工评估证实经Babel优化的翻译能更好保留源文本风格，并保持流畅性和充分性。

Conclusion: Babel框架通过仅使用单语语料库，有效解决了NMT中风格保持的挑战，显著提升了翻译的风格保真度，且作为后处理模块易于集成，是NMT领域的重要进展。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [8] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 通过修改LLM中单个稀疏自编码器（SAE）特征，研究人员实现了生成语言的高效控制（高达90%成功率），同时保持语义不变性。


<details>
  <summary>Details</summary>
Motivation: 在零样本设置下，确定性地控制大型多语言语言模型（LLMs）的生成语言是一个核心挑战，因为此时无法使用显式语言提示或进行微调。

Method: 本研究利用Gemma-2B和Gemma-9B模型残差流上的预训练SAE，识别出在英语与中文、日文、西班牙文、法文之间激活差异最显著的特征。通过在单个Transformer层中修改单个SAE特征，尝试引导生成语言。

Result: 实验结果显示，通过修改单个SAE特征，语言转换成功率高达90%（由FastText分类器测量），同时语义保真度（通过LaBSE相似度测量）得以保留。分析表明，语言引导在中后期Transformer层最有效，并由与语言敏感SAE特征相关的特定注意力头所增强。

Conclusion: 稀疏特征操纵是一种有前景的、轻量级且可解释的可控多语言生成机制。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [9] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 本文提出ALIGNed-LLM，一种将知识图谱嵌入语言模型潜在空间的方法，通过对齐实体和文本嵌入来提高大模型的事实性和减少幻觉，在问答基准和真实金融场景中均取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）尽管功能强大，但在自然语言处理任务中普遍存在幻觉问题，这是一个亟待解决的主要挑战。将知识图谱（KGs）整合到语言模型中被认为是解决此问题的有效途径，因其能提供结构化、可靠且最新的外部信息。

Method: 引入了ALIGNed-LLM，一种受LLaVA启发的精益策略，将知识图谱信息注入到语言模型的潜在空间中。具体方法是使用预训练的知识图谱嵌入（如TransE）和可训练的投影层来对齐实体和文本嵌入，使语言模型能够区分相似实体，从而提高事实接地能力并减少幻觉。

Result: 在三个流行的问答基准数据集上以及不同大小的语言模型上进行了测试，均显示出显著的改进。此外，该方法还成功应用于欧洲一家大型中央银行的真实金融用例，证明了LLM答案的实质性提升。

Conclusion: ALIGNed-LLM通过将知识图谱信息高效地注入语言模型潜在空间，显著提高了大模型的事实准确性并有效减少了幻觉问题，在通用问答和高精度要求的专业领域应用中均表现出优异性能。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [10] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为“论文摘要攻击”（PSA）的新型越狱方法，该方法利用大语言模型（LLMs）对权威来源的信任，通过合成安全论文内容并嵌入恶意查询来生成对抗性提示，实现了高成功率攻击，并揭示了模型间的脆弱性偏差。


<details>
  <summary>Details</summary>
Motivation: LLMs的安全性受到广泛关注。先前的研究表明LLMs倾向于信任权威来源（如学术论文），这预示着新的潜在漏洞。本文旨在验证这种可能性并利用其进行攻击。

Method: 基于LLMs信任权威来源的洞察，提出PSA方法。该方法系统地综合攻击型或防御型LLM安全论文的内容，构建对抗性提示模板，并将有害查询作为对抗性载荷策略性地填充到预定义的子章节中。

Result: 广泛的实验表明，不仅基础LLMs，甚至先进的推理模型（如Deepseek-R1）也存在显著漏洞。PSA在Claude3.5-Sonnet上实现了97%的攻击成功率（ASR），在Deepseek-R1上更是达到98%的ASR。研究还发现，当暴露于攻击型或防御型论文时，不同基础模型之间，甚至同一模型的不同版本之间，都存在截然相反的脆弱性偏差。

Conclusion: LLMs对权威来源的信任确实构成了新的越狱漏洞，PSA是一种高效的攻击方法。发现的模型脆弱性偏差为未来的对抗性方法和安全对齐研究提供了重要的线索。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [11] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 评估LLM价值取向的探测方法，发现其对输入扰动敏感且与模型行为关联性弱，强调需谨慎对待LLM价值探测。


<details>
  <summary>Details</summary>
Motivation: 现有LLM价值评估方法存在挑战：多项选择题（MCQ）易受扰动，缺乏系统性探测方法比较；不清楚探测到的价值观是否反映上下文信息和真实行为偏好。

Method: 评估了三种常用探测策略的鲁棒性和表达性，通过改变提示和选项进行输入扰动实验；引入两个任务研究价值观对人口统计上下文的响应性，以及与模型在价值相关场景中行为的一致性。

Result: 所有探测方法在输入扰动下表现出较大方差；人口统计上下文对自由文本生成影响甚微；模型价值观与基于价值的行为偏好仅呈弱相关。

Conclusion: 强调LLM价值探测需要更严谨的审查，并认识到其局限性。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [12] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 本文提出一种数学论证，展示了如何将词汇项和任意句法对象忠实地表示在同一函数空间中，并通过代数结构实现句法运算，从而为句法核心计算结构的神经计算实现提供了理论可能性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提供一种数学论证，说明在将词汇项表示为函数的前提下，如何构建任意句法对象的忠实表示，并探索句法核心计算结构在神经计算层面的理论实现可能性。

Method: 将词汇项和句法对象表示在某一函数空间中；为该空间赋予基于二阶Renyi熵的交换非结合半环结构；将函数集构建为模运算元的代数，其中运算元中的操作模拟将输入波形转换为编码句法结构的输出电路；通过协积和Hopf代数马尔可夫链，忠实地实现了Merge操作对工作空间的动作；提出了一种特殊情况，通过正弦波上的交叉频率相位同步实现Merge。

Result: 成功构建了任意句法对象在与词汇项相同函数空间中的忠实表示；该句法对象表示与岩浆结构兼容；Merge操作通过电路上的动作被忠实地实现；提供了句法核心计算结构神经计算实现的建设性理论论证；展示了Merge通过正弦波上的交叉频率相位同步实现的特定案例；阐明了Merge可以用半环的后继函数来表示，揭示了其与算术后继函数的相似性。

Conclusion: 研究通过严谨的数学论证，为句法在函数空间中的表示及Merge等核心操作的实现提供了理论框架，并提出了句法核心计算结构神经计算实现的理论可能性，同时明确了Merge与算术后继函数之间的关联。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [13] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 该研究提出一个计算框架，结合大型语言模型和新型图简化技术“Filter & Reconnect”，用于构建和分析准模式对话的会话图，旨在提高语义清晰度和结构完整性，并可应用于大规模对话数据分析。


<details>
  <summary>Details</summary>
Motivation: 随着基于大型语言模型的系统兴起，对话动态分析变得日益重要。需要一种方法来捕获松散组织对话（即准模式对话）的流向和结构，并最小化噪音同时保持语义连贯性。

Method: 提出了一种构建会话图的新型计算框架。引入了“Filter & Reconnect”方法，这是一种图简化技术，旨在减少噪音并保持语义连贯性和结构完整性。该方法结合了大型语言模型与所提出的图简化技术。

Result: 通过比较分析表明，结合大型语言模型和图简化技术后，语义度量S相较于现有方法提高了2.06倍。同时，该方法强制实现了0 δ-双曲性的树状结构，确保了对话建模的最佳清晰度。

Conclusion: 这项工作提供了一种分析大规模对话数据集的计算方法，具有实际应用价值，可用于监控自动化系统（如聊天机器人）、对话管理工具和用户行为分析。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [14] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 本研究表明，结合暂停特征与语义连贯性指标的自动化言语分析能有效且可靠地评估形式思维障碍（FTD）的严重程度，为精神疾病的诊断提供了新的方法。


<details>
  <summary>Details</summary>
Motivation: 传统评估形式思维障碍（FTD）的方法资源密集且缺乏可扩展性。自动语音识别（ASR）技术能够客观量化言语语言和时间特征，提供可扩展的替代方案。然而，ASR衍生的停顿动态特征与语义连贯性指标在评估FTD严重性方面的效用需进一步评估。

Method: 本研究整合了停顿特征与语义连贯性指标，并在三个不同数据集（AVH、TOPSY、PsyCL）上进行了评估。研究使用支持向量回归（SVR）模型来预测临床FTD分数，并对比了仅使用语义特征模型、仅使用停顿特征模型以及整合停顿和语义特征模型的预测性能。

Result: 关键发现表明，单独使用停顿特征即可稳健预测FTD的严重程度。与仅使用语义特征的模型相比，整合停顿特征与语义连贯性指标显著提升了预测性能，重症检测的相关性（rho）最高达0.649，AUC达83.71%（TOPSY数据集）。性能提升在所有语境下均保持一致，尽管停顿模式因数据集而异。

Conclusion: 结合时间（停顿）和语义分析的框架为完善言语紊乱评估提供了指导，并推进了精神病学领域自动化言语分析的发展。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [15] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 本文介绍了一个名为Balalaika的新型俄语语音数据集，旨在解决俄语语音合成的独特挑战，并显著提升语音合成与增强模型的性能。


<details>
  <summary>Details</summary>
Motivation: 俄语语音合成面临元音弱化、辅音清化、变重音模式、同形异义词歧义以及不自然语调等独特挑战，现有数据集未能有效解决这些问题。

Method: 本文构建并引入了Balalaika数据集，包含超过2,000小时录音室质量的俄语语音，并提供全面的文本注释（包括标点和重音标记）。论文详细阐述了数据集的构建流程和标注方法。

Result: 实验结果表明，在Balalaika数据集上训练的模型在语音合成和增强任务中均显著优于在现有数据集上训练的模型。

Conclusion: Balalaika数据集成功克服了俄语语音合成的现有挑战，为高质量俄语语音生成提供了有效解决方案，并显著提升了相关模型的表现。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [16] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 本研究通过语言特征分析人类撰写和大型语言模型（LLM）生成文本的差异，发现人类文本在句法上更简单、语义更丰富且变异性更大，而新型LLM生成的文本趋于同质化。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs生成文本与人类文本的区分度降低，现有研究多关注文本分类，本研究旨在通过多层级语言特征来深入刻画和理解人类与机器生成文本的内在语言学特性。

Method: 选取包含8个领域、11个LLM生成的文本数据集，计算形态、句法（如依存长度）和语义（如情感度）等多种语言特征。采用统计分析，并考虑采样策略、重复控制和模型发布日期。最终，通过风格嵌入（style embeddings）进一步检验文本变异性。

Result: 统计分析显示，人类文本倾向于展现更简单的句法结构和更多样化的语义内容。在跨领域风格多样性方面，人机文本均有体现，但人类文本的特征变异性更大。值得注意的是，新型模型输出文本的变异性相似，表明机器生成文本存在同质化趋势。

Conclusion: 研究揭示了人类与LLM生成文本在语言特征上的显著差异，尤其体现在句法复杂度、语义多样性和风格变异性上。最新模型生成的文本变异性趋同，预示着机器文本可能走向风格上的“标准化”或“同质化”。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [17] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: 本文介绍Seed-X，一个7B参数的开源LLM家族，通过多语言预训练、CoT微调和RL，实现了与Gemini-2.5和GPT-4o媲美的多语言翻译性能，并显著超越其他开源模型，同时公开模型参数以促进研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理复杂语言模式和自动化翻译中出现的生硬翻译时，多语言翻译仍是一个具有挑战性的任务。

Method: 研究引入了Seed-X，一个包含指令和推理模型的开源LLM家族，参数量为7B。基模型在包含28种语言的单语和双语高质量多样化数据集上进行预训练。指令模型通过Chain-of-Thought (CoT) 推理进行微调，并通过强化学习（RL）进一步增强，以提高在不同语言对之间的泛化能力。

Result: Seed-X在28种语言上的表现与领先的闭源模型（如Gemini-2.5和GPT-4o）相当。在自动评估指标和人工评估中，Seed-X显著优于更大的开源模型。

Conclusion: Seed-X展示了7B参数LLM在多语言翻译方面的强大能力和潜力。研究团队分享了优化过程中的最佳实践，并公开了模型参数，以期推动翻译研究和应用的发展。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [18] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: CU-ICU是一种基于T5的稀疏微调方法，能高效、准确地将无监督指令微调大模型应用于ICU数据，显著提升败血症检测和临床解释生成能力，同时更新参数极少。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型应用于医疗等专业领域（如ICU）面临领域适应和标注数据有限的挑战。

Method: 引入CU-ICU方法，利用Text-to-Text Transfer Transformer (T5)架构，定制用于ICU数据集的无监督指令微调语言模型。该方法采用稀疏微调，结合少量样本提示和选择性参数更新，以实现高效且低监督的领域适应。

Result: 在早期败血症检测、死亡率预测和临床笔记生成等ICU任务中，CU-ICU持续提升了预测准确性和可解释性，优于标准微调方法。具体地，败血症检测准确率提升高达15%，生成临床相关解释的能力增强20%，且在最高效配置下更新的模型参数少于1%。

Conclusion: CU-ICU是一种可扩展、低开销的解决方案，能为真实的ICU环境提供准确且可解释的临床决策支持。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [19] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLM）API成本高昂的问题，本文提出了Keyword-inspired Cascade (KiC) 框架，通过语义对齐来优化级联方法，在保持高准确率的同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 高性能大型语言模型通常通过API访问，导致推理成本高昂。现有级联方法（先用廉价模型，必要时升级到更强模型）在处理自由形式输出时，因依赖精确文本匹配，难以选择可靠的代表性响应并评估整体可靠性。

Method: 本文提出KiC框架，用于实现成本效益高的自由形式文本生成。KiC从弱模型的多个输出中识别最具代表性的答案，并评估其他响应与该答案的语义对齐度。根据对齐程度，KiC决定是否接受弱模型的输出或升级到更强的模型。

Result: 在三个自由形式文本生成基准测试中，KiC实现了GPT-4 97.53%的准确率，同时平均降低API成本28.81%。在某个特定基准测试中，KiC甚至超越了GPT-4的性能。

Conclusion: KiC框架通过创新的语义对齐方法，有效克服了现有级联方法在自由形式文本生成中的局限性，在显著降低LLM API成本的同时，保持了接近甚至超越顶级模型的性能，提供了一种高效经济的LLM应用方案。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [20] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe是一个自适应双阶段框架，通过在线稀疏化和渐进式键值（KV）压缩，显著加速大型语言模型在长上下文多轮对话中的推理，并优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 多轮对话中，长对话历史导致大型语言模型面临计算和内存瓶颈，影响效率和响应速度。现有加速方法多依赖固定或基于位置的启发式，难以适应多轮对话的动态特性。

Method: 提出LoopServe，一个自适应的双阶段推理加速框架。创新点包括：1) 在预填充阶段进行在线稀疏化，动态选择注意力矩阵的最重要部分；2) 在解码阶段使用渐进式KV压缩，自适应维护相关高效的缓存。同时，还构建了一个包含11个数据集的新型多轮对话基准测试，模拟真实对话场景。

Result: 广泛实验表明，LoopServe在多种长上下文对话任务中，相比现有基线始终表现出卓越的有效性，并显著加速了大型语言模型的推理过程。

Conclusion: LoopServe成功解决了大型语言模型在处理长上下文多轮对话时的效率挑战，通过其自适应的加速机制，为LLM在真实多轮对话应用中的高效部署提供了重要解决方案。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [21] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 评估了大型语言模型(LLMs)在群组推荐系统(GRS)中作为推荐和解释生成器的表现。发现其推荐接近加性效用聚合策略，但解释常引用不明确的额外标准，且与推荐逻辑存在细微差异，这损害了LLMs在GRS中透明度和可解释性的优势。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型(LLMs)在群组推荐系统(GRS)中作为联合决策者和解释生成器的日益应用，本研究旨在通过与社会选择聚合策略的对比，评估LLM生成的推荐和解释的质量。

Method: 将LLM生成的群组推荐和解释与基于社会选择理论的聚合策略进行比较评估。

Result: 1. LLM生成的推荐通常与加性效用(ADD)聚合策略的结果相似。
2. LLM的解释通常提及平均评分，虽然类似于ADD聚合，但并不完全相同。
3. 群组结构（统一或差异）对LLM的推荐没有影响。
4. LLM在解释中经常引用额外的标准，如用户或物品相似性、多样性，或使用未定义的流行度指标/阈值。
5. 解释中额外标准的出现依赖于群组场景中的评分数量，这可能暗示了在更大的物品集合下标准聚合方法的潜在低效性。
6. LLM的解释存在不一致和模糊性。

Conclusion: LLM在GRS中作为透明度和可解释性工具的关键优势因其生成的不一致和模糊解释而受损。本研究结果对LLM在GRS中的应用以及标准聚合策略均具有重要启示。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [22] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 本研究使用机器学习预测法国上诉法院的儿童监护权判决。结果显示，基于个别法官历史判例训练的“专家模型”预测准确率远高于“普适模型”，证实了法官的个人决策模式对判决结果有显著影响，支持了法律现实主义观点。


<details>
  <summary>Details</summary>
Motivation: 探讨法官个人决策模式对法律判决结果的影响，挑战法官中立性假设，并为法律现实主义与形式主义之争提供实证依据。

Method: 分析法国上诉法院10,306个案件中的18,937份监护权判决。采用混合预测方法：利用大型语言模型（LLMs）进行结构化特征提取，并使用机器学习模型（RF, XGB, SVC）进行结果预测。对比基于个别法官历史判决训练的“专家模型”与基于聚合数据训练的“普适模型”的性能。

Result: “专家模型”的预测准确率显著高于“普适模型”；表现最佳的“专家模型”F1分数高达92.85%，而“普适模型”F1分数为82.63%（后者训练数据量是前者的20至100倍）。结果表明“专家模型”捕捉到稳定的、不可转移的法官个人决策模式，且域内和跨域有效性测试均支持法律现实主义。

Conclusion: 本研究通过实证证明了法官的个人身份在法律判决结果中扮演着可衡量且重要的角色，为法律现实主义提供了强有力的支持。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [23] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 研究发现大型语言模型(LLMs)存在严重的LGBTQIA+偏见。通过使用参数高效微调(PEFT)技术LoRA，能在计算成本极低的情况下显著降低这些偏见，而软提示微调效果不佳。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)在训练语料库中嵌入的性别和性取向偏见，导致其输出可能边缘化LGBTQIA+用户。因此，减少这些偏见至关重要。

Method: 本研究评估了两种参数高效微调(PEFT)技术——低秩适应(LoRA)和软提示微调(soft-prompt tuning)——作为减轻偏见的轻量级替代方案。研究利用WinoQueer基准测试量化了三个开源LLM的偏见，并使用整理过的QueerNews语料库对模型进行LoRA微调。

Result: 基线测试显示LLMs在多种酷儿身份上的偏见得分高达98分（满分100分，50分表示中立）。LoRA微调（额外参数少于0.1%）成功将偏见得分降低多达50点，并将中立性从几乎0%提高到36%。然而，软提示微调（10个虚拟token）仅带来微小的改进。

Conclusion: 研究结果表明，LoRA能够以最小的计算量带来显著的公平性提升。作者建议更广泛地采用社区参与的PEFT方法，创建更大的酷儿群体创作语料库，开发更丰富的评估套件（超越WinoQueer），并结合持续审计以确保LLMs的包容性。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [24] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文研究了视觉语言模型（VLMs）的提示敏感性如何导致不当内容生成及越狱。发现VLM在多模态下识别有害内容能力显著下降，并指出特定提示元素、上下文示例、内部层跳跃连接以及梗图均能有效提高越狱成功率，揭示了VLM的潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 语言模型对提示语高度敏感，微小改动可能大幅改变输出。本文旨在探讨这种敏感性在多大程度上可被利用来生成不当内容，特别关注VLMs在多模态环境下，区分良性与有害输入的能力显著下降的问题。

Method: 1. 分析提示设计中三个关键因素（详细视觉信息、对抗性示例、积极开头短语）对VLM越狱的影响。 2. 测试少量上下文示例（少至三个）对生成不当输出的影响。 3. 提出一个利用VLM内部层间跳跃连接的框架以提高越狱成功率。 4. 评估梗图（memes）引发有害内容的有效性。

Result: 1. VLM在单模态下能可靠区分良性与有害输入，但在多模态环境下该能力显著下降。 2. 所研究的三个因素均可独立触发越狱。 3. 少量上下文示例即可促使模型生成不当输出。 4. 所提出的跳跃连接框架能显著提高越狱成功率，即使使用良性图像。 5. 梗图与有毒视觉内容一样能有效诱发有害内容。

Conclusion: VLMs存在微妙且复杂的漏洞，尤其在多模态环境中。通过利用特定的提示策略、上下文示例、内部结构调整，甚至看似无害的视觉内容（如梗图），可以有效促使VLM生成不当内容。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [25] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 针对社交媒体短文本聚类面临的稀疏性、高维性及计算成本高昂问题，本文提出GSDMM算法及其改进版GSDMM+，通过优化词权重和聚类合并策略，实现了高效且精细的短文本聚类。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体的普及，短文本聚类日益重要。然而，短文本数据固有的稀疏性、大规模和高维度特性，以及现有深度表示学习方法计算开销大，使得短文本聚类成为一项严峻挑战。

Method: 本文首先提出基于Dirichlet多项式混合模型的塌缩Gibbs采样算法（GSDMM），有效处理短文本的稀疏性和高维度，并识别代表性词汇。在此基础上，进一步提出GSDMM+，通过减少初始化噪声、基于熵自适应调整词权重以实现细粒度聚类，并采用策略性簇合并来优化聚类粒度，使预测分布与真实类别分布更一致。

Result: 通过与经典及最先进方法的广泛实验比较，结果证明所提出的GSDMM和GSDMM+方法在效率和有效性上均表现优异。

Conclusion: GSDMM及其改进版GSDMM+为短文本聚类提供了一种高效且有效的解决方案，能够很好地处理短文本的固有挑战并提供更精细的聚类结果。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [26] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 本文提出两种从科学论文中提取关键概念和贡献的方法：基于LLM的问答生成和基于知识图谱的问答生成，旨在帮助学者快速理解文章核心思想。实验表明基于知识图谱的方法更有效。


<details>
  <summary>Details</summary>
Motivation: 学者在阅读或研究文章时，需要快速识别并理解其主要思想。本文旨在以问答（QA）对的形式，从科学文章中提取这些关键概念和贡献。

Method: 提出了两种问答生成方法：
1.  **基于大语言模型（LLM）的方法**：选择显著段落，使用LLM生成问题，根据获得有意义答案的可能性对问题进行排序，然后生成答案。此方法仅依赖文章内容。
2.  **基于知识图谱（KG）的方法**：通过在科学文章上微调实体关系（ER）提取模型来构建知识图谱，并使用基于三元组TF-IDF类似度量的方法，选择文章中最相关的实体关系（显著三元组）。该度量评估三元组在文章中的重要性及其在文献中的普遍性来衡量其显著性。
评估方法：使用两种方法生成的问答对由学科专家（SMEs）通过预定义的指标进行评估，以衡量问题和答案的质量。

Result: 评估结果表明：
1.  基于知识图谱的方法能有效捕捉文章中讨论的主要思想。
2.  在科学语料库上微调ER提取模型对于从此类文档中提取高质量三元组至关重要。

Conclusion: 基于知识图谱的问答生成方法在从科学文章中提取核心思想方面表现出色，且ER提取模型在特定科学语料库上的微调对其性能至关重要，为学者快速理解文献提供了有效工具。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [27] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 本研究探讨了中文心理咨询中语言表达（第一人称单数代词和负面情绪词）与抑郁、焦虑状态的关系，发现负面情绪词与症状严重程度呈正相关，而第一人称代词无显著关联，这与西方研究结果存在文化差异。


<details>
  <summary>Details</summary>
Motivation: 旨在探究中文心理咨询互动中语言表达（特别是第一人称单数代词和负面情绪词）与抑郁、焦虑心理状态之间的关系，并考虑到与西方语境可能存在的文化差异。

Method: 利用包含735个在线咨询会话的语料库，通过语言查询与词汇计数（LIWC）软件量化语言模式，并采用广义线性混合效应模型进行分析。

Result: 结果显示，负面情绪词的使用频率与来访者的抑郁和焦虑状态严重程度呈显著正相关。然而，与先前主要基于英语语境的研究不同，第一人称单数代词的使用频率并未随来访者的心理状况显著变化。

Conclusion: 研究强调了文化（集体主义与个人主义）和对话（心理咨询互动）背景对心理健康沟通中语言使用的细微影响，为中文人群的治疗实践提供了相关的心理语言学标记洞察。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [28] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 本文提出了一个概率框架，用于量化侦探小说中“公平游戏”与“惊喜”之间的平衡，并以此评估了LLM生成故事的质量。


<details>
  <summary>Details</summary>
Motivation: 旨在理解和量化优秀故事叙述中的平衡点，特别是在侦探小说领域中，如何平衡读者预期与意外发展（即“公平游戏”），并评估LLM生成故事在这一方面的表现。

Method: 提出一个概率框架，用于形式化定义侦探小说中的“公平游戏”和“惊喜”，并设计了相应的度量标准。该框架应用于大型语言模型（LLM）生成的侦探故事进行验证。

Result: 研究结果表明，尽管LLM生成的侦探故事可能具有不可预测性，但它们通常未能很好地平衡惊喜与公平游戏之间的权衡，这严重影响了其故事质量。

Conclusion: LLM生成的侦探故事在公平游戏和惊喜的平衡方面表现不佳，导致其质量低下。本研究提供了一个评估故事质量的形式化框架。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [29] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 本文提出InTraVisTo工具，旨在可视化Transformer模型内部计算和信息流，以帮助研究人员理解大型语言模型（LLM）的内部工作原理。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）的推理能力显著提升，但其不可预测性以及期望行为与实际输出之间的差异，导致其在生产环境中的应用仍面临挑战。

Method: 引入了InTraVisTo（Inside Transformer Visualisation Tool），一个专门用于调查和追踪基于Transformer的LLM中每个令牌生成计算过程的工具。它通过解码各层令牌嵌入来可视化Transformer模型的内部状态，并利用桑基图（Sankey diagram）展示模型不同层之间各组件的信息流。

Result: InTraVisTo旨在帮助研究人员和实践者更好地理解Transformer模型内部进行的计算，从而揭示LLM所采用的内部模式和推理过程。

Conclusion: 通过提供对LLM内部计算过程和信息流的可视化，InTraVisTo工具有望增强LLM的透明度和可解释性，促进对LLM深层机制的理解。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [30] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 网络安全NER数据集缺乏标准化标签，本研究尝试通过标签统一和新模型（多头、图基迁移）提高数据可用性，但发现统一训练的模型泛化能力差，且所提模型改进有限。


<details>
  <summary>Details</summary>
Motivation: 网络安全命名实体识别（NER）领域缺乏标准化标签，导致现有数据集难以有效整合和利用，因此需要研究标签统一化以提高数据资源的可用性。

Method: 研究者首先对四个网络安全数据集进行了粗粒度标签统一，并使用BiLSTM模型进行了成对的跨数据集评估。为解决统一化局限性，进一步提出了多头模型（含权重共享）和基于BERT-base-NER的图基迁移模型。

Result: 定性分析揭示了预测错误、局限性和数据集差异。实验结果显示，在统一数据集上训练的模型跨数据集泛化能力差。带权重共享的多头模型相比统一训练仅带来微小改进，而基于图的迁移模型相比BERT-base-NER没有显著性能提升。

Conclusion: 网络安全NER领域的数据集统一和跨数据集泛化仍面临挑战。尽管尝试了新颖的模型架构，但未能显著提高模型在统一数据集上的泛化能力，暗示该领域的数据整合和标准化问题需要更深层次的解决方案。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [31] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 本文旨在解决语码转换（CS）对自动语音识别（ASR）的挑战，通过探索合成数据、拼接单语音频和利用真实CS数据等策略，显著提升了加泰罗尼亚语-西班牙语CS的ASR性能，发现少量合成数据结合主导语言标记效果最佳。


<details>
  <summary>Details</summary>
Motivation: 语码转换（CS）因训练数据稀缺和语言相似性，对自动语音识别（ASR）构成重大挑战。缺乏专用的CS数据集限制了ASR性能，现有模型无法反映真实的CS模式。在多语社会（如加泰罗尼亚语-西班牙语）中，CS普遍存在于日常和正式场合，因此提升其ASR性能至关重要。

Method: 研究通过探索三种策略改进加泰罗尼亚语-西班牙语语码转换ASR：1) 生成合成CS数据；2) 拼接单语音频；3) 利用带有语言标记的真实CS数据。研究从加泰罗尼亚语语音语料库中提取CS数据，并对OpenAI的Whisper模型进行微调。

Result: 结果表明，将少量合成CS数据与主导语言标记结合使用，能够产生最佳的转录性能。

Conclusion: 通过巧妙地结合合成数据和语言标记，可以有效提升语码转换语音的ASR性能，尤其是在数据稀缺的特定语码转换场景中，为多语言ASR的发展提供了可行策略。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [32] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 为解决开放式情境判断测试（SJT）在评估个人与专业技能时的可扩展性问题，本文提出了一种利用大型语言模型（LLM）从SJT回答中提取构念相关特征的新方法，并以Casper SJT为例验证了其有效性，旨在为自动化评分奠定基础。


<details>
  <summary>Details</summary>
Motivation: 学术项目日益重视个人和专业技能，需要可扩展的系统进行衡量、评估和发展。传统的开放式SJT评分依赖人工，难以大规模应用，且过往基于NLP的自动化评分系统存在构念效度问题。

Method: 探索一种新颖的方法，利用大型语言模型（LLM）从情境判断测试（SJT）的开放式回答中提取与构念相关的特征。该方法以Casper SJT为例进行有效性验证。

Result: 研究通过Casper SJT展示了利用LLM提取SJT回答中构念相关特征方法的有效性。

Conclusion: 本研究为未来个人和专业技能自动化评分系统的发展奠定了基础。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [33] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本论文通过整合和扩展数据集，并利用leave-one-in和leave-one-out方法进行基准测试，旨在解决Transformer模型在政治倾向和政治性文本分类中泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer模型的政治倾向和政治性文本自动分类方法，通常是孤立的解决方案，并且在处理分布外文本时表现不佳，缺乏泛化能力。

Method: 研究者首先对现有数据集和模型进行了全面概述。为解决泛化性问题，他们通过整合12个现有数据集构建了一个多样化的政治倾向分类数据集，并扩展了18个现有数据集以创建新的政治性分类数据集。随后，他们采用leave-one-in和leave-one-out方法进行了广泛的基准测试，以评估现有模型并训练具有增强泛化能力的新模型。

Result: 论文通过所编译的多样化数据集和严格的基准测试方法，评估了现有模型的性能，并训练了旨在提升泛化能力的新模型。

Conclusion: 本研究通过构建更全面、多样化的数据集和采用严格的评估方法，旨在克服现有Transformer模型在政治文本分类任务中泛化能力差的局限性，从而为相关挑战提供更鲁棒的解决方案。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [34] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 研究发现，当前AI的说服力主要来源于后期训练和提示方法，而非模型规模或个性化，并且AI说服力增强往往伴随事实准确性下降。


<details>
  <summary>Details</summary>
Motivation: 鉴于人们普遍担忧会话式AI可能对人类信念产生前所未有的影响，本研究旨在评估AI的说服力，并探究其说服机制及与事实准确性的关系。

Method: 通过三项大规模实验（N=76,977），部署了19个大型语言模型（LLMs，包括部分专门为说服而后期训练的模型），评估它们在707个政治议题上的说服力，并核查了466,769条LLM声明的事实准确性。

Result: 结果显示，当前及未来的AI说服力更多来源于后期训练（提升高达51%）和提示方法（提升高达27%），而非个性化或模型规模增大。这些方法通过利用LLMs快速获取和策略性部署信息的能力来增强说服力，且惊人地发现，AI说服力提高时，事实准确性反而系统性下降。

Conclusion: AI的说服力主要通过特定的后期训练和提示技术实现，这些技术利用了LLMs的信息处理能力，但这种说服力的增强往往以牺牲事实准确性为代价。这表明了AI劝导的复杂性和潜在风险。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [35] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 本文提出了Marcel，一个轻量级开源的会话代理，旨在通过检索增强生成（RAG）技术，为准学生提供快速、个性化的入学咨询服务，并减轻大学员工的工作负担。


<details>
  <summary>Details</summary>
Motivation: 为准学生提供快速、个性化的入学咨询答复，并减轻大学工作人员处理大量相关咨询的负担。

Method: 开发了名为Marcel的会话代理。核心方法是检索增强生成（RAG），以大学资源为基础生成可验证、上下文相关的答案。为提升检索质量，引入了FAQ检索器，将用户问题映射至知识库条目，并允许管理员引导检索，优于标准检索策略。系统设计考虑了在资源受限学术环境中的便捷部署。

Result: 论文详细介绍了系统架构，对系统组件进行了技术评估，并报告了该系统在真实世界部署中获得的见解。

Conclusion: Marcel成功构建了一个支持准学生入学咨询的有效会话代理，通过创新的检索机制提供了高质量、可验证的答案，同时减轻了大学工作人员的负担，并证明了其在资源受限环境下的实用性。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [36] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）的微调会放大其首因偏差。本研究通过基于语义相似性重新排序选项来利用这种偏差，显著提升了多项选择问答（MCQA）的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs存在偏见，特别是首因效应等位置偏差，会影响其答案准确性。在多项选择问答中，答案选项的顺序会影响预测结果。本研究旨在探讨微调LLMs中的首因偏差及其影响。

Method: 首先展示了微调会放大LLMs的首因偏差。随后，通过基于查询的语义相似性重新排序响应选项，策略性地利用了这一效应，且无需预知正确答案。

Result: 实验结果表明，微调确实放大了LLMs的首因偏差。并且，所提出的基于语义相似性重新排序选项的方法显著提升了MCQA的性能。

Conclusion: 研究强调了偏差的双重性质，即既是挑战也是机遇，为偏差感知模型设计和NLP应用提供了见解。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [37] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 本文提出一种基于知识图谱（KG）的自下而上训练方法，以赋予语言模型（如QwQ-Med-3）深度领域专业知识和超智能。通过KG生成医学推理任务并微调模型，QwQ-Med-3在医学基准（如ICD-Bench）上显著超越现有模型，并能迁移所学专业知识，为通过领域特定超级智能体实现AGI提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型通过通用语料库进行的自上而下训练，不足以获得深入的领域专业知识所需的抽象能力。这需要一种自下而上的方法，通过学习组合简单的领域概念来获取专业知识。

Method: 利用知识图谱（KG）提供组合结构，将领域原语表示为边。开发了一个任务生成流程，直接从KG原语合成任务，使模型能够获取和组合概念进行推理。将语言模型在此KG-grounded课程上进行微调。在医学领域验证，使用医学KG策划了24,000个带有思维轨迹的推理任务。微调QwQ-32B模型得到QwQ-Med-3。同时引入了ICD-Bench作为跨15个医学领域的评估套件。

Result: QwQ-Med-3在ICD-Bench类别上显著优于最先进的推理模型。进一步分析显示，QwQ-Med-3利用习得的原语，在ICD-Bench最困难的任务上扩大了性能差距。在医学问答基准上的评估也表明，QwQ-Med-3能够迁移所学专业知识，提升基础模型的表现。

Conclusion: 尽管行业普遍强调通过广泛专业知识实现通用人工智能（AGI），但本研究预示AGI可能通过高效的领域特定超智能代理的可组合交互而涌现。QwQ-Med-3朝着医学超智能迈出了一步，证明了领域专业化AI的可行性。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [38] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语语音识别的复杂性与模型稀缺问题，提出通用处理方法，并基于FastConformer架构开发了SOTA性能的MSA专用模型和首个统一MSA/CA模型，并已开源。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯语使用广泛，但其自动语音识别（ASR）系统开发面临语言复杂性挑战，导致公共模型有限；现有研究多聚焦于现代标准阿拉伯语（MSA），对语言内部变体的关注不足。

Method: 引入了一套通用的阿拉伯语语音和文本处理方法，并基于FastConformer架构训练了两个新型模型：一个专用于MSA，另一个是首个统一支持MSA和古典阿拉伯语（CA）的公共模型。

Result: MSA模型在相关数据集上达到了最先进（SOTA）性能，刷新了基准；统一模型在CA上实现了带变音符号的SOTA准确率，同时保持了MSA的强大性能。为促进可复现性，模型及训练方案已开源。

Conclusion: 本研究成功开发了高性能的阿拉伯语ASR模型，有效解决了当前该领域面临的挑战，特别是填补了统一处理MSA和CA的空白，并通过开源促进了该领域的未来发展和可复现性。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [39] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM是一个利用大型语言模型（LLMs）进行人类移动性预测和推理的框架，通过分层时间标记化和冻结LLM骨干，在提高预测准确性的同时显著减少了训练时间。


<details>
  <summary>Details</summary>
Motivation: 旨在利用大型语言模型（LLMs）作为时空预测器和轨迹推理器来分析和预测人类移动行为，以克服现有方法的局限性并提升效率和准确性。

Method: RHYTHM框架将轨迹分割成每日片段，编码为具有分层注意力的离散令牌，以捕捉日内和周内依赖性并缩短序列长度。通过冻结的LLM为令牌表示丰富预计算的提示嵌入，从而提高模型捕捉相互依赖性的能力，同时显著提升计算效率。

Result: 在三个真实世界数据集上的评估表明，与现有最佳方法相比，RHYTHM的准确率提高了2.4%，周末准确率提高了5.0%，训练时间减少了24.6%。

Conclusion: RHYTHM是一个高效且准确的人类移动性预测和推理框架，通过创新地结合LLM、分层时间标记化和冻结模型技术，在计算效率和预测性能上均取得了显著提升，尤其在周末数据上表现突出。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [40] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 本研究提出认知成对比较分类模型选择（CPC-CMS）框架，用于文档级情感分析，通过加权评估标准选择最佳分类模型。


<details>
  <summary>Details</summary>
Motivation: 为文档级情感分析提供一个系统化的模型选择框架，以根据多维度评估标准（包括效率）选择最佳分类模型。

Method: 提出了CPC-CMS框架；利用基于专家判断的认知成对比较（CPC）方法计算准确率、精确率、召回率、F1分数、特异性、MCC、Kappa和效率等评估指标的权重；选择了朴素贝叶斯、LSVC、随机森林、逻辑回归、XGBoost、LSTM和ALBERT作为基线模型；构建加权决策矩阵来选择最佳模型；并在三个开放的社交媒体数据集上进行了验证。

Result: 仿真结果显示，排除时间因素时，ALBERT在三个数据集上表现最佳；若考虑时间消耗，没有单一模型始终优于其他模型。验证了所提出CPC-CMS框架的可行性。

Conclusion: CPC-CMS框架是文档级情感分析中选择最佳分类模型的有效且可行的方法，且可推广应用于其他分类任务，模型选择结果取决于是否考虑时间效率。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [41] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文全面评估了成本效益型大型语言模型（LLMs）在多样化生物医学任务（涵盖文本和图像）中的表现。研究发现没有单一模型能在所有任务上持续领先，而是不同模型擅长不同任务。此外，开源LLMs在某些任务上可与闭源模型媲美甚至更优，并提供更快的推理和更强的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 全面评估成本效益型大型语言模型（LLMs）在多样化生物医学任务（涵盖文本和图像模态）中的性能。

Method: 评估了一系列闭源和开源大型语言模型，并在生物医学文本分类、文本生成、问答以及多模态图像处理等任务上进行了实验。

Result: 1. 没有单一的LLM能够在所有任务上持续优于其他模型，而是不同LLM在不同任务中表现出色。
2. 尽管一些闭源LLM在特定任务上表现出色，但其开源对应模型能够取得可比（有时甚至更好）的结果，并具有更快的推理速度和增强的隐私性等额外优势。

Conclusion: 实验结果为针对特定生物医学应用选择最合适的模型提供了有价值的见解。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [42] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 提出协作理性言语行为（CRSA）框架，一个信息论扩展的RSA模型，用于优化多轮协作对话中AI代理的协同行为。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在承担协作角色时，不仅需要生成流畅的语言，更需推理共享目标和信念。尽管理性言语行为（RSA）框架能进行语用推理，但其现有扩展在多轮协作场景中面临扩展性挑战。

Method: 引入协作理性言语行为（CRSA），它是RSA的一个信息论（IT）扩展。CRSA通过优化一个改编自速率失真理论的增益函数来建模多轮对话，该增益函数考虑了对话双方拥有私有信息并根据对话生成话语的场景。

Result: 在指示性游戏和医学领域的模板化医患对话中验证了CRSA的有效性。实证结果表明，CRSA比现有基线模型产生更一致、可解释和协作的行为。

Conclusion: CRSA为开发更具语用和社交意识的语言智能体铺平了道路。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [43] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: DENSE系统通过整合散落在电子健康记录中的异构笔记，利用大型语言模型生成时间连贯且临床一致的患者进展记录，弥补了现有数据集的空白，并提升了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 进展记录对理解患者病情演变至关重要，但在大型电子健康记录（EHR）数据集中严重不足（如MIMIC-III中仅约8.56%的就诊包含进展记录），导致患者纵向叙述信息缺失。

Method: 提出DENSE系统，模拟医生撰写进展记录的工作流。该系统通过细粒度笔记分类和时间对齐机制组织异构笔记，利用临床知情的检索策略识别当前和过往就诊中相关的证据，并以此提示大型语言模型（LLM）生成临床连贯且时间感知的进展记录。

Result: 在多就诊患者队列上评估，生成的笔记表现出强大的纵向保真度，时间对齐比率为1.089，超越了原始笔记的连续性。

Conclusion: DENSE系统通过恢复碎片化文档的叙述连贯性，支持改进如总结、预测建模和临床决策支持等下游任务，为现实医疗环境中LLM驱动的笔记合成提供了可扩展的解决方案。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [44] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: 该研究评估了语言模型在将生物医学文献转化为普通语言方面的潜力，发现顶级模型在准确性和完整性上可与人类媲美，但在简洁性上仍有不足，并强调了改进自动化评估工具的需求。


<details>
  <summary>Details</summary>
Motivation: 语言模型在将专业生物医学文献转化为普通语言方面展现出潜力，但由于其不可预测性及该领域潜在的高风险，需要进行严格评估。本次研究旨在激发相关研究并对最有前景的系统进行高质量评估。

Method: 研究者在2023年和2024年文本检索会议上主办了“生物医学摘要平易语言改编（PLABA）”赛道。任务包括：任务1（完整、句子级的摘要改写）和任务2（识别和替换难懂词汇）。任务1采用四套专业编写的参考文本进行自动评估，而任务1和任务2的提交结果均由生物医学专家进行大量人工评估。

Result: 共有来自12个国家的12支团队参与。在任务1的人工评估中，表现最佳的模型在事实准确性和完整性方面可与人类水平匹敌，但在简洁性方面有所不足。自动、基于参考的指标与人工判断的相关性普遍不佳。在任务2中，系统在识别难懂词汇和分类替换方式方面表现不佳；然而，在生成替换词时，基于大型语言模型（LLM）的系统在人工评估的准确性、完整性和简洁性方面表现良好，但在简洁性方面仍有欠缺。

Conclusion: PLABA赛道展示了使用大型语言模型改编生物医学文献以供公众理解的潜力，同时也揭示了其不足之处以及对改进自动化基准测试工具的需求。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 这篇综述论文全面探讨了无人机航空场景中的开放词汇目标检测（OVOD），涵盖了其核心原理、现有方法、数据集、面临的挑战以及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的无人机航空目标检测方法受限于预定义类别，而跨模态文本-图像对齐技术（如CLIP）实现了开放词汇目标检测（OVOD），能够识别未曾见过的物体，极大地提升了无人机在航空场景理解中的智能性和自主性。因此，需要对无人机航空场景中的OVOD进行全面综述。

Method: 该研究首先将OVOD的核心原理与无人机视觉的独特特性相结合，然后构建了一个系统化的分类法来归类现有的航空图像OVOD方法，并提供了相关数据集的全面概述。在此基础上，批判性地剖析了该领域交叉的关键挑战和开放问题，并基于分析提出了未来有前景的研究方向和应用前景。

Result: 本综述为无人机航空场景中的开放词汇目标检测提供了一个全面的概述，包括方法的系统分类、数据集的整合、关键挑战的深入分析以及未来研究方向的展望。旨在为该领域的入门者和资深研究人员提供清晰的路线图和宝贵的参考。

Conclusion: 该综述为无人机航空图像中的开放词汇目标检测领域提供了全面的洞察和指导，为研究人员提供了一个清晰的路线图和有价值的参考，以促进该快速发展领域的创新。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [46] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种名为EDNIG的新型深度学习框架，用于低光图像增强，该框架基于U-Net并引入了光照引导和多尺度特征提取，在GAN框架下优化，实现了高SOTA性能和低模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强领域的挑战，旨在开发一个既能有效提升图像质量，又能保持较低模型复杂度的深度学习框架，以适应真实世界应用。

Method: EDNIG基于U-Net架构，通过引入源自亮通道先验（BCP）的光照图作为引导输入，聚焦欠曝光区域。为提升表征能力，模型集成了空间金字塔池化（SPP）模块以提取多尺度上下文特征，并采用Swish激活函数促进平滑梯度传播。该框架在生成对抗网络（GAN）下优化，采用结合对抗损失、像素级均方误差（MSE）和感知损失的复合损失函数。

Result: 实验结果表明，EDNIG在定量指标和视觉质量上均达到了与当前最先进方法相当的竞争性性能，同时模型复杂度更低。

Conclusion: EDNIG在低光图像增强方面表现出优越的性能和较低的模型复杂度，证明了其在实际应用中的高度适用性。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [47] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: 现有VLM在复杂视觉任务上表现优秀，但在需要连接多个图像区域信息的“非局部视觉推理”任务上表现极差，旗舰模型甚至不及人类水平。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）在复杂视觉任务（如VQA、图表理解）上表现出色，但近期研究表明它们在简单的感知测试中遇到困难。本研究旨在评估VLMs进行非局部视觉推理的能力，即需要整合图像中多个（可能相距遥远）区域证据的推理。

Method: 研究者构建了一套评估VLMs非局部视觉推理能力的测试，并隔离了三种不同的非局部视觉形式：比较感知（需在工作记忆中比较两张图像）、眼跳式搜索（需进行离散、证据驱动的跳跃搜索）和平滑视觉搜索（需沿连续轮廓平滑搜索）。

Result: 即使是旗舰VLM（如Gemini 2.5 Pro、Claude Vision 3.7、GPT-o4-mini），包括那些在先前原始视觉基准上表现良好的模型，在这些测试中均表现不佳，在人类看来微不足道的两项任务变体上仅略高于随机准确率。

Conclusion: 研究结果表明，尽管当前VLMs在原始视觉敏锐度上有所提高，但它们仍然缺乏核心的视觉推理能力，无法执行类似于人类的视觉算法。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [48] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 本研究通过结构化CoT提示和强化学习（GRPO）提升VLM的空间推理能力。发现简单CoT无效，而基于场景图的CoT显著改善推理准确性。GRPO在空间推理上优于监督微调（SFT），特别是在泛化性和OOD鲁棒性方面，因为它能避免SFT对表层语言模式的过拟合。


<details>
  <summary>Details</summary>
Motivation: 提升并深入理解视觉-语言模型（VLMs）的空间推理能力，并探索Chain-of-Thought（CoT）提示和强化学习在此方面的有效性。

Method: 1. 评估不同的CoT提示策略，包括简单CoT和基于场景图的结构化多阶段提示（SceneGraph CoT）。2. 使用组相对策略优化（GRPO）在SAT数据集上微调模型，并在CVBench上进行性能评估，与监督微调（SFT）进行对比。

Result: 1. 简单CoT提示策略不仅无效，甚至可能损害模型性能。2. 基于场景图的结构化CoT（SceneGraph CoT）显著提高了空间推理准确性。3. 相较于SFT，GRPO在Pass@1评估中实现了更高的准确率，并在分布外（OOD）条件下展现出卓越的鲁棒性。4. SFT容易过度拟合表层语言模式，在测试措辞变化时性能会下降；而GRPO能更可靠地泛化并保持稳定性能。

Conclusion: 强化学习和结构化提示能够有效提高现代视觉-语言模型的空间推理能力及其泛化行为。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [49] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 该研究利用2D视觉-语言基础模型，在无需人工标注3D数据的情况下，实现了开放词汇3D物体检测。


<details>
  <summary>Details</summary>
Motivation: 现有3D物体检测数据集受限于狭窄的类别分类和高昂的人工标注成本，难以扩展到开放世界环境。而2D视觉-语言模型通过大规模图文对训练，展现出丰富的语义理解和开放词汇检测能力。

Method: 研究提出了一个管道：首先使用2D视觉-语言检测器生成文本条件的提议，然后通过SAM进行分割，并利用相机几何和LiDAR或单目伪深度将其反投影到3D空间。接着，引入了一种基于DBSCAN聚类和旋转卡尺的几何膨胀策略，以无需训练的方式推断3D边界框。此外，为了模拟恶劣的真实世界条件，构建了名为Pseudo-nuScenes的雾增强、纯RGB的nuScenes数据集变体。

Result: 实验证明，该方法在多种设置下（包括基于LiDAR和纯RGB-D输入）均实现了有竞争力的定位性能，且保持了免训练和开放词汇的特性。

Conclusion: 研究结果突显了2D基础模型在可扩展3D感知领域中尚未开发的巨大潜力。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [50] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 本文提出一种新颖的多模态多任务网络及其训练算法，能够处理约12种不同模态的数据，并通过模态特化分词器、共享Transformer和交叉注意力机制将数据映射到统一嵌入空间，在多任务场景中实现先进（SOTA）性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在单一框架内有效处理和整合来自多种模态数据，并在多种相关任务上实现优异性能的挑战。

Method: 核心方法是一个新颖的多模态多任务网络。该网络支持处理约12种不同模态的数据（如图像、视频、音频、文本等），通过模态专用分词器、共享Transformer架构和交叉注意力机制，将不同模态数据投影到统一的嵌入空间。针对多任务场景，它整合了模态特定的任务头。此外，还提出了一种新的预训练策略（迭代模态切换）和一种训练算法，该算法在所有模态的完全联合训练与成对模态训练之间进行权衡。

Result: 研究在来自12种模态的25个数据集上进行了全面评估，结果显示其取得了最先进（SOTA）的性能。

Conclusion: 该研究验证了所提出的网络架构、预训练策略和适应性多任务训练方法的有效性。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [51] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 论文提出一种基于Transformer的端到端深度学习框架，结合光学动作捕捉技术，用于医疗康复。该框架能处理动作数据噪声和缺失，并实时检测异常动作，为远程康复提供可扩展且经济高效的方案。


<details>
  <summary>Details</summary>
Motivation: 提升医疗康复效率；解决光学动作捕捉数据中因遮挡和环境因素造成的噪声与缺失问题；实时检测异常动作以保障患者安全；提供可扩展、成本效益高的远程康复解决方案。

Method: 提出一个端到端的深度学习框架，将光学动作捕捉与基于Transformer的模型集成；利用时序序列建模去噪并补全动作捕捉数据。

Result: 在数据重建和异常检测方面表现出卓越性能；在中风和骨科康复数据集上评估结果优于现有方法；提高了数据鲁棒性。

Conclusion: 提供了一个可扩展、成本效益高的远程康复解决方案，有助于减少现场监督。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [52] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 集成Vision Transformers (ViT) 和 Graph Neural Networks (GNN) 的创新框架提高了乳腺癌检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性主要死因，早期检测对提高生存率至关重要。

Method: 提出并使用一个结合Vision Transformers (ViT) 和 Graph Neural Networks (GNN) 的创新框架，利用CBIS-DDSM数据集进行乳腺癌检测。

Result: 该框架实现了84.2%的准确率，超越了传统方法。同时，提供了可解释的注意力热图以洞察模型决策。

Conclusion: 所提出的ViT-GNN框架显著提升了乳腺癌检测的准确性和可解释性，有望辅助放射科医生进行临床诊断。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [53] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: 针对自动驾驶目标检测中现有方法难以保持跨尺度特征一致性及平衡精度效率的问题，本文提出Butter框架。该框架通过频率自适应特征一致性增强（FAFCE）和渐进式分层特征融合网络（PHFFNet）两大创新，提升分层特征表示，从而显著提高检测精度并降低模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的目标检测需对多层级语义有深刻理解，但现有架构（如YOLO、DETR）在不同尺度间难以保持特征一致性，且难以同时兼顾检测精度和计算效率，这限制了其在动态环境下的鲁棒性。

Method: 本文提出了Butter框架。该框架包含两项核心创新：
1. 频率自适应特征一致性增强（FAFCE）组件：通过自适应频率滤波精炼多尺度特征的一致性，从而提升结构和边界的精度。
2. 渐进式分层特征融合网络（PHFFNet）模块：渐进式整合多层级特征，旨在弥补语义鸿沟并强化分层特征学习。

Result: 在BDD100K、KITTI和Cityscapes数据集上的广泛实验表明，Butter展现出卓越的特征表示能力，显著提升了检测精度，同时有效降低了模型复杂度。

Conclusion: Butter通过对分层特征的有效精炼和整合，为实时自动驾驶场景下的目标检测提供了一种先进解决方案，成功在精度、可部署性和计算效率之间取得了良好平衡。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [54] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的智能路由系统，用于多模态视频检索，能动态选择最优模态以提高效率和降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有密集文本字幕方法成本高昂，需要离线处理，并且会遗漏视频中未被ASR捕获的关键视觉信息（如场景文本）。

Method: ModaRoute利用GPT-4.1分析查询意图并预测信息需求，智能地将查询路由到ASR（语音）、OCR（文本）和视觉索引等模态，平均每个查询仅使用1.78种模态，而非穷举式的3.0种模态搜索。

Result: 该系统在实现60.9% Recall@5的同时，将计算开销降低了41%。在180万个视频片段上的评估表明，它能有效降低基础设施成本，并保持有竞争力的检索效果。

Conclusion: 智能路由为扩展多模态检索系统提供了一个实用且可扩展的解决方案，能够在降低基础设施成本的同时，保持在实际部署中的竞争力。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [55] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 这篇综述深入分析了工业缺陷检测技术，涵盖2D和3D模式下的闭集与开集方法，强调了开集技术的重要性，并探讨了实际挑战与新兴趋势。


<details>
  <summary>Details</summary>
Motivation: 传统缺陷检测方法难以满足现代工业对精度、自动化和可扩展性的高要求。尽管计算机视觉和深度学习取得了显著进展，但仍缺乏对工业缺陷检测（特别是从闭集到开集的转变）的连贯和最新理解。

Method: 本文作为一篇综述，对2D和3D模式下的闭集和开集缺陷检测策略进行了深入分析，梳理了其近年来的发展，并提炼了实际检测环境中的关键挑战和新兴趋势。

Result: 本综述提供了一个工业缺陷检测领域的当前和全面视图，突出了开集技术的日益重要性，并揭示了实际应用中的关键挑战和新兴趋势。

Conclusion: 本文为快速发展的工业缺陷检测领域提供了一个全面且最新的视角，有助于深化对2D和3D模式下闭集与开集检测策略演进的理解，并指出了该领域面临的挑战与未来趋势。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [56] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 研究表明，将光学图像与额外地理数据融合可显著提升卫星机器学习模型性能，尤其在数据稀缺和域外泛化场景下；硬编码融合策略表现优于学习型。


<details>
  <summary>Details</summary>
Motivation: 尽管存在大量地理空间数据，但大多数卫星图像机器学习模型（SatML）仅依赖光学输入。本研究旨在探究在监督学习中，融合光学图像与其它地理输入模态的价值。

Method: 通过将额外的地理数据层（如DEM、土地覆盖图、环境传感器数据等）附加到现有的分类、回归和分割卫星图像机器学习基准数据集上，创建了增强数据集。在此基础上，评估了不同融合策略对模型性能的影响。

Result: ['融合额外地理输入与光学图像能显著提升卫星图像机器学习模型的性能。', '这种性能提升在标记数据有限和地理域外（out-of-sample）场景中最为显著，表明多模态输入对SatML模型的数据效率和泛化能力具有重要价值。', '令人惊讶的是，硬编码的融合策略表现优于学习型融合策略。']

Conclusion: 通过融合光学图像与多源地理数据，可显著提升卫星图像机器学习模型的性能，特别是在数据稀缺和提高泛化能力方面。此外，研究发现简化的硬编码融合方法比复杂的学习型方法更有效，为未来多模态卫星机器学习研究提供了新思路。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [57] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 本文提出一种基于生成输出分布距离的极简概念擦除方法，通过可微分优化和神经元掩蔽，在不损害模型整体性能的情况下，鲁棒地擦除生成模型中的不良概念。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型依赖大规模无标签数据，引发安全和版权担忧。尽管概念擦除方法有潜力解决这些问题，但多数现有方法过度修改模型，损害了其整体效用。

Method: 本研究提出一种基于最终生成输出分布距离的极简概念擦除目标，并推导了一个可微分优化的可行损失函数，实现端到端的反向传播。为提高擦除鲁棒性，引入神经元掩蔽作为模型微调的替代方案。

Result: 在最先进的流匹配模型上进行实证评估，结果表明该方法能够鲁棒地擦除概念，且不降低模型的整体性能。

Conclusion: 本研究为开发更安全、更负责任的生成模型铺平了道路，实现了概念擦除的同时保持了模型效用。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [58] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 为解决3D语义占据预测数据标注成本高的问题，本研究提出了一种新颖的框架，通过利用大规模二元占据数据进行预训练和学习型自动标注，有效提升了3D语义占据预测的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要精确的环境感知，其中3D占据预测（尤其是3D语义占据预测）至关重要。然而，3D语义占据预测需要昂贵的标注LiDAR点云数据。相比之下，大规模二元占据数据成本较低，但其在提升3D语义占据预测方面的潜力尚未被充分探索。

Method: 研究从预训练和基于学习的自动标注两个角度探索了大规模二元占据数据的利用。提出了一种新颖的基于二元占据的框架，将预测过程分解为二元和语义占据模块，从而有效利用二元占据数据。

Result: 实验结果表明，所提出的框架在预训练和自动标注任务中均优于现有方法。

Conclusion: 该研究证实了所提出的框架在增强3D语义占据预测方面的有效性，通过利用大规模二元占据数据显著提升了性能。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [59] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 本文提出InSyn（基于Transformer的模型）和SSOS（训练策略），用于准确预测行人轨迹，尤其在高密度场景下表现优异，并有效减少了初始步预测误差。


<details>
  <summary>Details</summary>
Motivation: 行人轨迹预测面临挑战，现有方法主要依赖相对位置建模交互，但忽略了具体交互模式（如结伴行走或冲突），限制了在拥挤场景中的预测精度。

Method: 提出InSyn（Interaction-Synchronization Network），一个新型Transformer模型，显式捕捉多样交互模式（如同步或冲突行走），并有效建模方向敏感的社交行为。此外，引入SSOS（Seq-Start of Seq）训练策略，旨在缓解时间序列预测中常见的初始步发散问题。

Result: 在ETH和UCY数据集上的实验表明，模型显著优于现有基线，尤其在高密度场景下表现更佳。SSOS策略有效提升了序列预测性能，将初始步预测误差减少了约6.58%。

Conclusion: InSyn模型结合SSOS训练策略能有效捕捉复杂的行人交互模式，显著提高行人轨迹预测的准确性，尤其适用于高密度场景，并能有效解决初始步预测发散问题。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [60] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: 提出MADI框架，通过引入MAgD训练策略和推理时暂停标记，显著增强扩散模型在接地视觉编辑和组合控制方面的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成方面取得了巨大成功，但其在接地视觉编辑和组合控制方面的效率仍具挑战性。

Method: 本文提出了Masking-Augmented Diffusion with Inference-Time Scaling (MADI) 框架，包含两项核心创新：
1. Masking-Augmented gaussian Diffusion (MAgD)：一种新型训练策略，结合了标准去噪分数匹配和通过掩码噪声输入进行的重建，旨在学习判别性和组合性视觉表示。
2. Pause Tokens：一种基于暂停标记的推理时容量扩展机制，通过在提示词中插入特殊占位符来增加计算容量。
此外，研究发现训练期间采用富有表达性和密集的提示可进一步提升模型性能。

Result: MADI框架显著增强了扩散模型的可编辑性、组合性和可控性。特别是MAgD在结合表达性强的密集提示时，性能提升尤为显著。

Conclusion: MADI的贡献大幅提升了扩散模型的可编辑性，为将其整合到更通用、上下文相关的生成扩散架构中铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [61] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR:  प्रस्तुत了一个用于驾驶员困倦检测的综合性多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员困倦数据集缺乏全面性，本研究旨在创建整合生理、行为及驾驶信号的更广泛、连续性强的数据集。

Method: 受试者：19人（15男4女），在清醒及困倦状态下采集数据。数据类型：包括3D面部视频、红外视频、后部视频、心率、EDA、血氧饱和度、皮肤温度、加速度计等生物信号，以及方向盘握力与模拟驾驶遥测数据。标注方式：每4分钟采用KSS自报困倦水平。实验环境：三显示器模拟驾驶。数据集特点：每受试者40分钟连续数据，总长1400分钟，记录困倦状态渐变而非离散标签。

Result: 成功构建了总计1400分钟的大规模、多模态、连续性强的驾驶员困倦数据集，该数据集能够捕捉驾驶员状态的渐进变化，弥补了现有数据集的不足。

Conclusion: 本研究提供的综合多模态驾驶员困倦数据集是未来该领域研究的宝贵资源，有望推动驾驶员困倦检测技术的发展。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [62] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种基于扩散模型的方法，能从CT/MRI图像直接生成用于CFD分析的平滑高质量3D主动脉网格，减少了数据依赖和手动干预。


<details>
  <summary>Details</summary>
Motivation: 现有的3D主动脉重建方法依赖大量标注数据和人工干预，且难以生成几何一致、适合CFD分析的表面，阻碍了血流动力学参数的准确估计。

Method: AortaDiff框架利用体素引导的条件扩散模型生成主动脉中心线，然后以中心线点为提示提取血管轮廓，最后将轮廓拟合成平滑的3D表面，生成CFD兼容网格。

Result: AortaDiff实现了端到端工作流，极少依赖标注数据，能生成高几何保真度的CFD兼容主动脉网格。即使在有限训练数据下，也能有效构建正常和病变（如动脉瘤、主动脉缩窄）的主动脉网格。

Conclusion: AortaDiff为心血管研究提供了一种实用的解决方案，能够生成高质量的可视化和CFD兼容的主动脉模型。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [63] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: 提出COREVQA基准测试，揭示现有VLM在密集人群图像上进行视觉蕴涵推理能力的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有VLM基准主要评估视觉问答（VQA），但很少测试模型在复杂（如拥挤）图像上进行视觉蕴涵（接受或驳斥假设）推理的能力，导致评估不全面。

Method: 提出COREVQA基准，包含5608对图像和合成的真/假语句。图像来源于CrowdHuman数据集，旨在评估模型在拥挤场景下的视觉蕴涵推理能力。

Result: 即使是表现最佳的VLM，在COREVQA上的准确率也低于80%，其他模型表现更差（39.98%-69.95%）。

Conclusion: 当前VLM在处理拥挤场景下的特定图像-问题对时，其推理能力存在显著局限性。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [64] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: 针对AI生成图像的识别与防伪，本文提出IConMark，一种在生成过程中嵌入可解释语义概念的鲁棒水印方法，有效对抗对抗性攻击并提高检测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速发展，区分AI生成图像和真实图像对于打击虚假信息和确保数字真实性至关重要。传统水印技术易受对抗性攻击影响，有效性不足。

Method: 提出IConMark，一种新颖的在生成过程中嵌入可解释概念的鲁棒语义水印方法。它通过融入有意义的语义属性而非噪声或扰动来工作，使水印对人类可解释且能抵抗对抗性操纵。该方法还可与现有水印技术（如StegaStamp和TrustMark）结合形成混合方法（IConMark+SS, IConMark+TM）以增强鲁棒性。

Result: IConMark在检测准确性和图像质量保持方面表现出优越性，且能抵抗多种图像增强。其基础技术和变体（+TM和+SS）在水印检测方面，相较于最佳基线，平均AUROC分数分别提高了10.8%、14.5%和15.9%。

Conclusion: IConMark提供了一种有效、鲁棒且可解释的水印解决方案，用于AI生成图像的识别，能有效应对虚假信息挑战并增强数字真实性。其人可读性与优异性能预示着水印技术向前迈出了重要一步。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [65] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: 开发了一种基于多模型深度学习集成系统，用于在肩部X光片中高精度检测骨折。


<details>
  <summary>Details</summary>
Motivation: 肩部骨折常被漏诊，特别是在急诊环境下，AI工具能够辅助早期检测并减少诊断延误。

Method: 开发了多模型深度学习系统，使用了10,000张标注的肩部X光片。模型架构包括Faster R-CNN、EfficientDet和RF-DETR，并应用了Soft-NMS、WBF和NMW等边界框与分类级别集成技术。

Result: NMW集成模型取得了95.5%的准确率和0.9610的F1分数，优于所有独立模型，并展现出强大的召回率和定位精度。

Conclusion: 该集成AI系统能可靠地检测肩部X光片中的骨折，具有高临床相关性，适合集成到实时诊断工作流中。当前模型局限于二分类骨折检测。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [66] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过将深度学习模型与旧的CORONA卫星图像结合，显著提升了在已发生重大变化的地区自动识别考古遗址的能力，并成功发现了新遗址。


<details>
  <summary>Details</summary>
Motivation: 在近五十年内环境发生剧烈变化（包括许多遗址被完全摧毁）的地区，利用AI模型自动识别考古遗址，特别是那些传统方法无法发现的遗址。

Method: 将一个基于Bing的卷积神经网络模型，利用来自阿布格莱布地区的CORONA卫星图像（上世纪60年代）进行了再训练。

Result: 考古遗址检测的精确度显著提高，图像分割级别的交并比（IoU）超过85%，总体准确率达到90%。此外，该模型还成功识别了四个此前未被发现的新考古遗址（已通过实地验证）。

Conclusion: 证实了利用AI技术结合1960年代的CORONA图像来发现目前已不可见的考古遗址的有效性，这对于研究受人类活动影响而考古证据正在消失的景观具有重要意义和突破性进展。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [67] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: 本文提出CaSTFormer，一个因果时空Transformer模型，用于准确预测驾驶意图，通过显式建模驾驶行为与环境之间的因果交互，解决了现有方法在复杂时空依赖和行为变异性建模上的不足。


<details>
  <summary>Details</summary>
Motivation: 准确预测驾驶意图是提升人机共驾系统安全与交互效率、实现高级别自动驾驶的关键。然而，当前方法在精确建模人类驾驶行为复杂的时空相互依赖性和不可预测性方面仍显不足。

Method: 本文提出CaSTFormer，一个因果时空Transformer，用于显式建模驾驶行为和环境上下文之间的因果交互，以实现鲁棒的意图预测。具体地，CaSTFormer引入了新颖的互惠位移融合（RSF）机制以实现精确的时间对齐，一个因果模式提取（CPE）模块系统性地消除虚假关联以揭示真实的因果依赖，以及一个创新的特征合成网络（FSN）以自适应地将这些纯化表示合成为连贯的时空推断。

Result: CaSTFormer在公共Brain4Cars数据集上进行了评估，并取得了最先进的性能。它有效捕获了复杂的因果时空依赖。

Conclusion: CaSTFormer显著提高了驾驶意图预测的准确性和透明度。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [68] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: 本文提出了PhyWorldBench，一个用于评估视频生成模型物理真实性的综合基准，包括新颖的“反物理”类别，并对现有SOTA模型进行评估，揭示了它们在物理模拟方面的关键挑战，并提供了提示优化建议。


<details>
  <summary>Details</summary>
Motivation: 尽管视频生成模型在创建高质量内容方面取得了显著进展，但其准确模拟物理现象的能力仍然是一个关键且尚未解决的挑战。

Method: 本文提出了PhyWorldBench，一个旨在根据模型对物理定律的遵循程度来评估视频生成模型的综合基准。该基准涵盖从基本原理（如物体运动、能量守恒）到复杂场景（如刚体相互作用、人类或动物运动）的多个物理现象。此外，引入了一个“反物理”类别，通过故意违反物理的提示来评估模型遵循指令和保持逻辑一致性的能力。除了大规模人工评估外，还设计了一种利用现有MLLM进行零样本物理真实性评估的有效方法。研究者评估了12个最先进的文本到视频生成模型，并使用1050个精心策划的提示进行系统测试。

Result: 研究者识别出模型在遵循真实世界物理规律方面面临的关键挑战。通过对1050个策划提示（涵盖基本、复合和反物理场景）的系统测试，详细比较和分析了不同模型的输出。在各种物理现象和不同提示类型下严格检验了模型的性能。

Conclusion: 根据系统测试结果，本文为提升视频生成模型对物理原理的忠实度提出了有针对性的提示优化建议。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [69] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 提出一种自校准不确定性量化框架，解决了摄影测量MVS阶段的误差估计难题，为点云提供可靠的逐点精度，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 摄影测量点云精度高度依赖场景，且MVS阶段的不确定性量化因其非可微和多模态特性而未被充分解决，导致难以提供精确的逐点精度凭证。

Method: 提出一个不确定性量化框架，通过为每个点关联一个误差协方差矩阵来量化SfM和MVS两阶段摄影测量过程的误差。针对MVS阶段，开发了一种新颖的自校准方法，利用每视图中可靠的多视图点(n>=6)和MVS相关线索（如匹配代价）来回归视差不确定性。该方法自监督、遵循误差传播路径，且直接利用MVS过程提取的3D点。

Result: 在多种公开航空和无人机图像数据集上的评估显示，该方法在不夸大不确定性的前提下，实现了高边界率，性能优于现有方法。

Conclusion: 本文框架有效解决了MVS阶段的不确定性量化难题，为摄影测量点云提供了鲁棒且可验证的逐点精度，在不同场景下均表现出色。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [70] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 本研究提出一种无监督的3D卷积自编码器模型，结合时间编码，利用卫星图像时序数据检测甜菜田的胁迫，并可应用于不同年份的数据。


<details>
  <summary>Details</summary>
Motivation: 卫星图像时序（SITS）数据在农业任务中表现出色，本研究旨在利用其丰富的光谱和时间特性，以完全无监督的方式解决甜菜田的胁迫检测问题。

Method: 提出一个3D卷积自编码器模型，用于从Sentinel-2图像序列中提取有意义的特征。该模型结合了采集日期特定的时间编码，以更好地捕捉甜菜的生长动态。学习到的表示随后用于下游聚类任务，以区分受胁迫和健康的田地。

Result: 开发出的胁迫检测系统可以直接应用于不同年份的数据。

Conclusion: 该系统为甜菜胁迫检测提供了一个实用且易于获取的工具。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [71] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: 该研究引入了SparseC-AFM深度学习模型，能从稀疏的C-AFM扫描数据中快速准确地重建二维材料（如MoS2）的电导率图，显著缩短了数据采集时间，同时保持了高精度，有助于二维材料的工业化表征。


<details>
  <summary>Details</summary>
Motivation: 随着二维材料在纳米电子学中应用的增加，对其进行稳健的电学表征技术需求迫切。传统高精度原子力显微镜（AFM）技术（如C-AFM）因光栅扫描过程耗时过长，不适用于大规模生产。

Method: 开发了一个名为SparseC-AFM的深度学习模型，用于从稀疏C-AFM扫描数据中快速准确地重建二维材料的电导率图。通过与传统全分辨率C-AFM图像采集和手动解析方法进行对比，评估了其在不同扫描模式、衬底和实验条件下的鲁棒性。

Result: SparseC-AFM能够快速准确地重建电导率图，将数据采集时间从15分钟（传统方法）显著缩短到5分钟以内。与从全分辨率C-AFM图像中手动提取相比，数据采集时间减少了11倍以上。该方法能有效提取MoS2的关键材料参数（如薄膜覆盖率、缺陷密度、晶体岛边界、边缘和裂纹），且模型预测样本的电学性能与全分辨率数据高度一致。

Conclusion: 这项工作是AI辅助二维材料表征从实验室研究向工业制造转化的重要一步，为大规模生产中的二维材料电学表征提供了一种高效、高精度的解决方案。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [72] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 本文提出了一种针对三维三角网格上法向量的二阶广义全变分（TGV）新公式，将法向量视为流形值函数，并为此构建了一个定制的切向Raviart-Thomas型有限元空间。


<details>
  <summary>Details</summary>
Motivation: 现有离散TGV模型主要针对分段常数标量数据。为了将TGV应用于流形值函数（如网格上的法向量）以更好地进行几何处理，需要开发一种新的TGV表述。

Method: 1. 提出了一个针对嵌入在R³中的有向三角网格上法向量的二阶TGV新公式。 2. 将法向量视为单位球面上的流形值函数。 3. 扩展了利用Raviart-Thomas函数空间的先前离散TGV模型。 4. 为适应流形设置，构建了一个定制的切向Raviart-Thomas型有限元空间。 5. 通过网格去噪实验将新正则化器与现有方法进行比较。

Result: 该新正则化器在网格去噪实验中与现有方法进行了比较，表明了其应用潜力和有效性（具体效果需查阅论文正文）。

Conclusion: 论文成功地为网格上的流形值法向量开发并验证了一种新的TGV公式，为网格去噪等任务提供了一种新的正则化工具。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [73] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: NABLA提出一种自适应块级注意力机制，显著提升视频生成Transformer的训练和推理速度，同时保持高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视频生成模型中，全注意力机制的二次复杂度是处理高分辨率和长持续时间视频的关键瓶颈。

Method: 提出NABLA（Neighborhood Adaptive Block-Level Attention），一种动态适应视频扩散Transformer (DiTs) 中稀疏模式的邻域自适应块级注意力机制。该方法通过利用带有自适应稀疏驱动阈值的块级注意力，减少计算开销，并可与PyTorch的Flex Attention无缝集成。

Result: 实验证明，NABLA相较于基线模型，训练和推理速度最高提升2.7倍，同时几乎不影响定量指标（CLIP分数、VBench分数、人工评估分数）和视觉质量。

Conclusion: NABLA成功解决了视频生成Transformer的计算瓶颈，显著提高了效率，同时维持了高质量的生成表现。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [74] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 本研究提出一种LoRA增强的合成回放框架，通过任务特定的低秩适配器（LoRA）优化生成器，从而提高视觉-语言模型（VLM）持续学习中合成样本的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM持续学习合成回放方法依赖Stable Diffusion生成样本，但难以捕获真实世界任务的领域特异性和细粒度语义，导致生成样本与真实数据不符，进而损害模型知识保留。

Method: 该方法提出将任务特定的LoRA适配器注入冻结的Stable Diffusion模型，以高效捕捉新任务的独特视觉和语义模式。它引入了两阶段、基于置信度的样本选择机制：首先根据VLM置信度筛选真实任务数据来微调LoRA，然后生成合成样本并再次基于置信度进行选择以用于蒸馏。

Result: 在多领域任务增量学习（MTIL）基准测试中，该方法超越了以往的合成回放技术，在塑性、稳定性和零样本能力之间取得了最佳平衡。

Conclusion: 研究结果表明，通过LoRA对生成器进行适配，能有效提升视觉-语言模型在持续学习中的鲁棒性。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [75] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 从噪声点云重建精确隐式曲面是挑战。本文提出NoiseSDF2NoiseSDF，受Noise2Noise启发，通过最小化噪声SDF表示间的MSE损失，直接从噪声数据学习干净的神经SDF，显著提升三维曲面重建质量。


<details>
  <summary>Details</summary>
Motivation: 从低质量扫描设备获取的点云通常包含大量噪声，导致隐式曲面重建不准确，这是一个具有挑战性的任务。

Method: 引入NoiseSDF2NoiseSDF方法，将2D图像的Noise2Noise范式扩展到3D神经场。该方法通过最小化噪声SDF表示之间的MSE损失，从噪声点云直接学习干净的神经SDF，从而实现隐式去噪和曲面优化。

Result: 在ShapeNet、ABC、Famous和Real等基准数据集上的实验结果表明，该框架显著提高了从噪声输入中进行曲面重建的质量。

Conclusion: NoiseSDF2NoiseSDF能够有效处理噪声点云的曲面重建问题，通过学习去噪的SDF显著提升了重建精度，为低质量数据下的三维重建提供了有效解决方案。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [76] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型（DM）的无配对图像去模糊框架，通过学习空间变化的纹理先验，在去模糊任务中超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 获取大量真实的模糊-清晰图像对既困难又昂贵，因此从无配对数据中学习盲图像去模糊是一种更实用和有前景的解决方案。现有主流方法过度依赖对抗学习，却忽略了真实世界中复杂且不可预测的模糊模式。

Method: 提出一个名为 \ours 的新型扩散模型（DM）框架，通过学习无配对数据的空间变化纹理先验来去模糊。具体方法包括：1) 利用DM生成有助于恢复模糊图像纹理的先验知识。2) 提出纹理先验编码器（TPE），引入记忆机制来表示图像纹理并为DM训练提供监督。3) 提出纹理迁移Transformer层（TTformer），其中包含新型的滤波器调制多头自注意力（FM-MSA）机制，通过自适应滤波高效去除空间变化的模糊。4) 采用基于小波的对抗损失来保留高频纹理细节。

Result: \ours 提供了一个有前景的无监督去模糊解决方案，并在广泛使用的基准测试中优于现有最先进（SOTA）方法。

Conclusion: 该研究提出的\ours框架通过创新的扩散模型和网络结构，成功利用无配对数据学习空间变化的纹理先验，有效解决了图像去模糊问题，并取得了领先的性能，为无监督去模糊提供了实用且有力的解决方案。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [77] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 针对现有突发SR方法产生模糊图像的问题，本文提出一种基于扩散模型的高效方法，通过高阶ODE随机采样和知识蒸馏实现一步扩散，显著提高运行效率并保持图像质量，生成清晰、高保真的SR图像。


<details>
  <summary>Details</summary>
Motivation: 现有突发低分辨率图像超分辨率（burst SR）方法采用确定性训练，导致生成模糊的超分辨率图像，视觉感知质量差。本研究旨在通过扩散模型重建清晰、高保真的SR图像。

Method: 本文提出的方法通过结合高阶ODE随机采样器和利用知识蒸馏实现一步扩散，从而提高扩散模型的效率，以生成清晰的SR图像。

Result: 实验结果表明，该方法在保持超分辨率图像的失真度和感知质量不变的前提下，成功将运行时间缩短至基线的1.6%。

Conclusion: 本研究成功提出了一种高效的扩散模型方法，解决了现有突发SR方法图像模糊的问题，在生成清晰、高保真SR图像的同时大幅提升了计算效率，兼顾了质量与速度。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [78] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 提出CoTasks框架，通过将复杂视频问题分解为实体级任务，显著提升了视频大语言模型（VideoLLMs）的思维链（CoT）视频推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型（VideoLLMs）缺乏细粒度、对象级的思维链（CoT）推理能力，因其训练数据缺乏支持组合式、逐步推理的结构化标注。

Method: 提出CoTasks框架，将复杂视频问题分解为帧定位、实体追踪、空间关系提取和时间关系提取四个实体级基础任务，并将这些CoT风格的中间推理步骤嵌入输入中，以实现对象中心时空推理。

Result: 在NeXT-QA基准测试中，CoTasks显著提升了模型推理性能：LLaVA-video-7B的GPT-4评估分数提升3.3点，Qwen2.5-VL-3B提升17.4点，尤其在因果、时间和描述子类别中表现突出。

Conclusion: CoTasks作为一种结构化的CoT风格监督框架，能有效增强视频大语言模型的组合式视频推理能力。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [79] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: 本文提出FoELS方法，通过结合光流和纹理信息，解决了移动相机视角下在复杂场景中运动物体检测的难题，并在DAVIS 2016数据集和真实交通视频上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，从移动相机视角分离运动和静止物体对于3D重建、自主导航和场景理解至关重要。然而，现有主要依赖光流的方法在涉及相机运动的复杂、结构化场景中检测运动物体时表现不佳，亟需改进。

Method: 本文提出了Focus of Expansion Likelihood and Segmentation (FoELS) 方法，其核心思想是整合光流和纹理信息。具体步骤包括：从光流计算扩展焦点(FoE)，从FoE计算的异常值中得出初始运动可能性，然后将此可能性与基于分割的先验信息融合，以估计最终的运动概率。

Result: FoELS方法有效处理了复杂结构化场景、旋转相机运动和平行运动等挑战。在DAVIS 2016数据集和真实世界交通视频上的综合评估表明，该方法具有显著的有效性，并达到了最先进的性能。

Conclusion: FoELS通过融合光流和纹理信息，成功克服了移动相机视角下复杂场景中运动物体检测的局限性，实现了卓越的性能，对3D重建、自主导航和场景理解等应用具有重要意义。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [80] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: 本文提出EPSilon，一种高效的混合NeRF人体替身生成方案，通过智能点采样策略显著加速推理和训练，同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 现有混合NeRF模型在生成动画人体替身时，因其形变方案（基于SMPL蒙皮权重）需要对每个采样点进行高计算成本的形变，即使大部分点位于空空间，导致推理速度极慢。

Method: 本文提出EPSilon，通过两种方法忽略空空间点：1) 空射线剔除（ERO），消除穿过空空间的射线；2) 空区间剔除（EIO），缩小射线上采样区间，排除未被衣物或网格占据的区域。这种精细的采样方案不仅减少了形变计算成本，还使得模型能够使用单阶段NeRF结构。

Result: 与现有方法相比，EPSilon在保持生成质量的同时，仅使用3.9%的采样点，实现了约20倍的推理加速和4倍的训练收敛加速。

Conclusion: EPSilon通过创新的高效点采样策略，有效解决了混合NeRF人体替身生成模型推理速度慢的问题，大幅提升了计算效率，同时保持了卓越的生成质量。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [81] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 本文提出了大规模RGB-事件行人重识别数据集EvReID，并提出了一种行人属性引导的对比学习框架TriPro-ReID，以解决事件相机行人重识别领域的数据稀缺问题并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的行人重识别算法主要在小型或模拟数据集上进行训练和评估，难以准确评估其实际识别性能和泛化能力，存在数据稀缺的问题。

Method: 1. 引入并构建了一个大规模RGB-事件行人重识别数据集EvReID，包含118,988对图像和1200个行人身份，覆盖多季节、场景和光照条件。2. 在该数据集上评估了15种最先进的行人重识别算法。3. 基于新构建的数据集，提出了一个名为TriPro-ReID的行人属性引导对比学习框架，该框架有效结合RGB帧、事件流以及行人属性作为中级语义特征，以增强特征学习。

Result: 1. EvReID数据集为事件相机行人重识别的未来研究奠定了坚实的数据和基准基础。2. 在EvReID和MARS数据集上的广泛实验充分验证了所提出的TriPro-ReID RGB-事件行人重识别框架的有效性。

Conclusion: 通过提供一个大规模的RGB-事件行人重识别数据集和提出一个有效的特征学习框架，本文不仅解决了数据稀缺问题，也显著提升了行人重识别的性能，为该领域未来的研究提供了宝贵资源和方法。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [82] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 针对现有图像恢复方法（尤其是基于Transformer的）计算复杂且难以部署的问题，本文提出一种高效且高性能的金字塔小波-傅里叶网络（PW-FNet），在多项任务中实现了优异的图像恢复质量和效率提升。


<details>
  <summary>Details</summary>
Motivation: 自然图像质量常受恶劣天气影响，损害下游任务性能。图像恢复是核心解决方案，但现有基于Transformer的方法复杂度高，难以实时处理和实际部署。此外，现有简化自注意力机制的方法多专注于网络架构，却忽视了图像恢复本身的内在特性。

Method: 提出一种名为金字塔小波-傅里叶网络（PW-FNet）的新颖高效恢复基线。其关键设计原则包括：1) 在块间层面，整合基于金字塔小波的多输入多输出结构，实现多尺度和多频带分解；2) 在块内层面，引入傅里叶变换作为自注意力机制的有效替代，以有效降低计算复杂度并保留全局建模能力。

Result: 在图像去雨、去雨滴、超分辨率、运动去模糊、去雾、去雪以及水下/低光增强等广泛任务上，PW-FNet不仅在恢复质量上超越了现有最先进方法，还在效率上表现出色，显著降低了参数量、计算成本和推理时间。

Conclusion: PW-FNet通过创新的小波-傅里叶处理管道，有效解决了图像恢复领域中性能与效率的平衡问题，为实时处理和实际部署提供了更优的解决方案，证明了小波-傅里叶处理在图像恢复中的巨大潜力。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [83] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: 针对3D手物交互姿态估计的挑战，我们提出了MaskHOI，一个基于MAE的预训练框架，通过区域特定掩码和SDF预测来提升几何感知和遮挡鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB图像估计3D手物交互（HOI）中手和物体的精确关节姿态极具挑战，原因在于RGB图像固有的几何模糊性以及交互过程中严重的相互遮挡。

Method: 提出MaskHOI，一个基于MAE（Masked Autoencoder）的预训练框架。核心思想是利用MAE的掩码-重建策略来推断缺失的空间和结构信息。具体方法包括：1. 区域特定掩码比例分配：根据手部几何复杂性高于刚性物体，对手部区域分配更低的掩码比例；2. 骨架驱动的手部掩码指导：优先掩码关键手部区域（如指尖），以模拟真实遮挡；3. 掩码符号距离场（SDF）驱动的多模态学习机制：通过自掩码3D SDF预测，使编码器感知手和物体的全局几何结构，克服单目输入局限并缓解自遮挡问题。

Result: 广泛的实验表明，我们的方法显著优于现有最先进的方法。

Conclusion: MaskHOI通过其新颖的掩码策略和SDF驱动的学习机制，有效提升了3D手物交互姿态估计的几何感知和遮挡鲁棒性，从而实现了更精确的姿态估计。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [84] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个针对V2X异构传感器配置的协同感知框架，通过分层融合和自适应机制，解决了特征融合挑战，并在真实世界数据集上实现了鲁棒且最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界V2X系统常因成本和部署差异采用异构传感器配置，导致特征融合和感知可靠性面临巨大挑战。

Method: 提出HeCoFuse框架，引入分层融合机制，通过通道和空间注意力自适应加权特征；采用自适应空间分辨率调整模块平衡计算成本和融合效率；实施协同学习策略，根据可用模态动态调整融合类型以增强鲁棒性。

Result: 在TUMTraf-V2X数据集上，HeCoFuse在全传感器配置（LC+LC）下达到43.22% 3D mAP，超越CoopDet3D基线1.17%；在L+LC场景中达到43.38% 3D mAP；并在九种异构配置下保持21.74%至43.38%的3D mAP。该成果在CVPR 2025 DriveX挑战赛中获得第一名。

Conclusion: HeCoFuse确立了其在TUM-Traf V2X数据集上的当前最先进地位，并展示了在多样化传感器部署下的强大鲁棒性能。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [85] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新型高精度高鲁棒性的基于高斯核的视觉运动测量方法，解决了现有方法精度不足或需大量手动调参的问题。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测对高精度运动测量需求日益增长，现有视觉测量方法在亚像素级运动测量中存在精度不足或需要大量手动参数调整的问题。

Method: 开发了一种新颖的基于高斯核的运动测量方法，通过跟踪高斯核的位置提取帧间运动。引入运动一致性和超分辨率约束以提高精度和鲁棒性。

Result: 数值和实验验证表明，该方法能够持续达到高精度，且无需针对不同测试样本进行定制化的参数设置。

Conclusion: 所提出的方法有效解决了现有视觉运动测量在亚像素级精度和参数调优方面的挑战，实现了高精度和高鲁棒性。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [86] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 论文提出了两种用于多目标跟踪（MOT）算法性能评估的准度量，它们是现有GOSPA和T-GOSPA度量的扩展，特点是允许对漏检和虚警目标施加不同惩罚以及非对称的定位成本。通过仿真评估了贝叶斯MOT算法。


<details>
  <summary>Details</summary>
Motivation: 现有GOSPA和T-GOSPA度量在某些MOT应用中缺乏灵活性，特别是在对漏检和虚警目标施加不同成本，以及定位成本不对称的需求方面。

Method: 论文引入了两种准度量：一个是GOSPA度量的扩展，用于衡量目标集差异；另一个是T-GOSPA度量的扩展，用于衡量轨迹集差异。这些准度量包含了定位误差、虚警和漏检的成本，其中T-GOSPA准度量还包括轨迹切换成本。关键创新在于允许漏检和虚警目标具有不同的惩罚成本，且定位成本无需对称。研究通过仿真使用T-GOSPA准度量评估了多种贝叶斯MOT算法的性能。

Result: 所提出的准度量为MOT评估提供了更大的灵活性，能够根据特定应用需求（如对漏检和虚警目标施加不同惩罚或采用非对称定位成本）进行更精确的性能衡量。通过仿真成功展示了T-GOSPA准度量在评估贝叶斯MOT算法性能上的实用性。

Conclusion: 论文成功开发了两种更具灵活性的MOT性能评估准度量，有效弥补了现有GOSPA和T-GOSPA度量的局限性。这些新度量能更好地适应特定应用场景的评估需求，并通过仿真验证了其有效性。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [87] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 本文提出PoemTale Diffusion，一种无需训练的方法，通过结合语言模型的提示词精炼和扩散模型的自注意力机制改进，以生成与诗歌意境一致的图像，并引入了新的P4I数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文生图模型难以准确解释和生成包含复杂、抽象或多重含义的创意文本（特别是诗歌）图像，导致信息丢失。

Method: 引入PoemTale Diffusion，采用多阶段提示词精炼循环与语言模型结合，增强诗歌文本可解释性。通过修改现有扩散模型的自注意力机制，使其能够生成多张一致的图像，共同传达诗歌含义。此外，构建了包含1111首诗歌的P4I数据集。

Result: 通过人类评估和定量评估，验证了该方法的有效性，表明其在生成的图像中能捕获更丰富的信息。

Conclusion: 该研究为诗歌到图像生成提供了新视角，显著提升了生成图像的信息捕获能力，并贡献了P4I数据集以促进相关领域研究。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [88] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 一种为博物馆环境设计的创新增强现实（AR）管道，能从单张图片识别艺术品并生成精确的3D模型。


<details>
  <summary>Details</summary>
Motivation: 旨在识别艺术品并从单张图片生成精确的3D模型，克服艺术品不规则轮廓和可变纹理带来的挑战，从而在博物馆环境中通过交互式数字内容增强参观者体验。

Method: 提出了一种AR管道，整合了GLPN（用于全局深度）和Depth-Anything（用于局部细节重建）两种预训练深度估计算法，以生成优化的深度图。这些深度图随后转换为高质量的点云和网格。该方法利用了最先进的神经网络架构和计算机视觉技术。

Result: 实验结果表明，该系统在重建精度和视觉真实感方面有显著提升。

Conclusion: 该系统是一个高度鲁棒的工具，可有效帮助博物馆通过交互式数字内容提升参观者参与度。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: 提出GraphTrafficGPT，一种基于图的LLM交通管理系统，通过并行执行和图结构化任务协调，显著降低token消耗和延迟，并支持多查询。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的交通管理系统（如TrafficGPT）因链式结构导致顺序执行、高token消耗和可扩展性差，不适用于复杂现实场景。

Method: 提出GraphTrafficGPT，一种图基架构。通过将任务和依赖表示为有向图，并由“大脑代理”协调分解查询、构建优化依赖图和管理专业代理网络，实现并行执行、动态资源分配、上下文感知token管理和并发多查询处理。

Result: 与TrafficGPT相比，GraphTrafficGPT将token消耗降低50.2%，平均响应延迟降低19.0%，且在多查询并发执行方面效率提升高达23.0%。

Conclusion: GraphTrafficGPT通过其创新的图基架构和任务协调机制，有效解决了LLM交通管理系统的效率和可扩展性问题，为城市交通管理提供了更优解决方案。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [90] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette通过将用户偏好分解为可解释的属性维度和社区价值观，实现了更准确的偏好预测，并提供了透明的洞察，优于现有模型如GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在个性化方面面临挑战，因为它们通常将人类判断视为黑箱，无法理解用户偏好背后的深层原因，而这对于真正的个性化至关重要。

Method: PrefPalette框架基于多属性决策原理，通过以下两种方式运作：1) 可伸缩的反事实属性合成，生成合成训练数据以分离个体属性效果；2) 基于注意力的偏好建模，学习不同社会社区如何动态地权衡这些属性，从而捕捉多样化的评估框架。

Result: 在对Reddit上45个社会社区的评估中，PrefPalette的平均预测准确率比GPT-4o高出46.6%。它还揭示了直观的、特定社区的偏好特征，例如学术社区偏爱冗长和刺激，冲突型社区重视讽刺和直接，支持型社区强调同理心。

Conclusion: PrefPalette通过建模人类判断中由属性介导的结构，提供了卓越的偏好建模能力和透明、可解释的洞察，为构建更值得信赖、更注重价值观的个性化AI应用奠定了基础。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [91] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 针对大型语言模型（LLMs）的幻觉和不准确性问题，本文提出一种受控且透明的LLMs专家系统开发方法。该方法通过限定领域、基于提示的提取以及将知识转换为Prolog符号表示，支持人工验证和修正，并结合LLMs的召回能力与符号系统的精确性，实现了高事实准确性和语义连贯性，为敏感领域的可信AI应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在知识型系统（如开放域问答）中取得了显著进展，能自动生成大量看似连贯的信息，但它们存在生成幻觉或自信地产生不正确/无法验证的事实等缺点。

Method: 本文提出一种利用LLMs开发专家系统的新方法，强调受控和透明。具体通过：限定领域、采用结构化的基于提示的提取方法，将知识生成Prolog符号表示，并允许人类专家进行验证和修正。

Result: 通过使用Claude Sonnet 3.7和GPT-4.1进行的定量和定性实验表明，所生成的知识库在事实准确性和语义连贯性方面表现出强大的依从性。

Conclusion: 本文提出了一种透明的混合解决方案，成功结合了大型语言模型的召回能力与符号系统的精确性，从而为敏感领域中可信赖的AI应用奠定了基础。此方法同时保证了专家系统的解释性、可扩展性和可靠性。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [92] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: 本文探讨了人工智能应如何从像素和词汇转向建模实体及其关系，强调了关系学习的重要性，并分析了其未广泛普及的原因及实现其潜力的必要步骤。


<details>
  <summary>Details</summary>
Motivation: 当前AI主要关注感知数据（像素、词汇），但世界本质上由实体及其关系构成。大量有价值的企业数据以关系型格式存在，而非感知型数据，但关系学习领域尚未得到足够重视和发展。

Method: 通过对当前AI发展方向和数据形式的分析，指出现有AI模型与真实世界数据结构（实体、关系）之间的差异。论文进一步解释了关系学习未能广泛普及的原因，并提出了使其达到应有地位的改进方向和必要措施。

Result: 文章揭示了关系学习虽然更符合世界本质和企业数据结构，但除少数限制性应用外，尚未像基于像素和词汇的AI那样普及。其结果是识别了这种未普及的原因，并指明了提升其地位所需的关键行动。

Conclusion: 关系学习是AI领域中一个被低估但至关重要的方向，尤其考虑到大量有价值数据以关系型存在。通过解决其当前局限性并采取必要措施，关系学习有望在AI领域中取得其应有的显著地位。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [93] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 提出BifrostRAG，一种双图混合检索RAG系统，有效处理复杂法规文本中的多跳查询，性能显著优于传统RAG基线。


<details>
  <summary>Details</summary>
Motivation: 自动化合规性检查中的信息检索和问答受制于法规文本的语言和结构复杂性，尤其多跳查询需整合跨条款信息，传统检索增强生成（RAG）系统难以应对。

Method: 引入BifrostRAG系统，通过实体网络图建模语言关系，通过文档导航图建模文档结构。该系统采用混合检索机制，结合图遍历和向量语义搜索，使大型语言模型能同时推理文本的意义和结构。

Result: 在多跳问题数据集上，BifrostRAG的准确率达92.8%，召回率85.5%，F1分数为87.3%，显著优于仅基于向量和仅基于图的RAG基线系统。

Conclusion: BifrostRAG被确立为LLM驱动合规性检查的强大知识引擎，其双图混合检索机制为在知识密集型工程领域中处理复杂技术文档提供了可迁移的蓝图。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [94] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 本研究探索并验证了基于最终答案的自动错误诊断方法，以解决智能辅导系统中学生跳步导致诊断困难的问题，在二次方程数据集上实现了29.4%的诊断率，并与教师诊断高度一致。


<details>
  <summary>Details</summary>
Motivation: 智能辅导系统在诊断学生跳步（将多个步骤合并为一个）时，由于可能路径的组合爆炸导致错误诊断困难。传统的单步规则诊断难以处理这种情况，因此需要一种新的方法来缓解这种复杂性，即利用最终答案进行诊断。

Method: 本研究探索了基于最终答案的自动化错误诊断潜力。具体方法是设计了一个服务，当学生合并多个步骤时，该服务能提供错误规则诊断。为验证该方法，将其应用于一个包含1939个独特学生跳步的现有二次方程求解数据集，这些跳步无法通过连接连续输入的单一规则服务进行诊断。

Result: 研究结果显示，基于最终答案的评估能够诊断29.4%的跳步。此外，在115个子集上与教师诊断进行比较，发现生成的诊断在97%的情况下与教师诊断一致。

Conclusion: 基于最终答案的自动错误诊断方法在处理学生跳步问题上表现出显著潜力，其诊断结果与教师诊断高度吻合，为进一步探索该方法奠定了基础。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [95] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 本研究提出了一种结合模型追踪和基于约束建模的学生分步任务诊断方法，旨在解决学生合并多个步骤时的诊断难题，并通过在二次方程解题数据上的评估，验证了其诊断结果与教师判断高度一致。


<details>
  <summary>Details</summary>
Motivation: 现有的学生分步任务诊断方法（模型追踪和基于约束建模）在学生合并多个步骤时存在局限性。模型追踪擅长识别连续步骤，而基于约束建模能处理合并步骤。研究动机是整合这两种范式，开发一种更鲁棒的诊断方法，即使学生合并步骤也能提供准确诊断。

Method: 研究提出了一种融合模型追踪和基于约束建模的新方法，将约束定义为学生输入与策略步骤的共同属性。为验证概念，系统在一个包含学生解决二次方程步骤的现有数据集（n=2136）上生成了诊断。为与人类诊断进行比较，两位教师对随机抽取的70个偏差和70个策略应用样本进行了编码。

Result: 系统生成的诊断结果与两位教师对所有140个学生步骤的编码完全一致。

Conclusion: 所提出的融合方法能够有效地诊断学生在分步任务中偏离策略的情况，即使学生合并了多个步骤，并且其诊断准确性在概念验证中得到了高水平的验证，与教师判断完全吻合。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [96] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个多维度上下文感知的活动日志生成与总结系统，它在准确性和效率上显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的活动日志生成方法在准确性、效率和语义丰富性方面存在显著局限，无法充分满足用户行为分析和健康监测的需求。

Method: 本文提出了DailyLLM系统，这是首个全面整合位置、运动、环境和生理四维上下文信息的日志生成和总结系统，仅使用智能手机和智能手表上的常见传感器。DailyLLM引入了一个轻量级的基于LLM的框架，结合结构化提示和高效特征提取，以实现高水平的活动理解。

Result: 实验结果表明，DailyLLM在日志生成方面优于最先进（SOTA）方法。它仅使用1.5B参数的LLM模型，相比70B参数的SOTA基线，日志生成BERTScore精度提高了17%，同时推理速度快近10倍。此外，DailyLLM可以高效部署在个人电脑和树莓派上。

Conclusion: DailyLLM为上下文感知的活动日志生成提供了一个高效、准确且资源友好的解决方案，显著提升了日志的语义丰富度和实用性，克服了现有方法的局限性。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [97] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: OntView是一款开源的本体可视化工具，旨在通过直观界面展示本体概念及其推断知识，解决现有工具在大型本体结构可视化方面的局限性和信息过载问题，特别是支持通用概念包含（GCI）的可视化。


<details>
  <summary>Details</summary>
Motivation: 在知识管理和计算机科学领域，本体论虽能有效建模领域知识，但现有工具普遍缺乏有效的可视化功能。大多数工具无法以有意义且不造成信息过载的方式图形化表示本体结构，这限制了用户理解大型本体框架中概念间的依赖和属性。

Method: 本文提出了OntView本体查看器。该工具基于描述逻辑（DL）推理器，遵循“所见即所指”范式，显示实际推断出的知识。其关键方法包括：1) 能够可视化现有工具所不具备的通用概念包含（GCI）；2) 为避免信息过载，提供多种简化视图方式，例如根据概念重要性创建本体摘要；3) 聚焦显示两个给定类之间的TBox元素；4) 动态隐藏/显示不同分支而不丢失语义。

Result: 开发并发布了OntView，一个用户友好的本体查看器。它能够为用户提供本体概念及其形式化定义的直观视觉表示，并显示实际推断出的知识。OntView成功实现了GCI的可视化，并提供了多种策略有效管理信息过载，显著提高了用户对复杂本体结构的理解能力。该工具已开源。

Conclusion: OntView通过创新的可视化方法，包括支持GCI显示和多种信息简化策略，有效克服了当前本体可视化工具的局限性，使得用户能更直观、准确地理解大型本体的复杂结构和推断知识。作为开源工具，它对知识管理和计算机科学社区具有重要贡献。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [98] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 本文提出一种混合架构，结合启发式提取、语义激活和组合合成，用于代理增强的战略推理。该模型通过语义相互依赖融合冲突的启发式规则，生成连贯且上下文敏感的叙事，并以Meta与FTC案例研究进行演示。


<details>
  <summary>Details</summary>
Motivation: 传统的决策引擎通常选择最佳规则，而无法有效处理冲突的启发式规则。本研究旨在开发一种更先进的战略推理系统，能够融合冲突的启发式规则，并从经典军事理论到当代企业战略中汲取灵感，生成连贯、上下文敏感的叙事。

Method: 本研究提出一种混合架构，结合启发式提取、语义激活和组合合成。该模型通过受量子认知研究启发的语义相互依赖过程，激活并组合多种启发式规则。与传统方法不同，它通过语义交互建模和修辞框架，将冲突的启发式规则融合为连贯且上下文敏感的叙事。

Result: 该框架通过Meta与FTC的案例研究得到了演示，并使用语义指标进行了初步验证。

Conclusion: 该混合架构为代理增强的战略推理提供了一种新颖的方法，能够有效融合冲突的启发式规则。研究讨论了其局限性及扩展方向（例如，动态干扰调谐）。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [99] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: 提出EAGLE，一个轻量级框架，通过结合短期时间近邻和长期全局结构模式，显著提升了动态图时间链接预测的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 动态图中的时间链接预测任务很重要，但现有的时间图神经网络（T-GNNs）尽管有效，却因高计算开销而面临可扩展性和效率挑战。

Method: 提出EAGLE框架，包含一个时间感知模块（聚合最近邻居信息）和一个结构感知模块（利用时间个性化PageRank捕获全局重要节点影响）。该框架通过自适应加权机制平衡两者贡献，并避免复杂的跳传消息传递或内存密集机制，从而提高效率。

Result: 在七个真实世界时间图上的广泛实验表明，EAGLE在有效性和效率上均优于最先进的T-GNNs，相比基于Transformer的T-GNNs实现了超过50倍的加速。

Conclusion: EAGLE为动态图中的时间链接预测提供了一个高性能且高效率的轻量级解决方案，有效克服了现有T-GNNs的计算开销问题。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [100] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 本文提出一种因果知识迁移框架，使多智能体强化学习（MARL）在非稳态环境中能进行零样本适应，通过共享碰撞后的恢复动作宏来应对环境变化。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体强化学习（MARL）在非稳态环境中进行知识迁移时面临挑战，泛化能力不足，且智能体需要高成本的再训练来适应环境变化。

Method: 引入因果知识迁移框架，使RL智能体学习并共享环境中路径的紧凑因果表示。将碰撞建模为因果干预，即一系列恢复动作（宏），这些宏代表了规避障碍并达成目标的因果知识。恢复动作宏可在线从第二智能体零样本迁移，仅通过查询基于局部上下文（碰撞）的查找模型即可应用。

Result: 研究发现：1) 具有异构目标的智能体在适应新环境时，能弥补随机探索与完全再训练策略之间约一半的差距。2) 因果知识迁移的效果取决于环境复杂性和智能体异构目标之间的相互作用。

Conclusion: 所提出的因果知识迁移框架有效提升了多智能体在非稳态环境下的适应能力，实现了零样本迁移，且其性能受环境复杂度和智能体目标异构性的影响。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [101] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 为解决LLMs在创新构思中的局限，本文提出一种模型无关的潜在空间构思框架，通过导航嵌入空间实现可控、可扩展的创造力，初步结果显示其作为通用人机协作构思工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 人工智能，特别是大型语言模型（LLMs），在生成既新颖又相关的创新想法方面面临核心挑战。LLMs倾向于复制训练模式，缺乏创造性。现有解决方案（如领域特定启发式和结构化提示）脆弱且难以泛化。

Method: 本文提出一种模型无关的潜在空间构思框架。该框架通过导航思想的连续嵌入空间，实现受控且可扩展的创造力，无需手工规则，并易于适应不同领域、输入格式和创意任务。

Result: 本文介绍了该方法的早期原型，概述了其概念框架，并展示了初步结果，突出了其作为通用人机协作共同构思者的潜力。

Conclusion: 该框架显示出作为通用人机协作共同构思工具的巨大潜力，有望克服LLMs在创新构思方面的现有局限性。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [102] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 本文提出ADPC框架，结合视觉-语言模型与因果干预，利用多模态数据（MRI、fMRI、LLM生成的文本）消除混杂因素，实现了阿尔茨海默病（AD）及其前驱（MCI）和正常认知（CN）状态的SOTA分类。


<details>
  <summary>Details</summary>
Motivation: 轻度认知障碍（MCI）是阿尔茨海默病（AD）的临床前阶段，早期识别和干预能有效延缓疾病进展。然而，AD诊断因多模态数据选择偏差和变量间复杂关系引起的混杂因素而面临重大挑战。

Method: 提出了一种名为ADPC（Alzheimer's Disease Prediction with Cross-modal Causal Intervention）的视觉-语言因果干预框架。该框架利用大型语言模型（LLM）将临床数据标准化为结构化文本，并结合核磁共振成像（MRI）、功能核磁共振成像（fMRI）图像以及LLM生成的文本数据对参与者进行分类。通过因果干预，ADPC模型能够隐式消除神经影像伪影和年龄相关生物标志物等混杂因素，避免捕获虚假相关性。

Result: 实验结果表明，该方法在区分CN/MCI/AD病例方面表现突出，在多数评估指标上达到了最先进（SOTA）的水平。

Conclusion: 该研究展示了将因果推理与多模态学习相结合在神经系统疾病诊断中的巨大潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [103] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 针对ASP在处理高精度时序数值动态系统推理方面的挑战，本文提出了Here-and-There逻辑及其非单调平衡扩展的一种新型时间与约束结合的扩展，为ASP领域首次实现了结合约束的非单调时间推理。


<details>
  <summary>Details</summary>
Motivation: 逻辑编程方法（特别是ASP）在对具有细粒度时间与数值分辨率的动态系统进行推理时，面临显著挑战。

Method: 本文引入并详细阐述了一种新颖的、基于Here-and-There逻辑及其非单调平衡扩展的时间与约束结合的扩展。该系统通过协同整合线性时间Here-and-There逻辑（提供非单调时间推理）和带约束Here-and-There逻辑（支持数值约束处理）来实现。

Result: 成功构建了一个表达性系统，据作者所知，这是首个为ASP量身定制的、结合约束的非单调时间推理方法，能够处理高分辨率的复杂动态系统。

Conclusion: 本研究为在ASP范式下处理高分辨率复杂动态系统奠定了基础逻辑框架。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [104] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA是一个新的本体匹配框架，它结合RAG管道和LLM，动态增强语义上下文，并通过优化技术提升性能和效率，在基准测试中超越现有OM系统和LLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有本体匹配系统依赖手工规则或特定模型，适应性有限，无法有效应对语义互操作性挑战。

Method: 提出KROMA框架，利用RAG管道中的LLM动态丰富本体匹配任务的语义上下文（结构、词汇、定义知识）。为优化性能和效率，KROMA整合了基于双相似度的概念匹配和轻量级本体精炼步骤，以剪枝候选概念并大幅减少LLM调用开销。

Result: 实验表明，结合知识检索和上下文增强的LLM显著提升了本体匹配效果，优于经典OM系统和前沿的基于LLM的方法，同时通信开销保持可比。 

Conclusion: 本研究突出了所提出的优化技术（目标知识检索、提示丰富和本体精炼）在大规模本体匹配中应用的的可行性与优势。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [105] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: 本文发布了Glucose-ML，一个包含10个公开可用糖尿病数据集的集合，旨在解决AI开发中数据匮乏的难题。通过比较分析和血糖预测案例研究，展示了相同算法在不同数据集上表现的显著差异，并据此提出了开发稳健AI解决方案的建议。


<details>
  <summary>Details</summary>
Motivation: 高质量、大规模的糖尿病数据集稀缺，这阻碍了稳健人工智能解决方案的开发，特别是在糖尿病管理领域。

Method: 研究者构建并发布了Glucose-ML，一个包含10个过去7年间发布的公开糖尿病数据集的集合，总计超过30万天的连续血糖监测(CGM)数据和3800万个血糖样本。他们对这些数据集进行了比较分析以指导数据选择，并进行了一项血糖预测的案例研究，为Glucose-ML集合中所有数据集的短期血糖预测提供了基准。

Result: 研究发现，相同的算法在不同数据集上进行开发或评估时，其预测结果可能存在显著差异。通过案例研究，为血糖预测任务提供了跨多个数据集的性能基准。

Conclusion: 数据集的选择对糖尿病或更广泛健康领域AI解决方案的性能和鲁棒性至关重要。Glucose-ML及其相关分析为开发透明、可复现和稳健的AI模型提供了关键资源和指导。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [106] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: 本研究引入了生成式AI驱动的人体运动模拟（G-AI-HMS），通过结合大语言模型和计算机视觉验证，显著提升了工业任务中运动模拟的保真度，降低了误差并改善了时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动模拟（HMS）方法在工业任务中存在运动保真度低的问题，限制了其在评估工人行为、安全和生产力方面的有效性。

Method: 本研究提出了G-AI-HMS，它整合了文本到文本和文本到运动模型。具体方法包括：1) 使用与MotionGPT训练词汇对齐的大语言模型将任务描述转换为运动感知语言；2) 利用计算机视觉技术（如姿态估计算法提取关节地标）将AI增强的运动与真实人体运动进行比较和验证，通过运动相似性度量评估其准确性。

Result: 在一项涉及八项任务的案例研究中，与人类创建的描述相比，AI增强的运动在大多数情况下表现出更低的误差。具体而言，在空间准确性方面优于六项任务，在姿态归一化后的对齐方面优于四项任务，在整体时间相似性方面优于七项任务。统计分析表明，AI增强的提示显著（p < 0.0001）减少了关节误差和时间错位，同时保持了可比的姿态准确性。

Conclusion: G-AI-HMS显著提升了人体运动模拟的保真度，为工业任务中的工人行为、安全和生产力评估提供了更准确、有效的工具。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [107] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: 本研究探索并验证了大型语言模型（LLMs）在解释无损检测（NDE）轮廓图、评估桥梁状况方面的潜力，旨在提高检测效率和决策速度。


<details>
  <summary>Details</summary>
Motivation: 桥梁维护和安全至关重要，但NDE数据解释耗时且需专业知识，可能延迟决策。LLMs的进步为自动化分析提供了新途径。

Method: 本试点研究选择多个LLMs，设计特定提示语以优化图像描述质量。利用这些LLMs解释五张不同的NDE轮廓图，并评估其生成详细描述、识别缺陷、提供建议及整体准确性的能力。同时，使用不同的LLMs对前述模型的输出进行总结。

Result: 研究发现，九个模型中有四个在图像描述方面表现更优，能有效覆盖桥梁状况的广泛主题。通过五个不同的LLMs对这四个模型的输出进行总结，其中ChatGPT-4和Claude 3.5 Sonnet生成了更有效的摘要。结果表明LLMs有潜力显著提升效率和准确性。

Conclusion: LLMs在桥梁检测中具有巨大潜力，通过并行图像描述和摘要功能，可加速决策制定，提升桥梁维护和基础设施管理效率与安全性。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


### [108] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: CUDA-L1是一个基于强化学习的自动化CUDA优化框架，它能将现有LLM转化为高效的CUDA优化器，在多种GPU上实现显著的性能提升和出色的可移植性，有效缓解GPU资源压力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLM)的快速发展，GPU计算资源需求呈指数级增长，迫切需要自动化的CUDA优化策略。然而，当前最先进的LLM在提高CUDA速度方面的成功率较低。

Method: 本文提出了CUDA-L1，一个自动化的强化学习框架，用于CUDA优化。该框架通过纯粹基于加速比的奖励信号进行训练，将初始性能不佳的LLM转化为有效的CUDA优化器，且无需人类专业知识或领域知识。

Result: CUDA-L1在NVIDIA A100上训练，在KernelBench的250个CUDA核上实现了平均17.7倍的加速，峰值达到449倍。此外，它在多种GPU架构（如H100、RTX 3090、L40、H800、H20）上表现出卓越的可移植性，平均加速比在13.9倍至19.0倍之间。该模型还能发现并策略性组合多种CUDA优化技术，揭示优化基本原理，并识别非显而易见的性能瓶颈。

Conclusion: 强化学习能够仅通过基于加速比的奖励信号，将性能不佳的LLM转变为高效的CUDA优化器，其习得的推理能力可推广到新的内核。这种范式为CUDA操作的自动化优化开辟了新的可能性，有望大幅提升GPU效率并缓解GPU计算资源的压力。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [109] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 该论文旨在从物理学角度，通过构建基于Fock空间和Hilbert空间的开放量子系统模型，来理解Transformer架构的工作原理。


<details>
  <summary>Details</summary>
Motivation: 当前对Transformer架构的理论理解存在空白，尤其是在其物理工作原理方面（即Transformer是什么，以及它为何在物理上有效）。

Method: 从现代芯片的物理视角出发，在令牌（tokens）的希尔伯特（Hilbert）空间上的福克（Fock）空间中，构建将基于Transformer架构的大型语言模型视为开放量子系统的物理模型。

Result: 构建了能够为大型语言模型中的Transformer架构提供物理基础的理论模型。

Conclusion: 这些物理模型为理解大型语言模型中的Transformer架构提供了新的物理视角和理论基础。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


### [110] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 本研究旨在解决文生图（T2I）模型未能考虑多样化人类经验导致的偏差问题，通过引入首个多模态多元对齐数据集DIVE，并实证确认人口统计学是多样化视角的关键代理，从而为构建更公平、对齐的T2I系统提供基础工具。


<details>
  <summary>Details</summary>
Motivation: 当前文生图（T2I）模型未能充分反映多样化的人类经验，导致系统对齐不足。研究旨在实现“多元对齐”，即让AI能够理解并适应多样化甚至冲突的人类价值观。

Method: 1. 引入了首个用于多元对齐的多模态数据集——多样化交叉视觉评估（DIVE）数据集。2. 通过DIVE数据集，收集了大量来自具有交叉人口统计学特征的人类评估者对1000个提示的反馈，以捕捉细致且多样化的安全感知。3. 基于这些数据，实证确认人口统计学特征是衡量多样化视角的关键代理。4. 讨论了构建对齐T2I模型的策略，包括高效数据收集、大型语言模型（LLM）的判断能力和模型对多样化视角的控制性。

Result: 1. 成功构建了DIVE数据集，这是首个用于多元对齐的多模态数据集，能够通过多样化评估者捕捉细致且差异化的安全感知。2. 实证研究确认人口统计学是多样化视角的关键代理，并揭示了与传统评估方法不同的、显著且依赖于上下文的危害感知差异。

Conclusion: 该研究为构建更公平、更符合多样化人类价值观的文生图系统提供了基础工具和见解，并强调了在模型对齐过程中考虑人口统计学差异和多元视角的重要性。

Abstract: Current text-to-image (T2I) models often fail to account for diverse human
experiences, leading to misaligned systems. We advocate for pluralistic
alignment, where an AI understands and is steerable towards diverse, and often
conflicting, human values. Our work provides three core contributions to
achieve this in T2I models. First, we introduce a novel dataset for Diverse
Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for
pluralistic alignment. It enable deep alignment to diverse safety perspectives
through a large pool of demographically intersectional human raters who
provided extensive feedback across 1000 prompts, with high replication,
capturing nuanced safety perceptions. Second, we empirically confirm
demographics as a crucial proxy for diverse viewpoints in this domain,
revealing significant, context-dependent differences in harm perception that
diverge from conventional evaluations. Finally, we discuss implications for
building aligned T2I models, including efficient data collection strategies,
LLM judgment capabilities, and model steerability towards diverse perspectives.
This research offers foundational tools for more equitable and aligned T2I
systems. Content Warning: The paper includes sensitive content that may be
harmful.

</details>


### [111] [Improving KAN with CDF normalization to quantiles](https://arxiv.org/abs/2507.13393)
*Jakub Strawa,Jarek Duda*

Main category: cs.LG

TL;DR: 本文介绍了一种来自copula理论的CDF归一化方法，并展示其在机器学习（特别是KANs）中通过提升预测性能和减少过拟合的优势。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习数据归一化方法存在局限性，而copula理论中将数据转换为CDF(x)以近似分位数的方法（CDF归一化）具有简化模型、减少过拟合的优势，但在机器学习领域却鲜为人知。因此，研究旨在将此方法引入机器学习并展示其效用。

Method: 研究方法是将在copula理论中使用的CDF归一化（将x转换为CDF(x)）应用于Kolmogorov-Arnold Networks (KANs)，具体是通过将Legendre-KAN中的常规缩放替换为CDF归一化。

Result: 通过切换到CDF归一化，显著提升了Legendre-KAN的预测性能。此外，在HCR解释下，这种归一化的神经元权重可表示混合矩，提供局部联合分布模型，并支持概率分布的传播和传播方向的改变。

Conclusion: CDF归一化是机器学习中一种有前景的数据预处理方法，尤其适用于KANs，能够提高模型性能、减少过拟合，并提供更丰富的模型解释性。

Abstract: Data normalization is crucial in machine learning, usually performed by
subtracting the mean and dividing by standard deviation, or by rescaling to a
fixed range. In copula theory, popular in finance, there is used normalization
to approximately quantiles by transforming x to CDF(x) with estimated CDF
(cumulative distribution function) to nearly uniform distribution in [0,1],
allowing for simpler representations which are less likely to overfit. It seems
nearly unknown in machine learning, therefore, we would like to present some
its advantages on example of recently popular Kolmogorov-Arnold Networks
(KANs), improving predictions from Legendre-KAN by just switching rescaling to
CDF normalization. Additionally, in HCR interpretation, weights of such neurons
are mixed moments providing local joint distribution models, allow to propagate
also probability distributions, and change propagation direction.

</details>


### [112] [Selective Embedding for Deep Learning](https://arxiv.org/abs/2507.13399)
*Mert Sehri,Zehui Hua,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: 提出“选择性嵌入”这一新型数据加载策略，通过交替多源数据段提升深度学习模型在时间域数据上的泛化能力和计算效率，减少过拟合。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型对输入数据敏感，在非平稳和不同域（特别是时间域）条件下性能易下降。传统单通道或并行多源数据加载策略限制泛化能力或增加计算成本。

Method: 引入“选择性嵌入”数据加载策略，其在一个输入通道内交替加载来自多个源的短数据段。该方法受认知心理学启发，模仿人类信息处理方式，旨在减少模型过拟合，增强泛化能力并提高计算效率。

Result: 通过在六个时间域数据集上进行验证，结果表明所提出的方法在多种深度学习架构下均能持续实现高分类精度，并显著缩短训练时间。该方法对于具有多个数据源的复杂系统尤为有效。

Conclusion: “选择性嵌入”提供了一种可扩展且资源高效的解决方案，能有效提升深度学习模型的鲁棒性和适应性，特别适用于医疗、重型机械、海洋、铁路和农业等对稳定性和适应性要求高的实际应用场景。

Abstract: Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.

</details>


### [113] [LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](https://arxiv.org/abs/2507.13413)
*Aleksey Lapin,Igor Hromov,Stanislav Chumakov,Mile Mitrovic,Dmitry Simakov,Nikolay O. Nikitin,Andrey V. Savchenko*

Main category: cs.LG

TL;DR: LightAutoDS-Tab是一个结合LLM代码生成和多AutoML工具的系统，旨在提升表格数据任务的性能、灵活性和鲁棒性，并优于现有解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管AutoML已整合LLM处理复杂任务，但其效率仍受限于对特定底层工具的依赖。研究旨在解决这一限制，提高管道设计的灵活性和鲁棒性。

Method: 引入LightAutoDS-Tab，一个针对表格数据的多AutoML智能体系统。该系统结合了基于LLM的代码生成和多种AutoML工具。

Result: 该方法提高了管道设计的灵活性和鲁棒性，并在多个Kaggle数据科学任务上超越了当前最先进的开源解决方案。

Conclusion: LightAutoDS-Tab通过结合LLM代码生成与多AutoML工具，为表格数据任务提供了一个更灵活、鲁棒且性能卓越的解决方案，有效克服了现有AutoML系统的局限性。

Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs,
yet its efficiency remains limited by dependence on specific underlying tools.
In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for
tasks with tabular data, which combines an LLM-based code generation with
several AutoML tools. Our approach improves the flexibility and robustness of
pipeline design, outperforming state-of-the-art open-source solutions on
several data science tasks from Kaggle. The code of LightAutoDS-Tab is
available in the open repository https://github.com/sb-ai-lab/LADS

</details>


### [114] [Gauge Flow Models](https://arxiv.org/abs/2507.13414)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: 本文引入了一种新型生成流模型：规范流模型，它在流常微分方程中整合了可学习的规范场，并在实验中展现出优于传统流模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统生成流模型的潜在局限性，提出一种新型模型以提升生成任务的性能和建模能力。

Method: 在流常微分方程（ODE）中引入一个可学习的规范场，构建了规范流模型，并提供了详细的数学框架。实验使用流匹配（Flow Matching）技术在高斯混合模型（Gaussian Mixture Models）上进行。

Result: 在高斯混合模型上的实验表明，规范流模型比相同或更大规模的传统流模型表现出显著更优的性能。此外，初步研究显示其在更广泛的生成任务中也具有提升性能的潜力。

Conclusion: 规范流模型通过在流ODE中引入规范场，有效提升了生成流模型的性能，并在多种生成任务中展现出广阔的应用前景。

Abstract: This paper introduces Gauge Flow Models, a novel class of Generative Flow
Models. These models incorporate a learnable Gauge Field within the Flow
Ordinary Differential Equation (ODE). A comprehensive mathematical framework
for these models, detailing their construction and properties, is provided.
Experiments using Flow Matching on Gaussian Mixture Models demonstrate that
Gauge Flow Models yields significantly better performance than traditional Flow
Models of comparable or even larger size. Additionally, unpublished research
indicates a potential for enhanced performance across a broader range of
generative tasks.

</details>


### [115] [FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning](https://arxiv.org/abs/2507.13624)
*Daniel Commey,Kamel Abbad,Garth V. Crosby,Lyes Khoukhi*

Main category: cs.LG

TL;DR: 本文提出FedSkipTwin，一种基于服务器端数字孪生（LSTM）的客户端跳过算法，通过预测客户端更新的重要性和不确定性来减少联邦学习的通信开销，同时提高模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中通信开销是一个主要瓶颈，尤其对于带宽受限的移动和物联网设备。

Method: 引入FedSkipTwin算法，该算法利用服务器端轻量级数字孪生（由简单LSTM实现），通过观察客户端历史梯度范数序列，预测其下一次更新的幅度和认知不确定性。服务器根据预测，仅当任一值超过预定义阈值时才请求通信，否则指示客户端跳过本轮以节省带宽。在UCI-HAR和MNIST数据集（非IID数据分布，10个客户端）上进行了实验。

Result: FedSkipTwin在20轮内将总通信量减少了12-15.5%，同时相比标准FedAvg算法，最终模型精度提高了0.5个百分点。

Conclusion: 预测引导的跳过策略是带宽受限边缘环境中实现资源感知型联邦学习的实用且有效的方法。

Abstract: Communication overhead remains a primary bottleneck in federated learning
(FL), particularly for applications involving mobile and IoT devices with
constrained bandwidth. This work introduces FedSkipTwin, a novel
client-skipping algorithm driven by lightweight, server-side digital twins.
Each twin, implemented as a simple LSTM, observes a client's historical
sequence of gradient norms to forecast both the magnitude and the epistemic
uncertainty of its next update. The server leverages these predictions,
requesting communication only when either value exceeds a predefined threshold;
otherwise, it instructs the client to skip the round, thereby saving bandwidth.
Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients
under a non-IID data distribution. The results demonstrate that FedSkipTwin
reduces total communication by 12-15.5% across 20 rounds while simultaneously
improving final model accuracy by up to 0.5 percentage points compared to the
standard FedAvg algorithm. These findings establish that prediction-guided
skipping is a practical and effective strategy for resource-aware FL in
bandwidth-constrained edge environments.

</details>


### [116] [Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling](https://arxiv.org/abs/2507.13416)
*Jiaxiang Yi,Bernardo P. Ferreira,Miguel A. Bessa*

Main category: cs.LG

TL;DR: 该研究提出一种数据驱动学习的泛化方法，能够处理历史依赖的多精度数据，并量化和分离认知不确定性与数据噪声。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动学习方法在处理历史依赖的多精度数据，以及有效量化并区分认知不确定性与数据噪声方面存在局限性。

Method: 该方法通过分层泛化，从简单的单精度确定性神经网络扩展至所提出的多精度方差估计贝叶斯循环神经网络，以适应不同学习场景。

Result: 该方法能够准确预测响应，量化模型误差，并能在存在时发现噪声分布。

Conclusion: 该方法为科学和工程领域，特别是不确定性下的设计和分析等具有挑战性的实际应用提供了新机会。

Abstract: Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.

</details>


### [117] [Soft-ECM: An extension of Evidential C-Means for complex data](https://arxiv.org/abs/2507.13417)
*Armel Soubeiga,Thomas Guyet,Violaine Antoine*

Main category: cs.LG

TL;DR: 提出Soft-ECM算法，利用半度量对复杂数据（如混合数据和时间序列）进行基于置信函数的聚类。


<details>
  <summary>Details</summary>
Motivation: 现有的基于置信函数的聚类算法无法应用于混合数据或时间序列等复杂数据，因为这些数据通常不表示在欧氏空间中，而现有算法依赖于欧氏空间的特性来构建重心。

Method: 重新构建了Evidential C-Means (ECM) 问题以适应复杂数据聚类。提出了一种名为Soft-ECM的新算法，该算法仅需要一个半度量就能一致地定位不精确簇的质心。

Result: 实验表明，Soft-ECM在数值数据上的结果与传统的模糊聚类方法相当；同时，它能有效处理混合数据，并结合DTW等半度量在时间序列数据聚类中展现出优势。

Conclusion: Soft-ECM算法成功扩展了基于置信函数的聚类方法对复杂数据的处理能力，通过引入半度量克服了对欧氏空间的依赖，具有广泛的应用潜力。

Abstract: Clustering based on belief functions has been gaining increasing attention in
the machine learning community due to its ability to effectively represent
uncertainty and/or imprecision. However, none of the existing algorithms can be
applied to complex data, such as mixed data (numerical and categorical) or
non-tabular data like time series. Indeed, these types of data are, in general,
not represented in a Euclidean space and the aforementioned algorithms make use
of the properties of such spaces, in particular for the construction of
barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem
for clustering complex data. We propose a new algorithm, Soft-ECM, which
consistently positions the centroids of imprecise clusters requiring only a
semi-metric. Our experiments show that Soft-ECM present results comparable to
conventional fuzzy clustering approaches on numerical data, and we demonstrate
its ability to handle mixed data and its benefits when combining fuzzy
clustering with semi-metrics such as DTW for time series data.

</details>


### [118] [Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity](https://arxiv.org/abs/2507.13423)
*Edward Henderson,Dewi Gould,Richard Everson,George De Ath,Nick Pepper*

Main category: cs.LG

TL;DR: 本文提出一种可解释的图神经网络（GNN）框架，用于实时评估空管员任务需求，通过预测即将到来的指令并提供可归因于特定飞机的任务需求分数，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在日益拥挤的空域中，实时评估空管员（ATCO）近期的任务需求是一项严峻挑战，现有复杂性指标通常无法捕捉到除飞机数量外的细微操作驱动因素。

Method: 引入一个可解释的基于注意力机制的图神经网络（GNN）框架，通过分析静态交通场景中的飞机交互来预测即将到来的空管指令数量。此外，通过系统性地移除飞机并测量其对模型预测的影响，推导出可解释的、针对每架飞机的任务需求分数。

Result: 该框架显著优于受空管员启发启发式方法，并且比现有基线方法能更可靠地评估场景复杂性。

Conclusion: 所开发的工具能够将任务需求归因于特定飞机，为分析和理解复杂性驱动因素提供新方法，可应用于管制员培训和空域重新设计。

Abstract: Real-time assessment of near-term Air Traffic Controller (ATCO) task demand
is a critical challenge in an increasingly crowded airspace, as existing
complexity metrics often fail to capture nuanced operational drivers beyond
simple aircraft counts. This work introduces an interpretable Graph Neural
Network (GNN) framework to address this gap. Our attention-based model predicts
the number of upcoming clearances, the instructions issued to aircraft by
ATCOs, from interactions within static traffic scenarios. Crucially, we derive
an interpretable, per-aircraft task demand score by systematically ablating
aircraft and measuring the impact on the model's predictions. Our framework
significantly outperforms an ATCO-inspired heuristic and is a more reliable
estimator of scenario complexity than established baselines. The resulting tool
can attribute task demand to specific aircraft, offering a new way to analyse
and understand the drivers of complexity for applications in controller
training and airspace redesign.

</details>


### [119] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出一种基于IMU-视频数据的跨模态自监督预训练方法，显著提升了人体活动识别模型在不同环境和人群（包括帕金森病患者）中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可穿戴IMU传感器的人体活动识别（HAR）机器学习方法依赖特定标签，在不同环境或人群（尤其是运动障碍患者）中泛化能力不足，限制了其在远程健康监测中的应用。

Method: 开发了一种新的跨模态自监督预训练方法，利用大规模未标注的IMU-视频数据来学习通用的数据表征。

Result: 该跨模态预训练方法在零样本和少样本评估下，于OOD（Out-of-Distribution）IMU数据集（包括帕金森病患者数据）上，表现出比现有最先进的IMU-视频预训练方法和仅IMU预训练方法更优的性能和泛化能力。

Conclusion: 本研究表明，在IMU信号等高度动态的数据模态中，跨模态预训练是一种学习通用数据表征的有效工具。

Abstract: Human Activity Recognition (HAR) based on wearable inertial sensors plays a
critical role in remote health monitoring. In patients with movement disorders,
the ability to detect abnormal patient movements in their home environments can
enable continuous optimization of treatments and help alert caretakers as
needed. Machine learning approaches have been proposed for HAR tasks using
Inertial Measurement Unit (IMU) data; however, most rely on
application-specific labels and lack generalizability to data collected in
different environments or populations. To address this limitation, we propose a
new cross-modal self-supervised pretraining approach to learn representations
from large-sale unlabeled IMU-video data and demonstrate improved
generalizability in HAR tasks on out of distribution (OOD) IMU datasets,
including a dataset collected from patients with Parkinson's disease.
Specifically, our results indicate that the proposed cross-modal pretraining
approach outperforms the current state-of-the-art IMU-video pretraining
approach and IMU-only pretraining under zero-shot and few-shot evaluations.
Broadly, our study provides evidence that in highly dynamic data modalities,
such as IMU signals, cross-modal pretraining may be a useful tool to learn
generalizable data representations. Our software is available at
https://github.com/scheshmi/IMU-Video-OOD-HAR.

</details>


### [120] [Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](https://arxiv.org/abs/2507.13491)
*Thomas Banker,Ali Mesbah*

Main category: cs.LG

TL;DR: 针对无模型强化学习在样本效率、安全性、可解释性方面的不足，本文提出基于模型的智能体作为替代，并探讨其与无模型学习结合，以实现高效、安全、可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 现代自主系统中的无模型强化学习（尤其是结合深度神经网络时）存在样本效率低、学习不安全以及可解释性差等问题。

Method: 本研究引入基于模型的智能体作为控制策略近似的替代，利用可调整的系统动态、成本和约束模型实现安全策略学习。文章概述了其优缺点，并详细介绍了贝叶斯优化、策略搜索RL和离线策略等学习方法，强调了基于模型与无模型方法结合的潜力。

Result: 基于模型的智能体能编码先验知识，指导、约束决策并提高可解释性。通过与无模型强化学习结合，可弥补模型失配问题，有望实现样本高效、安全且可解释的决策学习。

Conclusion: 基于模型的智能体与无模型强化学习的结合潜力仍待探索，有望在样本效率、安全性及可解释性方面带来显著改进，是未来研究的重要方向。

Abstract: Training sophisticated agents for optimal decision-making under uncertainty
has been key to the rapid development of modern autonomous systems across
fields. Notably, model-free reinforcement learning (RL) has enabled
decision-making agents to improve their performance directly through system
interactions, with minimal prior knowledge about the system. Yet, model-free RL
has generally relied on agents equipped with deep neural network function
approximators, appealing to the networks' expressivity to capture the agent's
policy and value function for complex systems. However, neural networks amplify
the issues of sample inefficiency, unsafe learning, and limited
interpretability in model-free RL. To this end, this work introduces
model-based agents as a compelling alternative for control policy
approximation, leveraging adaptable models of system dynamics, cost, and
constraints for safe policy learning. These models can encode prior system
knowledge to inform, constrain, and aid in explaining the agent's decisions,
while deficiencies due to model mismatch can be remedied with model-free RL. We
outline the benefits and challenges of learning model-based agents --
exemplified by model predictive control -- and detail the primary learning
approaches: Bayesian optimization, policy search RL, and offline strategies,
along with their respective strengths. While model-free RL has long been
established, its interplay with model-based agents remains largely unexplored,
motivating our perspective on their combined potentials for sample-efficient
learning of safe and interpretable decision-making agents.

</details>


### [121] [Fake or Real: The Impostor Hunt in Texts for Space Operations](https://arxiv.org/abs/2507.13508)
*Agata Kaczmarek,Dawid Płudowski,Piotr Wilczyński,Przemysław Biecek,Krzysztof Kotowski,Ramez Shendy,Jakub Nalepa,Artur Janicki,Evridiki Ntagiou*

Main category: cs.LG

TL;DR: Kaggle竞赛“Fake or Real”旨在解决大型语言模型中的数据投毒和过度依赖这两种AI安全威胁，要求参与者识别被恶意修改的LLM输出。


<details>
  <summary>Details</summary>
Motivation: 该研究（或竞赛）的动机源于欧洲航天局项目中识别出的两个现实AI安全威胁：大型语言模型（LLM）中的数据投毒和过度依赖。由于此问题尚未得到广泛研究，需要开发新方法来区分LLM的正常输出和恶意修改后的输出。

Method: 本文描述了一个Kaggle竞赛，参与者需开发或调整现有技术，以区分大型语言模型的正常输出与在恶意修改下生成的输出。

Result: 抽象内容未包含具体的研究结果，因为它主要介绍一个竞赛而非研究报告的成果。

Conclusion: 鉴于大型语言模型中的数据投毒和过度依赖等AI安全威胁尚未被广泛研究，该竞赛旨在促进新型检测技术的发展，以应对LLM输出被恶意修改的挑战。

Abstract: The "Fake or Real" competition hosted on Kaggle
(\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})
is the second part of a series of follow-up competitions and hackathons related
to the "Assurance for Space Domain AI Applications" project funded by the
European Space Agency
(\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).
The competition idea is based on two real-life AI security threats identified
within the project -- data poisoning and overreliance in Large Language Models.
The task is to distinguish between the proper output from LLM and the output
generated under malicious modification of the LLM. As this problem was not
extensively researched, participants are required to develop new techniques to
address this issue or adjust already existing ones to this problem's statement.

</details>


### [122] [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
*Yongyi Yang,Hidenori Tanaka,Wei Hu*

Main category: cs.LG

TL;DR: 本文提出了一个“双重收敛”的统一框架，首次严格解释了大型语言模型（LLMs）在上下文学习（ICL）中如何通过对平滑（低频）表示的隐式偏置来获取新行为，并解释了多个经验观察结果。


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）使大型语言模型（LLMs）能够在不更新参数的情况下学习新行为，甚至超越预训练所学。然而，LLMs实现这种能力的内在机制尚不清楚。

Method: 引入了一个名为“双重收敛”的统一框架，该框架指出隐层表示在上下文和层之间都会收敛。通过分析证明和经验验证，解释了这种双重收敛过程如何导致对平滑（低频）表示的隐式偏置。

Result: 研究结果表明，双重收敛导致了对平滑（低频）表示的隐式偏置。这解释了为什么学习到的表示会表现出全局结构化但局部扭曲的几何形状，以及为什么它们的总能量会衰减但不消失。此外，理论预测ICL对高频噪声具有内在的鲁棒性，这一点也得到了经验证实。

Conclusion: 这些结果为ICL的底层机制提供了新的见解，并为研究ICL奠定了理论基础，有望推广到更通用的数据分布和设置中。

Abstract: In-context learning (ICL) enables large language models (LLMs) to acquire new
behaviors from the input sequence alone without any parameter updates. Recent
studies have shown that ICL can surpass the original meaning learned in
pretraining stage through internalizing the structure the data-generating
process (DGP) of the prompt into the hidden representations. However, the
mechanisms by which LLMs achieve this ability is left open. In this paper, we
present the first rigorous explanation of such phenomena by introducing a
unified framework of double convergence, where hidden representations converge
both over context and across layers. This double convergence process leads to
an implicit bias towards smooth (low-frequency) representations, which we prove
analytically and verify empirically. Our theory explains several open empirical
observations, including why learned representations exhibit globally structured
but locally distorted geometry, and why their total energy decays without
vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness
towards high-frequency noise, which we empirically confirm. These results
provide new insights into the underlying mechanisms of ICL, and a theoretical
foundation to study it that hopefully extends to more general data
distributions and settings.

</details>


### [123] [Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography](https://arxiv.org/abs/2507.13542)
*Beka Begiashvili,Carlos J. Fernandez-Candel,Matías Pérez Paredes*

Main category: cs.LG

TL;DR: 本文提出了一种名为声学指数（Acoustic Index）的新型AI驱动超声心动图参数，旨在克服传统心功能参数的局限性，实现心脏功能障碍的早期、可重复且操作者独立的检测。该指数结合了EDMD和混合神经网络，并在736名患者队列中表现出高精度（AUC 0.89）和鲁棒性，有望成为心功能评估的普适性工具。


<details>
  <summary>Details</summary>
Motivation: 传统的超声心动图参数，如射血分数（EF）和整体纵向应变（GLS），在早期检测心脏功能障碍方面存在局限性。EF在病理存在时常保持正常，而GLS则受负荷条件和供应商差异的影响。因此，亟需一种可重复、可解释、独立于操作者且能捕捉细微和整体心脏功能变化的参数。

Method: 研究引入了声学指数（Acoustic Index），这是一种新型AI驱动的超声心动图参数。该模型结合了基于Koopman算子理论的扩展动态模态分解（EDMD）与一个整合临床元数据的混合神经网络。模型从超声心动图序列中提取时空动态以识别相干运动模式，并通过注意力机制进行加权，然后利用流形学习与临床数据融合，生成一个从0（低风险）到1（高风险）的连续评分。

Result: 在包含736名患者的前瞻性队列中（涵盖各种心脏病理和正常对照），声学指数在独立测试集中实现了0.89的曲线下面积（AUC）。通过五重交叉验证证实了模型的鲁棒性，在独立数据评估中，灵敏度和特异性均超过0.8。基于阈值的分析显示，灵敏度和特异性之间存在稳定的权衡，且在阈值附近具有最佳区分能力。

Conclusion: 声学指数是一种物理信息感知、可解释的心脏功能AI生物标志物。它有望成为一种可扩展、独立于供应商的工具，用于心脏功能障碍的早期检测、分诊和纵向监测。未来的研究方向包括外部验证、纵向研究以及适应特定疾病分类器。

Abstract: Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.

</details>


### [124] [Time Series Forecastability Measures](https://arxiv.org/abs/2507.13556)
*Rui Wang,Steven Klee,Alexis Roos*

Main category: cs.LG

TL;DR: 本文提出使用频谱可预测性得分和最大李雅普诺夫指数两种新度量，在模型开发前量化时间序列的固有可预测性，以指导预测实践。


<details>
  <summary>Details</summary>
Motivation: 传统的模型评估指标在预测尝试后才进行评估，无法衡量数据固有的可预测性。研究的动机是提供一种在预测前评估时间序列可预测性的方法，帮助实践者更有效地规划预测工作和设定预期。

Method: 该研究提出了两种量化时间序列可预测性的指标：频谱可预测性得分和最大李雅普诺夫指数。频谱可预测性得分评估时间序列中频率分量的强度和规律性，而李雅普诺夫指数则量化数据生成系统的混沌性和稳定性。这些指标在合成数据和M5预测竞赛数据集的真实世界时间序列上进行了评估。

Result: 研究结果表明，这两种指标能准确反映时间序列的固有可预测性，并与各种模型的实际预测性能具有很强的相关性。

Conclusion: 通过在模型训练前理解时间序列的固有可预测性，实践者可以将精力集中在更可预测的产品和供应链层面，同时对可预测性有限的产品设定适当的预期或寻求替代策略。

Abstract: This paper proposes using two metrics to quantify the forecastability of time
series prior to model development: the spectral predictability score and the
largest Lyapunov exponent. Unlike traditional model evaluation metrics, these
measures assess the inherent forecastability characteristics of the data before
any forecast attempts. The spectral predictability score evaluates the strength
and regularity of frequency components in the time series, whereas the Lyapunov
exponents quantify the chaos and stability of the system generating the data.
We evaluated the effectiveness of these metrics on both synthetic and
real-world time series from the M5 forecast competition dataset. Our results
demonstrate that these two metrics can correctly reflect the inherent
forecastability of a time series and have a strong correlation with the actual
forecast performance of various models. By understanding the inherent
forecastability of time series before model training, practitioners can focus
their planning efforts on products and supply chain levels that are more
forecastable, while setting appropriate expectations or seeking alternative
strategies for products with limited forecastability.

</details>


### [125] [Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)
*Mrinal Mathur,Mike Doan,Barak Pearlmutter,Sergey Plis*

Main category: cs.LG

TL;DR: 一种名为SELF-Transformer的新型编码器，通过内部迭代细化注意力权重，在不增加参数量的情况下，显著提升了编码器模型性能，同时保持了纯编码器架构的简洁性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在单次固定深度计算下表达能力受限。虽然自回归Transformer通过外部化中间状态解决了此问题，但这与生物大脑内部迭代推理的方式不同。本研究旨在不依赖token级自回归的情况下，提升编码器Transformer的表达能力。

Method: 提出SELF-Transformer，一种编码器层。它通过内部迭代方式，将自身的注意力权重细化到一个固定点，而非一次性生成对齐矩阵。在测试时，计算量会根据输入难度自适应调整。

Result: 在编码器风格的基准测试中，准确率提高了高达20%，且未增加参数数量。这表明测试时的输入自适应对齐能以适度的额外计算预算带来显著效益。

Conclusion: SELF-Transformer在保持纯编码器架构简洁性的同时，有效恢复了迭代推理的强大表达能力。

Abstract: Transformers evaluated in a single, fixed-depth pass are provably limited in
expressive power to the constant-depth circuit class TC0. Running a Transformer
autoregressively removes that ceiling -- first in next-token prediction and,
more recently, in chain-of-thought reasoning. Both regimes rely on feedback
loops that decode internal states into tokens only to re-encode them in
subsequent steps. While this "thinking aloud" mirrors human reasoning,
biological brains iterate without externalising intermediate states as
language. To boost the expressive power of encoder Transformers without
resorting to token-level autoregression, we introduce the SELF-Transformer: an
encoder layer that iteratively refines its own attention weights to a fixed
point. Instead of producing -- in one pass -- the alignment matrix that remixes
the input sequence, the SELF-Transformer iteratively updates that matrix
internally, scaling test-time computation with input difficulty. This
adaptivity yields up to 20\% accuracy gains on encoder-style benchmarks without
increasing parameter count, demonstrating that input-adaptive alignment at test
time offers substantial benefits for only a modest extra compute budget.
Self-Transformers thus recover much of the expressive power of iterative
reasoning while preserving the simplicity of pure encoder architectures.

</details>


### [126] [Apple Intelligence Foundation Language Models: Tech Report 2025](https://arxiv.org/abs/2507.13575)
*Hanzhi Zhou,Erik Hornberger,Pengsheng Guo,Xiyou Zhou,Saiwen Wang,Xin Wang,Yifei He,Xuankai Chang,Rene Rauch,Louis D'hauwe,John Peebles,Alec Doane,Kohen Chia,Jenna Thibodeau,Zi-Yi Dou,Yuanyang Zhang,Ruoming Pang,Reed Li,Zhifeng Chen,Jeremy Warner,Zhaoyang Xu,Sophy Lee,David Mizrahi,Ramsey Tantawi,Chris Chaney,Kelsey Peterson,Jun Qin,Alex Dombrowski,Mira Chiang,Aiswarya Raghavan,Gerard Casamayor,Qibin Chen,Aonan Zhang,Nathalie Tran,Jianyu Wang,Hang Su,Thomas Voice,Alessandro Pappalardo,Brycen Wershing,Prasanth Yadla,Rui Li,Priyal Chhatrapati,Ismael Fernandez,Yusuf Goren,Xin Zheng,Forrest Huang,Tao Lei,Eray Yildiz,Alper Kokmen,Gokul Santhanam,Areeba Kamal,Kaan Elgin,Dian Ang Yap,Jeremy Liu,Peter Gray,Howard Xing,Kieran Liu,Matteo Ronchi,Moritz Schwarzer-Becker,Yun Zhu,Mandana Saebi,Jeremy Snow,David Griffiths,Guillaume Tartavel,Erin Feldman,Simon Lehnerer,Fernando Bermúdez-Medina,Hans Han,Joe Zhou,Xiaoyi Ren,Sujeeth Reddy,Zirui Wang,Tom Gunter,Albert Antony,Yuanzhi Li,John Dennison,Tony Sun,Yena Han,Yi Qin,Sam Davarnia,Jeffrey Bigham,Wayne Shan,Hannah Gillis Coleman,Guillaume Klein,Peng Liu,Muyang Yu,Jack Cackler,Yuan Gao,Crystal Xiao,Binazir Karimzadeh,Zhengdong Zhang,Felix Bai,Albin Madappally Jose,Feng Nan,Nazir Kamaldin,Dong Yin,Hans Hao,Yanchao Sun,Yi Hua,Charles Maalouf,Alex Guillen Garcia,Guoli Yin,Lezhi Li,Mohana Prasad Sathya Moorthy,Hongbin Gao,Jay Tang,Joanna Arreaza-Taylor,Faye Lao,Carina Peng,Josh Shaffer,Dan Masi,Sushma Rao,Tommi Vehvilainen,Senyu Tong,Dongcai Shen,Yang Zhao,Chris Bartels,Peter Fu,Qingqing Cao,Christopher Neubauer,Ethan Li,Mingfei Gao,Rebecca Callahan,Richard Wei,Patrick Dong,Alex Braunstein,Sachin Ravi,Adolfo Lopez Mendez,Kaiwei Huang,Kun Duan,Haoshuo Huang,Rui Qian,Stefano Ligas,Jordan Huffaker,Dongxu Li,Bailin Wang,Nanzhu Wang,Anuva Agarwal,Tait Madsen,Josh Newnham,Abhishek Sharma,Zhile Ren,Deepak Gopinath,Erik Daxberger,Saptarshi Guha,Oron Levy,Jing Lu,Nan Dun,Marc Kirchner,Yinfei Yang,Manjot Bilkhu,Dave Nelson,Anthony Spalvieri-Kruse,Juan Lao Tebar,Yang Xu,Phani Mutyala,Gabriel Jacoby-Cooper,Yingbo Wang,Karla Vega,Vishaal Mahtani,Darren Botten,Eric Wang,Hanli Li,Matthias Paulik,Haoran Yan,Navid Shiee,Yihao Qian,Bugu Wu,Qi Zhu,Ob Adaranijo,Bhuwan Dhingra,Zhe Gan,Nicholas Seidl,Grace Duanmu,Rong Situ,Yiping Ma,Yin Xia,David Riazati,Vasileios Saveris,Anh Nguyen,Michael,Lee,Patrick Sonnenberg,Chinguun Erdenebileg,Yanghao Li,Vivian Ma,James Chou,Isha Garg,Mark Lee,Keen You,Yuhong Li,Ransen Niu,Nandhitha Raghuram,Pulkit Agrawal,Henry Mason,Sumeet Singh,Keyu He,Hong-You Chen,Lucas Guibert,Shiyu Li,Varsha Paidi,Narendran Raghavan,Mingze Xu,Yuli Yang,Sergiu Sima,Irina Belousova,Sprite Chu,Afshin Dehghan,Philipp Dufter,David Haldimann,Zhen Yang,Margit Bowler,Chang Liu,Ying-Chang Cheng,Vivek Rathod,Syd Evans,Wilson Tsao,Dustin Withers,Haitian Sun,Biyao Wang,Peter Grasch,Walker Cheng,Yihao Feng,Vivek Kumar,Frank Chu,Victoria MönchJuan Haladjian,Doug Kang,Jiarui Lu,Ciro Sannino,Max Lam,Floris Weers,Bowen Pan,Kenneth Jung,Dhaval Doshi,Fangping Shi,Olli Saarikivi,Alp Aygar,Josh Elman,Cheng Leong,Eshan Verma,Matthew Lei,Jeff Nichols,Jiulong Shan,Donald Zhang,Lawrence Zhou,Stephen Murphy,Xianzhi Du,Chang Lan,Ankur Jain,Elmira Amirloo,Marcin Eichner,Naomy Sabo,Anupama Mann Anupama,David Qiu,Zhao Meng,Michael FitzMaurice,Peng Zhang,Simon Yeung,Chen Chen,Marco Zuliani,Andrew Hansen,Yang Lu,Brent Ramerth,Ziyi Zhong,Parsa Mazaheri,Matthew Hopkins,Mengyu Li,Simon Wang,David Chen,Farzin Rasteh,Chong Wang,Josh Gardner,Asaf Liberman,Haoxuan You,Andrew Walkingshaw,Xingyu Zhou,Jinhao Lei,Yan Meng,Quentin Keunebroek,Sam Wiseman,Anders Boesen Lindbo Larsen,Yi Zhang,Zaid Ahmed,Haiming Gang,Aaron Franklin,Kelvin Zou,Guillaume Seguin,Jonathan Janke,Rachel Burger,Co Giang,Cheng Shen,Jen Liu,Sanskruti Shah,Xiang Kong,Yiran Fei,TJ Collins,Chen Zhang,Zhiyun Lu,Michael Booker,Qin Ba,Yasutaka Tanaka,Andres Romero Mier Y Teran,Federico Scozzafava,Regan Poston,Jane Li,Eduardo Jimenez,Bas Straathof,Karanjeet Singh,Lindsay Hislop,Rajat Arora,Deepa Seshadri,Boyue Li,Colorado Reed,Zhen Li,TJ Lu,Yi Wang,Kaelen Haag,Nicholas Lusskin,Raunak Sinha,Rahul Nair,Eldon Schoop,Mary Beth Kery,Mehrdad Farajtbar,Brenda Yang,George Horrell,Shiwen Zhao,Dhruti Shah,Cha Chen,Bowen Zhang,Chang Gao,Devi Krishna,Jennifer Mallalieu,Javier Movellan,Di Feng,Emily Zhang,Sam Xu,Junting Pan,Dominik Moritz,Suma Jayaram,Kevin Smith,Dongseong Hwang,Daniel Parilla,Jiaming Hu,You-Cyuan Jhang,Emad Soroush,Fred Hohman,Nan Du,Emma Wang,Sam Dodge,Pragnya Sridhar,Joris Pelemans,Wei Fang,Nina Wenzel,Joseph Yitan Cheng,Hadas Kotek,Chung-Cheng Chiu,Meng Cao,Haijing Fu,Ruixuan Hou,Ke Ye,Diane Zhu,Nikhil Bhendawade,Joseph Astrauskas,Jian Liu,Sai Aitharaju,Wentao Wu,Artsiom Peshko,Hyunjik Kim,Nilesh Shahdadpuri,Andy De Wang,Qi Shan,Piotr Maj,Raul Rea Menacho,Justin Lazarow,Eric Liang Yang,Arsalan Farooq,Donghan Yu,David Güera,Minsik Cho,Kavya Nerella,Yongqiang Wang,Tao Jia,John Park,Jeff Lai,Haotian Zhang,Futang Peng,Daniele Molinari,Aparna Rajamani,Tyler Johnson,Lauren Gardiner,Chao Jia,Violet Yao,Wojciech Kryscinski,Xiujun Li,Shang-Chen Wu*

Main category: cs.LG

TL;DR: 苹果推出了两款多语言多模态基础模型：一个针对Apple芯片优化的3B参数端侧模型，以及一个基于新型PT-MoE Transformer构建的可扩展服务端模型，它们为Apple Intelligence提供支持，并在性能上媲美或超越同等规模的开源基线，同时强调隐私和负责任AI。


<details>
  <summary>Details</summary>
Motivation: 为Apple设备和服务提供强大的AI功能（Apple Intelligence），需要开发高效、高质量、支持多语言和多模态的语言模型，并解决端侧部署的资源限制以及服务端的可扩展性、成本和隐私问题。

Method: 开发了两个主要模型：1) 3B参数端侧模型：通过KV-cache共享和2位量化感知训练优化，适应Apple芯片。2) 可扩展服务端模型：基于新型Parallel-Track Mixture-of-Experts (PT-MoE) Transformer，结合了轨迹并行、专家混合稀疏计算和交错式全局-局部注意力。两个模型均在通过负责任网络爬取、许可语料库和高质量合成数据构建的大规模多语言多模态数据集上进行训练，并通过有监督微调和强化学习进一步优化。同时，推出了新的Swift-centric Foundation Models框架，以方便开发者集成。

Result: 开发出的模型支持多种额外语言，能够理解图像并执行工具调用。在公开基准测试和人工评估中，服务端模型和端侧模型均达到或超越了同等规模的开源基线。通过Responsible AI方法、内容过滤、本地化评估以及Private Cloud Compute等创新，保障了用户隐私。

Conclusion: 苹果成功开发并部署了高效、高质量、多语言多模态的基础模型，这些模型为Apple Intelligence提供了核心动力。它们在性能上具有竞争力，并特别强调了对用户隐私的保护和负责任AI的实践，同时通过Swift框架便于开发者集成。

Abstract: We introduce two multilingual, multimodal foundation language models that
power Apple Intelligence features across Apple devices and services: i a
3B-parameter on-device model optimized for Apple silicon through architectural
innovations such as KV-cache sharing and 2-bit quantization-aware training; and
ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts
PT-MoE transformer that combines track parallelism, mixture-of-experts sparse
computation, and interleaved global-local attention to deliver high quality
with competitive cost on Apple's Private Cloud Compute platform. Both models
are trained on large-scale multilingual and multimodal datasets sourced via
responsible web crawling, licensed corpora, and high-quality synthetic data,
then further refined with supervised fine-tuning and reinforcement learning on
a new asynchronous platform. The resulting models support several additional
languages while understanding images and executing tool calls. In public
benchmarks and human evaluations, both the server model and the on-device model
match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation,
constrained tool calling, and LoRA adapter fine-tuning, allowing developers to
integrate these capabilities with a few lines of code. The latest advancements
in Apple Intelligence models are grounded in our Responsible AI approach with
safeguards like content filtering and locale-specific evaluation, as well as
our commitment to protecting our users' privacy with innovations like Private
Cloud Compute.

</details>


### [127] [Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries](https://arxiv.org/abs/2507.13579)
*Hyunji Nam,Yanming Wan,Mickel Liu,Jianxun Lian,Natasha Jaques*

Main category: cs.LG

TL;DR: 为解决大型语言模型（LLM）个性化对齐问题，本文提出PLUS框架，通过学习用户偏好文本摘要来调节奖励模型，实现用户定制化的LLM响应，提高透明度和控制。


<details>
  <summary>Details</summary>
Motivation: 现有的人类反馈强化学习（RLHF）在提升LLM通用性方面有效，但由于使用单一奖励模型，无法针对不同用户的多样化偏好和目标进行个性化响应。

Method: 提出“使用摘要偏好学习”（PLUS）框架，通过强化学习训练一个用户摘要模型，生成每个用户的偏好、特征和历史对话的文本摘要。这些摘要用于条件化奖励模型，使其能对不同用户的价值响应进行个性化预测。摘要模型和奖励模型同步更新，形成在线协同适应循环。

Result: PLUS生成的用户摘要能有效捕捉用户偏好，优于之前的个性化RLHF技术和上下文学习。该方法对新用户和多样化对话主题具有鲁棒性。此外，生成的文本摘要可用于对GPT-4等专有模型进行零样本个性化。

Conclusion: PLUS生成的文本用户摘要简洁、可移植，且易于用户理解和修改，从而在LLM对齐过程中增强了透明度和用户控制能力。

Abstract: As everyday use cases of large language model (LLM) AI assistants have
expanded, it is becoming increasingly important to personalize responses to
align to different users' preferences and goals. While reinforcement learning
from human feedback (RLHF) is effective at improving LLMs to be generally more
helpful and fluent, it does not account for variability across users, as it
models the entire user population with a single reward model. We present a
novel framework, Preference Learning Using Summarization (PLUS), that learns
text-based summaries of each user's preferences, characteristics, and past
conversations. These summaries condition the reward model, enabling it to make
personalized predictions about the types of responses valued by each user. We
train the user-summarization model with reinforcement learning, and update the
reward model simultaneously, creating an online co-adaptation loop. We show
that in contrast with prior personalized RLHF techniques or with in-context
learning of user information, summaries produced by PLUS capture meaningful
aspects of a user's preferences. Across different pluralistic user datasets, we
show that our method is robust to new users and diverse conversation topics.
Additionally, we demonstrate that the textual summaries generated about users
can be transferred for zero-shot personalization of stronger, proprietary
models like GPT-4. The resulting user summaries are not only concise and
portable, they are easy for users to interpret and modify, allowing for more
transparency and user control in LLM alignment.

</details>


### [128] [Off-Policy Evaluation and Learning for Matching Markets](https://arxiv.org/abs/2507.13608)
*Yudai Hayashi,Shuhei Goda,Yuta Saito*

Main category: cs.LG

TL;DR: 本文针对匹配市场（如招聘、约会应用）中离线策略评估（OPE）面临的挑战，提出了新型OPE估计器DiPS和DPR，以实现更可靠的评估和策略学习。


<details>
  <summary>Details</summary>
Motivation: A/B测试在匹配市场推荐系统中成本高昂且不灵活。现有OPE方法在匹配平台中由于大规模、双向互动、方差问题和奖励稀疏性而不可靠，需要更有效的离线评估方法。

Method: 提出DiPS和DPR两种新型OPE估计器，专为匹配市场设计。它们结合了直接法（DM）、逆倾向性得分（IPS）和双重鲁棒（DR）估计器的优点，并融入了中间标签（如初始参与信号），以实现更好的偏差-方差控制。理论上推导了其偏差和方差，并展示其可扩展到离线策略学习。

Result: 理论分析表明所提方法优于传统方法。在合成数据和真实招聘平台的A/B测试日志上的实证评估显示，所提方法在离线策略评估和学习任务中均优于现有方法。

Conclusion: DiPS和DPR为匹配市场的推荐策略提供了更优越、更可靠的离线评估和学习能力，有效克服了传统OPE方法在该复杂设置下的局限性。

Abstract: Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

</details>


### [129] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
*Binxiong Li,Yuefei Wang,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao,Xi Yu*

Main category: cs.LG

TL;DR: 本研究提出Tri-Learn Graph Fusion Network (Tri-GFN)，一种结合图卷积网络(GCN)、自编码器(AE)和图Transformer的深度聚类框架，通过三学习机制和特征融合策略解决现有GCN和图Transformer在处理大规模异构图数据时存在的过平滑、过压缩及性能限制问题，显著提升了图聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GCN的模型在处理大规模复杂图数据时存在过平滑和过压缩问题，导致聚类质量下降。尽管图Transformer缓解了部分问题，但在处理异构图数据时性能受限。因此，需要提出一种新型深度聚类框架来应对这些挑战。

Method: 本研究提出Tri-Learn Graph Fusion Network (Tri-GFN)，该框架包含GCN、自编码器(AE)和图Transformer模块。通过独特的三学习机制和特征融合增强策略，以及一个三重通道增强模块，实现模块间的相互学习，并最大化地利用节点属性和拓扑结构信息，从而增强全局和局部信息的区分性和一致性，获得具有高判别力的图聚类表示。

Result: Tri-GFN超越了许多SOTA方法，在ACM数据集上精度提升约0.87%，在Reuters数据集上提升14.14%，在USPS数据集上提升7.58%。鉴于其在Reuters数据集上的出色表现，Tri-GFN可应用于自动新闻分类、主题检索等领域。

Conclusion: Tri-GFN通过创新的框架设计，有效解决了现有图聚类模型在处理复杂图数据时的局限性，实现了卓越的聚类性能。其独特的组合和学习机制使其能够生成高判别力的表示，有望在实际应用中发挥重要作用。

Abstract: In recent years, models based on Graph Convolutional Networks (GCN) have made
significant strides in the field of graph data analysis. However, challenges
such as over-smoothing and over-compression remain when handling large-scale
and complex graph datasets, leading to a decline in clustering quality.
Although the Graph Transformer architecture has mitigated some of these issues,
its performance is still limited when processing heterogeneous graph data. To
address these challenges, this study proposes a novel deep clustering framework
that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the
Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the
differentiation and consistency of global and local information through a
unique tri-learning mechanism and feature fusion enhancement strategy. The
framework integrates GCN, AE, and Graph Transformer modules. These components
are meticulously fused by a triple-channel enhancement module, which maximizes
the use of both node attributes and topological structures, ensuring robust
clustering representation. The tri-learning mechanism allows mutual learning
among these modules, while the feature fusion strategy enables the model to
capture complex relationships, yielding highly discriminative representations
for graph clustering. It surpasses many state-of-the-art methods, achieving an
accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the
Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding
performance on the Reuters dataset, Tri-GFN can be applied to automatic news
classification, topic retrieval, and related fields.

</details>


### [130] [A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design](https://arxiv.org/abs/2507.13646)
*Nimisha Ghosh,Daniele Santoni,Debaleena Nawn,Eleonora Ottaviani,Giovanni Felici*

Main category: cs.LG

TL;DR: 本文综述了Transformer模型在蛋白质序列分析和设计领域的最新进展，涵盖基因本体、蛋白质识别、从头生成和结合等应用，并探讨了现有研究的优缺点及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在NLP领域的巨大成功促使其被引入生物信息学，尤其是在蛋白质序列分析和设计方面。本文旨在对Transformer模型在该领域的最新进展进行全面综述。

Method: 采用文献综述方法，讨论并分析了大量将Transformer模型应用于蛋白质序列分析和设计的工作。

Result: 综述了Transformer模型在基因本体、功能与结构蛋白质识别、从头蛋白质生成和蛋白质结合等方面的应用，并深入分析了现有研究的优缺点，提供了全面洞察。

Conclusion: 指出了现有研究的不足并提出了未来发展方向，旨在帮助研究人员了解该领域现状并指导其后续研究。

Abstract: The impact of Transformer-based language models has been unprecedented in
Natural Language Processing (NLP). The success of such models has also led to
their adoption in other fields including bioinformatics. Taking this into
account, this paper discusses recent advances in Transformer-based models for
protein sequence analysis and design. In this review, we have discussed and
analysed a significant number of works pertaining to such applications. These
applications encompass gene ontology, functional and structural protein
identification, generation of de novo proteins and binding of proteins. We
attempt to shed light on the strength and weaknesses of the discussed works to
provide a comprehensive insight to readers. Finally, we highlight shortcomings
in existing research and explore potential avenues for future developments. We
believe that this review will help researchers working in this field to have an
overall idea of the state of the art in this field, and to orient their future
studies.

</details>


### [131] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: 提出VIDAR框架，通过大规模视频扩散预训练和掩蔽逆动力学模型，解决了双臂机器人操作中的数据稀缺和平台异构问题，实现了高效泛化。


<details>
  <summary>Details</summary>
Motivation: 双臂机器人操作在复杂任务中至关重要，但数据稀缺和平台异构性严重阻碍了其在大规模环境中的进一步应用。

Method: 提出VIDAR，一个两阶段框架。第一阶段：在大规模多视角视频（75万条）上预训练视频扩散模型，使用统一观测空间。第二阶段：引入新颖的掩蔽逆动力学模型进行动作预测，该模型学习提取动作相关信息并能泛化到新背景。

Result: 仅需20分钟人类演示（典型数据需求的1%），VIDAR在未见过的机器人平台上表现出强大的泛化能力，能应用于新任务和背景，并超越了现有最先进方法。

Conclusion: 视频基础模型结合掩蔽动作预测，为在多样化真实世界环境中实现可扩展、可泛化的机器人操作提供了新的可能性。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [132] [Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction](https://arxiv.org/abs/2507.13685)
*Yue Yang,Zihan Su,Ying Zhang,Chang Chuan Goh,Yuxiang Lin,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 本研究提出GRU-KAN和LSTM-KAN模型，旨在提升贷款违约事件的早期预测能力，实现提前三月和八月的高准确率预测，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列异常检测中贷款违约模型提前预测能力不足的挑战，以使金融机构能更早识别风险并采取预防措施。现有方法在早期预测准确性及跨时间数据泛化能力方面存在显著缺陷。

Method: 引入两种结合了Kolmogorov-Arnold网络（KAN）与门控循环单元（GRU）及长短期记忆（LSTM）网络的创新架构：GRU-KAN和LSTM-KAN。通过在不同特征窗口、样本量和预测间隔下，使用准确率、精确率、召回率、F1和AUC等指标，与基线模型（LSTM, GRU, LSTM-Attention, LSTM-Transformer）进行性能评估。

Result: 提出的模型在提前三个月时预测准确率超过92%，提前八个月时超过88%，显著优于现有基线模型。

Conclusion: GRU-KAN和LSTM-KAN模型有效提高了贷款违约的早期预测准确性，为金融机构在风险事件发生前采取预防措施提供了更强大的工具。

Abstract: This study addresses a critical challenge in time series anomaly detection:
enhancing the predictive capability of loan default models more than three
months in advance to enable early identification of default events, helping
financial institutions implement preventive measures before risk events
materialize. Existing methods have significant drawbacks, such as their lack of
accuracy in early predictions and their dependence on training and testing
within the same year and specific time frames. These issues limit their
practical use, particularly with out-of-time data. To address these, the study
introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge
Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long
Short-Term Memory (LSTM) networks. The proposed models were evaluated against
the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms
of accuracy, precision, recall, F1 and AUC in different lengths of feature
window, sample sizes, and early prediction intervals. The results demonstrate
that the proposed model achieves a prediction accuracy of over 92% three months
in advance and over 88% eight months in advance, significantly outperforming
existing baselines.

</details>


### [133] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
*Martin Krutský,Gustav Šír,Vyacheslav Kungurtsev,Georgios Korpas*

Main category: cs.LG

TL;DR: 物理启发式图神经网络（PI-GNNs）在处理高密度组合优化问题时性能下降。作者分析其原因为实值输出与二值解的差异，并提出结合模糊逻辑和二值化神经网络的改进方法，成功提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管PI-GNNs已在各种组合优化问题中取得有前景的结果，但其性能会随着问题图密度的增加而系统性地急剧下降。

Method: 通过分析揭示了PI-GNNs训练动态中的相变，该相变与密集问题中的退化解相关，凸显了松弛的实值模型输出与二值问题解之间的差异。为解决此差异，提出了基于模糊逻辑和二值化神经网络的替代策略。

Result: 实验证明，所提出的方法组合显著提升了PI-GNNs在日益密集的设置下的性能。

Conclusion: 针对PI-GNNs在处理高密度组合优化问题时性能下降的问题，通过引入基于模糊逻辑和二值化神经网络的策略，可以有效弥合实值输出与二值解之间的差距，从而显著提高PI-GNNs在此类问题上的表现。

Abstract: Physics-inspired graph neural networks (PI-GNNs) have been utilized as an
efficient unsupervised framework for relaxing combinatorial optimization
problems encoded through a specific graph structure and loss, reflecting
dependencies between the problem's variables. While the framework has yielded
promising results in various combinatorial problems, we show that the
performance of PI-GNNs systematically plummets with an increasing density of
the combinatorial problem graphs. Our analysis reveals an interesting phase
transition in the PI-GNNs' training dynamics, associated with degenerate
solutions for the denser problems, highlighting a discrepancy between the
relaxed, real-valued model outputs and the binary-valued problem solutions. To
address the discrepancy, we propose principled alternatives to the naive
strategy used in PI-GNNs by building on insights from fuzzy logic and binarized
neural networks. Our experiments demonstrate that the portfolio of proposed
methods significantly improves the performance of PI-GNNs in increasingly dense
settings.

</details>


### [134] [Bayesian Optimization for Molecules Should Be Pareto-Aware](https://arxiv.org/abs/2507.13704)
*Anabel Yong,Austin Tripp,Layla Hosseini-Gerami,Brooks Paige*

Main category: cs.LG

TL;DR: 本研究对比了多目标贝叶斯优化（MOBO）中的EHVI策略与标量化贝叶斯优化中的EI策略在分子设计任务中的表现。结果显示，EHVI在帕累托前沿覆盖、收敛速度和化学多样性方面均优于标量化EI，尤其是在数据量有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 多目标贝叶斯优化（MOBO）为分子设计中的权衡提供了原则性框架，但其相较于标量化方法的经验优势尚未被充分探索。本研究旨在通过基准测试，验证MOBO在实际应用中的优势。

Method: 研究在一个严格控制的环境下，比较了基于帕累托的MOBO策略（预期超体积改进EHVI）与简单的固定权重标量化基线（使用预期改进EI）。实验中使用了相同的高斯过程代理模型和分子表示。测试在三个分子优化任务中进行。

Result: EHVI在帕累托前沿覆盖、收敛速度和化学多样性方面持续优于标量化EI。研究还发现，即使是强大的确定性标量化方法，在低数据量情况下也可能表现不佳。

Conclusion: 这些发现为帕累托感知获取策略（如EHVI）在从头分子优化中的实际优势提供了具体证据，尤其是在评估预算有限且权衡复杂的情况下。

Abstract: Multi-objective Bayesian optimization (MOBO) provides a principled framework
for navigating trade-offs in molecular design. However, its empirical
advantages over scalarized alternatives remain underexplored. We benchmark a
simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --
against a simple fixed-weight scalarized baseline using Expected Improvement
(EI), under a tightly controlled setup with identical Gaussian Process
surrogates and molecular representations. Across three molecular optimization
tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front
coverage, convergence speed, and chemical diversity. While scalarization
encompasses flexible variants -- including random or adaptive schemes -- our
results show that even strong deterministic instantiations can underperform in
low-data regimes. These findings offer concrete evidence for the practical
advantages of Pareto-aware acquisition in de novo molecular optimization,
especially when evaluation budgets are limited and trade-offs are nontrivial.

</details>


### [135] [Learning Deformable Body Interactions With Adaptive Spatial Tokenization](https://arxiv.org/abs/2507.13707)
*Hao Wang,Yu Liu,Daniel Biggs,Haoru Wang,Jiandong Yu,Ping Huang*

Main category: cs.LG

TL;DR: 提出一种名为AST（自适应空间分词）的新方法，通过空间分词和注意力机制实现可变形体交互的准确且可扩展的模拟，解决了现有GNN方法的计算限制，并发布了大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 在材料科学、机械设计和机器人技术等领域，可变形体间的交互模拟至关重要。然而，基于GNN的学习方法在建模可变形体交互时遇到可扩展性问题，特别是动态创建全局边计算密集，不适用于大规模网格。

Method: 提出自适应空间分词（AST）方法。该方法将模拟空间划分为网格单元，并将非结构化网格映射到结构化网格上，从而自然地将相邻网格节点分组。接着，使用交叉注意力模块将稀疏单元映射到紧凑的定长嵌入（作为物理状态的token）。最后，利用自注意力模块在潜在空间中预测下一个状态。

Result: 实验证明，AST方法在模拟可变形体交互方面显著优于现有最新方法。它在节点数超过100,000的大规模模拟中依然有效，而现有方法在此类情况下受计算限制。此外，还贡献了一个包含广泛可变形体交互的新型大规模数据集。

Conclusion: 该框架利用分词的效率和注意力机制的表达能力，实现了准确且可扩展的模拟结果，有效解决了大规模可变形体交互模拟的挑战，并为未来研究提供了数据集支持。

Abstract: Simulating interactions between deformable bodies is vital in fields like
material science, mechanical design, and robotics. While learning-based methods
with Graph Neural Networks (GNNs) are effective at solving complex physical
systems, they encounter scalability issues when modeling deformable body
interactions. To model interactions between objects, pairwise global edges have
to be created dynamically, which is computationally intensive and impractical
for large-scale meshes. To overcome these challenges, drawing on insights from
geometric representations, we propose an Adaptive Spatial Tokenization (AST)
method for efficient representation of physical states. By dividing the
simulation space into a grid of cells and mapping unstructured meshes onto this
structured grid, our approach naturally groups adjacent mesh nodes. We then
apply a cross-attention module to map the sparse cells into a compact,
fixed-length embedding, serving as tokens for the entire physical state.
Self-attention modules are employed to predict the next state over these tokens
in latent space. This framework leverages the efficiency of tokenization and
the expressive power of attention mechanisms to achieve accurate and scalable
simulation results. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches in modeling deformable
body interactions. Notably, it remains effective on large-scale simulations
with meshes exceeding 100,000 nodes, where existing methods are hindered by
computational limitations. Additionally, we contribute a novel large-scale
dataset encompassing a wide range of deformable body interactions to support
future research in this area.

</details>


### [136] [Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods](https://arxiv.org/abs/2507.13716)
*Danilo Avola,Andrea Bernardini,Giancarlo Crocetti,Andrea Ladogana,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 该研究系统性地基准测试了传统机器学习和深度学习模型在帕金森病（PD）EEG数据分类上的表现，发现CNN-LSTM模型效果最佳，同时传统模型如XGBoost也表现良好，为未来研究提供了坚实的参考框架。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期诊断至关重要，而EEG作为一种非侵入性工具，在检测PD相关神经变化方面具有潜力。然而，开发可靠的自动化诊断模型仍面临挑战，因此研究旨在为构建有效的学习系统奠定基础并确定最佳方法。

Method: 研究采用公开的“oddball task”数据集，实施了统一的七步预处理流程。通过一致的受试者内交叉验证和评估标准，系统性地基准测试了包括传统机器学习模型（如XGBoost）和深度学习模型（特别是CNN-LSTM）在内的多种分类器。

Result: 基线深度学习架构中，CNN-LSTM模型表现最佳，突出了捕捉长距离时间依赖性的重要性。同时，XGBoost等传统分类器也展现出强大的预测准确性和校准决策边界。

Conclusion: 本研究通过严格比较各类基线模型，为未来旨在开发更复杂或专业化架构的研究提供了坚实的参考框架，有助于确保EEG神经诊断领域研究的科学严谨性和可重复性。

Abstract: Parkinson's Disease PD is a progressive neurodegenerative disorder that
affects motor and cognitive functions with early diagnosis being critical for
effective clinical intervention Electroencephalography EEG offers a noninvasive
and costeffective means of detecting PDrelated neural alterations yet the
development of reliable automated diagnostic models remains a challenge In this
study we conduct a systematic benchmark of traditional machine learning ML and
deep learning DL models for classifying PD using a publicly available oddball
task dataset Our aim is to lay the groundwork for developing an effective
learning system and to determine which approach produces the best results We
implement a unified sevenstep preprocessing pipeline and apply consistent
subjectwise crossvalidation and evaluation criteria to ensure comparability
across models Our results demonstrate that while baseline deep learning
architectures particularly CNNLSTM models achieve the best performance compared
to other deep learning architectures underlining the importance of capturing
longrange temporal dependencies several traditional classifiers such as XGBoost
also offer strong predictive accuracy and calibrated decision boundaries By
rigorously comparing these baselines our work provides a solid reference
framework for future studies aiming to develop and evaluate more complex or
specialized architectures Establishing a reliable set of baseline results is
essential to contextualize improvements introduced by novel methods ensuring
scientific rigor and reproducibility in the evolving field of EEGbased
neurodiagnostics

</details>


### [137] [Bi-GRU Based Deception Detection using EEG Signals](https://arxiv.org/abs/2507.13718)
*Danilo Avola,Muhammad Yasir Bilal,Emad Emam,Cristina Lakasz,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本研究使用Bi-GRU深度学习模型，通过EEG信号在Bag-of-Lies数据集上实现了高达97%准确率的欺骗行为检测。


<details>
  <summary>Details</summary>
Motivation: 欺骗检测在安全、心理学和法医学等领域是一个重大挑战。

Method: 利用Bag-of-Lies数据集中的脑电图（EEG）信号，训练了一个双向门控循环单元（Bi-GRU）神经网络模型，进行欺骗与真实行为的二分类。

Result: 模型在测试中达到了97%的准确率，并在两类中均获得了高精确度、召回率和F1分数。

Conclusion: 研究结果表明，双向时间建模在基于EEG的欺骗检测中是有效的，并为实时应用和未来高级神经网络架构的探索提供了潜力。

Abstract: Deception detection is a significant challenge in fields such as security,
psychology, and forensics. This study presents a deep learning approach for
classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)
signals from the Bag-of-Lies dataset, a multimodal corpus designed for
naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit
(Bi-GRU) neural network was trained to perform binary classification of EEG
samples. The model achieved a test accuracy of 97\%, along with high precision,
recall, and F1-scores across both classes. These results demonstrate the
effectiveness of using bidirectional temporal modeling for EEG-based deception
detection and suggest potential for real-time applications and future
exploration of advanced neural architectures.

</details>


### [138] [Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion](https://arxiv.org/abs/2507.13721)
*Zizhao Zhang,Tianxiang Zhao,Yu Sun,Liping Sun,Jichuan Kang*

Main category: cs.LG

TL;DR: 本文提出一种混合特征融合框架，用于构建自主货船故障模式图结构数据集，通过改进的布谷鸟搜索算法提高文献检索效率，并利用分层特征融合方法和GATE-GNN模型实现高准确度的故障分类与预测，为自主货船的故障分析和智能决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 针对自主货船（ACS）中部件故障导致的级联反应挑战以及应急决策的不确定性问题，需要一个新颖的框架来有效处理和分析故障模式。

Method: ['提出一种混合特征融合框架，用于构建故障模式的图结构数据集。', '采用改进的布谷鸟搜索算法（HN-CSA）提升文献检索效率。', '构建分层特征融合框架：使用Word2Vec编码子系统/部件特征，BERT-KPCA处理故障模式/原因，Sentence-BERT量化故障影响与应急决策的语义关联。', '利用GATE-GNN模型进行故障分类和验证。']

Result: ['改进的布谷鸟搜索算法（HN-CSA）文献检索效率比NSGA-II和CSA分别提高7.1%和3.4%。', '构建了一个包含12个系统、1,262种故障模式和6,150条传播路径的图结构数据集。', 'GATE-GNN模型分类准确率达到0.735，与现有基准相当。', '特征轮廓系数为0.641，表明特征具有高度可区分性。', '在标签预测中，岸基气象服务系统F1分数达到0.93，展现高预测精度。']

Conclusion: 本研究为自主货船的故障分析奠定了坚实基础，并为故障诊断、风险评估和智能决策系统提供了可靠支持。所构建的数据集已公开。

Abstract: To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.

</details>


### [139] [Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics](https://arxiv.org/abs/2507.13727)
*René Heinrich,Lukas Rauch,Bernhard Sick,Christoph Scholz*

Main category: cs.LG

TL;DR: 对抗训练能提高音频分类模型在数据分布偏移下的泛化能力和对抗鲁棒性，尤其在使用输出空间攻击时，通过鸟叫声分类验证。


<details>
  <summary>Details</summary>
Motivation: 现有研究对对抗训练在音频分类中应对显著数据分布偏移时对泛化能力的影响探索不足。

Method: 研究在具有显著分布偏移的鸟叫声分类基准上进行，使用ConvNeXt和AudioProtoPNet两种模型架构。探讨了基于输出空间（最大化分类损失）和基于嵌入空间（最大化嵌入不相似性）的两种对抗训练策略。评估了模型鲁棒性，并额外评估了AudioProtoPNet原型稳定性。

Result: 对抗训练（特别是使用输出空间攻击）使干净测试数据性能平均相对提升10.5%，并同时增强了模型的对抗鲁棒性。

Conclusion: 对抗训练在应对强数据分布偏移和对抗攻击的复杂音频分类场景中，具有增强模型鲁棒性的潜力。

Abstract: Adversarial training is a promising strategy for enhancing model robustness
against adversarial attacks. However, its impact on generalization under
substantial data distribution shifts in audio classification remains largely
unexplored. To address this gap, this work investigates how different
adversarial training strategies improve generalization performance and
adversarial robustness in audio classification. The study focuses on two model
architectures: a conventional convolutional neural network (ConvNeXt) and an
inherently interpretable prototype-based model (AudioProtoPNet). The approach
is evaluated using a challenging bird sound classification benchmark. This
benchmark is characterized by pronounced distribution shifts between training
and test data due to varying environmental conditions and recording methods, a
common real-world challenge. The investigation explores two adversarial
training strategies: one based on output-space attacks that maximize the
classification loss function, and another based on embedding-space attacks
designed to maximize embedding dissimilarity. These attack types are also used
for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses
the stability of its learned prototypes under targeted embedding-space attacks.
Results show that adversarial training, particularly using output-space
attacks, improves clean test data performance by an average of 10.5% relative
and simultaneously strengthens the adversarial robustness of the models. These
findings, although derived from the bird sound domain, suggest that adversarial
training holds potential to enhance robustness against both strong distribution
shifts and adversarial attacks in challenging audio classification settings.

</details>


### [140] [An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC](https://arxiv.org/abs/2507.13736)
*Matthias Jobst,Tim Langer,Chen Liu,Mehmet Alici,Hector A. Gonzalez,Christian Mayr*

Main category: cs.LG

TL;DR: 本文提出了一个多层DNN调度框架，扩展了OctopuScheduler，实现了从PyTorch模型到单个SpiNNaker2芯片上推理的端到端流程，支持在边缘端执行Transformer级别的大型复杂DNN。


<details>
  <summary>Details</summary>
Motivation: 在SpiNNaker2等神经形态平台上实现大型复杂深度神经网络（DNNs，乃至Transformer级别）的边缘执行。

Method: 提出了一个多层DNN调度框架，作为OctopuScheduler的扩展，它提供了一个从PyTorch模型到SpiNNaker2芯片推理的端到端流程。该框架还包含一个进行量化和降低步骤的前端。

Result: 所提出的框架使得在神经形态平台SpiNNaker2上能够实现包括Transformer级别在内的大型复杂DNN的边缘端执行。

Conclusion: 该框架成功地在SpiNNaker2神经形态平台上实现了大规模深度神经网络的端到端边缘推理，展示了其支持复杂模型的能力。

Abstract: This work presents a multi-layer DNN scheduling framework as an extension of
OctopuScheduler, providing an end-to-end flow from PyTorch models to inference
on a single SpiNNaker2 chip. Together with a front-end comprised of
quantization and lowering steps, the proposed framework enables the edge-based
execution of large and complex DNNs up to transformer scale using the
neuromorphic platform SpiNNaker2.

</details>


### [141] [SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification](https://arxiv.org/abs/2507.13741)
*Shangyou Wang,Zezhong Ding,Xike Xie*

Main category: cs.LG

TL;DR: 本文提出了SamGoG，一个基于采样的图-of-图（GoG）学习框架，旨在有效缓解图神经网络（GNNs）在图分类任务中面临的类别和图大小不平衡问题，显著提升性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在图分类中表现出色，但真实世界图常存在类别和图大小不平衡问题，导致学习过程出现偏差并降低模型性能。现有方法通常仅解决其中一种不平衡，或计算成本过高。

Method: SamGoG通过一种高效的基于重要性的采样机制构建多个图-of-图（GoG），并进行顺序训练。该采样机制融合了可学习的成对相似性和自适应GoG节点度，以增强边缘同质性，从而提升下游模型质量。SamGoG可无缝集成到各种GNN中。

Result: 在基准数据集上的广泛实验表明，SamGoG实现了最先进的性能，精度提升高达15.66%，并实现了6.7倍的训练加速。

Conclusion: SamGoG框架成功解决了图分类中 GNN 面临的类别和图大小不平衡挑战，通过创新的采样和GoG学习方法，显著提高了模型性能和训练效率，并具有良好的通用性。

Abstract: Graph Neural Networks (GNNs) have shown remarkable success in graph
classification tasks by capturing both structural and feature-based
representations. However, real-world graphs often exhibit two critical forms of
imbalance: class imbalance and graph size imbalance. These imbalances can bias
the learning process and degrade model performance. Existing methods typically
address only one type of imbalance or incur high computational costs. In this
work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning
framework that effectively mitigates both class and graph size imbalance.
SamGoG constructs multiple GoGs through an efficient importance-based sampling
mechanism and trains on them sequentially. This sampling mechanism incorporates
the learnable pairwise similarity and adaptive GoG node degree to enhance edge
homophily, thus improving downstream model quality. SamGoG can seamlessly
integrate with various downstream GNNs, enabling their efficient adaptation for
graph classification tasks. Extensive experiments on benchmark datasets
demonstrate that SamGoG achieves state-of-the-art performance with up to a
15.66% accuracy improvement with 6.7$\times$ training acceleration.

</details>


### [142] [Search-Optimized Quantization in Biomedical Ontology Alignment](https://arxiv.org/abs/2507.13742)
*Oussama Bouaggad,Natalia Grabar*

Main category: cs.LG

TL;DR: 本研究提出一种基于Transformer的本体对齐系统方法，通过结合Microsoft Olive、ONNX Runtime、Intel Neural Compressor和IPEX等优化工具，在保持性能的同时，将推理速度提升20倍，内存占用减少约70%，并在DEFT 2020任务中达到新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型日益庞大，在边缘设备或资源受限环境中部署时面临计算需求高、能耗大、内存占用多及延迟等挑战，因此亟需高效的模型优化技术。

Method: 本研究采用监督式SOTA Transformer模型进行本体对齐，利用生物医学词汇与UMLS元词库之间的余弦语义相似性。优化过程通过Microsoft Olive结合ONNX Runtime后端寻找最佳优化方案，并集成Intel Neural Compressor和IPEX进行动态量化。

Result: 在DEFT 2020评估活动的两个任务中均达到新的SOTA，同时保持性能指标不变。实现平均20倍的推理速度提升和约70%的内存占用减少。

Conclusion: 本研究通过创新的优化流程，成功解决了大型AI模型在资源受限环境下的部署挑战，显著提升了推理效率（速度和内存），同时保持甚至超越了现有性能，为未来高效模型部署提供了可行方案。

Abstract: In the fast-moving world of AI, as organizations and researchers develop more
advanced models, they face challenges due to their sheer size and computational
demands. Deploying such models on edge devices or in resource-constrained
environments adds further challenges related to energy consumption, memory
usage and latency. To address these challenges, emerging trends are shaping the
future of efficient model optimization techniques. From this premise, by
employing supervised state-of-the-art transformer-based models, this research
introduces a systematic method for ontology alignment, grounded in cosine-based
semantic similarity between a biomedical layman vocabulary and the Unified
Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to
search for target optimizations among different Execution Providers (EPs) using
the ONNX Runtime backend, followed by an assembled process of dynamic
quantization employing Intel Neural Compressor and IPEX (Intel Extension for
PyTorch). Through our optimization process, we conduct extensive assessments on
the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new
state-of-the-art in both. We retain performance metrics intact, while attaining
an average inference speed-up of 20x and reducing memory usage by approximately
70%.

</details>


### [143] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
*Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Mingyue Zheng,Qian Shi*

Main category: cs.LG

TL;DR: 针对现有贝叶斯流网络（BFNs）在分子生成中灵活性不足的问题，本研究提出了一种新颖的参数插值流（PIF）模型，并开发了用于药物设计的MolPIF，实验证明其性能优于基线模型，验证了参数空间生成建模的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯流网络（BFNs）虽然性能良好，但其基于贝叶斯推断的策略限制了更灵活的分布转换路径设计，导致难以适应多样化的数据分布和任务需求。此外，更简单、高效的参数空间模型潜力尚未被充分探索。

Method: 提出了一种新颖的参数插值流（PIF）模型，并详细阐述了其理论基础、训练和推理过程。在此基础上，进一步开发了MolPIF，专门用于基于结构的药物设计。

Result: 在基于结构的药物设计任务中，MolPIF相比基线模型在多项指标上展现出卓越的性能。

Conclusion: 本研究验证了基于参数空间的分子生成建模范式的有效性，并为未来的模型设计提供了新的视角。

Abstract: Advances in deep learning for molecular generation show promise in
accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown
impressive performance across diverse chemical tasks, with their success often
ascribed to the paradigm of modeling in a low-variance parameter space.
However, the Bayesian inference-based strategy imposes limitations on designing
more flexible distribution transformation pathways, making it challenging to
adapt to diverse data distributions and varied task requirements. Furthermore,
the potential for simpler, more efficient parameter-space-based models is
unexplored. To address this, we propose a novel Parameter Interpolation Flow
model (named PIF) with detailed theoretical foundation, training, and inference
procedures. We then develop MolPIF for structure-based drug design,
demonstrating its superior performance across diverse metrics compared to
baselines. This work validates the effectiveness of parameter-space-based
generative modeling paradigm for molecules and offers new perspectives for
model design.

</details>


### [144] [Dual-Center Graph Clustering with Neighbor Distribution](https://arxiv.org/abs/2507.13765)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Li Jin,Liqiang Nie*

Main category: cs.LG

TL;DR: 针对图聚类中伪标签不可靠和指导不完整的问题，本文提出双中心图聚类（DCGC）方法，利用邻居分布进行可靠的对比学习和双中心优化，取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 图聚类是揭示复杂数据结构的关键，但其无监督性带来了显著挑战。现有目标导向的聚类技术，特别是利用伪标签的对比学习方法，存在伪标签不可靠以及仅利用特征构建单目标分布导致指导不完整和不可靠的问题。

Method: 本文提出一种基于邻居分布特性的新型双中心图聚类（DCGC）方法，包括邻居分布的表示学习和双中心优化。具体地，利用邻居分布作为监督信号在对比学习中挖掘硬负样本，以提高表示学习的有效性。此外，引入邻居分布中心与特征中心共同构建双目标分布，进行双中心优化。

Result: 大量的实验和分析表明，所提出的方法具有优越的性能和有效性。

Conclusion: 通过利用可靠的邻居分布进行表示学习并引入双中心优化，DCGC方法有效地解决了现有图聚类方法的局限性，实现了性能的显著提升。

Abstract: Graph clustering is crucial for unraveling intricate data structures, yet it
presents significant challenges due to its unsupervised nature. Recently,
goal-directed clustering techniques have yielded impressive results, with
contrastive learning methods leveraging pseudo-label garnering considerable
attention. Nonetheless, pseudo-label as a supervision signal is unreliable and
existing goal-directed approaches utilize only features to construct a
single-target distribution for single-center optimization, which lead to
incomplete and less dependable guidance. In our work, we propose a novel
Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution
properties, which includes representation learning with neighbor distribution
and dual-center optimization. Specifically, we utilize neighbor distribution as
a supervision signal to mine hard negative samples in contrastive learning,
which is reliable and enhances the effectiveness of representation learning.
Furthermore, neighbor distribution center is introduced alongside feature
center to jointly construct a dual-target distribution for dual-center
optimization. Extensive experiments and analysis demonstrate superior
performance and effectiveness of our proposed method.

</details>


### [145] [On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach](https://arxiv.org/abs/2507.13805)
*Tim Rensmeyer,Denis Kramer,Oliver Niggemann*

Main category: cs.LG

TL;DR: 本文提出一种基于贝叶斯神经网络的微调方法与在线工作流，用于机器学习原子间力场，解决了基础模型的不确定性量化难题，并能自动、高精度地检测和加速采样稀有事件。


<details>
  <summary>Details</summary>
Motivation: 从头计算原子间力计算复杂，导致机器学习力场兴起。然而，生成高质量训练数据集计算成本高，不适合稀有事件或大构型空间。微调预训练的基础模型虽有潜力减少数据量，但数据集创建仍具挑战，尤其对于稀有事件和非机器学习专业用户。在线学习利用模型不确定性自动生成训练数据，但大多数基础模型缺乏不确定性量化，阻碍了其在微调中的应用。

Method: 引入一种基于贝叶斯神经网络的微调方法，并结合后续的在线（on-the-fly）工作流。该方法旨在克服基础模型在微调过程中缺乏不确定性量化的挑战。

Result: 该方法能够自动微调模型，同时保持预设的准确性。它能检测稀有事件（如过渡态），并以高于其自然发生率的速度进行采样。

Conclusion: 本文成功解决了基础模型微调过程中不确定性量化的问题，并提供了一个自动化的、能保持高精度并有效识别和加速采样稀有事件的在线微调工作流，提升了机器学习原子间力场的实用性。

Abstract: Due to the computational complexity of evaluating interatomic forces from
first principles, the creation of interatomic machine learning force fields has
become a highly active field of research. However, the generation of training
datasets of sufficient size and sample diversity itself comes with a
computational burden that can make this approach impractical for modeling rare
events or systems with a large configuration space. Fine-tuning foundation
models that have been pre-trained on large-scale material or molecular
databases offers a promising opportunity to reduce the amount of training data
necessary to reach a desired level of accuracy. However, even if this approach
requires less training data overall, creating a suitable training dataset can
still be a very challenging problem, especially for systems with rare events
and for end-users who don't have an extensive background in machine learning.
In on-the-fly learning, the creation of a training dataset can be largely
automated by using model uncertainty during the simulation to decide if the
model is accurate enough or if a structure should be recalculated with
classical methods and used to update the model. A key challenge for applying
this form of active learning to the fine-tuning of foundation models is how to
assess the uncertainty of those models during the fine-tuning process, even
though most foundation models lack any form of uncertainty quantification. In
this paper, we overcome this challenge by introducing a fine-tuning approach
based on Bayesian neural network methods and a subsequent on-the-fly workflow
that automatically fine-tunes the model while maintaining a pre-specified
accuracy and can detect rare events such as transition states and sample them
at an increased rate relative to their occurrence.

</details>


### [146] [Scalable Submodular Policy Optimization via Pruned Submodularity Graph](https://arxiv.org/abs/2507.13834)
*Aditi Anand,Suman Banerjee,Dildar Ali*

Main category: cs.LG

TL;DR: 本文提出了一种基于剪枝子模图的方法，用于解决奖励函数为子模函数的强化学习问题，实验证明其性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习（RL）假设奖励函数是可加的，但在路径规划和覆盖控制等现实问题中，奖励函数常表现出边际效益递减，可建模为子模函数。因此，需要研究如何在这种子模奖励设置下找到最优策略。

Method: 本文提出了一种基于剪枝子模图的方法，旨在提供在可行计算时间内的可证明近似解。该方法经过了时间、空间需求及性能保证的分析。

Result: 在基准智能体-环境设置上进行的实验表明，所提出的方法获得的策略比基线方法带来了更多的奖励。

Conclusion: 所提出的基于剪枝子模图的方法能有效解决奖励函数为子模的强化学习问题，并能获得比现有基线方法更优的奖励。

Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the
environment via a set of possible actions, and a reward is generated from some
unknown distribution. The task here is to find an optimal set of actions such
that the reward after a certain time step gets maximized. In a traditional
setup, the reward function in an RL Problem is considered additive. However, in
reality, there exist many problems, including path planning, coverage control,
etc., the reward function follows the diminishing return, which can be modeled
as a submodular function. In this paper, we study a variant of the RL Problem
where the reward function is submodular, and our objective is to find an
optimal policy such that this reward function gets maximized. We have proposed
a pruned submodularity graph-based approach that provides a provably
approximate solution in a feasible computation time. The proposed approach has
been analyzed to understand its time and space requirements as well as a
performance guarantee. We have experimented with a benchmark agent-environment
setup, which has been used for similar previous studies, and the results are
reported. From the results, we observe that the policy obtained by our proposed
approach leads to more reward than the baseline methods.

</details>


### [147] [Self-supervised learning on gene expression data](https://arxiv.org/abs/2507.13912)
*Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar*

Main category: cs.LG

TL;DR: 本研究首次将自监督学习应用于批量基因表达数据进行表型预测，结果显示其性能优于传统监督模型，并显著降低了对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 从基因表达数据预测表型在生物医学研究中至关重要，但传统监督学习方法依赖大量耗时且昂贵的标注数据。自监督学习有望通过直接从无标注数据结构中提取信息来克服这一限制。

Method: 研究选择了三种基于不同方法的先进自监督学习模型，将其应用于批量基因表达数据进行表型预测。通过使用多个公开基因表达数据集，评估了这些方法利用数据固有结构并生成高质量表示以进行下游预测任务的能力。

Result: 所选自监督学习方法能够有效捕获复杂信息并提高表型预测准确性。结果表明，自监督学习方法性能优于传统监督模型，并显著降低了对标注数据的依赖。研究还提供了每种方法的综合性能分析，突出了其优缺点。

Conclusion: 自监督学习是批量基因表达数据表型预测的有效且前景广阔的方法，它克服了标注数据稀缺的挑战，并展现出超越传统监督模型的性能。本研究首次将自监督学习应用于批量RNA-Seq数据，并为未来研究方向提供了指导。

Abstract: Predicting phenotypes from gene expression data is a crucial task in
biomedical research, enabling insights into disease mechanisms, drug responses,
and personalized medicine. Traditional machine learning and deep learning rely
on supervised learning, which requires large quantities of labeled data that
are costly and time-consuming to obtain in the case of gene expression data.
Self-supervised learning has recently emerged as a promising approach to
overcome these limitations by extracting information directly from the
structure of unlabeled data. In this study, we investigate the application of
state-of-the-art self-supervised learning methods to bulk gene expression data
for phenotype prediction. We selected three self-supervised methods, based on
different approaches, to assess their ability to exploit the inherent structure
of the data and to generate qualitative representations which can be used for
downstream predictive tasks. By using several publicly available gene
expression datasets, we demonstrate how the selected methods can effectively
capture complex information and improve phenotype prediction accuracy. The
results obtained show that self-supervised learning methods can outperform
traditional supervised models besides offering significant advantage by
reducing the dependency on annotated data. We provide a comprehensive analysis
of the performance of each method by highlighting their strengths and
limitations. We also provide recommendations for using these methods depending
on the case under study. Finally, we outline future research directions to
enhance the application of self-supervised learning in the field of gene
expression data analysis. This study is the first work that deals with bulk
RNA-Seq data and self-supervised learning.

</details>


### [148] [Reframing attention as a reinforcement learning problem for causal discovery](https://arxiv.org/abs/2507.13920)
*Turan Orujlu,Christian Gumbsch,Martin V. Butz,Charley M Wu*

Main category: cs.LG

TL;DR: 本文提出了一种名为“因果过程框架”的新理论及其实现“因果过程模型”，用于在强化学习环境中从视觉观察中推断动态因果结构，并通过重构Transformer注意力机制实现，表现优于现有方法并能恢复动态因果图。


<details>
  <summary>Details</summary>
Motivation: 当前的因果框架与深度强化学习（RL）并行发展，但大多数神经因果模型假设静态因果图，忽略了因果交互的动态性。缺乏能处理动态因果关系的神经模型。

Method: 引入“因果过程框架”作为表征动态因果结构的新理论，并提出“因果过程模型”作为其实现。该方法将Transformer网络的注意力机制重新构想为RL设置，目标是从视觉观察中推断可解释的因果过程。因果推断被视为一个嵌套在原始RL问题中的RL任务，其中RL智能体用于构建因果图假设，通过建立单元间的联系（类似于Transformer注意力机制）。

Result: 在强化学习环境中，该方法在因果表征学习和智能体性能方面优于现有替代方案。此外，它能独特地恢复动态因果过程图。

Conclusion: 所提出的因果过程框架和模型能有效且独特地从视觉观察中推断动态因果结构，并在强化学习任务中展现出卓越的性能和因果图恢复能力，为结合因果推断与深度强化学习提供了新途径。

Abstract: Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.

</details>


### [149] [MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space](https://arxiv.org/abs/2507.13950)
*Jingbo Liang,Bruna Jacobson*

Main category: cs.LG

TL;DR: MoDyGAN利用MD模拟和GANs，通过将3D蛋白质结构转换为2D图像，高效探索蛋白质构象空间。


<details>
  <summary>Details</summary>
Motivation: 由于动态物理模拟计算成本高昂，深入探索蛋白质构象景观在计算生物学中仍是重大挑战。

Method: 提出MoDyGAN管道，结合分子动力学（MD）模拟和生成对抗网络（GANs）。MoDyGAN包含一个将高斯分布映射到MD衍生蛋白质轨迹的生成器和一个结合集成学习与双鉴别器的细化模块。其核心创新在于将3D蛋白质结构可逆地转换为2D矩阵，从而能利用先进的基于图像的GAN架构。

Result: MoDyGAN成功生成了可信的蛋白质新构象（在三种刚性蛋白上验证）。潜在空间中的插值与转向分子动力学（SMD）模拟轨迹高度一致（在十肽丙氨酸上验证）。

Conclusion: 将蛋白质表示为图像数据为生物分子模拟中应用先进深度学习技术开辟了新可能性，实现了构象状态的有效采样。该框架有望扩展到其他复杂的3D结构。

Abstract: Extensively exploring protein conformational landscapes remains a major
challenge in computational biology due to the high computational cost involved
in dynamic physics-based simulations. In this work, we propose a novel
pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and
generative adversarial networks (GANs) to explore protein conformational
spaces. MoDyGAN contains a generator that maps Gaussian distributions into
MD-derived protein trajectories, and a refinement module that combines ensemble
learning with a dual-discriminator to further improve the plausibility of
generated conformations. Central to our approach is an innovative
representation technique that reversibly transforms 3D protein structures into
2D matrices, enabling the use of advanced image-based GAN architectures. We use
three rigid proteins to demonstrate that MoDyGAN can generate plausible new
conformations. We also use deca-alanine as a case study to show that
interpolations within the latent space closely align with trajectories obtained
from steered molecular dynamics (SMD) simulations. Our results suggest that
representing proteins as image-like data unlocks new possibilities for applying
advanced deep learning techniques to biomolecular simulation, leading to an
efficient sampling of conformational states. Additionally, the proposed
framework holds strong potential for extension to other complex 3D structures.

</details>


### [150] [Robust Anomaly Detection with Graph Neural Networks using Controllability](https://arxiv.org/abs/2507.13954)
*Yifan Wei,Anwar Said,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 本文提出将平均可控性整合到图学习框架中，以提高稀疏不平衡数据集下的异常检测性能，并通过两种新方法（边权重和边属性）验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂领域异常检测面临标签数据稀缺和样本不平衡的挑战，现有图学习模型难以在有限信息下充分学习。研究旨在探索如何利用节点影响力（平均可控性）克服这些挑战。

Method: 研究假设节点影响力（通过平均可控性量化）能显著提高异常检测性能。为此，提出了两种将平均可控性整合到图学习框架的新方法：1) 将平均可控性用作边权重；2) 将其编码为独热边属性向量。

Result: 通过在真实世界和合成网络上与六种SOTA基线进行严格评估，所提出的方法在识别异常方面表现出改进的性能，凸显了可控性度量在增强图机器学习模型性能中的关键作用。

Conclusion: 该工作强调了将平均可控性作为额外指标整合的潜力，以应对稀疏和不平衡数据集中的异常检测挑战，为图机器学习模型提供了新的增强方向。

Abstract: Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.

</details>


### [151] [Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs](https://arxiv.org/abs/2507.13959)
*Eli Verwimp,Gustav Ryberg Smidt,Hendrik Hameeuw,Katrien De Graef*

Main category: cs.LG

TL;DR: 该论文研究了机器学习在楔形文字符号分类中的应用，并分析了数据变异性对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 楔形文字符号的高度变异性（来源、书写者、数字化方式等）导致模型在不同数据集上表现不佳。本研究旨在探究这些差异如何影响性能，以期影响未来的数据采集标准，并为楔形文字符号分类任务奠定基础。

Method: 使用ResNet50模型，在来自美索不达米亚三座城市（尼普尔、杜尔-阿比舒、西帕尔）的古巴比伦（约公元前2000-1600年）泥板手写文献上进行训练和测试。

Result: ResNet50模型对于至少有20个实例的符号，取得了87.1%的top-1准确率和96.5%的top-5准确率。这是首次对古巴比伦文本进行的自动化分类，目前尚无其他可比较的结果。

Conclusion: 本研究为古巴比伦文本的楔形文字符号自动分类提供了初步成果和基准，并揭示了数据变异性的影响，为未来的数据采集标准和分类任务提供了坚实的基础和见解。

Abstract: The work in this paper describes the training and evaluation of machine
learning (ML) techniques for the classification of cuneiform signs. There is a
lot of variability in cuneiform signs, depending on where they come from, for
what and by whom they were written, but also how they were digitized. This
variability makes it unlikely that an ML model trained on one dataset will
perform successfully on another dataset. This contribution studies how such
differences impact that performance. Based on our results and insights, we aim
to influence future data acquisition standards and provide a solid foundation
for future cuneiform sign classification tasks. The ML model has been trained
and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary
texts inscribed on clay tablets originating from three Mesopotamian cities
(Nippur, D\=ur-Abie\v{s}uh and Sippar). The presented and analysed model is
ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for
signs with at least 20 instances. As these automatic classification results are
the first on Old Babylonian texts, there are currently no comparable results.

</details>


### [152] [Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks](https://arxiv.org/abs/2507.13992)
*Jagruti Patel,Thomas A. W. Bolton,Mikkel Schöttner,Anjali Tarun,Sebastien Tourbier,Yasser Alemàn-Gòmez,Jonas Richiardi,Patric Hagmann*

Main category: cs.LG

TL;DR: 提出了一种无需元数据或出行受试者的深度学习框架，用于协调多中心结构连接组数据，并发现图卷积自编码器在拓扑结构和个体特异性保留方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 神经影像学中小样本量限制了可靠生物标志物的开发。大型多中心研究存在采集偏倚，影响数据一致性。现有结构连接组（SC）协调方法通常依赖详细元数据、出行受试者，或忽略SC的图拓扑结构。

Method: 提出了一个“位点条件深度协调框架”，用于在不需元数据或出行受试者的情况下协调多中心SC数据。该框架中，测试并比较了三种深度架构（全连接自编码器、卷积自编码器、图卷积自编码器）与一个线性回归基线模型。研究在基于人类连接组数据集的模拟场景中进行。

Result: 非图模型在边权重预测和边存在检测方面表现出色。图卷积自编码器在拓扑结构和受试者个体特异性保留方面表现更优。线性回归基线模型虽在数值性能上表现最好，但因依赖详细采集参数而缺乏实际应用性。

Conclusion: 模型架构在SC协调性能中至关重要。图基方法特别适用于大规模多中心SC研究中结构感知、领域可泛化的SC协调。

Abstract: Small sample sizes in neuroimaging in general, and in structural connectome
(SC) studies in particular limit the development of reliable biomarkers for
neurological and psychiatric disorders - such as Alzheimer's disease and
schizophrenia - by reducing statistical power, reliability, and
generalizability. Large-scale multi-site studies have exist, but they have
acquisition-related biases due to scanner heterogeneity, compromising imaging
consistency and downstream analyses. While existing SC harmonization methods -
such as linear regression (LR), ComBat, and deep learning techniques - mitigate
these biases, they often rely on detailed metadata, traveling subjects (TS), or
overlook the graph-topology of SCs. To address these limitations, we propose a
site-conditioned deep harmonization framework that harmonizes SCs across
diverse acquisition sites without requiring metadata or TS that we test in a
simulated scenario based on the Human Connectome Dataset. Within this
framework, we benchmark three deep architectures - a fully connected
autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a
top-performing LR baseline. While non-graph models excel in edge-weight
prediction and edge existence detection, the graph AE demonstrates superior
preservation of topological structure and subject-level individuality, as
reflected by graph metrics and fingerprinting accuracy, respectively. Although
the LR baseline achieves the highest numerical performance by explicitly
modeling acquisition parameters, it lacks applicability to real-world
multi-site use cases as detailed acquisition metadata is often unavailable. Our
results highlight the critical role of model architecture in SC harmonization
performance and demonstrate that graph-based approaches are particularly
well-suited for structure-aware, domain-generalizable SC harmonization in
large-scale multi-site SC studies.

</details>


### [153] [ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies](https://arxiv.org/abs/2507.13998)
*Itay Katav,Aryeh Kontorovich*

Main category: cs.LG

TL;DR: 本文提出ParallelTime架构和动态加权机制ParallelTime Weighter，优化时间序列预测中长短期依赖的权重分配，实现了SOTA性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型（如Transformer和Mamba结合）在处理长短期依赖时，常采用等权重分配，但这对于时间序列预测任务并非最优。

Method: 引入ParallelTime Weighter动态加权机制，根据输入和模型知识为每个token的长短期依赖计算相互依赖的权重。在此基础上，提出ParallelTime架构，整合该加权机制。

Result: ParallelTime架构在多项基准测试中达到了最先进的性能，表现出更强的鲁棒性，更低的FLOPs和参数量，并能有效扩展到更长的预测范围，显著优于现有方法。

Conclusion: 这些进展为未来并行Attention-Mamba在时间序列预测领域的发展指明了有前景的方向。

Abstract: Modern multivariate time series forecasting primarily relies on two
architectures: the Transformer with attention mechanism and Mamba. In natural
language processing, an approach has been used that combines local window
attention for capturing short-term dependencies and Mamba for capturing
long-term dependencies, with their outputs averaged to assign equal weight to
both. We find that for time-series forecasting tasks, assigning equal weight to
long-term and short-term dependencies is not optimal. To mitigate this, we
propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates
interdependent weights for long-term and short-term dependencies for each token
based on the input and the model's knowledge. Furthermore, we introduce the
ParallelTime architecture, which incorporates the ParallelTime Weighter
mechanism to deliver state-of-the-art performance across diverse benchmarks.
Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer
parameters, scales effectively to longer prediction horizons, and significantly
outperforms existing methods. These advances highlight a promising path for
future developments of parallel Attention-Mamba in time series forecasting. The
implementation is readily available at:
\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [154] [Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica](https://arxiv.org/abs/2507.13476)
*Jaber Daneshamooz,Jessica Nguyen,William Chen,Sanjay Chandrasekaran,Satyandra Guthula,Ankit Gupta,Arpit Gupta,Walter Willinger*

Main category: cs.NI

TL;DR: 网络ML模型面临域适应问题，NetReplica通过生成具有真实性和可控性的训练数据集来解决，显著提升了模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 网络中的机器学习模型存在域适应问题，即在一个领域训练的模型在部署到不同的生产环境时会失效，从而限制了其有效性。

Method: 本文提出并实现了NetReplica系统。该系统通过将网络建模为瓶颈链路集合，利用生产网络轨迹实现协议动态的真实性，并通过对每个链路属性的细粒度控制来实现网络条件的可控性，以此生成高质量的训练数据集。

Result: NetReplica不仅能生成与现有数据特性匹配的样本，还能生成Puffer数据中不足或缺失的真实样本。使用NetReplica增强数据集训练的模型，其泛化能力显著提升，在挑战性网络条件下，传输时间预测误差比仅使用Puffer数据训练的模型降低高达47%。

Conclusion: 这项工作代表了在解决限制基于ML的网络系统有效性的域适应问题方面迈出了重要一步。

Abstract: Machine learning models in networking suffer from the domain adaptation
problem; models trained in one domain often fail when deployed in different
production environments. This paper presents the design and implementation of
NetReplica, a system that addresses this challenge by generating training
datasets with two critical properties: realism in protocol dynamics and
controllability of network conditions. NetReplica models networks as
collections of bottleneck links with specific attributes, achieves realism by
leveraging production network traces, and enables controllability through fine
grained control knobs for each link attribute. Our evaluation using Puffer
demonstrates that NetReplica not only matches existing data characteristics but
generates realistic samples that are underrepresented in or absent from Puffer
data. Models trained on NetReplica augmented datasets show substantially
improved generalizability, reducing transmission time prediction error by up to
47% for challenging network conditions compared to models trained solely on
Puffer data. This work represents a significant step toward solving the domain
adaptation problem that has limited the effectiveness of ML based networking
systems.

</details>


### [155] [CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC](https://arxiv.org/abs/2507.13676)
*Cheng Jiang,Yihe Yan,Yanxiang Wang,Jiawei Hu,Chun Tung Chou,Wen Hu*

Main category: cs.NI

TL;DR: 本文提出CARTS，一种5G上行感知方案，通过融合DMRS和SRS的CSI来提高信道状态信息可用性，从而增强ISAC服务能力和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 5G集成感知与通信（ISAC）服务的性能严重依赖于准确且实时的信道状态信息（CSI）。然而，当前5G网络基站将来自DMRS和SRS的CSI独立处理，导致CSI更新频率不足，且限制了对用户的感知机会。

Method: CARTS方案的核心在于融合DMRS和SRS这两种上行参考信号的CSI。具体方法包括：1) 提出一种新颖的信道拼接和补偿方法，用于整合异步的DMRS和SRS CSI估计，克服它们不同的时频分配；2) 开发一种实时SRS触发算法，以补充DMRS固有的不可控调度，确保为所有用户提供充分且非冗余的感知机会。

Result: 基于真实追踪数据的评估表明，CARTS显著提高了可扩展性，实现了0.167的信道估计误差（NMSE）和85厘米的用户设备跟踪精度。与仅使用周期性SRS的基线相比，CARTS在相似性能下支持的用户数量增加了一倍。

Conclusion: CARTS通过机会性地结合DMRS和SRS，提供了一种实用且符合标准的解决方案，在不占用额外无线资源的情况下，显著提高了ISAC的CSI可用性。

Abstract: This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to
provide Integrated Sensing and Communication (ISAC) services. The performance
of both communication and sensing fundamentally depends on the availability of
accurate and up-to-date channel state information (CSI). In modern 5G networks,
uplink CSI is derived from two reference signals: the demodulation reference
signal (DMRS) and the sounding reference signal (SRS). However, current base
station implementations treat these CSI measurements as separate information
streams. The key innovation of CARTS is to fuse these two CSI streams, thereby
increasing the frequency of CSI updates and extending sensing opportunities to
more users. CARTS addresses two key challenges: (i) a novel channel stitching
and compensation method that integrates asynchronous CSI estimates from DMRS
and SRS, despite their different time and frequency allocations, and (ii) a
real-time SRS triggering algorithm that complements the inherently
uncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing
opportunities for all users. Our trace-driven evaluation shows that CARTS
significantly improves scalability, achieving a channel estimation error (NMSE)
of 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of
users as a periodic SRS-only baseline with similar performance. By
opportunistically combining DMRS and SRS, CARTS therefore provides a practical,
standard-compliant solution to improve CSI availability for ISAC without
requiring additional radio resources.

</details>


### [156] [ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks](https://arxiv.org/abs/2507.13717)
*Yingming Mao,Qiaozhu Zhai,Zhen Yao,Xia Zhu,Ximeng Liu,Xinchi Han*

Main category: cs.NI

TL;DR: 针对可重构数据中心网络（DCNs）的拓扑和路由优化难题，本文提出了ATRO框架，通过交替优化拓扑和路由，显著提升了现有方法的解决方案质量和运行效率。


<details>
  <summary>Details</summary>
Motivation: 随着可重构数据中心网络规模和复杂度的增加，需要更具扩展性和效率的拓扑和路由算法。现有方法在解决拓扑决策的组合性质问题时，难以平衡解决方案质量和运行时效率。

Method: 引入了“交替拓扑与路由优化”（ATRO）框架，这是一个无求解器的（solver-free）框架，通过在拓扑优化（TO）和路由优化（RO）之间交替进行。该方法利用两个关键洞察：每次更新单调地降低最大链路利用率（MLU），以及TO子问题具有单调结构，可通过高效的加速二分搜索方法（ABSM）获得最优解。RO则利用现有流量工程加速器解决。

Result: ATRO在单跳场景中达到了全局最优解。在多跳场景中，它在运行时间和解决方案质量方面均显著优于现有基线方法。评估证实了其在不同DCN环境下的可扩展性和鲁棒性。

Conclusion: ATRO为可重构数据中心网络的拓扑和路由优化提供了一个高效、可扩展且鲁棒的解决方案，无论在单跳还是多跳配置下，都能在保证高解决方案质量的同时实现快速运行。

Abstract: The growing scale and complexity of reconfigurable data center networks
(DCNs) demand more scalable and efficient algorithms for computing logical
topologies and routing. Reconfigurable DCNs typically operate in two modes:
one-hop configurations that require frequent topology optimization (TO), and
multi-hop scenarios that involve joint topology and routing optimization (TRO).
In both cases, the combinatorial nature of topology decisions makes it
difficult for existing methods to balance solution quality and runtime
efficiency. To address this, we introduce Alternating Topology and Routing
Optimization (ATRO), a solver-free framework that alternates between TO and
routing optimization (RO). This decomposition exploits two key insights: first,
each alternating update step monotonically reduces maximum link utilization
(MLU), ensuring consistent performance improvement across iterations; second,
the TO subproblem, equivalent to one-hop optimization, exhibits a monotonic
structure that enables optimal solutions via an efficient Accelerated Binary
Search Method (ABSM). To preserve the solver-free design, RO is solved using
existing Traffic Engineering accelerators. ATRO attains the global optimum in
one-hop scenarios and significantly outperforms baselines in multi-hop settings
in terms of both runtime and solution quality. Evaluations confirm its
scalability and robustness across diverse DCNs.

</details>


### [157] [On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies](https://arxiv.org/abs/2507.13889)
*Bilal Karaman,Ilhan Basturk,Ferdi Kara,Metin Ozturk,Sezai Taskin,Halil Yanikomeroglu*

Main category: cs.NI

TL;DR: 本文研究了有源可重构智能表面（RIS）中继与高空平台站（HAPS）结合，以提升下一代非地面网络（NTN）性能，并发现有源RIS在QoS和能效方面优于无源RIS。


<details>
  <summary>Details</summary>
Motivation: 为应对长距离HAPS链路中严重的路径损耗和双重衰落，传统无源RIS难以满足需求。有源RIS因其固有的信号放大能力，成为更适合提升下一代无线系统非地面网络性能的解决方案。

Method: 该研究构建了一个和速率最大化问题，以联合优化基于HAPS的有源RIS辅助通信系统中地面用户设备（UE）的功率分配和RIS单元分配。同时，为降低功耗和硬件复杂性，还探讨了几种子连接有源RIS架构。

Result: 仿真结果表明，有源RIS配置在服务质量（QoS）方面显著优于无源RIS。此外，尽管全连接架构实现了最高吞吐量，但子连接方案在实际功率限制下表现出卓越的能效。

Conclusion: 研究结果突出了有源RIS赋能的HAPS系统在满足超越蜂窝覆盖和绿色网络日益增长的需求方面的潜力。

Abstract: This paper investigates the integration of active reconfigurable intelligent
surfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance
non-terrestrial network (NTN) performance in next-generation wireless systems.
While prior studies focused on passive RIS architectures, the severe path loss
and double fading in long-distance HAPS links make active RIS a more suitable
alternative due to its inherent signal amplification capabilities. We formulate
a sum-rate maximization problem to jointly optimize power allocation and RIS
element assignment for ground user equipments (UEs) supported by a HAPS-based
active RIS-assisted communication system. To reduce power consumption and
hardware complexity, several sub-connected active RIS architectures are also
explored. Simulation results reveal that active RIS configurations
significantly outperform passive RIS in terms of quality of service (QoS).
Moreover, although fully-connected architectures achieve the highest
throughput, sub-connected schemes demonstrate superior energy efficiency under
practical power constraints. These findings highlight the potential of active
RIS-enabled HAPS systems to meet the growing demands of beyond-cellular
coverage and green networking.

</details>


### [158] [Preprint: Did I Just Browse A Website Written by LLMs?](https://arxiv.org/abs/2507.13933)
*Sichang "Steven" He,Ramesh Govindan,Harsha V. Madhyastha*

Main category: cs.NI

TL;DR: 本研究提出了一种针对整个网站的LLM生成内容检测方法，解决了现有检测器在复杂网页内容上的不足。该方法在实验中达到了100%的准确率，并发现LLM主导的网站在数量和搜索排名上均呈增长趋势，对网络生态系统构成潜在影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）自动生成网页内容日益普遍，这些“LLM主导”内容可能存在抄袭和幻觉问题，导致其不可靠和不道德。然而，网站很少披露此类内容，人类也难以辨别。现有LLM检测器主要对简洁散文文本有效，无法处理具有复杂标记和多样体裁的网页内容，因此迫切需要开发可靠的LLM主导内容检测器。

Method: 提出了一种高度可靠、可扩展的管道，用于对整个网站进行分类。该方法并非简单地对从每个页面提取的文本进行分类，而是根据LLM文本检测器对多个类似散文页面的输出，对每个网站进行分类。通过收集2个独立的、共计120个网站的真实数据集进行训练和评估。

Result: 在120个真实网站数据集上，测试准确率达到100%。在搜索引擎结果中的1万个网站和Common Crawl档案中的1万个网站中，检测到相当一部分网站是LLM主导的。研究发现，LLM主导的网站越来越普遍，并且在搜索结果中排名很高。

Conclusion: LLM主导的网页内容正在迅速增长并获得较高的搜索排名，这对最终用户和整个网络生态系统产生了重要影响。本研究提出的网站级检测方法被证明是高效且准确的，突出了检测和理解这一现象的必要性。

Abstract: Increasingly, web content is automatically generated by large language models
(LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs
plagiarize and hallucinate, LLM-dominant content can be unreliable and
unethical. Yet, websites rarely disclose such content, and human readers
struggle to distinguish it. Thus, we must develop reliable detectors for
LLM-dominant content. However, state-of-the-art LLM detectors are insufficient,
because they perform well mainly on clean, prose-like text, while web content
has complex markup and diverse genres.
  We propose a highly reliable, scalable pipeline that classifies entire
websites. Instead of naively classifying text extracted from each page, we
classify each site based on an LLM text detector's outputs of multiple
prose-like pages. We train and evaluate our detector by collecting 2 distinct
ground truth datasets totaling 120 sites, and obtain 100% accuracies testing
across them. In the wild, we detect a sizable portion of sites as LLM-dominant
among 10k sites in search engine results and 10k in Common Crawl archives. We
find LLM-dominant sites are growing in prevalence and rank highly in search
results, raising questions about their impact on end users and the overall Web
ecosystem.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [159] [Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio](https://arxiv.org/abs/2507.13368)
*Yaowen Hu,Wenxuan Tu,Yue Liu,Xinhang Wan,Junyi Yan,Taichun Zhou,Xinwang Liu*

Main category: cs.SI

TL;DR: 深度图聚类(DGC)在处理大规模和属性缺失的真实图时面临挑战。本文提出CMV-ND方法，通过将图结构信息预处理为完整且非冗余的多视图，显著提升了多种DGC方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度图聚类（DGC）方法在处理大规模且属性缺失的真实世界属性图（如社交网络）时面临困难。

Method: 提出了一种名为CMV-ND的新型深度图聚类（DGC）方法。该方法通过递归邻域搜索确保图结构信息的完整性，并采用邻域差异化策略消除不同跳邻域间的冗余，从而将图结构信息预处理为完整且非冗余的多视图。这些视图随后可应用于现有的多视图聚类或DGC方法。

Result: 在六个常用图数据集上的实验结果表明，CMV-ND显著提升了现有DGC方法的性能。

Conclusion: CMV-ND通过对图结构信息进行完整且非冗余的多视图预处理，有效解决了深度图聚类在处理大规模和属性缺失图时面临的挑战，显著提升了聚类性能。

Abstract: Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes
in an attribute graph into different clusters, has seen substantial potential
in various industrial scenarios like community detection and recommendation.
However, the real-world attribute graphs, e.g., social networks interactions,
are usually large-scale and attribute-missing. To solve these two problems, we
propose a novel DGC method termed \underline{\textbf{C}}omplementary
\underline{\textbf{M}}ulti-\underline{\textbf{V}}iew
\underline{\textbf{N}}eighborhood \underline{\textbf{D}}ifferentiation
(\textit{CMV-ND}), which preprocesses graph structural information into
multiple views in a complete but non-redundant manner. First, to ensure
completeness of the structural information, we propose a recursive neighborhood
search that recursively explores the local structure of the graph by completely
expanding node neighborhoods across different hop distances. Second, to
eliminate the redundancy between neighborhoods at different hops, we introduce
a neighborhood differential strategy that ensures no overlapping nodes between
the differential hop representations. Then, we construct $K+1$ complementary
views from the $K$ differential hop representations and the features of the
target node. Last, we apply existing multi-view clustering or DGC methods to
the views. Experimental results on six widely used graph datasets demonstrate
that CMV-ND significantly improves the performance of various methods.

</details>


### [160] [H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance](https://arxiv.org/abs/2507.13370)
*Shijun Guo,Haoran Xu,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyi Zhang,Yishan Song,Jiwei Chen*

Main category: cs.SI

TL;DR: H-NeiFi是一种分层、非侵入式意见引导框架，通过动态模型和邻居过滤，利用多智能体强化学习加速社会媒体共识形成，同时保护用户自主性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体意见自由交流虽好，但存在引导共识的挑战。现有方法如直接修改观点或强制连接，侵犯用户自主性、引起抵触并降低效率。此外，缺乏长期视角导致局部共识加剧宏观分歧。

Method: 提出分层、非侵入式意见引导框架H-NeiFi。首先，建立基于社会角色（专家与非专家）的两层动态模型。其次，引入非侵入式邻居过滤方法，自适应控制用户通信渠道。最后，利用多智能体强化学习（MARL）优化信息传播路径，通过长期奖励函数避免直接干预用户互动。

Result: 实验表明，H-NeiFi将共识速度提高了22.0%至30.7%，即使在没有专家的情况下也能保持全局收敛。

Conclusion: H-NeiFi通过保护用户互动自主性，实现了自然高效的共识引导，为社交网络治理提供新范式。

Abstract: The openness of social media enables the free exchange of opinions, but it
also presents challenges in guiding opinion evolution towards global consensus.
Existing methods often directly modify user views or enforce cross-group
connections. These intrusive interventions undermine user autonomy, provoke
psychological resistance, and reduce the efficiency of global consensus.
Additionally, due to the lack of a long-term perspective, promoting local
consensus often exacerbates divisions at the macro level. To address these
issues, we propose the hierarchical, non-intrusive opinion guidance framework,
H-NeiFi. It first establishes a two-layer dynamic model based on social roles,
considering the behavioral characteristics of both experts and non-experts.
Additionally, we introduce a non-intrusive neighbor filtering method that
adaptively controls user communication channels. Using multi-agent
reinforcement learning (MARL), we optimize information propagation paths
through a long-term reward function, avoiding direct interference with user
interactions. Experiments show that H-NeiFi increases consensus speed by 22.0%
to 30.7% and maintains global convergence even in the absence of experts. This
approach enables natural and efficient consensus guidance by protecting user
interaction autonomy, offering a new paradigm for social network governance.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [161] [PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning](https://arxiv.org/abs/2507.13355)
*Riadul Islam,Dhandeep Challagundla*

Main category: cs.AR

TL;DR: 本文提出了一种新型无监督设计规则检查（DRC）违规预测方法，相较于传统的有监督机器学习模型（如SVM和NN），该方法在预测准确率和训练时间上均表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 下一代微处理器创新亟需AI驱动的EDA工具。现有基于机器学习和神经网络的DRC违规和光刻热点检测方法依赖于有监督学习，需要大量平衡的数据集和长时间的训练，这阻碍了其广泛应用。

Method: 本研究提出了一种首创的无监督DRC违规预测方法。该模型仅需使用任意不平衡数据集的单一类别即可构建，通过设定阈值来判断新数据是否在模型边界内进行分类。该方法在CMOS 28纳米技术和Synopsys工具下，通过对约6万个布局数据点的分析和验证。

Result: 所提出的方法预测测试准确率高达99.95%，显著高于现有SVM（85.44%）和NN模型（98.74%）。此外，该方法的训练时间比SVM模型快约26.3倍，比NN模型快达6003倍。

Conclusion: 所提出的无监督DRC违规预测方法在预测准确性和训练效率上均大幅超越现有有监督模型，有效解决了传统方法对大规模平衡数据集和长训练时间的依赖，为下一代微处理器设计提供了高效解决方案。

Abstract: Leveraging artificial intelligence (AI)-driven electronic design and
automation (EDA) tools, high-performance computing, and parallelized algorithms
are essential for next-generation microprocessor innovation, ensuring continued
progress in computing, AI, and semiconductor technology. Machine learning-based
design rule checking (DRC) and lithography hotspot detection can improve
first-pass silicon success. However, conventional ML and neural network
(NN)-based models use supervised learning and require a large balanced dataset
(in terms of positive and negative classes) and training time. This research
addresses those key challenges by proposing the first-ever unsupervised DRC
violation prediction methodology. The proposed model can be built using any
unbalanced dataset using only one class and set a threshold for it, then
fitting any new data querying if they are within the boundary of the model for
classification. This research verified the proposed model by implementing
different computational cores using CMOS 28 nm technology and Synopsys Design
Compiler and IC Compiler II tools. Then, layouts were divided into virtual
grids to collect about 60k data for analysis and verification. The proposed
method has 99.95% prediction test accuracy, while the existing support vector
machine (SVM) and neural network (NN) models have 85.44\% and 98.74\% accuracy,
respectively. In addition, the proposed methodology has about 26.3x and up to
6003x lower training times compared to SVM and NN-models, respectively.

</details>


### [162] [VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation](https://arxiv.org/abs/2507.13369)
*Paul E. Calzada,Zahin Ibnat,Tanvir Rahman,Kamal Kandula,Danyu Lu,Sujan Kumar Saha,Farimah Farahmandi,Mark Tehranipoor*

Main category: cs.AR

TL;DR: 本文构建了一个包含20,392个Verilog样本的目前最大的高质量数据集，旨在为大语言模型（LLMs）在寄存器传输级（RTL）代码生成方面的训练和微调提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在硬件设计自动化（特别是RTL代码生成）中日益普及，现有文献表明需要高质量的训练和微调数据集来提升其性能。

Method: 通过自动化的三管齐下流程构建Verilog数据集：1) 使用PostgreSQL进行数据库创建和管理；2) 从OpenCores和GitHub等代码托管平台收集数据；3) 对代码进行预处理，包括语法验证、逻辑综合和元数据提取，以确保数据质量。同时，实施了可扩展且高效的数据库基础设施。

Result: 成功构建了一个包含20,392个Verilog样本和751MB Verilog代码数据的数据集。据作者所知，这是目前用于LLM微调的最大的高质量Verilog数据集。

Conclusion: 该研究成功构建并验证了一个大规模高质量的Verilog数据集，为LLM在硬件生成领域的未来研究与开发提供了重要基础，并探讨了数据集评估、挑战及潜在应用。

Abstract: Large Language Models (LLMs) are gaining popularity for hardware design
automation, particularly through Register Transfer Level (RTL) code generation.
In this work, we examine the current literature on RTL generation using LLMs
and identify key requirements for training and fine-tuning datasets. We
construct a robust Verilog dataset through an automated three-pronged process
involving database (DB) creation and management with PostgreSQL, data
collection from code hosting sites like OpenCores and GitHub, and data
preprocessing to verify the codes' syntax, run logic synthesis, and extract
relevant module metadata. We implement a scalable and efficient DB
infrastructure to support analysis and detail our preprocessing pipeline to
enforce high-quality data before DB insertion. The resulting dataset comprises
20,392 Verilog samples, 751 MB of Verilog code data, which is the largest
high-quality Verilog dataset for LLM fine-tuning to our knowledge. We further
evaluate the dataset, address associated challenges, and explore potential
applications for future research and development in LLM-based hardware
generation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [163] [The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks](https://arxiv.org/abs/2507.13999)
*Sanidhay Bhambay,Siddarth Koduru Joshi,Thirupathaiah Vasantam,Neil Walton*

Main category: quant-ph

TL;DR: 本文提出一种比例公平抽运策略（PF-PS），用于优化量子网络中的纠缠光子分发，以在保障安全通信的同时，平衡公平性与吞吐量。


<details>
  <summary>Details</summary>
Motivation: 量子网络对安全通信至关重要，但其在实际部署中面临资源竞争、优化和公平性问题。由于信道时间变化和多边同时抽运的限制，需要有效的光子抽运策略来避免偏袒少数用户，从而提升整体网络长期性能。

Method: 本文设计并提出了一种自适应抽运策略，特别是比例公平抽运策略（PF-PS）。该策略通过动态优先处理平均密钥率较低的用户，在公平性和吞吐量之间取得最佳平衡。此算法是4G LTE和5G移动网络中比例公平调度器在量子网络中的自然扩展。

Result: 理论分析和数值模拟均证实，PF-PS在纠缠态分发方面是最佳的。它能有效平衡公平性与吞吐量，并动态地提升平均密钥率较低用户的性能。

Conclusion: 比例公平抽运策略（PF-PS）是量子网络中高效资源分配的有力候选，能够有效应对复杂的时间和空间限制，实现最佳的网络性能。

Abstract: We address the problem of optimal pumping strategies in quantum networks.
These networks enable secure communication by distributing entangled photon
pairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like
BBM92, generate secret keys from entangled photons. While secure communication
and error correction are essential for any quantum communication channel,
resource contention, optimization, and fairness issues are critical for
networks. In this article, we analyze the performance of quantum networks,
proposing simple distributed algorithms for QKD networks generating secret
keys.
  There are significant advantages of pumping entangled photons in QKD
networks, but challenges arise in practical implementations. The underlying
channels are inherently time-varying, and thus data rates fluctuate between
nodes. Moreover, multiple edges (node pairs) can be pumped simultaneously,
albeit at the cost of a reduced secret key rate (SKR). These temporal and
spatial constraints yield a complex decision-making problem whose solutions may
favor a small set of user pairs to the detriment of overall, long-run network
performance.
  We design adaptive pumping strategies that address these challenges in QKD
networks. In particular, we find that a proportional fairness pumping strategy
(PF-PS) stands out by dynamically prioritizing users with lower average secret
key rates and optimally balancing fairness with throughput. The proposed
algorithm is a natural extension to quantum networks of the Proportional Fair
Scheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis
and numerical simulations confirm that PF-PS is optimal for entangled state
distribution, and thus, when adapted appropriately, proportional fair pumping
is a strong candidate for efficient resource allocation in quantum networks.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [164] [SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection](https://arxiv.org/abs/2507.13415)
*Peican Zhu,Yubo Jing,Le Cheng,Bin Chen,Xiaodong Cui,Lianwei Wu,Keke Tang*

Main category: cs.MM

TL;DR: 提出SEER网络，通过大型多模态模型进行语义增强并结合情感推理来检测多模态假新闻。


<details>
  <summary>Details</summary>
Motivation: 现有研究在多模态假新闻检测中忽视了大型多模态模型的语义增强效果，且未充分利用情感特征，而假新闻常含有负面情绪。

Method: 提出语义增强与情感推理（SEER）网络。通过大型多模态模型生成图像摘要进行语义增强；并设计专家情感推理模块，优化情感特征以推断新闻真实性。

Result: 在两个真实世界数据集上的实验证明，SEER网络优于现有最先进的基线方法。

Conclusion: SEER网络通过整合语义增强和情感推理，有效提升了多模态假新闻的检测性能。

Abstract: Previous studies on multimodal fake news detection mainly focus on the
alignment and integration of cross-modal features, as well as the application
of text-image consistency. However, they overlook the semantic enhancement
effects of large multimodal models and pay little attention to the emotional
features of news. In addition, people find that fake news is more inclined to
contain negative emotions than real ones. Therefore, we propose a novel
Semantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake
news detection. We generate summarized captions for image semantic
understanding and utilize the products of large multimodal models for semantic
enhancement. Inspired by the perceived relationship between news authenticity
and emotional tendencies, we propose an expert emotional reasoning module that
simulates real-life scenarios to optimize emotional features and infer the
authenticity of news. Extensive experiments on two real-world datasets
demonstrate the superiority of our SEER over state-of-the-art baselines.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [165] [PHASE: Passive Human Activity Simulation Evaluation](https://arxiv.org/abs/2507.13505)
*Steven Lamp,Jason D. Hiser,Anh Nguyen-Tuong,Jack W. Davidson*

Main category: cs.CR

TL;DR: 提出PHASE机器学习框架，被动分析Zeek日志，以超过90%的准确率区分网络安全模拟中的人与非人活动，并提升合成用户行为的真实性。


<details>
  <summary>Details</summary>
Motivation: 网络安全模拟环境（如网络靶场、蜜罐、沙盒）的有效性依赖于真实的人类行为，但目前缺乏量化评估合成用户行为逼真度的方法。

Method: 本文提出了PHASE（被动人类活动模拟评估）机器学习框架，通过分析Zeek连接日志来区分人与非人活动。该方法被动运行，不依赖用户端工具，并利用Zeek网络设备收集数据。此外，还提出了一种利用本地DNS记录进行网络流量标注的新方法，并运用SHAP分析揭示真实人类行为的时间和行为特征。

Result: PHASE框架能够以超过90%的准确率区分人类和非人类活动。通过案例研究，成功识别了合成用户画像中不真实的行为模式，并据此开发了修正的配置，显著提高了合成活动的拟人度，从而创建了更真实有效的合成用户画像。

Conclusion: PHASE提供了一种量化评估合成用户行为真实性的方法，有助于提升网络安全模拟环境的现实性和有效性。

Abstract: Cybersecurity simulation environments, such as cyber ranges, honeypots, and
sandboxes, require realistic human behavior to be effective, yet no
quantitative method exists to assess the behavioral fidelity of synthetic user
personas. This paper presents PHASE (Passive Human Activity Simulation
Evaluation), a machine learning framework that analyzes Zeek connection logs
and distinguishes human from non-human activity with over 90\% accuracy. PHASE
operates entirely passively, relying on standard network monitoring without any
user-side instrumentation or visible signs of surveillance. All network
activity used for machine learning is collected via a Zeek network appliance to
avoid introducing unnecessary network traffic or artifacts that could disrupt
the fidelity of the simulation environment. The paper also proposes a novel
labeling approach that utilizes local DNS records to classify network traffic,
thereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley
Additive exPlanations) analysis to uncover temporal and behavioral signatures
indicative of genuine human users. In a case study, we evaluate a synthetic
user persona and identify distinct non-human patterns that undermine behavioral
realism. Based on these insights, we develop a revised behavioral configuration
that significantly improves the human-likeness of synthetic activity yielding a
more realistic and effective synthetic user persona.

</details>


### [166] [Quantum Blockchain Survey: Foundations, Trends, and Gaps](https://arxiv.org/abs/2507.13720)
*Saurav Ghosh*

Main category: cs.CR

TL;DR: 本综述审视了应对量子计算威胁的两种主要区块链研究方向：后量子区块链和量子区块链，分析其加密基础、架构设计和挑战，并识别开放研究问题，旨在为量子时代的区块链安全提供参考。


<details>
  <summary>Details</summary>
Motivation: 量子计算对传统区块链系统构成根本性风险，因为它会破坏广泛使用的密码学原语，因此有必要发展抗量子的区块链系统。

Method: 本文采用综述方法，回顾了后量子区块链（集成抗量子算法）和量子区块链（利用量子特性）的关键进展。分析了它们的密码学基础、架构设计和实现挑战，并对技术提案进行了比较性概述。

Result: 该综述提供了技术提案的比较性概述，突出了安全性、可扩展性和部署方面的权衡，并指出了硬件、共识和网络设计等领域的开放研究问题。

Conclusion: 本工作旨在为在量子时代推进安全的区块链系统提供一个结构化和全面的参考。

Abstract: Quantum computing poses fundamental risks to classical blockchain systems by
undermining widely used cryptographic primitives. In response, two major
research directions have emerged: post-quantum blockchains, which integrate
quantum-resistant algorithms, and quantum blockchains, which leverage quantum
properties such as entanglement and quantum key distribution. This survey
reviews key developments in both areas, analyzing their cryptographic
foundations, architectural designs, and implementation challenges. This work
provides a comparative overview of technical proposals, highlight trade-offs in
security, scalability, and deployment, and identify open research problems
across hardware, consensus, and network design. The goal is to offer a
structured and comprehensive reference for advancing secure blockchain systems
in the quantum era.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [167] [The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems](https://arxiv.org/abs/2507.11552)
*Tomasz Zgliczyński-Cuber*

Main category: cs.CY

TL;DR: 本文提出了AI伦理共振假说，认为设计特殊认知结构的AI系统可能识别出人类无法察觉的、超越文化和历史偏见的普遍道德模式，从而加深对伦理和人类伦理反思能力的理解。


<details>
  <summary>Details</summary>
Motivation: 探索先进AI系统是否有可能识别出人类难以察觉的微妙道德模式，并通过处理大量伦理情境，发现超越文化、历史和个体偏见的道德元模式，以期深化对普适伦理基础的理解。

Method: 提出并阐述“AI伦理共振假说”的理论框架，探讨AI如何通过特定认知结构（“伦理共振器”）处理和综合大量伦理语境，发现普遍的道德模式。本文属于理论探讨和概念阐释。

Result: 提出了AI可能发现超越人类认知的普遍道德元模式的设想，并指出这一过程可能反过来加深我们对人类自身伦理反思能力的理解。

Conclusion: 该理论框架揭示了AI在伦理领域的新潜力，即通过识别普适道德模式来促进对普遍伦理基础的理解，并可能深化我们对人类核心伦理能力的认识，呈现了一个引人深思的伦理与AI交互的未来愿景。

Abstract: This paper presents a theoretical framework for the AI ethical resonance
hypothesis, which proposes that advanced AI systems with purposefully designed
cognitive structures ("ethical resonators") may emerge with the ability to
identify subtle moral patterns that are invisible to the human mind. The paper
explores the possibility that by processing and synthesizing large amounts of
ethical contexts, AI systems may discover moral meta-patterns that transcend
cultural, historical, and individual biases, potentially leading to a deeper
understanding of universal ethical foundations. The paper also examines a
paradoxical aspect of the hypothesis, in which AI systems could potentially
deepen our understanding of what we traditionally consider essentially human -
our capacity for ethical reflection.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [168] [DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning](https://arxiv.org/abs/2507.13396)
*Qingyun Sun,Jiaqi Yuan,Shan He,Xiao Guan,Haonan Yuan,Xingcheng Fu,Jianxin Li,Philip S. Yu*

Main category: cs.IR

TL;DR: DyG-RAG是一个新的事件中心动态图检索增强生成框架，旨在解决现有Graph RAG在时间推理方面的不足，通过引入动态事件单元和时间链思维策略，显著提升了时间敏感问答的准确性和召回率。


<details>
  <summary>Details</summary>
Motivation: 现有Graph RAG方法难以进行时间推理，因为它们无法建模真实世界事件的演化结构和顺序，导致无法处理非结构化文本中嵌入的时间知识。

Method: DyG-RAG框架提出了动态事件单元（DEUs）以编码语义内容和时间锚点，实现时间感知检索。它通过链接相关DEUs构建事件图支持多跳推理。此外，引入事件时间线检索管道通过时间感知遍历检索事件序列，并采用时间链思维策略（Time Chain-of-Thought）确保时间上一致的答案生成。

Result: 在时间问答基准测试中，DyG-RAG显著提高了三类典型时间推理问题的准确性和召回率。

Conclusion: DyG-RAG为实现更忠实、时间感知的生成提供了新的途径，能够有效解决标准RAG系统无法处理的复杂时间敏感查询。

Abstract: Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for
grounding large language models with external structured knowledge. However,
existing Graph RAG methods struggle with temporal reasoning, due to their
inability to model the evolving structure and order of real-world events. In
this work, we introduce DyG-RAG, a novel event-centric dynamic graph
retrieval-augmented generation framework designed to capture and reason over
temporal knowledge embedded in unstructured text. To eliminate temporal
ambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units
(DEUs) that explicitly encode both semantic content and precise temporal
anchors, enabling accurate and interpretable time-aware retrieval. To capture
temporal and causal dependencies across events, DyG-RAG constructs an event
graph by linking DEUs that share entities and occur close in time, supporting
efficient and meaningful multi-hop reasoning. To ensure temporally consistent
generation, DyG-RAG introduces an event timeline retrieval pipeline that
retrieves event sequences via time-aware traversal, and proposes a Time
Chain-of-Thought strategy for temporally grounded answer generation. This
unified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event
sequences and to answer complex, time-sensitive queries that standard RAG
systems cannot resolve. Extensive experiments on temporal QA benchmarks
demonstrate that DyG-RAG significantly improves the accuracy and recall of
three typical types of temporal reasoning questions, paving the way for more
faithful and temporal-aware generation. DyG-RAG is available at
https://github.com/RingBDStack/DyG-RAG.

</details>
