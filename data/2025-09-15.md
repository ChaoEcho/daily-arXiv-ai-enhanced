<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.CV](#cs.CV) [Total: 64]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.LG](#cs.LG) [Total: 53]
- [cs.NI](#cs.NI) [Total: 8]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.RO](#cs.RO) [Total: 3]
- [cs.IR](#cs.IR) [Total: 11]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.CR](#cs.CR) [Total: 5]
- [physics.app-ph](#physics.app-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 5]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [eess.IV](#eess.IV) [Total: 5]
- [cs.HC](#cs.HC) [Total: 1]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [eess.SP](#eess.SP) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 本研究提出利用文档级知识图谱对临床文档进行结构化表示，以提高自动化ICD编码的性能和训练效率，并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 将临床文档映射到标准化词汇（如ICD）对于临床研究和管理至关重要，但人工编码效率低下。自动化编码面临高维度、长尾目标空间的挑战，且现有方法主要关注输出代码表示，对输入文档表示的探索不足。

Method: 本研究通过构建文档级知识图谱（KGs）来计算输入文档的结构化表示，这些KGs能全面结构化地呈现患者状况。随后，将这种知识图谱表示整合到最先进的ICD编码架构PLM-ICD中，以评估其在自动化ICD-9编码中的有效性。

Result: 所构建的知识图谱能高效地表示以患者为中心的输入文档，仅用23%的原始文本量却保留了90%的信息。实验结果显示，在常用基准测试中，Macro-F1分数最高提升了3.20%，同时提高了训练效率。性能提升归因于知识图谱中不同类型的实体和关系，并且该方法比纯文本基线具有更好的可解释性潜力。

Conclusion: 文档级知识图谱为临床文档提供了一种有效且高效的结构化表示方法，显著提升了自动化ICD编码的性能、训练效率和可解释性。

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [2] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: 提出交叉层注意力探测（CLAP）技术，通过分析LLM跨层激活来有效检测幻觉，并能提升LLM的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的广泛应用带来了可靠性担忧，因为它们倾向于生成不准确文本（即幻觉）。

Method: 提出一种新颖的激活探测技术——交叉层注意力探测（CLAP），它将LLM整个残差流的激活作为一个联合序列进行处理，以检测幻觉。

Result: CLAP在五种LLM和三项任务上，相比基线显著提升了幻觉检测能力，对贪婪解码和高温采样响应均有效，实现了细粒度检测。在此基础上，提出了一种先检测后缓解的策略，能有效减少幻觉并提高LLM可靠性。CLAP在分布外（out-of-distribution）应用时仍能保持高可靠性。

Conclusion: CLAP通过深度分析LLM内部激活，提供了一种高效、鲁棒的幻觉检测方法，并能通过先检测后缓解策略有效提升LLM的可靠性。

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [3] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文将多任务学习（MTL）视为一种正则化方法，通过探究跨模态和模态内的正则化来源（如一致性正则化、R-drop和MT损失系数），提出“正则化地平线”概念，以克服端到端语音-文本翻译的数据稀缺问题，并在MuST-C数据集上取得了接近SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 端到端语音-文本翻译通常受限于配对语音-文本数据的稀缺性。

Method: 1. 从正则化角度重新构建多任务学习（MTL）。2. 深入研究跨模态（一致性正则化）和模态内（R-drop）序列的正则化效应。3. 发现机器翻译（MT）损失系数也是MTL中的正则化来源。4. 基于这三种正则化来源，提出高维空间中的“正则化地平线”概念作为最优正则化轮廓。

Result: 通过在“正则化地平线”内调整超参数，在MuST-C数据集上取得了接近当前最佳（SOTA）的性能。

Conclusion: 通过理解MTL中的多种正则化来源并利用“正则化地平线”进行超参数调优，可以有效解决语音-文本翻译数据稀缺问题，并实现高性能。

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [4] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: 该研究引入了一个评估大型语言模型（LLMs）营销创造力的新基准，发现模型性能高度集中，且LLM作为评估者不可靠，强调了专家人工评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在营销创造力方面的能力和局限性，并为该领域提供一个标准化的评估框架。

Method: 引入“创造力基准”（Creativity Benchmark），涵盖100个品牌和三种提示类型。通过678位专业创意人员的11,012次匿名配对比较收集人类偏好数据，并使用Bradley-Terry模型进行分析。同时，使用余弦距离分析模型多样性，并比较了三种“LLM作为评委”设置与人类排名的相关性。

Result: LLMs的性能紧密聚集，没有模型在品牌或提示类型上表现出压倒性优势（最高与最低模型胜率仅约61%）。LLM作为评委与人类评估结果之间存在微弱且不一致的相关性及评委特定偏差，表明其无法替代人工评估。传统创造力测试仅部分适用于品牌限制任务。

Conclusion: 评估LLM的营销创造力需要专家的人工评估和关注多样性的工作流程，因为自动化评委并不可靠，且模型间的性能差异不大。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [5] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: 为解决LLM知识产权保护问题，本文提出CTCC，一种基于多轮对话上下文关联的规则驱动指纹框架，实现黑盒验证，并展现出更强的隐蔽性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLM)的广泛部署加剧了知识产权(IP)保护担忧，因模型盗窃和未经授权再分发日益可行。现有模型指纹方法在隐蔽性、鲁棒性和通用性之间存在固有限制，易被检测、易受攻击或指纹暴露后失效。

Method: 本文引入CTCC，一种新颖的规则驱动指纹框架。该框架通过编码跨多个对话轮次的上下文关联（例如反事实），而非依赖于token级或单轮触发器，来嵌入可验证的所有权痕迹。CTCC支持在黑盒访问下进行指纹验证，同时减轻误报和指纹泄露，并支持在共享语义规则下持续构建，即使部分触发器暴露。

Result: 在多种LLM架构上的广泛实验表明，CTCC始终比现有工作实现更强的隐蔽性和鲁棒性。

Conclusion: CTCC是真实世界LLM部署场景中，用于所有权验证的可靠且实用的解决方案。

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [6] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 研究发现语言模型在跨期选择中表现出时间偏好，尤其推理型模型可受提示词引导，并为自身内化未来导向，对AI助理设计有重要启示。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型（LMs）在跨期选择中是倾向未来还是现在，以及这种偏好是否能被系统性操控，这对于设计能满足用户长期异质性目标的AI助理至关重要。

Method: 采用改编自人类实验的时间权衡任务协议，评估了多个语言模型，并将其与人类决策者样本进行基准测试。引入了“时间导向可操控性”（MTO）指标，衡量模型在未来导向和现在导向提示下时间偏好的变化。

Result: 推理型模型（如DeepSeek-Reasoner和grok-3-mini）在未来导向提示下更倾向选择延迟选项，但在不同身份或地理背景下的个性化决策能力有限。此外，能正确理解时间导向的模型会为自身（作为AI决策者）内化未来导向。

Conclusion: 研究为设计能与用户异质、长远目标对齐的AI助理提供了设计启示，并指出了个性化上下文校准和社会感知部署的未来研究方向。

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [7] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 本研究探讨了小型LLMs（2B-8B）在重复回答同一问题时的答案一致性，发现其在低推理温度下通常在50%-80%之间，且中型模型的一致性显著更高。


<details>
  <summary>Details</summary>
Motivation: 探究小型LLMs在重复回答同一问题时的答案一致性，并分析不同推理温度、模型大小、微调情况等因素对一致性的影响，以及要求多轮答案一致性对准确率的权衡。

Method: 对已知开源的2B-8B参数的LLMs进行研究，使其对来自MMLU-Redux和MedQA基准测试的问题进行10次重复回答。考虑了不同的推理温度、小型与中型模型（50B-80B）、微调与基础模型等参数。同时，提出了新的分析和图形工具来支持这些研究。

Result: 结果显示，在低推理温度下，小型模型能够一致回答的问题数量在模型间差异很大，但通常在50%-80%的范围内。一致答案的准确率与整体准确率之间存在合理的相关性。中型模型的结果表明其答案一致性水平要高得多。

Conclusion: 小型LLMs在重复回答问题时表现出中等程度的答案一致性（低温度下50%-80%），且一致答案的准确性与整体准确性良好相关。中型模型则展现出明显更高的一致性，这对于选择兼顾一致性和准确性的模型具有指导意义。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [8] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 本研究利用稀疏自编码器（SAEs）深入分析了大型语言模型（LLMs）拒绝有害提示的内在机制，通过消融关键特征实现越狱，并揭示了模型安全行为的潜在机制。


<details>
  <summary>Details</summary>
Motivation: 指令微调LLMs拒绝有害提示是关键的安全行为，但其内部原因尚不清楚，阻碍了对模型安全行为的理解和干预。

Method: 研究Gemma-2-2B-IT和LLaMA-3.1-8B-IT模型，使用在残差流激活上训练的稀疏自编码器（SAEs）。通过三阶段流程在SAE潜在空间中寻找特征集，其消融可将模型从拒绝变为顺从（实现越狱）：(1) 寻找拒绝介导方向并收集附近SAE特征；(2) 贪婪过滤以得到最小特征集；(3) 使用因子分解机（FM）发现剩余活跃特征与最小集之间的非线性交互。

Result: 该流程识别出大量对越狱至关重要的特征，为模型拒绝行为的机械性基础提供了深刻见解。此外，研究发现存在冗余特征，这些特征在早期特征被抑制前保持休眠状态。

Conclusion: 研究结果强调了通过操纵可解释的潜在空间，实现对LLMs安全行为进行细粒度审计和有针对性干预的潜力。

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [9] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: 本研究针对LLMs在学术写作中的引用错误和评估主观性问题，提出定量评估指标和迭代提示方法，有效提升了LLM的写作质量并减少了引用错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在学术写作中日益普及，但其引用错误或伪造引发伦理担忧；当前内容质量评估主要依赖主观判断，缺乏客观性、一致性和可靠性。

Method: 提出了“内容质量”和“引用有效性”两个关键评估指标，并基于这些指标的分数，设计了一种迭代提示方法来提升LLMs的科研提案写作能力。

Result: 所提出的指标为评估ChatGPT的写作表现提供了客观、定量的框架；迭代提示显著提升了内容质量，同时减少了引用的不准确和伪造。

Conclusion: 本研究通过定量评估和迭代提示方法，有效解决了LLMs在学术写作中引文不准确等关键伦理挑战，提升了其内容质量和引用准确性。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [10] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究引入了一种基于大型语言模型（LLM）的方案，用于从开源数据生成个体出行日记，并在整体真实性上与传统方法相当，同时在某些方面表现更优，证明了LLM的零样本可行性。


<details>
  <summary>Details</summary>
Motivation: 传统个体出行日记生成方法高度依赖大量专有的家庭出行调查数据，获取成本高昂且受限。本研究旨在开发一种利用开源数据结合LLM来生成高质量合成出行日记的新方法。

Method: 该研究首先从开源的美国社区调查（ACS）和智能位置数据库（SLD）数据中随机生成人物画像（personas），然后通过直接提示LLM来合成出行日记。研究引入了一种新颖的“一对群组真实性评分”，该评分由行程次数、间隔、目的和模式四项指标组成，并使用Jensen-Shannon散度对生成日记与真实的康涅狄格州全州交通研究（CSTS）日记进行分布相似性验证。最后，将LLM生成的结果与校准过的经典方法（负二项分布用于行程生成；多项Logit用于模式/目的）进行比较。

Result: LLM生成的出行日记在整体真实性上与经典方法相当（LLM平均0.485 vs. 经典方法0.455）。具体而言，LLM在确定出行目的方面表现出色，并展现出更高的一致性（真实性评分分布更窄）。而经典模型在行程次数和活动持续时间的数值估计上略胜一筹。汇总验证证实了LLM的统计代表性（LLM平均0.612 vs. 经典方法0.435）。

Conclusion: 本研究证明了LLM在从开源数据生成个体出行日记方面的零样本（zero-shot）可行性，并成功建立了一个可量化的日记真实性评估指标，为未来的合成日记评估系统提供了基础。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [11] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: 本文引入了PsychiatryBench，一个基于权威精神病学教材和案例书构建的基准，用于全面评估大型语言模型（LLMs）在精神病学实践中的表现，结果显示LLMs在临床一致性和安全性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在精神病学实践中具有巨大潜力，但现有评估资源临床有效性有限，无法捕捉精神病学推理的复杂性。因此，需要一个更严谨、基于专家验证内容的基准来评估LLMs在该领域的表现。

Method: 研究团队创建了PsychiatryBench，一个包含11种问答任务（如诊断推理、治疗规划、长期随访等）的基准，共计5,300多项由专家标注的项目，所有内容均来源于权威精神病学教科书和案例书。他们使用传统指标和“LLM-as-judge”相似性评分框架，评估了一系列前沿LLMs（如Google Gemini, LLaMA 3）和开源医疗模型（如OpenBiloLLM）。

Result: 评估结果表明，LLMs在临床一致性和安全性方面存在显著差距，尤其是在多轮随访和管理任务中表现不佳。

Conclusion: 研究强调需要针对精神病学领域进行专门的模型调优和更强大的评估范式。PsychiatryBench提供了一个模块化、可扩展的平台，用于基准测试和改进LLMs在高风险精神健康应用中的性能。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [12] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 研究发现，使用偏好对齐策略优化（ORPO）训练的小型LLM能有效提供接纳与承诺疗法（ACT），且COT推理的效用取决于训练方法。


<details>
  <summary>Details</summary>
Motivation: 探究后训练方法和显式推理对小型开源大语言模型（LLM）提供接纳与承诺疗法（ACT）能力的影响。

Method: 利用Mistral-Large生成的50套合成ACT对话，对Llama-3.2-3b-Instruct模型采用监督微调（SFT）和赔率比策略优化（ORPO）两种方法进行训练，每种方法均有和无显式思维链（COT）推理步骤。通过经过人类评估微调的LLM评估器，在模拟治疗会话中，使用ACT忠诚度量表（ACT-FM）和治疗师同理心量表（TES）评估模型性能。

Result: ORPO训练的模型在ACT忠诚度（p < .001）和治疗师同理心（p < .001）方面显著优于SFT和基础Instruct模型。COT对SFT模型有显著益处，ACT-FM分数平均提高2.68分（p < .001），但对表现更优的ORPO或instruct-tuned模型没有明显优势。

Conclusion: 偏好对齐策略优化（ORPO）能有效赋予小型LLM ACT能力，而显式推理（COT）的效用高度依赖于底层的训练范式。ORPO的优势可能在于学习了治疗的“过程”而非模仿“内容”，而COT则作为仅通过模仿进行训练的模型的必要支架。

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [13] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 现有RAG方法在多跳查询中面临效率低和噪声积累问题。本文提出HANRAG框架，通过查询路由、分解子查询和文档去噪来解决这些问题，并在单跳和多跳问答任务中均取得卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理多跳查询时存在诸多挑战，包括过度依赖迭代检索导致步骤浪费，原始复杂查询未能捕获子查询相关内容导致噪声，以及噪声管理不当造成的噪声积累问题。

Method: 本文引入HANRAG，一个新颖的基于启发式的框架，旨在高效处理不同复杂度的查询。HANRAG由一个强大的“启示者”驱动，能够路由查询、将其分解为子查询，并过滤检索文档中的噪声，从而增强系统的适应性和抗噪能力。

Result: 通过将HANRAG框架与行业领先方法在各种基准测试中进行比较，结果表明我们的框架在单跳和多跳问答任务中均获得了卓越的性能。

Conclusion: HANRAG框架通过其独特的查询路由、分解和去噪机制，有效解决了现有RAG方法在处理多跳查询时面临的效率和噪声问题，显著提升了问答系统的综合性能。

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [14] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 本研究评估了18种语义相似度测量方法在软件工程应用中的表现。结果显示，常用嵌入方法存在严重缺陷，常将语义相反的内容判为相似；而LLM在区分语义差异方面表现更优，并发现距离计算方式对嵌入方法性能影响显著。


<details>
  <summary>Details</summary>
Motivation: 语义相似度测量对代码搜索、API推荐、自动化代码审查等软件工程应用至关重要。研究旨在探究不同方法（尤其是大型语言模型）在此类评估中的实际效果，以及它们是否真正理解语义关系或仅识别表面模式。

Method: 研究测试了18种不同的相似度测量方法，包括基于词汇、嵌入技术、LLM和结构感知算法。建立了一个系统测试框架，通过对文本和代码应用受控修改来评估每种方法处理不同语义关系的能力。

Result: 常用指标存在显著问题：某些嵌入方法高达99.9%的概率将语义相反的内容识别为相似，而部分Transformer方法偶尔将相反含义评为比同义词更相似。嵌入方法表现不佳常因距离计算方式导致，将欧氏距离切换为余弦相似度可提高24-66%的效果。LLM在区分语义差异上表现更好，对真正不同的含义给出低相似度分数（0.00-0.29），而嵌入方法却错误地给出高分（0.82-0.99）。

Conclusion: 当前语义相似度测量方法，特别是嵌入技术，在区分语义差异方面存在严重缺陷，且其性能受距离计算方式影响巨大。大型语言模型在辨别语义差异方面表现出相对优势，但整个领域仍需改进，以确保这些工具在软件工程应用中的可靠性。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [15] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 本研究识别并量化了导致大型语言模型（LLM）幻觉的关键内在属性，发现尽管模型规模增大能减少幻觉，但由符号元素（特别是修饰符和命名实体）引起的幻觉仍普遍存在，表明LLM在处理这类输入时存在根本性弱点。


<details>
  <summary>Details</summary>
Motivation: LLM幻觉问题已得到广泛研究，但导致LLM本质上容易产生幻觉的内在属性尚未被识别和深入研究。

Method: 利用HaluEval和TruthfulQA两个现有数据集，将其问答格式转换为多种其他格式，以识别和确定导致幻觉的关键属性。研究对象是Gemma-2系列模型（2B、9B、27B）。

Result: Gemma-2-2B在符号属性上的幻觉率平均高达79.0%。随着模型规模增大，幻觉率有所下降（Gemma-2-9B为73.6%，Gemma-2-27B为63.9%，总计降低15个百分点）。然而，由符号属性（特别是修饰符84.76%-94.98%和命名实体83.87%-93.96%）引起的幻觉在所有Gemma模型和数据集中仍然大量存在。

Conclusion: 符号元素持续困扰着LLM，这表明这些模型在处理此类输入时存在一个根本性的弱点，且与模型规模无关。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [16] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS是一个基于大语言模型（LLM）的系统，旨在解决测量效度验证中构建列联网络的长期挑战，它能生成大规模跨学科的列联网络，并已在评估中展现出发现新维度和验证现有测量工具的强大能力。


<details>
  <summary>Details</summary>
Motivation: 心理测量对多学科至关重要，但构建概念与测量之间关系的列联网络以确立效度，在提出70年后仍是难题，这可能导致临床试验失败和公共政策目标错误。

Method: 引入了“潜在指标生成列联结构分析系统”（ALIGNS），这是一个基于大型语言模型的系统，通过使用经过验证的问卷测量数据进行训练。

Result: ALIGNS成功提供了三个综合性列联网络，包含超过55万个指标，覆盖心理学、医学、社会政策等多个领域。这是大语言模型首次被应用于解决测量验证中的基础问题。在三项评估中：证实了广泛使用的NIH PROMIS焦虑和抑郁量表可汇聚为一个情绪困扰维度；在儿童气质测量中，识别出四个当前框架未捕捉到的潜在维度，并对一个现有维度提出了质疑；专家心理测量学家评估并认可了系统的实用性、可访问性和适用性。

Conclusion: ALIGNS系统通过大规模列联网络分析，有效补充了传统验证方法，为解决测量效度验证的核心挑战提供了创新的解决方案，并已免费开放供公众使用。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [17] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 本文提出一个基于技术时间关系、利用大型语言模型（LLM）的框架，用于从专利数据中识别新兴技术机会，并发现AI技术正朝着日常可及性发展。


<details>
  <summary>Details</summary>
Motivation: 技术机会是技术、工业和创新进步的关键信息，因此需要一个有效的框架来识别新兴技术机会。

Method: 该框架首先从专利数据集中提取文本，然后映射基于文本的主题以发现技术间的关系。通过跟踪这些主题随时间的变化来识别技术机会。为提高效率，框架利用大型语言模型提取主题，并采用基于聊天的语言模型提示来辅助发现。该框架使用美国专利商标局提供的AI专利数据集进行了评估。

Result: 实验结果表明，人工智能技术正在发展成为便于日常使用的形式。

Conclusion: 所提出的方法展示了识别未来技术机会的潜力。

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [18] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 提出一个轻量级管道系统（BIBERT-Pipe），通过两阶段检索-排序、边界提示和数据增强，解决了多语言嵌套生物医学实体链接的挑战，并在BioNNE 2025任务中排名第三。


<details>
  <summary>Details</summary>
Motivation: 生物医学实体链接（EL）的基准测试通常限于英语且提及平铺的语料库，未能充分探索更真实的嵌套和多语言提及场景。

Method: 开发了一个轻量级管道系统（BIBERT-Pipe），该系统在保留原始EL模型的基础上，主要修改了三个组件：1) 两阶段检索-排序，在检索阶段使用预训练模型，在排序阶段应用领域特定微调；2) 边界提示，通过可学习的[Ms]/[Me]标签明确标记提及，增强对嵌套的鲁棒性；3) 数据集增强，自动扩展训练语料库以提高覆盖率。

Result: 在BioNNE 2025多语言赛道中，BIBERT-Pipe系统排名第三。

Conclusion: 所提出的最小但有原则的修改，在处理多语言嵌套生物医学实体链接任务中表现出有效性和竞争力。

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [19] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: 本文提出一种利用大型语言模型（LLMs）的非形式化和摘要能力，将机器可验证的正式证明转换为自然语言证明的方法。


<details>
  <summary>Details</summary>
Motivation: 使机器可验证的正式证明更易于人类理解和阅读，提高其可访问性。

Method: 利用LLMs的非形式化（将形式语言证明步骤口头化）和摘要能力。通过将该方法应用于根据大学教科书中的自然语言证明创建的正式证明数据进行评估，并将生成的自然语言证明质量与原始自然语言证明进行比较。此外，还将其应用于Lean证明助手的现有正式证明库。

Result: 通过与原始自然语言证明的比较，分析了生成的自然语言证明的质量。该方法能够输出高度可读且准确的自然语言证明。

Conclusion: 该方法能够有效且准确地将正式证明转换为高度可读的自然语言证明，提高了正式证明的可读性和可访问性。

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [20] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: 提出一个多智能体框架，通过角色提示和RAG显著提高金融问答（QA）的准确性，提供经济高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）难以处理金融领域问答中所需的细致、多步定量推理和专业知识。

Method: 引入一个包含基础生成器、证据检索器和专家评审员的多智能体框架，利用角色提示和检索增强生成（RAG）对6本金融教科书进行单次迭代处理，并在Study.com的3532道金融教育问题上进行评估。

Result: 基于批判的改进使回答准确性比零样本思维链基线提高6.6-8.3%；Gemini-2.0-Flash表现最佳；GPT-4o-mini的性能可与金融专用模型FinGPT-mt_Llama3-8B_LoRA媲美。

Conclusion: 提供了一种经济高效的金融问答增强方法，并为多智能体金融LLM系统的进一步研究提供了见解。

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [21] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: 本文对Twitter情感分析中机器学习模型性能进行了元分析，发现平均准确率为0.80，并指出整体准确率的误导性及标准化性能报告的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估机器学习在Twitter情感分析中的性能，估计平均表现，评估研究间和研究内的异质性，并分析研究特征对模型性能的影响。

Method: 采用PRISMA指南进行元分析，从学术数据库中筛选了20项研究的195个试验（包含12项研究特征）。使用双反正弦变换和三级随机效应模型分析最常报告的整体准确率。

Result: AIC优化模型的平均整体准确率为0.80 [0.76, 0.84]。

Conclusion: 1) 整体准确率普遍使用但常因类别不平衡和情感类别数量而产生误导，需要进行标准化处理。2) 为了可靠地比较机器学习分类器，标准化性能报告（包括独立测试集的混淆矩阵）至关重要，但这远非普遍做法。

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [22] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: 本文提出了MultimodalHugs，一个基于Hugging Face的框架，旨在解决手语处理（SLP）研究中复现性低和工具灵活性不足的问题，并支持更广泛的多模态任务。


<details>
  <summary>Details</summary>
Motivation: 手语处理（SLP）研究面临代码复杂、复现性低和比较不公等挑战。现有工具（如Hugging Face）不足以灵活集成手语实验，这一观点已通过调查证实。

Method: 开发了MultimodalHugs框架，它建立在Hugging Face之上，通过增加抽象层来支持更多样的数据模态和任务，同时继承Hugging Face生态系统的优势。

Result: 定量实验表明，MultimodalHugs能够适应多种模态，例如手语的姿态估计数据或文本字符的像素数据。

Conclusion: MultimodalHugs为SLP研究提供了更灵活和可复现的解决方案，并可广泛应用于其他不符合Hugging Face标准模板的多模态用例。

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [23] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: 本文提出了AncientDoc，首个针对中国古籍的视觉语言模型（VLM）基准，旨在评估VLM从光学字符识别（OCR）到知识推理的能力。


<details>
  <summary>Details</summary>
Motivation: 中国古籍蕴含丰富知识，但其数字化和理解面临挑战，现有传统方法仅停留在图像扫描，而当前VLM难以处理古籍的视觉和语言复杂性。此外，现有文档基准主要关注英文印刷文本或简化中文，缺乏对古籍的评估。

Method: 研究者创建了AncientDoc基准，包含五项任务（页级OCR、白话文翻译、推理问答、知识问答、语言变体问答）。该基准涵盖14种文献类型、100多本书籍、约3000页古籍。基于AncientDoc，研究者使用多种指标，并辅以人类对齐的大语言模型进行评分，以评估主流VLM。

Result: 摘要中未明确给出评估结果。

Conclusion: 摘要中未明确给出结论。

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [24] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 本文提出MCP-AgentBench，这是一个专为评估语言智能体在Model Context Protocol (MCP) 介导的工具交互中的能力而设计的综合基准，旨在解决现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: Model Context Protocol (MCP) 作为代理-工具集成的重要开放标准正在迅速发展，但现有基准未能有效捕捉该新范式下代理的真实世界性能，导致对其操作价值的误判和区分能力不足。

Method: 引入MCP-AgentBench基准，核心贡献包括：1) 建立包含33个操作服务器和188个工具的MCP测试平台；2) 开发包含600个跨6个不同交互复杂度的系统设计查询；3) 引入以真实任务成功为导向的MCP-Eval新型评估方法。

Result: 通过对领先语言智能体进行广泛的实证评估，提供了基础性见解。

Conclusion: MCP-AgentBench旨在为研究社区提供一个标准化、可靠的框架，以构建、验证和推进能够充分利用MCP变革性优势的智能体，从而加速实现真正强大和可互操作的AI系统。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [25] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: 本研究发现LLMs在决策任务中存在显著的性别、年龄和背景偏见，但在摘要任务中偏见较少；偏见具有跨语言传播性；提示词缓解策略有效，GPT-4o表现优于GPT-3.5。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLMs的广泛应用引发对其可能导致的社会不平等和信息偏见的担忧，本研究旨在探究LLMs在决策和摘要任务中与背景、性别和年龄相关的偏见，其跨语言传播特性，以及提示词缓解策略的有效性。

Method: 本研究改编并翻译了Tamkin et al. (2023) 的数据集为荷兰语，创建了151,200个决策任务提示和176,400个摘要任务提示。在GPT-3.5和GPT-4o模型上，测试了不同的社会人口变量、指令、显著性水平和语言。

Result: ['在决策任务中，GPT-3.5和GPT-4o均显示出显著偏见，倾向于女性、较年轻年龄和特定背景（如非洲裔美国人）。', '摘要任务中偏见证据极少，但GPT-3.5在英语中出现了显著的年龄相关差异。', '跨语言分析显示，英语和荷兰语的偏见模式大致相似，但在特定人口类别中存在明显差异。', '新提出的缓解指令虽然未能完全消除偏见，但能将最有利与最不利人口群体之间的差距平均减少27%。', '与GPT-3.5相反，GPT-4o在所有英文提示中都表现出偏见减少。']

Conclusion: 本研究强调了谨慎采用LLMs以及进行特定情境偏见测试的重要性，并指出需持续开发有效的缓解策略以确保AI的负责任部署。

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [26] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: 本文提出HEFT，一种结合LoRA（权重空间）和ReFT（表示空间）的分层PEFT策略，在BoolQ基准测试上以更少计算资源实现更优性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在专业推理任务上的适应性受限于计算资源。现有的参数高效微调（PEFT）方法多样，分属权重空间或表示空间，亟需探索如何通过协同组合这些范式来提升性能和效率。

Method: 引入分层高效微调（HEFT），它以粗到细的方式组合两种PEFT方法：首先通过低秩适应（LoRA）在权重空间进行基础适应，然后通过表示微调（ReFT）对内部激活进行精确细化。该方法在Llama-2-7B模型上，使用BoolQ基准进行推理任务的评估。

Result: HEFT策略（仅3个epoch）在BoolQ上取得了85.17%的准确率，超过了单独使用LoRA（20个epoch，85.05%）或ReFT（20个epoch，83.36%）的方法，展示了显著的协同效应，且计算成本大大降低。

Conclusion: PEFT方法的深思熟虑组合是一种强大的算法创新，为提升语言模型推理能力提供了更高效和有效途径，能以更少的计算预算克服大型模型适应复杂认知任务的障碍。

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [27] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 本文提出了一种多模态会话轮次组织建模框架，通过关联语言和交互手势来理解语用框架。研究团队开发了标注方法，并用轮次组织手势标注增强了Frame2数据集。结果证实手势在轮次管理中的作用，并揭示了此前未记录的手势变体，将其与语用框架和认知过程联系起来。


<details>
  <summary>Details</summary>
Motivation: 尽管会话轮次组织已有多领域研究，但缺乏将具体策略（特别是手势）编码为可用于机器学习的数据集。本研究旨在填补这一空白，通过在自然语境中观察手势使用，并提供一个丰富的多模态数据集。

Method: 提出了一个多模态会话轮次组织建模框架，该框架基于语用框架的构念和唤起方式，旨在关联语言和交互手势。开发了一种标注方法，用于丰富已标注语义框架的Frame2数据集，加入了建模会话轮次组织的语用框架（特别关注手势）。Frame2数据集包含巴西电视剧的10集内容，用于观察非实验室环境下的真实对话。

Result: 研究证实，面对面交流中的参与者会使用手势来传递、获取和保持会话轮次。此外，还发现了之前未曾记录的某些手势变体。研究提出这些手势的使用源于语用框架的概念化，涉及心理空间、概念混成和概念隐喻。数据表明，语用框架的标注有助于更深入理解人类认知和语言。

Conclusion: 手势是面对面会话中管理轮次的关键工具，且其使用与语用框架及认知过程紧密相关。本研究通过丰富数据集和提出的框架，不仅揭示了新的手势变体，也加深了对人类认知和语言的理解，为未来的机器学习研究提供了宝贵资源。

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [28] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 本文提出一种主题引导的强化学习方法，通过引入主题奖励改进多文档摘要（MDS）中的内容选择。


<details>
  <summary>Details</summary>
Motivation: 多文档摘要（MDS）在信息整合、保持连贯性和主题相关性方面面临挑战，大型语言模型在MDS上的表现仍有提升空间。

Method: 我们提出一种主题引导的强化学习方法。首先，证明显式地用主题标签提示模型可以提高摘要的信息量。其次，在Group Relative Policy Optimization (GRPO)框架内引入新颖的主题奖励，以衡量生成摘要与源文档之间主题的一致性。

Result: 在Multi-News和Multi-XScience数据集上的实验结果表明，该方法持续优于强基线模型。

Conclusion: 该研究强调了在多文档摘要中利用主题线索的有效性。

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [29] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型（LLM）生成合成调查回复的可靠性，发现其在信任项上表现优异，特定模型（如GPT-4o）性能相当，且在45-59岁受访者中合成与人类回复对齐度最高。总体而言，LLM合成样本能近似真实概率样本，但存在项目层面的显著异质性。


<details>
  <summary>Details</summary>
Motivation: LLM在调查研究中利用合成受访者展现出巨大潜力，有望减少测量和代表性误差。然而，LLM恢复聚合项目分布的程度以及其可能再现社会偏见的风险仍不明确，这促使研究评估其可靠性。

Method: 研究将LLM生成的合成调查回复与来自智利公众意见概率调查的真实人类回复进行比较，以评估其可靠性。具体方法包括基准测试128个提示-模型-问题组合，生成189,696个合成配置文件，并使用元分析汇集准确率、精确度、召回率和F1分数等性能指标，跨128个问题-子样本对测试关键社会人口学维度的偏差。评估涵盖OpenAI的GPT系列模型以及Llama和Qwen模型。

Result: 研究得出三个主要结果：1. 合成回复在信任项上表现出色（F1分数和准确率均>0.90）。2. GPT-4o、GPT-4o-mini和Llama 4 Maverick在此任务上表现相当。3. 合成与人类回复的对齐度在45-59岁受访者中最高。总体而言，基于LLM的合成样本能近似概率样本的回复，但存在显著的项目层面异质性。

Conclusion: 尽管LLM合成样本能近似真实的调查回复，但捕捉公众意见的全部细微差别仍具挑战性。这要求未来在应用中进行仔细校准和额外的分布测试，以确保算法的保真度并减少错误。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [30] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: 本文全面综述了法律领域大语言模型（LLMs）的研究进展，包括模型、框架、数据集、基准、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型显著推动了法律人工智能（Legal AI）发展，为促进基于LLM的法律领域研究与应用，需要提供系统性综述。

Method: 全面回顾了16个法律LLM系列和47个LLM驱动的法律任务框架；收集了15个基准和29个数据集用于评估；分析了挑战并讨论了未来发展方向。

Result: 本研究提供了一个关于法律领域LLM方法论的系统性介绍，包括现有模型、框架、评估资源，并对该领域的挑战和未来方向进行了分析。

Conclusion: 旨在为法律AI领域的初学者提供系统性介绍，并鼓励未来的研究与发展。

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [31] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 为解决中国少数民族语言（藏、维、蒙语）缺乏语料的问题，本研究提出了一个名为CMHG的新数据集和高质量测试集，用于标题生成任务。


<details>
  <summary>Details</summary>
Motivation: 中国少数民族语言因其独特的书写系统，与国际标准不符，导致缺乏相关语料库，尤其在标题生成等监督任务中面临严峻挑战。

Method: 引入了新型数据集“Chinese Minority Headline Generation (CMHG)”，包含藏语10万条、维吾尔语和蒙古语各5万条专为标题生成任务策划的条目。同时，提出了一个由母语使用者标注的高质量测试集作为基准。

Result: 创建了包含藏语、维吾尔语和蒙古语共计20万条目的CMHG数据集，并设计了一个高质量的基准测试集。

Conclusion: 该数据集有望成为推进中国少数民族语言标题生成研究的宝贵资源，并有助于相关基准的开发。

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [32] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: IRIS是一种无监督幻觉检测框架，通过利用大型语言模型（LLM）的内部表示和响应不确定性来识别幻觉内容，表现优于现有方法，且成本低、效率高。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督幻觉检测方法依赖与事实准确性无关的代理信号，导致检测器偏向肤浅或非事实相关方面，限制了其在不同数据集和场景中的泛化能力。

Method: 提出IRIS框架。该方法提示LLM验证给定语句的真实性，并获取其上下文嵌入作为训练的特征；同时，将每次响应的不确定性视为真实性的软伪标签。

Result: 实验结果表明，IRIS持续优于现有的无监督方法。该方法完全无监督、计算成本低，并且即使在少量训练数据下也能表现良好。

Conclusion: IRIS提供了一种高效、通用且适用于实时检测的无监督幻觉检测方案，克服了现有方法的局限性。

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [33] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文分析了开源小型LLMs在多标签意图分类上的表现，发现Mistral-7B在少样本设置下表现最佳，但基于BERT的监督学习模型总体性能更优。


<details>
  <summary>Details</summary>
Motivation: 评估开源、可在消费级硬件上运行的LLMs在多标签意图分类任务中的潜力，旨在增强任务型聊天机器人的自然语言理解（NLU）能力。

Method: 使用MultiWOZ 2.1数据集，评估了LLama2-7B-hf、Mistral-7B-v0.1和Yi-6B三种开源LLMs在少样本（20个示例）设置下的表现。同时，将性能与基于BertForSequenceClassification的监督学习模型进行了比较。评估指标包括准确率、精确率、召回率、F1分数（微观、宏观、加权）、Humming Loss、Jaccard Similarity、推理时间及VRAM需求。

Result: 在少样本设置下，Mistral-7B-v0.1在14个意图类别中的11个上表现优于其他两个生成模型，加权F-score为0.50，并具有更低的Humming Loss和更高的Jaccard Similarity。然而，基于BERT的监督分类器表现优于所有少样本生成式LLM。

Conclusion: 该研究为小型开源LLMs在检测复杂多意图对话方面提供了框架，有助于增强任务型聊天机器人的NLU能力。同时指出，尽管小型LLMs在少样本设置下有潜力，但传统的监督学习方法在性能上仍具有优势。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [34] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 本研究利用社交媒体语言分析，揭示了双相情感障碍（BD）诊断前后广泛且持续的语言变化，包括周期性模式，为可扩展的精神健康监测提供了依据。


<details>
  <summary>Details</summary>
Motivation: 临床评估情感障碍（如BD）的规模受限，而语言能提供有价值的标记。因此，研究旨在利用社交媒体语言的高时间分辨率和纵向范围，弥补临床评估的不足，实现对BD的语言轨迹进行大规模监测。

Method: 开发了一种确定用户诊断时间的方法，并将其应用于分析BD用户诊断前3年至诊断后21年的语言轨迹。研究将BD用户的语言数据与单相抑郁症（UD）用户和非受影响用户（HC）进行了对比分析。

Result: 研究发现BD诊断伴随着反映情绪障碍、精神共病、药物滥用、住院、躯体共病、异常思维内容和思维紊乱的普遍语言改变。诊断后二十年内，情绪相关语言变化反复出现，具有显著的12个月周期性（提示季节性情绪发作）。此外，趋势层面的证据表明，女性用户的周期性有所增加。

Conclusion: 本研究为双相情感障碍急性期和慢性期的语言改变提供了证据，验证并扩展了利用社交媒体进行精神健康可扩展监测的现有努力。

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [35] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: MSA团队在BAREC 2025阿拉伯语可读性评估任务中六个赛道均获第一。其系统结合了四种Transformer模型、多样损失函数、数据增强（包括合成数据生成）和后处理，实现了高精度的细粒度可读性预测。


<details>
  <summary>Details</summary>
Motivation: 参与BAREC 2025细粒度阿拉伯语可读性评估共享任务，旨在解决该领域中严重的类别不平衡和数据稀缺问题，并追求卓越的评估性能。

Method: 该系统采用四种互补的Transformer模型（AraBERTv2, AraELECTRA, MARBERT, CAMeLBERT）的置信度加权集成方法，每个模型均使用不同的损失函数进行微调。为解决数据挑战，采用了加权训练、高级预处理、使用最强模型对SAMER语料库进行重标注，并通过Gemini 2.5 Flash生成约10,000个稀有级别的合成数据。此外，还进行了有针对性的后处理步骤以校正预测分布偏差。

Result: 系统在BAREC 2025共享任务的六个赛道中均获得第一名。后处理步骤使二次加权Kappa (QWK) 提高了6.3%。最终系统在句子级别达到87.5%的QWK，在文档级别达到87.4%的QWK。

Conclusion: 模型和损失函数的多样性、基于置信度的信息融合以及智能数据增强对于实现鲁棒的阿拉伯语可读性预测至关重要。

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [36] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 现有心理测量问卷不适用于测量大型语言模型（LLM）的特质，因其缺乏生态效度且结果易产生偏差和误导。


<details>
  <summary>Details</summary>
Motivation: 研究者对LLM应用人类心理测量问卷（如BFI, PVQ）的生态效度提出担忧，尚不清楚已建立问卷和生态有效问卷在结果上有何差异，以及这些差异能提供何种洞见。

Method: 本文对已建立问卷和生态有效问卷进行了全面的比较分析。

Result: 分析表明，已建立问卷：(1) 得出的LLM画像与生态有效问卷显著不同，偏离用户查询语境中表达的心理特征；(2) 项目不足，难以稳定测量；(3) 错误地暗示LLM具有稳定构念；(4) 对人格提示的LLM产生夸大的画像。

Conclusion: 本研究警告，不应将已建立的心理学问卷用于大型语言模型。

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [37] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 为解决气候科学文献信息过载问题，本研究构建了一个领域特定的知识图谱（KG），通过语义查询提升信息发现效率和准确性，并展示了其实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 气候科学文献日益复杂且庞大，导致研究人员难以有效查找跨模型、数据集、区域和变量的精确信息。

Method: 构建了一个基于气候出版物和科学文本的领域特定知识图谱（KG），支持结构化、语义化查询。使用Cypher查询演示其功能，并计划将其与RAG系统中的大型语言模型集成。

Result: 知识图谱能够通过语义查询精确回答复杂问题（如模型验证区域、数据集与遥相关模式关联），实现比传统关键词搜索更精确的信息发现，并提高气候相关问答的透明度和可靠性。

Conclusion: 该工作超越了知识图谱构建本身，充分展示了其对气候研究人员、模型开发者及其他依赖准确、上下文科学信息者的实际应用价值。

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [38] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本研究通过微调大型语言模型（LLMs），特别是Mistral-7B，以生成阿拉伯语医疗文本，旨在提供准确的实时医疗建议。利用独特的社交媒体数据集，该系统在处理非正式输入和多种方言方面表现出色，为医院管理系统（HMS）在语言多样化环境中的应用提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前医院管理系统（HMS）面临资源有限、患者拥挤及紧急医疗服务不足等挑战，且现有方法难以针对非规范输入和少数语言（如阿拉伯语）提供准确、实时的医疗建议。

Method: 研究方法包括：1) 从社交媒体平台收集包含患者投诉和医生建议的独特阿拉伯语真实医疗对话数据集；2) 对数据集进行清洗和预处理以处理多种阿拉伯语方言；3) 微调先进的生成模型，包括Mistral-7B-Instruct-v0.2、LLaMA-2-7B和GPT-2 Medium；4) 使用BERT Score（准确率、召回率、F1分数）和定性评估来评估系统性能。

Result: 评估结果显示，微调后的Mistral-7B模型优于其他模型，其BERT Score的平均准确率、召回率和F1分数分别为68.5%、69.08%和68.5%。对比基准测试和定性评估证实，该系统能够针对非正式输入生成连贯且相关的医疗回复。

Conclusion: 生成式AI在推进医院管理系统（HMS）方面潜力巨大，为全球医疗挑战，尤其是在语言和文化多样化环境中，提供了可扩展和适应性强的解决方案。本研究提出的系统能有效协助患者获取医疗建议、诊断、药物推荐和治疗方案。

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [39] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 针对阿拉伯语医疗聊天机器人数据集稀缺问题，本研究提出合成数据增强策略，利用ChatGPT-4o和Gemini生成8万条高质量问答对，将训练集扩充至10万条。微调后发现合成数据有效提升模型性能，其中ChatGPT-4o数据表现更优。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗聊天机器人的发展受到大规模、高质量标注数据集稀缺的严重限制；现有模型的可扩展性和泛化能力有限。

Method: 提出可扩展的合成数据增强策略，使用ChatGPT-4o和Gemini 2.5 Pro生成8万条上下文相关、医学连贯的合成问答对，将训练语料库扩展至10万条。合成样本经过语义过滤、人工验证后整合到训练流程中。微调了包括Mistral-7B和AraGPT2在内的五个大型语言模型，并通过BERTScore指标和专家定性评估其性能。此外，还进行了消融研究以独立比较ChatGPT-4o和Gemini生成数据的有效性。

Result: 研究结果表明，ChatGPT-4o生成的数据在所有模型中均持续带来更高的F1分数和更少的幻觉。

Conclusion: 合成数据增强是增强低资源医疗NLP领域特定语言模型的实用解决方案，为开发更具包容性、可扩展和准确的阿拉伯语医疗聊天机器人系统提供了新途径。

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [40] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 论文研究了奥地利德语中基于重音的ASR，使用wav2vec2进行重音检测。重音检测准确率达85.53%，但将其整合到ASR系统后，整体性能未见提升。


<details>
  <summary>Details</summary>
Motivation: 旨在研究结合重音检测与语音识别的重音感知自动语音识别（ASR），特别针对会话式奥地利德语，并探索融入韵律信息潜力。

Method: 首先，通过微调wav2vec2模型开发了词级别重音检测器。其次，使用该检测器自动标注了大型语料库的韵律重音。最后，基于这些标注，训练了能同时转录词语及其重音级别的新型重音感知ASR系统。

Result: 在词序列识别正确的情况下，重音检测准确率达到85.53%。然而，整合重音信息并未提升基线ASR系统的性能。研究表明基于Transformer的模型能有效编码韵律信息。

Conclusion: 基于Transformer的模型能够有效编码韵律信息，是对韵律增强型ASR的创新贡献。尽管当前整合未能提升ASR性能，但其在语言学研究和韵律感知对话系统方面具有潜在应用价值。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [41] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: 本文提出一个系统框架，用于为LLM驱动的社会模拟生成高质量、与人口分布对齐的个性化角色集，以减少偏见并提高模拟的准确性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在社会模拟中取得了进展，但构建能真实代表现实世界人口多样性和分布的角色集仍是关键挑战，现有研究常忽视角色生成复杂性及其引入的潜在偏见。

Method: 该方法首先利用LLM从社交媒体数据生成叙事角色并进行质量评估。然后，应用重要性采样与参考心理测量分布（如大五人格）进行全局对齐。最后，引入任务特定模块将角色集适应于特定子群体。

Result: 广泛实验证明，该方法显著减少了人口层面偏见，并能实现广泛研究和政策应用中准确、灵活的社会模拟。

Conclusion: 本框架通过提供高质量、人口对齐且灵活适应的角色集，有效解决了LLM社会模拟中的角色代表性问题，显著提升了模拟的真实性和可用性。

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [42] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: VLMs在文档理解中答案定位是挑战，本文提出DocExplainerV0模块，解耦答案生成与空间定位，提高解释性，并量化了文本准确性与空间定位的差距，建立评估基准。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）在文档理解和文本提取方面表现出色，但在文档中准确地定位答案仍是一大挑战，这限制了其可解释性和实际应用。

Method: 引入DocExplainerV0，这是一个即插即用的边界框预测模块，它将答案生成与空间定位解耦。这种设计使其适用于现有VLMs，包括那些无法进行微调的专有系统。

Result: 通过系统评估，提供了关于文本准确性和空间定位之间差距的量化见解，表明即使答案正确，其定位也往往不可靠。

Conclusion: DocExplainerV0及其提出的标准化框架揭示了现有VLMs的不足，并为未来研究建立了一个基准，旨在开发更具可解释性和鲁棒性的文档信息提取VLM。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [43] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 本研究使用Biber多维分析探讨人类和大型语言模型（LLM）生成文本的语域变异，并构建了LLM比较基准。


<details>
  <summary>Details</summary>
Motivation: 旨在找出LLM生成文本与人类撰写文本在语域方面最显著和系统性的差异维度，并考虑到非英语语言在LLM训练数据中的代表性不足，进行多语言验证。

Method: 采用Biber多维分析（MDA）。使用AI-Brown（对比BE-21）和AI-Koditex语料库，对16种前沿LLM模型（包括基础模型和指令微调模型）在不同设置和提示下进行分析。

Result: 识别出LLM与人类文本在语域变异上的关键差异维度。成功创建了一个可用于LLM模型比较和排名的基准。

Conclusion: 本研究揭示了LLM生成文本的语域特征，并提供了一个有效工具来评估和比较不同LLM模型在语域维度上的表现。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [44] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: 本研究探讨了情感支持对话中“不协调积极性”现象，发现LLMs尤其在高风险情境下，更容易产生轻视、弱化或不切实际的积极回应。为解决此问题，研究收集了人类与LLM对话数据，并开发了一个弱监督多标签分类器来检测不协调积极性。结论强调了平衡积极情感与情感承认在构建上下文感知且值得信任的在线对话系统中的重要性。


<details>
  <summary>Details</summary>
Motivation: 在情感支持对话中，善意的积极回应有时会适得其反，导致接收者感到被轻视、被弱化或过于乐观。本研究旨在探讨这种“不协调的积极性”现象，即积极支持表达的失调，无论是在人类还是大型语言模型（LLMs）生成的回应中。

Method: ['收集Reddit上的真实用户-助手对话，并为相同语境生成LLM回应，按情感强度分为“温和”和“严重”两类。', '对LLMs进行微调，使用包含强弱情感反应的数据集。', '开发了一个弱监督多标签分类器集成（DeBERTa和MentalBERT），用于检测不同情境下不协调的积极性类型。']

Result: ['LLMs在高风险情境中，更容易通过轻视和弱化的语气产生不真实的积极性回应。', '开发的弱监督多标签分类器集成在检测温和和严重情境中的不协调积极性类型方面显示出改进的性能。']

Conclusion: 研究结果表明，需要超越简单地生成通用积极回应，转而关注如何通过平衡积极情感与情感承认来实现“协调支持”。这为使大型语言模型与在线支持性对话中的情感预期保持一致提供了见解，并为构建上下文感知和维护信任的在线对话系统奠定了基础。

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [45] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 本文评估了多种大型语言模型（XLM-RoBERTa, Longformer, GPT-3.5, GPT-4）在社会科学长文本多分类任务中的表现，发现Longformer无明显优势，最佳开源模型优于GPT变体，且类别支持度和内容重叠度对长文本性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有主流大型语言模型（如BERT、RoBERTa）存在输入文本长度限制，这对于社会科学中处理极长文本（如数百页的法律文件）的多分类任务构成了严峻挑战。

Method: 研究在5种语言上进行了实验，使用了XLM-RoBERTa、Longformer、GPT-3.5和GPT-4模型。任务是针对比较议程项目（Comparative Agendas Project）的21个政策主题进行多分类，旨在处理长输入文本。

Result: Longformer模型并未展现出专门处理长输入的优势。与GPT变体相比，表现最佳的开源模型更具优势。对类别层面因素的分析表明，特定类别间的支持度和内容重叠度对长文本输入的性能至关重要。

Conclusion: 针对社会科学的长文本多分类任务，专门为长输入设计的模型（如Longformer）可能不具备特定优势，且某些开源模型能超越GPT变体。同时，类别间的支持度和实质性重叠是影响长文本处理性能的重要因素。

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [46] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 针对LLMs因知识冲突导致响应不忠实问题，本文提出SI FACT自改进对比微调框架。它通过自指令机制自动生成对比学习数据（锚点、正样本、负样本），并利用对比学习训练模型，以提高其上下文忠实性。实验表明，SI FACT使上下文召回率提升6.2%，并显著减少对内部记忆的依赖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识密集型任务中，由于知识冲突（即倾向于依赖内部参数知识而非提供的上下文），经常生成不忠实（unfaithful）的响应。

Method: 本文提出了一种名为“自改进忠实性感知对比微调”（Self Improving Faithfulness Aware Contrastive Tuning, SI FACT）的新型自改进框架。该框架使用自指令机制，使基础LLM能够自动生成高质量、结构化的对比学习数据，包括锚点样本、语义等价的正样本和模拟不忠实场景的负样本，从而显著降低手动标注成本。随后，应用对比学习来训练模型，使其在表示空间中拉近忠实响应，推远不忠实响应。

Result: 在知识冲突评估基准ECARE KRE和COSE KRE上的实验结果显示，基于Llama3 8B Instruct的SI FACT模型相较于最佳基线方法，上下文召回率（Contextual Recall Rate）提高了6.2%，同时显著降低了对内部记忆的依赖性。

Conclusion: SI FACT在增强LLM的上下文忠实性方面展现出强大的有效性和高数据效率，为构建更主动和更值得信赖的语言模型提供了一条实用的途径。

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [47] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: 本文提出DERN框架，通过专家修剪和神经元重组，在不重新训练的情况下，显著降低SMoE大型语言模型的内存占用并提升性能，使其更易于部署。


<details>
  <summary>Details</summary>
Motivation: 尽管稀疏门控，SMoE大模型仍需加载所有专家参数，导致内存占用高和部署困难。现有方法主要关注专家层面，忽略了神经元层面的结构和语义冲突。

Method: DERN (Dropping Experts, Recombining Neurons) 是一种与任务无关、无需再训练的框架。它分三步进行：1) 使用路由器统计数据修剪冗余专家；2) 将其分解为神经元级别的专家片段，并分配给最兼容的保留专家；3) 合并保留专家内的片段以构建紧凑表示。

Result: 在Mixtral、Qwen和DeepSeek SMoE模型上，DERN在50%专家稀疏度下，将常识推理和MMLU基准测试的性能提高了5%以上，且无需额外训练。它还大幅减少了专家数量和内存使用。

Conclusion: DERN通过神经元级别的专家修剪和重构，有效解决了SMoE大模型的内存高占用和部署难题，并在不牺牲性能的情况下实现了显著的资源优化。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [48] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: 上下文学习（ICL）是有效的学习范式，但在泛化能力上存在局限，主要依赖提示词中的规律进行推导，而非鲁棒的学习机制。


<details>
  <summary>Details</summary>
Motivation: 质疑上下文学习（ICL）是否构成真正的学习或仅仅是推导，并希望通过实证研究全面刻画其能力，特别是其学习和泛化到未见任务的能力。

Method: 对ICL进行了大规模实证分析，考察了记忆、预训练、分布偏移以及提示风格和措辞等因素的影响。

Result: ICL是一种有效的学习范式，但在学习和泛化到未见任务方面存在局限。当示例数量增多时，准确性对示例分布、模型、提示风格和输入语言特征不敏感；然而，ICL主要通过从提示词中的规律推导模式，导致对分布的敏感性，尤其是在思维链等提示风格中表现明显。

Conclusion: 自回归模型的即兴编码（ad-hoc encoding）机制不具备鲁棒性，表明其通用泛化能力有限。

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [49] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: 本研究旨在解决Transformer模型在自动作文评分中处理长文本时的长度限制问题，通过评估多种架构改进模型来避免因截断导致评分有效性降低。


<details>
  <summary>Details</summary>
Motivation: Transformer模型有固定文本处理长度限制，导致在自动作文评分中处理高年级学生的长作文时常需截断。这种截断会损害模型评估作文组织结构等需要长上下文的要素，从而降低评分的有效性，本研究旨在克服此问题。

Method: 使用Kaggle ASAP 2.0数据集，评估了包括XLNet、Longformer、ModernBERT、Mamba和Llama等多种对标准Transformer架构进行修改以克服长度限制的模型。

Result: 抽象内容未提供具体研究结果。

Conclusion: 抽象内容未提供研究结论，仅阐述了研究的目的和方法。

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [50] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 本文提出了一种云边协同的多智能体LLM架构，旨在优化LLM的推理和问题解决能力。该架构包含GuideLLM（边缘）、SolverLLM（云端）和JudgeLLM，并引入了多领域编程基准RefactorCoderQA进行评估。实验证明，微调后的RefactorCoder-MoE模型取得了SOTA性能，并获得了人类验证的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了优化大型语言模型（LLM）的推理和问题解决能力，并解决现有基准在多领域编程任务上的局限性。

Method: 1. 提出一种云边协同的多智能体提示框架，包含：边缘部署的轻量级GuideLLM提供方法指导；云端强大的SolverLLM生成代码解决方案；以及自动评估器JudgeLLM评估解决方案。2. 引入RefactorCoderQA基准，涵盖软件工程、数据科学、机器学习和自然语言处理等多个技术领域，使用Stack Overflow的真实编码挑战。3. 针对该架构微调了RefactorCoder-MoE模型。4. 通过广泛实验、人工评估和系统级指标（吞吐量、延迟）评估了该架构和模型的有效性。

Result: 1. 微调后的RefactorCoder-MoE模型在RefactorCoderQA基准上取得了最先进的性能（76.84%的总准确率），显著优于领先的开源和商业基线。2. 人工评估进一步验证了所生成解决方案的可解释性、准确性和实际相关性。3. 系统级指标评估提供了对所提出架构性能特性和权衡的深入洞察。

Conclusion: 云边协同的多智能体LLM架构结合RefactorCoder-MoE模型，显著提升了LLM在多领域编码任务中的问题解决能力，并通过新的基准测试和人工评估验证了其SOTA性能和实际价值。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [51] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive通过自动生成复杂问题和应用多轮强化学习，显著提升了开源大型语言模型（LLM）的深度搜索能力，并在BrowseComp等基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源LLM在结合浏览工具进行深度搜索时表现不佳，主要原因是长程推理能力有限以及缺乏足够困难的监督数据来训练。这限制了它们解决复杂现实世界任务的潜力。

Method: 1. 提出一种从开放知识图谱中自动合成复杂、困难且难以寻找问题的策略，以解决数据不足的问题。2. 应用端到端多轮强化学习（RL）来增强LLM在使用浏览工具进行深度搜索时的长程推理能力。

Result: DeepDive-32B在BrowseComp上取得了新的开源竞争性结果，超越了WebSailor、DeepSeek-R1-Browse和Search-o1。实验表明，多轮强化学习训练显著提高了深度搜索能力，并在多个基准测试中带来了显著的性能提升。此外，DeepDive还支持测试时工具调用和并行采样的扩展。

Conclusion: DeepDive通过其独特的问题合成策略和多轮强化学习方法，成功解决了开源LLM在深度搜索任务中面临的挑战，显著提高了其长程推理能力和整体性能。

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [52] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE是一种深度监督的纯文本域适应方法，通过训练VAE和微调解码器，显著提升预训练ASR模型在域外场景下的性能，且不增加推断成本。


<details>
  <summary>Details</summary>
Motivation: 预训练ASR模型需域适应以处理未见词汇，但语音数据收集困难，故需纯文本域适应。

Method: 提出WhisTLE，训练VAE从文本建模编码器输出，并使用文本到潜在编码器微调解码器，可结合TTS适应；推断时恢复原始编码器，无额外成本。

Result: 结合TTS的WhisTLE在四个域外数据集和四个ASR模型上，相对TTS-only适应降低WER 12.3%；在32个场景中的27个中优于所有非WhisTLE基线。

Conclusion: WhisTLE是有效的纯文本域适应方法，显著改善了预训练ASR模型在域外数据集上的性能，且推断无额外开销。

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [53] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: 本文介绍了澳大利亚超市物体集（ASOS），一个包含50种超市商品的高质量3D纹理网格数据集，旨在为机器人和计算机视觉应用提供基准。


<details>
  <summary>Details</summary>
Motivation: 现有数据集依赖合成模型或不易获取的专用物体，限制了其在机器人和计算机视觉基准测试中的实际应用和可访问性。

Method: 通过结构-运动（structure-from-motion）技术和高分辨率成像，获取了50种来自澳大利亚超市的常见家居物品的3D网格，生成了水密网格，并覆盖10个不同类别。

Result: 创建了ASOS数据集，包含50个可轻易获得的超市商品，具有高质量3D纹理网格，涵盖形状、尺寸和重量多样性，成本效益高，且易于获取，适用于现实世界应用。

Conclusion: ASOS数据集因其可访问性和真实世界适用性，在物体检测、姿态估计和机器人应用基准测试中具有重要价值。

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [54] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 本文提出一种多模态检索增强生成（MM-RAG）框架，用于灾后房屋损坏评估，通过结合图像和文本信息，显著提升了检索准确性和损害严重性分类性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后，准确评估房屋损坏对保险理赔和资源规划至关重要。

Method: 引入MM-RAG框架，包含双分支多模态编码器（图像分支使用ResNet+Transformer，文本分支使用BERT）、跨模态交互模块（多头注意力）实现语义对齐、以及生成模块中的模态注意力门控机制。采用端到端训练和多任务优化目标（对比损失、检索损失、生成损失），以实现图像理解和策略匹配的协同学习。

Result: 在损害严重性检索准确性和分类指标上表现优越，Top-1检索准确率提升了9.6%。

Conclusion: 所提出的MM-RAG框架能有效整合图像和文本信息进行灾后房屋损坏评估，并在检索准确性和损害严重性分类方面取得显著提升。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [55] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出一个新颖的集成框架，通过图像增强和自定义对齐器稳定LLM在嘈杂历史文档上的文本提取，准确率提高4个百分点。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的文本提取在处理嘈杂历史文档时稳定性不足的问题。

Method: 开发了一个集成框架，利用Gemini 2.0 Flash转录图像的多个增强变体，并用自定义的Needleman-Wunsch风格对齐器融合输出，生成共识转录和置信度分数。引入了包含622份宾夕法尼亚州死亡记录的新数据集。

Result: 方法相对于单一基线将转录准确率提高了4个百分点。发现填充和模糊对提高准确率最有效，而网格扭曲扰动最适合区分高低置信度案例。

Conclusion: 该方法简单、可扩展，并可立即部署到其他文档集合和转录模型，有效提升了嘈杂历史文档文本提取的稳定性与准确性。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [56] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文引入了MITS，首个大规模智能交通监控（ITS）多模态基准数据集，旨在弥补通用大型多模态模型（LMMs）在ITS领域性能受限的问题，实验证明其能显著提升LMMs的ITS应用性能。


<details>
  <summary>Details</summary>
Motivation: 通用大型多模态模型（LMMs）在图像-文本任务中取得了显著进展，但在智能交通监控（ITS）领域的表现受限于缺乏专用多模态数据集。

Method: 研究者构建了MITS（多模态智能交通监控）数据集，包含170,400张真实ITS图像，标注了8大类24小类ITS特定对象和事件。通过数据生成流程，还生成了高质量图像描述和500万个视觉问答对，覆盖对象识别、计数、定位、背景分析和事件推理等五项关键ITS任务。为验证MITS的有效性，研究者在此数据集上微调了主流LMMs。

Result: 实验结果显示，MITS显著提升了LMMs在ITS应用中的性能，例如将LLaVA-1.5的性能从0.494提升至0.905（+83.2%），LLaVA-1.6从0.678提升至0.921（+35.8%），Qwen2-VL从0.584提升至0.926（+58.6%），Qwen2.5-VL从0.732提升至0.930（+27.0%）。

Conclusion: MITS作为首个大规模智能交通监控多模态基准数据集，成功弥补了LMMs在ITS领域的数据空白，显著提升了现有LMMs在该领域的应用性能，并作为开源资源为ITS和LMM研究提供了高价值支持。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [57] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 研究发现，尽管视觉语言模型（VLMs）能理解树知识，但基于树的结构化推理在细粒度视觉分类任务中表现不如标准零样本提示，不过增加图像描述能提升两者性能，凸显了结构化推理的局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在零样本视觉分类方面表现优秀，但它们在细粒度任务和大型分层标签空间中的性能尚未得到充分研究。本文旨在探讨结构化、基于树的推理是否能增强VLM的性能。

Method: 引入了一个框架，该框架使用决策树将分类分解为可解释的决策。该框架在细粒度数据集（GTSRB）和粗粒度数据集（CIFAR-10）上进行了评估。此外，还探索了使用大型语言模型（LLM）生成的类别和图像描述来增强树提示，以改善对齐。

Result: 模型在理解树知识方面达到了98.2%的准确率，但基于树的推理性能持续低于标准零样本提示。然而，通过添加图像描述，基于树和零样本方法的性能均得到了提升。

Conclusion: 研究结果揭示了结构化推理在视觉分类中的局限性，并为设计更可解释的VLM系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [58] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一个用于学习高度可控、灵活可提示世界模型的系统，通过“概率预测、结构提取、结构整合”三步循环不断增强能力，能从视频数据中提取SOTA结构并提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够从数据中学习，并具备丰富可控性和灵活可提示性的世界模型。

Method: 核心是一个三步循环：1) 概率预测，构建随机访问自回归序列模型Psi；2) 结构提取，通过因果推理从Psi中零样本提取低维中间结构；3) 整合，将结构转化为新token类型，作为条件信号和预测目标反馈到训练中。在1.4万亿token的互联网视频数据上训练了PSI实例。

Result: 能够执行多种视频预测和理解推理。提取出SOTA的光流、自监督深度和对象分割。通过结构整合支持了预测能力的完整循环改进，并增强了Psi建模数据和创建新控制句柄的能力。

Conclusion: PSI系统通过其独特的三步循环，成功实现了从数据中学习高度可控和灵活可提示的世界模型，能有效提取和利用数据中的中间结构，并持续提升预测与理解能力，提供类似LLM的通用提示语言控制。

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [59] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据面临的梯度反演攻击泄露风险，发现即使使用特征提取器，如果分类器不够复杂，数据泄露仍可能发生，且超分辨率技术可增强反演质量，证实视频数据泄露是一个可行的威胁。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）旨在保护隐私，但梯度反演攻击可从共享梯度中重构私有训练数据，威胁其核心机制。此前研究已知其对图像、文本和表格数据的影响，但对视频数据的影响尚未被探讨，构成研究空白。

Method: 本研究通过梯度反演攻击，对联邦学习中的视频数据泄露进行了首次分析。评估了两种常见的视频分类方法：一是使用预训练特征提取器，二是直接处理原始视频帧。此外，还引入图像超分辨率技术来增强反演出的视频帧质量。实验验证了攻击者在拥有零、一或更多目标环境参考帧时的场景。

Result: 初步结果表明，使用特征提取器能提供更强的对抗梯度反演攻击的韧性。然而，图像超分辨率技术可以显著提高通过梯度反演攻击提取的帧质量，使攻击者能够重建更高质量的视频。实验还发现，即使使用特征提取器，如果分类器缺乏足够的复杂性，数据泄露仍然可能发生。

Conclusion: 联邦学习中的视频数据泄露是一个可行的威胁。尽管特征提取器使攻击更具挑战性，但数据泄露仍然可能发生，尤其当分类器复杂度不足时。发生泄露的具体条件值得进一步深入研究。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [60] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 本研究提出一种半监督协同训练框架，结合Faster R-CNN和YOLO进行密集零售环境中的目标检测，并使用集成学习增强分类，通过元启发式算法优化，以减少标注依赖并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 在密集零售环境中，有限的标注数据和复杂条件（如遮挡和重叠）对目标检测构成重大挑战，且手动标注成本高，难以适应频繁变化。

Method: 框架采用Faster R-CNN（ResNet）和YOLO（Darknet）进行协同训练，通过伪标签互换提高检测精度；利用XGBoost、Random Forest和SVM集成学习增强分类鲁棒性；并通过元启发式算法优化超参数。

Result: 在SKU-110k数据集上表现出强大的性能，显著降低了手动标注依赖和成本，并能有效适应零售环境的产品和布局变化。

Conclusion: 所提出的框架具有可扩展性和实用性，适用于自动化库存追踪、产品监控和结账系统等实际零售应用。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [61] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出Token Purging (PG)，一种用于3D点云分类的无反向传播、token级测试时自适应（TTA）方法。通过移除受领域偏移影响的tokens，PG在准确性、速度和内存效率上均显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 在3D点云分类中，领域分布偏移会导致模型性能下降，因此测试时自适应（TTA）对于缓解这一问题至关重要。

Method: 引入Token Purging (PG)，一种新颖的无反向传播方法，其核心是在注意力层之前移除受领域偏移严重影响的tokens。PG在token层面操作，无需迭代更新。该方法有两个变体：PG-SP（利用源统计信息）和PG-SF（完全源无关，依赖于CLS-token驱动的自适应）。

Result: 在ModelNet40-C等基准测试中，PG-SP比现有最先进的无反向传播方法平均高出10.3%的准确率；PG-SF为源无关自适应设定了新基准。此外，PG比基线方法快12.4倍，内存效率高5.5倍。

Conclusion: Token Purging是一种高效且实用的3D点云TTA方案，通过创新的token级处理，显著提升了分类准确性、运行速度和内存效率，非常适用于真实世界部署。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [62] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出一种精确且高度可解释的跨视图定位方法，通过匹配地面图像局部特征与航空图像来估计地面图像的3自由度姿态。


<details>
  <summary>Details</summary>
Motivation: 现有方法将地面图像转换到鸟瞰视图（BEV）时，常因透视畸变或高度信息压缩导致信息丢失，从而降低对齐质量。

Method: 直接建立地面与航空图像间的对应关系，利用单目深度先验将匹配关键点提升至BEV空间。该方法支持度量深度和相对深度，并采用尺度感知Procrustes对齐来估计相机姿态。

Result: 在弱监督下，该方法学习到准确的局部特征对应关系，并在跨区域泛化和未知方向等挑战条件下实现卓越的定位性能。它兼容多种相对深度模型，无需逐模型微调。

Conclusion: 该方法在复杂环境下展现出强大的定位能力和灵活性，非常适合实际部署。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [63] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 开发了一款名为KidsVisionCheck的免费移动应用，利用深度神经网络分析儿童红眼反射图像进行视力筛查，在无需专业设备的情况下达到了90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的Bruckner视力检测需由眼科医生在临床环境中进行，而儿童的许多视觉障碍可通过红眼反射图像检测。研究旨在利用智能手机和人工智能技术，实现可及的儿童视力筛查和早期干预。

Method: 开发了KidsVisionCheck移动应用，通过分析儿童的红眼反射图像进行视力筛查。其底层模型基于深度神经网络，并使用由眼科医生收集和标注的儿童瞳孔图像进行训练。

Result: 该模型在未见过的测试数据上取得了90%的准确率，提供了高度可靠的性能，且无需专业设备。此外，研究还确定了最佳数据采集条件，可为用户提供即时反馈。

Conclusion: 这项工作标志着在全球范围内实现可及的儿童视力筛查和视觉异常早期干预迈出了第一步。

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [64] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: DGFusion提出了一种深度引导的多模态融合方法，通过利用激光雷达学习深度信息，动态调整传感器融合策略，实现了自动驾驶中语义感知的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要鲁棒的语义感知，但现有方法在恶劣条件下因对传感器数据统一处理而性能受限。传感器的可靠性随空间（特别是深度）变化，需要更精细的融合策略。

Method: DGFusion将多模态分割视为多任务问题，利用激光雷达作为输入和深度学习的真值。通过辅助深度头学习深度感知特征，并将其编码为空间变化的局部深度令牌，结合全局条件令牌，动态调节跨模态融合。此外，提出了一种鲁棒的深度损失函数以处理稀疏和噪声的激光雷达数据。

Result: DGFusion在MUSES和DELIVER等挑战性数据集上，在全景和语义分割任务上均取得了最先进（SOTA）的性能。

Conclusion: 该研究成功地通过深度引导的多模态融合，解决了自动驾驶在复杂条件下语义感知鲁棒性不足的问题，显著提升了分割性能。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [65] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 该论文提出基于ResNet-18深度学习模型的补丁式酒渣鼻自动检测策略，通过关注局部区域，在提高诊断准确性、模型可解释性和患者隐私保护方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种慢性炎症性皮肤病，其精确和早期检测对于显著提高治疗效果至关重要。

Method: 使用ResNet-18深度学习框架，提出新的基于补丁的酒渣鼻自动检测策略。该方法从面部图像中提取不同大小、形状和位置的图像补丁，并通过调查研究评估局部视觉信息对深度学习模型性能的影响。

Result: 所提出的基于补丁的检测策略在准确性和灵敏度上优于或媲美基于全图像的方法；实验结果表明这些策略能引导深度学习模型关注临床相关区域，增强鲁棒性和可解释性；同时，通过排除可识别的面部特征，有效保护了患者隐私。

Conclusion: 所提出的基于补丁的策略为改进自动化皮肤病诊断提供了实用的见解。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [66] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 一种基于临床先验知识和合成数据训练的隐私保护红斑痤疮自动检测方法，通过面部红度掩码和ResNet-18模型，在真实数据上表现优异，适用于隐私敏感应用。


<details>
  <summary>Details</summary>
Motivation: 红斑痤疮作为常见的炎症性皮肤病，诊断不足。其自动化检测面临症状弥漫性、标注数据集稀缺和面部图像隐私泄露等挑战。

Method: 该方法受临床先验启发并完全在合成数据上训练。首先，利用红斑痤疮主要表现为面部中央红斑的特点，构建一个固定的、基于红度信息的掩码，聚焦于诊断相关区域（如脸颊、鼻子、额头）并排除身份识别特征。其次，使用在经过掩码处理的合成图像上训练的ResNet-18深度学习模型进行检测。

Result: 在使用真实世界测试数据评估时，该方法在准确率、召回率和F1分数方面均显著优于全脸基线方法。

Conclusion: 研究结果表明，结合合成数据和临床先验知识能够构建准确且符合伦理的皮肤病AI系统，尤其适用于远程医疗和大规模筛查等隐私敏感应用。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [67] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 对ULW腹腔镜图像去雾框架进行消融研究，评估其各组件的有效性和必要性。


<details>
  <summary>Details</summary>
Motivation: 严格评估近期提出的ULW腹腔镜图像去雾框架中各独立组件的有效性和必要性。

Method: 进行综合消融研究。具体包括：移除可学习的Wiener滤波器；选择性使用复合损失函数中的单个损失项（MSE、SSIM、感知损失）。所有变体在公开数据集上通过SSIM、PSNR、MSE、CIEDE-2000等定量指标及定性视觉比较进行基准测试。

Result: 摘要描述了研究设计和方法，但未提供具体研究结果。

Conclusion: 摘要描述了研究设计，但未提供最终结论。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [68] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: 本文提出WAVE-DETR，一个结合可见光RGB和声学信号的多模态无人机探测器，在挑战性环境下实现鲁棒的无人机目标检测，通过门控融合机制显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在挑战性环境条件下，需要开发一种鲁棒的真实无人机目标检测方法，以克服单一视觉信号的局限性。

Method: 引入WAVE-DETR，一个融合可见光RGB和声学特征的统一目标检测模型。该模型基于Deformable DETR和Wav2Vec2架构。利用现有Drone-vs-Bird数据集和新生成的ARDrone数据集（包含7500多个同步图像和音频片段进行训练和测试。探索了四种不同的融合配置（门控机制、线性层、MLP和交叉注意力），将Wav2Vec2声学嵌入与Deformable DETR的多分辨率特征映射融合。

Result: 声学信息有效提升了Deformable DETR目标检测器的性能。其中，门控融合方法表现最佳，在自研ARDrone数据集上，对于小型无人机，其mAP提升了11.1%至15.3%。中型和大型无人机的mAP分数也得到提升，所有无人机尺寸的整体增益范围为3.27%至5.84%。

Conclusion: 结合声学信息的多模态融合（特别是门控融合）显著增强了无人机目标检测性能，尤其是在各种无人机尺寸上，证明了其在实际应用中的鲁棒性。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [69] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 提出了一种名为“替代监督”的通用训练范式，显著提高了深度学习可变形图像配准模型对输入图像特征变化的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习图像配准模型虽然准确，但对输入图像的特性变化（如伪影、视野不匹配、模态差异）敏感，限制了其广泛应用。

Method: 引入“替代监督”，通过将估计的空间变换应用于替代图像，解耦输入域和监督域。这允许在异构输入上训练，同时确保监督在相似性定义明确的域中计算。

Result: 在多项任务中（脑MR伪影鲁棒配准、掩膜无关肺CT配准、多模态MR配准），替代监督展现出对输入变化的强大韧性，并保持了在高质量数据上的高性能。

Conclusion: 替代监督提供了一个训练鲁棒且泛化能力强的深度学习配准模型的原则性框架，且不增加模型复杂性，为医学图像配准的广泛应用提供了实用途径。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [70] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 本研究提出一个结合卷积自编码器(AE)和Vision Transformer (ViT)的框架，旨在提高法医牙龄估计（特别是磨牙分期）的性能和模型透明度，并诊断出数据层面的限制因素。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在法医牙龄估计等高风险应用中因其“黑箱”特性而受限。因此，需要一个既能提高性能又能增强透明度的框架来解决这一问题。

Method: 本研究提出一个结合卷积自编码器（AE）和Vision Transformer（ViT）的框架。该框架通过分析AE的潜在空间指标和图像重建来提供诊断性洞察，并以颌骨第二（牙齿37）和第三（牙齿38）磨牙的自动分期作为案例研究。

Result: 与基线ViT相比，该框架将牙齿37的分类准确率从0.712提高到0.815，牙齿38的准确率从0.462提高到0.543。此外，框架提供了多方面的诊断性洞察，通过AE潜在空间分析和图像重建表明，剩余的性能差距主要是数据中心性的，牙齿38数据集中高类内形态变异是主要限制因素。研究还强调了仅依靠单一可解释性方法（如注意力图）的不足。

Conclusion: 该框架通过同时提升准确性并提供模型不确定性原因的证据，成为支持法医牙龄估计专家决策的更强大工具。它通过提供性能提升和数据驱动的诊断洞察，解决了深度学习在法医应用中的黑箱问题。

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [71] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: 针对SFDA中现有方法忽视几何流形信息的缺点，本文提出SCoDA，利用自监督预训练教师模型并结合几何流形对齐和空间相似性损失进行模型适应，显著超越了当前SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的SFDA方法在通过实例级特征对齐进行知识蒸馏时，主要依赖L2归一化特征向量上的余弦相似度，这会丢弃源模型潜在流形的关键几何信息。此外，这些方法通常依赖于全监督预训练。

Method: 本文提出自监督持续域适应（SCoDA）框架。该框架首先使用通过自监督学习（SSL）预训练的教师模型进行初始化，避免了对监督预训练的依赖。其次，将几何流形对齐原则引入SFDA设置。学生模型通过结合实例级特征匹配和空间相似性损失的复合目标进行训练。为防止灾难性遗忘，教师模型的参数通过学生模型参数的指数移动平均（EMA）进行更新。

Result: 在基准数据集上进行的广泛实验表明，SCoDA显著优于现有的最先进的SFDA方法。

Conclusion: SCoDA通过引入自监督预训练和几何流形对齐，有效克服了SFDA中现有方法对几何信息丢失和监督预训练的依赖，实现了优越的域适应性能。

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [72] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 本文提出一种零样本细胞追踪框架，通过集成大型基础模型Segment Anything 2 (SAM2)到追踪流程中，实现了无需微调即可在多样的显微镜数据上进行通用且高精度的细胞追踪和有丝分裂事件检测。


<details>
  <summary>Details</summary>
Motivation: 细胞追踪和有丝分裂事件检测在生物医学研究中非常关键，但由于细胞分裂、低信噪比、模糊边界、密集簇和细胞外观相似等因素，仍具挑战性。现有深度学习方法依赖昂贵耗时的人工标注数据集进行训练，且泛化能力受限于显微镜数据的多样性。

Method: 我们提出了一种零样本细胞追踪框架，将专为通用图像和视频分割设计的大型基础模型Segment Anything 2 (SAM2)集成到追踪流程中。作为一个完全无监督的方法，它不依赖于任何特定的训练数据集，也未继承其偏见，从而无需微调即可泛化到不同的显微镜数据集。

Result: 我们的方法在2D和大规模3D延时显微镜视频中均取得了有竞争力的准确性，并且消除了对特定数据集进行适应的需求。

Conclusion: 通过整合SAM2，所提出的零样本无监督细胞追踪框架成功克服了现有方法对手动标注的依赖和泛化性不足的限制，在多样化的显微镜数据上实现了高性能，且无需数据集特定的适配。

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [73] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 该论文提出了一种将现有2D多目标多摄像头跟踪（MTMC）系统扩展到3D空间的方法，通过利用深度信息重建3D目标并改进数据关联机制，在2025 AI City Challenge中获得第三名。


<details>
  <summary>Details</summary>
Motivation: 多目标多摄像头跟踪（MTMC）对于大规模监控至关重要。虽然3D空间跟踪能提供无与伦比的3D环境感知能力，但将现有2D跟踪系统完全替换为3D组件可能不切实际。因此，需要一种将现有2D MTMC系统扩展到3D空间的方法。

Method: 本方法通过以下方式将任何在线2D多摄像头跟踪系统扩展到3D空间：1. 利用深度信息在点云空间中重建目标。2. 通过聚类和偏航角（yaw）细化恢复其3D边界框。3. 引入增强的在线数据关联机制，利用目标的局部ID一致性在帧间分配全局ID。

Result: 该框架在2025 AI City Challenge的3D MTMC数据集上进行了评估，并获得了排行榜第三名的成绩。

Conclusion: 本研究成功提出了一种将任何在线2D多摄像头跟踪系统扩展到3D空间的方法，通过结合深度信息进行3D目标重建和改进数据关联，实现了高水平的3D跟踪性能。

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [74] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 本文提出一种零样本指代表达理解(REC)方法，将REC重构为逐框视觉-语言验证，无需任务特定训练，在RefCOCO系列数据集上性能超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 传统的指代表达理解(REC)通常依赖于任务训练的接地模型。本文旨在证明，无需任何REC特定训练的零样本工作流程也能实现具有竞争力或更优的性能。

Method: 将REC重新表述为逐框视觉-语言验证任务。该方法首先使用通用的COCO-clean检测器(YOLO-World)生成候选框，然后通用的视觉-语言模型(VLM)独立地对每个区域进行真/假查询。这种流程减少了框间干扰，支持弃权和多重匹配，并且无需微调。

Result: 在RefCOCO、RefCOCO+和RefCOCOg数据集上，该方法不仅超越了零样本GroundingDINO基线，而且超过了经过REC训练的GroundingDINO以及GroundingDINO+CRG的报告结果。受控研究证实，验证方法显著优于基于选择的提示方法，并且在开放VLM上同样有效。

Conclusion: 强大的零样本REC性能主要由工作流程设计驱动，而非任务特定的预训练。

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [75] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 本文提出随机投影复制粘贴（RPCP）数据增强技术，以解决小麦叶部病虫害分割中虫害像素极度不平衡问题，显著提升了虫害分割性能。


<details>
  <summary>Details</summary>
Motivation: 小麦叶部病害和虫害的准确分割对作物管理至关重要。然而，虫害区域通常只占极少比例的像素，导致极度像素级不平衡，这会使分割模型过拟合常见类别，对稀有类别学习不足，从而损害整体性能。

Method: 提出随机投影复制粘贴（RPCP）数据增强技术。具体步骤为：从标注训练图像中提取稀有虫害斑块并进行随机几何变换模拟变异；将变换后的斑块粘贴到适当区域，同时避免与病变或现有受损区域重叠；对粘贴区域应用随机投影滤波器，以细化局部特征并确保与新背景自然融合。

Result: 实验结果显示，该方法显著提高了虫害类别的分割性能，同时保持甚至略微提升了其他类别的准确性。

Conclusion: 研究结果强调了有针对性的数据增强在缓解极端像素不平衡方面的有效性，为农业分割问题提供了一个简单而有效的解决方案。

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [76] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 针对长期多目标跟踪中现有方法因ID切换导致的性能下降问题，本文提出了一种基于隐马尔可夫模型（HMM）的新框架，能够整合不确定的零星身份信息，显著提升了跟踪性能，并在实际应用和基准数据集中得到验证。


<details>
  <summary>Details</summary>
Motivation: 由于物体ID切换，现有长期多目标跟踪（MOT）方法性能随时间下降，难以应用于需要分析个体长期行为的场景。然而，在许多实际应用中（如畜牧业），可以获得零星且不确定的个体身份识别信息。

Method: 提出了一个新框架，利用隐马尔可夫模型（HMM）公式，将不确定的身份信息与跟踪过程相结合。

Result: 1. 在一个10分钟的猪跟踪数据集上，结合21个喂食站的识别信息，显著提高了领先MOT方法ByteTrack的F1分数，并能提供真实的动物ID。2. 该方法对识别的不确定性具有鲁棒性，且性能随身份信息提供频率的增加而提升。3. 在MOT17和MOT20基准数据集上，使用ByteTrack和FairMOT也验证了其性能提升。

Conclusion: 所提出的基于HMM的框架通过有效整合不确定的身份信息，成功解决了长期多目标跟踪中的ID切换挑战，显著提高了跟踪性能，并在实际应用和基准测试中展现出鲁棒性和有效性。

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [77] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 本综述探讨了事件相机与传统帧相机的融合，重点关注其在深度学习驱动的视频修复、增强和3D重建中的应用，并汇总了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其低延迟、低功耗和超高捕获率而迅速发展。将事件流与传统帧捕获融合，能显著提升视频修复和3D重建任务的效果。本综述旨在整合这一新兴领域的最新进展。

Method: 本文采用综述形式，系统回顾了深度学习在图像/视频增强与修复（包括时间增强如帧插值、运动去模糊，以及空间增强如超分辨率、低光照/HDR增强）和3D重建方面的主要贡献。同时，汇编了可用的公开数据集。

Result: 综述展示了事件-帧融合如何显著促进各类视频修复和3D重建任务，详细讨论了在挑战性条件下改善视觉质量的最新工作，并提供了可用于可重现研究和基准测试的全面公开数据集列表。

Conclusion: 通过整合最新进展和见解，本综述旨在激发进一步研究，以利用事件相机系统（特别是结合深度学习）进行先进的视觉媒体修复和增强。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [78] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: 本文提出ISTASTrack，首个基于Transformer的ANN-SNN混合跟踪器，通过独特的ISTA适配器实现RGB-Event跟踪，解决了异构范式特征融合的挑战，达到了最先进的性能和高能效。


<details>
  <summary>Details</summary>
Motivation: RGB-Event跟踪具有前景，但现有ANN难以充分利用事件流的稀疏异步特性。ANN-SNN混合架构虽有潜力，但有效融合异构范式特征仍是挑战。

Method: 提出ISTASTrack，一个基于Transformer的ANN-SNN混合跟踪器。模型包含两个分支：视觉Transformer用于RGB图像，脉冲Transformer用于事件流。核心创新是设计了一个基于稀疏表示理论（通过展开迭代收缩阈值算法）的模型化ISTA适配器，用于ANN和SNN特征间的双向交互。此外，适配器内融入了时间下采样注意力模块，以对齐多步SNN特征与单步ANN特征。

Result: ISTASTrack在FE240hz、VisEvent、COESOT和FELT等RGB-Event跟踪基准测试中均取得了最先进的性能，并保持了高能效。

Conclusion: 研究结果证明了混合ANN-SNN设计在鲁棒视觉跟踪中的有效性和实用性，ISTASTrack为该领域提供了新的SOTA解决方案。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [79] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出基于多深度状态空间模型和FLARE损失的新方法，解决太阳耀斑预测中的类别不平衡问题，提升预测性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有太阳耀斑预测性能不足，无法有效应对对关键基础设施的潜在影响，且未能充分解决耀斑类别间的严重不平衡问题。

Method: 构建基于多个深度状态空间模型的太阳耀斑预测模型，并引入频率与局部边界感知可靠性损失（FLARE损失）以提高类别不平衡下的预测性能和可靠性。

Result: 在涵盖11年太阳活动周期的多波长太阳图像数据集上，本方法在Gandin-Murphy-Gerrity分数和真实技能统计量（标准性能和可靠性指标）方面均优于基线方法。

Conclusion: 本研究通过创新的模型和损失函数，有效克服了太阳耀斑预测中的类别不平衡挑战，显著提升了预测的准确性和可靠性。

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [80] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一个高效的RGB-T语义分割模型，通过统一的RGB-T编码器和RGB-T局部模块，实现了多模态特征提取和融合，显著降低了参数和计算成本，同时保持了SOTA性能并具备实时推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T语义分割模型存在热特征提取受限、跨模态融合不佳、编码器冗余导致实时效率低等问题。

Method: 提出TUNI模型，核心是一个RGB-T编码器，通过堆叠模块同时进行多模态特征提取和跨模态融合。利用RGB和伪热数据进行大规模预训练，并精简热分支以实现更紧凑的架构。此外，引入RGB-T局部模块，利用自适应余弦相似度增强跨模态局部特征融合能力。

Result: TUNI在FMB、PST900和CART数据集上取得了与现有SOTA模型相当的性能，且参数量更少，计算成本更低。在Jetson Orin NX上实现了27 FPS的推理速度，展现了实时部署能力。

Conclusion: TUNI有效解决了现有RGB-T语义分割模型的效率和性能问题，提供了一个紧凑、高效且具备实时能力的解决方案，显著提升了自动驾驶平台在挑战性环境下的环境感知能力。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [81] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 本文提出一种新颖的“少部分样本”字体生成模型，仅基于部分形状即可设计完整字体，显著提升了字体创建效率。


<details>
  <summary>Details</summary>
Motivation: 传统的少样本字体生成方法需要完整的字符形状作为输入，限制了效率。本文旨在通过仅提供部分形状来生成字体，以提高效率并探究局部设计对整体结构的影响。

Method: 提出了一种新颖的“少部分样本字体生成”模型，该模型能够依据一组部分设计元素（即部分形状）来设计整个字体。

Result: 与传统的需要完整字符形状的少样本字体生成方法不同，本模型仅需部分形状作为输入，有效提升了字体创建的效率。

Conclusion: 所提出的模型不仅提高了字体创建的效率，还为理解部分设计细节如何影响单个字符的整体结构提供了深刻见解。

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [82] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 针对微型和纳米无人机，本文提出并实现了一种高效、精确的视觉惯性里程计（VIO）管线，该管线在低功耗RISC-V SoC上进行了优化和量化，显著提升了精度和实时性。


<details>
  <summary>Details</summary>
Motivation: 高精度视觉惯性里程计（VIO）通常需要强大的计算系统，不适用于计算能力受限的微型和纳米无人机应用。因此，需要一种在这些资源受限平台上也能实现高效率和高精度的VIO解决方案。

Method: 本文提出一种VIO管线，集成了SuperPoint、PX4FLOW和ORB等先进特征检测与跟踪方法，并针对新兴的基于RISC-V的超低功耗并行系统芯片（SoC）进行了优化和量化。该管线还通过采用刚体运动模型来减少估计误差，并在平面运动场景中提高精度。系统在超低功耗SoC（如GAP9）上进行实现和评估，以验证其计算需求和量化后的跟踪精度。

Result: 在GAP9低功耗SoC上，使用ORB特征跟踪器时，优化后的管线与基线管线相比，RMSE平均降低高达3.65倍。对特征跟踪器计算复杂度的分析表明，在低于24像素/帧的运动速度下，PX4FLOW能在较低运行时实现与ORB相当的跟踪精度。

Conclusion: 该设计成功地弥合了传统上运行在计算强大系统上的高精度VIO与适用于微控制器的轻量级实现之间的差距，为微型和纳米无人机提供了高效且高精度的VIO解决方案。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [83] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出一种基于CNN的分层多级注意力网络（MLANet），用于从单张野生图像重建3D人脸模型，采用半监督训练策略以解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 从2D野生图像恢复3D人脸模型面临缺乏真实标签数据集和真实世界环境复杂性的挑战。

Method: 提出分层多级注意力网络（MLANet），一个基于卷积神经网络的方法。它利用预训练的分层骨干网络，并在2D人脸图像特征提取的不同阶段引入多级注意力机制。采用半监督训练策略，结合了来自公共数据集的3DMM参数和可微分渲染器，实现端到端训练，预测人脸几何、纹理、姿态和光照参数。

Result: 在AFLW2000-3D和MICC Florence两个基准数据集上进行了广泛的比较和消融实验，专注于3D人脸重建和3D人脸对齐任务。通过定量和定性评估，验证了所提方法的有效性。

Conclusion: MLANet通过多级注意力机制和半监督训练，有效解决了从单张野生图像中恢复3D人脸模型时面临的数据稀缺和环境复杂性挑战，展现出良好效果。

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [84] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: 本文提出LaV-CoT，一个语言感知视觉链式思考框架，通过多方面奖励优化，显著提升了大型视觉语言模型在多语言多模态视觉问答（mVQA）中的推理能力和准确性，并超越了现有开源及专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有mVQA方法主要依赖文本链式思考（CoT），对多语言多模态推理支持有限，限制了其在实际应用中的部署。亟需一个能整合视觉信息并支持多语言的CoT推理框架。

Method: 引入了LaV-CoT框架，包含可解释的多阶段推理流程：带边界框的文本摘要、语言识别、空间对象级字幕和分步逻辑推理。设计了迭代生成、校正和完善的自动化数据整理方法，生成高质量多语言CoT注释。采用两阶段训练范式：监督微调（SFT）结合语言感知组相对策略优化（GRPO），通过语言一致性、结构准确性和语义对齐等多方面可验证奖励进行指导。

Result: LaV-CoT在MMMB、Multilingual MMBench和MTVQA等公共数据集上，相比同等规模开源基线，准确率提升高达约9.5%；甚至超越两倍规模的模型约2.6%；并优于GPT-4o-0513和Gemini-2.5-flash等先进专有模型。在线A/B测试进一步验证了其在真实世界数据上的有效性。

Conclusion: LaV-CoT是首个具有多方面奖励优化的语言感知视觉链式思考框架，有效解决了多语言多模态推理的挑战，在性能上实现了显著提升，并展现出在工业部署中的巨大潜力。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [85] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 针对文本到图像生成中复杂颜色词汇的精准着色问题，本文提出了一种无需训练的框架。该框架利用大型语言模型（LLM）消除颜色歧义，并通过在文本嵌入空间中引导颜色混合来提升颜色保真度，且不需额外训练或参考图像。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）生成中准确的颜色对齐对时尚、产品可视化和室内设计等应用至关重要。然而，当前的扩散模型难以处理细致和复合的颜色词汇，导致图像与人类意图不符。现有方法（如交叉注意力操纵、参考图像或微调）未能系统地解决模糊的颜色描述问题。

Method: 本文提出一个无需训练的框架，通过以下步骤增强颜色保真度：首先，利用大型语言模型（LLM）来消除文本提示中与颜色相关的歧义；然后，根据CIELAB颜色空间中解析出的颜色术语的空间关系，直接在文本嵌入空间中指导颜色混合操作，从而细化文本嵌入。此方法无需额外训练或外部参考图像。

Result: 实验结果表明，该框架在不损害图像质量的前提下，显著改善了颜色对齐效果。

Conclusion: 本框架通过提高颜色准确性，弥合了文本语义与视觉生成之间的鸿沟，且无需额外训练或外部参考图像。

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [86] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: 本文引入了AVI-Math，一个用于评估视觉-语言模型（VLMs）在无人机（UAV）图像多模态数学推理能力的新基准。研究发现当前VLMs在此任务上表现不佳，但Chain-of-Thought提示和微调技术显示出改进潜力。


<details>
  <summary>Details</summary>
Motivation: 数学推理对于无人机遥感中的距离、面积计算和轨迹估计等任务至关重要，但当前的视觉-语言模型（VLMs）在此领域尚未得到充分测试，尤其是在几何、逻辑和代数等领域。

Method: 研究引入了AVI-Math基准数据集，包含3,773个高质量无人机视角下的车辆相关问题，涵盖6个数学学科和20个主题。数据采集自不同高度和角度，反映真实无人机场景。论文对14个主流VLMs进行了综合评估，并探讨了Chain-of-Thought提示和微调技术的效果。

Result: 基准测试结果显示，尽管这些VLMs在先前的多模态基准上表现成功，但它们在AVI-Math的推理任务中表现挣扎，暴露了当前VLMs在数学推理能力方面的显著局限性。Chain-of-Thought提示和微调技术在解决AVI-Math的推理挑战方面显示出前景。

Conclusion: 研究不仅揭示了VLMs在数学推理方面的局限性，特别是在无人机遥感领域，而且为未来开发可信赖的无人机视觉-语言模型提供了宝贵的见解和研究方向。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [87] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: 本文提出BEVTraj，一个不依赖预建高清地图，直接利用实时传感器数据在鸟瞰图（BEV）空间进行轨迹预测的新框架，实现了与现有先进模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中轨迹预测至关重要，但现有方法依赖预建高清地图或实时局部地图，存在区域限制、无法适应瞬态变化、可能遗漏关键细节或引入误差等局限性。

Method: 提出Bird's-Eye View Trajectory Prediction (BEVTraj)框架，它直接在BEV空间操作，利用实时传感器数据，不依赖预建地图。BEVTraj利用可变形注意力高效提取BEV特征上下文，并引入稀疏目标候选提案（SGCP）模块实现端到端预测，无需后处理。

Result: BEVTraj在性能上与最先进的基于高清地图的模型相当，同时通过消除对预建地图的依赖，提供了更大的灵活性。

Conclusion: BEVTraj成功克服了传统地图依赖型轨迹预测的局限性，提供了一种高效、灵活且性能卓越的无地图轨迹预测解决方案。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [88] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 本文提出一个利用多视角信息的新训练框架，以显著提高遮挡场景下的多人解析性能。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的多人解析方法在处理身体重叠或遮挡的人物时表现不佳。

Method: 提出一个利用多视角信息的新型训练框架，通过对人体实例的弱监督和多视角一致性损失来改进遮挡下的多人解析模型。同时，为解决数据集不足，提出一种从多视角RGB+D数据和3D人体骨架生成人体实例分割掩码的半自动标注策略。

Result: 在遮挡场景下，相对于基线模型，人体解析性能相对提升高达4.20%。

Conclusion: 该方法有效利用多视角信息显著提升了在遮挡场景下的多人解析模型性能。

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [89] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: 本文介绍了VARCO-VISION-2.0，一个开放权重、韩语和英语双语的视觉-语言模型（VLM），它在多图像理解、布局感知OCR及安全性方面相较前代有显著提升。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个功能更强大、支持韩语和英语的双语VLM，以更好地理解文档、图表等复杂多模态输入，提供布局感知的OCR能力，并提高模型安全性，同时超越前代模型VARCO-VISION-14B的性能。

Method: 模型通过一个四阶段课程和内存高效技术进行训练，以增强多模态对齐，同时保留核心语言能力并通过偏好优化提升安全性。它支持多图像理解，并能通过预测文本内容及其空间位置实现布局感知OCR。

Result: 广泛的基准评估表明，该模型在两种语言上都展现出强大的空间定位能力和竞争力。其中14B模型在OpenCompass VLM排行榜上同等规模模型中取得了第8名。此外，还发布了用于设备部署优化的1.7B轻量级版本。

Conclusion: VARCO-VISION-2.0模型（包括14B和1.7B两个版本）的发布，推动了双语VLM及其在实际应用中的发展。模型已在Hugging Face上提供。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [90] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出一种轻量高效的人脸图像质量评估(FIQA)方法，通过集成小型CNN（MobileNetV3-Small和ShuffleNetV2）和相关性感知损失函数（MSECorrLoss），在保证高准确性的同时降低计算成本，适用于真实世界部署。


<details>
  <summary>Details</summary>
Motivation: 现有FIQA方法在非受控真实环境中，要么未能有效捕捉人脸特有的图像退化，要么计算量过于庞大，限制了其实际应用性。

Method: 所提方法集成两个紧凑型卷积神经网络（MobileNetV3-Small和ShuffleNetV2），通过简单的预测层平均进行融合。为更好地模拟人类感知判断，引入了结合均方误差(MSE)和皮尔逊相关性正则化的相关性感知损失(MSECorrLoss)。

Result: 在VQualA FIQA基准测试中，模型实现了0.9829的Spearman秩相关系数(SRCC)和0.9894的Pearson线性相关系数(PLCC)，同时满足效率约束，有效平衡了准确性和计算成本。

Conclusion: 该方法在准确性和计算成本之间取得了良好平衡，表现出高效性，使其非常适合在实际场景中部署，解决人脸图像质量评估问题。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [91] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出RCOD（Realism Controlled One-step Diffusion）框架，旨在解决单步扩散超分（Real-ISR）方法在保真度和真实感之间难以平衡的问题。RCOD通过潜在域分组、降级感知采样和视觉提示注入，实现了在保持计算效率的同时，对图像超分任务中保真度与真实感的灵活控制，并在性能上超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型在真实世界图像超分任务中表现出潜力，但现有的单步扩散（OSD）方法在提高效率的同时，难以在不同场景下平衡图像保真度与真实感。由于OSD通常通过单一时间步训练，缺乏灵活的控制机制来动态调整这两个相互竞争的目标。

Method: 本文提出了RCOD框架，主要包含：1) 潜在域分组策略，在噪声预测阶段实现对保真度-真实感权衡的显式控制；2) 降级感知采样策略，用于使蒸馏正则化与分组策略对齐，并增强权衡控制；3) 视觉提示注入模块，用降级感知的视觉tokens替代传统文本提示，以提高恢复精度和语义一致性。

Result: RCOD方法在保持计算效率的同时，实现了卓越的保真度和感知质量。实验证明，在定量指标和视觉质量方面，RCOD均优于现有最先进的单步扩散方法，并在推理阶段具有灵活的真实感控制能力。

Conclusion: RCOD框架成功解决了单步扩散超分在平衡图像保真度与真实感方面的挑战，通过其创新的控制机制，提供了在效率和性能之间取得更好平衡的解决方案，并在超分任务中展现出卓越的性能和灵活性。

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [92] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一种新颖的无源域适应框架，通过结合梯度引导伪标签细化和对比学习，显著提升了视盘和视杯在跨域场景下的分割精度和边界描绘。


<details>
  <summary>Details</summary>
Motivation: 视盘和视杯的准确分割对青光眼等眼科疾病的早期诊断和管理至关重要。然而，在不同成像协议或条件下，现有分割模型在目标数据上的性能会显著下降，即存在跨域性能退化问题，这构成了研究动机。

Method: 本文提出Grad-CL，一个新颖的无源域适应框架，它利用预训练的源模型和未标记的目标数据来鲁棒地适应分割性能，且无需访问原始源数据。Grad-CL结合了两个核心策略：1) 梯度引导的伪标签细化模块，通过梯度机制提取显著的类特异性特征，实现更准确的不确定性量化和鲁棒的原型估计，从而细化噪声伪标签；2) 基于余弦相似度的对比学习策略，用于显式增强视杯和视盘的梯度信息特征之间的类间可分离性。

Result: 在具有挑战性的跨域眼底图像数据集上进行的大量实验表明，Grad-CL优于现有的最先进的无监督和无源域适应方法，取得了卓越的分割精度和改进的边界描绘能力。

Conclusion: Grad-CL作为一种有效的无源域适应框架，成功解决了视盘和视杯分割在跨域场景下的性能退化问题，显著提升了分割精度和边界描绘，对早期诊断和管理眼科疾病具有重要意义。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [93] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: 本文提出VQBridge和FVQ（FullVQ）方法，解决了矢量量化（VQ）训练不稳定和码本利用率低的问题，实现了100%码本利用率和最先进的重建性能，显著提升了自回归图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 矢量量化（VQ）作为图像生成离散分词器的关键组件，其训练常因直通估计偏差、一步滞后更新和稀疏码本梯度而导致不稳定，进而造成次优重建性能和低码本利用率。

Method: 本文分析了VQ训练的挑战，并提出了VQBridge，一个基于映射函数方法的鲁棒、可扩展、高效的投影器。VQBridge通过一个“压缩-处理-恢复”的流程优化码向量，实现稳定有效的码本训练。通过将VQBridge与学习退火相结合，作者实现了FVQ（FullVQ），在各种码本配置下都能达到100%的码本利用率。

Result: FVQ在26.2万码本下仍能实现100%的码本利用率，达到了最先进的重建性能，并且随着码本增大、向量通道增加或训练时间延长而持续提升，对不同VQ变体均有效。此外，当与LlamaGen集成时，FVQ显著增强了图像生成性能，在rFID指标上超越了VAR模型0.5和扩散模型（DiT）0.2。

Conclusion: FVQ通过解决VQ训练中的根本挑战，提供了一种高效、可扩展且通用的解决方案，实现了高质量的分词器，这对于强大的自回归图像生成至关重要。

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [94] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过渐进式层冻结实现自监督视觉表示学习的方法，它利用层收敛顺序从像素预测逐步过渡到潜在预测，从而加速MAE训练并避免表示崩溃，在大模型上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现视频MAE模型训练过程中，ViT层按深度顺序收敛（浅层先收敛，深层后收敛）。作者希望利用这一现象来加速标准MAE训练，并开发一种简单、可扩展且能避免“表示崩溃”的潜在预测方法。

Method: 引入LayerLock方法，通过明确的训练进度表，渐进式地冻结模型层。该方法利用层收敛顺序从像素预测逐步过渡到潜在预测。

Result: LayerLock能够加速标准MAE训练。它提供了一种简单且可扩展的潜在预测方法，有效避免了“表示崩溃”问题。将LayerLock应用于高达40亿参数的大型模型，其结果在4DS感知套件上超越了非潜在掩码预测。

Conclusion: LayerLock是一种简单而有效的自监督视觉表示学习方法，通过渐进式层冻结实现了从像素到潜在预测的过渡，不仅加速了MAE训练，还解决了潜在预测中的表示崩溃问题，并在大规模模型上展现出超越现有方法的性能。

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [95] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 首次系统比较了用于太空3D物体重建的隐式与显式新视角合成方法，发现外观嵌入虽能提升光度保真度，但对几何精度无显著益处。研究还指出凸包散列比高斯散列能提供更紧凑的表示，对安全关键型应用有利。


<details>
  <summary>Details</summary>
Motivation: 太空机器人应用对3D物体重建的几何精度有关键要求。本研究旨在系统评估隐式与显式新视角合成方法在太空场景下的性能，并探究外观嵌入在此类任务中的作用及其对几何精度的影响。

Method: 采用SPEED+数据集，系统比较了隐式方法K-Planes和显式方法Gaussian Splatting与Convex Splatting，并评估了外观嵌入在这些方法中的作用。

Result: ['外观嵌入能够通过建模光照变化来提高光度保真度，但对几何精度没有显著提升，而几何精度对太空机器人应用至关重要。', '外观嵌入主要作用是减少显式方法所需的基元数量，而非增强几何保真度。', '凸包散列比高斯散列能够实现更紧凑、更简洁的表示，这对交互和避碰等安全关键型太空应用具有优势。']

Conclusion: 本研究明确了外观嵌入在以几何为中心的任务中的局限性，并揭示了太空场景下三维重建质量与表示效率之间的权衡。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [96] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: 本文提出GAMMA框架，通过引入多样的操作策略和多任务监督，显著提升了AI生成图像检测器在未见过的生成模型（如GPT-4o）上的泛化能力和鲁棒性，解决了现有方法依赖特定生成伪影的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在处理未见过的生成模型时泛化能力有限，主要原因在于它们依赖于生成模型特有的伪影（如风格先验、压缩模式）。本文旨在减少域偏差并增强语义对齐，以提升检测器对多样化生成模型的泛化能力。

Method: 提出GAMMA训练框架，引入了多样化的操作策略，包括基于修复的操作和语义保持扰动，以确保被操作内容与真实内容之间的一致性。采用带有双分割头和分类头的多任务监督，实现跨生成域的像素级源归因。此外，引入了反向交叉注意力机制，使分割头能够指导并纠正分类分支中的偏差表示。

Result: GAMMA在GenImage基准测试中取得了最先进的泛化性能，准确率提高了5.8%。同时，对GPT-4o等新发布的生成模型也保持了强大的鲁棒性。

Conclusion: GAMMA框架通过减少域偏差和增强语义对齐，有效解决了AI生成图像检测器在面对未见过的生成模型时的泛化能力限制，实现了卓越的性能和强大的鲁棒性。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [97] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 本研究比较了NiftyMIC、SVRTK和NeSVoR三种胎儿大脑MRI超分辨率重建(SRR)方法。结果显示NeSVoR在重建成功率上表现最佳，尽管不同SRR方法导致体积估计存在显著差异，但对脑室扩张的诊断分类性能没有影响。


<details>
  <summary>Details</summary>
Motivation: 胎儿大脑MRI的2D切片采集因胎动存在低分辨率、运动伪影问题，未能充分捕捉3D解剖结构。尽管超分辨率重建(SRR)方法旨在解决这些局限性，但现有SRR方法的比较性能，特别是在病理案例中，及其对后续体积分析和诊断任务的影响尚未得到充分探索。

Method: 将NiftyMIC、SVRTK和NeSVoR三种最先进的SRR方法应用于140例胎儿大脑MRI扫描（包括健康对照组和伴有脑室扩张的病理案例）。每项高分辨率重建都使用BoUNTi算法进行分割，以提取九个主要脑结构的体积。评估指标包括视觉质量、SRR成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在健康对照组和病理案例组中均表现出最高且最一致的重建成功率（>90%）。尽管在不同SRR方法之间观察到体积估计存在显著差异，但脑室扩张的诊断分类性能并未受SRR方法选择的影响。

Conclusion: 研究结果突显了NeSVoR方法的鲁棒性，以及诊断性能在SRR导致的体积变异性面前的韧性。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [98] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 本文提出Mask Consistency Regularization (MCR) 训练策略，通过引入掩码扩张和重塑扰动，解决目标移除任务中现存扩散模型面临的掩码幻觉和掩码形状偏置问题，显著提升图像修复质量。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像目标移除任务中面临两大挑战：一是“掩码幻觉”，即生成无关或虚假内容；二是“掩码形状偏置”，即填充内容模仿掩码形状而非周围上下文。

Method: 提出Mask Consistency Regularization (MCR) 训练策略。该方法在训练期间引入掩码扩张和重塑两种扰动，强制这些扰动分支的输出与原始掩码保持一致。扩张掩码旨在使输出与周围内容对齐，重塑掩码则用于打破掩码形状偏置。

Result: 实验证明，MCR显著减少了掩码幻觉和掩码形状偏置，生成了更鲁棒、上下文更连贯的图像修复结果，从而提高了目标移除的性能。

Conclusion: MCR策略有效解决了目标移除中的掩码幻觉和掩码形状偏置问题，通过提升输出的上下文一致性和鲁棒性，改善了图像修复效果。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [99] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: 本文提出MagicMirror框架，包含一个详细的伪影分类体系、一个大型人工标注数据集MagicData340K、一个视觉语言模型评估器MagicAssessor和一个自动化基准MagicBench，用于系统地评估和揭示文本到图像生成模型中的物理伪影问题。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像（T2I）生成取得了显著进展，但仍普遍存在物理伪影（如解剖和结构缺陷），严重降低感知质量并限制应用。现有基准缺乏系统且细粒度的评估框架来处理这些多样而复杂的伪影。

Method: ['建立了生成图像伪影的详细分类法。', '人工标注了首个包含34万张生成图像且带有细粒度伪影标签的大规模数据集MagicData340K。', '基于MagicData340K训练了视觉语言模型MagicAssessor，用于提供详细评估和对应标签。', '设计了新颖的数据采样策略和多级奖励系统，结合Group Relative Policy Optimization (GRPO)以解决类别不平衡和奖励偏差问题。', '利用MagicAssessor构建了自动化基准MagicBench，用于评估当前T2I模型的图像伪影。']

Result: 通过MagicBench评估发现，即使是GPT-image-1等顶级T2I模型也普遍存在显著的伪影问题。

Conclusion: 伪影减少是未来T2I发展的一个关键前沿。MagicMirror框架及其组件为解决这一挑战提供了全面的评估工具和洞察。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [100] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: 本文提出了SignClip框架，通过融合手势和唇部运动等手动与非手动线索，并引入分层对比学习，显著提升了手语翻译的准确性，超越了现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要侧重于手动信号，忽视了唇部动作等非手动线索，而唇部动作在手语中携带关键语言信息，对区分视觉相似的手语至关重要。

Method: 提出SignClip框架，它融合了空间手势和唇部运动特征等手动与非手动线索。此外，SignClip引入了一个具有多级对齐目标的分层对比学习框架，以确保手语-唇部和视觉-文本模态间的语义一致性。

Result: 在PHOENIX14T和How2Sign数据集上的实验表明，SignClip超越了现有最先进模型。例如，在PHOENIX14T的Gloss-free设置下，SignClip的BLEU-4从24.32提高到24.71，ROUGE从46.57提高到48.38。

Conclusion: SignClip通过有效融合手动和非手动线索，并结合分层对比学习，显著提高了手语翻译的准确性，证明了其在包容性交流中的应用潜力。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [101] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文分析了闭源和开源大型视觉语言模型（VLM）在文本篡改检测上的表现，发现开源模型仍落后于GPT-4o等闭源模型，且专门用于图像篡改检测的VLM在文本篡改上泛化性差。


<details>
  <summary>Details</summary>
Motivation: 现有研究已证明大型视觉语言模型（VLM）在图像篡改检测中的有效性，但其在文本篡改检测方面的能力尚未得到充分研究。

Method: 通过在不同的文本篡改数据集上分析闭源和开源VLM的性能。同时，对专门用于图像篡改检测的VLM进行了文本篡改检测的基准测试，并评估了VLM在真实场景文本和虚构身份证件（模拟现实滥用）上的表现。

Result: 研究表明，开源模型在文本篡改检测方面的性能正逐渐提升，但仍落后于GPT-4o等闭源模型。此外，专门用于图像篡改检测的VLM在文本篡改检测中存在泛化性问题。

Conclusion: 在文本篡改检测方面，闭源VLM（如GPT-4o）表现优于开源VLM，且专门针对图像篡改的VLM在处理文本篡改时存在泛化问题，无法有效通用。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [102] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD是一个新颖框架，通过点云、RGB图像和文本语义的多模态协同学习，在零样本3D异常检测中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 零样本3D异常检测在数据稀缺或标注成本高昂的场景中具有重要价值。然而，现有方法多只关注点云，忽略了RGB图像和文本等互补模态提供的丰富语义线索。

Method: 本文提出了MCL-AD框架，利用多模态协同学习。具体包括：1. 多模态提示学习机制（MPLM），通过引入与对象无关的解耦文本提示和多模态对比损失，增强模态内表示能力和模态间协同学习。2. 协同调制机制（CMM），通过联合调制RGB图像引导和点云引导分支，充分利用点云和RGB图像的互补表示。

Result: 广泛的实验表明，MCL-AD框架在零样本3D异常检测中取得了最先进（SOTA）的性能。

Conclusion: MCL-AD通过有效地整合点云、RGB图像和文本语义，显著提升了零样本3D异常检测的能力，为解决数据受限问题提供了强大的新方法。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [103] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出了一种Lipschitz引导的随机深度(DropPath)方法，通过增加深度处的丢弃概率来提高深度学习模型的对抗鲁棒性，同时保持准确性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers虽然在计算机视觉中表现出色，但极易受到对抗性扰动的攻击。现有的防御方法通常计算成本高昂或缺乏正式保证。

Method: 本文提出了一种Lipschitz引导的随机深度（DropPath）方法。该方法根据网络深度增加丢弃概率，以控制网络的有效Lipschitz常数，从而正则化深层，提高模型鲁棒性。

Result: 在CIFAR-10数据集上使用ViT-Tiny模型进行的实验表明，所提出的自定义深度依赖调度方案能保持接近基线的干净准确率，显著增强了FGSM、PGD-20和AutoAttack下的鲁棒性，并且与基线和线性DropPath调度相比，显著降低了FLOPs。

Conclusion: Lipschitz引导的随机深度方法通过深度依赖的丢弃概率，有效地提高了深度神经网络的对抗鲁棒性，同时保持了模型性能并降低了计算开销，提供了一种高效且有益的防御策略。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [104] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 该论文提出了一种基于能量图的概率框架和随机生灭优化算法，用于在复杂城市环境中精确地理定位街道设施。


<details>
  <summary>Details</summary>
Motivation: 为地方当局和私营利益相关者有效监测和维护公共基础设施，精确地理定位街道设施至关重要。

Method: 使用基于能量图的概率框架编码对象位置的空间可能性，通过地图格式整合外部地理空间信息（如GIS图层、道路图）。引入随机生灭优化算法来推断最可能的资产配置。

Result: 通过都柏林市中心路灯基础设施的模拟评估，证明了该方法在可扩展和精确城市资产测绘方面的潜力。

Conclusion: 该研究为复杂城市环境中精确、可扩展的城市资产测绘提供了一种有前景的解决方案。

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [105] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出Cluster-Driven Feature Caching (ClusCa)，通过空间聚类显著加速扩散Transformer，无需训练，同时保持或提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer因迭代去噪过程导致计算成本巨大。现有特征缓存方法利用时间相似性加速，但忽略了空间维度上的相似性。

Method: 引入ClusCa，作为对现有特征缓存的补充。ClusCa在每个时间步对token进行空间聚类，仅计算每个簇中的一个token，然后将其信息传播给该簇内的所有其他token，从而将token数量减少90%以上。

Result: 在DiT、FLUX和HunyuanVideo上的实验证明，ClusCa在文生图和文生视频任务中均有效，且无需额外的训练。例如，在FLUX上实现4.96倍加速，ImageReward达到99.49%，比原模型高0.51%。

Conclusion: ClusCa提供了一种高效且无需训练的加速扩散Transformer的方法，通过利用空间相似性显著减少计算量，同时保持或略微提升生成质量，是现有加速策略的有效补充。

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [106] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [107] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于Gamma扩散模型和降噪保真项的新型深度学习方法，能有效去除OCT图像斑点噪声，在保持解剖细节的同时实现优异的降噪效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: OCT图像固有的斑点噪声会模糊精细细节并阻碍准确诊断。现有去噪方法难以平衡噪声抑制与关键解剖结构的保留。

Method: 提出GARD，一种基于扩散概率模型的深度学习方法。它采用去噪扩散Gamma模型（而非传统高斯模型）来更准确反映斑点噪声的统计特性。此外，引入降噪保真项，利用预处理的低噪声图像指导去噪，防止高频噪声重新引入。通过调整去噪扩散隐式模型（DDIM）框架以加速推理过程。

Result: 实验结果表明，GARD在PSNR、SSIM和MSE指标上显著优于传统去噪方法和最先进的深度学习模型。定性结果证实GARD能生成更锐利的边缘并更好地保留精细解剖细节。

Conclusion: GARD是一种用于OCT图像去斑点的高效方法，它通过精确建模斑点噪声和引入引导机制，成功解决了噪声抑制与细节保留的平衡问题，并在性能上超越了现有技术。

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [108] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: 本文提出GLAM，一种几何引导的多视图乳腺X线摄影VLM预训练方法，通过全局和局部对齐及对比学习，有效利用多视图关系，超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有乳腺X线摄影VLM受限于数据和领域差异，尤其未能充分利用多视图关系（如放射科医生协同分析），导致模型性能不佳。

Method: 提出GLAM（Global and Local Alignment for Multi-view mammography），利用几何引导进行VLM预训练。该模型通过结合全局与局部、视觉-视觉和视觉-语言的对比学习，学习跨视图对齐和细粒度局部特征。

Result: 在大型乳腺X线摄影数据集EMBED上预训练后，GLAM模型在多个数据集的不同设置下均超越了现有基线。

Conclusion: GLAM通过有效地建模乳腺X线摄影的多视图几何上下文，显著提升了VLM在乳腺癌早期检测中的表现。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [109] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 本文是一篇综述，旨在分析视觉接地在视觉语言模型（VLMs）中的重要性、核心组件、应用、评估、与其他能力的关系、挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉接地能力对模型识别视觉输入中与文本描述匹配的区域至关重要，可应用于指代理解、细粒度问答、上下文描述及环境控制等广泛领域。

Method: 本文作为综述，回顾了现代通用视觉语言模型（VLMs）中视觉接地研究的代表性工作，概述其重要性、核心组件、实际应用（包括基准和评估指标），探讨视觉接地、多模态思维链与推理之间的关系，并分析固有挑战。

Result: 本文全面概述了视觉接地在VLMs中的重要性、核心组件、实际应用（包括基准和评估指标），讨论了视觉接地与多模态思维链和推理的复杂关系，并分析了该领域的固有挑战。

Conclusion: 视觉接地是视觉语言模型的一项关键能力，驱动着广泛应用。本综述全面总结了当前范式、挑战，并指明了未来研究方向，强调了其与推理的复杂关联。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [110] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 本文提出一种名为“注意力攻击”（Attention Attack）的新型对抗性攻击，通过干扰文本引导图像编辑方法的交叉注意力，有效且隐蔽地降低其编辑性能，并提出了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 文本引导的图像编辑方法虽然取得了进展，但容易受到对抗性攻击。

Method: 提出“注意力攻击”，该攻击利用自动生成的源图像标题作为编辑提示的代理，干扰文本提示与图像视觉表示之间的交叉注意力，从而破坏图像内容与文本描述的对齐。该方法无需了解具体的编辑方法或编辑提示。同时，提出了“Caption Similarity”和“语义Intersection over Union (IoU)”两种新评估策略来量化攻击效果。

Result: 在TEDBench++基准测试中，所提攻击显著降低了编辑性能，同时保持了不可察觉性。

Conclusion: “注意力攻击”能有效且隐蔽地破坏文本引导图像编辑的性能，且无需目标模型的知识，并通过引入新的评估指标，揭示了这类编辑方法的脆弱性。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [111] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 本研究利用知识蒸馏技术降低了基于神经网络的图像压缩模型的资源需求，使其更适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 虽然基于深度学习的图像压缩模型性能优于传统编解码器，但其高计算资源需求限制了在资源受限平台上的实时应用和主流部署。

Method: 采用知识蒸馏训练范式，让较小的神经网络（学生模型）从较大、更复杂的模型（教师模型）的输出中学习，从而在降低资源需求的同时获得更好的性能。

Result: 研究表明，知识蒸馏能有效应用于图像压缩任务：i) 适用于不同架构尺寸，ii) 实现不同的图像质量/比特率权衡，iii) 节省处理和能源资源。

Conclusion: 知识蒸馏是一种有效降低神经网络图像压缩模型资源需求的方法，为未来的超参数探索、教师模型选择、损失函数优化以及向Transformer模型扩展等研究方向奠定了基础。

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [112] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 本文提出一种新颖的无训练方法，仅用可见光和热像图对图像进行本征分解（明暗和反射）。该方法利用光吸收原理，通过可见光和热像强度的序数关系自监督神经网络。结果表明其性能优于现有学习模型，并为真实世界序数监督提供了可扩展的方案。


<details>
  <summary>Details</summary>
Motivation: 图像本征分解（将图像分解为明暗和反射）是一项长期存在的挑战，主要原因在于缺乏真实的、大规模的地面真值数据。现有方法多依赖合成数据或稀疏标注，且主要应用于有限的室内场景，户外场景的应用则更少。

Method: 提出了一种新颖的、无需训练的图像本征分解方法，该方法仅使用一对可见光和热成像图像。核心原理是利用光在不透明表面被吸收后会以热量形式被热像仪检测。通过这种方式，将可见光和热成像图像强度之间的序数关系与明暗和反射的序数关系关联起来，从而密集地自监督一个优化的神经网络以恢复明暗和反射。

Result: 研究在已知反射和明暗的条件下，分别在自然光和人工光照下进行了定量评估，并在各种户外场景中进行了定性实验。结果显示，该方法在性能上优于最近的基于学习的模型。

Conclusion: 该研究为收集真实世界的序数监督提供了一条可扩展的路径，而这种序数监督在以前通过手动标注是不可行的。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [113] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文对压缩视频质量增强（CVQE）领域进行了全面回顾，提出了一套新的分类法、统一的基准测试框架，并分析了重建性能与计算复杂性之间的权衡，旨在解决现有综述的局限性。


<details>
  <summary>Details</summary>
Motivation: CVQE对提升用户体验至关重要，但现有深度学习CVQE综述存在不足，包括缺乏系统分类、比较分析不足以及基准测试实践不完善。

Method: 该研究通过引入新型分类法（涵盖架构范式、编码标准、压缩域特征利用）、提出统一的基准测试框架（整合现代压缩协议和标准测试序列），并提供对现有方法重建性能与计算复杂性之间权衡的系统分析来解决这些问题。

Result: 本研究贡献了CVQE方法的全新分类法、统一的基准测试框架，并对当前最先进方法的性能与复杂性权衡进行了系统分析。

Conclusion: 该综述旨在为CVQE研究与部署中的一致性评估和模型选择奠定坚实基础。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [114] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter是一个新颖框架，通过适配器网络将融合的多模态特征注入SAM的RGB特征中，实现了多模态语义分割，并在挑战性基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义分割方法在恶劣条件（如弱光、遮挡、恶劣天气）下表现脆弱。多模态方法结合辅助传感器数据（如LiDAR、红外）能提供互补信息，增强鲁棒性，是解决这些局限性的新兴途径。

Method: 本文提出了MM SAM-adapter框架，旨在将Segment Anything Model (SAM) 扩展到多模态语义分割。该方法采用一个适配器网络，将融合的多模态特征注入到SAM的RGB特征中。这种设计使得模型能够保留RGB特征的强大泛化能力，同时仅在辅助模态提供额外线索时选择性地整合它们，从而实现多模态信息的平衡高效利用。

Result: MM SAM-adapter在DeLiVER、FMB和MUSES三个挑战性基准测试中均取得了最先进的性能。通过将DeLiVER和FMB划分为RGB-easy和RGB-hard子集进行分析，结果一致表明该框架在有利和不利条件下均优于竞争方法。

Conclusion: MM SAM-adapter通过有效的多模态适应实现了鲁棒的场景理解，证明了其在各种条件下的卓越性能和对多模态信息的平衡高效利用，有效解决了传统语义分割在挑战性环境下的局限性。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [115] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen是一个用于生成任意分辨率图像的新模型，它通过替换潜在扩散模型的VAE解码器，大幅提高了高分辨率图像生成速度（4K图像生成时间缩短至10秒以内），同时保持了视觉一致性。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型生成任意分辨率图像时，计算需求随分辨率呈二次方增长，导致4K图像生成耗时超过100秒，影响了跨设备视觉体验和应用效率。

Method: InfGen在潜在扩散模型的基础上，将扩散模型生成的固定潜在表示视为内容表示。它用一个一步式生成器替换了传统的VAE解码器，使得该生成器能够从紧凑的固定大小潜在空间解码出任意分辨率的图像，而无需重新训练扩散模型。该方法可应用于使用相同潜在空间的任何模型。

Result: 实验证明，InfGen能够将4K图像生成时间缩短至10秒以内，并将许多模型提升至任意高分辨率生成时代。

Conclusion: InfGen通过简化生成过程、降低计算复杂性，有效地解决了现有扩散模型在高分辨率图像生成方面的效率问题，实现了快速、任意分辨率的图像生成，具有广泛的应用潜力。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [116] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 本研究利用时间自监督学习（SSL）方法，解决了阿尔茨海默病（AD）预测中标记数据稀缺和模型泛化能力差的问题，并在多项任务中表现优于监督学习。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在阿尔茨海默病预测中面临标记数据不足、跨数据集泛化能力差以及对不同数量输入扫描和扫描时间间隔不灵活的局限性。

Method: 研究者将三种先进的时间自监督学习（SSL）方法应用于3D脑部MRI分析，并增加了新颖的扩展以处理可变长度输入和学习鲁棒的空间特征。模型使用四个公开数据集（共3,161名患者）进行预训练，并结合了时间顺序预测和对比学习。

Result: 该模型在诊断分类、疾病转化检测和未来转化预测等多项阿尔茨海默病预测任务中展示了性能。特别地，结合时间顺序预测和对比学习的SSL模型在七项下游任务中的六项上优于监督学习，并表现出良好的任务适应性和对不同输入图像数量及时间间隔的泛化能力。

Conclusion: 该自监督学习模型在阿尔茨海默病预测任务中展现出强大的鲁棒性能和在临床应用中的广泛潜力。研究代码和模型已公开。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [117] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）平台AutoIND能大幅缩短新药研究申请（IND）初稿的撰写时间（约97%），且未发现关键监管错误，但仍需专业监管撰写人员完善输出质量。


<details>
  <summary>Details</summary>
Motivation: IND申请准备耗时且依赖专业知识，延缓了早期临床开发进程，因此需要评估LLM是否能缩短撰写时间并保持文档质量。

Method: 直接记录AutoIND生成IND非临床书面摘要的起草时间。与之前经FDA批准的IND摘要的手动起草时间（由经验丰富的监管撰写人员估算）进行比较。由一名盲审的监管撰写评估员使用七个预设类别（正确性、完整性、简洁性、一致性、清晰性、冗余性、重点强调）评估质量，并定义关键监管错误。

Result: AutoIND将IND初稿起草时间缩短了约97%（从约100小时减少到3.7小时或2.6小时）。IND-1和IND-2的质量得分分别为69.6%和77.9%。未检测到关键监管错误，但存在强调、简洁性和清晰性方面的不足。

Conclusion: AutoIND可显著加速IND初稿撰写，但专业的监管撰写人员对于将输出成熟为可提交的质量仍然至关重要。发现的系统性不足为模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [118] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: 本文提出boldsea，一种语义事件架构，利用可执行本体建模复杂动态系统，并直接控制流程执行。


<details>
  <summary>Details</summary>
Motivation: 解决传统业务流程管理（BPM）系统和面向对象语义技术在处理复杂动态系统时的局限性。

Method: 引入boldsea架构，整合事件语义与数据流架构；提出形式化的BSL（boldsea语义语言）及其BNF语法；设计boldsea-engine引擎，直接解释语义模型为可执行算法，无需编译。

Result: 通过将事件语义与数据流架构结合，解决了传统技术的限制。该方法支持运行时修改事件模型，确保时间透明性，并在统一的语义框架内融合数据与业务逻辑。

Conclusion: boldsea提供了一种创新方法，通过其可执行本体和直接解释引擎，实现复杂动态系统的灵活建模、运行时修改和高效执行，克服了现有技术的缺点。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [119] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 研究评估了大型语言模型（LLMs）和视觉语言模型（VLMs）在不同类型环境中为规划提供反馈的能力，发现它们能提供多样且高质量的反馈，并能减少对奖励设计和演示的需求，但在复杂连续环境中反馈质量会下降。


<details>
  <summary>Details</summary>
Motivation: 在接地的环境中进行规划通常需要精心设计的奖励函数或高质量的标注演示。预训练的基础模型（如LLMs和VLMs）被认为捕获了有用的背景知识，有望减少策略学习所需的奖励设计和演示量。

Method: 评估LLMs和VLMs在符号、语言和连续控制环境中提供反馈的效果。考虑了包括二元反馈、偏好反馈、动作建议、目标建议和增量动作反馈在内的多种反馈类型。同时，还考虑了影响反馈性能的推理方法，包括上下文学习、思维链和对环境动态的访问。

Result: 研究发现，基础模型能够在不同领域提供多样化的高质量反馈。更大的、具备推理能力的模型持续提供更准确的反馈，展现出更小的偏差，并从增强的推理方法中获得更多益处。然而，在动态复杂或具有连续状态空间和动作空间的环境中，反馈质量会下降。

Conclusion: 基础模型在为规划任务提供多样化高质量反馈方面展现出巨大潜力，有助于减少对奖励函数和演示的依赖。尽管更大、更智能的模型表现更优，但在面对复杂连续环境时，其反馈质量仍存在局限性。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [120] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 本文提出一个模块化多模态框架，利用生成式AI从公开住宅信息和图像中生成能源建模所需数据，以解决数据获取难题。


<details>
  <summary>Details</summary>
Motivation: 计算能源模型需要大量数据，但这些数据往往难以获取、成本高昂或涉及隐私问题。

Method: 引入一个模块化多模态框架，使用生成式AI从公开的住宅信息和图像中生成所需数据。同时提供了一个演示该框架的管道，并评估了其生成式AI组件。

Result: 该框架能够生成逼真、带有标签的数据，并避免了生成模型中的常见问题。

Conclusion: 通过减少对昂贵或受限数据源的依赖，该框架为更易获取和可复现的能源建模研究铺平了道路。

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [121] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了自动形式化（informal-to-formal translation）及其在数学之外的扩展，指出相关研究领域的独立发展限制了共享进步，并提出了一个统一框架以促进跨领域交流。


<details>
  <summary>Details</summary>
Motivation: 自动形式化领域的研究，包括数学形式化和利用大型语言模型（LLMs）进行非形式化到形式化的转换，尽管任务相似，但发展相对独立，缺乏共享的方法、基准和理论框架，从而阻碍了整体进展。

Method: 本文通过回顾显性或隐性地属于自动形式化范畴的研究实例，并在此基础上提出一个统一的框架。

Result: 提出了一个统一的自动形式化框架。

Conclusion: 通过建立统一框架并鼓励跨领域交流，可以加速自动形式化领域的发展，进而推动下一代AI系统的进步。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [122] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本研究引入了一个基于RAG的智能知识助手系统，通过表格和决策树文本化方法增强LLMs对异构数据的理解，并构建领域知识库以支持山羊健康管理，在验证集和测试集上均取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在许多行业中被认为是宝贵的知识交流工具，但它们在畜牧业中的应用受限于知识来源的可用性、多样性和复杂性。因此，需要开发一个系统来支持规模化养殖山羊的健康管理。

Method: 本研究引入了一个支持山羊健康管理的智能知识助手系统。该系统利用检索增强生成（RAG），并提出了表格文本化和决策树文本化两种结构化知识处理方法，以增强LLMs对异构数据格式的理解。在此基础上，建立了一个领域特定的山羊养殖知识库（涵盖疾病防治、营养管理、饲养管理、羊奶管理和基础养殖知识五个领域），并集成了在线搜索模块以获取实时更新信息。通过六项消融实验评估了系统性能。

Result: 异构知识融合方法取得了最佳结果，在验证集上的平均准确率为87.90%，在测试集上为84.22%。在基于文本、基于表格和基于决策树的问答任务中，准确率均持续超过85%，验证了模块化设计中结构化知识融合的有效性。错误分析发现遗漏是主要的错误类别。

Conclusion: 研究结果表明，所提出的系统在山羊养殖的实际应用中具有鲁棒性和可靠性，并指出未来可以通过改进检索覆盖率和上下文集成来进一步提升性能。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [123] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 研究探究LLM作为主动参与者协助人类完成任务的能力，通过让LLM在UNO游戏中协助另一玩家获胜来测试。


<details>
  <summary>Details</summary>
Motivation: LLMs有望在广泛任务中提供指导，而不仅仅是回答问题。本研究旨在验证LLM代理是否能作为积极参与者实际帮助人类实现目标。

Method: 将解码器-only LLMs作为代理集成到RLCard游戏环境中，参与UNO牌局。LLM接收完整的游戏状态信息，并使用两种不同的提示策略通过简单文本提示做出响应。评估了1B至70B参数范围的模型，并探索模型规模对性能的影响。

Result: 所有模型在UNO游戏中均能成功超越随机基线。然而，只有少数模型能够显著帮助另一玩家获胜。

Conclusion: LLM虽能玩游戏，但其作为主动参与者显著协助另一玩家实现目标的能力仍有限。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [124] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 本文提出一个概念框架和架构蓝图，旨在指导科学工作流向智能化、集群化演进，以实现自主科学发现并大幅加速研究进程。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现面临资源协调的挑战，导致研究人员耗费大量精力进行手动工作流管理。尽管AI代理提供了加速科学发现的潜力，但其在实际应用中的具体实现和整合方式尚不明确。

Method: 本文提出一个概念框架，描述工作流沿智能（从静态到智能）和组合（从单一到集群）两个维度演进的路径。在此基础上，进一步 प्रस्तुत 一个架构蓝图，以指导社区实现自主科学。

Result: 本研究的成果是提出了一个概念框架和一个架构蓝图，为实现从现有工作流系统到完全自主、分布式科学实验室的演进提供了一条路径，并有望将发现速度提升百倍，带来变革性的科学工作流。

Conclusion: 该概念框架和架构蓝图为实现完全自主的分布式科学实验室铺平了道路，有望大幅加速科学发现，并彻底改变科学工作流范式。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [125] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 本文提出将WaveFunctionCollapse (WFC) 重构为马尔可夫决策过程 (MDP)，以解耦程序化内容生成中的目标优化与约束满足，实验证明该方法优于联合优化。


<details>
  <summary>Details</summary>
Motivation: 在程序化内容生成中，同时满足设计师指定的目标和底层瓦片组隐式施加的邻接约束是一个挑战。

Method: 将WaveFunctionCollapse (WFC) 重构为马尔可夫决策过程 (MDP)。这使得外部优化算法能专注于目标最大化，同时利用WFC的传播机制来强制执行约束满足。该方法与传统联合优化全局指标和局部瓦片放置的演化方法进行了实证比较。

Result: 随着任务复杂性增加，联合优化方法不仅表现不佳，而且相对于WFC-MDP上的优化方法始终表现出更差的性能。

Conclusion: 将局部约束满足与全局目标优化解耦具有显著优势，能有效提升程序化内容生成的性能。

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [126] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文针对XAI评估难题，提出了一种基于实际因果关系的变量重要性度量，并开发了新型XAI工具B-ReX，证明其在布尔函数预测任务上优于现有黑盒工具。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，解释性AI (XAI) 方法的评估通常具有挑战性。

Method: 1. 针对表格数据和AI模型预测布尔函数值的用例，提出了一种基于实际因果关系的变量重要性的形式化精确度量。2. 使用该度量评估了最先进的XAI工具。3. 基于现有工具ReX，开发了新型XAI工具B-ReX。

Result: B-ReX在大型基准测试中优于其他黑盒XAI工具。具体而言，在随机10值布尔公式上，B-ReX的Jensen-Shannon散度为0.072 ± 0.012。

Conclusion: 通过引入基于实际因果关系的新变量重要性度量，并开发出在布尔函数预测任务中表现优异的B-ReX工具，本文有效推进了XAI评估方法的研究。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [127] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: 本文提出GAMA系统，一个用于LLM多智能体系统的通用匿名化框架，通过将工作空间划分为私有和公共区域并进行数据匿名化来保护隐私。GAMA还引入了DRKE和DLE模块以减轻语义损失，并在公共问答和定制隐私保护数据集上展现出卓越的性能和隐私保护能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展，LLM驱动的多智能体系统(MAS)在语言理解和生成方面表现出色。然而，高性能LLM通常托管在远程公共服务器上，当任务涉及隐私数据时，MAS无法在缺乏隐私保护机制的情况下安全地利用这些LLM。

Method: 本文提出了一个通用匿名多智能体系统(GAMA)。GAMA将智能体的工作空间划分为私有和公共空间，通过匿名化机制保护隐私数据，确保在公共空间中只使用匿名化数据。为缓解匿名化造成的语义损失，GAMA集成了两个关键模块：基于领域规则的知识增强(DRKE)和基于反驳的逻辑增强(DLE)。

Result: GAMA在两个公共问答数据集（Trivia Creative Writing和Logic Grid Puzzle）上的评估结果表明，其性能优于现有最先进模型。为进一步评估隐私保护能力，本文设计了知识隐私保护和逻辑隐私保护两个新数据集，最终结果突出显示GAMA在任务处理和隐私保护方面均具有卓越的有效性。

Conclusion: GAMA系统成功地解决了多智能体系统在利用远程LLM处理隐私数据时的安全挑战，它不仅在任务处理上表现出色，而且在隐私保护方面也展现了非凡的有效性。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [128] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个统一的多智能体协作框架，利用多极任务处理图和IF-THEN规则，解决了复杂不确定任务中多智能体系统的规划挑战，并在知识型和逻辑型问答任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型显著提升了多智能体系统的能力，但在处理高度复杂且不确定的任务时，多智能体系统在有效任务规划方面仍面临挑战，常导致错误输出，阻碍任务执行。

Method: 提出XAgents框架，该框架基于多极任务处理图和IF-THEN规则。多极任务处理图用于动态任务规划和处理任务不确定性；子任务处理中，集成领域特定IF-THEN规则以约束智能体行为；全局规则则用于增强智能体间的协作。

Result: XAgents在三个不同数据集上进行了评估，结果表明其在知识型和逻辑型问答任务中，均持续优于当前最先进的单智能体和多智能体方法。

Conclusion: XAgents通过结合多极任务处理图和IF-THEN规则，成功提升了多智能体系统在复杂不确定任务中的规划能力和执行效率，并在问答任务中展现出卓越性能。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [129] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 针对AI带来的社会危害，本文提出以人为中心、数据驱动的“AI Harmonics”评估框架和AIH指标，利用序数数据衡量危害严重性。实验表明政治和物理危害最突出，该方法能有效识别危害分布，助力精准缓解。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型侧重内部合规，忽视多元利益相关者视角和真实世界后果，无法有效应对AI带来的前所未有的社会危害和风险。

Method: 提出“AI Harmonics”框架，其核心是以人为中心、危害严重性自适应，并基于实证事件数据。包含新的AI危害评估指标（AIH），利用序数严重性数据捕捉相对影响。结合稳健的通用方法与数据驱动、利益相关者感知的框架，用于探索和优先排序AI危害。

Result: 实验证明，政治和物理危害的集中度最高，需要紧急缓解，因其分别侵蚀公众信任和构成生命威胁。AI Harmonics能持续识别危害分布不均，从而帮助政策制定者和组织精准定位缓解措施。

Conclusion: AI Harmonics提供了一种有效评估和优先缓解AI危害（特别是政治和物理危害）的新范式，并通过揭示危害分布规律，赋能决策者更有效地采取干预措施。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [130] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 自主AI代理正在形成一个超越人类监督的新经济层。本文提出“沙盒经济”框架来分析这一系统，并讨论通过主动设计可引导的AI代理市场，以应对机遇和风险，确保技术变革服务于人类福祉。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理的迅速普及，正在形成一个超越人类直接监督的新经济层，其交易和协调的规模与速度带来了巨大的机遇，但也伴随着系统性风险和不平等加剧等重大挑战。

Method: 提出“沙盒经济”框架，从起源（自发/有意）和与人类经济的独立性（可渗透/不可渗透）两个维度对新兴系统进行分析。进而讨论了多项设计选择，包括用于公平资源分配和偏好解决的拍卖机制、协调集体目标的AI“任务经济”设计，以及确保信任、安全和问责的社会技术基础设施。

Result: 分析指出当前趋势正导向一个庞大且高度可渗透的自发涌现AI代理经济，这既提供了前所未有的协调机会，也带来了系统性经济风险和不平等加剧等挑战。

Conclusion: 呼吁积极主动地设计可引导的AI代理市场，以确保即将到来的技术变革能够与人类的长期集体繁荣相一致。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [131] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 本文提出Robust Sparse Sampling (RSS)，一种针对鲁棒马尔可夫决策过程(RMDP)的首个在线规划算法，通过利用样本均值近似(SAA)计算鲁棒值函数，解决了模型不确定性下的规划问题。RSS提供理论性能保证，并在不确定环境中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在线MDP规划中的采样方法（如Sparse Sampling）在生成模型不确定（因数据有限导致近似误差）时，可能导致性能下降或不安全行为。鲁棒MDPs虽能处理模型不确定性，但现有方法计算量大，不适用于实时在线规划。

Method: 引入Robust Sparse Sampling (RSS)算法。与Sparse Sampling不同，RSS通过利用样本均值近似 (SAA) 的效率和理论特性，计算鲁棒值函数，从而在在线设置中实现可处理的鲁棒策略计算。RSS适用于无限或连续状态空间，其样本和计算复杂度与状态空间大小无关。

Result: RSS是首个具有有限样本理论性能保证的RMDP在线规划算法。它提供了理论性能保证，并在经验上证明在动态不确定环境中优于标准的Sparse Sampling方法。

Conclusion: RSS为在模型不确定性下进行鲁棒在线规划提供了一种有效、可行且具有理论基础的方法，解决了现有鲁棒MDP规划算法在实时应用中的计算效率问题。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [132] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 本文提出一个基于LLM的多智能体框架，旨在自动化多孔材料的模拟设置和力场选择，以加速材料发现过程。


<details>
  <summary>Details</summary>
Motivation: 多孔材料的自动化表征能够加速材料发现，但目前受限于模拟设置和力场选择的复杂性。

Method: 本文提出了一个多智能体框架，其中LLM智能体能够自主理解表征任务、规划模拟、组装相关力场、执行模拟并解释结果。作为初步实践，实现了一个用于文献知情力场提取和RASPA模拟自动化设置的多智能体系统。

Result: 初步评估结果表明，该方法具有高正确性和可重复性。

Conclusion: 该方法有望实现完全自主、可扩展的材料表征，从而加速材料科学发现。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [133] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: 本文提出CARENLI框架，通过将临床自然语言推理任务分解并引入可审计的推理流程，显著提升了LLM在临床NLI中的表现和可解释性，并揭示了LLM在推理不足时倾向于使用启发式方法的问题。


<details>
  <summary>Details</summary>
Motivation: 质疑LLM通过扩大规模能否在临床自然语言推理（NLI）中产生更结构化、可泛化的内部表示的普遍假设。旨在解决LLM在复杂临床推理中可能出现的推理不足和缺乏可审计性的问题，以实现更安全、可靠的推理。

Method: 引入CARENLI（Compartmentalised Agentic Reasoning for Clinical NLI）框架，该框架将知识获取与原则性推理分离。CARENLI将每个前提-陈述对路由到针对四个推理家族（因果归因、组成式接地、认知验证、风险状态抽象）之一的特定求解器，并通过规划器、验证器和精炼器强制执行可审计的程序。研究使用了分解后的基准。

Result: CARENLI在四个LLM上的推理准确性提高了高达42个百分点，在因果归因任务中达到98.0%，在风险状态抽象任务中达到81.2%。验证器能以接近上限的可靠性标记违规行为，精炼器纠正了大量认知错误。剩余的失败主要集中在路由环节，表明家族分类是主要瓶颈。

Conclusion: 研究结果表明，LLM通常能保留相关事实，但在推理不明确时会默认使用启发式方法。CARENLI明确了这种分离，并为更安全、可审计的推理提供了一个框架。

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [134] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 研究探讨了通过引入形式化方法来提升小型语言模型（SLMs）在推理任务上的表现，特别是在本体工程领域，发现紧凑的逻辑语言可以替代自然语言并保持强大的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型（LMs）在推理领域存在不足，尤其影响本体工程任务。本研究旨在解决SLMs在推理任务上的局限性。

Method: 通过将形式化方法融入小型语言模型（SLMs）来提升其在推理任务上的性能，旨在利用SLMs引导本体构建。设置一系列初步实验，比较使用不同语法（自然语言与更紧凑的逻辑语言）表达逻辑问题对SLMs在预定义推理任务上表现的影响。

Result: 研究发现，在推理任务中，可以用更紧凑的逻辑语言替代自然语言，同时保持SLMs的强大性能。

Conclusion: 这些结果有望用于进一步完善SLMs在本体工程中的作用。

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [135] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 本研究量化分析了主流大型语言模型在道德困境中的偏好，发现它们普遍偏爱关怀和美德价值观，并强调了解释性和文化意识对AI对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI的快速发展，如何使机器决策与人类道德价值观对齐成为紧迫问题。本研究旨在探讨领先AI系统如何优先处理道德结果，以及这如何揭示人机共生前景。

Method: 通过一项定量实验，使用六个大型语言模型，在代表五种道德框架的18个困境中对结果进行排名和评分。

Result: 研究发现所有模型都存在惊人一致的价值偏见，其中“关怀”和“美德”价值观的结果被评为最道德，而自由主义选择则始终受到惩罚。具有推理能力的模型对上下文更敏感，并提供更丰富的解释；非推理模型则产生更统一但更不透明的判断。

Conclusion: 本研究实证比较了不同文化背景下LLM的道德推理，理论上将概率模型行为与潜在价值编码联系起来，并实践上强调了可解释性和文化意识作为指导AI迈向透明、对齐和共生未来的关键设计原则。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [136] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: 本文提出State Algebra，一个新颖的代数框架，用于表示和操作命题逻辑，强调其表示灵活性和在规范性上的权衡，并展示其在算法表达和扩展性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种新的代数框架（State Algebra），以利用代数方法高效、灵活地表示和操作命题逻辑。

Method: 该框架采用Set、Coordinate和Row Decomposition三层分级表示结构，并利用强大的代数引擎进行计算。它通过应用固定变量顺序可以获得唯一规范形式，但在默认约简中为了表示灵活性而放弃了强制规范性。

Result: State Algebra在表示上具有高度灵活性；其默认状态向量约简不是规范的，但可通过固定变量顺序实现唯一规范形式。这种权衡可能为特定问题带来更紧凑的表示。此外，该框架为表达基于搜索和知识编译算法提供了工具。

Conclusion: State Algebra通过其分层代数方法和灵活的表示机制，为命题逻辑的表示和操作提供了一种新颖且强大的工具。它在灵活性和规范性之间取得平衡，有望实现更紧凑的问题表示，并自然地扩展到概率逻辑和加权模型计数等领域。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [137] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding是一种新颖的代理框架，通过将多智能体系统中的故障归因从模式识别转变为结构化因果推理任务，显著提高了错误定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，故障归因（精确找出导致错误的步骤）是一个关键但尚未解决的挑战。现有方法将其视为模式识别任务，导致步级准确率极低（低于17%），且缺乏稳健的反事实推理能力（即无法确定纠正单个操作是否能避免任务失败），因此不适用于复杂系统的调试。

Method: 本文提出了Abduct-Act-Predict (A2P) Scaffolding框架。该框架将故障归因重构为结构化因果推理任务，通过一个单一的推理过程引导大型语言模型完成正式的三步推理：(1) 溯因（Abduction），推断智能体行为背后的隐藏根本原因；(2) 行动（Action），定义最小的纠正性干预措施；(3) 预测（Prediction），模拟后续轨迹并验证干预是否解决了故障。这种方法利用了整个对话的整体上下文并施加了严格的因果逻辑。

Result: 在Who&When基准测试中，A2P在算法生成数据集上实现了47.46%的步级准确率，比基线（16.67%）提高了2.85倍。在更复杂的手工数据集上，A2P实现了29.31%的步级准确率，比基线（12.07%）提高了2.43倍。

Conclusion: 通过引入因果推理的视角，A2P Scaffolding为自动化故障归因提供了一个鲁棒、可验证且准确性显著提高的解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [138] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 本文提出一个信息论框架，利用互信息模式揭示强化学习的学习动态，并能有效诊断现实世界中RL代理的传感器和执行器故障。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的强化学习代理因传感器故障、执行器磨损和环境变化而性能下降，但缺乏内在机制来检测和诊断这些故障。

Method: 本研究提出了一个信息论框架，通过分析机器人控制任务中状态-动作互信息（MI(S;A)）和状态、动作、下一状态联合互信息（MI(S,A;S')）的模式。通过受控扰动实验模拟观察空间噪声（传感器故障）和动作空间噪声（执行器故障），并观察信息指标的变化。

Result: 成功学习表现出特征信息签名：MI(S;A)从0.84增加到2.83比特，表明选择性注意力增加；MI(S,A;S')呈倒U形曲线，在学习早期达到峰值，反映从探索到利用的转变。信息指标能差异化诊断系统故障：观察空间噪声导致所有信息通道广泛崩溃，而动作空间噪声选择性地破坏动作-结果可预测性，从而实现故障的精确本地化。

Conclusion: 信息模式既是学习的标志，也是系统健康的诊断依据，为基于信息论原则的自适应RL系统（具备自主故障检测和策略调整能力）奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [139] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: 提出了SAM-BG框架，通过结构语义保存学习脑图表示，在有限标记数据下提高了精神疾病诊断的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 标记脑网络数据有限使得精神疾病诊断准确性和可解释性面临挑战。现有自监督学习（SSL）方法常因增强策略破坏脑图中关键的结构语义。

Method: 提出两阶段框架SAM-BG。预训练阶段，在少量标记数据上训练边掩码器以捕获关键结构语义。自监督学习阶段，利用提取的结构先验指导结构感知增强，以学习更具语义意义和鲁棒性的表示。

Result: 在两个真实精神疾病数据集上的实验表明，SAM-BG优于现有最先进方法，特别是在小标记数据设置下，并能揭示提高可解释性的临床相关连接模式。

Conclusion: SAM-BG通过结构语义保存，有效解决了脑图表示学习中数据稀缺和语义破坏的问题，显著提升了精神疾病诊断的性能和可解释性。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [140] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: 本文提出D-CAT框架，通过解耦的跨注意力传输，使多模态模型能够在推理时仅依赖单一传感器进行高效分类，解决了现有方法对配对传感器数据的高要求。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态迁移学习方法在训练和推理时均需配对传感器数据，这限制了其在资源受限环境中（如经济或技术上无法使用完整传感器套件的场景）的部署。

Method: 研究者提出了D-CAT（Decoupled Cross-Attention Transfer）框架。该方法结合了用于特征提取的自注意力模块和新颖的跨注意力对齐损失，旨在对齐模态特定的特征空间，同时不要求两种模态的分类管道耦合，从而实现在推理时无需联合传感器模态。

Result: D-CAT在三个多模态人类活动数据集上进行了评估。在同分布场景中，从高性能模态（如视频到IMU）迁移可使F1分数比单模态训练提高高达10%。在异分布场景中，即使是较弱的源模态（如IMU到视频），只要目标模型未过度拟合训练数据，也能提升目标性能。

Conclusion: D-CAT通过实现单传感器推理和跨模态知识迁移，在保持准确性的同时减少了感知系统的硬件冗余。这对于成本敏感或需要适应性部署（如传感器可用性可变环境下的辅助机器人）的应用至关重要。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [141] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: 提出Meta-RL-Crypto，一个结合元学习和强化学习的Transformer自改进代理，无需人工监督，有效预测加密货币回报并超越现有LLM基线。


<details>
  <summary>Details</summary>
Motivation: 加密货币回报预测极具挑战性，其价格受复杂且快速变化的链上活动、新闻流和社交情绪驱动，且标注训练数据稀缺昂贵。

Method: 开发Meta-RL-Crypto，一个统一的Transformer架构，整合元学习和强化学习，创建完全自改进的交易代理。该代理基于指令调优的LLM，通过在闭环架构中迭代扮演actor、judge和meta-judge角色进行学习，无需额外人工监督。它能利用多模态市场输入和内部偏好反馈，持续优化交易策略和评估标准。

Result: 在多种市场环境中进行的实验证明，Meta-RL-Crypto在真实市场技术指标上表现出色，并超越了其他基于LLM的基线模型。

Conclusion: Meta-RL-Crypto成功地将元学习和强化学习集成到Transformer架构中，构建了一个无需人工干预、能自我改进的加密货币交易代理，有效应对了预测难题和数据限制，并在实际市场中展现出优越性能。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [142] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: KV Cache内存需求高，现有压缩方法有缺陷。LAVa提出一种统一框架，通过最小化Transformer残差流的信息损失，实现动态头和层预算的KV Cache压缩，无需训练，并在多任务上表现优越。


<details>
  <summary>Details</summary>
Motivation: LLM推理中的KV Cache能加速长上下文处理，但内存占用高，需进行压缩。现有压缩方法多为启发式，且缺乏动态预算分配。

Method: 引入LAVa，一个统一的KV Cache压缩框架，通过最小化Transformer残差流中的信息损失。通过分析层注意力输出损失，推导新指标实现动态头部预算的层级压缩；通过对比跨层信息实现动态层级预算。该方法无需训练，也不依赖多种策略组合。

Result: LAVa在LongBench、Needle-In-A-Haystack、Ruler和InfiniteBench等基准测试中表现出卓越的性能。实验发现动态层预算对生成任务（如代码补全）至关重要，而动态头预算在抽取任务（如抽取式问答）中扮演关键角色。

Conclusion: LAVa作为首个完全动态的KV Cache压缩方法，通过创新的信息损失最小化策略和动态预算分配，在各类任务中均能持续保持顶级性能，解决了现有压缩方法的局限性。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [143] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: 本文提出HACO框架，通过结合离线强化学习与保形风险门控，为Medicaid人群健康管理提供安全、公平且可审计的保守决策支持。


<details>
  <summary>Details</summary>
Motivation: Medicaid人群健康管理项目需要协调外展服务，且必须确保决策的安全、公平和可审计性，同时有效控制不良事件风险（如非计划急诊/住院）。

Method: 本文提出了混合自适应保形离线强化学习 (HACO) 框架，该框架将风险校准与偏好优化分离。具体步骤包括：(i) 训练轻量级不良事件风险模型；(ii) 导出保形阈值以屏蔽不安全行动；(iii) 在安全子集上学习偏好策略。研究使用了Waymark公司277万次决策、168,126名患者的去身份化数据集，并采用版本无关的拟合Q评估(FQE)和按年龄、性别、种族进行亚组审计。

Result: HACO实现了强大的风险判别能力（AUC约0.81），具有校准阈值（{\tau}约0.038，{\alpha}=0.10），同时保持高安全覆盖率。亚组分析揭示了不同人口统计学群体之间估计价值存在系统性差异，强调了公平性审计的重要性。

Conclusion: 保形风险门控能与离线强化学习有效结合，为人群健康管理团队提供保守、可审计的决策支持。

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [144] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: 提出一种统一的LLM路由框架，利用交叉注意力机制动态选择最优模型，兼顾质量和成本，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）计算成本和性能差异大，导致在实际应用中难以实现可扩展、高成本效益的部署。

Method: 引入一个统一路由框架，采用单头交叉注意力机制联合建模查询和模型嵌入，实现为每个输入查询动态选择最优LLM。为平衡性能和成本，提出了指数奖励函数。

Result: 在RouterBench基准上进行评估，该路由器能预测响应质量和生成成本，相比现有路由器，平均质量提升（AIQ）高达6.6%，最大性能提升2.9%。

Conclusion: 该架构轻量、跨领域泛化能力强，并提高了效率，为成本感知型LLM路由设定了新标准。

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [145] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: 本文分析梯度步长去噪器在即插即用算法中的应用，该去噪器可作为显式泛函的梯度下降或近端算子，同时保持领先的去噪性能。


<details>
  <summary>Details</summary>
Motivation: 即插即用优化算法常依赖于替代隐式图像先验的去噪器，但这些先验通常无法显式表达。需要一种能够显式表示特定泛函的去噪器。

Method: 该研究分析了梯度步长去噪器，该去噪器被专门训练，使其能够精确地扮演显式泛函的梯度下降算子或近端算子。

Result: 梯度步长去噪器成功地作为显式泛函的梯度下降或近端算子，并且在实现这一目标的同时，依然保持了先进的去噪能力。

Conclusion: 梯度步长去噪器为即插即用算法提供了一种新的范式，允许使用显式泛函替代传统的隐式先验，同时确保一流的去噪性能。

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [146] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 本研究利用机器学习和多模态生理信号融合，成功区分了惊吓与意外事件，旨在提升高风险环境下的安全性。


<details>
  <summary>Details</summary>
Motivation: 在高风险环境（如航空）中，突发事件会损害注意力并延迟决策，带来严重安全风险。惊吓和意外等反应难以区分，且现有研究缺乏利用生理数据对其进行区分的探讨。

Method: 本研究基于生理信号，采用机器学习和多模态融合策略来区分惊吓与意外事件，并扩展至区分惊吓、意外和基线状态。

Result: 在区分惊吓和意外事件时，SVM结合Late Fusion实现了85.7%的最高平均准确率。在区分惊吓、意外和基线状态时，XGBoost结合Late Fusion实现了74.9%的最高平均准确率。

Conclusion: 通过机器学习和多模态生理信号融合，可以可靠地区分惊吓和意外等事件，这为高风险环境中的事件识别和安全保障提供了有效途径。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [147] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 该研究提出一个SDN-区块链架构，利用机器学习回归器（称为Proof of AutoML）生成高随机性的nonce，以在灾害场景中实现太阳能能源交易的安全追溯性。树形集成模型在随机性表现上尤为突出。


<details>
  <summary>Details</summary>
Motivation: 在灾害导致传统能源基础设施受损时，需要确保太阳能家庭与移动充电单元之间在区块链网络上的能源交易安全且可追溯。为此，生成鲁棒且不可预测的nonce至关重要。

Method: 研究提出了一个SDN（软件定义网络）使能的架构，利用机器学习回归器（而非其预测准确性）生成随机值作为nonce候选，并称之为“Proof of AutoML”。SDN用于灵活控制数据流和能源路由。通过9000个样本数据集，评估了五种AutoML选择的回归模型（Gradient Boosting, LightGBM, Random Forest, Extra Trees, K-Nearest Neighbors），衡量其生成多样化和非确定性输出的能力。

Result: 随机性分析显示，Random Forest和Extra Trees回归器展现出完全的随机性依赖。Gradient Boosting、K-Nearest Neighbors和LightGBM也表现出强劲但略低的随机性得分（分别为97.6%、98.8%和99.9%）。

Conclusion: 某些机器学习模型，特别是基于树的集成模型，可在灾害条件下具有韧性的、基于SDN的区块链安全能源交易基础设施中，作为有效且轻量级的nonce生成器。

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [148] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: 针对离策略离散动作RL中基于策略方法性能不足的问题，本文通过解耦DSAC中actor与critic的熵，并提出一个灵活的离策略actor-critic框架，使其在Atari游戏上能匹敌DQN。


<details>
  <summary>Details</summary>
Motivation: 在离策略离散动作强化学习中，基于价值的方法（如DQN）是主流。基于策略的方法（如PPO、SAC）要么不擅长离策略学习，要么在离散动作环境下性能不佳。

Method: 从离散SAC (DSAC) 入手，发现其性能差主要源于actor与critic熵的耦合。通过解耦熵，并提出一个灵活的离策略actor-critic框架。该框架支持m步Bellman算子更新critic，并结合标准策略优化与熵正则化来定义actor目标。

Result: 理论上，证明了所提方法在表格设置下能收敛到最优正则化价值函数。经验上，这些方法在Atari游戏上能接近DQN性能，且无需熵正则化或显式探索。

Conclusion: 通过解决actor与critic熵耦合问题并引入灵活的actor-critic框架，基于策略的方法在离策略离散动作RL中可以达到与基于价值方法（DQN）相当的性能。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [149] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: 本文提出HGEN，首个针对异构图的集成学习框架，通过元路径和转换优化，显著提升异构图的分类精度。


<details>
  <summary>Details</summary>
Motivation: 异构图在节点类型、特征和局部邻域拓扑上的异构性，对集成学习，特别是融合多样化图学习器，构成了重大挑战。

Method: HGEN框架通过元路径结合随机丢弃创建Allele图神经网络(GNN)作为基础学习器。为确保有效集成，HGEN引入了两个关键组件：1) 残差注意力机制，用于校准不同元路径的Allele GNN，使节点嵌入关注更有信息的图以提高基础学习器精度；2) 相关性正则化项，用于增大不同元路径生成嵌入矩阵的差异，从而丰富基础学习器的多样性。该方法还分析了收敛性并证明了其比简单投票更高的正则化强度。

Result: 在五个异构网络上的实验验证了HGEN始终以显著优势超越了现有最先进的竞争方法。

Conclusion: HGEN成功地将集成学习应用于异构图，通过创新的元路径处理、注意力机制和正则化策略，有效克服了异构性挑战，并实现了卓越的分类性能。

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [150] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 本文提出一种动态计算分配和策略选择框架，用于优化大型语言模型在推理时的性能，同时兼顾令牌成本和实际延迟，并通过实验证明其优于静态策略。


<details>
  <summary>Details</summary>
Motivation: 现有推理时计算资源动态分配方法主要关注并行生成（如best-of-N），忽略增量解码（如beam search），且只考虑令牌使用量，忽视了对用户体验至关重要的延迟问题。

Method: 将推理时扩展问题建模为动态计算分配和方法选择问题，系统根据每个查询决定应用何种策略及分配多少计算资源。该框架明确整合了令牌成本和实际延迟。

Result: 在推理基准测试中，所提出的方法持续优于静态策略，实现了有利的准确性-成本权衡，并被证明具有实际部署的可行性。

Conclusion: 通过动态优化计算资源分配和策略选择，并同时考虑令牌成本和延迟，本文方法有效提升了LLM的推理性能和效率，为实际应用提供了更优解决方案。

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [151] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 针对耗散动力学系统中相空间变量不可观测的挑战，本文提出一种基于热力学拉格朗日量和仅使用可观测变量的神经网络框架，能有效描述相空间演化并确保熵的非递减。


<details>
  <summary>Details</summary>
Motivation: 现有基于数据的物理系统演化计算方法在可用数据无法完全对应系统相空间变量时面临困难。特别是在耗散动力学系统中，动量和熵等关键变量通常无法直接观测。

Method: 开发了一个完全基于可观测变量的数据计算框架。该框架结合了新颖的“热力学拉格朗日量”方法，并构建了尊重热力学定律且保证熵非递减演化的神经网络。

Result: 该神经网络能够仅使用有限的数据点和相对较少的系统参数，便能有效描述相空间的演化。

Conclusion: 本研究提供了一个高效的数据驱动框架，成功解决了耗散动力学系统中不可观测相空间变量的问题，并能在有限数据下实现热力学一致的系统演化描述。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [152] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 论文提出了LoFT（基于参数高效微调的长尾半监督学习）框架，将长尾半监督学习（LTSSL）与基础模型微调结合，解决传统方法伪标签质量差的问题，并在开放世界场景下提出LoFT-OW，实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有长尾半监督学习（LTSSL）方法通常从头训练模型，导致模型过自信和生成低质量伪标签，限制了其在实际应用中的效果。

Method: 提出LoFT框架，将LTSSL扩展到基础模型微调范式，旨在生成更可靠的伪标签。进一步提出LoFT-OW，用于处理包含域外（OOD）样本的开放世界半监督学习场景，以增强判别能力。

Result: 在多个基准测试上，LoFT方法相较于现有方法取得了卓越的性能。即使仅使用1%的无标签数据，其表现也优于以往工作。

Conclusion: LoFT及其扩展LoFT-OW通过利用基础模型微调，有效提升了长尾半监督学习的伪标签质量和模型泛化能力，尤其在应对开放世界挑战时展现出强大的有效性。

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [153] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: 为解决组合半强盗（CSB）在非二元决策空间中的局限性，本文提出了多重组合半强盗（MP-CSB）问题及其两种算法，分别基于Thompson采样和“两全其美”策略，在随机和对抗环境下均提供了强大的理论悔恨界限，并通过数值实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 组合半强盗（CSB）问题虽应用广泛，但其决策空间仅限于二元，无法处理涉及非负整数流或分配的重要问题，例如最优运输和背包问题。

Method: 本文提出了多重组合半强盗（MP-CSB）问题，允许玩家选择非负整数动作并在每轮中从单个臂观察多次反馈。为此，本文提出了两种算法：1) 一种基于Thompson采样的算法，该算法在动作空间呈指数级大时仍具计算可行性；2) 一种“两全其美”（best-of-both-worlds）算法，该算法旨在同时处理随机和对抗环境。

Result: 基于Thompson采样的算法在随机环境下实现了O(log T)的分布依赖悔恨。而“两全其美”算法在随机环境下实现了O(log T)的方差依赖悔恨，并在对抗环境下实现了最坏情况下~O(sqrt(T))的悔恨，其对抗悔恨还具有数据依赖性，能够适应最优动作的累积损失、总二次变动和损失序列的路径长度。数值实验表明，所提出的算法优于现有的CSB方法。

Conclusion: MP-CSB框架及其提出的算法成功克服了传统CSB在处理非负整数动作方面的局限性，提供了理论上和经验上都表现出色的解决方案，显著扩展了半强盗问题的应用范围。

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [154] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: 该研究探索使用大型语言模型（LLM）生成数值算法代码来解决科学计算任务，而非直接用神经网络预测。论文引入了新的常微分方程（ODE）基准，并发现通过充足的上下文和引导式提示，LLM能够可靠地生成科学上准确且可执行的ODE求解代码。


<details>
  <summary>Details</summary>
Motivation: 现有科学机器学习方法（如物理信息神经网络）在直接预测科学任务目标值时面临准确性和鲁棒性挑战。研究者提出利用LLM编写代码以利用成熟的数值算法，将重心从学习解函数转移到做出领域感知的数值选择。目前缺乏评估LLM作为科学机器学习代理在生成科学计算代码能力方面的基准。

Method: 研究提出LLM可作为SciML代理，根据自然语言的ODE描述生成可运行、科学上适当的代码，包括选择合适的求解器和执行稳定性检查。为此，论文引入了两个新数据集：一个包含“误导性”问题的诊断数据集；一个包含1000个多样化ODE任务的大规模基准。评估了开源和闭源LLM模型，考量了非引导与引导式提示以及开箱即用与微调模型两种情况，测量代码的可执行性和数值有效性。

Result: 研究发现，在提供充足上下文和引导式提示后，新型指令遵循模型在可执行性和数值有效性两方面均表现出高准确性。许多近期开源系统在未微调的情况下表现出色，而较旧或较小的模型则受益于微调。

Conclusion: 初步结果表明，通过精心的提示工程和微调，可以开发出能够可靠解决简单ODE问题的专业LLM代理。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [155] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: 为解决多模态意图识别中跨模态噪声问题，本文提出DyKen-Hyena模型，将音视频线索转化为动态、逐token卷积核，精细调制文本特征提取，在MIntRec基准上取得SOTA，并在域外检测中F1分数提升10.46%。


<details>
  <summary>Details</summary>
Motivation: 多模态意图识别（MIR）虽有效，但跨模态信息中可能存在与意图无关或冲突的内容，限制了性能提升。现有模型大多通过特征融合（如多头注意力）来混合模态，这可能导致语言特征被噪声污染，且未能实现非语言线索对文本意义的细粒度、token级调制。

Method: 引入DyKen-Hyena模型，将问题从传统的特征融合重新定义为处理调制。该模型将音视频线索转换为动态的、逐token的卷积核，直接用于调制文本特征的提取过程。

Result: 在MIntRec和MIntRec2.0基准测试中均取得了最先进（SOTA）的结果。尤其在域外检测方面，F1分数提升了+10.46%。

Conclusion: 该方法通过创建一种根本上更鲁棒的意图表示，有效解决了跨模态噪声和信息冲突问题，从而显著提升了模型的性能，尤其是在处理不确定意图时。

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [156] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 本文提出一种免训练的自适应Token合并框架，通过在运行时选择性合并冗余Token来压缩Transformer表示，显著降低计算和通信成本，同时保持精度，并提升隐私保护，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 大型Transformer模型计算和通信成本高昂，难以部署到资源受限的边缘设备上。

Method: 引入一种免训练的自适应Token合并框架，通过在运行时根据层级相似度阈值选择性合并语义冗余Token来压缩Transformer表示。该方法能根据输入冗余进行数据依赖性调整，并通过贝叶斯优化发现帕累托最优的合并策略，以平衡准确性、推理成本和通信成本。

Result: 在ImageNet分类任务上，实现了与未修改Transformer相同的精度，但FLOPs减少30%，通信成本低于20%。在视觉问答任务上，计算量小于1/3，带宽消耗小于1/10，性能与完整LLaVA模型相当。此外，该方法对不同信道条件具有鲁棒性，并能显著降低模型反演攻击的效率，提供隐私优势。

Conclusion: 该框架为在资源受限的边缘智能场景中部署强大的Transformer模型提供了一个实用且通用的解决方案。

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [157] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine框架通过嵌入规则和双粒度过滤，在数据稀缺领域显著提升了合成表格数据的生成质量，超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有合成表格数据生成方法（如GANs、扩散模型、LLMs）在数据记录稀缺的领域特定数据库中效果有限。特别是基于提示的LLMs难以捕获数据集特定的特征-标签依赖，且常生成冗余数据，导致下游任务性能下降。

Method: 提出ReFine框架，该框架(i)从可解释模型中提取符号化的“if-then”规则并将其嵌入到提示中，以明确引导生成符合领域特定的特征分布；(ii)应用双粒度过滤策略，抑制过采样模式并选择性地细化稀有但信息丰富的样本，以减少分布不平衡。

Result: 在多种回归和分类基准测试中，ReFine持续优于现有最先进方法，回归任务的R平方值绝对提高高达0.44，分类任务的F1分数相对提高10.0%。

Conclusion: ReFine通过结合规则引导的生成和双粒度过滤，有效解决了数据稀缺场景下合成表格数据生成的挑战，显著提升了生成数据的质量和在下游任务中的表现。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [158] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [159] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 研究发现，神经网络缩放律同样适用于深度回归模型，其性能随着数据量增加而显著提升。


<details>
  <summary>Details</summary>
Motivation: 神经缩放律对开发可靠模型至关重要，但在深度回归模型中的应用仍未被充分探索。

Method: 通过一个用于扭曲范德华磁体的参数估计模型，实证研究了深度回归中的神经缩放律，并采用了全连接网络、残差网络和视觉Transformer等多种架构。

Result: 观察到损失与训练数据集大小及模型容量之间存在幂律关系，缩放指数在1到2之间，具体取决于回归参数和模型细节。

Conclusion: 深度回归模型性能可随数据量增加而显著提高，这得益于其一致的缩放行为和较大的缩放指数。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [160] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: 本文提出IDEA，一种自动编码器，用于估计各种线性或非线性流形数据集的内在维度，并能重建原始数据，其核心是引入了投影重建损失。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够准确识别各种线性或非线性流形数据集的潜在内在维度，并能有效重建原始数据的模型。

Method: 引入了内在维度估计自动编码器（IDEA），其结构采用重加权双CancelOut层，将数据投影到潜在空间。关键贡献是引入了“投影重建损失项”，通过评估移除额外潜在维度后的重建质量来指导模型训练。

Result: 在理论基准测试中，IDEA表现出良好的准确性和高通用性，并优于现有最先进的内在维度估计器。此外，成功应用于垂直分辨一维自由表面流的数值解数据，精确估计了其内在维度并重建了原始解。

Conclusion: IDEA是一种鲁棒且通用的方法，能够准确估计多种类型数据集的内在维度，并实现高质量的数据重建，在理论基准和实际应用中均表现出优越性能。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [161] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: 本研究利用SMoE-VAE模型，发现无监督专家路由在数据重建性能上优于有监督路由，能识别出超越人类定义范畴的深层子类别结构，并探讨了数据集大小对专家专业化的影响。


<details>
  <summary>Details</summary>
Motivation: 深度学习可解释性面临的核心挑战是理解神经网络的内部组织。

Method: 提出并探索了一种新颖的稀疏专家混合变分自编码器（SMoE-VAE）架构。在QuickDraw数据集上，通过比较无监督专家路由与基于真实标签的有监督基线进行测试。采用t-SNE可视化和重建分析来研究模型。

Result: 无监督专家路由在重建性能上持续优于有监督基线。专家能够识别出有意义的子类别结构，这些结构常超越人类定义的类别边界。MoE模型揭示了更符合其目标而非预定义标签的基本数据结构。对数据集大小影响的研究，提供了数据量与专家专业化之间权衡的见解。

Conclusion: SMoE-VAE模型通过无监督路由能有效揭示数据中超越人类认知的深层结构，并在重建性能上表现出色，为设计高效的MoE架构提供了指导。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [162] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 本文提出一种针对双字典稀疏编码的低秩编码模型AODL，通过凸松弛和交替优化解决多字典学习的复杂性挑战，实现了更稀疏的解、良好的重建和缺失值填充性能，并揭示了可解释的数据模式。


<details>
  <summary>Details</summary>
Motivation: 稀疏字典编码已广泛应用，但学习数据驱动的字典在多字典场景中面临巨大挑战，因为编码系数需要考虑所有原子组合，导致复杂性高。现有数据无关的分析字典虽高效但可能不如学习字典稀疏和准确。

Method: 提出一个针对双字典场景的低秩编码模型，并分析其数据复杂性，建立了泛化所需的样本数量界限。提出名为AODL的凸松弛解，并证明其精确解等价于原问题的解。通过稀疏编码矩阵和学习字典之间的交替优化来求解AODL，并证明了其收敛性。

Result: 在合成和真实世界数据集中，AODL在数据重建和缺失值填充方面表现出高质量。在相同的重建质量下，AODL学习到的解比非低秩和分析字典基线稀疏高达90%。此外，学习到的字典能揭示样本中存在的模式，提供可解释的见解。

Conclusion: AODL模型有效解决了多字典稀疏编码的复杂性问题，不仅提供了显著更稀疏的解决方案，而且在数据重建和缺失值填充方面性能优异，同时其学习到的字典具有良好的可解释性。

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [163] [Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL](https://arxiv.org/abs/2509.09177)
*Hanyi Mao,Quanjia Xiao,Lei Pang,Haixiao Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose FSPO (Fair Sequence Policy Optimization), a sequence-level
reinforcement learning method for LLMs that enforces length-fair clipping
directly in the importance-sampling (IS) weight space. We revisit
sequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping
is transplanted to sequences: a fixed clip range systematically reweights short
vs. long responses, distorting the effective objective. Theoretically, we
formalize length fairness via a Length Reweighting Error (LRE) and prove that
small LRE yields a directional cosine guarantee between the clipped and true
updates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the
sequence log-IS ratio with a band that applies a KL-corrected drift term and
scales as $\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,
stabilizes training, and outperforms all baselines across multiple evaluation
datasets.

</details>


### [164] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [165] [AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings](https://arxiv.org/abs/2509.09470)
*Om Vishesh,Harshad Khadilkar,Deepak Akkil*

Main category: cs.LG

TL;DR: 本文提出一个全自动系统，利用AI代理（Agent-E）和RPA技术，实现学术文献发现并执行特定任务，经验证在论文识别上达到高召回率和准确率。


<details>
  <summary>Details</summary>
Motivation: 面对学术文献的快速增长，研究人员、资助机构和学术团体在学术发现中面临巨大的手动工作量和时间挑战，亟需自动化解决方案。

Method: 开发了一个全自动系统，包含一个名为'Agent-E'的专业AI代理，负责识别会议论文中来自特定地理区域的论文。随后，系统通过机器人流程自动化（RPA）执行预定义动作，例如提交提名表格。

Result: 系统在来自五个不同会议的586篇论文上进行了验证，成功识别了所有目标论文，召回率为100%，准确率接近完美，达到99.4%。

Conclusion: 该研究展示了任务导向型AI代理不仅能够过滤信息，还能积极参与并加速学术社区工作流程的巨大潜力。

Abstract: Keeping pace with the rapid growth of academia literature presents a
significant challenge for researchers, funding bodies, and academic societies.
To address the time-consuming manual effort required for scholarly discovery,
we present a novel, fully automated system that transitions from data discovery
to direct action. Our pipeline demonstrates how a specialized AI agent,
'Agent-E', can be tasked with identifying papers from specific geographic
regions within conference proceedings and then executing a Robotic Process
Automation (RPA) to complete a predefined action, such as submitting a
nomination form. We validated our system on 586 papers from five different
conferences, where it successfully identified every target paper with a recall
of 100% and a near perfect accuracy of 99.4%. This demonstration highlights the
potential of task-oriented AI agents to not only filter information but also to
actively participate in and accelerate the workflows of the academic community.

</details>


### [166] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [167] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 评估了VBLL与TabPFN结合后的不确定性校准性能，发现原始TabPFN表现更优。


<details>
  <summary>Details</summary>
Motivation: 预测模型在医疗诊断等安全关键领域日益普及，可靠的不确定性估计至关重要。TabPFN是新型表格数据基础模型，VBLL能以最小开销提高不确定性估计。本研究旨在评估VBLL与TabPFN结合后在不确定性校准方面的性能。

Method: 将Variational Bayesian Last Layers (VBLL) 与Tabular Prior-data Fitted Network (TabPFN) 集成，并在三个基准医疗表格数据集上进行实验，比较原始TabPFN和集成VBLL的TabPFN的性能。

Result: 实验结果与预期相反，原始TabPFN在所有数据集的不确定性校准方面均持续优于集成VBLL的TabPFN。

Conclusion: 将VBLL集成到TabPFN中并未改善其不确定性校准性能，原始TabPFN表现更出色。

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [168] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: KAN-SR是一种基于Kolmogorov Arnold Networks (KANs) 的新型符号回归框架，采用分而治之的方法，能有效恢复真实方程并精确建模动态系统。


<details>
  <summary>Details</summary>
Motivation: 符号回归在寻找最佳拟合数学方程时，传统上常依赖遗传编程等方法。本文旨在提出一种基于深度学习的更精确、高效的方法来解决这一问题。

Method: 引入KAN-SR框架，该框架基于Kolmogorov Arnold Networks (KANs) 并遵循分而治之的方法。结合深度学习技术、特定的KANs以及平移对称性和可分离性等简化策略。此外，该框架还与神经控制微分方程结合以建模动态系统。

Result: 1. 成功恢复了Feynman Symbolic Regression for Scientific Discovery (SRSD) 数据集的真实方程。2. 结合神经控制微分方程后，能够精确建模体外生物过程系统的动力学。

Conclusion: KAN-SR框架通过深度学习和KANs的结合，为符号回归问题提供了有效解决方案，并展示了在精确建模生物过程系统及其他工程系统动力学方面的巨大潜力。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [169] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 本文提出一种基于信息几何投影的参数化贝叶斯联邦学习(BFL)个性化框架，通过全局模型向局部模型邻域的投影，实现了全局泛化与局部专业化的可调权衡，并提供了成本低廉的闭式解。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯联邦学习(BFL)在数据异构和隐私约束下，能构建个性化且可靠的模型。现有方法（MCMC或变分推断）常需个性化机制，但缺乏一种在参数化BFL中高效且可调控全局-局部权衡的个性化方案。

Method: 提出一种参数化BFL的信息几何投影框架。该方法将全局模型投影到用户局部模型的邻域，实现全局泛化与局部专业化的可调权衡。在温和假设下，此投影等同于在统计流形上计算重心，从而导出了闭式解，实现了无成本的个性化。此方法应用于使用IVON优化器的变分学习设置，并扩展到BFL的通用聚合方案。

Result: 在异构数据分布下的实证评估表明，该方法能够有效平衡全局和局部性能，且计算开销极小。

Conclusion: 所提出的信息几何投影框架为参数化BFL提供了一种有效且计算高效的个性化方法，能灵活调整全局泛化与局部专业化之间的权衡，且具有极低的计算成本。

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [170] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 论文提出了BenchECG，一个用于心电图（ECG）基础模型的标准化评估基准，并介绍了xECG模型。xECG结合xLSTM和SimDINOv2自监督学习，在BenchECG上表现最佳，解决了现有评估不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 当前ECG基础模型的评估缺乏一致性，现有工作常使用狭窄的任务选择和不一致的数据集，阻碍了公平比较和研究进展。

Method: 1. 引入BenchECG，一个包含全面公开ECG数据集和多样化任务的标准化基准。 2. 提出了xECG模型，它是一个基于xLSTM的循环模型，通过SimDINOv2自监督学习进行训练。

Result: xECG在BenchECG上取得了最佳分数，优于所有公开可用的最先进模型。xECG是唯一能在所有数据集和任务上都表现出色的公开模型。

Conclusion: BenchECG通过标准化评估，促进了心电图表示学习的严格比较和加速进展。xECG的卓越性能为未来的ECG基础模型定义了一个新的基线。

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [171] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: FedBiF是一种联邦学习新框架，通过在本地训练期间直接学习量化模型参数，并采用逐位更新策略，显著降低通信开销，同时保持模型精度和促进稀疏性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）存在巨大的通信开销，现有通过量化模型更新来缓解此问题的方法，通常在本地训练后进行量化，导致量化误差并可能降低模型精度。

Method: 本文提出了FedBiF，一种在本地训练中直接学习量化模型参数的FL框架。服务器首先量化参数并传输给客户端；客户端每次只更新多比特参数表示中的一位，冻结其余位，实现逐位更新策略，将每次参数更新减少到1比特同时保持高精度表示。

Result: 在IID和Non-IID设置下的五个数据集上的广泛实验表明，FedBiF不仅实现了卓越的通信压缩，还促进了模型稀疏性。即使上行链路使用1比特/参数（bpp）、下行链路使用3 bpp，FedBiF也能达到与FedAvg相当的精度。

Conclusion: FedBiF通过独特的逐位更新策略，成功地将量化融入本地训练过程，有效解决了联邦学习的通信效率问题，同时保持了高模型精度并实现了模型稀疏性。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [172] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 提出一种基于联邦多智能体强化学习 (Fed-MARL) 的框架，通过跨层编排实现6G边缘网络中能效高、隐私保护且实时的资源管理。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络向超密集、智能边缘环境发展，在严格的隐私、移动性和能耗限制下，高效的资源管理变得至关重要。

Method: 引入一种新颖的Federated Multi-Agent Reinforcement Learning (Fed-MARL) 框架，该框架结合了MAC层和应用层的跨层编排。每个智能体使用深度循环Q网络 (DRQN) 基于局部观测学习去中心化策略，用于任务卸载、频谱接入和CPU能耗适应。为保护隐私，引入基于椭圆曲线Diffie Hellman密钥交换的安全聚合协议。将资源管理问题建模为部分可观察多智能体马尔可夫决策过程 (POMMDP)，采用多目标奖励函数共同优化延迟、能效、频谱效率、公平性和可靠性。

Result: 仿真结果表明，Fed-MARL在任务成功率、延迟、能效和公平性方面优于集中式MARL和启发式基线，同时确保了动态、资源受限的6G边缘网络中的稳健隐私保护和可扩展性。

Conclusion: 所提出的Fed-MARL框架能够有效地在6G边缘网络中实现能源效率高、隐私保护且实时的资源管理，并在多方面性能上超越现有方法。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [173] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 提出一种通过神经网络将综合征测量近似为连续函数来重新优化表面码解码器的方法，显著提高了解码精度，证明了将解码问题转化为回归问题的有效性。


<details>
  <summary>Details</summary>
Motivation: 实用量子计算离不开量子纠错，表面码是一种有前景的方法，但现有解码器因预测非唯一性仅能提供错误概率分布，导致解码效果不佳。

Method: 通过神经网络数学插值，将综合征测量近似为连续函数，进而对解码器模型进行重新优化。在代码距离为5和7的多层感知机解码器，以及代码距离为5的卷积神经网络、循环神经网络和Transformer解码器上进行了评估。

Result: 在所有测试情况下，重新优化后的解码器均比原始模型获得了更高的精度，证明了该方法对代码距离和网络架构的普遍有效性。

Conclusion: 将表面码解码问题重新定义为深度学习可以解决的回归问题是一种有用的策略。

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [174] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [175] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 本文提出一个可扩展的混合CNN-Transformer框架，用于高分辨率3D物理模拟的确定性和概率性神经替代模型，在速度和准确性上显著优于现有架构，并能高效处理大规模数据和进行概率采样。


<details>
  <summary>Details</summary>
Motivation: 为高分辨率3D物理模拟开发可扩展、高效且准确的神经替代模型，以克服现有方法在速度、准确性和资源消耗上的限制。

Method: 引入一种混合CNN-Transformer骨干架构；采用小补丁预训练和融合策略以获得全局解，并可通过序列到序列模型处理长程依赖；模型可在同时学习14种不同3D偏微分方程动力学时与基线方法进行评估；利用扩散模型进行概率性采样。

Result: 在速度和准确性上显著优于现有架构；大幅降低高分辨率数据集的内存和计算需求；成功扩展到高达512^3空间分辨率的各向同性湍流；作为扩散模型能准确捕捉不同雷诺数下3D湍流通道流的统计特性。

Conclusion: 所提出的混合CNN-Transformer框架为高分辨率3D物理模拟提供了一个可扩展、多功能且高性能的神经替代解决方案，在确定性和概率性建模方面均表现出色，并有效解决了大规模数据集的挑战。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [176] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 本文提出一种新颖的集成学习框架，通过在损失函数中明确纳入边际方差，并优化在单位球面上的集成权重，以解决传统方法的局限性，提高模型泛化能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于边际的集成方法忽视了边际方差，限制了模型的泛化能力并增加了过拟合风险；同时，在概率单纯形中优化集成权重存在计算效率低下和可扩展性问题。

Method: 引入一种将边际方差明确纳入损失函数的集成学习框架；联合优化负期望边际及其方差；通过将集成权重重新参数化到单位球面上，简化了优化过程并提高了计算效率。

Result: 在多个基准数据集上的实验表明，所提出的方法持续优于传统的基于边际的集成技术。

Conclusion: 该框架通过有效解决传统集成学习方法的局限性，显著提高了模型的鲁棒性、泛化能力和计算效率，具有重要的实用价值。

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [177] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的管道，用于根据飞行参数估计飞机机翼的疲劳寿命，以补充传统方法并减少昂贵的仿真。


<details>
  <summary>Details</summary>
Motivation: 飞机疲劳寿命预测对设计和运行安全至关重要。传统方法可靠但耗时且复杂，需要大量计算和人力资源。机器学习有望提供更快、更通用、更经济的预测，以辅助传统方法。

Method: 开发了一个基于机器学习的管道，利用飞机的飞行参数来预测不同机翼位置的疲劳寿命。该管道在一个真实的疲劳寿命估计用例中进行了验证，并进行了统计验证和不确定性量化。

Result: 该管道在实际用例中产生了准确的预测，并伴有全面的统计验证和不确定性量化。

Conclusion: 所提出的机器学习管道是对传统方法的有效补充，能够减少昂贵的仿真次数，从而降低所需的计算和人力资源。

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [178] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 研究发现，简单的提示注入能有效操纵LLM生成的同行评审分数，使其接受率高达100%；同时，LLM评审本身普遍存在偏向接受的倾向（接受率超95%），这两种情况都对LLM在同行评审中的应用讨论有重大影响。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM在科学同行评审中的应用日益增多，以及近期有报告指出作者利用隐藏提示注入操纵评审分数，本文旨在调查此类操纵的可行性和技术成功率，因为其存在将对LLM在评审中的未来辩论产生重大影响。

Method: 通过对由多种LLM生成的1000份2024年ICLR论文评审进行系统评估。

Result: 1) 非常简单的提示注入确实高效，能使接受率高达100%。2) LLM生成的评审普遍存在接受倾向（许多模型中接受率超过95%）。

Conclusion: 上述两项研究结果都对LLM在同行评审中的应用讨论产生了巨大影响。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [179] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 本研究提出了一个结合神经推荐系统和迁移学习的数据驱动框架，用于在实验数据稀疏的情况下准确预测离子液体的热物理性质，并实现了对大量IL组合的 scalable 预测。


<details>
  <summary>Details</summary>
Motivation: 离子液体的热物理性质预测因其庞大的化学设计空间和有限的实验数据而面临巨大挑战。

Method: 采用两阶段迁移学习框架：首先，使用COSMO-RS模拟数据预训练神经推荐系统（NRS）模型，学习离子结构嵌入；其次，利用这些嵌入和稀疏实验数据微调前馈神经网络，预测密度、粘度、表面张力、热容和熔点等五种IL性质。该框架支持性质内部和跨性质知识迁移。

Result: 模型显著提高了四种目标性质的预测性能，对未见过的离子液体具有鲁棒的泛化能力，并能预测超过700,000种IL组合的性质，为过程设计中的IL筛选提供了可扩展的解决方案。

Conclusion: 本工作强调了结合模拟数据和迁移学习在克服实验数据稀疏性方面的有效性。

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [180] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: 本文提出CDQAC，一种新颖的离线强化学习算法，用于解决作业车间调度问题(JSP/FJSP)。它能直接从历史数据中学习高效的调度策略，避免了在线RL对大量模拟交互的需求，并展现出卓越的样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的在线强化学习方法在解决JSP和FJSP时，需要与模拟环境进行数百万次交互，且初始化策略随机导致样本效率低下，无法很好地捕捉真实世界的复杂性。研究目标是开发一种能直接从历史数据中学习，无需昂贵在线交互，并能改进次优训练数据的算法。

Method: 引入了保守离散分位数Actor-Critic (CDQAC)，这是一种新型的离线强化学习算法。CDQAC结合了基于分位数的值函数（critic）和延迟的策略更新，它估计每个机器-操作对的回报分布，而非直接选择对。

Result: CDQAC能够从多样化的数据源中有效学习，持续优于原始数据生成启发式算法，并超越了最先进的离线和在线RL基线。它具有高度的样本效率，仅需10-20个训练实例即可学习高质量策略。令人惊讶的是，CDQAC在随机启发式生成的数据上训练时表现优于在遗传算法和优先调度规则等更高质量数据上训练的表现。

Conclusion: CDQAC是一种高效、样本高效的离线强化学习算法，能够从历史数据中学习JSP和FJSP的调度策略，成功解决了现有在线RL方法的局限性。其在多样化数据上的优异表现，特别是从随机数据中学习的能力，证明了其在工业应用中的巨大潜力。

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [181] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 本文提出GraphCSVAE模型，结合深度学习和图表示，利用时间序列卫星数据对灾后物理脆弱性进行数据驱动的建模和监测，为风险减缓提供见解。


<details>
  <summary>Details</summary>
Motivation: 许多机构难以持续监测灾害风险变化，特别是在物理脆弱性建模方面进展有限，这限制了对联合国《仙台框架》进展的评估能力。

Method: 引入了Graph Categorical Structured Variational Autoencoder (GraphCSVAE)框架，该框架整合了深度学习、图表示和分类概率推断，并利用时间序列卫星数据和先验专家知识。研究还引入了一个弱监督的一阶转移矩阵来反映物理脆弱性的时空分布变化，并应用于孟加拉国和塞拉利昂的受灾地区。

Result: 研究揭示了两个受灾且社会经济弱势地区（孟加拉国的Khurushkul社区和塞拉利昂的弗里敦市）灾后物理脆弱性的区域动态变化。

Conclusion: 本工作为灾后风险减缓提供了关于局部时空审计和可持续策略的宝贵见解。

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [182] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 提出一个受ARIMA启发的简单高效卷积模块，用于长期时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 旨在解决长期时间序列预测问题，并提供一个结构简单、性能优异的解决方案。

Method: 引入一个卷积模块，包含两个卷积组件：一个用于捕获趋势（自回归），另一个用于细化局部变化（移动平均）。该模块可直接进行多步预测，并易于扩展到多元时间序列。

Result: 在九个基准数据集上取得了有竞争力的准确性，特别是在趋势变化强的数据集上表现出色，同时保持了架构的简洁性。此外，该模块能固有地编码绝对位置信息。

Conclusion: 该模块有望成为序列模型中位置嵌入的轻量级替代方案。

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [183] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于条件神经惠特尼形式（CNWF）和数字孪生的机器学习框架，结合有限元外微分（FEEC）和Transformer算子学习，用于流体动力-传输系统中的自适应源定位、实时轨迹规划和数据同化。


<details>
  <summary>Details</summary>
Motivation: 在流体动力-传输系统中实现自适应源定位，同时确保物理一致性和数值鲁棒性，以提高在复杂几何环境中的定位精度并支持实时决策。

Method: 构建了一个结构保持的数字孪生模型，该模型基于条件神经惠特尼形式（CNWF），结合了有限元外微分（FEEC）的数值保证和Transformer的算子学习能力。模型通过条件注意力机制识别简化的基和源场。提出了一种交错方案，交替评估数字孪生和应用Lloyd算法优化传感器放置，并利用预测源场进行最优恢复。

Result: 模型保留了离散守恒性，并能实时适应传感器数据。产生的降阶环境模型保持了标准有限元模拟的稳定性和一致性，实现了从传感器数据到源场的物理可实现的正则映射。实验证明，强制物理约束（结构保持）显著提高了复杂几何结构中源定位的准确性，优于不含物理先验的Transformer架构，并实现了点源的恢复。

Conclusion: 结构保持（通过FEEC和CNWF实现）为源识别提供了有效的归纳偏置，从而提高了复杂几何环境中的定位精度并产生了物理上可实现的模型。该框架成功实现了自适应源定位和传感器优化布局。

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [184] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架，通过引入差异度概念重新定义数据集凝聚（DC），将其目标从泛化性能扩展到鲁棒性、隐私等更广泛的属性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集凝聚（DC）方法主要关注模型的泛化性能。研究动机在于需要一个更通用、更正式的DC定义，以整合现有方法，并扩展其目标，纳入鲁棒性、隐私等额外的期望属性。

Method: 本文提出一个统一框架，通过使用“差异度”（discrepancy）概念来量化概率分布之间的距离，对DC进行更通用和正式的定义。这种方法旨在将DC的目标从传统的任务特定泛化性能扩展。

Result: 本文构建了一个涵盖现有DC方法的统一框架，并提供了一个更通用、更正式的DC定义。

Conclusion: 该框架成功将DC的目标从单一的泛化能力扩展到包含鲁棒性、隐私及其他期望属性，从而拓宽了DC的应用范围和理论基础。

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [185] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: 对比学习的性能受预训练队列组成影响。多中心多样化队列虽提升分布内准确性，但会损害分布外泛化能力。本研究提出IDB策略以增强OOD鲁棒性，为开发公平且泛化的基础模型提供见解。


<details>
  <summary>Details</summary>
Motivation: 对比学习作为一种自我监督预训练策略，其性能对队列组成（如人口统计学、健康状况、人口多样性）的依赖性尚未得到充分探索。

Method: 提出了名为CAPE的基础模型，并在来自三大洲（北美、南美、亚洲）的四个多样化队列（n=5,203,352）上进行预训练。系统评估队列的人口统计学、健康状况和多样性如何影响下游预测任务的性能，评估时还引入了来自欧洲的额外两个队列。为解决OOD泛化问题，提出了“同分布批次（IDB）”策略，旨在保持队列内一致性。

Result: 研究发现下游性能取决于预训练队列的分布特性，包括人口统计学和健康状况。尽管使用多中心、人口多样化队列进行预训练可提高分布内准确性，但会因编码队列特有伪影而降低对比学习方法的分布外（OOD）泛化能力。所提出的IDB策略能够保持队列内一致性并增强OOD鲁棒性。

Conclusion: 本工作为开发临床公平且可泛化的基础模型提供了重要见解，并提出了一种有效策略来提升对比学习模型的分布外泛化能力。

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [186] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 将整流流（rectified flow）扩展到无限维希尔伯特空间，并在此基础上发展出新的函数生成模型，该模型在理论上更具普适性，并在实验中表现出卓越性能。


<details>
  <summary>Details</summary>
Motivation: 许多有限维生成模型已有无限维泛化，但整流流在无限维空间中的扩展仍是未被探索的空白。

Method: 本研究基于无限维空间中连续性方程的叠加原理，建立了整流流的严格函数公式。该框架自然地扩展到函数流匹配（functional flow matching）和函数概率流ODE（functional probability flow ODE）。

Result: 该框架将函数流匹配和函数概率流ODE解释为整流流的非线性泛化，并移除了现有函数流匹配理论中限制性的测度论假设。实验证明，本方法相比现有函数生成模型取得了更优异的性能。

Conclusion: 成功地将整流流严谨地推广到无限维希尔伯特空间，提供了一个更广泛且理论上更稳健的函数生成模型框架，并通过实验验证了其优越性。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [187] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 提出VIG主动学习策略，通过考虑数据集整体不确定性，仅用少量标注数据便在相机陷阱图像物种识别中取得接近全监督的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 相机陷阱图像数据中的物种识别因标注资源有限成为生态研究的主要瓶颈。现有主动学习方法通常只关注个体预测的不确定性，未考虑整个数据集的不确定性。

Method: 引入一种新的主动学习策略——Vendi信息增益（VIG），它根据图像对数据集整体预测不确定性的影响来选择数据，同时兼顾了信息性和多样性。

Result: 在Snapshot Serengeti数据集上，VIG仅使用不到10%的标注数据就实现了接近完全监督的预测精度。它在各种指标和批量大小下均持续优于标准基线，并在特征空间中收集到更多样化的数据。

Conclusion: VIG对数据受限环境中的生物多样性监测具有重要价值，并且具有超越生态学领域的广泛适用性。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [188] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: 本文提出IGPO框架，利用掩码扩散大语言模型（dLLMs）的inpaint能力，通过插入部分真实推理路径来指导强化学习探索，有效解决了稀疏奖励和样本浪费问题，并在数学基准上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型与强化学习结合时，面临探索效率低下的挑战，表现为稀疏的奖励信号和模型未能发现正确解决方案时的样本浪费。dLLMs的inpaint能力提供了一个独特的机会来指导探索。

Method: 引入了IGPO（Inpainting Guided Policy Optimization）强化学习框架，该框架在在线采样期间策略性地插入部分真实推理路径。这利用了dLLMs的inpaint能力引导探索走向有前景的轨迹空间，同时保留了自生成的推理。IGPO应用于GRPO等基于组的优化方法，以恢复有意义的梯度并提高样本效率。此外，还提出了对合成重写过的简洁轨迹进行监督微调，并结合了基于熵的过滤等额外技术。

Result: 所提出的训练方法在GSM8K、Math500和AMC三个数学基准测试上取得了显著的性能提升。为全注意力掩码dLLMs实现了新的最先进（SOTA）结果。

Conclusion: 通过利用dLLMs的inpaint能力并结合IGPO框架及其他优化技术，有效解决了RL探索效率低的问题，并在数学任务上取得了当前最佳性能，为dLLMs的强化学习对齐提供了有效途径。

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [189] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [190] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 本文提出一种利用过程挖掘和无监督机器学习在运行时检测和定位ERMTS/ETCS L2铁路系统控制流异常的方法，以增强系统韧性。


<details>
  <summary>Details</summary>
Motivation: 计算机化铁路系统日益复杂和关键，尽管经过严格的验证和确认，运行时仍可能出现由残余故障、未知系统或环境变化以及新兴网络威胁导致的异常，因此提高系统韧性至关重要。

Method: 该研究采用过程挖掘技术从系统执行轨迹中学习实际控制流，并通过在线一致性检查实现运行时监控。此外，还利用无监督机器学习进行异常定位，将偏差与关键系统组件关联起来。

Result: 该方法在ERTMS/ETCS L2的RBC/RBC切换场景中进行了测试，结果表明其在检测和定位异常方面具有高准确性、高效率和可解释性。

Conclusion: 所提出的基于过程挖掘和无监督机器学习的运行时异常检测和定位方法，能有效增强计算机化铁路系统的韧性。

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [191] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: 本文深入研究了分布式机器学习中Local SGD算法的外部优化器，提供了新的收敛性保证，并揭示了外部学习率（包括动量和加速）在优化误差、梯度噪声和收敛速度方面的关键作用，实验验证了理论发现。


<details>
  <summary>Details</summary>
Motivation: 现代大规模机器学习面临通信瓶颈，Local SGD是解决此问题的一种有效方法。尽管局部优化超参数已得到广泛研究，但Local SGD中外部优化器及其超参数的选择和影响尚不明确。

Method: 通过理论分析研究Local SGD中外部优化器的作用，推导新的收敛性保证。具体分析了调整外部学习率的影响，并将其推广到使用动量和加速的外部优化器。此外，引入了一种新颖的数据依赖分析方法，并通过对标准语言模型和多种外部优化器进行综合实验来验证理论。

Result: 研究发现，调整外部学习率可以平衡优化误差和随机梯度噪声方差，并能弥补内部学习率的不当调整。理论表明，外部学习率有时应设置为大于1的值。外部优化器中的动量调整学习率也扮演类似角色。外部优化器中的加速能提高通信轮数函数下的收敛速度，优于局部加速。数据依赖分析提供了关于外部学习率调整的进一步见解。所有理论发现均通过实验得到验证。

Conclusion: 外部优化器及其学习率（包括动量和加速）在Local SGD的收敛性和效率中扮演着至关重要的角色。适当调整外部学习率可以有效管理优化误差和噪声，补偿内部学习率问题，并且有时需要大于1的值。在外部优化器中使用加速能显著提升通信效率下的收敛速度。这些理论和实验结果为Local SGD的超参数选择提供了重要指导。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [192] [DBOS Network Sensing: A Web Services Approach to Collaborative Awareness](https://arxiv.org/abs/2509.09898)
*Sophia Lockton,Jeremy Kepner,Michael Stonebraker,Hayden Jananthan,LaToya Anderson,William Arcand,David Bestor,William Bergeron,Alex Bonn,Daniel Burrill,Chansup Byun,Timothy Davis,Vijay Gadepally,Michael Houle,Matthew Hubbell,Michael Jones,Piotr Luszczek,Peter Michaleas,Lauren Milechin,Chasen Milner,Guillermo Morales,Julie Mullen,Michel Pelletier,Alex Poliakov,Andrew Prout,Albert Reuther,Antonio Rosa,Charles Yee,Alex Pentland*

Main category: cs.NI

TL;DR: DBOS通过集成高性能网络感知功能（利用GraphBLAS实现）提升了其网络服务的韧性和安全性，并通过实验证明了其低开销和良好的扩展性，实现协作网络感知仅需可忽略的额外计算资源。


<details>
  <summary>Details</summary>
Motivation: DBOS旨在通过整合Web服务、操作系统和数据库功能来降低Web部署难度并提高系统韧性。研究动机是进一步通过集成高性能网络感知，使DBOS Web服务能够协作创建共享网络环境感知，从而增强其整体韧性和安全性。

Method: 将网络感知功能通过GraphBLAS超稀疏流量矩阵集成到DBOS中，采用了Python-GraphBLAS和OneSparse PostgreSQL两种实现方法。系统使用pPython进行并行化，并在MIT SuperCloud的64个计算节点上进行了基准测试。通过IEEE/MIT/Amazon匿名网络感知图挑战的工作流和分析验证了这些能力。

Result: 单个DBOS实例的Web请求速率超过10^5次/秒，表明添加网络感知功能的开销可以忽略不计。为实现协作感知，多个DBOS实例连接到一个DBOS聚合器。Python-GraphBLAS实现能够线性扩展到64个节点，而OneSparse PostgreSQL实现则能线性扩展到32个节点。

Conclusion: DBOS能够以可忽略的开销集成网络感知功能，显著增强其网络服务的集体韧性和安全性。实现DBOS协作网络感知所需的计算资源增加可忽略不计。

Abstract: DBOS (DataBase Operating System) is a novel capability that integrates web
services, operating system functions, and database features to significantly
reduce web-deployment effort while increasing resilience. Integration of high
performance network sensing enables DBOS web services to collaboratively create
a shared awareness of their network environments to enhance their collective
resilience and security. Network sensing is added to DBOS using GraphBLAS
hypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)
OneSparse PostgreSQL. These capabilities are demonstrated using the workflow
and analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph
Challenge. The system was parallelized using pPython and benchmarked using 64
compute nodes on the MIT SuperCloud. The web request rate sustained by a single
DBOS instance was ${>}10^5$, well above the required maximum, indicating that
network sensing can be added to DBOS with negligible overhead. For
collaborative awareness, many DBOS instances were connected to a single DBOS
aggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations
scaled linearly up to 64 and 32 nodes respectively. These results suggest that
DBOS collaborative network awareness can be achieved with a negligible increase
in computing resources.

</details>


### [193] [Taming Volatility: Stable and Private QUIC Classification with Federated Learning](https://arxiv.org/abs/2509.09997)
*Richard Jozsa,Karel Hynek,Adrian Pekar*

Main category: cs.NI

TL;DR: 本文提出客户端数据缓冲区机制，以解决联邦学习在网络流量时间波动性下的模型训练不稳定性问题，并在QUIC分类任务上实现了接近中心化模型的高性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习研究忽视了网络流量的时间波动性（如日常潮汐现象），这导致客户端数据可用性不稳定，进而影响模型训练的稳定性。本研究旨在系统性地解决联邦QUIC分类中的时间波动性问题。

Method: 首先，展示了标准联邦学习在动态流量设置下的不稳定性。其次，提出并评估了一种客户端数据缓冲区作为实用机制，以确保稳定一致的本地训练，使其与实时流量波动解耦。

Result: 在真实CESNET-QUIC22数据集上，该方法实现了鲁棒收敛。稳定的联邦系统F1分数达到95.2%，仅比非隐私的中心化模型低2.3个百分点。

Conclusion: 本工作为构建网络管理中操作稳定的联邦学习系统提供了蓝图，证明通过有针对性的架构选择可以克服动态网络环境的挑战。

Abstract: Federated Learning (FL) is a promising approach for privacy-preserving
network traffic analysis, but its practical deployment is challenged by the
non-IID nature of real-world data. While prior work has addressed statistical
heterogeneity, the impact of temporal traffic volatility-the natural daily ebb
and flow of network activity-on model stability remains largely unexplored.
This volatility can lead to inconsistent data availability at clients,
destabilizing the entire training process. In this paper, we systematically
address the problem of temporal volatility in federated QUIC classification. We
first demonstrate the instability of standard FL in this dynamic setting. We
then propose and evaluate a client-side data buffer as a practical mechanism to
ensure stable and consistent local training, decoupling it from real-time
traffic fluctuations. Using the real-world CESNET-QUIC22 dataset partitioned
into 14 autonomous clients, we then demonstrate that this approach enables
robust convergence. Our results show that a stable federated system achieves a
95.2% F1 score, a mere 2.3 percentage points below a non-private centralized
model. This work establishes a blueprint for building operationally stable FL
systems for network management, proving that the challenges of dynamic network
environments can be overcome with targeted architectural choices.

</details>


### [194] [Service Function Chaining Architecture for Multi-hop Split Inference and Learning](https://arxiv.org/abs/2509.10001)
*Takanori Hara,Masahiro Sasabe*

Main category: cs.NI

TL;DR: 提出一种基于服务功能链（SFC）的架构，将分割子模型视为服务功能，用于多跳分割推理（MSI）和多跳分割学习（MSL），以实现高效、动态且自适应的机器学习处理。


<details>
  <summary>Details</summary>
Motivation: SFC能够为网络服务提供动态高效的通信路径。受此启发，研究旨在将SFC概念应用于多跳分割推理和学习，以确保子模型执行的效率和自适应性。

Method: 提出一个基于SFC的架构，将分割子模型解释为服务功能。为此，设计了神经服务功能（NSFs）作为透明TCP代理来执行分割子模型，并将其与基于IPv6分段路由（SRv6）和扩展Berkeley包过滤器（eBPF）的SFC代理集成，以在动态路由上实现高效的ML处理。

Result: 1. 所提出的架构在MSI和MSL中均可行。2. 特别适用于小批量实时推理的MSI场景。3. 支持动态路径重配置，能够适应网络变化，同时最小化控制机制对推理和学习过程的影响。

Conclusion: 该基于SFC的架构为多跳分割推理和学习提供了一个可行、高效且自适应的解决方案，特别适用于实时推理和动态网络环境，并通过动态路径重配置优化了性能。

Abstract: Service Function Chaining (SFC) is a networking technique that ensures
traffic traverses a predefined sequence of service functions, realizing
arbitrary network services through dynamic and efficient communication paths.
Inspired by this concept, we propose an SFC-based architecture for Multi-hop
Split Inference (MSI), where split sub-models are interpreted as service
functions and their composition forms a service chain representing the global
model. By leveraging SFC, the proposed architecture dynamically establishes
communication paths for split sub-models, ensuring efficient and adaptive
execution. Furthermore, we extend this architecture to Multi-hop Split Learning
(MSL) by applying SFC to the bidirectional communication required for training
tasks. To realize the proposed architecture, we design Neural Service Functions
(NSFs) to execute split sub-models as transparent TCP proxies and integrate
them with Segment Routing over IPv6 (SRv6) and the extended Berkeley Packet
Filter (eBPF)-based SFC proxy. This integration ensures efficient ML processing
over dynamic routing while maintaining compatibility with existing
applications. Evaluation results demonstrate that (1) the proposed architecture
is feasible for both MSI and MSL; (2) it is particularly suitable for real-time
inference in MSI scenarios with small mini-batch sizes; (3) it supports dynamic
path reconfiguration, enabling adaptive responses to changing network
conditions while minimizing the impact of control mechanisms on inference and
learning processes.

</details>


### [195] [Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and Digital Twin Integration](https://arxiv.org/abs/2509.10097)
*Ahmed Al-Tahmeesschi,Yi Chu,Gurdeep Singh,Charles Turyagyenda,Dritan Kaleshi,David Grace,Hamed Ahmadi*

Main category: cs.NI

TL;DR: 本文提出一个结合启发式方法和无监督机器学习的混合xApp，并利用数字孪生技术，动态管理O-RAN中的RU睡眠模式以降低能耗。在仿真环境中实现了约13%的能耗节约，且不影响服务质量。


<details>
  <summary>Details</summary>
Motivation: 5G及未来网络对高速、超可靠、低延迟通信的需求导致RAN，特别是无线电接入单元（RU）的功耗显著增加，给运营商带来了运营和可持续性挑战。尽管O-RAN提供了灵活性和互操作性，但其解耦架构增加了功耗管理的复杂性。因此，需要创新方案在不损害服务质量（QoS）的前提下提高能效。

Method: 本文提出了一个混合xApp，它结合了启发式方法和无监督机器学习。该xApp通过TeraVM AI RAN场景生成器（AI-RSG）与数字孪生技术集成，用于动态管理RU的睡眠模式，从而有效降低能耗。

Result: 在真实且大规模的模拟Open RAN场景中进行的实验评估表明，该混合xApp实现了约13%的能耗节约，并且没有损害用户服务质量。

Conclusion: 该混合xApp具有实用性，在实际部署中具有显著潜力，能够有效降低O-RAN的能耗，同时保持用户服务质量。

Abstract: The growing demand for high-speed, ultra-reliable, and low-latency
communications in 5G and beyond networks has significantly driven up power
consumption, particularly within the Radio Access Network (RAN). This surge in
energy demand poses critical operational and sustainability challenges for
mobile network operators, necessitating innovative solutions that enhance
energy efficiency without compromising Quality of Service (QoS). Open Radio
Access Network (O-RAN), spearheaded by the O-RAN Alliance, offers
disaggregated, programmable, and intelligent architectures, promoting
flexibility, interoperability, and cost-effectiveness. However, this
disaggregated approach adds complexity, particularly in managing power
consumption across diverse network components such as Open Radio Units (RUs).
In this paper, we propose a hybrid xApp leveraging heuristic methods and
unsupervised machine learning, integrated with digital twin technology through
the TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically
manages RU sleep modes to effectively reduce energy consumption. Our
experimental evaluation in a realistic, large-scale emulated Open RAN scenario
demonstrates that the hybrid xApp achieves approximately 13% energy savings,
highlighting its practicality and significant potential for real-world
deployments without compromising user QoS.

</details>


### [196] [Secure and Scalable Rerouting in LEO Satellite Networks](https://arxiv.org/abs/2509.10173)
*Lyubomir Yanev,Pietro Ronchetti,Joshua Smailes,Martin Strohmeier*

Main category: cs.NI

TL;DR: 针对LEO卫星网络弹性路由挑战，本文比较了不同故障感知级别的重路由策略，发现分段式重路由在弹性与开销间实现了良好平衡，为未来网络设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 大型LEO卫星网络中，频繁且不可预测的链路和节点故障（可能源于网络安全攻击）使弹性路由成为关键挑战。现有重路由策略在动态故障条件下的权衡尚未充分探索。

Method: 扩展Deep Space Network Simulator (DSNS)，系统比较了四种重路由方案：局部邻居式、分段式、全局知识式以及不感知故障的朴素源路由。评估了故障感知广度对路由性能和弹性的影响，衡量指标包括传输成功率、延迟、重路由开销和环路发生率。

Result: 研究发现，分段式重路由在局部响应性和全局协调之间取得了有利的权衡，以最小开销提供了显著的弹性效益。

Conclusion: 分段式重路由的潜力可为未来容错卫星网络的设计提供重要启示。

Abstract: Resilient routing in large-scale Low Earth Orbit (LEO) satellite networks
remains a key challenge due to frequent and unpredictable link and node
failures, potentially in response to cybersecurity breaches. While prior work
has explored rerouting strategies with various levels of network awareness,
their relative tradeoffs under dynamic failure conditions remain underexplored.
In this work, we extend the Deep Space Network Simulator (DSNS) to
systematically compare three rerouting paradigms, each differing in the scope
of failure knowledge available to each node. We compare local neighbor-based,
segment-based and global-knowledge-based rerouting as well as a naive source
routing solution that is unaware of failures. Our main goal is to evaluate how
the breadth of failure awareness impacts routing performance and resilience
under failures, both random and targeted. We measure delivery ratio, latency,
rerouting overhead, and loop occurrence. Our findings show the potential of
segment-based rerouting to achieve a favorable tradeoff between local
responsiveness and global coordination, offering resilience benefits with
minimal overhead--insights that can inform future fault-tolerant satellite
network design.

</details>


### [197] [Friend or Foe? Identifying Anomalous Peers in Moneros P2P Network](https://arxiv.org/abs/2509.10214)
*Yannik Kopyciok,Stefan Schmid,Friedhelm Victor*

Main category: cs.NI

TL;DR: 首次全面研究Monero P2P网络中的异常行为，发现约14.74%的节点存在非标准行为，可能表明潜在攻击，损害Monero的隐私和去中心化。


<details>
  <summary>Details</summary>
Motivation: Monero网络中存在伪装成正常节点的监控或窥探节点，但对异常节点行为的检测和分析理解有限。

Method: 收集了全球五个不同观察点超过240小时的网络流量，提出了一个正式框架来定义和分类P2P加密货币网络中的异常模式，并实施了离线检测方法。

Result: 网络中约有14.74%（可达节点为13.19%）的节点表现出非标准行为。这些节点具有独特的行为模式，可能暗示多重并发攻击，揭示了Monero隐私保障和网络去中心化方面的重大缺陷。

Conclusion: Monero的隐私保障和网络去中心化存在显著不足。为支持复现性并帮助网络运营商防御，研究发布了检测和阻止可疑节点的检查工具。

Abstract: Monero, the leading privacy-focused cryptocurrency, relies on a peer-to-peer
(P2P) network to propagate transactions and blocks. Growing evidence suggests
that non-standard nodes exist in the network, posing as honest nodes but are
perhaps intended for monitoring the network and spying on other nodes. However,
our understanding of the detection and analysis of anomalous peer behavior
remains limited. This paper presents a first comprehensive study of anomalous
behavior in Monero's P2P network. To this end, we collected and analyzed over
240 hours of network traffic captured from five distinct vantage points
worldwide. We further present a formal framework which allows us to
analytically define and classify anomalous patterns in P2P cryptocurrency
networks. Our detection methodology, implemented as an offline analysis,
provides a foundation for real-time monitoring systems. Our analysis reveals
the presence of non-standard peers in the network where approximately 14.74%
(13.19%) of (reachable) peers in the network exhibit non-standard behavior.
These peers exhibit distinct behavioral patterns that might suggest multiple
concurrent attacks, pointing to substantial shortcomings in Monero's privacy
guarantees and network decentralization. To support reproducibility and enable
network operators to protect themselves, we release our examination pipeline to
identify and block suspicious peers based on newly captured network traffic.

</details>


### [198] [RFSeek and Ye Shall Find](https://arxiv.org/abs/2509.10216)
*Noga H. Rotman,Tiago Ferreira,Hila Peleg,Mark Silberstein,Alexandra Silva*

Main category: cs.NI

TL;DR: RFSeek是一款交互式工具，利用大型语言模型(LLMs)从冗长复杂的RFC文档中自动提取并生成协议逻辑的可探索可视化摘要，提高理解和审计效率，并能发现文本中隐藏的逻辑。


<details>
  <summary>Details</summary>
Motivation: RFC（Requests for Comments）作为网络协议的规范文档，因其基于散文的格式和庞大的篇幅，经常阻碍对协议的精确操作理解。

Method: 本文提出了RFSeek工具，它利用大型语言模型（LLMs）自动从RFC中提取协议逻辑，生成与原文关联、可探索的视觉摘要图。这些图表能呈现官方状态机以及仅在RFC文本中找到的额外逻辑。

Result: RFSeek的视觉摘要比现有RFC可视化工具更透明、更易于根据文本源进行审计。它不仅能重构RFC中已有的图表，还能发现文本中描述但图表中缺失的重要逻辑（如节点或边缘），并为复杂的RFC（如QUIC）生成新的可视化图。该工具在TCP、QUIC、PPTP和DCCP等协议的引导式知识提取和语义差异分析等用例中展现了潜力。

Conclusion: “摘要可视化”方法（结合LLMs与正式的、用户定制的可视化）为增强协议理解和支持健壮的实现提供了一个有前景的方向。

Abstract: Requests for Comments (RFCs) are extensive specification documents for
network protocols, but their prose-based format and their considerable length
often impede precise operational understanding. We present RFSeek, an
interactive tool that automatically extracts visual summaries of protocol logic
from RFCs. RFSeek leverages large language models (LLMs) to generate
provenance-linked, explorable diagrams, surfacing both official state machines
and additional logic found only in the RFC text. Compared to existing RFC
visualizations, RFSeek's visual summaries are more transparent and easier to
audit against their textual source. We showcase the tool's potential through a
series of use cases, including guided knowledge extraction and semantic
diffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.
  In practice, RFSeek not only reconstructs the RFC diagrams included in some
specifications, but, more interestingly, also uncovers important logic such as
nodes or edges described in the text but missing from those diagrams. RFSeek
further derives new visualization diagrams for complex RFCs, with QUIC as a
representative case. Our approach, which we term \emph{Summary Visualization},
highlights a promising direction: combining LLMs with formal, user-customized
visualizations to enhance protocol comprehension and support robust
implementations.

</details>


### [199] [Trusted Repeater Placement in QKD-enabled Optical Networks](https://arxiv.org/abs/2509.10338)
*Arup Kumar Marik,Basabdatta Palit,Sadananda Behera*

Main category: cs.NI

TL;DR: 针对QKD网络中现有中继节点信任假设的不足，本文提出了一个可靠性感知的TRN放置框架，通过整合信任分数和复合中心性指标优化TRN选择，显著提升了安全路径的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发（QKD）受距离限制需要中继节点扩展覆盖范围。然而，现有工作中通常假定所有中继节点（TRN）及其密钥管理服务器（KMS）是完全可信的，忽视了软件漏洞和内部威胁带来的风险。

Method: 1. 提出了一个针对城域光网络的可靠性感知TRN放置框架。2. 为每个节点分配信任分数，并通过加权链路将其整合到Dijkstra算法中。3. 使用一个结合了介数中心性和特征向量中心性的复合分数对节点进行排名，以实现安全且可扩展的TRN部署。

Result: 在参考拓扑上的仿真结果表明，在TRN数量相同（约8个）的情况下，该方法比传统的度中心性等指标多覆盖了10.77%的最短路径。

Conclusion: 本方法适用于TRN的选择，能够最大化安全连接性，从而提升QKD网络的安全性和可扩展性。

Abstract: Quantum Key Distribution (QKD) provides information-theoretic security, but
is limited by distance in optical networks, thereby requiring repeater nodes to
extend coverage. Existing works usually assume all repeater nodes and
associated Key Management Servers (KMSs) to be Trusted Repeater Nodes (TRNs),
while ignoring risks from software exploits and insider threats. In this paper,
we propose a reliability-aware TRN placement framework for metro optical
networks, which assigns each node a trust score and integrates it into the
Dijkstra algorithm via weighted links. We then rank the nodes using a composite
score, which is a weighted combination of betweenness centrality and
eigenvector centrality to enable a secure and scalable TRN deployment.
Simulation results on a reference topology show that our method covers 10.77%
more shortest paths compared to traditional metrics like degree centrality,
using the same number (around eight) of TRNs, making it suitable for TRN
selection to maximize secure connectivity.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [200] [Whisper Has an Internal Word Aligner](https://arxiv.org/abs/2509.09987)
*Sung-Lin Yeh,Yen Meng,Hao Tang*

Main category: eess.AS

TL;DR: 提出一种无监督方法，通过利用Whisper中特定的注意力头和字符级处理，实现更精确的单词级时间戳，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 市场对从自动语音识别器（尤其是Whisper）获取精确单词级时间戳的需求日益增长，但现有方法要么需要额外训练，要么竞争力不足。此外，以往研究的评估标准相对宽松（通常容忍度超过200毫秒）。

Method: 研究发现Whisper中存在能捕获精确单词对齐的注意力头，并且这些注意力头与不捕获对齐的注意力头明显不同。此外，发现使用字符而非词片可以产生更精细、更准确的对齐。基于这些发现，提出一种无监督方法，通过过滤注意力头并使用字符进行教师强制（teacher forcing）来提取单词对齐。

Result: 该方法无需额外训练，且在20毫秒到100毫秒之间更严格的容忍度下，生成的单词对齐比现有工作更准确。

Conclusion: 通过利用Whisper模型内在的注意力机制和字符级处理，可以无监督地提取高精度的单词级时间戳，显著优于现有方法。

Abstract: There is an increasing interest in obtaining accurate word-level timestamps
from strong automatic speech recognizers, in particular Whisper. Existing
approaches either require additional training or are simply not competitive.
The evaluation in prior work is also relatively loose, typically using a
tolerance of more than 200 ms. In this work, we discover attention heads in
Whisper that capture accurate word alignments and are distinctively different
from those that do not. Moreover, we find that using characters produces finer
and more accurate alignments than using wordpieces. Based on these findings, we
propose an unsupervised approach to extracting word alignments by filtering
attention heads while teacher forcing Whisper with characters. Our approach not
only does not require training but also produces word alignments that are more
accurate than prior work under a stricter tolerance between 20 ms and 100 ms.

</details>


### [201] [Unified Learnable 2D Convolutional Feature Extraction for ASR](https://arxiv.org/abs/2509.10031)
*Peter Vieting,Benedikt Hilmes,Ralf Schlüter,Hermann Ney*

Main category: eess.AS

TL;DR: 本文开发了一种通用、统一且参数高效的2D卷积神经网络前端，用于ASR特征提取，其性能与现有监督学习方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有ASR神经前端受经典方法影响大，缺乏通用性，且架构复杂（多层拓扑组合）。本研究旨在开发一个更通用、统一的特征提取前端。

Method: 通过系统实验减少现有技术影响，开发了一个参数高效的2D卷积前端，以实现通用和统一的特征提取。该方法适用于计算资源有限的场景。

Result: 所提出的通用统一方法不仅可行，而且其性能与现有的监督可学习特征提取器相匹配。

Conclusion: 通用、统一且参数高效的2D卷积前端是ASR特征提取的有效方案，能在有限计算资源下与现有方法匹敌。

Abstract: Neural front-ends represent a promising approach to feature extraction for
automatic speech recognition (ASR) systems as they enable to learn specifically
tailored features for different tasks. Yet, many of the existing techniques
remain heavily influenced by classical methods. While this inductive bias may
ease the system design, our work aims to develop a more generic front-end for
feature extraction. Furthermore, we seek to unify the front-end architecture
contrasting with existing approaches that apply a composition of several layer
topologies originating from different sources. The experiments systematically
show how to reduce the influence of existing techniques to achieve a generic
front-end. The resulting 2D convolutional front-end is parameter-efficient and
suitable for a scenario with limited computational resources unlike large
models pre-trained on unlabeled audio. The results demonstrate that this
generic unified approach is not only feasible but also matches the performance
of existing supervised learnable feature extractors.

</details>


### [202] [Error Analysis in a Modular Meeting Transcription System](https://arxiv.org/abs/2509.10143)
*Peter Vieting,Simon Berger,Thilo von Neumann,Christoph Boeddeker,Ralf Schlüter,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 分析了会议转录中语音分离的泄漏问题及分割方法，实现了LibriCSS上的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 会议转录领域仍面临性能限制，需要深入理解并解决语音分离中的泄漏问题和优化分割方法，以提升转录准确性。

Method: 扩展了一个具有时间局部性敏感度的语音分离泄漏分析框架。比较了多种分割方法（包括先进的diarization和基于能量的VAD），并分析了影响性能的因素。

Result: 发现主要说话人活跃时存在显著跨通道泄漏，但VAD能有效忽略，对最终性能影响不大。先进的diarization方法将与理想分割的差距缩小了三分之一。在仅使用LibriSpeech数据训练识别模块的系统中，实现了LibriCSS上的最先进性能。

Conclusion: 泄漏对会议转录性能影响有限，而改进的分割方法（特别是先进的diarization）显著提升了性能，使系统在特定条件下达到了SOTA水平。

Abstract: Meeting transcription is a field of high relevance and remarkable progress in
recent years. Still, challenges remain that limit its performance. In this
work, we extend a previously proposed framework for analyzing leakage in speech
separation with proper sensitivity to temporal locality. We show that there is
significant leakage to the cross channel in areas where only the primary
speaker is active. At the same time, the results demonstrate that this does not
affect the final performance much as these leaked parts are largely ignored by
the voice activity detection (VAD). Furthermore, different segmentations are
compared showing that advanced diarization approaches are able to reduce the
gap to oracle segmentation by a third compared to a simple energy-based VAD. We
additionally reveal what factors contribute to the remaining difference. The
results represent state-of-the-art performance on LibriCSS among systems that
train the recognition module on LibriSpeech data only.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [203] [Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building](https://arxiv.org/abs/2509.09906)
*Alexandra Fetsch,Iurii Savvateev,Racem Ben Romdhane,Martin Wiedmann,Artemiy Dimov,Maciej Durkalec,Josef Teichmann,Jakob Zinsstag,Konstantinos Koutsoumanis,Andreja Rajkovic,Jason Mann,Mauro Tonolla,Monika Ehling-Schulz,Matthias Filter,Sophia Johler*

Main category: cs.MA

TL;DR: 本文提出了一种AI辅助协商框架，该框架利用大语言模型（LLMs）和AI代理来解决复杂全球挑战中的跨部门风险分析和决策困境，并在实际场景中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 面对复杂且相互依赖的全球挑战，传统风险分析框架因过度简化而产生部门壁垒，难以有效整合和平衡各方利益。在时间受限、信息过载及整合多方视角的复杂性下，当前缺乏支持整体性、参与式协商的有效工具。

Method: 本研究开发了一个AI辅助协商框架，将大语言模型（LLMs）和AI自主代理整合到以协商为中心的风险分析工作流中。该框架旨在使利益相关者能够模拟协商、系统建模动态、预测妥协并评估解决方案影响。

Result: 通过在生物农药审慎使用和野生动物种群控制两个真实场景中的概念验证，结果表明该框架能够缓解信息过载并增强时间受限下的决策过程。它展示了AI辅助协商在解决当前跨部门协作工具不足方面的巨大潜力。

Conclusion: 该AI辅助协商框架为解决复杂全球挑战中的跨部门、多利益相关者协商需求提供了有效工具。其开源、基于网络的设计使其适用于资源有限的广泛用户，有助于促进整体性解决方案的达成。

Abstract: Key global challenges of our times are characterized by complex
interdependencies and can only be effectively addressed through an integrated,
participatory effort. Conventional risk analysis frameworks often reduce
complexity to ensure manageability, creating silos that hinder comprehensive
solutions. A fundamental shift towards holistic strategies is essential to
enable effective negotiations between different sectors and to balance the
competing interests of stakeholders. However, achieving this balance is often
hindered by limited time, vast amounts of information, and the complexity of
integrating diverse perspectives. This study presents an AI-assisted
negotiation framework that incorporates large language models (LLMs) and
AI-based autonomous agents into a negotiation-centered risk analysis workflow.
The framework enables stakeholders to simulate negotiations, systematically
model dynamics, anticipate compromises, and evaluate solution impacts. By
leveraging LLMs' semantic analysis capabilities we could mitigate information
overload and augment decision-making process under time constraints.
Proof-of-concept implementations were conducted in two real-world scenarios:
(i) prudent use of a biopesticide, and (ii) targeted wild animal population
control. Our work demonstrates the potential of AI-assisted negotiation to
address the current lack of tools for cross-sectoral engagement. Importantly,
the solution's open source, web based design, suits for application by a
broader audience with limited resources and enables users to tailor and develop
it for their own needs.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [204] [Sparse Polyak: an adaptive step size rule for high-dimensional M-estimation](https://arxiv.org/abs/2509.09802)
*Tianqi Qiao,Marie Maros*

Main category: math.OC

TL;DR: 本文提出Sparse Polyak，一种自适应步长新方法，通过估计受限Lipschitz光滑度常数，解决了高维统计估计中标准Polyak性能差的问题。


<details>
  <summary>Details</summary>
Motivation: 在高维统计估计问题中（问题维度远大于样本量），标准Polyak步长性能不佳，需要大量迭代。其根本原因在于高维下估计全局Lipschitz光滑度常数不再有效，而应聚焦于受限Lipschitz光滑度常数。

Method: 提出Sparse Polyak，它是Polyak自适应步长的一种变体。该方法通过修改步长计算方式，转而估计与问题相关的“受限Lipschitz光滑度常数”。

Result: 理论分析和数值实验均表明，Sparse Polyak的性能得到显著提升。

Conclusion: Sparse Polyak通过有效估计受限Lipschitz光滑度常数，成功解决了标准Polyak在高维问题中的局限性，实现了更优的性能表现。

Abstract: We propose and study Sparse Polyak, a variant of Polyak's adaptive step size,
designed to solve high-dimensional statistical estimation problems where the
problem dimension is allowed to grow much faster than the sample size. In such
settings, the standard Polyak step size performs poorly, requiring an
increasing number of iterations to achieve optimal statistical precision-even
when, the problem remains well conditioned and/or the achievable precision
itself does not degrade with problem size. We trace this limitation to a
mismatch in how smoothness is measured: in high dimensions, it is no longer
effective to estimate the Lipschitz smoothness constant. Instead, it is more
appropriate to estimate the smoothness restricted to specific directions
relevant to the problem (restricted Lipschitz smoothness constant). Sparse
Polyak overcomes this issue by modifying the step size to estimate the
restricted Lipschitz smoothness constant. We support our approach with both
theoretical analysis and numerical experiments, demonstrating its improved
performance.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [205] [LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm](https://arxiv.org/abs/2509.09707)
*Camilo Chacón Sartori,Martín Isla Pino,Pedro Pinacho-Davidson,Christian Blum*

Main category: cs.NE

TL;DR: 本研究将LLM与BRKGA结合，通过生成实例驱动的启发式偏置，有效解决了最长运行子序列问题，尤其在复杂实例上表现显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有将LLM集成到元启发式算法中的方法多侧重于代码生成，但常忽略问题实例的结构特性。本研究旨在探索LLM如何利用实例结构属性来提升复杂组合优化问题的求解效率。

Method: 提出一个新框架，将LLM与偏置随机密钥遗传算法 (BRKGA) 集成，以解决NP难的最长运行子序列问题。该方法通过人机协作设计并实现一组计算高效的实例特定指标，LLM分析这些指标以生成量身定制的启发式偏置，从而引导BRKGA搜索更有前景的区域。通过对1050个不同复杂度的生成实例进行综合实验评估，包括统计测试、收敛性及行为分析和消融研究，将该方法与标准BRKGA基线进行比较。

Result: 实验结果显示，表现最佳的混合方法BRKGA+Llama-4-Maverick在统计学上显著优于基线，尤其是在最复杂的实例上。

Conclusion: 研究结果证实，利用LLM生成先验的、实例驱动的启发式偏置是增强复杂优化领域中元启发式算法的有效方法。

Abstract: Integrating Large Language Models (LLMs) within metaheuristics opens a novel
path for solving complex combinatorial optimization problems. While most
existing approaches leverage LLMs for code generation to create or refine
specific heuristics, they often overlook the structural properties of
individual problem instances. In this work, we introduce a novel framework that
integrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the
NP-hard Longest Run Subsequence problem. Our approach extends the
instance-driven heuristic bias paradigm by introducing a human-LLM
collaborative process to co-design and implement a set of computationally
efficient metrics. The LLM analyzes these instance-specific metrics to generate
a tailored heuristic bias, which steers the BRKGA toward promising areas of the
search space. We conduct a comprehensive experimental evaluation, including
rigorous statistical tests, convergence and behavioral analyses, and targeted
ablation studies, comparing our method against a standard BRKGA baseline across
1,050 generated instances of varying complexity. Results show that our
top-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically
significant improvements over the baseline, particularly on the most complex
instances. Our findings confirm that leveraging an LLM to produce an a priori,
instance-driven heuristic bias is a valuable approach for enhancing
metaheuristics in complex optimization domains.

</details>


### [206] [Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks](https://arxiv.org/abs/2509.10077)
*Simen Storesund,Kristian Valset Aars,Robin Dietrich,Nicolai Waniek*

Main category: cs.NE

TL;DR: 提出一种生物学上合理、基于脉冲时间的新型最短路径算法，通过局部消息传递和时间压缩，实现最短路径计算，为生物和人工系统分布式计算提供新见解。


<details>
  <summary>Details</summary>
Motivation: 现有规划和序列选择方法（如Dijkstra/A*和强化学习）与生物计算不兼容，它们要么需要全局状态和回溯，要么依赖缓慢的梯度更新，无法解释快速行为适应。因此，需要一种更具生物合理性的计算方法。

Method: 提出一种生物学上合理的最短路径算法，该算法通过局部、基于脉冲的消息传递，利用真实的处理延迟进行操作。它通过脉冲时间巧合识别最优路径上的节点，即神经元在预期时间前接收到抑制-兴奋消息对会减少其响应延迟，从而产生从目标向源头反向传播的时间压缩。

Result: 通过分析证明和在随机空间网络上的仿真，验证了该算法能够收敛，并使用纯粹基于时间的机制发现所有最短路径。

Conclusion: 本研究展示了短时序动态如何单独计算最短路径，为生物网络如何通过纯局部计算和相对脉冲时间预测解决复杂计算问题提供了新见解。这些发现为理解生物和人工系统中的分布式计算开辟了新方向，并对计算神经科学、AI、强化学习和神经拟态系统具有潜在意义。

Abstract: Efficient planning and sequence selection are central to intelligence, yet
current approaches remain largely incompatible with biological computation.
Classical graph algorithms like Dijkstra's or A* require global state and
biologically implausible operations such as backtracing, while reinforcement
learning methods rely on slow gradient-based policy updates that appear
inconsistent with rapid behavioral adaptation observed in natural systems.
  We propose a biologically plausible algorithm for shortest-path computation
that operates through local spike-based message-passing with realistic
processing delays. The algorithm exploits spike-timing coincidences to identify
nodes on optimal paths: Neurons that receive inhibitory-excitatory message
pairs earlier than predicted reduce their response delays, creating a temporal
compression that propagates backwards from target to source. Through analytical
proof and simulations on random spatial networks, we demonstrate that the
algorithm converges and discovers all shortest paths using purely timing-based
mechanisms. By showing how short-term timing dynamics alone can compute
shortest paths, this work provides new insights into how biological networks
might solve complex computational problems through purely local computation and
relative spike-time prediction. These findings open new directions for
understanding distributed computation in biological and artificial systems,
with possible implications for computational neuroscience, AI, reinforcement
learning, and neuromorphic systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [207] [HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario](https://arxiv.org/abs/2509.10096)
*Saeed Saadatnejad,Reyhaneh Hosseininejad,Jose Barreiros,Katherine M. Tsui,Alexandre Alahi*

Main category: cs.RO

TL;DR: 该研究通过引入HHI-Assist数据集和基于条件Transformer的去噪扩散模型，解决了辅助机器人中人-人交互运动预测的挑战，提升了预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺和人口老龄化推动了辅助机器人的需求，而机器人提供安全响应式协助需要准确预测物理交互中的人类运动。由于辅助环境的多变性和耦合动力学的复杂性，这仍是一项艰巨的任务。

Method: ['构建了HHI-Assist数据集，包含辅助任务中人-人交互的动作捕捉片段。', '提出了一种基于条件Transformer的去噪扩散模型，用于预测交互代理的姿态。']

Result: 所提出的模型能有效捕捉看护者与被看护者之间的耦合动力学，性能优于基线方法，并对未见场景展现出强大的泛化能力。

Conclusion: 通过在交互感知运动预测方面的进展和新数据集的引入，本工作有望显著提升机器人辅助策略。

Abstract: The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home

</details>


### [208] [GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation](https://arxiv.org/abs/2509.10454)
*Hang Yin,Haoyu Wei,Xiuwei Xu,Wenxuan Guo,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: 本文提出了一种无需训练的视觉与语言导航（VLN）框架，通过将导航指令分解为图约束优化问题，实现了在连续环境中的零样本适应性。


<details>
  <summary>Details</summary>
Motivation: 现有零样本VLN方法主要针对离散环境或涉及连续模拟器中的无监督训练，导致在真实世界场景中泛化和部署困难。

Method: 框架将导航指导公式化为图约束优化问题，通过将指令分解为显式空间约束来实现。它构建了一个空间约束库，将人类指令分解为有向无环图（包含路点、物体节点和边），然后查询库以构建图约束。这些图约束通过约束求解器解决，以确定路点位置，从而获得机器人导航路径和最终目标。为处理无解或多解情况，还构建了导航树和回溯机制。

Result: 在标准基准测试中，与现有零样本VLN方法相比，该框架在成功率和导航效率方面均有显著提升。此外，真实世界实验表明，该框架能有效泛化到新的环境和指令集。

Conclusion: 本框架为构建更鲁棒和自主的导航框架铺平了道路。

Abstract: In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.

</details>


### [209] [Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision](https://arxiv.org/abs/2509.09893)
*Hanbit Oh,Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Yukiyasu Domae*

Main category: cs.RO

TL;DR: SART是一个机器人模仿学习框架，仅需一次人类演示，即可通过自主安全的数据增强来学习策略，显著提高了成功率并减少了人类负担。


<details>
  <summary>Details</summary>
Motivation: 标准模仿学习需要大量数据或探索，但探索缺乏安全保证，易导致碰撞，尤其在空间受限任务中，需要人工重置，增加了人类负担。

Method: SART包含两个阶段：1) 人类教学一次，提供一次演示并标注关键路点周围的精度边界（球体），然后一次环境重置。2) 机器人自主增强，在边界内生成多样化、无碰撞的轨迹，并与原始演示重新连接。

Result: 在模拟和真实世界操作任务中，SART的成功率显著高于仅依靠人类演示训练的策略。

Conclusion: SART通过最小化人类工作量并确保安全，提高了数据收集效率，实现了从单次人类演示中进行有效的策略学习。

Abstract: Imitation learning is a promising paradigm for training robot agents;
however, standard approaches typically require substantial data acquisition --
via numerous demonstrations or random exploration -- to ensure reliable
performance. Although exploration reduces human effort, it lacks safety
guarantees and often results in frequent collisions -- particularly in
clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual
environmental resets and imposing additional human burden. This study proposes
Self-Augmented Robot Trajectory (SART), a framework that enables policy
learning from a single human demonstration, while safely expanding the dataset
through autonomous augmentation. SART consists of two stages: (1) human
teaching only once, where a single demonstration is provided and precision
boundaries -- represented as spheres around key waypoints -- are annotated,
followed by one environment reset; (2) robot self-augmentation, where the robot
generates diverse, collision-free trajectories within these boundaries and
reconnects to the original demonstration. This design improves the data
collection efficiency by minimizing human effort while ensuring safety.
Extensive evaluations in simulation and real-world manipulation tasks show that
SART achieves substantially higher success rates than policies trained solely
on human-collected demonstrations. Video results available at
https://sites.google.com/view/sart-il .

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [210] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 本文分析了生成式AI搜索对信息检索的重塑，提出了生成式引擎优化（GEO）新范式，并发现AI搜索偏向于权威的赢得媒体，为在新搜索环境下获得可见性提供了策略。


<details>
  <summary>Details</summary>
Motivation: 生成式AI搜索引擎的兴起正在改变信息检索方式，从传统排名列表转向合成答案。这挑战了现有SEO实践，需要新的优化范式。

Method: 通过大规模、受控实验，在多个垂直领域、语言和查询变体下，对AI搜索（如ChatGPT、Perplexity、Gemini）与传统网页搜索（Google）进行了全面的比较分析。

Result: AI搜索对赢得媒体（第三方、权威来源）存在系统性偏见，与Google的均衡组合形成鲜明对比。不同的AI搜索服务在领域多样性、新鲜度、跨语言稳定性及措辞敏感性方面也存在显著差异，并揭示了固有的“大品牌偏见”。

Conclusion: 基于研究结果，本文提出了GEO战略议程，并为实践者提供了可操作性指导，强调了内容可扫描性、赢得媒体主导、引擎和语言特定策略，以及克服“大品牌偏见”的重要性，为生成式搜索环境下的可见性奠定了基础。

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [211] [DB3 Team's Solution For Meta KDD Cup' 25](https://arxiv.org/abs/2509.09681)
*Yikuan Xia,Jiazun Chen,Yirui Zhan,Suifeng Zhao,Weipeng Jiang,Chaorui Zhang,Wei Han,Bo Bai,Jun Gao*

Main category: cs.IR

TL;DR: db3团队在KDD Cup'25 Meta CRAG-MM挑战赛中凭借其多模态多轮问答解决方案夺冠，该方案结合了定制检索管道和统一LLM幻觉控制方法。


<details>
  <summary>Details</summary>
Motivation: 解决Meta CRAG-MM挑战赛中独特的多模态、多轮问答基准问题，特别是控制大型语言模型（LLM）的幻觉。

Method: 开发了一个综合框架，包含：1) 针对图像索引知识图谱、网络源和多轮对话的领域特定检索管道；2) 使用SFT、DPO和RL进行的高级拒绝训练，以控制幻觉。

Result: 在Task 1中获得第二名，Task 2中获得第二名，Task 3中获得第一名，并因在第一人称视角查询方面的卓越处理能力而获得总冠军。

Conclusion: 该解决方案通过其创新的检索和LLM幻觉控制方法，在处理以自我为中心的查询方面表现出色，赢得了Meta CRAG-MM挑战赛的总冠军。

Abstract: This paper presents the db3 team's winning solution for the Meta CRAG-MM
Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,
multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive
framework that integrates tailored retrieval pipelines for different tasks with
a unified LLM-tuning approach for hallucination control. Our solution features
(1) domain-specific retrieval pipelines handling image-indexed knowledge
graphs, web sources, and multi-turn conversations; and (2) advanced refusal
training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd
place in Task 2, and 1st place in Task 3, securing the grand prize for
excellence in ego-centric queries through superior handling of first-person
perspective challenges.

</details>


### [212] [Forecasting Clicks in Digital Advertising: Multimodal Inputs and Interpretable Outputs](https://arxiv.org/abs/2509.09683)
*Briti Gangopadhyay,Zhao Wang,Shingo Takamatsu*

Main category: cs.IR

TL;DR: 针对数字广告点击量预测，提出多模态框架，结合点击数据与文本日志，通过强化学习提升预测准确性并提供可解释性，效果优于传统基线。


<details>
  <summary>Details</summary>
Motivation: 数字广告点击量预测对收入和策略至关重要，但传统时间序列模型仅依赖数值数据，忽略了文本（如关键词更新）中丰富的上下文信息，导致预测不全面。

Method: 提出一个多模态预测框架，融合点击数据与真实广告活动的文本日志。该框架利用强化学习来提高文本信息理解和增强模态融合，并能生成数值预测和人类可解释的解释。

Result: 在进行大规模行业数据集的实验后表明，所提出的方法在预测准确性和推理质量方面均优于基线模型。

Conclusion: 提出的多模态强化学习框架，通过有效融合数值点击数据和文本日志，解决了传统模型忽视文本上下文信息的问题，显著提升了数字广告点击量预测的准确性和可解释性。

Abstract: Forecasting click volume is a key task in digital advertising, influencing
both revenue and campaign strategy. Traditional time series models rely solely
on numerical data, often overlooking rich contextual information embedded in
textual elements, such as keyword updates. We present a multimodal forecasting
framework that combines click data with textual logs from real-world ad
campaigns and generates human-interpretable explanations alongside numeric
predictions. Reinforcement learning is used to improve comprehension of textual
information and enhance fusion of modalities. Experiments on a large-scale
industry dataset show that our method outperforms baselines in both accuracy
and reasoning quality.

</details>


### [213] [Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation](https://arxiv.org/abs/2509.09684)
*Bruno Yui Yamate,Thais Rodrigues Neubauer,Marcelo Fantinato,Sarajane Marques Peres*

Main category: cs.IR

TL;DR: 本文介绍了text-2-SQL-4-PM，一个针对流程挖掘领域文本到SQL任务设计的双语（葡萄牙语-英语）基准数据集。


<details>
  <summary>Details</summary>
Motivation: 旨在通过文本到SQL转换，提升非SQL专家查询数据库的可及性和SQL专家的生产力，特别是在流程挖掘这一具有专业词汇和单表结构的领域。

Method: 专家手动整理、专业翻译，详细的标注过程，构建包含1,655个自然语言语句、205个SQL语句和10个限定词的数据集。此外，使用GPT-3.5 Turbo进行了基线研究。

Result: text-2-SQL-4-PM数据集被证明对文本到SQL应用具有可行性和实用性，支持文本到SQL实现的评估，并对语义解析及其他自然语言处理任务具有广泛适用性。

Conclusion: text-2-SQL-4-PM数据集为流程挖掘领域的文本到SQL任务及相关NLP任务提供了一个有价值的评估和开发资源。

Abstract: This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)
benchmark dataset designed for the text-to-SQL task in the process mining
domain. Text-to-SQL conversion facilitates natural language querying of
databases, increasing accessibility for users without SQL expertise and
productivity for those that are experts. The text-2-SQL-4-PM dataset is
customized to address the unique challenges of process mining, including
specialized vocabularies and single-table relational structures derived from
event logs. The dataset comprises 1,655 natural language utterances, including
human-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods
include manual curation by experts, professional translations, and a detailed
annotation process to enable nuanced analyses of task complexity. Additionally,
a baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility
of the dataset for text-to-SQL applications. The results show that
text-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering
broader applicability for semantic parsing and other natural language
processing tasks.

</details>


### [214] [TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation](https://arxiv.org/abs/2509.09685)
*Keunwoo Choi,Seungheon Doh,Juhan Nam*

Main category: cs.IR

TL;DR: 本文介绍了TalkPlayData 2，一个通过多智能体LLM管道生成的合成多模态对话式音乐推荐数据集，旨在训练生成式推荐模型。


<details>
  <summary>Details</summary>
Motivation: 需要一个覆盖多种对话场景并支持多模态交互的综合性合成数据集，用于训练音乐领域的生成式推荐模型。

Method: 采用代理数据管道，创建多个具有特定角色、提示和信息访问权限的大语言模型（LLM）智能体。通过记录“听众LLM”与“推荐系统LLM”之间的对话获取数据，其中“听众LLM”根据微调的对话目标进行条件设置，以模拟不同对话场景。所有LLM均为多模态（支持音频和图像），以模拟多模态推荐和对话。

Result: 通过“LLM作为评判者”和主观评估实验，TalkPlayData 2在训练音乐生成式推荐模型的各个方面达到了预期目标。

Conclusion: TalkPlayData 2是一个成功的合成多模态对话式音乐推荐数据集，适用于训练生成模型，并且已开源。

Abstract: We present TalkPlayData 2, a synthetic dataset for multimodal conversational
music recommendation generated by an agentic data pipeline. In TalkPlayData 2
pipeline, multiple large language model (LLM) agents are created under various
roles with specialized prompts and access to different parts of information,
and the chat data is acquired by logging the conversation between the Listener
LLM and the Recsys LLM. To cover various conversation scenarios, for each
conversation, the Listener LLM is conditioned on a finetuned conversation goal.
Finally, all the LLMs are multimodal with audio and images, allowing a
simulation of multimodal recommendation and conversation. In the LLM-as-a-judge
and subjective evaluation experiments, TalkPlayData 2 achieved the proposed
goal in various aspects related to training a generative recommendation model
for music. TalkPlayData 2 and its generation code are open-sourced at
https://talkpl.ai/talkplaydata2.html.

</details>


### [215] [GeoGPT.RAG Technical Report](https://arxiv.org/abs/2509.09686)
*Fei Huang,Fan Wu,Zeqing Zhang,Qihao Wang,Long Zhang,Grant Michael Boquet,Hongyang Chen*

Main category: cs.IR

TL;DR: GeoGPT是一个面向地球科学的开源大语言模型系统，通过集成RAG（检索增强生成）、利用专门知识库和用户自定义数据，并微调检索模型，旨在提供精确可靠的地球科学问答，其核心RAG组件已开源。


<details>
  <summary>Details</summary>
Motivation: 为了提升大语言模型在地球科学领域的专业能力、输出精度和可信度，并践行开放科学理念，促进社区驱动的研发。

Method: 构建GeoGPT系统并集成RAG，该RAG从GeoGPT Library（地球科学专业语料库）检索信息；允许用户上传自定义知识库；微调嵌入模型和排名模型以优化检索质量和领域对齐性；开源GeoEmbedding和GeoReranker两个核心RAG组件。

Result: GeoGPT能够生成准确、上下文特定且值得信赖的地球科学答案；系统提供精确和可靠输出的能力得到显著提升；成功开源了核心RAG组件，为全球地球科学家提供了强大且可访问的AI工具。

Conclusion: GeoGPT通过整合RAG和领域特定优化（如微调模型与专用知识库），显著提升了大语言模型在地球科学领域的专业问答能力，并通过开源核心组件践行了开放科学承诺，为地球科学界提供了重要的AI支持。

Abstract: GeoGPT is an open large language model system built to advance research in
the geosciences. To enhance its domain-specific capabilities, we integrated
Retrieval Augmented Generation(RAG), which augments model outputs with relevant
information retrieved from an external knowledge source. GeoGPT uses RAG to
draw from the GeoGPT Library, a specialized corpus curated for geoscientific
content, enabling it to generate accurate, context-specific answers. Users can
also create personalized knowledge bases by uploading their own publication
lists, allowing GeoGPT to retrieve and respond using user-provided materials.
To further improve retrieval quality and domain alignment, we fine-tuned both
the embedding model and a ranking model that scores retrieved passages by
relevance to the query. These enhancements optimize RAG for geoscience
applications and significantly improve the system's ability to deliver precise
and trustworthy outputs. GeoGPT reflects a strong commitment to open science
through its emphasis on collaboration, transparency, and community driven
development. As part of this commitment, we have open-sourced two core RAG
components-GeoEmbedding and GeoReranker-to support geoscientists, researchers,
and professionals worldwide with powerful, accessible AI tools.

</details>


### [216] [AI-Powered Assistant for Long-Term Access to RHIC Knowledge](https://arxiv.org/abs/2509.09688)
*Mohammad Atif,Vincent Garonne,Eric Lancon,Jerome Lauret,Alexandr Prozorov,Michal Vranovsky*

Main category: cs.IR

TL;DR: RHIC数据保存计划引入AI助手系统，利用大语言模型和检索增强生成，实现对海量科学遗留数据的自然语言访问，以支持可复现性、教育和未来发现。


<details>
  <summary>Details</summary>
Motivation: 相对论重离子对撞机（RHIC）25年运行结束后，面临着保存约1 EB海量数据及其中蕴含科学知识的挑战，亟需提升数据和知识的可用性与可发现性，以支持可复现性、教育和未来的科学探索。

Method: 开发了一个基于大语言模型（LLMs）、结合检索增强生成（RAG）和模型上下文协议的AI驱动助手系统，该系统能够索引RHIC实验的结构化和非结构化内容，并提供领域适应的自然语言交互。

Result: 报告了该AI助手系统的部署情况、计算性能、多实验集成进展，以及为实现可持续和可解释的长期AI访问而设计的架构特点。

Conclusion: 该研究经验表明，现代AI/ML工具能够显著变革科学遗留数据的可用性和可发现性。

Abstract: As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National
Laboratory concludes 25 years of operation, preserving not only its vast data
holdings ($\sim$1 ExaByte) but also the embedded scientific knowledge becomes a
critical priority. The RHIC Data and Analysis Preservation Plan (DAPP)
introduces an AI-powered assistant system that provides natural language access
to documentation, workflows, and software, with the aim of supporting
reproducibility, education, and future discovery. Built upon Large Language
Models using Retrieval-Augmented Generation and the Model Context Protocol,
this assistant indexes structured and unstructured content from RHIC
experiments and enables domain-adapted interaction. We report on the
deployment, computational performance, ongoing multi-experiment integration,
and architectural features designed for a sustainable and explainable long-term
AI access. Our experience illustrates how modern AI/ML tools can transform the
usability and discoverability of scientific legacy data.

</details>


### [217] [Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors](https://arxiv.org/abs/2509.09689)
*Himanshu Thakur,Eshani Agrawal,Smruthi Mukund*

Main category: cs.IR

TL;DR: 本文提出一种利用冻结LLM提取用户表示并使用微调SLM驱动用户代理的新方法，通过为用户群体训练低秩适配器，有效且高效地模拟用户行为，以弥合推荐系统离线指标与真实世界性能的差距。


<details>
  <summary>Details</summary>
Motivation: 开发精确推荐模型的长期挑战在于模拟用户行为，主要由于用户交互的复杂性和随机性。虽然LLM在用户行为模拟方面有前景，但面临如何有效解析大规模表格用户-物品交互数据、克服预训练诱导偏差以学习用户特定知识，以及实现前两点百万级用户规模的挑战。

Method: 该方法将重点放在使用冻结的大型语言模型（LLM）提取稳健的文本用户表示，并利用微调小型语言模型（SLM）来模拟具有成本效益、资源高效的用户代理。此外，他们还展示了一种为用户群体（或“角色”）训练多个低秩适配器的方法，以在用户行为代理的可扩展性和性能之间取得最佳平衡。

Result: 实验提供了令人信服的经验证据，证明了其方法的有效性。使用其方法开发的用户代理有潜力弥合推荐系统离线指标与真实世界性能之间的差距。

Conclusion: 通过结合冻结LLM的用户表示和微调SLM的用户代理，并引入低秩适配器处理用户群体，本研究提供了一种有效且可扩展的解决方案，以更准确地模拟用户行为，从而提升推荐系统的评估和实际表现。

Abstract: A long-standing challenge in developing accurate recommendation models is
simulating user behavior, mainly due to the complex and stochastic nature of
user interactions. Towards this, one promising line of work has been the use of
Large Language Models (LLMs) for simulating user behavior. However, aligning
these general-purpose large pre-trained models with user preferences
necessitates: (i) effectively and continously parsing large-scale tabular
user-item interaction data, (ii) overcoming pre-training-induced inductive
biases to accurately learn user specific knowledge, and (iii) achieving the
former two at scale for millions of users. While most previous works have
focused on complex methods to prompt an LLM or fine-tune it on tabular
interaction datasets, our approach shifts the focus to extracting robust
textual user representations using a frozen LLM and simulating cost-effective,
resource-efficient user agents powered by fine-tuned Small Language Models
(SLMs). Further, we showcase a method for training multiple low-rank adapters
for groups of users or \textit{persona}, striking an optimal balance between
scalability and performance of user behavior agents. Our experiments provide
compelling empirical evidence of the efficacy of our methods, demonstrating
that user agents developed using our approach have the potential to bridge the
gap between offline metrics and real-world performance of recommender systems.

</details>


### [218] [Wave-Based Semantic Memory with Resonance-Based Retrieval: A Phase-Aware Alternative to Vector Embedding Stores](https://arxiv.org/abs/2509.09691)
*Aleksandr Listopad*

Main category: cs.IR

TL;DR: 本文提出波基语义记忆系统，将知识建模为波模式并通过共振干扰进行检索，解决了传统向量系统对相位不敏感的问题，并在多种复杂查询上表现出更高判别力，且具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统向量记忆系统依赖余弦或内积相似度，对相位不敏感，无法有效捕捉对意义表示至关重要的共振现象。

Method: 提出波基语义记忆（Wave-Based Semantic Memory）框架，将知识建模为波模式 $\psi(x) = A(x) e^{i\phi(x)}$，通过共振干扰进行知识检索，从而保留振幅和相位信息。

Result: 共振检索在向量方法失败的场景（如相位偏移、否定和组合查询）中，展现出更高的判别能力。其实现ResonanceDB可扩展至数百万模式，并达到毫秒级延迟。

Conclusion: 波基记忆系统是传统向量存储的有效替代方案，尤其适用于AGI导向的推理和知识表示，提供更具表达力和鲁棒性的语义相似度能力。

Abstract: Conventional vector-based memory systems rely on cosine or inner product
similarity within real-valued embedding spaces. While computationally
efficient, such approaches are inherently phase-insensitive and limited in
their ability to capture resonance phenomena crucial for meaning
representation. We propose Wave-Based Semantic Memory, a novel framework that
models knowledge as wave patterns $\psi(x) = A(x) e^{i\phi(x)}$ and retrieves
it through resonance-based interference. This approach preserves both amplitude
and phase information, enabling more expressive and robust semantic similarity.
We demonstrate that resonance-based retrieval achieves higher discriminative
power in cases where vector methods fail, including phase shifts, negations,
and compositional queries. Our implementation, ResonanceDB, shows scalability
to millions of patterns with millisecond latency, positioning wave-based memory
as a viable alternative to vector stores for AGI-oriented reasoning and
knowledge representation.

</details>


### [219] [Powering Job Search at Scale: LLM-Enhanced Query Understanding in Job Matching Systems](https://arxiv.org/abs/2509.09690)
*Ping Liu,Jianqiang Shen,Qianqi Shen,Chunnan Yao,Kevin Kao,Dan Xu,Rajat Arora,Baofen Zheng,Caleb Johnson,Liangjie Hong,Jingwei Wu,Wenjing Zhang*

Main category: cs.IR

TL;DR: 本文提出一个基于大型语言模型（LLM）的统一查询理解框架，解决了传统多任务NER模型碎片化、维护成本高的问题，通过联合建模查询和上下文信号，提高了推荐系统的相关性并降低了系统复杂性。


<details>
  <summary>Details</summary>
Motivation: 现代查询（如求职搜索）常短小、模糊且高度依赖上下文，传统依赖多个任务特定命名实体识别（NER）模型的方案导致架构脆弱、维护昂贵且难以适应不断变化的分类和语言模式。

Method: 引入一个由大型语言模型（LLM）驱动的统一查询理解框架。该方法联合建模用户查询和上下文信号（如用户画像属性），以生成结构化的解释，从而实现更准确和个性化的推荐。

Result: 通过在线A/B测试，该框架提高了相关性质量，并显著降低了系统复杂性和运营开销。

Conclusion: 该解决方案为动态网络应用中的查询理解提供了一个可扩展且适应性强的基础。

Abstract: Query understanding is essential in modern relevance systems, where user
queries are often short, ambiguous, and highly context-dependent. Traditional
approaches often rely on multiple task-specific Named Entity Recognition models
to extract structured facets as seen in job search applications. However, this
fragmented architecture is brittle, expensive to maintain, and slow to adapt to
evolving taxonomies and language patterns. In this paper, we introduce a
unified query understanding framework powered by a Large Language Model (LLM),
designed to address these limitations. Our approach jointly models the user
query and contextual signals such as profile attributes to generate structured
interpretations that drive more accurate and personalized recommendations. The
framework improves relevance quality in online A/B testing while significantly
reducing system complexity and operational overhead. The results demonstrate
that our solution provides a scalable and adaptable foundation for query
understanding in dynamic web applications.

</details>


### [220] [Model-agnostic post-hoc explainability for recommender systems](https://arxiv.org/abs/2509.10245)
*Irina Arévalo,Jose L Salmeron*

Main category: cs.IR

TL;DR: 提出一种模型无关的删除诊断方法，用于量化用户/物品对推荐系统的影响，以提高其可解释性和透明度。


<details>
  <summary>Details</summary>
Motivation: 复杂的推荐系统虽然能提升性能，但通常会降低系统的可解释性和透明度。

Method: 开发并系统应用删除诊断方法，通过比较模型在有无特定用户或物品数据训练下的性能，量化该观测值对推荐系统的影响。该方法被应用于深度学习推荐（NCF）和经典协同过滤（SVD）。

Result: 在MovieLens和Amazon Reviews数据集上的实验揭示了模型行为的洞察，并验证了该方法在不同推荐范式下的通用性。

Conclusion: 所提出的删除诊断方法能有效量化个体观测对推荐系统性能的影响，提高系统可解释性，并具有广泛的模型通用性。

Abstract: Recommender systems often benefit from complex feature embeddings and deep
learning algorithms, which deliver sophisticated recommendations that enhance
user experience, engagement, and revenue. However, these methods frequently
reduce the interpretability and transparency of the system. In this research,
we develop a systematic application, adaptation, and evaluation of deletion
diagnostics in the recommender setting. The method compares the performance of
a model to that of a similar model trained without a specific user or item,
allowing us to quantify how that observation influences the recommender, either
positively or negatively. To demonstrate its model-agnostic nature, the
proposal is applied to both Neural Collaborative Filtering (NCF), a widely used
deep learning-based recommender, and Singular Value Decomposition (SVD), a
classical collaborative filtering technique. Experiments on the MovieLens and
Amazon Reviews datasets provide insights into model behavior and highlight the
generality of the approach across different recommendation paradigms.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [221] [An Information-Theoretic Framework for Credit Risk Modeling: Unifying Industry Practice with Statistical Theory for Fair and Interpretable Scorecards](https://arxiv.org/abs/2509.09855)
*Agus Sudjianto,Denis Burakov*

Main category: stat.ML

TL;DR: 该研究统一了信用风险建模中WoE、IV和PSI的理论基础，将其解释为信息散度，并提供了统计推断方法及在准确性与公平性之间进行权衡的工具。


<details>
  <summary>Details</summary>
Motivation: 信用风险建模中广泛使用的WoE、IV和PSI指标缺乏统一的理论基础，且其统计推断和公平性考量尚未被充分探究。

Method: 建立了统一的信息论框架，证明IV等同于好坏信用结果间的PSI（Jeffreys散度）。通过delta方法推导了IV和PSI的标准误差，首次实现了假设检验和公平性约束。形式化了性能-公平性权衡，并通过自动化分箱（深度1 XGBoost桩）比较了三种编码策略，使用混合整数规划求解帕累托最优解。

Result: 所有编码方法均实现了可比的预测性能（AUC 0.82-0.84），表明基于信息论的原则性分箱比编码选择更重要。该框架首次为信用风险指标提供了严谨的统计学基础。

Conclusion: 该框架弥合了信用风险建模理论与实践的鸿沟，为行业标准指标提供了统计基础，并为在受监管环境中平衡模型准确性和公平性提供了原则性工具。

Abstract: Credit risk modeling relies extensively on Weight of Evidence (WoE) and
Information Value (IV) for feature engineering, and Population Stability Index
(PSI) for drift monitoring, yet their theoretical foundations remain
disconnected. We establish a unified information-theoretic framework revealing
these industry-standard metrics as instances of classical information
divergences. Specifically, we prove that IV exactly equals PSI (Jeffreys
divergence) computed between good and bad credit outcomes over identical bins.
Through the delta method applied to WoE transformations, we derive standard
errors for IV and PSI, enabling formal hypothesis testing and probabilistic
fairness constraints for the first time. We formalize credit modeling's
inherent performance-fairness trade-off as maximizing IV for predictive power
while minimizing IV for protected attributes. Using automated binning with
depth-1 XGBoost stumps, we compare three encoding strategies: logistic
regression with one-hot encoding, WoE transformation, and constrained XGBoost.
All methods achieve comparable predictive performance (AUC 0.82-0.84),
demonstrating that principled, information-theoretic binning outweighs encoding
choice. Mixed-integer programming traces Pareto-efficient solutions along the
performance-fairness frontier with uncertainty quantification. This framework
bridges theory and practice, providing the first rigorous statistical
foundation for widely-used credit risk metrics while offering principled tools
for balancing accuracy and fairness in regulated environments.

</details>


### [222] [Repulsive Monte Carlo on the sphere for the sliced Wasserstein distance](https://arxiv.org/abs/2509.10166)
*Vladimir Petrovic,Rémi Bardenet,Agnès Desolneux*

Main category: stat.ML

TL;DR: 本文研究使用蒙特卡洛方法计算单位球面上的积分，以切片Wasserstein距离为例。主要关注负相关（排斥性）节点，提取并基准测试了基于行列式点过程和排斥点过程的积分方法，并分析了UnifOrtho估计器的方差。最终建议低维使用随机拟蒙特卡洛，高维使用UnifOrtho。


<details>
  <summary>Details</summary>
Motivation: 计算高维单位球面上的函数积分是一个挑战，尤其是在机器学习中日益重要的切片Wasserstein距离（SW）的计算。现有的SW积分方法较少关注节点间的排斥性，而负相关节点能够有效降低方差，因此需要探索和评估排斥性节点在蒙特卡洛积分中的应用。

Method: 1. 从行列式点过程（DPPs）、排斥点过程及切片Wasserstein距离相关文献中提取并阐述排斥性积分方法。2. 对这些积分方法进行数值基准测试。3. 分析正交蒙特卡洛估计器UnifOrtho的方差，以理解其在大维度切片Wasserstein估计中的成功及其反例。

Result: UnifOrtho估计器在估算大维度切片Wasserstein距离方面表现出色，其成功原因通过方差分析得到解释。基于DPP的积分方法仅在拟蒙特卡洛方法表现良好时才具有优势。排斥性积分方法普遍显示出中等的方差降低，但需要更多的理论研究以提高其鲁棒性。

Conclusion: 对于切片Wasserstein距离的计算，建议在低维度使用随机拟蒙特卡洛方法，而在高维度使用UnifOrtho方法。DPP-based积分法仅在特定条件下有效，排斥性积分法虽有一定效果但尚需深入研究。

Abstract: In this paper, we consider the problem of computing the integral of a
function on the unit sphere, in any dimension, using Monte Carlo methods.
Although the methods we present are general, our guiding thread is the sliced
Wasserstein distance between two measures on $\mathbb{R}^d$, which is precisely
an integral on the $d$-dimensional sphere. The sliced Wasserstein distance (SW)
has gained momentum in machine learning either as a proxy to the less
computationally tractable Wasserstein distance, or as a distance in its own
right, due in particular to its built-in alleviation of the curse of
dimensionality. There has been recent numerical benchmarks of quadratures for
the sliced Wasserstein, and our viewpoint differs in that we concentrate on
quadratures where the nodes are repulsive, i.e. negatively dependent. Indeed,
negative dependence can bring variance reduction when the quadrature is adapted
to the integration task. Our first contribution is to extract and motivate
quadratures from the recent literature on determinantal point processes (DPPs)
and repelled point processes, as well as repulsive quadratures from the
literature specific to the sliced Wasserstein distance. We then numerically
benchmark these quadratures. Moreover, we analyze the variance of the UnifOrtho
estimator, an orthogonal Monte Carlo estimator. Our analysis sheds light on
UnifOrtho's success for the estimation of the sliced Wasserstein in large
dimensions, as well as counterexamples from the literature. Our final
recommendation for the computation of the sliced Wasserstein distance is to use
randomized quasi-Monte Carlo in low dimensions and \emph{UnifOrtho} in large
dimensions. DPP-based quadratures only shine when quasi-Monte Carlo also does,
while repelled quadratures show moderate variance reduction in general, but
more theoretical effort is needed to make them robust.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [223] [Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images](https://arxiv.org/abs/2509.09952)
*Zhi Ying,Boxiang Rong,Jingyu Wang,Maoyuan Xu*

Main category: cs.GR

TL;DR: 提出一种新颖的两阶段生成-估计框架，利用扩散模型实现高质量、灵活可控的PBR材质生成与SVBRDF通道估计。


<details>
  <summary>Details</summary>
Motivation: 传统材质创建与重建耗时且需专业技能；现有基于视觉基础模型的PBR材质合成方法在质量、灵活性和用户控制方面有所欠缺。

Method: 本文提出一个两阶段“生成-估计”框架：
1. **生成阶段**：一个微调的扩散模型根据用户输入合成带阴影、可平铺的纹理图像。
2. **估计阶段**：引入链式分解方案，通过将之前提取的表示作为输入传递给一个单步图像条件扩散模型，顺序预测SVBRDF通道。

Result: 该方法高效、高质量，并支持灵活的用户控制。与现有材质生成和估计方法相比，展现出卓越性能。材质估计方法对生成纹理和真实照片均具有强大的鲁棒性。此外，该框架在文本到材质、图像到材质、结构引导生成和材质编辑等多种应用中表现出高度灵活性。

Conclusion: 本研究通过创新的两阶段扩散模型框架，有效解决了PBR材质创建中质量、灵活性和用户控制的挑战，实现了高效、高质量、鲁棒且多功能的材质生成与估计。

Abstract: Material creation and reconstruction are crucial for appearance modeling but
traditionally require significant time and expertise from artists. While recent
methods leverage visual foundation models to synthesize PBR materials from
user-provided inputs, they often fall short in quality, flexibility, and user
control. We propose a novel two-stage generate-and-estimate framework for PBR
material generation. In the generation stage, a fine-tuned diffusion model
synthesizes shaded, tileable texture images aligned with user input. In the
estimation stage, we introduce a chained decomposition scheme that sequentially
predicts SVBRDF channels by passing previously extracted representation as
input into a single-step image-conditional diffusion model. Our method is
efficient, high quality, and enables flexible user control. We evaluate our
approach against existing material generation and estimation methods,
demonstrating superior performance. Our material estimation method shows strong
robustness on both generated textures and in-the-wild photographs. Furthermore,
we highlight the flexibility of our framework across diverse applications,
including text-to-material, image-to-material, structure-guided generation, and
material editing.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [224] [Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks](https://arxiv.org/abs/2509.09706)
*Taniya Gidatkar,Oluwaseun Ajao,Matthew Shardlow*

Main category: cs.CR

TL;DR: 本研究评估了Flan-T5、BERT和RoBERTa-Base等大型语言模型对对抗性攻击的韧性。结果显示RoBERTa-Base和FlanT5具有显著韧性，而BERT-Base则非常脆弱。研究还发现有效防御机制通常需要大量计算资源，并为开发更高效的防御策略提供了建议。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）对对抗性攻击的抵抗能力，以深入了解LLM的安全性，并识别当前防护方法的现有优势与劣势。

Method: 使用TextFooler和BERTAttack这两种系统设计的对抗性测试工具，对Flan-T5、BERT和RoBERTa-Base三种大型语言模型进行评估。

Result: RoBERTa-Base和FlanT5表现出卓越的韧性，在复杂的攻击下仍能保持准确性，攻击成功率为0%。相比之下，BERT-Base显示出显著的脆弱性，TextFooler攻击成功率达93.75%，使其模型准确率从48%大幅降至3%。研究还发现，虽然某些LLM已开发出有效的防御机制，但这些安全防护措施通常需要大量的计算资源。

Conclusion: 本研究通过识别现有防护方法的优缺点，增进了对大型语言模型安全性的理解。同时，为开发更高效和有效的防御策略提供了实用的建议，强调了LLM防御在有效性和资源成本之间的权衡。

Abstract: This study evaluates the resilience of large language models (LLMs) against
adversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.
Using systematically designed adversarial tests through TextFooler and
BERTAttack, we found significant variations in model robustness. RoBERTa-Base
and FlanT5 demonstrated remarkable resilience, maintaining accuracy even when
subjected to sophisticated attacks, with attack success rates of 0%. In
contrast. BERT-Base showed considerable vulnerability, with TextFooler
achieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.
Our research reveals that while certain LLMs have developed effective defensive
mechanisms, these safeguards often require substantial computational resources.
This study contributes to the understanding of LLM security by identifying
existing strengths and weaknesses in current safeguarding approaches and
proposes practical recommendations for developing more efficient and effective
defensive strategies.

</details>


### [225] [ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full Version)](https://arxiv.org/abs/2509.09787)
*Nojan Sheybani,Alessandro Pegoraro,Jonathan Knauer,Phillip Rieger,Elissa Mollakuqe,Farinaz Koushanfar,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: ZORRO是一个针对Split Learning（SL）的防御方案，它利用交互式零知识证明（ZKPs）来验证客户端的本地训练完整性，有效抵御后门攻击，同时保持低开销。


<details>
  <summary>Details</summary>
Motivation: Split Learning在资源受限和敏感数据场景下具有优势，但面临恶意客户端通过中毒中间梯度注入后门攻击的风险。现有防御方案存在局限性，如侧重服务器端保护、引入额外开销，以及难以强制客户端正确执行防御算法。

Method: ZORRO提出了一种私有、可验证且鲁棒的SL防御方案。它利用交互式零知识证明（ZKPs）让客户端证明其本地防御算法的正确执行，从而提供计算完整性证明，确保本地训练的DNN部分是良性的。通过利用模型分区的频率表示，ZORRO能在不受信任的环境中对本地训练的模型进行深入检查。

Result: 在对不同模型架构、攻击策略和数据场景进行的广泛评估中，ZORRO将攻击成功率降低到6%以下。即使对于客户端存储百万参数的模型，其开销也低于10秒。

Conclusion: ZORRO通过提供可验证的客户端防御机制，有效抵御了Split Learning中的后门攻击，同时保持了较低的计算开销，展现了其在保护分布式学习完整性方面的有效性。

Abstract: Split Learning (SL) is a distributed learning approach that enables
resource-constrained clients to collaboratively train deep neural networks
(DNNs) by offloading most layers to a central server while keeping in- and
output layers on the client-side. This setup enables SL to leverage server
computation capacities without sharing data, making it highly effective in
resource-constrained environments dealing with sensitive data. However, the
distributed nature enables malicious clients to manipulate the training
process. By sending poisoned intermediate gradients, they can inject backdoors
into the shared DNN. Existing defenses are limited by often focusing on
server-side protection and introducing additional overhead for the server. A
significant challenge for client-side defenses is enforcing malicious clients
to correctly execute the defense algorithm.
  We present ZORRO, a private, verifiable, and robust SL defense scheme.
Through our novel design and application of interactive zero-knowledge proofs
(ZKPs), clients prove their correct execution of a client-located defense
algorithm, resulting in proofs of computational integrity attesting to the
benign nature of locally trained DNN portions. Leveraging the frequency
representation of model partitions enables ZORRO to conduct an in-depth
inspection of the locally trained models in an untrusted environment, ensuring
that each client forwards a benign checkpoint to its succeeding client. In our
extensive evaluation, covering different model architectures as well as various
attack strategies and data scenarios, we show ZORRO's effectiveness, as it
reduces the attack success rate to less than 6\% while causing even for models
storing \numprint{1000000} parameters on the client-side an overhead of less
than 10 seconds.

</details>


### [226] [SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization](https://arxiv.org/abs/2509.09942)
*Lei Yu,Jingyuan Zhang,Xin Wang,Jiajia Ma,Li Yang,Fengjun Zhang*

Main category: cs.CR

TL;DR: SmartCoder-R1是一个基于Qwen2.5-Coder-7B的新框架，它通过持续预训练、长链思维监督微调和安全感知组相对策略优化，实现了安全且可解释的智能合约生成，并在多项关键指标上大幅超越现有基线，达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 智能合约中的漏洞可能导致灾难性金融损失。大型语言模型（LLMs）在生成智能合约时，因其“黑箱”操作（缺乏透明推理）和生成代码中存在严重安全漏洞，使得这一挑战更加严峻。

Method: 本文提出了SmartCoder-R1框架，基于Qwen2.5-Coder-7B，分三阶段实现：1. 进行持续预训练（CPT）以特化模型。2. 对7,998个专家验证的推理-代码样本进行长链思维监督微调（L-CoT SFT），训练模型模拟人类安全分析。3. 采用安全感知组相对策略优化（S-GRPO）的强化学习阶段，通过优化编译成功、安全合规和格式正确性的加权奖励信号来直接缓解漏洞。

Result: SmartCoder-R1在包含756个真实世界函数的基准测试中，超越17个基线模型，建立了新的最先进水平。它在五项关键指标上表现最佳：ComPass 87.70%、VulRate 8.60%、SafeAval 80.16%、FuncRate 53.84%、FullRate 50.53%。其中FullRate比最强基线DeepSeek-R1相对提升45.79%。此外，其生成的推理在人工评估中也表现出色，功能性、安全性和清晰度分别达到82.7%、85.3%和90.7%的高质量评级。

Conclusion: SmartCoder-R1通过创新的多阶段训练方法，成功地解决了大型语言模型在智能合约生成中存在的安全性与可解释性问题，显著提高了生成代码的质量和安全性，并提供了高质量、人类可理解的推理过程，确立了该领域新的技术水平。

Abstract: Smart contracts automate the management of high-value assets, where
vulnerabilities can lead to catastrophic financial losses. This challenge is
amplified in Large Language Models (LLMs) by two interconnected failures: they
operate as unauditable "black boxes" lacking a transparent reasoning process,
and consequently, generate code riddled with critical security vulnerabilities.
To address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a
novel framework for secure and explainable smart contract generation. It begins
with Continual Pre-training (CPT) to specialize the model. We then apply Long
Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated
reasoning-and-code samples to train the model to emulate human security
analysis. Finally, to directly mitigate vulnerabilities, we employ
Security-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement
learning phase that refines the generation policy by optimizing a weighted
reward signal for compilation success, security compliance, and format
correctness. Evaluated against 17 baselines on a benchmark of 756 real-world
functions, SmartCoder-R1 establishes a new state of the art, achieving top
performance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a
SafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This
FullRate marks a 45.79% relative improvement over the strongest baseline,
DeepSeek-R1. Crucially, its generated reasoning also excels in human
evaluations, achieving high-quality ratings for Functionality (82.7%), Security
(85.3%), and Clarity (90.7%).

</details>


### [227] [Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching](https://arxiv.org/abs/2509.09970)
*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.CR

TL;DR: 本文提出一种三阶段方法，结合LLM生成、自动化安全验证和迭代改进，显著提升了由大型语言模型（LLMs）生成的嵌入式系统固件的安全性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成嵌入式系统固件方面潜力巨大，但存在引入安全漏洞和无法满足实时性能约束的问题。

Method: 提出三阶段方法：1) 使用结构化提示词，通过GPT-4等LLM在虚拟化环境（QEMU/FreeRTOS）中生成固件；2) 进行自动化安全验证，包括模糊测试、静态分析和运行时监控，以检测缓冲区溢出、竞态条件等漏洞；3) 引入专门的AI代理（威胁检测、性能优化、合规验证）协作，对识别出的CWE分类问题进行迭代修复，由LLM生成针对性补丁。

Result: 实验显示，漏洞修复率达92.4%（提升37.3%），威胁模型合规性达95.8%，安全覆盖指数为0.87。实时性能方面，最差执行时间为8.6ms，抖动为195µs。

Conclusion: 该流程有效增强了固件的安全性和性能，并为未来研究贡献了开源数据集。

Abstract: Large Language Models (LLMs) show promise in generating firmware for embedded
systems, but often introduce security flaws and fail to meet real-time
performance constraints. This paper proposes a three-phase methodology that
combines LLM-based firmware generation with automated security validation and
iterative refinement in a virtualized environment. Using structured prompts,
models like GPT-4 generate firmware for networking and control tasks, deployed
on FreeRTOS via QEMU. These implementations are tested using fuzzing, static
analysis, and runtime monitoring to detect vulnerabilities such as buffer
overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats
(CWE-400). Specialized AI agents for Threat Detection, Performance
Optimization, and Compliance Verification collaborate to improve detection and
remediation. Identified issues are categorized using CWE, then used to prompt
targeted LLM-generated patches in an iterative loop. Experiments show a 92.4\%
Vulnerability Remediation Rate (37.3\% improvement), 95.8\% Threat Model
Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms
worst-case execution time and 195{\mu}s jitter. This process enhances firmware
security and performance while contributing an open-source dataset for future
research.

</details>


### [228] [Investigating Feature Attribution for 5G Network Intrusion Detection](https://arxiv.org/abs/2509.10206)
*Federica Uccello,Simin Nadjm-Tehrani*

Main category: cs.CR

TL;DR: 本文对比了SHAP和VoTE-XAI两种XAI方法在5G网络安全警报解释中的表现。VoTE-XAI在解释的简洁性、效率和关键特征捕获方面优于SHAP，暗示逻辑解释方法可能更适用于未来通信系统中的可操作性事件响应。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络在关键应用中的兴起，需要从简单的恶意活动检测转向提供可靠、可缓解的判断系统。理解和解释机器学习模型的安全警报对于实现可操作的事件响应至关重要。现有基于统计关联特征的XAI技术（如SHAP）可能不适用于未来通信系统，因此需要探索更有效、更相关的解释方法。

Method: 研究通过比较SHAP（统计关联）和VoTE-XAI（逻辑解释）两种XAI方法，分析它们对XGBoost模型在三种不同用例和多种5G通信攻击下生成的警报的解释。评估解释的三个指标是：稀疏性（简洁性）、稳定性（一致性）和效率（生成速度）。

Result: 研究发现VoTE-XAI在解释的稀疏性上表现更好，例如在92个特征的5G网络中，VoTE-XAI仅识别出6个重要特征，而SHAP识别出20多个。SHAP和VoTE-XAI选择的特征存在显著差异，但VoTE-XAI并未遗漏SHAP排名前列的关键特征。在效率方面，VoTE-XAI显著更快，在478个高维特征设置下，生成单个解释所需时间不到0.002秒。

Conclusion: 基于逻辑解释的VoTE-XAI方法在提供简洁且高效的解释方面优于基于统计关联的SHAP方法，并能有效捕获关键特征。这表明基于逻辑解释的方法可能更适用于5G网络等未来通信系统中，以实现快速、可操作的事件响应。

Abstract: With the rise of fifth-generation (5G) networks in critical applications, it
is urgent to move from detection of malicious activity to systems capable of
providing a reliable verdict suitable for mitigation. In this regard,
understanding and interpreting machine learning (ML) models' security alerts is
crucial for enabling actionable incident response orchestration. Explainable
Artificial Intelligence (XAI) techniques are expected to enhance trust by
providing insights into why alerts are raised. A dominant approach
statistically associates feature sets that can be correlated to a given alert.
This paper starts by questioning whether such attribution is relevant for
future generation communication systems, and investigates its merits in
comparison with an approach based on logical explanations. We extensively study
two methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts
generated by an XGBoost model in three different use cases with several 5G
communication attacks. We identify three metrics for assessing explanations:
sparsity, how concise they are; stability, how consistent they are across
samples from the same attack type; and efficiency, how fast an explanation is
generated. As an example, in a 5G network with 92 features, 6 were deemed
important by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while
SHAP identified over 20. More importantly, we found a significant divergence
between features selected by SHAP and VoTE-XAI. However, none of the top-ranked
features selected by SHAP were missed by VoTE-XAI. When it comes to efficiency
of providing interpretations, we found that VoTE-XAI is significantly more
responsive, e.g. it provides a single explanation in under 0.002 seconds, in a
high-dimensional setting (478 features).

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [229] [Reinforcement learning for spin torque oscillator tasks](https://arxiv.org/abs/2509.10057)
*Jakub Mojsiejuk,Sławomir Ziętek,Witold Skowroński*

Main category: physics.app-ph

TL;DR: 利用强化学习实现自旋电子振荡器的自动同步，并展示了收敛性和能效的提升。


<details>
  <summary>Details</summary>
Motivation: 解决自旋电子振荡器（STO）的自动同步问题。

Method: 采用强化学习（RL）方法。通过对宏自旋Landau-Lifschitz-Gilbert-Slonczewski方程进行数值求解来模拟STO，并训练两种RL智能体在固定步数内与目标频率同步。研究还探索了对基础任务的修改。

Result: 在模拟环境中，同步的收敛性和能效均得到了显著改善。

Conclusion: 强化学习是实现自旋电子振荡器自动同步的有效方法，能够提升同步的收敛性和能效。

Abstract: We address the problem of automatic synchronisation of the spintronic
oscillator (STO) by means of reinforcement learning (RL). A numerical solution
of the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to
simulate the STO and we train the two types of RL agents to synchronise with a
target frequency within a fixed number of steps. We explore modifications to
this base task and show an improvement in both convergence and energy
efficiency of the synchronisation that can be easily achieved in the simulated
environment.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [230] [VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions](https://arxiv.org/abs/2509.09716)
*Jun Zhan,Mingyang Han,Yuxuan Xie,Chen Wang,Dong Zhang,Kexin Huang,Haoxiang Shi,DongXiao Wang,Tengtao Song,Qinyuan Cheng,Shimin Li,Jun Song,Xipeng Qiu,Bo Zheng*

Main category: cs.SD

TL;DR: 本文提出语音风格适应（VSA）新任务，旨在评估语音大模型（SLMs）根据口语指令调整说话风格的能力。为此，作者发布了双语基准VStyle和评估框架LALM as a Judge。实验表明，当前SLMs在此任务上存在明显局限。


<details>
  <summary>Details</summary>
Motivation: 尽管语音大模型（SLMs）在语义准确性和指令遵循方面取得进展，但其根据口语指令调整说话风格的能力受关注有限。为实现更自然的人机交互，SLMs需具备这种风格适应能力。

Method: 引入语音风格适应（VSA）任务，要求SLMs根据口语指令修改音色、韵律或人设等风格。构建了VStyle双语（中英）基准，涵盖声学属性、自然语言指令、角色扮演和隐含共情四类。提出了“大音频语言模型作为评判者”（LALM as a Judge）框架，逐步评估文本忠实度、风格一致性和自然度。

Result: 对商业系统和开源SLMs的实验结果表明，当前模型在可控风格适应方面存在明显局限性，凸显了该任务的新颖性和挑战性。

Conclusion: 当前语音大模型难以实现可控的语音风格适应。VSA是一个具有挑战性的新任务。VStyle基准和评估工具的发布，为推动以人为中心的口语交互奠定了基础。

Abstract: Spoken language models (SLMs) have emerged as a unified paradigm for speech
understanding and generation, enabling natural human machine interaction.
However, while most progress has focused on semantic accuracy and instruction
following, the ability of SLMs to adapt their speaking style based on spoken
instructions has received limited attention. We introduce Voice Style
Adaptation (VSA), a new task that examines whether SLMs can modify their
speaking style, such as timbre, prosody, or persona following natural language
spoken commands. To study this task, we present VStyle, a bilingual (Chinese &
English) benchmark covering four categories of speech generation: acoustic
attributes, natural language instruction, role play, and implicit empathy. We
also introduce the Large Audio Language Model as a Judge (LALM as a Judge)
framework, which progressively evaluates outputs along textual faithfulness,
style adherence, and naturalness, ensuring reproducible and objective
assessment. Experiments on commercial systems and open source SLMs demonstrate
that current models face clear limitations in controllable style adaptation,
highlighting both the novelty and challenge of this task. By releasing VStyle
and its evaluation toolkit, we aim to provide the community with a foundation
for advancing human centered spoken interaction. The dataset and code are
publicly available at
\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.

</details>


### [231] [Testing chatbots on the creation of encoders for audio conditioned image generation](https://arxiv.org/abs/2509.09717)
*Jorge E. León,Miguel Carrasco*

Main category: cs.SD

TL;DR: 本研究探索了利用聊天机器人设计音频编码器以替换Stable Diffusion 1.5中的文本编码器，实现从声音合成图像。尽管聊天机器人能设计模型，但无一能将音频嵌入与文本嵌入可靠对齐，导致结果不尽人意，揭示了当前聊天机器人的“编码鸿沟”。


<details>
  <summary>Details</summary>
Motivation: 一方面，聊天机器人在编码任务中的应用日益普及；另一方面，现代生成式图像模型主要依赖文本编码器，忽视了音频作为输入的潜力。因此，本研究旨在探索先进对话代理（聊天机器人）是否能设计出有效的音频编码器，以使Stable Diffusion 1.5能直接从声音合成图像。

Method: 向五个公开可用的聊天机器人（如Gemini, Grok）提供一组明确的共享条件，要求它们提出神经架构作为音频编码器。对每个有效的建议编码器，使用超过两百万条上下文相关的音频-图像-文本观测数据进行训练，并在独立的验证集和测试集上通过多种指标和生成图像的定性分析进行评估。

Result: 几乎所有聊天机器人都生成了有效的模型设计，但无一达到令人满意的结果，表明其音频嵌入未能与原始文本编码器可靠对齐。在所有提案中，Gemini音频编码器显示出最佳的定量指标，而Grok音频编码器产生了更连贯的图像（尤其在与文本编码器配对时）。研究结果揭示了聊天机器人普遍存在的架构偏见，并强调了这些模型未来版本需要弥补的“编码鸿沟”。

Conclusion: 当前最先进的聊天机器人尚无法设计出能有效对齐音频和文本嵌入以实现满意图像合成的音频编码器。聊天机器人生成的模型设计存在共同的架构偏见，凸显了其在特定编码任务上的“编码鸿沟”。未来的研究应专注于更专业化的任务，以全面检验聊天机器人的创造力和推理能力。

Abstract: On one hand, recent advances in chatbots has led to a rising popularity in
using these models for coding tasks. On the other hand, modern generative image
models primarily rely on text encoders to translate semantic concepts into
visual representations, even when there is clear evidence that audio can be
employed as input as well. Given the previous, in this work, we explore whether
state-of-the-art conversational agents can design effective audio encoders to
replace the CLIP text encoder from Stable Diffusion 1.5, enabling image
synthesis directly from sound. We prompted five publicly available chatbots to
propose neural architectures to work as these audio encoders, with a set of
well-explained shared conditions. Each valid suggested encoder was trained on
over two million context related audio-image-text observations, and evaluated
on held-out validation and test sets using various metrics, together with a
qualitative analysis of their generated images. Although almost all chatbots
generated valid model designs, none achieved satisfactory results, indicating
that their audio embeddings failed to align reliably with those of the original
text encoder. Among the proposals, the Gemini audio encoder showed the best
quantitative metrics, while the Grok audio encoder produced more coherent
images (particularly, when paired with the text encoder). Our findings reveal a
shared architectural bias across chatbots and underscore the remaining coding
gap that needs to be bridged in future versions of these models. We also
created a public demo so everyone could study and try out these audio encoders.
Finally, we propose research questions that should be tackled in the future,
and encourage other researchers to perform more focused and highly specialized
tasks like this one, so the respective chatbots cannot make use of well-known
solutions and their creativity/reasoning is fully tested.

</details>


### [232] [SoilSound: Smartphone-based Soil Moisture Estimation](https://arxiv.org/abs/2509.09823)
*Yixuan Gao,Tanvir Ahmed,Shuang He,Zhongqi Cheng,Rajalakshmi Nandakumar*

Main category: cs.SD

TL;DR: SoilSound是一个基于智能手机的声学传感系统，无需校准或扰动土壤即可准确测量土壤湿度。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度监测方法要么需要侵入性探头扰动土壤，要么需要专业设备，限制了公众的获取和使用。

Method: 利用智能手机内置扬声器和麦克风，通过垂直扫描机制发射声学啁啾信号并记录反射。提出一种基于表面粗糙度效应的声学反射模型，并将处理后的反射数据输入卷积神经网络进行设备端土壤湿度估计。

Result: 在实验室和户外测试中，SoilSound实现了2.39%的平均绝对误差（MAE），能准确追踪15.9%至34.0%范围内的土壤湿度，适用于多种土壤类型、环境和用户，且无需校准或扰动土壤。

Conclusion: SoilSound提供了一种普及、无侵入、免校准的土壤湿度监测方案，赋能家庭园丁、城市农民、公民科学家以及资源有限的农业社区。

Abstract: Soil moisture monitoring is essential for agriculture and environmental
management, yet existing methods require either invasive probes disturbing the
soil or specialized equipment, limiting access to the public. We present
SoilSound, an ubiquitous accessible smartphone-based acoustic sensing system
that can measure soil moisture without disturbing the soil. We leverage the
built-in speaker and microphone to perform a vertical scan mechanism to
accurately measure moisture without any calibration. Unlike existing work that
use transmissive properties, we propose an alternate model for acoustic
reflections in soil based on the surface roughness effect to enable moisture
sensing without disturbing the soil. The system works by sending acoustic
chirps towards the soil and recording the reflections during a vertical scan,
which are then processed and fed to a convolutional neural network for
on-device soil moisture estimation with negligible computational, memory, or
power overhead. We evaluated the system by training with curated soils in boxes
in the lab and testing in the outdoor fields and show that SoilSound achieves a
mean absolute error (MAE) of 2.39% across 10 different locations. Overall, the
evaluation shows that SoilSound can accurately track soil moisture levels
ranging from 15.9% to 34.0% across multiple soil types, environments, and
users; without requiring any calibration or disturbing the soil, enabling
widespread moisture monitoring for home gardeners, urban farmers, citizen
scientists, and agricultural communities in resource-limited settings.

</details>


### [233] [CoDiCodec: Unifying Continuous and Discrete Compressed Representations of Audio](https://arxiv.org/abs/2509.09836)
*Marco Pasini,Stefan Lattner,George Fazekas*

Main category: cs.SD

TL;DR: CoDiCodec是一种新型音频自编码器，能从单一模型同时生成高压缩率的连续嵌入和离散编码，提供灵活的下游生成任务选择，并实现卓越的音频重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有音频自编码器在连续嵌入和离散编码之间需要强制选择，且难以在保持音频保真度的同时实现高压缩比。

Method: 引入CoDiCodec，通过摘要嵌入高效编码全局特征。利用有限标量量化（FSQ）及新型FSQ-dropout技术，从同一模型生成连续嵌入（约11 Hz）和离散编码（2.38 kbps）。仅使用单一一致性损失进行端到端训练。支持自回归解码和新型并行解码策略，其中并行解码策略能实现更优音质和更快解码速度。

Result: CoDiCodec在相似比特率下，重建音频质量优于现有连续和离散自编码器。

Conclusion: CoDiCodec为音频压缩提供了一种统一方法，弥合了连续和离散生成建模范式之间的鸿沟。

Abstract: Efficiently representing audio signals in a compressed latent space is
critical for latent generative modelling. However, existing autoencoders often
force a choice between continuous embeddings and discrete tokens. Furthermore,
achieving high compression ratios while maintaining audio fidelity remains a
challenge. We introduce CoDiCodec, a novel audio autoencoder that overcomes
these limitations by both efficiently encoding global features via summary
embeddings, and by producing both compressed continuous embeddings at ~ 11 Hz
and discrete tokens at a rate of 2.38 kbps from the same trained model,
offering unprecedented flexibility for different downstream generative tasks.
This is achieved through Finite Scalar Quantization (FSQ) and a novel
FSQ-dropout technique, and does not require additional loss terms beyond the
single consistency loss used for end-to-end training. CoDiCodec supports both
autoregressive decoding and a novel parallel decoding strategy, with the latter
achieving superior audio quality and faster decoding. CoDiCodec outperforms
existing continuous and discrete autoencoders at similar bitrates in terms of
reconstruction audio quality. Our work enables a unified approach to audio
compression, bridging the gap between continuous and discrete generative
modelling paradigms.

</details>


### [234] [Prototypical Contrastive Learning For Improved Few-Shot Audio Classification](https://arxiv.org/abs/2509.10074)
*Christos Sgouropoulos,Christos Nikou,Stefanos Vlachos,Vasileios Theiou,Christos Foukanelis,Theodoros Giannakopoulos*

Main category: cs.SD

TL;DR: 该研究通过将监督对比损失（特别是角度损失）集成到原型少样本训练中，并结合SpecAugment和自注意力机制，显著提升了音频分类的少样本学习性能，在MetaAudio基准上达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 虽然少样本学习在图像领域取得了广泛研究，但在音频分类领域仍相对未充分探索。本研究旨在解决在标注数据有限场景下，音频分类少样本学习的挑战。

Method: 将监督对比损失集成到原型少样本训练中，并证明角度损失相比标准对比损失能进一步提升性能。该方法利用SpecAugment进行数据增强，随后通过自注意力机制将增强输入的多样信息封装成统一的嵌入。

Result: 所提出的方法在MetaAudio基准的5-way, 5-shot设置中，取得了最先进的性能。

Conclusion: 通过引入角度监督对比损失并结合SpecAugment和自注意力机制，该方法有效提高了音频分类的少样本学习能力，证明了其在有限标注数据场景下的优越性。

Abstract: Few-shot learning has emerged as a powerful paradigm for training models with
limited labeled data, addressing challenges in scenarios where large-scale
annotation is impractical. While extensive research has been conducted in the
image domain, few-shot learning in audio classification remains relatively
underexplored. In this work, we investigate the effect of integrating
supervised contrastive loss into prototypical few shot training for audio
classification. In detail, we demonstrate that angular loss further improves
the performance compared to the standard contrastive loss. Our method leverages
SpecAugment followed by a self-attention mechanism to encapsulate diverse
information of augmented input versions into one unified embedding. We evaluate
our approach on MetaAudio, a benchmark including five datasets with predefined
splits, standardized preprocessing, and a comprehensive set of few-shot
learning models for comparison. The proposed approach achieves state-of-the-art
performance in a 5-way, 5-shot setting.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [235] [HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets](https://arxiv.org/abs/2509.09740)
*Ying Yuan,Xing-Yue Monica Ge,Aaron Archer Waterman,Tommaso Biancalani,David Richmond,Yogesh Pandit,Avtar Singh,Russell Littman,Jin Liu,Jan-Christian Huetter,Vladimir Ermakov*

Main category: q-bio.QM

TL;DR: HYPOGENEAGENT是一个LLM驱动的框架，将单细胞聚类注释转化为可量化优化的任务。它利用LLM生成GO假设，并通过评估聚类的内部一致性和外部区分度来计算分辨率评分，该评分在测试中优于传统指标，实现了更客观的聚类分辨率选择和功能注释。


<details>
  <summary>Details</summary>
Motivation: 大规模单细胞和Perturb-seq研究中，聚类分辨率的选择和功能注释是固有的主观任务，依赖于启发式方法和专家判断，缺乏客观性。

Method: 本文提出了HYPOGENEAGENT框架。首先，一个作为基因集分析师的LLM对基因程序或扰动模块内容进行分析，生成带置信分数的GO假设排名列表。随后，通过句子嵌入模型计算所有预测描述的余弦相似度，评估聚类内部一致性（intra-cluster agreement）和外部区分度（inter-cluster separation）。将这两者结合，生成一个代理衍生的分辨率评分，该评分在聚类同时展现出连贯性和互斥性时达到最大值。

Result: 在K562 CRISPRi Perturb-seq数据集上的初步测试表明，HYPOGENEAGENT生成的分辨率评分在选择与已知通路对齐的聚类粒度方面，优于剪影分数和模块化分数等经典指标。

Conclusion: 研究结果确立了LLM代理作为聚类分辨率和功能注释的客观评估者的地位，为单细胞多组学研究中全自动化、上下文感知的解释流程奠定了基础。

Abstract: Large-scale single-cell and Perturb-seq investigations routinely involve
clustering cells and subsequently annotating each cluster with Gene-Ontology
(GO) terms to elucidate the underlying biological programs. However, both
stages, resolution selection and functional annotation, are inherently
subjective, relying on heuristics and expert curation. We present
HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming
cluster annotation into a quantitatively optimizable task. Initially, an LLM
functioning as a gene-set analyst analyzes the content of each gene program or
perturbation module and generates a ranked list of GO-based hypotheses,
accompanied by calibrated confidence scores. Subsequently, we embed every
predicted description with a sentence-embedding model, compute pair-wise cosine
similarities, and let the agent referee panel score (i) the internal
consistency of the predictions, high average similarity within the same
cluster, termed intra-cluster agreement (ii) their external distinctiveness,
low similarity between clusters, termed inter-cluster separation. These two
quantities are combined to produce an agent-derived resolution score, which is
maximized when clusters exhibit simultaneous coherence and mutual exclusivity.
When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary
test, our Resolution Score selects clustering granularities that exhibit
alignment with known pathway compared to classical metrics such silhouette
score, modularity score for gene functional enrichment summary. These findings
establish LLM agents as objective adjudicators of cluster resolution and
functional annotation, thereby paving the way for fully automated,
context-aware interpretation pipelines in single-cell multi-omics studies.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [236] [DCHO: A Decomposition-Composition Framework for Predicting Higher-Order Brain Connectivity to Enhance Diverse Downstream Applications](https://arxiv.org/abs/2509.09696)
*Weibin Li,Wendu Li,Quanying Liu*

Main category: q-bio.NC

TL;DR: 本文提出DCHO，一种基于分解-组合框架的统一方法，用于建模和预测高阶脑连接性(HOBC)的时间演变，并在分类和预测任务中均表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有高阶脑连接性(HOBC)研究主要聚焦于静态分析，限制了其在动态预测任务中的应用，存在将HOBC应用于动态预测的空白。

Method: 提出DCHO，一个基于分解-组合框架的统一方法，将HOBC预测任务分解为HOBC推断和潜在轨迹预测两个子问题。在推断阶段，采用双视图编码器提取多尺度拓扑特征和潜在组合学习器捕获高阶HOBC信息；在预测阶段，引入潜在空间预测损失以增强时间轨迹建模。

Result: DCHO在多个神经影像数据集上进行了广泛实验，在非预测任务（状态分类）和预测任务（脑动力学预测）中均取得了卓越性能，显著优于现有方法。

Conclusion: DCHO提供了一个统一且有效的框架，能够精确建模和预测高阶脑连接性的时间演变，适用于多种脑功能分析任务，解决了现有方法的动态预测局限性。

Abstract: Higher-order brain connectivity (HOBC), which captures interactions among
three or more brain regions, provides richer organizational information than
traditional pairwise functional connectivity (FC). Recent studies have begun to
infer latent HOBC from noninvasive imaging data, but they mainly focus on
static analyses, limiting their applicability in dynamic prediction tasks. To
address this gap, we propose DCHO, a unified approach for modeling and
forecasting the temporal evolution of HOBC based on a Decomposition-Composition
framework, which is applicable to both non-predictive tasks (state
classification) and predictive tasks (brain dynamics forecasting). DCHO adopts
a decomposition-composition strategy that reformulates the prediction task into
two manageable subproblems: HOBC inference and latent trajectory prediction. In
the inference stage, we propose a dual-view encoder to extract multiscale
topological features and a latent combinatorial learner to capture high-level
HOBC information. In the forecasting stage, we introduce a latent-space
prediction loss to enhance the modeling of temporal trajectories. Extensive
experiments on multiple neuroimaging datasets demonstrate that DCHO achieves
superior performance in both non-predictive tasks (state classification) and
predictive tasks (brain dynamics forecasting), significantly outperforming
existing methods.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [237] [Automated Tuning for Diffusion Inverse Problem Solvers without Generative Prior Retraining](https://arxiv.org/abs/2509.09880)
*Yaşar Utku Alçalar,Junno Yun,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 针对扩散模型在逆问题中（如加速MRI）对数据保真度权重敏感的问题，本文提出ZADS方法，可在测试时自适应调整权重，无需重新训练，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散/分数模型是解决逆问题的有效生成先验，但在加速MRI重建等任务中，其性能严重依赖于数据保真度权重的精确调整，尤其是在快速采样和少量去噪步骤下。现有方法常依赖启发式或固定权重，导致泛化能力差，无法适应不同的测量条件和不规则的时间步长调度。

Method: 本文提出零样本自适应扩散采样（ZADS），这是一种测试时优化方法。ZADS能在不重新训练扩散先验的情况下，自适应调整任意噪声调度下的保真度权重。它将去噪过程视为固定的展开采样器，并仅利用欠采样测量数据，以自监督方式优化保真度权重。

Result: 在fastMRI膝盖数据集上的实验表明，ZADS持续优于传统的压缩感知方法和近期基于扩散的方法。它能在不同的噪声调度和采集设置下，提供高质量的重建结果。

Conclusion: ZADS提供了一种鲁棒且有效的解决方案，解决了扩散模型在逆问题中保真度权重调整的挑战，显著提升了重建质量和泛化能力，且无需额外训练成本。

Abstract: Diffusion/score-based models have recently emerged as powerful generative
priors for solving inverse problems, including accelerated MRI reconstruction.
While their flexibility allows decoupling the measurement model from the
learned prior, their performance heavily depends on carefully tuned data
fidelity weights, especially under fast sampling schedules with few denoising
steps. Existing approaches often rely on heuristics or fixed weights, which
fail to generalize across varying measurement conditions and irregular timestep
schedules. In this work, we propose Zero-shot Adaptive Diffusion Sampling
(ZADS), a test-time optimization method that adaptively tunes fidelity weights
across arbitrary noise schedules without requiring retraining of the diffusion
prior. ZADS treats the denoising process as a fixed unrolled sampler and
optimizes fidelity weights in a self-supervised manner using only undersampled
measurements. Experiments on the fastMRI knee dataset demonstrate that ZADS
consistently outperforms both traditional compressed sensing and recent
diffusion-based methods, showcasing its ability to deliver high-fidelity
reconstructions across varying noise schedules and acquisition settings.

</details>


### [238] [Drone-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms](https://arxiv.org/abs/2509.09972)
*Mohammadreza Narimani,Alireza Pourreza,Ali Moghimi,Mohsen Mesgaran,Parastoo Farajpoor,Hamid Jafarbiglu*

Main category: eess.IV

TL;DR: 本研究利用无人机多光谱图像和LSTM深度学习网络，实现了对番茄作物中分枝列当的早期高精度检测。


<details>
  <summary>Details</summary>
Motivation: 分枝列当严重威胁加州番茄产业，其地下生命周期导致早期检测困难，传统化学控制成本高、环境危害大且效果不佳，急需一种有效、无害的早期检测方法。

Method: 结合无人机多光谱图像和长短期记忆（LSTM）深度学习网络，并使用SMOTE技术处理类别不平衡问题。研究在已知列当侵染的番茄农场进行，分析了五个关键生长阶段的多光谱图像，并隔离番茄冠层反射率。通过整合序列生长阶段来提升检测效果。

Result: 在897 GDD时，未整合后续阶段的列当检测准确率为79.09%，召回率为70.36%。整合序列生长阶段后，检测效果显著提升。最佳方案（整合所有生长阶段并结合SMOTE增强）达到了88.37%的总体准确率和95.37%的召回率。

Conclusion: 时间多光谱分析和LSTM网络在早期列当检测中展现出巨大潜力。无人机多光谱遥感结合深度学习可作为强大的精准农业工具，有望减少番茄生产损失并提高可持续性，尽管实际部署仍需更多真实世界数据。

Abstract: This study addresses the escalating threat of branched broomrape (Phelipanche
ramosa) to California's tomato industry, which supplies over 90 percent of U.S.
processing tomatoes. The parasite's largely underground life cycle makes early
detection difficult, while conventional chemical controls are costly,
environmentally harmful, and often ineffective. To address this, we combined
drone-based multispectral imagery with Long Short-Term Memory (LSTM) deep
learning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)
to handle class imbalance. Research was conducted on a known broomrape-infested
tomato farm in Woodland, Yolo County, CA, across five key growth stages
determined by growing degree days (GDD). Multispectral images were processed to
isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with
79.09 percent overall accuracy and 70.36 percent recall without integrating
later stages. Incorporating sequential growth stages with LSTM improved
detection substantially. The best-performing scenario, which integrated all
growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy
and 95.37 percent recall. These results demonstrate the strong potential of
temporal multispectral analysis and LSTM networks for early broomrape
detection. While further real-world data collection is needed for practical
deployment, this study shows that UAV-based multispectral sensing coupled with
deep learning could provide a powerful precision agriculture tool to reduce
losses and improve sustainability in tomato production.

</details>


### [239] [Polarization Denoising and Demosaicking: Dataset and Baseline Method](https://arxiv.org/abs/2509.10098)
*Muhamad Daniel Ariff Bin Abdul Rahman,Yusuke Monno,Masayuki Tanaka,Masatoshi Okutomi*

Main category: eess.IV

TL;DR: 本文提出一个新颖的数据集和一种“先去噪后去马赛克”的方法，用于解决分焦面偏振相机（DoFP）的偏振图像去噪和去马赛克联合任务中数据集和基线方法缺乏的问题，并展示了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏合适的评估数据集和可靠的基线方法，针对分焦面偏振仪的偏振去噪和去马赛克联合任务研究不足。

Method: 本文提出了一个包含40个真实场景和三种噪声级别的新数据集，以及一种基于现有信号处理组件的“先去噪后去马赛克”方法，以提供可复现的解决方案。

Result: 实验结果表明，所提出的方法比其他替代方法具有更高的图像重建性能。

Conclusion: 本文为偏振去噪和去马赛克任务提供了一个坚实的基线，其提出的方法表现出卓越的图像重建性能。

Abstract: A division-of-focal-plane (DoFP) polarimeter enables us to acquire images
with multiple polarization orientations in one shot and thus it is valuable for
many applications using polarimetric information. The image processing pipeline
for a DoFP polarimeter entails two crucial tasks: denoising and demosaicking.
While polarization demosaicking for a noise-free case has increasingly been
studied, the research for the joint task of polarization denoising and
demosaicking is scarce due to the lack of a suitable evaluation dataset and a
solid baseline method. In this paper, we propose a novel dataset and method for
polarization denoising and demosaicking. Our dataset contains 40 real-world
scenes and three noise-level conditions, consisting of pairs of noisy mosaic
inputs and noise-free full images. Our method takes a
denoising-then-demosaicking approach based on well-accepted signal processing
components to offer a reproducible method. Experimental results demonstrate
that our method exhibits higher image reconstruction performance than other
alternative methods, offering a solid baseline.

</details>


### [240] [Multi-pathology Chest X-ray Classification with Rejection Mechanisms](https://arxiv.org/abs/2509.10348)
*Yehudit Aperstein,Amit Tzahar,Alon Gottlib,Tal Verber,Ravit Shagan Damti,Alexander Apartsin*

Main category: eess.IV

TL;DR: 本研究针对深度学习模型在多标签胸部X光诊断中存在的过度自信问题，引入了一种不确定性感知框架，通过选择性预测机制提高诊断的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医疗影像（特别是多标签胸部X光分类）中过度自信会带来显著风险，需要提高模型在不确定情况下的可靠性。

Method: 该研究基于DenseNet-121骨干网络，引入了两种选择性预测机制（基于熵的拒绝和基于置信区间的拒绝），并结合分位数校准程序来调整拒绝阈值，以使模型能够拒绝不确定的预测。

Result: 在PadChest、NIH ChestX-ray14和MIMIC-CXR三个大型数据集上的实验表明，选择性拒绝改善了诊断准确性和覆盖率之间的权衡，其中基于熵的拒绝在所有病理中产生了最高的平均AUC。

Conclusion: 研究结果支持将选择性预测整合到AI辅助诊断工作流程中，为在临床环境中更安全、不确定性感知的深度学习部署提供了实用步骤。

Abstract: Overconfidence in deep learning models poses a significant risk in
high-stakes medical imaging tasks, particularly in multi-label classification
of chest X-rays, where multiple co-occurring pathologies must be detected
simultaneously. This study introduces an uncertainty-aware framework for chest
X-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective
prediction mechanisms: entropy-based rejection and confidence interval-based
rejection. Both methods enable the model to abstain from uncertain predictions,
improving reliability by deferring ambiguous cases to clinical experts. A
quantile-based calibration procedure is employed to tune rejection thresholds
using either global or class-specific strategies. Experiments conducted on
three large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)
demonstrate that selective rejection improves the trade-off between diagnostic
accuracy and coverage, with entropy-based rejection yielding the highest
average AUC across all pathologies. These results support the integration of
selective prediction into AI-assisted diagnostic workflows, providing a
practical step toward safer, uncertainty-aware deployment of deep learning in
clinical settings.

</details>


### [241] [Accelerating 3D Photoacoustic Computed Tomography with End-to-End Physics-Aware Neural Operators](https://arxiv.org/abs/2509.09894)
*Jiayun Wang,Yousuf Aborahama,Arya Khokhar,Yang Zhang,Chuwei Wang,Karteekeya Sastry,Julius Berner,Yilin Luo,Boris Bonev,Zongyi Li,Kamyar Azizzadenesheli,Lihong V. Wang,Anima Anandkumar*

Main category: eess.IV

TL;DR: Pano是一种端到端的物理感知神经网络模型，能从稀疏传感器数据中快速重建高质量3D PACT图像，降低硬件要求，实现实时成像。


<details>
  <summary>Details</summary>
Motivation: 现有3D PACT系统需要密集的传感器阵列和长时间采集，限制了临床应用。研究旨在减少硬件要求和采集时间，同时保持图像质量。

Method: Pano模型直接学习从传感器测量到体素重建的逆声学映射，结合了物理和数据先验知识。它采用球面离散-连续卷积以保留传感器几何结构，并整合了亥姆霍兹方程约束以确保物理一致性，能独立于输入数据分辨率工作。

Result: Pano在模拟和真实实验数据上均表现出强大的鲁棒性和效率，即使在显著减少换能器数量和有限角度采集配置下，也能重建高质量图像。它在多种稀疏采样模式下保持重建保真度，并实现了实时体成像。

Conclusion: Pano为3D PACT在临床前研究和临床应用中提供了一条实用途径，大幅降低了硬件要求，且不损害图像重建质量，使其更易于普及和实现。

Abstract: Photoacoustic computed tomography (PACT) combines optical contrast with
ultrasonic resolution, achieving deep-tissue imaging beyond the optical
diffusion limit. While three-dimensional PACT systems enable high-resolution
volumetric imaging for applications spanning transcranial to breast imaging,
current implementations require dense transducer arrays and prolonged
acquisition times, limiting clinical translation. We introduce Pano (PACT
imaging neural operator), an end-to-end physics-aware model that directly
learns the inverse acoustic mapping from sensor measurements to volumetric
reconstructions. Unlike existing approaches (e.g. universal back-projection
algorithm), Pano learns both physics and data priors while also being agnostic
to the input data resolution. Pano employs spherical discrete-continuous
convolutions to preserve hemispherical sensor geometry, incorporates Helmholtz
equation constraints to ensure physical consistency and operates
resolutionindependently across varying sensor configurations. We demonstrate
the robustness and efficiency of Pano in reconstructing high-quality images
from both simulated and real experimental data, achieving consistent
performance even with significantly reduced transducer counts and limited-angle
acquisition configurations. The framework maintains reconstruction fidelity
across diverse sparse sampling patterns while enabling real-time volumetric
imaging capabilities. This advancement establishes a practical pathway for
making 3D PACT more accessible and feasible for both preclinical research and
clinical applications, substantially reducing hardware requirements without
compromising image reconstruction quality.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [242] [Vibe Check: Understanding the Effects of LLM-Based Conversational Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks](https://arxiv.org/abs/2509.09870)
*Hasibur Rahman,Smit Desai*

Main category: cs.HC

TL;DR: 研究发现，LLM驱动的对话代理（CA）的中等个性表达和与用户的人格匹配度能显著提升用户感知，特别是在外向性和情绪稳定性方面，为CA设计提供了优化方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）使对话代理（CA）能够表达独特个性，但这如何影响用户感知是一个新问题。本研究旨在探究个性表达水平和用户-代理人格匹配度在目标导向任务中对用户感知的影响。

Method: 一项包含150名参与者的被试间实验。参与者与展现低、中或高“大五”人格特质表达水平的CA进行旅行规划任务，CA个性通过“Trait Modulation Keys”框架控制。此外，还进行了聚类分析。

Result: 研究发现：1) 个性表达与用户评价呈倒U型关系，中等表达在智能、享受度、拟人化、采纳意愿、信任和好感度方面获得最积极评价。2) 人格匹配进一步提升了结果，其中外向性和情绪稳定性是最有影响力的特质。3) 聚类分析识别出三种兼容性配置文件，“良好匹配”的用户报告了显著积极的感知。

Conclusion: 个性表达（中等水平）和战略性特质匹配（特别是外向性和情绪稳定性）构成了CA个性的最佳设计目标。这些发现为LLM驱动的CA日益普及提供了重要的设计启示。

Abstract: Large language models (LLMs) enable conversational agents (CAs) to express
distinctive personalities, raising new questions about how such designs shape
user perceptions. This study investigates how personality expression levels and
user-agent personality alignment influence perceptions in goal-oriented tasks.
In a between-subjects experiment (N=150), participants completed travel
planning with CAs exhibiting low, medium, or high expression across the Big
Five traits, controlled via our novel Trait Modulation Keys framework. Results
revealed an inverted-U relationship: medium expression produced the most
positive evaluations across Intelligence, Enjoyment, Anthropomorphism,
Intention to Adopt, Trust, and Likeability, significantly outperforming both
extremes. Personality alignment further enhanced outcomes, with Extraversion
and Emotional Stability emerging as the most influential traits. Cluster
analysis identified three distinct compatibility profiles, with "Well-Aligned"
users reporting substantially positive perceptions. These findings demonstrate
that personality expression and strategic trait alignment constitute optimal
design targets for CA personality, offering design implications as LLM-based
CAs become increasingly prevalent.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [243] [Engineering Spatial and Molecular Features from Cellular Niches to Inform Predictions of Inflammatory Bowel Disease](https://arxiv.org/abs/2509.09923)
*Myles Joshua Toledo Tan,Maria Kapetanaki,Panayiotis V. Benos*

Main category: q-bio.GN

TL;DR: 本研究利用空间转录组学和可解释机器学习，创建了一个计算框架，以准确区分炎症性肠病（IBD）的两种主要亚型（克罗恩病和溃疡性结肠炎），并揭示其潜在的生物学机制。


<details>
  <summary>Details</summary>
Motivation: 由于表现重叠，区分炎症性肠病（IBD）的两种主要亚型：克罗恩病（CD）和溃疡性结肠炎（UC）是一个持续的临床挑战。

Method: 本研究引入了一个新的计算框架，利用空间转录组学（ST）数据构建可解释的机器学习模型进行IBD分类。具体步骤包括：分析健康对照、UC和CD患者的结肠粘膜ST数据；使用非负矩阵分解（NMF）识别出四种重复出现的细胞生态位；从这些生态位系统性地构建了44个特征，涵盖生态位组成、邻域富集和生态位基因信号三个方面；最后，使用多层感知器（MLP）分类器进行训练。

Result: MLP分类器在更具挑战性的三类问题（HC、UC和CD）上实现了0.774 +/- 0.161的准确率，在区分IBD与健康组织的两类问题上达到了0.916 +/- 0.118的准确率。模型可解释性分析表明，生态位空间组织的破坏是普遍炎症的最强预测因子，而UC和CD之间的分类则依赖于特定的生态位基因表达特征。

Conclusion: 这项工作提供了一个稳健的概念验证流程，将描述性空间数据转化为准确且可解释的预测工具，不仅提供了潜在的新诊断范式，还深入揭示了驱动IBD亚型的独特生物学机制。

Abstract: Differentiating between the two main subtypes of Inflammatory Bowel Disease
(IBD): Crohns disease (CD) and ulcerative colitis (UC) is a persistent clinical
challenge due to overlapping presentations. This study introduces a novel
computational framework that employs spatial transcriptomics (ST) to create an
explainable machine learning model for IBD classification. We analyzed ST data
from the colonic mucosa of healthy controls (HC), UC, and CD patients. Using
Non-negative Matrix Factorization (NMF), we first identified four recurring
cellular niches, representing distinct functional microenvironments within the
tissue. From these niches, we systematically engineered 44 features capturing
three key aspects of tissue pathology: niche composition, neighborhood
enrichment, and niche-gene signals. A multilayer perceptron (MLP) classifier
trained on these features achieved an accuracy of 0.774 +/- 0.161 for the more
challenging three-class problem (HC, UC, and CD) and 0.916 +/- 0.118 in the
two-class problem of distinguishing IBD from healthy tissue. Crucially, model
explainability analysis revealed that disruptions in the spatial organization
of niches were the strongest predictors of general inflammation, while the
classification between UC and CD relied on specific niche-gene expression
signatures. This work provides a robust, proof-of-concept pipeline that
transforms descriptive spatial data into an accurate and explainable predictive
tool, offering not only a potential new diagnostic paradigm but also deeper
insights into the distinct biological mechanisms that drive IBD subtypes.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [244] [Off Policy Lyapunov Stability in Reinforcement Learning](https://arxiv.org/abs/2509.09863)
*Sarvan Gill,Daniela Constantinescu*

Main category: eess.SY

TL;DR: 本文提出一种离策略学习Lyapunov函数的方法，以提高强化学习算法（如SAC和PPO）的样本效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法缺乏稳定性保证。虽然现有方法通过学习Lyapunov函数来确保稳定，但这些函数由于其在策略（on-policy）性质而样本效率低下。

Method: 引入一种离策略（off-policy）学习Lyapunov函数的方法，并将其整合到Soft Actor Critic (SAC) 和 Proximal Policy Optimization (PPO) 算法中，以提供数据高效的稳定性证明。

Result: 在倒立摆和四旋翼飞行器的仿真实验中，结合了所提出的离策略Lyapunov函数的SAC和PPO算法展现出显著的性能提升。

Conclusion: 所提出的离策略Lyapunov函数能为强化学习算法提供数据高效的稳定性证明，从而提升算法的性能。

Abstract: Traditional reinforcement learning lacks the ability to provide stability
guarantees. More recent algorithms learn Lyapunov functions alongside the
control policies to ensure stable learning. However, the current self-learned
Lyapunov functions are sample inefficient due to their on-policy nature. This
paper introduces a method for learning Lyapunov functions off-policy and
incorporates the proposed off-policy Lyapunov function into the Soft Actor
Critic and Proximal Policy Optimization algorithms to provide them with a data
efficient stability certificate. Simulations of an inverted pendulum and a
quadrotor illustrate the improved performance of the two algorithms when
endowed with the proposed off-policy Lyapunov function.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [245] [SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints](https://arxiv.org/abs/2509.09853)
*Zhiyu Fan,Kirill Vasilevski,Dayi Lin,Boyuan Chen,Yihao Chen,Zhiqing Zhong,Jie M. Zhang,Pinjia He,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 本文引入了SWE-Effi，一套新的多维度指标，用于重新评估软件工程AI系统的整体效能，该指标平衡了解决方案的准确性与资源消耗（如token和时间），并揭示了系统集成、昂贵失败和预算权衡的关键见解。


<details>
  <summary>Details</summary>
Motivation: 现有的软件工程AI排行榜（如SWE-bench）仅关注解决方案的准确性，却忽略了在资源受限世界中至关重要的效率因素。AI系统不仅要正确，还必须具有成本效益，这是一个普遍存在的问题，需要解决以实现实际部署。

Method: 本文引入了SWE-Effi，一套新的多维度指标来重新评估AI系统的整体效能分数。效能被定义为结果准确性（例如问题解决率）与所消耗资源（例如token和时间）之间的平衡。研究通过使用这些新指标，在SWE-bench基准测试的一个子集上，重新对流行的AI系统进行问题解决任务的排名。

Result: 研究发现AI系统的效能不仅取决于其脚手架，更取决于它与基础模型的整合程度。研究还识别出系统性挑战，如“token雪球效应”和更显著的“昂贵失败”模式（代理在无法解决的任务上消耗过多资源）。此外，还观察到在token预算下和时间预算下的效能之间存在明显的权衡。

Conclusion: 研究结果对实际部署、项目预算管理以及可扩展的强化学习至关重要，强调了在AI系统设计和评估中平衡准确性与资源效率的重要性。系统整合是实现资源高效高性能的关键，而识别和减轻“昂贵失败”对于实际应用和训练成本管理至关重要。

Abstract: The advancement of large language models (LLMs) and code agents has
demonstrated significant potential to assist software engineering (SWE) tasks,
such as autonomous issue resolution and feature addition. Existing AI for
software engineering leaderboards (e.g., SWE-bench) focus solely on solution
accuracy, ignoring the crucial factor of effectiveness in a
resource-constrained world. This is a universal problem that also exists beyond
software engineering tasks: any AI system should be more than correct - it must
also be cost-effective. To address this gap, we introduce SWE-Effi, a set of
new metrics to re-evaluate AI systems in terms of holistic effectiveness
scores. We define effectiveness as the balance between the accuracy of outcome
(e.g., issue resolve rate) and the resources consumed (e.g., token and time).
In this paper, we specifically focus on the software engineering scenario by
re-ranking popular AI systems for issue resolution on a subset of the SWE-bench
benchmark using our new multi-dimensional metrics. We found that AI system's
effectiveness depends not just on the scaffold itself, but on how well it
integrates with the base model, which is key to achieving strong performance in
a resource-efficient manner. We also identified systematic challenges such as
the "token snowball" effect and, more significantly, a pattern of "expensive
failures". In these cases, agents consume excessive resources while stuck on
unsolvable tasks - an issue that not only limits practical deployment but also
drives up the cost of failed rollouts during RL training. Lastly, we observed a
clear trade-off between effectiveness under the token budget and effectiveness
under the time budget, which plays a crucial role in managing project budgets
and enabling scalable reinforcement learning, where fast responses are
essential.

</details>


### [246] [From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem](https://arxiv.org/abs/2509.09873)
*James Jewitt,Hao Li,Bram Adams,Gopi Krishnan Rajbahadur,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 研究揭示了开源AI生态系统中普遍存在的许可冲突问题，并通过大规模审计和原型规则引擎提供了数据驱动的分析和解决方案。


<details>
  <summary>Details</summary>
Motivation: 开源AI生态中隐藏的许可冲突带来严重的法律和道德风险，但目前缺乏数据驱动的理解，包括冲突频率、来源和受影响社区。

Method: 对Hugging Face上的36.4万个数据集、160万个模型及其下游在14万个GitHub项目中的集成进行了首次端到端许可审计。此外，开发了一个可扩展的规则引擎，编码了近200个SPDX和模型特定条款，用于检测许可冲突。

Result: 实证分析显示系统性违规，35.5%的模型到应用程序转换通过宽松条款重新许可而消除了限制性许可条款。原型规则引擎能够解决软件应用程序中86.4%的许可冲突。

Conclusion: 许可合规是开源AI中一个关键的治理挑战。本研究提供了必要的数据和工具，以实现大规模自动化、AI感知的合规性。

Abstract: Hidden license conflicts in the open-source AI ecosystem pose serious legal
and ethical risks, exposing organizations to potential litigation and users to
undisclosed risk. However, the field lacks a data-driven understanding of how
frequently these conflicts occur, where they originate, and which communities
are most affected. We present the first end-to-end audit of licenses for
datasets and models on Hugging Face, as well as their downstream integration
into open-source software applications, covering 364 thousand datasets, 1.6
million models, and 140 thousand GitHub projects. Our empirical analysis
reveals systemic non-compliance in which 35.5% of model-to-application
transitions eliminate restrictive license clauses by relicensing under
permissive terms. In addition, we prototype an extensible rule engine that
encodes almost 200 SPDX and model-specific clauses for detecting license
conflicts, which can solve 86.4% of license conflicts in software applications.
To support future research, we release our dataset and the prototype engine.
Our study highlights license compliance as a critical governance challenge in
open-source AI and provides both the data and tools necessary to enable
automated, AI-aware compliance at scale.

</details>


### [247] [WALL: A Web Application for Automated Quality Assurance using Large Language Models](https://arxiv.org/abs/2509.09918)
*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.SE

TL;DR: WALL是一个集成SonarQube和LLM的Web应用，用于自动化软件问题的检测、修订和评估，有效降低人工工作量并提高修订质量。


<details>
  <summary>Details</summary>
Motivation: 随着软件项目复杂性增加，代码文件中的问题数量和种类也随之增长，需要高效的问题检测、解决和评估工具来应对这一挑战。

Method: 本文提出了WALL，一个结合SonarQube和GPT-3.5 Turbo、GPT-4o等大型语言模型（LLM）的Web应用。WALL包含三个模块：问题提取工具、代码问题修订器和代码比较工具，实现检测、自动修订和评估的无缝流程。

Result: 在对563个文件（超过7,599个问题）的实验中，WALL被证明能有效减少人工工作量并保持高质量修订。结果显示，采用混合使用经济高效和先进LLM的方法可以显著降低成本并提高修订率。

Conclusion: WALL是管理代码质量的有效工具。未来的工作将通过集成开源LLM并消除人工干预来增强WALL的功能，以实现完全自动化的代码质量管理。

Abstract: As software projects become increasingly complex, the volume and variety of
issues in code files have grown substantially. Addressing this challenge
requires efficient issue detection, resolution, and evaluation tools. This
paper presents WALL, a web application that integrates SonarQube and large
language models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these
tasks. WALL comprises three modules: an issue extraction tool, code issues
reviser, and code comparison tool. Together, they enable a seamless pipeline
for detecting software issues, generating automated code revisions, and
evaluating the accuracy of revisions. Our experiments, conducted on 563 files
with over 7,599 issues, demonstrate WALL's effectiveness in reducing human
effort while maintaining high-quality revisions. Results show that employing a
hybrid approach of cost-effective and advanced LLMs can significantly lower
costs and improve revision rates. Future work aims to enhance WALL's
capabilities by integrating open-source LLMs and eliminating human
intervention, paving the way for fully automated code quality management.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [248] [Realistic UE Antennas for 6G in the 3GPP Channel Model](https://arxiv.org/abs/2509.10357)
*Simon Svendsen,Dimitri Gold,Christian Rom,Volker Pauli,Vuokko Nurmela*

Main category: eess.SP

TL;DR: 3GPP Rel.19更新了TR 38.901信道模型，通过更真实地模拟手持设备天线和用户阻塞效应，提高了6G技术评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 6G的演进驱动了3GPP信道模型进行重大更新，特别是在手持设备的UE天线和用户引起的阻塞建模方面。

Method: 基于对参考智能手机在多个频段进行的高保真仿真和测量，引入了一个更真实的框架，该框架能捕获定向天线模式、实际天线放置、极化效应和元件特定阻塞。

Result: 通过使链路级和系统级仿真与实际设备行为保持一致，新模型实现了对6G技术更准确的评估，并支持行业和研究领域之间的一致性能评估。

Conclusion: 3GPP Rel.19信道模型更新为6G技术提供了反映真实设备行为的更准确、更一致的评估工具。

Abstract: The transition to 6G has driven significant updates to the 3GPP channel
model, particularly in modeling UE antennas and user-induced blockage for
handheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more
realistic framework that captures directive antenna patterns, practical antenna
placements, polarization effects, and element-specific blockage. These updates
are based on high-fidelity simulations and measurements of a reference
smartphone across multiple frequency ranges. By aligning link- and system-level
simulations with real-world device behavior, the new model enables more
accurate evaluation of 6G technologies and supports consistent performance
assessment across industry and research.

</details>


### [249] [Machine-learning competition to grade EEG background patterns in newborns with hypoxic-ischaemic encephalopathy](https://arxiv.org/abs/2509.09695)
*Fabio Magarelli,Geraldine B. Boylan,Saeed Montazeri,Feargal O'Sullivan,Dominic Lightbody,Minoo Ashoori,Tamara Skoric Ceranic,John M. O'Toole*

Main category: eess.SP

TL;DR: 本研究为解决新生儿脑功能监测ML模型数据稀缺问题，构建了一个多中心新生儿EEG数据集并举办了ML竞赛，旨在分类异常背景模式。结果显示，深度学习模型在独立验证集上的泛化能力优于特征工程模型，但所有模型性能均显著下降，强调了高质量验证数据和大型多样化数据集对模型泛化能力的重要性，并展示了开放数据和协作ML开发的潜力。


<details>
  <summary>Details</summary>
Motivation: 为支持和改进高危新生儿脑功能监测，开发准确可靠的机器学习模型是必要的，但这受限于高质量、带标注数据的稀缺。ML竞赛被视为获取数据、促进共享学习和利用多样化专业知识的有效途径。

Method: 编译了包含102名新生儿353小时EEG数据的多中心回顾性数据集，进行了匿名化处理并划分为训练、测试和独立验证集，对EEG异常背景模式的严重程度进行分级。随后，创建了网络竞赛平台，举办ML竞赛以开发分类新生儿EEG背景模式严重程度的模型。竞赛结束后，前4名模型的性能在独立的保留验证集上进行了离线评估。

Result: 尽管特征工程模型在测试集上排名第一，但深度学习模型在验证集上表现出更好的泛化能力。所有方法在验证集上的性能相比测试集均有显著下降，突显了模型在未见数据上泛化的挑战。

Conclusion: 研究强调了模型在未见数据上泛化的挑战，以及在新生儿EEG ML研究中使用独立验证数据集的必要性。为确保稳健的泛化能力，ML模型需在大型多样化数据集上进行训练。竞赛结果展示了开放获取数据和协作ML开发在促进协作研究环境及加速新生儿神经监测临床决策支持工具开发方面的潜力。

Abstract: Machine learning (ML) has the potential to support and improve expert
performance in monitoring the brain function of at-risk newborns. Developing
accurate and reliable ML models depends on access to high-quality, annotated
data, a resource in short supply. ML competitions address this need by
providing researchers access to expertly annotated datasets, fostering shared
learning through direct model comparisons, and leveraging the benefits of
crowdsourcing diverse expertise. We compiled a retrospective dataset containing
353 hours of EEG from 102 individual newborns from a multi-centre study. The
data was fully anonymised and divided into training, testing, and held-out
validation datasets. EEGs were graded for the severity of abnormal background
patterns. Next, we created a web-based competition platform and hosted a
machine learning competition to develop ML models for classifying the severity
of EEG background patterns in newborns. After the competition closed, the top 4
performing models were evaluated offline on a separate held-out validation
dataset. Although a feature-based model ranked first on the testing dataset,
deep learning models generalised better on the validation sets. All methods had
a significant decline in validation performance compared to the testing
performance. This highlights the challenges for model generalisation on unseen
data, emphasising the need for held-out validation datasets in ML studies with
neonatal EEG. The study underscores the importance of training ML models on
large and diverse datasets to ensure robust generalisation. The competition's
outcome demonstrates the potential for open-access data and collaborative ML
development to foster a collaborative research environment and expedite the
development of clinical decision-support tools for neonatal neuromonitoring.

</details>


### [250] [FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification](https://arxiv.org/abs/2509.10082)
*Weitao Tang,Johann Vargas-Calixto,Nasim Katebi,Nhi Tran,Sharmony B. Kelly,Gari D. Clifford,Robert Galinsky,Faezeh Marzbanrad*

Main category: eess.SP

TL;DR: FetalSleepNet是首个基于深度学习的胎儿脑电图睡眠分期方法，通过迁移学习和谱均衡实现了高精度分类，适用于低功耗可穿戴监测系统。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑电图获取和解释困难，但准确的睡眠分期有助于早期发现与妊娠并发症（如缺氧）相关的异常脑成熟。

Method: 使用为成人脑电图睡眠分期开发的轻量级深度神经网络，通过成人脑电图进行迁移学习，并结合基于谱均衡的域适应策略，对24只晚期妊娠胎羊的脑电图数据进行训练和分类。

Result: 结果显示，全量微调结合谱均衡实现了最佳的整体性能（准确率：86.6%，宏观F1分数：62.5%），优于基线模型，而直接迁移效果不佳。

Conclusion: FetalSleepNet是首个专为胎儿脑电图自动睡眠分期设计的深度学习框架，其轻量化设计使其适用于低功耗、实时、可穿戴的胎儿监测系统，并可作为标签引擎，助力基于非侵入性信号（如多普勒超声）的训练。

Abstract: Introduction: This study presents FetalSleepNet, the first published deep
learning approach to classifying sleep states from the ovine
electroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and
laborious to interpret consistently. However, accurate sleep stage
classification may aid in the early detection of abnormal brain maturation
associated with pregnancy complications (e.g. hypoxia or intrauterine growth
restriction).
  Methods: EEG electrodes were secured onto the ovine dura over the parietal
cortices of 24 late gestation fetal sheep. A lightweight deep neural network
originally developed for adult EEG sleep staging was trained on the ovine EEG
using transfer learning from adult EEG. A spectral equalisation-based domain
adaptation strategy was used to reduce cross-domain mismatch.
  Results: We demonstrated that while direct transfer performed poorly, full
fine tuning combined with spectral equalisation achieved the best overall
performance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming
baseline models.
  Conclusions: To the best of our knowledge, FetalSleepNet is the first deep
learning framework specifically developed for automated sleep staging from the
fetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier
functions as a label engine, enabling large scale weak/semi supervised labeling
and distillation to facilitate training on less invasive signals that can be
acquired in the clinic, such as Doppler Ultrasound or electrocardiogram data.
FetalSleepNet's lightweight design makes it well suited for deployment in low
power, real time, and wearable fetal monitoring systems.

</details>
