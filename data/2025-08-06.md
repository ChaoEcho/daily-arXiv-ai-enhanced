<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 51]
- [cs.CV](#cs.CV) [Total: 63]
- [cs.AI](#cs.AI) [Total: 52]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.NI](#cs.NI) [Total: 9]
- [cs.IT](#cs.IT) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [eess.SP](#eess.SP) [Total: 4]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation](https://arxiv.org/abs/2508.02808)
*Radhika Dua,Young Joon,Kwon,Siddhant Dogra,Daniel Freedman,Diana Ruan,Motaz Nashawaty,Danielle Rigau,Daniel Alexander Alber,Kang Zhang,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: ICARE是一个基于LLM代理和动态MCQA的放射学报告评估框架，旨在提供可解释且临床相关的评估，其评估结果与专家判断高度一致。


<details>
  <summary>Details</summary>
Motivation: 自动化放射学报告生成（RRG）需要可靠的临床评估，但现有评估指标通常只依赖表面相似度，缺乏可解释性，难以确保安全部署。

Method: 引入了ICARE（可解释且以临床为基础的代理报告评估）框架。该方法利用大型语言模型代理和动态多项选择问答（MCQA），让两个代理（分别持有真实报告和生成报告）相互提问和回答临床相关问题。通过答案的一致性来衡量报告中发现的保留和一致性，以此作为临床精确度和召回率的可解释代理。

Result: 临床医生研究表明，ICARE与专家判断的吻合度显著高于现有指标。扰动分析证实了ICARE对临床内容的敏感性和可复现性，而模型比较则揭示了可解释的错误模式。

Conclusion: ICARE提供了一个透明且可解释的评估机制，能够可靠地评估自动化放射学报告的质量，并弥补了现有评估指标缺乏可解释性的不足，使其更适用于临床部署。

Abstract: Radiological imaging is central to diagnosis, treatment planning, and
clinical decision-making. Vision-language foundation models have spurred
interest in automated radiology report generation (RRG), but safe deployment
requires reliable clinical evaluation of generated reports. Existing metrics
often rely on surface-level similarity or behave as black boxes, lacking
interpretability. We introduce ICARE (Interpretable and Clinically-grounded
Agent-based Report Evaluation), an interpretable evaluation framework
leveraging large language model agents and dynamic multiple-choice question
answering (MCQA). Two agents, each with either the ground-truth or generated
report, generate clinically meaningful questions and quiz each other. Agreement
on answers captures preservation and consistency of findings, serving as
interpretable proxies for clinical precision and recall. By linking scores to
question-answer pairs, ICARE enables transparent, and interpretable assessment.
Clinician studies show ICARE aligns significantly more with expert judgment
than prior metrics. Perturbation analyses confirm sensitivity to clinical
content and reproducibility, while model comparisons reveal interpretable error
patterns.

</details>


### [2] [Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives](https://arxiv.org/abs/2508.02853)
*Yinuo Xu,Veronica Derricks,Allison Earl,David Jurgens*

Main category: cs.CL

TL;DR: 该研究提出DEM-MoE模型，通过整合标注者人口统计信息来建模主观NLP任务中的标注者分歧，并探索使用LLM生成的合成数据来弥补人口统计数据的稀疏性，旨在更好地表征多样化的观点。


<details>
  <summary>Details</summary>
Motivation: 主观性NLP任务中存在标注者分歧，传统的模型难以有效捕捉这种结构化的、群体层面的变异。研究旨在改进模型对多样化视角的表示能力。

Method: ['提出了DEM-MoE (Demographic-Aware Mixture of Experts) 模型，该模型根据标注者的人口统计信息将输入路由到专家子网络，以更好地表示结构化的、群体层面的变异。', '为解决人口统计覆盖稀疏的问题，测试了通过零样本角色提示（zero-shot persona prompting）利用大语言模型（LLM）生成合成标注数据进行数据填充。', '提出并评估了融合真实数据和合成数据的方法，这些策略根据数据集结构进行定制。']

Result: ['DEM-MoE模型在不同人口统计群体中表现出竞争力，并在标注者分歧较大的数据集上显示出尤其出色的结果。', 'LLM生成的合成标注数据与人类标注数据在中等程度上保持一致，并提供了一种可扩展的方式来丰富训练数据。', '发现最佳的真实与合成数据混合策略取决于数据集的结构。']

Conclusion: 该研究的贡献共同提高了对多样化视角的表示能力，有助于更好地处理主观性NLP任务中的标注者分歧。

Abstract: We present an approach to modeling annotator disagreement in subjective NLP
tasks through both architectural and data-centric innovations. Our model,
DEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert
subnetworks based on annotator demographics, enabling it to better represent
structured, group-level variation compared to prior models. DEM-MoE
consistently performs competitively across demographic groups, and shows
especially strong results on datasets with high annotator disagreement. To
address sparse demographic coverage, we test whether LLM-generated synthetic
annotations via zero-shot persona prompting can be used for data imputation. We
show these synthetic judgments align moderately well with human annotations on
our data and offer a scalable way to potentially enrich training data. We then
propose and evaluate approaches for blending real and synthetic data using
strategies tailored to dataset structure. We find that the optimal strategies
depend on dataset structure. Together, these contributions improve the
representation of diverse perspectives.

</details>


### [3] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
*Giovanni Cherubin,Andrew Paverd*

Main category: cs.CL

TL;DR: Highlight & Summarize (H&S)是一种新型检索增强生成（RAG）设计模式，通过隔离用户问题与生成式LLM，从设计上防止了LLM越狱和模型劫持攻击，并在问答质量上优于标准RAG。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的越狱和模型劫持是一个重要且具挑战性的问题。现有防御方法（如硬化系统提示或内容分类器）因输入和输出空间巨大，易被恶意用户绕过，导致LLM生成不良内容或偏离预期任务。

Method: 本文提出并评估了Highlight & Summarize (H&S)，一种新的RAG系统设计模式，旨在从设计层面预防此类攻击。其核心思想是在不向生成式LLM透露用户问题的情况下，基于相关源提供自然语言答案。该方法将处理流程拆分为两个组件：1. **高亮器 (highlighter)**：接收用户问题，并从检索到的文档中提取相关段落；2. **摘要器 (summarizer)**：接收高亮段落，并将其总结为连贯答案。研究评估了H&S在正确性、相关性和响应质量方面的表现。

Result: 研究发现，当使用基于LLM的高亮器时，H&S生成的大多数响应被判断为优于标准的RAG管道。

Conclusion: H&S设计模式能够通过其独特的结构（隔离用户问题）有效预防LLM越狱和模型劫持攻击，同时在生成答案的质量（正确性、相关性和响应质量）方面表现出色，甚至超越了传统的RAG系统。

Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs)
is an important yet challenging task. For example, when interacting with a
chatbot, malicious users can input specially crafted prompts to cause the LLM
to generate undesirable content or perform a completely different task from its
intended purpose. Existing mitigations for such attacks typically rely on
hardening the LLM's system prompt or using a content classifier trained to
detect undesirable content or off-topic conversations. However, these
probabilistic approaches are relatively easy to bypass due to the very large
space of possible inputs and undesirable outputs. In this paper, we present and
evaluate Highlight & Summarize (H&S), a new design pattern for
retrieval-augmented generation (RAG) systems that prevents these attacks by
design. The core idea is to perform the same task as a standard RAG pipeline
(i.e., to provide natural language answers to questions, based on relevant
sources) without ever revealing the user's question to the generative LLM. This
is achieved by splitting the pipeline into two components: a highlighter, which
takes the user's question and extracts relevant passages ("highlights") from
the retrieved documents, and a summarizer, which takes the highlighted passages
and summarizes them into a cohesive answer. We describe several possible
instantiations of H&S and evaluate their generated responses in terms of
correctness, relevance, and response quality. Surprisingly, when using an
LLM-based highlighter, the majority of H&S responses are judged to be better
than those of a standard RAG pipeline.

</details>


### [4] [Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages](https://arxiv.org/abs/2508.02885)
*Elliot Murphy,Rohan Venkatesh,Edward Khokhlovich,Andrey Vyshedskiy*

Main category: cs.CL

TL;DR: 本研究通过行为证据揭示了句法操作“Merge”产生的结构具有三种不同的类型，暗示其认知处理可能由不同机制支持，而非单一进化步骤。


<details>
  <summary>Details</summary>
Motivation: 现代语言学中“Merge”操作的认知基础存在争议，尤其是在其被视为单一不可分操作的演化论与其不同产物可能由不同机制支持的神经认知观之间。本研究旨在系统探究不同句法复杂度的句子理解，以确定是否存在支持不同“Merge”类型独立机制的证据。

Method: 研究人员系统性地调查了参与者对句法复杂度逐渐增加的句子的理解，并对收集到的行为证据进行了聚类分析。

Result: 聚类分析揭示了行为证据支持存在三种不同的句法结构类型。研究讨论这些类型可能在不同的发展阶段出现，并可能遭受选择性损伤。

Conclusion: 尽管核心句法操作“Merge”可能在演化上突然出现并促成了人类物种的符号化转向，但处理不同类型“Merge”产物的认知机制似乎是多样的，而非单一的。

Abstract: In the modern language sciences, the core computational operation of syntax,
'Merge', is defined as an operation that combines two linguistic units (e.g.,
'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase).
This can then be further combined with additional linguistic units based on
this categorial information, respecting non-associativity such that abstract
grouping is respected. Some linguists have embraced the view that Merge is an
elementary, indivisible operation that emerged in a single evolutionary step.
From a neurocognitive standpoint, different mental objects constructed by Merge
may be supported by distinct mechanisms: (1) simple command constructions
(e.g., "eat apples"); (2) the merging of adjectives and nouns ("red boat"); and
(3) the merging of nouns with spatial prepositions ("laptop behind the sofa").
Here, we systematically investigate participants' comprehension of sentences
with increasing levels of syntactic complexity. Clustering analyses revealed
behavioral evidence for three distinct structural types, which we discuss as
potentially emerging at different developmental stages and subject to selective
impairment. While a Merge-based syntax may still have emerged suddenly in
evolutionary time, responsible for the structured symbolic turn our species
took, different cognitive mechanisms seem to underwrite the processing of
various types of Merge-based objects.

</details>


### [5] [Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models](https://arxiv.org/abs/2508.02886)
*Wenjie Luo,Ruocheng Li,Shanshan Zhu,Julian Perry*

Main category: cs.CL

TL;DR: 本文提出Coherent Multimodal Reasoning Framework (CMRF)，通过迭代、自评估的推理机制，增强大型视听语言模型（LVLMs）在复杂、多步、跨模态常识推理任务中的能力，并在多个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）和视听语言模型（LVLMs）在处理复杂、多步、跨模态常识推理任务时表现不佳，常缺乏“深思熟虑”能力，倾向于依赖表面关联而非深度链式推理，尤其在整合视觉信息与抽象概念时。

Method: 提出Coherent Multimodal Reasoning Framework (CMRF)，模仿人类解决问题，分解复杂查询，生成逐步推断并自我纠正。框架包含：推理分解单元（RDU）、上下文推理引擎（CIE）和连贯性评估模块（CAM）。结合自适应迭代优化策略，CMRF系统性地优化推理路径。该框架基于LLaVA-1.6-34B，并利用新型多模态日常活动推理（MDAR）数据集进行训练。

Result: CMRF在VCR、A-OKVQA和DailyLife-MRC等挑战性基准测试中，在开源LVLMs中实现了最先进性能，平均准确率达69.4%，超越最佳开源基线2.4个百分点，在复杂推理场景中表现尤为突出。广泛的消融研究和人工评估证实了各模块的关键贡献及迭代优化的有效性。

Conclusion: CMRF框架通过模拟人类深思熟虑的推理过程，显著提升了LVLMs处理复杂多模态常识推理任务的能力，证明了迭代自评估和模块化方法在促进连贯和准确推理方面的有效性。

Abstract: Despite significant advancements, current large language models (LLMs) and
vision-language models (LVLMs) continue to struggle with complex, multi-step,
cross-modal common sense reasoning tasks, often exhibiting a lack of
"deliberative thinking." They tend to rely on superficial associations rather
than deep, chained inference, particularly when integrating visual information
with abstract concepts. To address this, we propose the Coherent Multimodal
Reasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense
reasoning capabilities through an iterative, self-evaluating inference
mechanism. CMRF mimics human problem-solving by decomposing complex queries,
generating step-by-step inferences, and self-correcting errors. Our framework
integrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking
down problems into sub-questions, a Contextual Inference Engine (CIE) for
contextual inference, and a Coherence Assessment Module (CAM) for evaluating
logical consistency and confidence. Coupled with an Adaptive Iterative
Refinement strategy, CMRF systematically refines its reasoning paths. Built
upon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning
(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source
LVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It
attains an average accuracy of 69.4%, surpassing the best open-source baseline
by +2.4 percentage points, with particular strength in complex reasoning
scenarios. Extensive ablation studies and human evaluations confirm the
critical contributions of each module and the effectiveness of iterative
refinement in fostering more coherent and accurate reasoning.

</details>


### [6] [SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations](https://arxiv.org/abs/2508.02901)
*Osama Khalid,Sanvesh Srivastava,Padmini Srinivasan*

Main category: cs.CL

TL;DR: 提出一种使用低维文体特征和新型SLIM-LLMs模型高效预测感官语言的方法，其性能与全尺寸语言模型相当，但参数大幅减少。


<details>
  <summary>Details</summary>
Motivation: 探索感官语言与传统文体特征（如LIWC衡量）之间的关系，并旨在开发一种更高效、参数更少的模型来理解和预测感官语言。

Method: 采用新颖的降秩岭回归（R4）方法探索和捕获LIWC特征中的文体信息。在此基础上，引入“文体精益可解释模型”（SLIM-LLMs）来建模这些低维文体维度间的非线性关系。

Result: 发现低维度的LIWC潜在表示（r=24）能有效捕获文体信息，用于感官语言预测，效果媲美完整特征集（r=74）。SLIM-LLMs结合低秩LIWC特征，在五种体裁上的表现与全尺寸语言模型匹配，同时模型参数减少了高达80%。

Conclusion: 研究表明，通过对传统文体特征进行降维并结合新颖的SLIM-LLMs模型，可以高效、准确地建模和预测感官语言，显著降低了计算资源需求，为语言分析提供了精简而强大的工具。

Abstract: Sensorial language -- the language connected to our senses including vision,
sound, touch, taste, smell, and interoception, plays a fundamental role in how
we communicate experiences and perceptions. We explore the relationship between
sensorial language and traditional stylistic features, like those measured by
LIWC, using a novel Reduced-Rank Ridge Regression (R4) approach. We demonstrate
that low-dimensional latent representations of LIWC features r = 24 effectively
capture stylistic information for sensorial language prediction compared to the
full feature set (r = 74). We introduce Stylometrically Lean Interpretable
Models (SLIM-LLMs), which model non-linear relationships between these style
dimensions. Evaluated across five genres, SLIM-LLMs with low-rank LIWC features
match the performance of full-scale language models while reducing parameters
by up to 80%.

</details>


### [7] [Can LLMs Generate High-Quality Task-Specific Conversations?](https://arxiv.org/abs/2508.02931)
*Shengqi Li,Amarnath Gupta*

Main category: cs.CL

TL;DR: 本文提出一种参数化框架，通过控制九个关键参数来精确管理大型语言模型的对话质量。


<details>
  <summary>Details</summary>
Motivation: 解决对话生成中的挑战，包括主题连贯性、知识演进、角色一致性和控制粒度问题。

Method: 引入跨六个维度的九个关键参数，通过实验与现有LLM相结合，实现对对话属性的精确控制。

Result: 实验证明，基于参数的控制能使生成的对话属性产生统计学上的显著差异。

Conclusion: 该框架为对话质量控制提供标准化方法，在教育、治疗、客服和娱乐等领域具有广泛应用前景。

Abstract: This paper introduces a parameterization framework for controlling
conversation quality in large language models. We explore nine key parameters
across six dimensions that enable precise specification of dialogue properties.
Through experiments with state-of-the-art LLMs, we demonstrate that
parameter-based control produces statistically significant differences in
generated conversation properties. Our approach addresses challenges in
conversation generation, including topic coherence, knowledge progression,
character consistency, and control granularity. The framework provides a
standardized method for conversation quality control with applications in
education, therapy, customer service, and entertainment. Future work will focus
on implementing additional parameters through architectural modifications and
developing benchmark datasets for evaluation.

</details>


### [8] [CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](https://arxiv.org/abs/2508.02997)
*Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis*

Main category: cs.CL

TL;DR: 针对大语言模型（LLMs）的越狱攻击，本文提出一种基于上下文共现矩阵的检测方法，在数据稀缺环境下，该方法在准确性和速度上均表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）因其复杂性和难以理解的特性，容易受到越狱攻击并产生有害响应。为确保LLMs的安全可靠使用，急需开发强大的检测方法来对抗这些威胁。

Method: 本文提出了一种新颖的方法，利用上下文共现矩阵和张量的潜在空间特性来有效识别对抗性及越狱提示。该方法特别适用于数据稀缺环境。

Result: 评估结果显示，该方法在使用仅0.5%的标注提示时，F1得分达到0.83，比基线模型提高了96.6%。同时，其速度比基线模型快2.3至128.4倍，尤其在标注数据稀缺时展现出强大的模式学习能力。

Conclusion: 所提出的方法在检测LLM越狱攻击方面表现出色，尤其在标注数据稀缺的情况下，在准确性和速度上均优于现有基线，为LLMs的安全部署提供了有力支持。

Abstract: The widespread use of Large Language Models (LLMs) in many applications marks
a significant advance in research and practice. However, their complexity and
hard-to-understand nature make them vulnerable to attacks, especially
jailbreaks designed to produce harmful responses. To counter these threats,
developing strong detection methods is essential for the safe and reliable use
of LLMs. This paper studies this detection problem using the Contextual
Co-occurrence Matrix, a structure recognized for its efficacy in data-scarce
environments. We propose a novel method leveraging the latent space
characteristics of Contextual Co-occurrence Matrices and Tensors for the
effective identification of adversarial and jailbreak prompts. Our evaluations
show that this approach achieves a notable F1 score of 0.83 using only 0.5% of
labeled prompts, which is a 96.6% improvement over baselines. This result
highlights the strength of our learned patterns, especially when labeled data
is scarce. Our method is also significantly faster, speedup ranging from 2.3 to
128.4 times compared to the baseline models. To support future research and
reproducibility, we have made our implementation publicly available.

</details>


### [9] [When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025](https://arxiv.org/abs/2508.03037)
*Ariya Mukherjee-Gandhi,Oliver Muellerklein*

Main category: cs.CL

TL;DR: 本研究分析了2013年至2025年间关于AI生成艺术的英文语料，发现艺术家对同意、透明度和创作劳动未来提出的担忧在主流论述中常被边缘化，并指出技术术语的使用可能成为排斥艺术家声音的门槛。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑艺术创作，受影响最直接的艺术家对同意、透明度和创意劳动的未来提出了紧急关切，但他们的声音在公共和学术讨论中常被边缘化。

Method: 研究对2013年至2025年间439份精选的英文语料（包括评论文章、新闻报道、博客、法律文件和口语转录）进行了十二年的分析。采用可复现的方法，识别出五个稳定的主题群，并提出了一种基于BERTopic的多模态基线方法。

Result: 研究识别出五个稳定的主题群，并揭示了艺术家感知与主流媒体叙事之间的不一致。结果强调技术术语的使用如何作为一种微妙的“把关”形式，常常使艺术家认为最紧迫的问题被边缘化。

Conclusion: 本研究为未来研究提供了一种基于BERTopic的方法和多模态基线，并明确呼吁在不断发展的AI-创意领域中，以更深入、更透明的方式关注艺术家的视角。

Abstract: As generative AI continues to reshape artistic production and alternate modes
of human expression, artists whose livelihoods are most directly affected have
raised urgent concerns about consent, transparency, and the future of creative
labor. However, the voices of artists are often marginalized in dominant public
and scholarly discourse. This study presents a twelve-year analysis, from 2013
to 2025, of English-language discourse surrounding AI-generated art. It draws
from 439 curated 500-word excerpts sampled from opinion articles, news reports,
blogs, legal filings, and spoken-word transcripts. Through a reproducible
methodology, we identify five stable thematic clusters and uncover a
misalignment between artists' perceptions and prevailing media narratives. Our
findings highlight how the use of technical jargon can function as a subtle
form of gatekeeping, often sidelining the very issues artists deem most urgent.
Our work provides a BERTopic-based methodology and a multimodal baseline for
future research, alongside a clear call for deeper, transparency-driven
engagement with artist perspectives in the evolving AI-creative landscape.

</details>


### [10] [Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03098)
*Haoran Wang,Xiongxiao Xu,Baixiang Huang,Kai Shu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large
language models (LLMs) by conditioning outputs on external knowledge sources.
However, when retrieval involves private or sensitive data, RAG systems are
susceptible to extraction attacks that can leak confidential information
through generated responses. We propose Privacy-Aware Decoding (PAD), a
lightweight, inference-time defense that adaptively injects calibrated Gaussian
noise into token logits during generation. PAD integrates confidence-based
screening to selectively protect high-risk tokens, efficient sensitivity
estimation to minimize unnecessary noise, and context-aware noise calibration
to balance privacy with generation quality. A \renyi Differential Privacy (RDP)
accountant rigorously tracks cumulative privacy loss, enabling explicit
per-response $(\varepsilon, \delta)$-DP guarantees for sensitive outputs.
Unlike prior approaches requiring retraining or corpus-level filtering, PAD is
model-agnostic and operates entirely at decoding time with minimal
computational overhead. Experiments on three real-world datasets demonstrate
that PAD substantially reduces private information leakage while preserving
response utility, outperforming existing retrieval- and post-processing-based
defenses. Our work takes an important step toward mitigating privacy risks in
RAG via decoding strategies, paving the way for universal and scalable privacy
solutions in sensitive domains. Our code is available:
https://github.com/wang2226/PAD.

</details>


### [11] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CL

TL;DR: 针对RAG系统中的恶意内容风险，本文提出TPARAG框架。该框架通过精细的token级优化，有效攻击RAG系统的检索与生成阶段，在黑白盒场景下均超越现有攻击方法，揭示了RAG的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）存在幻觉和知识过时问题。RAG框架旨在解决这些问题，但其对外部知识库的依赖引入了新的安全漏洞，即恶意内容可能被检索并用于操纵模型输出。现有RAG攻击方法受限于对检索器的依赖或未能整合考虑检索与生成阶段，特别是在黑盒场景下表现不佳。

Method: 提出“Token-level Precise Attack on the RAG (TPARAG)”框架。TPARAG利用一个轻量级白盒LLM作为攻击者，在token级别生成并迭代优化恶意段落。此方法确保了恶意内容既易于被目标RAG系统检索，又能在生成阶段导致高攻击成功率，支持对白盒和黑盒RAG系统的攻击。

Result: 在开放域问答数据集上进行的广泛实验证明，TPARAG在检索阶段和端到端攻击效果方面均持续优于此前的方法。

Conclusion: 研究结果揭示了RAG管道中存在的关键漏洞，并为提升RAG系统的鲁棒性提供了新的见解。

Abstract: While large language models (LLMs) have achieved remarkable success in
providing trustworthy responses for knowledge-intensive tasks, they still face
critical limitations such as hallucinations and outdated knowledge. To address
these issues, the retrieval-augmented generation (RAG) framework enhances LLMs
with access to external knowledge via a retriever, enabling more accurate and
real-time outputs about the latest events. However, this integration brings new
security vulnerabilities: the risk that malicious content in the external
database can be retrieved and used to manipulate model outputs. Although prior
work has explored attacks on RAG systems, existing approaches either rely
heavily on access to the retriever or fail to jointly consider both retrieval
and generation stages, limiting their effectiveness, particularly in black-box
scenarios. To overcome these limitations, we propose Token-level Precise Attack
on the RAG (TPARAG), a novel framework that targets both white-box and
black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an
attacker to generate and iteratively optimize malicious passages at the token
level, ensuring both retrievability and high attack success in generation.
Extensive experiments on open-domain QA datasets demonstrate that TPARAG
consistently outperforms previous approaches in retrieval-stage and end-to-end
attack effectiveness. These results further reveal critical vulnerabilities in
RAG pipelines and offer new insights into improving their robustness.

</details>


### [12] [Cross-lingual Opinions and Emotions Mining in Comparable Documents](https://arxiv.org/abs/2508.03112)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 本研究分析了英阿可比文本的情感和情绪差异，结果显示来自同一新闻机构的文章在情感和情绪标注上趋于一致，而来自不同机构的文章则存在分歧。


<details>
  <summary>Details</summary>
Motivation: 探讨英阿可比文档在情感和情绪上的差异，特别是当文档来源不同时，此方面在现有文献中尚未被充分探索。

Method: 首先，对文本进行情感（主观/客观）和情绪（愤怒、厌恶、恐惧、喜悦、悲伤、惊讶）标注。情感标注采用避免机器翻译的跨语言方法。情绪标注通过手动翻译英文WordNet-Affect词典创建双语情绪词典。随后，应用统计方法评估每对源-目标文档的情感和情绪一致性。研究数据集包括来自Euronews、BBC和Al-Jazeera的英阿文档对。

Result: 情感和情绪标注在文章来自同一新闻机构时趋于一致，而当文章来自不同新闻机构时则出现分歧。

Conclusion: 所提出的方法具有语言独立性，可推广到其他语言对。

Abstract: Comparable texts are topic-aligned documents in multiple languages that are
not direct translations. They are valuable for understanding how a topic is
discussed across languages. This research studies differences in sentiments and
emotions across English-Arabic comparable documents. First, texts are annotated
with sentiment and emotion labels. We apply a cross-lingual method to label
documents with opinion classes (subjective/objective), avoiding reliance on
machine translation. To annotate with emotions (anger, disgust, fear, joy,
sadness, surprise), we manually translate the English WordNet-Affect (WNA)
lexicon into Arabic, creating bilingual emotion lexicons used to label the
comparable corpora. We then apply a statistical measure to assess the agreement
of sentiments and emotions in each source-target document pair. This comparison
is especially relevant when the documents originate from different sources. To
our knowledge, this aspect has not been explored in prior literature. Our study
includes English-Arabic document pairs from Euronews, BBC, and Al-Jazeera
(JSC). Results show that sentiment and emotion annotations align when articles
come from the same news agency and diverge when they come from different ones.
The proposed method is language-independent and generalizable to other language
pairs.

</details>


### [13] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
*Ge Shi,Kaiyu Huang,Guochen Feng*

Main category: cs.CL

TL;DR: 本研究提出一种基于大型语言模型的多智能体故事生成器，通过记忆存储模型、叙事障碍框架和多智能体交互阶段，解决长篇故事生成中主题漂移和情节枯燥的问题，显著提升故事质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大纲的多阶段长篇故事生成方法存在两大问题：一是因记忆丢失导致的主题漂移；二是生成的情节枯燥且逻辑不连贯，对读者吸引力不足。

Method: 1. 提出多智能体故事生成器结构，以大型语言模型（LLMs）作为智能体的核心组件。
2. 引入记忆存储模型，包含长期记忆（防主题漂移）和短期记忆（保留最新大纲）。
3. 设计故事主题障碍框架，基于文学叙事理论引入不确定因素和评估标准，并通过构建知识图谱增强故事吸引力。
4. 建立多智能体交互阶段，模拟作者-读者对话并根据反馈修订故事文本，确保连贯性和逻辑性。

Result: 与现有方法相比，该方法能够生成更高质量的长篇故事。

Conclusion: 所提出的多智能体故事生成器有效解决了长篇故事生成中的主题漂移和情节质量问题，证明了其在生成高质量长篇故事方面的优越性。

Abstract: The generation of a long story consisting of several thousand words is a
sub-task in the field of long text generation~(LTG). Previous research has
addressed this challenge through outline-based generation, which employs a
multi-stage method for generating outlines into stories. However, this approach
suffers from two common issues: almost inevitable theme drift caused by the
loss of memory of previous outlines, and tedious plots with incoherent logic
that are less appealing to human readers.
  In this paper, we propose the multi-agent Story Generator structure to
improve the multi-stage method, using large language models~(LLMs) as the core
components of agents. To avoid theme drift, we introduce a memory storage model
comprising two components: a long-term memory storage that identifies the most
important memories, thereby preventing theme drift; and a short-term memory
storage that retains the latest outlines from each generation round. To
incorporate engaging elements into the story, we design a story theme obstacle
framework based on literary narratology theory that introduces uncertain
factors and evaluation criteria to generate outline. This framework calculates
the similarity of the former storyline and enhances the appeal of the story by
building a knowledge graph and integrating new node content. Additionally, we
establish a multi-agent interaction stage to simulate writer-reader interaction
through dialogue and revise the story text according to feedback, to ensure it
remains consistent and logical. Evaluations against previous methods
demonstrate that our approach can generate higher-quality long stories.

</details>


### [14] [RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior](https://arxiv.org/abs/2508.03140)
*Junyao Yang,Jianwei Wang,Huiping Zhuang,Cen Chen,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出RCP-Merging方法，旨在高效融合长CoT推理模型与领域特定模型，克服现有方法导致的推理能力下降问题，并在保持CoT能力的同时显著提升领域任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在长CoT推理和特定领域知识方面表现优异。然而，将具备长CoT能力的推理模型与领域特定模型融合以创建兼具双重能力的模型时，传统模型融合方法存在推理能力下降、输出混乱甚至崩溃的严重问题，且需要避免巨大的计算和数据成本。

Method: 提出RCP-Merging框架。该方法将推理模型的权重视为基础先验，并利用推理能力指标来保留核心长CoT能力模型的权重，同时选择性地融合关键的领域特定权重，从而在融合领域特定LLM和长CoT能力的同时，保持模型在原始领域的性能。

Result: RCP-Merging成功地将推理模型与领域特定模型融合。实验结果显示，在BioMedicine和Finance领域，该方法在领域任务性能上比现有最佳方法提高了9.5%和9.2%，同时没有显著损害原始长CoT推理能力。实验在Qwen2.5-7B、Llama3.1-8B和Qwen2.5-1.5B模型上进行。

Conclusion: RCP-Merging有效解决了长CoT模型与领域特定模型融合的挑战，提供了一种卓越且资源高效的解决方案，成功兼顾并保持了模型的推理能力和领域专业知识。

Abstract: Large Language Models (LLMs) with long chain-of-thought (CoT) capability,
termed Reasoning Models, demonstrate superior intricate problem-solving
abilities through multi-step long CoT reasoning. To create a dual-capability
model with long CoT capability and domain-specific knowledge without
substantial computational and data costs, model merging emerges as a highly
resource-efficient method. However, significant challenges lie in merging
domain-specific LLMs with long CoT ones since nowadays merging methods suffer
from reasoning capability degradation, even gibberish output and output
collapse. To overcome this, we introduce RCP-Merging: Merging Long
Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning
Capability as Prior, a novel merging framework designed to integrate
domain-specific LLMs with long CoT capability, meanwhile maintaining model
performance in the original domain. Treating reasoning model weights as
foundational prior, our method utilizes a reasoning capability indicator to
preserve core long CoT capability model weights while selectively merging
essential domain-specific weights. We conducted extensive experiments on
Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance
domains. Our results show that RCP-Merging successfully merges a reasoning
model with domain-specific ones, improving domain task performance by 9.5% and
9.2% over state-of-the-art methods, without significantly harming the original
long CoT reasoning capability.

</details>


### [15] [Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following](https://arxiv.org/abs/2508.03178)
*Chenyang Wang,Liang Wen,Shousheng Jia,Xiangzheng Zhang,Liang Xu*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLMs）在复杂指令遵循中表现不佳的问题，研究发现其根源在于思维阶段的“惰性推理”。为此，论文提出了一种包含预判和自检的严谨推理框架，并通过数据筛选、拒绝采样、Entropy-SFT结合TEA-RL的强化学习策略，显著提升了模型遵循指令的能力，甚至超越了更大型的模型。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在解决数学、编码和通用谜题方面的推理能力显著增强，但其在准确遵循指令方面的效果仍不一致，尤其是在面对更复杂的指令时。研究指出，这种不一致性主要归因于思维阶段的“惰性推理”。因此，需要开发一种框架来促使LLMs进行严谨的推理，以满足严格的指令约束。

Method: 1. 识别并确认“惰性推理”是导致指令遵循不佳的主要因素。2. 提出一个全面的框架，旨在实现包含预判和自检的严谨推理过程。3. 生成带有复杂约束的指令，并进行筛选，得到硬（hard）、易（easy）和通过（pass）三类提示数据集。4. 对“通过”提示采用拒绝采样，以创建一个小而高质量的数据集，用于模型冷启动初始化。5. 采用熵保持监督微调（Entropy-SFT）策略，并结合由基于规则的密集奖励引导的逐令牌熵自适应（TEA-RL）强化学习。此方法旨在促使模型转变其推理机制，培养可泛化的预判和自检能力。

Result: 在指令遵循基准上进行的广泛实验表明，该方法显著提升了各种规模模型的性能。值得注意的是，其“Light-IF-32B”模型超越了更大的开源模型（如DeepSeek-R1）和闭源模型（如Doubao-1.6）。

Conclusion: 该研究成功地通过提出的框架和训练策略解决了LLMs在复杂指令遵循中的不一致性问题。通过促使模型进行严谨的预判和自检推理，显著提升了其指令遵循能力和泛化性，实现了超越现有大型模型的卓越表现。

Abstract: While advancements in the reasoning abilities of LLMs have significantly
enhanced their performance in solving mathematical problems, coding tasks, and
general puzzles, their effectiveness in accurately adhering to instructions
remains inconsistent, particularly with more complex directives. Our
investigation identifies lazy reasoning during the thinking stage as the
primary factor contributing to poor instruction adherence. To mitigate this
issue, we propose a comprehensive framework designed to enable rigorous
reasoning processes involving preview and self-checking, essential for
satisfying strict instruction constraints. Specifically, we first generate
instructions with complex constraints and apply a filtering process to obtain
valid prompts, resulting in three distinct prompt datasets categorized as hard,
easy, and pass. Then, we employ rejection sampling on the pass prompts to
curate a small yet high-quality dataset, enabling a cold-start initialization
of the model and facilitating its adaptation to effective reasoning patterns.
Subsequently, we employ an entropy-preserving supervised fine-tuning
(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)
reinforcement learning guided by rule-based dense rewards. This approach
encourages the model to transform its reasoning mechanism, ultimately fostering
generalizable reasoning abilities that encompass preview and self-checking.
Extensive experiments conducted on instruction-following benchmarks demonstrate
remarkable performance improvements across various model scales. Notably, our
Light-IF-32B model surpasses both larger open-source models such as DeepSeek-R1
and closed-source models like Doubao-1.6.

</details>


### [16] [Analyzing German Parliamentary Speeches: A Machine Learning Approach for Topic and Sentiment Classification](https://arxiv.org/abs/2508.03181)
*Lukas Pätz,Moritz Beyer,Jannik Späth,Lasse Bohlen,Patrick Zschech,Mathias Kraus,Julian Rosenberger*

Main category: cs.CL

TL;DR: 通过机器学习分析德国议会演讲，揭示了政党角色（执政或反对）如何影响其话语风格、主题趋势和情感分布。


<details>
  <summary>Details</summary>
Motivation: 旨在深入理解德国议会中的政治话语，特别是探究话题演变、情感动态以及政党特定的论述策略。

Method: 分析了过去五年约28,000份德国议会演讲。开发并训练了两个机器学习模型（主题分类和情感分类），这些模型基于手动标注数据集，并在性能上表现出色（主题分类AUROC 0.94，情感分类AUROC 0.89）。将模型应用于评估政党间和随时间变化的主题趋势和情感分布。

Result: 分析揭示了政党与其在议会中角色之间的显著关系，尤其观察到政党从执政转为反对时话语风格的变化。研究表明，意识形态立场和执政责任共同塑造了政治话语。

Conclusion: 本研究通过量化分析直接回应了关于德国联邦议院中话题演变、情感动态和政党特定话语策略的关键问题，并证实了政党角色对政治论述风格的重要影响。

Abstract: This study investigates political discourse in the German parliament, the
Bundestag, by analyzing approximately 28,000 parliamentary speeches from the
last five years. Two machine learning models for topic and sentiment
classification were developed and trained on a manually labeled dataset. The
models showed strong classification performance, achieving an area under the
receiver operating characteristic curve (AUROC) of 0.94 for topic
classification (average across topics) and 0.89 for sentiment classification.
Both models were applied to assess topic trends and sentiment distributions
across political parties and over time. The analysis reveals remarkable
relationships between parties and their role in parliament. In particular, a
change in style can be observed for parties moving from government to
opposition. While ideological positions matter, governing responsibilities also
shape discourse. The analysis directly addresses key questions about the
evolution of topics, sentiment dynamics, and party-specific discourse
strategies in the Bundestag.

</details>


### [17] [Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models](https://arxiv.org/abs/2508.03199)
*Muhammed Saeed,Shaina Raza,Ashmal Vayani,Muhammad Abdul-Mageed,Ali Emami,Shady Shehata*

Main category: cs.CL

TL;DR: 研究了语法性别如何影响文本到图像（T2I）模型的视觉表示，发现其对图像生成存在显著偏见。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型偏见研究主要关注人口统计学表示和刻板印象，忽略了语法性别对跨语言视觉表示的根本性影响。

Method: 构建了一个跨语言基准数据集，包含5种有语法性别的语言（法、西、德、意、俄）和2种无语法性别的对照语言（英、中），共800个独特提示词，并使用三种最先进的T2I模型生成了28,800张图片进行分析。

Result: 语法性别显著影响图像生成：阳性语法标记使男性表示平均增加到73%（相比英语的22%），阴性语法标记使女性表示增加到38%（相比英语的28%）。这些影响系统地因语言资源可用性和模型架构而异，高资源语言表现出更强的影响。

Conclusion: 研究表明，语言结构本身，而非仅仅内容，塑造了AI生成的视觉输出，为理解多语言、多模态系统中的偏见和公平性引入了新的维度。

Abstract: Research on bias in Text-to-Image (T2I) models has primarily focused on
demographic representation and stereotypical attributes, overlooking a
fundamental question: how does grammatical gender influence visual
representation across languages? We introduce a cross-linguistic benchmark
examining words where grammatical gender contradicts stereotypical gender
associations (e.g., ``une sentinelle'' - grammatically feminine in French but
referring to the stereotypically masculine concept ``guard''). Our dataset
spans five gendered languages (French, Spanish, German, Italian, Russian) and
two gender-neutral control languages (English, Chinese), comprising 800 unique
prompts that generated 28,800 images across three state-of-the-art T2I models.
Our analysis reveals that grammatical gender dramatically influences image
generation: masculine grammatical markers increase male representation to 73\%
on average (compared to 22\% with gender-neutral English), while feminine
grammatical markers increase female representation to 38\% (compared to 28\% in
English). These effects vary systematically by language resource availability
and model architecture, with high-resource languages showing stronger effects.
Our findings establish that language structure itself, not just content, shapes
AI-generated visual outputs, introducing a new dimension for understanding bias
and fairness in multilingual, multimodal systems.

</details>


### [18] [Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP](https://arxiv.org/abs/2508.03204)
*Abhirup Sinha,Pritilata Saha,Tithi Saha*

Main category: cs.CL

TL;DR: 大型语言模型存在隐私泄露风险，本报告探讨了文本数据隐私保护的预处理方法。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型训练需要大量数据，这些数据常包含隐私信息，且隐私信息可能从模型中被提取，因此匿名化处理敏感数据至关重要。

Method: 本报告侧重于分析几种针对领域无关NLP任务的、用于文本数据中私人信息进行遮盖或假名化的预处理方法。

Result: 报告分析并介绍了多种现有用于文本数据中隐私信息遮盖或假名化的预处理方法。

Conclusion: 为应对大型语言模型训练数据中的隐私泄露风险，尽管完全匿名化可能不可行，但通过预处理方法对文本数据进行隐私保护是至关重要的。

Abstract: Privacy is a fundamental human right. Data privacy is protected by different
regulations, such as GDPR. However, modern large language models require a huge
amount of data to learn linguistic variations, and the data often contains
private information. Research has shown that it is possible to extract private
information from such language models. Thus, anonymizing such private and
sensitive information is of utmost importance. While complete anonymization may
not be possible, a number of different pre-processing approaches exist for
masking or pseudonymizing private information in textual data. This report
focuses on a few of such approaches for domain-agnostic NLP tasks.

</details>


### [19] [Probing Syntax in Large Language Models: Successes and Remaining Challenges](https://arxiv.org/abs/2508.03211)
*Pablo J. Diego-Simón,Emmanuel Chemla,Jean-Rémi King,Yair Lakretz*

Main category: cs.CL

TL;DR: 本文深入分析了大型语言模型中结构探针的局限性，发现它们受到词语距离的表层偏见影响，难以表示深层句法结构，但不受词语可预测性影响，并为此提供了一个受控基准。


<details>
  <summary>Details</summary>
Motivation: 尽管研究表明大型语言模型（LLMs）的激活可以揭示句法结构，但用于此目的的“结构探针”通常在未加区分的句子集上进行评估，导致不清楚结构和/或统计因素是否系统地影响这些句法表示。

Method: 通过在三个受控基准上对结构探针进行深入分析。

Result: ['结构探针受到表层属性的偏见影响：句子中两个词语距离越近，结构探针越倾向于认为它们存在句法关联。', '结构探针受到语言属性的挑战：它们难以有效表示深层句法结构，并会受到交互名词或不合语法动词形式的干扰。', '结构探针的性能似乎不受单个词语可预测性的影响。']

Conclusion: 这项工作揭示了结构探针当前面临的挑战，并提供了一个由受控刺激组成的基准，以更好地评估其性能。

Abstract: The syntactic structures of sentences can be readily read-out from the
activations of large language models (LLMs). However, the ``structural probes''
that have been developed to reveal this phenomenon are typically evaluated on
an indiscriminate set of sentences. Consequently, it remains unclear whether
structural and/or statistical factors systematically affect these syntactic
representations. To address this issue, we conduct an in-depth analysis of
structural probes on three controlled benchmarks. Our results are three-fold.
First, structural probes are biased by a superficial property: the closer two
words are in a sentence, the more likely structural probes will consider them
as syntactically linked. Second, structural probes are challenged by linguistic
properties: they poorly represent deep syntactic structures, and get interfered
by interacting nouns or ungrammatical verb forms. Third, structural probes do
not appear to be affected by the predictability of individual words. Overall,
this work sheds light on the current challenges faced by structural probes.
Providing a benchmark made of controlled stimuli to better evaluate their
performance.

</details>


### [20] [CardiffNLP at CLEARS-2025: Prompting Large Language Models for Plain Language and Easy-to-Read Text Rewriting](https://arxiv.org/abs/2508.03240)
*Mutaz Ayesh,Nicolás Gutiérrez-Rolón,Fernando Alva-Manchego*

Main category: cs.CL

TL;DR: CardiffNLP团队在CLEARS西班牙语文本改编任务中，采用LLM提示方法并最终使用Gemma-3，在两子任务中分获第三和第二名。


<details>
  <summary>Details</summary>
Motivation: 参与IberLEF 2025举办的CLEARS西班牙语文本改编共享任务及其两个子任务。

Method: 采用大型语言模型（LLM）提示方法，尝试多种提示变体。初期使用LLaMA-3.2，最终提交采用Gemma-3模型。

Result: 在子任务1中获得第三名，在子任务2中获得第二名。论文详细阐述了所用的提示变体、示例及实验结果。

Conclusion: 通过LLM提示结合Gemma-3模型，CardiffNLP团队在西班牙语文本改编任务中表现出色，验证了该方法的有效性。

Abstract: This paper details the CardiffNLP team's contribution to the CLEARS shared
task on Spanish text adaptation, hosted by IberLEF 2025. The shared task
contained two subtasks and the team submitted to both. Our team took an
LLM-prompting approach with different prompt variations. While we initially
experimented with LLaMA-3.2, we adopted Gemma-3 for our final submission, and
landed third place in Subtask 1 and second place in Subtask 2. We detail our
numerous prompt variations, examples, and experimental results.

</details>


### [21] [Somatic in the East, Psychological in the West?: Investigating Clinically-Grounded Cross-Cultural Depression Symptom Expression in LLMs](https://arxiv.org/abs/2508.03247)
*Shintaro Sakai,Jisun An,Migyeong Kang,Haewoon Kwak*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在模拟抑郁症的文化特异性症状（西方心理症状，东方躯体症状）方面表现不佳。尽管东方语言提示略有改善，但LLMs对文化角色敏感度低，且存在固定的症状优先级，表明它们不具备安全有效的心理健康应用所需的文化感知能力。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在心理健康领域的应用日益增多，本研究旨在测试LLMs是否能重现已知的临床心理学发现，即西方个体报告抑郁症心理症状，而东方个体报告躯体症状的文化模式。

Method: 通过使用西方或东方角色提示LLMs，并观察它们在英语和主要东方语言（如中文、日语、印地语）提示下的症状报告模式，以评估其是否能复制人类的文化特异性表现。

Result: ['LLMs在英语提示下未能普遍复制文化特异性症状模式。', '在主要东方语言（如中文、日语、印地语）提示下，模型的表现有所改善。', '分析发现LLMs失败的两个主要原因：模型对文化角色的敏感度低，以及存在一个强大的、文化不变的症状层次结构，该结构会覆盖文化线索。']

Conclusion: 尽管提示语言具有重要性，但当前通用LLMs缺乏稳健的、文化感知的、对安全有效心理健康应用至关重要的能力。

Abstract: Prior clinical psychology research shows that Western individuals with
depression tend to report psychological symptoms, while Eastern individuals
report somatic ones. We test whether Large Language Models (LLMs), which are
increasingly used in mental health, reproduce these cultural patterns by
prompting them with Western or Eastern personas. Results show that LLMs largely
fail to replicate the patterns when prompted in English, though prompting in
major Eastern languages (i.e., Chinese, Japanese, and Hindi) improves alignment
in several configurations. Our analysis pinpoints two key reasons for this
failure: the models' low sensitivity to cultural personas and a strong,
culturally invariant symptom hierarchy that overrides cultural cues. These
findings reveal that while prompt language is important, current
general-purpose LLMs lack the robust, culture-aware capabilities essential for
safe and effective mental health applications.

</details>


### [22] [RooseBERT: A New Deal For Political Language Modelling](https://arxiv.org/abs/2508.03250)
*Deborah Dore,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: 针对政治辩论分析的挑战，本文提出并训练了一个领域专用预训练语言模型RooseBERT，它在政治文本分析任务上显著优于通用语言模型。


<details>
  <summary>Details</summary>
Motivation: 政治辩论和相关讨论内容日益增多，需要新颖的计算方法自动分析以帮助公民理解。然而，政治语言的特殊性及其论证形式（包括隐藏的交流策略和隐含论点）使得即使是通用预训练语言模型也难以有效分析。

Method: 为解决上述问题，研究者引入了一个名为RooseBERT的政治话语领域专用预训练语言模型。该模型使用大量英文政治辩论和演讲语料库（包含8K场辩论）进行训练。为评估其性能，模型在四个政治辩论分析下游任务（命名实体识别、情感分析、论点成分检测与分类、论点关系预测与分类）上进行了微调。

Result: 实验结果表明，RooseBERT在这四项任务上的表现均显著优于通用语言模型，突出了领域特定预训练对提升政治辩论分析性能的有效性。

Conclusion: 领域特定预训练能够显著增强政治辩论分析的性能。RooseBERT模型已向研究社区发布。

Abstract: The increasing amount of political debates and politics-related discussions
calls for the definition of novel computational methods to automatically
analyse such content with the final goal of lightening up political
deliberation to citizens. However, the specificity of the political language
and the argumentative form of these debates (employing hidden communication
strategies and leveraging implicit arguments) make this task very challenging,
even for current general-purpose pre-trained Language Models. To address this
issue, we introduce a novel pre-trained Language Model for political discourse
language called RooseBERT. Pre-training a language model on a specialised
domain presents different technical and linguistic challenges, requiring
extensive computational resources and large-scale data. RooseBERT has been
trained on large political debate and speech corpora (8K debates, each composed
of several sub-debates on different topics) in English. To evaluate its
performances, we fine-tuned it on four downstream tasks related to political
debate analysis, i.e., named entity recognition, sentiment analysis, argument
component detection and classification, and argument relation prediction and
classification. Our results demonstrate significant improvements over
general-purpose Language Models on these four tasks, highlighting how
domain-specific pre-training enhances performance in political debate analysis.
We release the RooseBERT language model for the research community.

</details>


### [23] [Exploring Stability-Plasticity Trade-offs for Continual Named Entity Recognition](https://arxiv.org/abs/2508.03259)
*Duzhen Zhang,Chenxing Li,Jiahua Dong,Qi Liu,Dong Yu*

Main category: cs.CL

TL;DR: 针对持续命名实体识别（CNER）中现有方法稳定性过高而可塑性不足的问题，本文提出了稳定性-可塑性权衡（SPT）方法，从表示和权重两方面平衡知识保留与新知识获取，并引入置信度伪标签处理非实体类型语义漂移，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有持续命名实体识别（CNER）方法主要依赖知识蒸馏来防止灾难性遗忘，但这导致模型过度稳定（保留旧知识）而可塑性不足（获取新知识）。此外，这些方法普遍忽略了非实体类型的语义漂移问题。

Method: 本文提出稳定性-可塑性权衡（SPT）方法。在表示层面，通过在知识蒸馏中引入池化操作来允许一定程度的可塑性。在权重层面，动态融合新旧模型权重，并采用权重引导选择机制以强化旧知识同时保持新知识。此外，开发了一种基于置信度的伪标签方法，使用旧模型预测当前非实体类型，以处理其语义漂移问题。

Result: 在三个基准数据集的十种CNER设置上进行了广泛实验，结果表明本文提出的SPT方法超越了现有的CNER方法。

Conclusion: SPT方法成功地在持续命名实体识别中实现了合适的稳定性-可塑性权衡，有效解决了现有方法的局限性，并提升了模型的整体性能。

Abstract: Continual Named Entity Recognition (CNER) is an evolving field that focuses
on sequentially updating an existing model to incorporate new entity types.
Previous CNER methods primarily utilize Knowledge Distillation (KD) to preserve
prior knowledge and overcome catastrophic forgetting, strictly ensuring that
the representations of old and new models remain consistent. Consequently, they
often impart the model with excessive stability (i.e., retention of old
knowledge) but limited plasticity (i.e., acquisition of new knowledge). To
address this issue, we propose a Stability-Plasticity Trade-off (SPT) method
for CNER that balances these aspects from both representation and weight
perspectives. From the representation perspective, we introduce a pooling
operation into the original KD, permitting a level of plasticity by
consolidating representation dimensions. From the weight perspective, we
dynamically merge the weights of old and new models, strengthening old
knowledge while maintaining new knowledge. During this fusion, we implement a
weight-guided selective mechanism to prioritize significant weights. Moreover,
we develop a confidence-based pseudo-labeling approach for the current
non-entity type, which predicts entity types using the old model to handle the
semantic shift of the non-entity type, a challenge specific to CNER that has
largely been ignored by previous methods. Extensive experiments across ten CNER
settings on three benchmark datasets demonstrate that our SPT method surpasses
previous CNER approaches, highlighting its effectiveness in achieving a
suitable stability-plasticity trade-off.

</details>


### [24] [Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?](https://arxiv.org/abs/2508.03262)
*Junhyuk Choi,Hyeonchu Park,Haemin Lee,Hyebeen Shin,Hyun Joung Jin,Bugeun Kim*

Main category: cs.CL

TL;DR: 本研究使用真实人类数据评估LLM模拟经济决策的能力。发现LLM在群体层面表现合理，但个体层面预测不佳，且复杂提示方法无显著优势。


<details>
  <summary>Details</summary>
Motivation: 当前LLM模拟人类行为的研究多依赖虚构角色而非真实人类数据，这限制了其在实际应用中的有效性。本研究旨在弥补此局限性，评估LLM利用真实人类数据预测个体经济决策的能力。

Method: 研究采用“随意付”（PWYW）定价实验，收集了522名韩国参与者在文化消费场景中的真实详细人物画像数据。系统比较了三种最先进的多模态LLM，并探究了不同人物画像注入方法对预测性能的影响。

Result: 结果显示，LLM在精确的个体层面预测上表现不佳，但能合理展示群体层面的行为趋势。此外，常用的提示技术（如个人叙事重构或检索增强生成）与简单提示方法相比，未获得显著的性能提升。

Conclusion: 本研究首次全面评估了LLM利用真实人类数据模拟经济行为的能力，为计算社会科学中基于人物画像的模拟提供了重要的实证指导。

Abstract: Recent advances in Large Language Models (LLMs) have generated significant
interest in their capacity to simulate human-like behaviors, yet most studies
rely on fictional personas rather than actual human data. We address this
limitation by evaluating LLMs' ability to predict individual economic
decision-making using Pay-What-You-Want (PWYW) pricing experiments with real
522 human personas. Our study systematically compares three state-of-the-art
multimodal LLMs using detailed persona information from 522 Korean participants
in cultural consumption scenarios. We investigate whether LLMs can accurately
replicate individual human choices and how persona injection methods affect
prediction performance. Results reveal that while LLMs struggle with precise
individual-level predictions, they demonstrate reasonable group-level
behavioral tendencies. Also, we found that commonly adopted prompting
techniques are not much better than naive prompting methods; reconstruction of
personal narrative nor retrieval augmented generation have no significant gain
against simple prompting method. We believe that these findings can provide the
first comprehensive evaluation of LLMs' capabilities on simulating economic
behavior using real human data, offering empirical guidance for persona-based
simulation in computational social science.

</details>


### [25] [LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning](https://arxiv.org/abs/2508.03275)
*Jiahao Zhao*

Main category: cs.CL

TL;DR: LECTOR是一种基于LLM的间隔重复算法，通过语义分析和个性化学习来解决语义干扰，在模拟学习中将测试成功率提高到90.2%。


<details>
  <summary>Details</summary>
Motivation: 现有间隔重复算法在语义干扰和个性化适应方面表现不足，尤其在语言考试等以测试为导向的学习场景中，高成功率至关重要。

Method: 提出了一种名为LECTOR（LLM-Enhanced Concept-based Test-Oriented Repetition）的新型自适应调度算法。它利用大型语言模型（LLM）进行语义分析，并结合个性化学习档案。通过LLM驱动的语义相似性评估并整合到现有间隔重复原则中，解决词汇学习中的语义混淆问题。该算法在100名模拟学习者中进行了100天的综合评估，与SSP-MMC、SM2、HLR、FSRS、ANKI、THRESHOLD六种基线算法进行了对比。

Result: LECTOR实现了90.2%的成功率，优于表现最佳的基线算法SSP-MMC（88.4%），相对提升了2.0%。该算法在处理语义相似概念方面表现出色，减少了由混淆引起的错误，同时保持了计算效率。

Conclusion: 研究结果表明LECTOR是智能辅导系统和自适应学习平台的一个有前景的方向。

Abstract: Spaced repetition systems are fundamental to efficient learning and memory
retention, but existing algorithms often struggle with semantic interference
and personalized adaptation. We present LECTOR (\textbf{L}LM-\textbf{E}nhanced
\textbf{C}oncept-based \textbf{T}est-\textbf{O}riented \textbf{R}epetition), a
novel adaptive scheduling algorithm specifically designed for test-oriented
learning scenarios, particularly language examinations where success rate is
paramount. LECTOR leverages large language models for semantic analysis while
incorporating personalized learning profiles, addressing the critical challenge
of semantic confusion in vocabulary learning by utilizing LLM-powered semantic
similarity assessment and integrating it with established spaced repetition
principles. Our comprehensive evaluation against six baseline algorithms
(SSP-MMC, SM2, HLR, FSRS, ANKI, THRESHOLD) across 100 simulated learners over
100 days demonstrates significant improvements: LECTOR achieves a 90.2\%
success rate compared to 88.4\% for the best baseline (SSP-MMC), representing a
2.0\% relative improvement. The algorithm shows particular strength in handling
semantically similar concepts, reducing confusion-induced errors while
maintaining computational efficiency. Our results establish LECTOR as a
promising direction for intelligent tutoring systems and adaptive learning
platforms.

</details>


### [26] [Do language models accommodate their users? A study of linguistic convergence](https://arxiv.org/abs/2508.03276)
*Terra Blevins,Susanne Schmalwieser,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）是否展现语言趋同（即适应用户语言模式），发现模型趋同性强且常出现过拟合。指令微调和大型模型趋同性低于预训练模型，推测人类与模型的趋同机制不同。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在语言生成方面表现出色，但其语言使用与人类语言使用之间的相似性仍未被充分研究。特别是，模型是否展现语言趋同，即适应用户语言模式，是人类语言交流中的核心语用元素，需要深入探讨。

Method: 研究通过系统性地比较十六种语言模型在三种对话语料库中对现有对话的补全，并将其与原始人类回应进行对比，分析多种文体特征。

Result: 模型强烈趋同于对话风格，且这种趋同性相对于人类基线常出现显著过拟合。趋同模式通常是特征特定的。在不同模型设置下，趋同性存在一致性变化，其中指令微调和更大的模型趋同性低于其预训练的对应模型。

Conclusion: 鉴于观察到的人类与模型趋同模式之间的差异，研究者推测这两种行为的底层机制非常不同。

Abstract: While large language models (LLMs) are generally considered proficient in
generating language, how similar their language usage is to that of humans
remains understudied. In this paper, we test whether models exhibit linguistic
convergence, a core pragmatic element of human language communication, asking:
do models adapt, or converge, to the linguistic patterns of their user? To
answer this, we systematically compare model completions of exisiting dialogues
to the original human responses across sixteen language models, three dialogue
corpora, and a variety of stylometric features. We find that models strongly
converge to the conversation's style, often significantly overfitting relative
to the human baseline. While convergence patterns are often feature-specific,
we observe consistent shifts in convergence across modeling settings, with
instruction-tuned and larger models converging less than their pretrained
counterparts. Given the differences between human and model convergence
patterns, we hypothesize that the underlying mechanisms for these behaviors are
very different.

</details>


### [27] [Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes](https://arxiv.org/abs/2508.03292)
*Shahed Masoudian,Gustavo Escobedo,Hannah Strauss,Markus Schedl*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在长文本生成中存在性别偏见。本研究通过心理学性别刻板印象在叙事生成任务中评估LLMs，发现无条件生成偏向男性，中性属性可缓解偏见，多属性组合会放大或缓解偏见，且模型偏见与心理学真值一致并随模型尺寸增大而增强。


<details>
  <summary>Details</summary>
Motivation: 现有LLM性别偏见研究多聚焦显式线索或短文本任务，可能忽视长内容生成中的隐性偏见。本研究旨在探究LLMs在开放式叙事生成任务中基于心理学性别刻板印象的偏见表现。

Method: 构建StereoBias-Stories数据集，包含无条件或基于25种心理学刻板印象（随机1、2或6个属性）及3种结局条件的短故事。通过分析故事中性别贡献随属性变化的趋势，以评估LLM的性别偏见。

Result: ['无条件提示下，模型普遍高度偏向男性；但基于独立于性别刻板印象的属性进行条件生成能有效缓解此偏见。', '结合与同一性别刻板印象相关的多个属性，会加剧模型行为：男性相关属性放大偏见，女性相关属性则能缓解偏见。', '模型偏见与用于分类的心理学真实数据高度吻合，且这种吻合度随模型尺寸的增大而增强。']

Conclusion: 研究结果共同强调了基于心理学理论对大型语言模型进行评估的重要性。

Abstract: As Large Language Models (LLMs) are increasingly used across different
applications, concerns about their potential to amplify gender biases in
various tasks are rising. Prior research has often probed gender bias using
explicit gender cues as counterfactual, or studied them in sentence completion
and short question answering tasks. These formats might overlook more implicit
forms of bias embedded in generative behavior of longer content. In this work,
we investigate gender bias in LLMs using gender stereotypes studied in
psychology (e.g., aggressiveness or gossiping) in an open-ended task of
narrative generation. We introduce a novel dataset called StereoBias-Stories
containing short stories either unconditioned or conditioned on (one, two, or
six) random attributes from 25 psychological stereotypes and three task-related
story endings. We analyze how the gender contribution in the overall story
changes in response to these attributes and present three key findings: (1)
While models, on average, are highly biased towards male in unconditioned
prompts, conditioning on attributes independent from gender stereotypes
mitigates this bias. (2) Combining multiple attributes associated with the same
gender stereotype intensifies model behavior, with male ones amplifying bias
and female ones alleviating it. (3) Model biases align with psychological
ground-truth used for categorization, and alignment strength increases with
model size. Together, these insights highlight the importance of
psychology-grounded evaluation of LLMs.

</details>


### [28] [NLP Methods May Actually Be Better Than Professors at Estimating Question Difficulty](https://arxiv.org/abs/2508.03294)
*Leonidas Zotos,Ivo Pascal de Jong,Matias Valdenegro-Toro,Andreea Ioana Sburlea,Malvina Nissim,Hedderik van Rijn*

Main category: cs.CL

TL;DR: 研究发现，在估计考试题目难度方面，基于大型语言模型（LLM）的方法，尤其是在监督学习中利用LLM不确定性，表现优于教授。


<details>
  <summary>Details</summary>
Motivation: 开发高质量考试的关键在于准确估计题目难度，但教授们在这项任务上并非总能胜任。

Method: 研究比较了多种基于大型语言模型（LLM）的方法与三位教授在估计神经网络和机器学习领域是非题学生正确率方面的能力。其中，通过在监督学习设置中利用LLM解决问题时的不确定性，仅使用42个训练样本，获得了最佳结果。

Result: 结果显示，教授区分题目难易度的能力有限，且其表现不如直接使用Gemini 2.5。然而，通过在监督学习环境下，利用LLM解答问题时的不确定性，能够获得更好的估计结果。

Conclusion: 在监督学习中使用LLM的不确定性可以有效帮助教授更准确地估计考试题目难度，从而提升考试评估的质量。

Abstract: Estimating the difficulty of exam questions is essential for developing good
exams, but professors are not always good at this task. We compare various
Large Language Model-based methods with three professors in their ability to
estimate what percentage of students will give correct answers on True/False
exam questions in the areas of Neural Networks and Machine Learning. Our
results show that the professors have limited ability to distinguish between
easy and difficult questions and that they are outperformed by directly asking
Gemini 2.5 to solve this task. Yet, we obtained even better results using
uncertainties of the LLMs solving the questions in a supervised learning
setting, using only 42 training samples. We conclude that supervised learning
using LLM uncertainty can help professors better estimate the difficulty of
exam questions, improving the quality of assessment.

</details>


### [29] [Towards Trustworthy Multimodal Moderation via Policy-Aligned Reasoning and Hierarchical Labeling](https://arxiv.org/abs/2508.03296)
*Anqi Li,Wenwei Jin,Jintao Tong,Pengda Qin,Weijia Li,Guo Lu*

Main category: cs.CL

TL;DR: 本文提出Hi-Guard，一个多模态内容审核框架，通过分层审核流程、分层分类法和政策规则集成，显著提升了内容分类的准确性、泛化性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 社交平台加速有害内容传播，现有审核系统依赖于带噪标签学习，缺乏与审核规则的对齐，并产生不透明的决策，阻碍人工审查，因此需要更准确、可解释且可扩展的审核系统。

Method: 提出Hi-Guard多模态审核框架，包含：1) 分层审核管道，轻量级模型初筛安全内容，再由强模型进行细粒度风险分类；2) 第二阶段采用分层分类法，模型在从粗到细粒度的层次结构上进行基于路径的分类；3) 将规则定义直接整合到模型提示中以确保与政策对齐；4) 引入多级软边界奖励，并使用组相对策略优化（GRPO）进行优化，惩罚语义上相邻的错误分类，提升解释质量。

Result: 广泛的实验和实际部署表明，Hi-Guard在分类准确性、泛化能力和可解释性方面均表现出色。

Conclusion: Hi-Guard为构建可扩展、透明且可信赖的内容安全系统奠定了基础。

Abstract: Social platforms have revolutionized information sharing, but also
accelerated the dissemination of harmful and policy-violating content. To
ensure safety and compliance at scale, moderation systems must go beyond
efficiency and offer accuracy and interpretability. However, current approaches
largely rely on noisy, label-driven learning, lacking alignment with moderation
rules and producing opaque decisions that hinder human review. Therefore, we
propose Hierarchical Guard (Hi-Guard), a multimodal moderation framework that
introduces a new policy-aligned decision paradigm. The term "Hierarchical"
reflects two key aspects of our system design: (1) a hierarchical moderation
pipeline, where a lightweight binary model first filters safe content and a
stronger model handles fine-grained risk classification; and (2) a hierarchical
taxonomy in the second stage, where the model performs path-based
classification over a hierarchical taxonomy ranging from coarse to fine-grained
levels. To ensure alignment with evolving moderation policies, Hi-Guard
directly incorporates rule definitions into the model prompt. To further
enhance structured prediction and reasoning, we introduce a multi-level
soft-margin reward and optimize with Group Relative Policy Optimization (GRPO),
penalizing semantically adjacent misclassifications and improving explanation
quality. Extensive experiments and real-world deployment demonstrate that
Hi-Guard achieves superior classification accuracy, generalization, and
interpretability, paving the way toward scalable, transparent, and trustworthy
content safety systems. Code is available at:
https://github.com/lianqi1008/Hi-Guard.

</details>


### [30] [CTTS: Collective Test-Time Scaling](https://arxiv.org/abs/2508.03333)
*Zhende Song,Shengji Tang,Peng Ye,Jiayuan Fan,Tao Chen*

Main category: cs.CL

TL;DR: 本论文探索了集体测试时缩放 (CTTS) 范式，并提出了 CTTS-MM 框架，该框架通过多智能体和多奖励模型协作来增强大型语言模型 (LLM) 的性能，在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型 (LLM) 测试时缩放 (TTS) 方法（如 Best-of-N 和 Self-Consistency）受限于单智能体与单一奖励模型交互 (SA-SR) 的范式，其能力有限。鉴于集体智能体方法能够突破单智能体系统的上限，本研究旨在探索并开发集体测试时缩放 (CTTS) 以提升 LLM 效能。

Method: 研究首先设计了三种集体测试时缩放 (CTTS) 范式进行探索：单智能体对多奖励模型 (SA-MR)、多智能体对单奖励模型 (MA-SR) 和多智能体对多奖励模型 (MA-MR)。基于实验发现 MA-MR 性能最佳，提出了名为 CTTS-MM 的新型框架。该框架具体包括：用于多智能体协作的智能体协作搜索 (ACS)，以及用于多奖励模型协作的奖励模型混合 (MoR) 模块，其中 MoR 包含一个精心策划的问题池和通过成对奖励排序 (PRR) 指标选择最佳奖励模型组合的先验奖励模型集成选择 (PRES)。

Result: 广泛的实验表明，多智能体对多奖励模型 (MA-MR) 范式始终能取得最佳性能。所提出的 CTTS-MM 框架在七个主流基准测试中持续获得卓越表现。

Conclusion: 本研究成功地探索了集体测试时缩放 (CTTS) 的潜力，并提出了 CTTS-MM 框架。该框架通过有效地利用多智能体和多奖励模型的协同作用，显著增强了大型语言模型的推理能力，而无需额外的训练。

Abstract: Test-time scaling (TTS) has emerged as a promising research field for
enhancing the effectiveness of large language models (LLMs) without extra
training. However, most existing approaches, e.g., Best-of-N and
Self-Consistency rely on a single agent interacting with a reward model
(SA-SR), constrained by limited capabilities of a single test-time scaling
(STTS) paradigm. On the other hand, recent works demonstrate that
collective-agent methods can break through the upper bound of single-agent
systems by orchestrating diverse models. Thus, in this paper, we take a first
step towards exploring Collective Test-Time Scaling (CTTS). Consider the
different interaction types of single and multiple models, we design three
primary paradigms to investigate the optimal paradigm of CTTS: (1) single agent
to multiple reward models (SA-MR); (2) multiple agents to single reward model
(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive
experiments demonstrate that MA-MR consistently achieves the best performance.
Based on this, we propose a novel framework named CTTS-MM that effectively
leverages both multi-agent and multi-reward-model collaboration for enhanced
inference. Specifically, for multi-agent collaboration, we propose an Agent
Collaboration Search (ACS), which searches for the most effective combination
of LLM agents from a large candidate pool; for multi-reward-model
collaboration, we propose Mixture of Reword Models (MoR), which consists of a
curated question pool and a Prior Reward model Ensemble Selection (PRES) to
select the optimal combinations of reward models via Pair-wise Reward Ranking
(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that
the proposed CTTS-MM consistently obtains superior performance. Code will be
released at https://github.com/magent4aci/CTTS-MM.

</details>


### [31] [Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature](https://arxiv.org/abs/2508.03358)
*Tiago G Canário,Catarina Duarte,Flávio L. Pinheiro,João L. M. Pereira*

Main category: cs.CL

TL;DR: 本文提出Taggus管道，通过结合词性标注和启发式方法，从葡萄牙语小说中高效提取人物社交网络，性能显著优于现有SOTA工具。


<details>
  <summary>Details</summary>
Motivation: 现有NLP方法（如NER、POS）在从小说中自动识别人物及其互动以构建社交网络时表现不佳，尤其是在葡萄牙语等数据稀缺的语言中，因缺乏训练所需的标注数据而导致性能不足。

Method: 研究者提出了名为Taggus的管道，利用词性标注和启发式规则的组合来提取葡萄牙语文学作品中的社交网络。该方法与现成的最先进工具（如NER工具和大型语言模型ChatGPT）进行了比较。

Result: Taggus管道在人物识别和共指消解任务中获得了94.1%的平均F1分数，在互动检测中获得了75.9%的F1分数。这分别比现有最先进工具的结果提高了50.7%和22.3%。

Conclusion: Taggus管道在从葡萄牙语小说中提取人物社交网络方面表现出色，显著优于现有SOTA工具。该管道已公开可用，旨在促进葡萄牙语该领域的发展，并为未来的关系检测等研究奠定基础，尽管测试样本的规模和范围存在局限性。

Abstract: Automatically identifying characters and their interactions from fiction
books is, arguably, a complex task that requires pipelines that leverage
multiple Natural Language Processing (NLP) methods, such as Named Entity
Recognition (NER) and Part-of-speech (POS) tagging. However, these methods are
not optimized for the task that leads to the construction of Social Networks of
Characters. Indeed, the currently available methods tend to underperform,
especially in less-represented languages, due to a lack of manually annotated
data for training. Here, we propose a pipeline, which we call Taggus, to
extract social networks from literary fiction works in Portuguese. Our results
show that compared to readily available State-of-the-Art tools -- off-the-shelf
NER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which
uses POS tagging and a combination of heuristics, achieves satisfying results
with an average F1-Score of $94.1\%$ in the task of identifying characters and
solving for co-reference and $75.9\%$ in interaction detection. These
represent, respectively, an increase of $50.7\%$ and $22.3\%$ on results
achieved by the readily available State-of-the-Art tools. Further steps to
improve results are outlined, such as solutions for detecting relationships
between characters. Limitations on the size and scope of our testing samples
are acknowledged. The Taggus pipeline is publicly available to encourage
development in this field for the Portuguese language.2

</details>


### [32] [Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models](https://arxiv.org/abs/2508.03363)
*Haotian Wu,Bo Xu,Yao Shu,Menglin Yang,Chengwei Qin*

Main category: cs.CL

TL;DR: 本文提出JointThinking，一种新的上下文学习（ICL）范式，通过结合“思考”和“不思考”两种推理模式来提高RLLMs的推理准确性，并具有低延迟和高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管推理大型语言模型（RLLMs）展现出强大的推理能力，但其在上下文学习（ICL）方面的潜力仍未被充分探索，尤其是在结构化和多步推理方面，现有研究主要集中于训练和推理策略。

Method: 提出JointThinking范式，利用“思考”和“不思考”两种推理模式的结构化差异。模型并行生成这两种模式下的答案，仅当答案不一致时，触发第二轮思考，将原始问题与两个候选答案结合成一个提示。由于不一致情况较少，多数情况下只需一轮推理，开销极小。

Result: JointThinking在多个推理基准上显著优于少样本思维链（CoT）和多数投票法，并提高了答案的鲁棒性。其在分布内性能与基于训练的最先进方法相当，而在分布外任务上表现显著更优。研究还表明，利用不同推理模式能持续降低错误率，且随着模型规模增大，第二轮思考的实际与理想性能差距缩小，显示出强大可扩展性。

Conclusion: JointThinking通过利用不同的推理模式，显著提升了RLLMs在ICL中的推理准确性和鲁棒性，尤其在分布外任务中表现卓越。该方法具有良好的可扩展性，并为未来RLLMs的ICL研究指明了方向，强调了结构化思维多样性的价值。

Abstract: Reasoning large language models (RLLMs) have recently demonstrated remarkable
capabilities through structured and multi-step reasoning. While prior research
has primarily focused on improving their training and inference strategies,
their potential for in-context learning (ICL) remains largely underexplored. To
fill this gap, we propose Thinking with Nothinking Calibration (JointThinking),
a new ICL paradigm that leverages the structured difference between two
reasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.
Specifically, our method prompts the model to generate two answers in parallel:
one in Thinking mode and the other in Nothinking mode. A second round of
Thinking is triggered only when the two initial responses are inconsistent,
using a single prompt that incorporates the original question and both
candidate answers. Since such disagreement occurs infrequently (e.g., only 6\%
in GSM8K), our method performs just one round of reasoning in most cases,
resulting in minimal latency overhead. Extensive experiments across multiple
reasoning benchmarks demonstrate that JointThinking significantly outperforms
few-shot chain-of-thought (CoT) and majority voting with improved answer
robustness. Moreover, It achieves comparable in-distribution performance to
training-based SOTA method, while substantially outperforming on
out-of-distribution tasks. We further conduct a systematic analysis of the
calibration mechanism, showing that leveraging different reasoning modes
consistently lowers the error rate and highlights the value of structural
thinking diversity. Additionally, we observe that the performance gap between
actual and ideal reasoning narrows as model size increases in the second round
of thinking, indicating the strong scalability of our approach. Finally, we
discuss current limitations and outline promising directions for future ICL
research in RLLMs.

</details>


### [33] [ReDSM5: A Reddit Dataset for DSM-5 Depression Detection](https://arxiv.org/abs/2508.03399)
*Eliseo Bao,Anxo Pérez,Javier Parapar*

Main category: cs.CL

TL;DR: 引入ReDSM5语料库，该语料库由专业心理学家基于DSM-5标准对Reddit帖子进行症状和理由的句级标注。旨在开发可解释的抑郁症检测模型，并为症状分类和解释生成提供基准。


<details>
  <summary>Details</summary>
Motivation: 抑郁症普遍存在且常未诊断，传统诊断受阻碍与污名化。现有社交媒体抑郁症计算检测方法未能将语言与DSM-5标准关联，导致临床相关性和可解释性不足。

Method: 构建了ReDSM5语料库，包含1484篇Reddit长帖，由持证心理学家在句子级别详细标注9种DSM-5抑郁症症状，并提供临床理由。对语料库进行了探索性分析，研究了症状表达中的词汇、句法和情感模式。为多标签症状分类和解释生成任务建立了基准。

Result: 成功创建了独特结合症状特定标注和专家解释的ReDSM5语料库。探索性分析揭示了社交媒体叙述中症状表达的语言特征。为多标签症状分类和解释生成任务提供了参考基准。

Conclusion: ReDSM5语料库的创建及其提供的基准，有助于开发更具临床相关性和可解释性的抑郁症检测模型，克服现有方法缺乏DSM-5关联的局限性，并有望改善抑郁症的早期识别。

Abstract: Depression is a pervasive mental health condition that affects hundreds of
millions of individuals worldwide, yet many cases remain undiagnosed due to
barriers in traditional clinical access and pervasive stigma. Social media
platforms, and Reddit in particular, offer rich, user-generated narratives that
can reveal early signs of depressive symptomatology. However, existing
computational approaches often label entire posts simply as depressed or not
depressed, without linking language to specific criteria from the DSM-5, the
standard clinical framework for diagnosing depression. This limits both
clinical relevance and interpretability. To address this gap, we introduce
ReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each
exhaustively annotated at the sentence level by a licensed psychologist for the
nine DSM-5 depression symptoms. For each label, the annotator also provides a
concise clinical rationale grounded in DSM-5 methodology. We conduct an
exploratory analysis of the collection, examining lexical, syntactic, and
emotional patterns that characterize symptom expression in social media
narratives. Compared to prior resources, ReDSM5 uniquely combines
symptom-specific supervision with expert explanations, facilitating the
development of models that not only detect depression but also generate
human-interpretable reasoning. We establish baseline benchmarks for both
multi-label symptom classification and explanation generation, providing
reference results for future research on detection and interpretability.

</details>


### [34] [Variety Is the Spice of Life: Detecting Misinformation with Dynamic Environmental Representations](https://arxiv.org/abs/2508.03420)
*Bing Wang,Ximing Li,Yiming Wang,Changchun Li,Jiaxu Cui,Renchu Guan,Bo Yang*

Main category: cs.CL

TL;DR: 针对谣言检测中静态假设失效问题，提出MISDER框架，通过学习动态环境表示和时间模型来预测未来时期，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上谣言泛滥且危害巨大，谣言检测（MD）是重要研究课题。然而，主流MD方法将问题视为静态学习，忽视了新闻真实性在动态社会环境中可能随时间变化的现实，导致现有方法的静态假设失效。

Method: 提出了一种新颖的框架：具有动态环境表示的谣言检测（MISDER）。其核心思想是学习每个时期的社会环境表示，并采用时间模型来预测未来时期的表示。具体将时间模型指定为LSTM模型、连续动力学方程和预训练动力学系统，从而产生了MISDER-LSTM、MISDER-ODE和MISDER-PT三种变体。

Result: 在两个流行的数据集上，将MISDER与各种谣言检测基线方法进行了比较，实验结果表明所提出的模型是有效的。

Conclusion: MISDER框架通过引入动态环境表示和时间建模，成功解决了传统谣言检测中静态假设的局限性，有效提升了动态演变社会环境下的谣言检测性能。

Abstract: The proliferation of misinformation across diverse social media platforms has
drawn significant attention from both academic and industrial communities due
to its detrimental effects. Accordingly, automatically distinguishing
misinformation, dubbed as Misinformation Detection (MD), has become an
increasingly active research topic. The mainstream methods formulate MD as a
static learning paradigm, which learns the mapping between the content, links,
and propagation of news articles and the corresponding manual veracity labels.
However, the static assumption is often violated, since in real-world
scenarios, the veracity of news articles may vacillate within the dynamically
evolving social environment. To tackle this problem, we propose a novel
framework, namely Misinformation detection with Dynamic Environmental
Representations (MISDER). The basic idea of MISDER lies in learning a social
environmental representation for each period and employing a temporal model to
predict the representation for future periods. In this work, we specify the
temporal model as the LSTM model, continuous dynamics equation, and pre-trained
dynamics system, suggesting three variants of MISDER, namely MISDER-LSTM,
MISDER-ODE, and MISDER-PT, respectively. To evaluate the performance of MISDER,
we compare it to various MD baselines across 2 prevalent datasets, and the
experimental results can indicate the effectiveness of our proposed model.

</details>


### [35] [LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of Large Reasoning Models](https://arxiv.org/abs/2508.03440)
*Junhong Wu,Jinliang Lu,Zixuan Ren,Ganqiang Hu,Zhi Wu,Dai Dai,Hua Wu*

Main category: cs.CL

TL;DR: 本研究发现大型语言模型（LLMs）的“软思考”在连续概念空间推理中存在局限，倾向于贪婪解码；通过引入随机性（特别是Gumbel-Softmax技巧）可以显著提升其性能。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型依赖离散符号，限制了表达能力，而人类认知更侧重抽象和流动概念。新兴的“软思考”旨在让LLMs生成软、抽象符号以在连续概念空间推理，但其内部行为和实际效果有待深入探究。

Method: 通过探测技术检查不同LLMs的内部行为，分析其“软思考”能力。为解决发现的问题，探索了包括狄利克雷重采样和Gumbel-Softmax技巧在内的采样策略，以引入随机性并评估其效果。

Result: 研究发现，与普遍认知相反，LLMs在“软思考”中主要依赖软输入中最具影响力的部分进行后续解码，导致其行为类似于贪婪解码，从而阻碍了对不同推理路径的探索。然而，引入随机性（特别是Gumbel-Softmax技巧）能有效缓解这些局限，并在八个推理基准测试中展现出优越的性能。

Conclusion: 虽然初期的“软思考”存在偏向贪婪解码的限制，但通过引入受控的随机性（如Gumbel-Softmax技巧），可以有效释放其在连续概念空间中进行推理的潜力，从而提升LLMs的性能。

Abstract: Human cognition naturally engages with abstract and fluid concepts, whereas
existing reasoning models often rely on generating discrete tokens, potentially
constraining their expressive capabilities. Recent advancements aim to address
this limitation by enabling large language models (LLMs) to generate soft,
abstract tokens, thus facilitating reasoning within a continuous concept space.
This paper explores the `Soft Thinking' capabilities of various LLMs by
examining the models' internal behavior using a suite of probing techniques.
Contrary to the common belief that Soft Thinking enables the simultaneous
exploration of diverse reasoning paths, our findings reveal that LLMs
predominantly rely on the most influential component of the soft inputs during
subsequent decoding steps. This reliance hinders the exploration of different
reasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,
obscuring the advantage of transmitting more information through Soft Tokens.
To tackle this issue, we explore sampling strategies to introduce
\emph{randomness}, employing methods such as Dirichlet resampling and the
Gumbel-Softmax trick. Our experiments demonstrate that incorporating randomness
can alleviate the limitations of vanilla approaches and unleash the potential
of Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate
randomness with controlled smoothness, resulting in superior performance across
eight reasoning benchmarks.

</details>


### [36] [Cropping outperforms dropout as an augmentation strategy for training self-supervised text embeddings](https://arxiv.org/abs/2508.03453)
*Rita González-Márquez,Philipp Berens,Dmitry Kobak*

Main category: cs.CL

TL;DR: 本文系统比较了文本嵌入自监督对比学习中的两种数据增强策略（裁剪和Dropout），发现裁剪效果更好。自监督方法在域内数据上通过短时间微调可获得接近监督SOTA的嵌入质量，且仅微调最后几层即可。


<details>
  <summary>Details</summary>
Motivation: 当前高性能文本嵌入模型依赖大量监督微调，而计算机视觉领域已证明自监督数据增强的成功。研究旨在探索和评估自监督数据增强策略在文本嵌入学习中的潜力，以减少对大规模监督数据的依赖。

Method: 系统比较了两种最著名的用于文本嵌入对比学习中正样本对生成的自监督数据增强策略：裁剪（cropping）和基于Dropout的方法。通过MTEB基准测试和额外域内评估来评估嵌入质量，并分析Transformer层在微调过程中的表现。

Result: ['裁剪增强策略在文本嵌入质量上显著优于基于Dropout的方法。', '在域外数据上，自监督生成嵌入质量低于监督SOTA模型；但在域内数据上，经过非常短时间的微调，自监督嵌入能达到高质量，有时仅略低于监督SOTA。', '表示质量随着微调向Transformer最后几层增加，这些层在微调过程中变化最大。', '仅微调Transformer的最后几层足以达到相似的嵌入质量。']

Conclusion: 自监督微调，特别是结合裁剪增强，是一种有前景的方法，可以在显著缩短微调时间的情况下，为域内应用生成高质量的文本嵌入。尽管在域外数据上表现尚不及监督SOTA，但其在域内任务上的高效性以及发现只需微调特定层即可的结论，凸显了其巨大的潜力。

Abstract: Text embeddings, i.e. vector representations of entire texts, play an
important role in many NLP applications, such as retrieval-augmented
generation, sentiment analysis, clustering, or visualizing collections of texts
for data exploration. Currently, top-performing embedding models are derived
from pre-trained language models via extensive supervised fine-tuning using
curated text pairs. This contrasts with computer vision, where self-supervised
training based on data augmentations has demonstrated remarkable success. Here
we systematically compare the two most well-known augmentation strategies for
positive pair generation in contrastive learning of text embeddings. We assess
embedding quality on MTEB and additional in-domain evaluations and show that
cropping augmentation strongly outperforms the dropout-based approach. We find
that on out-of-domain data, the quality of resulting embeddings is below the
supervised SOTA models, but for in-domain data, self-supervised fine-tuning
produces high-quality text embeddings after very short fine-tuning, sometimes
only marginally below the supervised SOTA. Finally, we show that representation
quality increases towards the last transformer layers, which undergo the
largest change during fine-tuning; and that fine-tuning only those last layers
is sufficient to reach similar embedding quality.

</details>


### [37] [fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval](https://arxiv.org/abs/2508.03475)
*Pranshu Rastogi*

Main category: cs.CL

TL;DR: 通过微调双编码器模型，本文在SemEval-2025任务中实现了多语言和跨语言事实核查声明检索，使用轻量级模型取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 有效解决多语言和跨语言环境下事实核查声明的检索问题，以应对信息验证和跨语言信息访问的挑战。

Method: 采用学习排序（Learning-to-Rank）方法，使用从句子相似性预训练Transformer模型微调而来的轻量级（参数少于5亿）双编码器模型。多语言检索训练时结合源语言及其英语翻译，跨语言检索仅使用英语翻译，并在Kaggle T4 GPU上进行训练。

Result: 在多语言检索中达到92%的Success@10，在跨语言检索中达到80%的Success@10。在SemEval-2025任务中，跨语言赛道排名第5，多语言赛道排名第10。

Conclusion: 该轻量级模型方法在多语言和跨语言事实核查声明检索任务中表现出显著效果和效率，证明了其在解决此类问题上的竞争力。

Abstract: SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim
Retrieval is approached as a Learning-to-Rank task using a bi-encoder model
fine-tuned from a pre-trained transformer optimized for sentence similarity.
Training used both the source languages and their English translations for
multilingual retrieval and only English translations for cross-lingual
retrieval. Using lightweight models with fewer than 500M parameters and
training on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual
and 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.

</details>


### [38] [CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03489)
*Kaiwen Zhao,Bharathan Balaji,Stephen Lee*

Main category: cs.CL

TL;DR: 本研究针对PDF格式产品可持续性报告中碳足迹信息提取的挑战，引入了一个新的问答数据集CarbonPDF-QA，并提出了一种基于Llama 3微调的LLM技术CarbonPDF，该技术在处理数据不一致性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 产品可持续性报告（PDF格式，含表格和文本，缺乏标准化，格式多变）的分析复杂。现有方法难以从PDF解析的非结构化和不一致文本中提取和解释相关碳足迹信息，特别是回答相关问题。

Method: 引入CarbonPDF-QA，一个包含1735份产品报告问答对及人工标注答案的开源数据集。分析发现GPT-4o在处理数据不一致性时表现不佳。提出并开发了CarbonPDF，一种基于LLM（通过自有训练数据微调Llama 3）的技术，专门用于回答碳足迹问题。

Result: CarbonPDF技术在处理碳足迹问题上，其性能优于当前的先进技术，包括那些在表格和文本数据上微调的问答系统。

Conclusion: 本研究成功提出了一个解决PDF可持续性报告中碳足迹信息提取难题的有效LLM解决方案，并贡献了一个宝贵的问答数据集，为未来研究提供了基础。

Abstract: Product sustainability reports provide valuable insights into the
environmental impacts of a product and are often distributed in PDF format.
These reports often include a combination of tables and text, which complicates
their analysis. The lack of standardization and the variability in reporting
formats further exacerbate the difficulty of extracting and interpreting
relevant information from large volumes of documents. In this paper, we tackle
the challenge of answering questions related to carbon footprints within
sustainability reports available in PDF format. Unlike previous approaches, our
focus is on addressing the difficulties posed by the unstructured and
inconsistent nature of text extracted from PDF parsing. To facilitate this
analysis, we introduce CarbonPDF-QA, an open-source dataset containing
question-answer pairs for 1735 product report documents, along with
human-annotated answers. Our analysis shows that GPT-4o struggles to answer
questions with data inconsistencies. To address this limitation, we propose
CarbonPDF, an LLM-based technique specifically designed to answer carbon
footprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama
3 with our training data. Our results show that our technique outperforms
current state-of-the-art techniques, including question-answering (QA) systems
finetuned on table and text data.

</details>


### [39] [UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust Empathy Regression](https://arxiv.org/abs/2508.03520)
*Md Rakibul Hasan,Md Zakir Hossain,Aneesh Krishna,Shafin Rahman,Tom Gedeon*

Main category: cs.CL

TL;DR: 针对共情回归中自报告标签噪声问题，本文提出UPLME框架，该框架通过不确定性量化的概率语言模型和新型损失函数，实现了SOTA性能，并有效区分了噪声样本。


<details>
  <summary>Details</summary>
Motivation: 共情回归的监督学习面临自报告共情分数中的噪声标签挑战。尽管在文本分类中处理噪声标签已有较多研究，但在回归任务中，该领域相对未被充分探索。

Method: 提出UPLME（不确定性感知的概率语言建模）框架，用于捕获共情检测回归设置中的标签噪声。UPLME包含一个预测共情分数和异方差不确定性的概率语言模型，通过贝叶斯概念和变分模型集成进行训练。此外，引入两个新颖的损失组件：一个惩罚退化的不确定性量化，另一个强制预测共情的输入对之间的相似性。

Result: UPLME在两个带有标签噪声的公开基准测试中，实现了最先进的性能（Pearson相关系数：0.558→0.580和0.629→0.634）。通过合成标签噪声注入，证明UPLME能有效根据预测不确定性区分噪声和干净样本。UPLME在校准误差方面（0.571→0.376）优于近期为回归问题设计的变分模型集成不确定性量化方法。

Conclusion: UPLME框架有效解决了共情回归中存在的标签噪声问题，通过结合不确定性感知的概率建模和创新的损失函数，显著提升了预测性能，并能有效识别和处理噪声数据，为回归任务中的噪声标签学习提供了先进的解决方案。

Abstract: Supervised learning for empathy regression is challenged by noisy
self-reported empathy scores. While many algorithms have been proposed for
learning with noisy labels in textual classification problems, the regression
counterpart is relatively under-explored. We propose UPLME, an
uncertainty-aware probabilistic language modelling framework to capture label
noise in the regression setting of empathy detection. UPLME includes a
probabilistic language model that predicts both empathy score and
heteroscedastic uncertainty and is trained using Bayesian concepts with
variational model ensembling. We further introduce two novel loss components:
one penalises degenerate Uncertainty Quantification (UQ), and another enforces
the similarity between the input pairs on which we predict empathy. UPLME
provides state-of-the-art performance (Pearson Correlation Coefficient:
$0.558\rightarrow0.580$ and $0.629\rightarrow0.634$) in terms of the
performance reported in the literature in two public benchmarks, having label
noise. Through synthetic label noise injection, we show that UPLME is effective
in separating noisy and clean samples based on the predicted uncertainty. UPLME
further outperform (Calibration error: $0.571\rightarrow0.376$) a recent
variational model ensembling-based UQ method designed for regression problems.

</details>


### [40] [FilBench: Can LLMs Understand and Generate Filipino?](https://arxiv.org/abs/2508.03523)
*Lester James V. Miranda,Elyanah Aco,Conner Manuel,Jan Christian Blaise Cruz,Joseph Marvin Imperial*

Main category: cs.CL

TL;DR: 本文介绍了FilBench，一个为评估大型语言模型（LLMs）在菲律宾语系（包括菲律宾语、他加禄语和宿务语）中表现而设计的基准测试。研究发现当前LLMs在这些语言的阅读理解和翻译方面表现不足，且该基准具有挑战性，即使是顶级模型也表现有限，强调了构建特定语言基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在英语任务上取得了显著成就，但它们在特定语言（如菲律宾语）中的能力尚未被充分了解，存在研究空白。

Method: 研究者引入并构建了FilBench，一个以菲律宾语为中心的基准测试集，旨在评估LLMs在菲律宾语、他加禄语和宿务语中多种任务和能力。该基准的任务经过精心策划，涵盖文化知识、经典NLP、阅读理解和生成等，并用于评估了27个最先进的LLMs。

Result: 1. 多个LLM在菲律宾语的阅读理解和翻译能力上表现不佳。
2. FilBench基准测试具有挑战性，表现最好的模型GPT-4o也仅获得72.23%的得分。
3. 专门针对东南亚语言训练的模型在FilBench上表现不佳，其中表现最好的SEA-LION v3 70B也仅获得61.07%的得分。

Conclusion: 研究结果表明，策划特定语言的LLM基准测试对于推动菲律宾自然语言处理（NLP）的进步，并促进菲律宾语言在LLM开发中的整合和包容具有重要价值。

Abstract: Despite the impressive performance of LLMs on English-based tasks, little is
known about their capabilities in specific languages such as Filipino. In this
work, we address this gap by introducing FilBench, a Filipino-centric benchmark
designed to evaluate LLMs across a diverse set of tasks and capabilities in
Filipino, Tagalog, and Cebuano. We carefully curate the tasks in FilBench to
reflect the priorities and trends of NLP research in the Philippines such as
Cultural Knowledge, Classical NLP, Reading Comprehension, and Generation. By
evaluating 27 state-of-the-art LLMs on FilBench, we find that several LLMs
suffer from reading comprehension and translation capabilities. Our results
indicate that FilBench is challenging, with the best model, GPT-4o, achieving
only a score of 72.23%. Moreover, we also find that models trained specifically
for Southeast Asian languages tend to underperform on FilBench, with the
highest-performing model, SEA-LION v3 70B, achieving only a score of 61.07%.
Our work demonstrates the value of curating language-specific LLM benchmarks to
aid in driving progress on Filipino NLP and increasing the inclusion of
Philippine languages in LLM development.

</details>


### [41] [Marito: Structuring and Building Open Multilingual Terminologies for South African NLP](https://arxiv.org/abs/2508.03529)
*Vukosi Marivate,Isheanesu Dzingirai,Fiskani Banda,Richard Lastrucci,Thapelo Sindane,Keabetswe Madumo,Kayode Olaleye,Abiodun Modupe,Unarine Netshifhefhe,Herkulaas Combrink,Mohlatlego Nakeng,Matome Ledwaba*

Main category: cs.CL

TL;DR: Marito项目通过整合和标准化南非官方语言的术语数据，解决了多语言NLP领域数据不足的问题，并通过RAG管道显著提升了机器翻译的准确性。


<details>
  <summary>Details</summary>
Motivation: 南非官方语言缺乏结构化术语数据，现有术语列表零散且非机器可读，严重阻碍了多语言自然语言处理（NLP）的发展和计算研究。

Method: 项目系统地聚合、清洗并标准化了分散的术语资源，构建了开放、可互操作的Marito数据集，并将其在公平的NOODL框架下发布。为证明其效用，研究将该术语数据集成到检索增强生成（RAG）管道中。

Result: 实验表明，将Marito术语数据集成到RAG管道后，大型语言模型在英语到特西文达语的机器翻译准确性和领域特定一致性方面获得了显著提升。

Conclusion: Marito项目为开发强大且公平的NLP技术奠定了可扩展的基础，有助于确保南非丰富的语言多样性在数字时代得到充分体现。

Abstract: The critical lack of structured terminological data for South Africa's
official languages hampers progress in multilingual NLP, despite the existence
of numerous government and academic terminology lists. These valuable assets
remain fragmented and locked in non-machine-readable formats, rendering them
unusable for computational research and development. \emph{Marito} addresses
this challenge by systematically aggregating, cleaning, and standardising these
scattered resources into open, interoperable datasets. We introduce the
foundational \emph{Marito} dataset, released under the equitable,
Africa-centered NOODL framework. To demonstrate its immediate utility, we
integrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.
Experiments show substantial improvements in the accuracy and domain-specific
consistency of English-to-Tshivenda machine translation for large language
models. \emph{Marito} provides a scalable foundation for developing robust and
equitable NLP technologies, ensuring South Africa's rich linguistic diversity
is represented in the digital age.

</details>


### [42] [EmbedGrad: Gradient-Based Prompt Optimization in Embedding Space for Large Language Models](https://arxiv.org/abs/2508.03533)
*Xiaoming Hou,Jiquan Zhang,Zibin Lin,DaCheng Tao,Shengli Zhang*

Main category: cs.CL

TL;DR: 本文提出EmbedGrad，一种通过梯度优化文本提示嵌入的新框架，旨在解决预训练基础模型在多任务适应中的挑战，它弥补了离散提示工程和参数微调的不足，并在多个任务上展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前AI部署中，有效使强大的预训练基础模型适应多样化任务是一个关键挑战。现有方法（离散文本提示优化和连续参数适应）均有局限：离散方法缺乏精细度，而基于参数的方法增加了复杂性并降低可解释性。因此，需要一种新方法来克服这些限制。

Method: 提出EmbedGrad框架，通过基于梯度的细化来优化文本提示的嵌入。该方法独特地将训练与部署解耦：在优化期间，通过带标签的示例指导精确的嵌入调整，同时保持语义意义；在推理期间，只有优化后的嵌入与用户查询结合。这使得在文本空间中不可能实现的细粒度校准成为可能。

Result: 在数学推理、情感分析和因果判断任务上的综合评估表明EmbedGrad有效性显著：例如，为Qwen2.5-Math-1.5B模型优化推理提示后，其在数学问题上的准确率从14.74%提升到58.96%。在不同模型规模（0.5B-14B）和所有任务中均观察到持续改进，尤其在因果判断等复杂问题上，对小型模型的增益尤为显著。

Conclusion: 通过在不改变模型架构的情况下连接提示工程和参数效率，本研究将嵌入优化确立为一种强大的新任务适应范式。

Abstract: Effectively adapting powerful pretrained foundation models to diverse tasks
remains a key challenge in AI deployment. Current approaches primarily follow
two paradigms:discrete optimization of text prompts through prompt engineering,
or continuous adaptation via additional trainable parameters. Both exhibit
limitations-discrete methods lack refinement precision while parameter-based
techniques increase complexity and reduce interpretability. To address these
constraints, we propose EmbedGrad, a novel framework that optimizes text prompt
embeddings through gradient-based refinement. Our approach uniquely decouples
training from deployment:during optimization,labeled examples guide precise
embedding adjustments while preserving semantic meaning; during inference, only
optimized embeddings integrate with user queries. This enables fine-grained
calibration impossible in text space, such as enhancing the reasoning
capability of prompts like please reason step by step. Comprehensive
evaluations across mathematical reasoning, sentiment analysis, and causal
judgment tasks demonstrate EmbedGrad's effectiveness:optimizing this reasoning
prompt for Qwen2.5-Math-1.5B increased accuracy from 14.74\% to 58.96\% on
mathematical problems. Consistent improvements were observed across model
scales (0.5B-14B) and all tasks, with particularly significant gains for
smaller models on complex problems like causal judgment. By bridging prompt
engineering and parameter efficiency without architectural changes, our work
establishes embedding refinement as a powerful new paradigm for task
adaptation.

</details>


### [43] [Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations](https://arxiv.org/abs/2508.03550)
*Peng Lai,Jianjie Zheng,Sijie Cheng,Yun Chen,Peng Li,Yang Liu,Guanhua Chen*

Main category: cs.CL

TL;DR: LAGER框架通过利用大型语言模型（LLM）的内部跨层表示，在无需复杂提示或微调的情况下，显著提升了LLM作为评判者与人类偏好的一致性。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者（LLM-as-a-judge）在自动化评估中被广泛采用，但如何在不依赖复杂提示或微调的情况下提高其与人类偏好的一致性仍是挑战。研究发现LLM中层到上层编码的语义和任务相关表示往往比最终层更与人类判断对齐，这激发了通过内部表示来改进对齐的想法。

Method: 提出LAGER框架，一个轻量且高效的方法。它通过聚合跨层得分标记的对数（scoretoken logits），并从基于softmax的分布中计算预期得分，以生成细粒度的判断得分。该方法在LLM骨干网络保持冻结的情况下，充分利用了不同层之间的互补信息，克服了仅依赖最终层的局限性。

Result: 在Flask、HelpSteer和BIGGen等标准对齐基准测试中，LAGER在使用Spearman相关性评估时，相比最佳基线实现了高达7.5%的改进。在没有推理步骤的情况下，LAGER能够匹配或超越基于推理的方法。此外，在数据选择和情感理解等下游应用中也验证了其有效性。

Conclusion: LAGER通过创新性地利用LLM内部的跨层表示，提供了一种轻量且高效的途径，显著提升了LLM作为评判者与人类偏好的一致性，且无需复杂的提示工程或模型微调，展现出超越现有方法的潜力，并在多项任务中表现出色。

Abstract: The growing scale of evaluation tasks has led to the widespread adoption of
automated evaluation using large language models, a paradigm known as
"LLMas-a-judge." However, improving its alignment with human preferences
without complex prompts or fine-tuning remains challenging. In this work,
motivated by preliminary findings that middle-to-upper layers encode
semantically and taskrelevant representations that are often more aligned with
human judgments than the final layer, we propose LAGER, a lightweight and
efficient framework for enhancing LLM-as-a-Judge alignment with human scoring,
via internal representations. LAGER produces fine-grained judgment scores by
aggregating cross-layer scoretoken logits and computing the expected score from
a softmax-based distribution, with the LLM backbone kept frozen. LAGER fully
leverages the complementary information across different layers, overcoming the
limitations of relying solely on the final layer. We evaluate our method on the
standard alignment benchmarks Flask, HelpSteer, and BIGGen using Spearman
correlation, and find that LAGER achieves improvements of up to 7.5% over the
best baseline across these benchmarks. Without reasoning steps, LAGER matches
or outperforms reasoning-based methods. Experiments on downstream applications,
such as data selection and emotional understanding, further show the
effectiveness of our method.

</details>


### [44] [Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed Learning for Continual Adaptation](https://arxiv.org/abs/2508.03571)
*Iing Muttakhiroh,Thomas Fevens*

Main category: cs.CL

TL;DR: 本文提出KILO，一个结合动态知识图谱和指令微调的持续学习框架，旨在解决大型语言模型在领域迁移中面临的灾难性遗忘问题。实验证明KILO在适应性、知识保留和效率方面均优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在面对领域迁移时，常因灾难性遗忘导致性能显著下降。

Method: 本文提出KILO（Knowledge-Instructed Learning for Continual Adaptation），这是一个创新的持续学习框架，通过整合动态知识图谱和指令微调实现。KILO利用检索到的领域特定知识作为训练指导，旨在增强模型对新领域的适应性并保留既有知识。模型在WikiText-103上预训练，并在BioASQ、SciQ、TweetEval和MIND四个不同领域进行顺序适应性评估。

Result: 实验结果表明，KILO在逆向迁移、正向迁移、F1分数、知识保留率和训练效率方面，持续超越了包括持续微调、ERNIE 2.0和CPT在内的强大基线模型。

Conclusion: 研究结果强调了结合结构化知识检索和指令提示对于克服持续学习场景中领域迁移挑战的有效性。

Abstract: Large Language Models (LLMs) often suffer from performance degradation when
faced with domain shifts, primarily due to catastrophic forgetting. In this
work, we propose KILO (Knowledge-Instructed Learning for Continual Adaptation),
a novel continual learning framework that integrates dynamic knowledge graphs
with instruction tuning. By leveraging retrieved domain-specific knowledge as
guidance during training, KILO enhances both adaptability to new domains and
retention of previously acquired knowledge. We pretrain our model on
WikiText-103 and evaluate sequential adaptation across four diverse target
domains: BioASQ, SciQ, TweetEval, and MIND. Our experiments demonstrate that
KILO consistently outperforms strong baselines, including continual
fine-tuning, ERNIE 2.0, and CPT, in terms of backward transfer, forward
transfer, F1 score, retention rate, and training efficiency. These results
highlight the effectiveness of combining structured knowledge retrieval and
instruction prompting to overcome domain shift challenges in continual learning
scenarios.

</details>


### [45] [Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?](https://arxiv.org/abs/2508.03644)
*Wenxuan Shen,Mingjia Wang,Yaochen Wang,Dongping Chen,Junjie Yang,Yao Wan,Weiwei Lin*

Main category: cs.CL

TL;DR: 本文提出Double-Bench，一个大规模、多语言、多模态的RAG系统评估基准，旨在解决现有评估不足的问题。它能够细致评估RAG组件，并通过实验揭示了当前模型在检索和生成方面的不足，强调了更强文档检索模型的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前使用多模态大语言模型（MLLMs）的检索增强生成（RAG）系统在复杂文档理解方面潜力巨大，但其发展受到评估不足的严重阻碍。现有基准通常侧重于文档RAG系统的特定部分，并使用合成数据，其真实性和证据标签不完整，未能反映真实世界的瓶颈和挑战。

Method: 引入了Double-Bench，一个大规模、多语言、多模态的评估系统，能够对文档RAG系统中的每个组件进行细粒度评估。该系统包含3,276份文档（72,880页）和5,168个单跳及多跳查询，涵盖6种语言和4种文档类型，并支持流线型动态更新以解决潜在的数据污染问题。所有查询均基于详尽扫描的证据页面，并经人工专家验证以确保质量和完整性。研究者使用9个最先进的嵌入模型、4个MLLM和4个端到端文档RAG框架进行了全面实验。

Result: 实验结果显示，文本和视觉嵌入模型之间的差距正在缩小，这凸显了构建更强大文档检索模型的必要性。研究还揭示了当前文档RAG框架普遍存在的“过度自信困境”，即在没有证据支持的情况下也倾向于提供答案。

Conclusion: 完全开源的Double-Bench为未来高级文档RAG系统的研究提供了坚实的基础。研究团队计划及时获取语料库并每年发布新的基准。

Abstract: Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language
Models (MLLMs) show great promise for complex document understanding, yet their
development is critically hampered by inadequate evaluation. Current benchmarks
often focus on specific part of document RAG system and use synthetic data with
incomplete ground truth and evidence labels, therefore failing to reflect
real-world bottlenecks and challenges. To overcome these limitations, we
introduce Double-Bench: a new large-scale, multilingual, and multimodal
evaluation system that is able to produce fine-grained assessment to each
component within document RAG systems. It comprises 3,276 documents (72,880
pages) and 5,168 single- and multi-hop queries across 6 languages and 4
document types with streamlined dynamic update support for potential data
contamination issues. Queries are grounded in exhaustively scanned evidence
pages and verified by human experts to ensure maximum quality and completeness.
Our comprehensive experiments across 9 state-of-the-art embedding models, 4
MLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text
and visual embedding models is narrowing, highlighting the need in building
stronger document retrieval models. Our findings also reveal the
over-confidence dilemma within current document RAG frameworks that tend to
provide answer even without evidence support. We hope our fully open-source
Double-Bench provide a rigorous foundation for future research in advanced
document RAG systems. We plan to retrieve timely corpus and release new
benchmarks on an annual basis.

</details>


### [46] [Can Large Vision-Language Models Understand Multimodal Sarcasm?](https://arxiv.org/abs/2508.03654)
*Xinyu Wang,Yue Zhang,Liqiang Jing*

Main category: cs.CL

TL;DR: 评估了大型视觉语言模型（LVLMs）在多模态讽刺分析（MSA）中的应用，发现其在视觉理解和概念知识方面的局限性，并提出了一个结合深度对象提取和外部概念知识的免训练框架，有效提升了LVLMs处理多模态讽刺的能力。


<details>
  <summary>Details</summary>
Motivation: 讽刺是一种复杂的语言现象，在情感分析等任务中极具挑战性。尽管多模态信息已被用于讽刺检测，但大型视觉语言模型（LVLMs）在多模态讽刺分析（MSA）中的应用尚未得到充分探索。

Method: 首先评估了LVLMs在多模态讽刺检测和解释任务中的表现，并识别出其在视觉理解和概念知识方面的局限。然后，提出了一个免训练框架，该框架通过整合深度对象提取和外部概念知识来提升模型对多模态讽刺的解释能力。

Result: 实验发现现有LVLMs在MSA任务中存在视觉理解不足和概念知识缺乏等关键局限。所提出的免训练框架在多模型上的实验结果表明，该框架有效提升了LVLMs在多模态语境中解释和识别讽刺的能力。

Conclusion: LVLMs在多模态讽刺分析中具有潜力但存在明显不足。通过整合深度对象提取和外部概念知识，所提出的免训练框架能够有效弥补这些不足，显著提升模型处理多模态讽刺的能力。

Abstract: Sarcasm is a complex linguistic phenomenon that involves a disparity between
literal and intended meanings, making it challenging for sentiment analysis and
other emotion-sensitive tasks. While traditional sarcasm detection methods
primarily focus on text, recent approaches have incorporated multimodal
information. However, the application of Large Visual Language Models (LVLMs)
in Multimodal Sarcasm Analysis (MSA) remains underexplored. In this paper, we
evaluate LVLMs in MSA tasks, specifically focusing on Multimodal Sarcasm
Detection and Multimodal Sarcasm Explanation. Through comprehensive
experiments, we identify key limitations, such as insufficient visual
understanding and a lack of conceptual knowledge. To address these issues, we
propose a training-free framework that integrates in-depth object extraction
and external conceptual knowledge to improve the model's ability to interpret
and explain sarcasm in multimodal contexts. The experimental results on
multiple models show the effectiveness of our proposed framework. The code is
available at https://github.com/cp-cp/LVLM-MSA.

</details>


### [47] [CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction](https://arxiv.org/abs/2508.03668)
*Zixuan Li,Binzong Geng,Jing Xiong,Yong He,Yuxuan Hu,Jian Chen,Dingwei Chen,Xiyu Chang,Liang Zhang,Linjian Mo,Chengming Li,Chuan Yuan,Zhenan Sun*

Main category: cs.CL

TL;DR: 提出`CTR-Sink`框架，通过引入行为级注意力汇聚点（attention sinks）解决语言模型（LM）在点击率（CTR）预测中处理用户行为序列时的语义碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型（LM）被用于点击率（CTR）预测，将用户行为序列建模为文本。然而，用户行为序列与自然语言存在结构性差异，导致语义碎片化，即LM注意力分散，未能有效聚焦于行为边界和关系，从而降低预测性能。

Method: 提出`CTR-Sink`框架。该框架引入行为级注意力汇聚点，通过在连续行为之间插入“汇聚点令牌（sink tokens）”，并融入推荐场景特有的信号（如时间距离）。为增强通用性，设计了两阶段训练策略以引导LM注意力聚焦于汇聚点令牌，并采用注意力汇聚机制强化汇聚点间的依赖关系。

Result: 在一个工业数据集和两个开源数据集（MovieLens, Kuairec）上的实验，以及可视化结果，验证了该方法在不同场景下的有效性。

Conclusion: `CTR-Sink`框架成功解决了LM在CTR预测中遇到的语义碎片化问题，通过引导注意力聚焦于关键行为信息，有效提升了预测性能和方法的普适性。

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems,
estimates user click likelihood using historical behavioral data. Modeling user
behavior sequences as text to leverage Language Models (LMs) for this task has
gained traction, owing to LMs' strong semantic understanding and contextual
modeling capabilities. However, a critical structural gap exists: user behavior
sequences consist of discrete actions connected by semantically empty
separators, differing fundamentally from the coherent natural language in LM
pre-training. This mismatch causes semantic fragmentation, where LM attention
scatters across irrelevant tokens instead of focusing on meaningful behavior
boundaries and inter-behavior relationships, degrading prediction performance.
To address this, we propose $\textit{CTR-Sink}$, a novel framework introducing
behavior-level attention sinks tailored for recommendation scenarios. Inspired
by attention sink theory, it constructs attention focus sinks and dynamically
regulates attention aggregation via external information. Specifically, we
insert sink tokens between consecutive behaviors, incorporating
recommendation-specific signals such as temporal distance to serve as stable
attention sinks. To enhance generality, we design a two-stage training strategy
that explicitly guides LM attention toward sink tokens and a attention sink
mechanism that amplifies inter-sink dependencies to better capture behavioral
correlations. Experiments on one industrial dataset and two open-source
datasets (MovieLens, Kuairec), alongside visualization results, validate the
method's effectiveness across scenarios.

</details>


### [48] [FairLangProc: A Python package for fairness in NLP](https://arxiv.org/abs/2508.03677)
*Arturo Pérez-Peralta,Sandra Benítez-Peña,Rosa E. Lillo*

Main category: cs.CL

TL;DR: 论文提出了FairLangProc，一个Python包，旨在通过提供与Hugging Face兼容的统一接口，促进NLP偏见缓解技术的广泛应用和民主化。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型在决策场景中应用日益广泛，其公平性问题引发社会关注。尽管已有多种偏见缓解技术，但其实现方式分散且缺乏标准化。

Method: 开发了一个名为FairLangProc的综合Python软件包，该软件包集成了自然语言处理领域中最新的公平性进展，并提供了与Hugging Face transformers库兼容的接口。

Result: 成功开发并发布了FairLangProc软件包，它为NLP偏见测量和缓解技术提供了一个统一且易于访问的实现平台。

Conclusion: FairLangProc有望推动偏见缓解技术在NLP领域的普及和标准化，从而促进公平性实践。

Abstract: The rise in usage of Large Language Models to near ubiquitousness in recent
years has risen societal concern about their applications in decision-making
contexts, such as organizational justice or healthcare. This, in turn, poses
questions about the fairness of these models in critical settings, which leads
to the developement of different procedures to address bias in Natural Language
Processing. Although many datasets, metrics and algorithms have been proposed
to measure and mitigate harmful prejudice in Natural Language Processing, their
implementation is diverse and far from centralized. As a response, this paper
presents FairLangProc, a comprehensive Python package providing a common
implementation of some of the more recent advances in fairness in Natural
Language Processing providing an interface compatible with the famous Hugging
Face transformers library, aiming to encourage the widespread use and
democratization of bias mitigation techniques. The implementation can be found
on https://github.com/arturo-perez-peralta/FairLangProc.

</details>


### [49] [More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation](https://arxiv.org/abs/2508.03678)
*Yangtian Zi,Harshitha Menon,Arjun Guha*

Main category: cs.CL

TL;DR: 研究LLM在专业代码生成任务中表现不佳的原因，通过PartialOrderEval工具分析提示词细节的影响，发现I/O规范、边界处理和分步说明是提升性能的关键。


<details>
  <summary>Details</summary>
Motivation: 探究LLM在专业代码生成基准（如ParEval）上表现逊色的原因：是缺乏领域知识还是提示词细节不够？

Method: 提出了PartialOrderEval工具，可为任何代码生成基准提供从最简到最详尽的偏序提示词。将此工具应用于HumanEval和ParEval（包含串行和OpenMP子集），使用Llama-3.x和Qwen2.5-Coder模型，测量pass@1指标随提示词特异性变化的规律。

Result: 实验结果显示，不同任务对提示词的敏感度存在差异。定性分析表明，明确的输入/输出规范、对边缘情况的处理以及分步拆解是提升提示词细节效果的关键驱动因素。

Conclusion: 提示词细节，特别是明确的I/O、边缘情况处理和分步说明，对提升LLM在代码生成任务中的性能至关重要，且其影响程度因任务而异。

Abstract: State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general
benchmarks like HumanEval but underperform on specialized suites such as
ParEval. Is this due to LLMs missing domain knowledge or insufficient prompt
detail is given? To answer this, we introduce PartialOrderEval, which augments
any code generation benchmark with a partial order of prompts from minimal to
maximally detailed. Applying it to HumanEval and both serial and OpenMP subsets
of ParEval, we measure how pass@1 scales with prompt specificity. Our
experiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of
prompt sensitivity across different tasks, and a qualitative analysis
highlights explicit I/O specifications, edge-case handling, and stepwise
breakdowns as the key drivers of prompt detail improvement.

</details>


### [50] [CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward](https://arxiv.org/abs/2508.03686)
*Shudong Liu,Hongwei Liu,Junnan Liu,Linchen Xiao,Songyang Gao,Chengqi Lyu,Yuzhe Gu,Wenwei Zhang,Derek F. Wong,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 本文开发了CompassVerifier，一个准确、鲁棒且轻量级的答案验证模型，并构建了VerifierBench基准，旨在解决大型语言模型（LLM）答案验证中现有方法的局限性，提升评估和奖励模型的效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM答案验证方法存在两项主要局限：1) 缺乏全面系统地评估不同LLM验证能力的基准；2) 现有验证器开发处于初期，缺乏处理复杂边缘情况的鲁棒性和跨领域泛化能力。此外，现有评估框架（如正则匹配或通用LLM）需要大量重复定制。

Method: 1. 开发了CompassVerifier，一个用于LLM评估和结果奖励的准确、鲁棒且轻量级的验证模型。2. 引入了VerifierBench基准，该基准包含从多个数据源收集的模型输出，并通过人工分析元错误模式进行增强，以优化CompassVerifier。

Result: CompassVerifier在数学、知识和多样推理任务中展现了多领域能力，能处理多子问题、公式和序列答案等多种答案类型，并有效识别异常/无效响应。

Conclusion: CompassVerifier和VerifierBench有望推动答案验证、评估协议以及强化学习研究的进步。

Abstract: Answer verification is crucial not only for evaluating large language models
(LLMs) by matching their unstructured outputs against standard answers, but
also serves as the reward model to guide LLM optimization. Most evaluation
frameworks rely on regularized matching or employ general LLMs for answer
verification, which demands extensive, repetitive customization for regex rules
or evaluation prompts. Two fundamental limitations persist in current
methodologies: 1) the absence of comprehensive benchmarks that systematically
evaluate verification capabilities across different LLMs; and 2) the nascent
stage of verifier development, where existing approaches lack both the
robustness to handle complex edge cases and the generalizability across
different domains. In this work, we develop CompassVerifier, an accurate and
robust lightweight verifier model for evaluation and outcome reward. It
demonstrates multi-domain competency spanning math, knowledge, and diverse
reasoning tasks, with the capability to process various answer types, including
multi-subproblems, formulas, and sequence answers, while effectively
identifying abnormal/invalid responses. We introduce VerifierBench benchmark
comprising model outputs collected from multiple data sources, augmented
through manual analysis of metaerror patterns to enhance CompassVerifier. We
anticipate that CompassVerifier and VerifierBench will facilitate answer
verification, evaluation protocols, and reinforcement learning research. Code
and dataset are available at https://github.com/open-compass/CompassVerifier.

</details>


### [51] [Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025](https://arxiv.org/abs/2508.01263)
*Long S. T. Nguyen,Khang H. N. Vo,Thu H. A. Nguyen,Tuan C. Bui,Duc Q. Nguyen,Thanh-Tung Tran,Anh D. Nguyen,Minh L. Nguyen,Fabien Baldacci,Thang H. Bui,Emanuel Di Nardo,Angelo Ciaramella,Son H. Le,Ihsan Ullah,Lorenzo Di Rocco,Tho T. Quan*

Main category: cs.CL

TL;DR: 本文分析了XAI Challenge 2025，一项旨在教育领域构建可解释问答系统（使用轻量级LLM或混合系统）的黑客马拉松，旨在弥合大型语言模型与符号推理之间的鸿沟以提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在教育领域日益深入，对透明度和可解释性的需求日益增长。现有黑客马拉松鲜少直接关注真实教育环境中的可解释AI（XAI）。该挑战旨在解决这一空白，推动AI在教育中的可信应用。

Method: 本文分析了XAI Challenge 2025的设计与实施。该挑战要求参与者构建问答系统，以回答学生关于大学政策的查询，并生成清晰、基于逻辑的自然语言解释。为确保透明度和可信度，解决方案必须使用轻量级大型语言模型（LLMs）或混合LLM-符号系统。挑战提供了一个通过逻辑模板、Z3验证和专家学生审查构建的高质量数据集。论文描述了挑战的动机、结构、数据集构建和评估协议。

Result: 通过对XAI Challenge 2025的全面分析，论文认为这项竞赛是弥合LLMs和符号推理之间差距以服务可解释性的一项新颖尝试。其发现为未来的以XAI为中心的教育系统和竞争性研究计划提供了可操作的见解。

Conclusion: XAI Challenge 2025代表了在教育背景下，通过结合LLMs和符号推理来提升AI可解释性的一项创新努力，并为未来的XAI教育应用和研究提供了宝贵经验。

Abstract: The growing integration of Artificial Intelligence (AI) into education has
intensified the need for transparency and interpretability. While hackathons
have long served as agile environments for rapid AI prototyping, few have
directly addressed eXplainable AI (XAI) in real-world educational contexts.
This paper presents a comprehensive analysis of the XAI Challenge 2025, a
hackathon-style competition jointly organized by Ho Chi Minh City University of
Technology (HCMUT) and the International Workshop on Trustworthiness and
Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International
Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked
participants with building Question-Answering (QA) systems capable of answering
student queries about university policies while generating clear, logic-based
natural language explanations. To promote transparency and trustworthiness,
solutions were required to use lightweight Large Language Models (LLMs) or
hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed
via logic-based templates with Z3 validation and refined through expert student
review to ensure alignment with real-world academic scenarios. We describe the
challenge's motivation, structure, dataset construction, and evaluation
protocol. Situating the competition within the broader evolution of AI
hackathons, we argue that it represents a novel effort to bridge LLMs and
symbolic reasoning in service of explainability. Our findings offer actionable
insights for future XAI-centered educational systems and competitive research
initiatives.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [PyCAT4: A Hierarchical Vision Transformer-based Framework for 3D Human Pose Estimation](https://arxiv.org/abs/2508.02806)
*Zongyou Yang,Jonathan Loo*

Main category: cs.CV

TL;DR: 本文通过引入Transformer特征提取层、时序特征融合和空间金字塔结构，对Pymaf网络进行深度优化，显著提升了3D人体姿态估计的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN和金字塔网格对齐反馈循环的Pymaf网络在3D人体姿态估计方面取得了显著进步，且Transformer在计算机视觉的时序分析中表现出色。研究旨在结合这些进展，对现有Pymaf网络架构进行深度优化和改进。

Method: 本研究提出了PyCAT4模型，主要创新点包括：1) 引入基于自注意力机制的Transformer特征提取网络层以增强低级特征捕获；2) 通过特征时序融合技术增强视频序列的时序信号理解和捕获；3) 实现空间金字塔结构以进行多尺度特征融合，平衡不同尺度的特征表示差异。

Result: 在COCO和3DPW数据集上进行的实验验证表明，所提出的改进策略显著增强了网络在人体姿态估计方面的检测能力。

Conclusion: 所提出的PyCAT4模型通过整合Transformer、时序和多尺度特征融合技术，有效提升了3D人体姿态估计的性能，进一步推动了该技术的发展。

Abstract: Recently, a significant improvement in the accuracy of 3D human pose
estimation has been achieved by combining convolutional neural networks (CNNs)
with pyramid grid alignment feedback loops. Additionally, innovative
breakthroughs have been made in the field of computer vision through the
adoption of Transformer-based temporal analysis architectures. Given these
advancements, this study aims to deeply optimize and improve the existing Pymaf
network architecture. The main innovations of this paper include: (1)
Introducing a Transformer feature extraction network layer based on
self-attention mechanisms to enhance the capture of low-level features; (2)
Enhancing the understanding and capture of temporal signals in video sequences
through feature temporal fusion techniques; (3) Implementing spatial pyramid
structures to achieve multi-scale feature fusion, effectively balancing feature
representations differences across different scales. The new PyCAT4 model
obtained in this study is validated through experiments on the COCO and 3DPW
datasets. The results demonstrate that the proposed improvement strategies
significantly enhance the network's detection capability in human pose
estimation, further advancing the development of human pose estimation
technology.

</details>


### [53] [DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework](https://arxiv.org/abs/2508.02807)
*Tongchun Zuo,Zaiyu Huang,Shuliang Ning,Ente Lin,Chao Liang,Zerong Zheng,Jianwen Jiang,Yuan Zhang,Mingyuan Gao,Xin Dong*

Main category: cs.CV

TL;DR: DreamVVT是一个基于DiTs的两阶段视频虚拟试穿框架，通过利用多模态信息和预训练模型，有效解决了现有方法在细节保留和时间一致性上的挑战，实现了更真实、稳定的试穿效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频虚拟试穿（VVT）方法过度依赖稀缺的配对数据集，且未能有效利用先进视觉模型和测试时输入的先验知识，导致在非受限场景下服装细节保留不足和时间一致性差。

Method: 提出DreamVVT两阶段框架：
1. 第一阶段: 采样代表性视频帧，利用整合VLM的多帧试穿模型生成高保真关键帧试穿图像，作为后续视频生成的视觉引导。
2. 第二阶段: 提取骨骼图、运动与外观描述，结合关键帧试穿图像输入到由LoRA增强的预训练视频生成模型，以确保长程时间连贯性和逼真动态。该框架能利用多样化的非配对数据。

Result: 实验证明，DreamVVT在保留服装细节内容和时间稳定性方面优于现有方法，尤其在真实世界场景中表现卓越。

Conclusion: DreamVVT通过其创新的两阶段架构，有效解决了视频虚拟试穿中的核心挑战，显著提升了服装细节保留和时间一致性，展现了其在实际应用中的优越性。

Abstract: Video virtual try-on (VVT) technology has garnered considerable academic
interest owing to its promising applications in e-commerce advertising and
entertainment. However, most existing end-to-end methods rely heavily on scarce
paired garment-centric datasets and fail to effectively leverage priors of
advanced visual models and test-time inputs, making it challenging to
accurately preserve fine-grained garment details and maintain temporal
consistency in unconstrained scenarios. To address these challenges, we propose
DreamVVT, a carefully designed two-stage framework built upon Diffusion
Transformers (DiTs), which is inherently capable of leveraging diverse unpaired
human-centric data to enhance adaptability in real-world scenarios. To further
leverage prior knowledge from pretrained models and test-time inputs, in the
first stage, we sample representative frames from the input video and utilize a
multi-frame try-on model integrated with a vision-language model (VLM), to
synthesize high-fidelity and semantically consistent keyframe try-on images.
These images serve as complementary appearance guidance for subsequent video
generation. \textbf{In the second stage}, skeleton maps together with
fine-grained motion and appearance descriptions are extracted from the input
content, and these along with the keyframe try-on images are then fed into a
pretrained video generation model enhanced with LoRA adapters. This ensures
long-term temporal coherence for unseen regions and enables highly plausible
dynamic motions. Extensive quantitative and qualitative experiments demonstrate
that DreamVVT surpasses existing methods in preserving detailed garment content
and temporal stability in real-world scenarios. Our project page
https://virtu-lab.github.io/

</details>


### [54] [Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)
*Adam Colton*

Main category: cs.CV

TL;DR: 本文发现IJEPA中的层归一化（LN）破坏了视觉token的能量层级，导致性能下降。研究提出用DynTanh激活函数替代LN，以保留token能量，从而提升自监督学习效果，并在ImageNet和NYU Depth V2上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 标准IJEPA中的特征层归一化（LN）破坏了视觉token的自然能量层级，使高能量（语义重要）区域无法被优先处理，并导致损失图出现棋盘状伪影，影响模型性能。

Method: 将IJEPA中教师编码器输出特征的层归一化替换为DynTanh激活函数。该方法旨在更好地保留token能量，并允许高能量token对预测损失做出更大贡献。

Result: 使用DynTanh的IJEPA模型展现出更长的损失分布尾部，并修复了损失图中的棋盘状伪影。经验结果显示，ViT-Small在ImageNet线性探针准确率从38%提升至42.7%，并在NYU Depth V2单目深度估计中将RMSE降低了0.08。

Conclusion: 保留视觉token的自然能量层级对于实现有效的自监督视觉表示学习至关重要。

Abstract: In the standard image joint embedding predictive architecture (IJEPA),
features at the output of the teacher encoder are layer normalized (LN) before
serving as a distillation target for the student encoder and predictor. We
propose that this feature normalization disrupts the natural energy hierarchy
of visual tokens, where high-energy tokens (those with larger L2 norms) encode
semantically important image regions. LN forces all features to have identical
L2 norms, effectively equalizing their energies and preventing the model from
prioritizing semantically rich regions. We find that IJEPA models trained with
feature LN exhibit loss maps with significant checkerboard-like artifacts. We
propose that feature LN be replaced with a DynTanh activation as the latter
better preserves token energies and allows high-energy tokens to greater
contribute to the prediction loss. We show that IJEPA trained with feature
DynTanh exhibits a longer-tailed loss distribution and fixes the checkerboard
artifacts in the loss map. Our empirical results show that our simple
modification improves ImageNet linear probe accuracy from 38% to 42.7% for
ViT-Small and reduces RMSE by 0.08 on NYU Depth V2 monocular depth estimation.
These results suggest that preserving natural token energies is crucial for
effective self-supervised visual representation learning.

</details>


### [55] [GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing](https://arxiv.org/abs/2508.02831)
*Mikołaj Zieliński,Krzysztof Byrski,Tomasz Szczepanik,Przemysław Spurek*

Main category: cs.CV

TL;DR: GENIE是一种混合模型，它结合了NeRF的高保真渲染和GS的可编辑结构，通过高斯特征编码和高效的近邻搜索，实现了实时、局部感知的交互式神经渲染，并兼容物理模拟。


<details>
  <summary>Details</summary>
Motivation: NeRF虽能实现高保真渲染，但难以进行编辑和物理交互；而GS则因其显式结构更适合交互式编辑。本研究旨在结合两者优势，弥合基于几何的编辑与神经渲染之间的鸿沟，从而实现既具备高品质渲染又能直观操作的神经场景表示。

Method: 本文提出了GENIE（Gaussian Encoding for Neural Radiance Fields Interactive Editing）模型。核心方法是为每个高斯点分配可训练的特征嵌入，并使用这些嵌入以及查询点k近邻高斯来条件化NeRF网络。为提高效率，引入了基于改进光线追踪管道的“光线追踪高斯邻近搜索”（RT-GPS）技术，以及多分辨率哈希网格来初始化和更新高斯特征，以实现高效的近邻搜索和特征管理。

Result: GENIE模型实现了实时、局部感知的编辑。当高斯基元被重新定位或修改时，其插值影响会立即反映在渲染输出中，从而支持直观的场景操作、动态交互以及与物理模拟的兼容性。

Conclusion: GENIE通过结合隐式（NeRF）和显式（GS）表示的优势，成功地弥合了几何编辑与神经渲染之间的差距，提供了一种既能实现高保真渲染又具备强大可编辑性的3D场景表示和交互方式。

Abstract: Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) have recently
transformed 3D scene representation and rendering. NeRF achieves high-fidelity
novel view synthesis by learning volumetric representations through neural
networks, but its implicit encoding makes editing and physical interaction
challenging. In contrast, GS represents scenes as explicit collections of
Gaussian primitives, enabling real-time rendering, faster training, and more
intuitive manipulation. This explicit structure has made GS particularly
well-suited for interactive editing and integration with physics-based
simulation. In this paper, we introduce GENIE (Gaussian Encoding for Neural
Radiance Fields Interactive Editing), a hybrid model that combines the
photorealistic rendering quality of NeRF with the editable and structured
representation of GS. Instead of using spherical harmonics for appearance
modeling, we assign each Gaussian a trainable feature embedding. These
embeddings are used to condition a NeRF network based on the k nearest
Gaussians to each query point. To make this conditioning efficient, we
introduce Ray-Traced Gaussian Proximity Search (RT-GPS), a fast nearest
Gaussian search based on a modified ray-tracing pipeline. We also integrate a
multi-resolution hash grid to initialize and update Gaussian features.
Together, these components enable real-time, locality-aware editing: as
Gaussian primitives are repositioned or modified, their interpolated influence
is immediately reflected in the rendered output. By combining the strengths of
implicit and explicit representations, GENIE supports intuitive scene
manipulation, dynamic interaction, and compatibility with physical simulation,
bridging the gap between geometry-based editing and neural rendering. The code
can be found under (https://github.com/MikolajZielinski/genie)

</details>


### [56] [RefineSeg: Dual Coarse-to-Fine Learning for Medical Image Segmentation](https://arxiv.org/abs/2508.02844)
*Anghong Du,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: cs.CV

TL;DR: 本文提出一个从粗到细的分割框架，利用带噪声的粗粒度标注和转移矩阵，实现医学图像的精确分割，性能媲美全监督方法。


<details>
  <summary>Details</summary>
Motivation: 高质量医学图像像素级标注成本高昂且需专业知识，限制了监督分割任务的开展。

Method: 提出一种新颖的从粗到细的分割框架，完全依赖粗粒度标注（包括目标和补充绘制），即便其包含噪声。通过引入转移矩阵来建模粗标注中不准确和不完整的区域，并联合训练多组粗标注，逐步优化网络输出，推断真实的分割分布，从而实现精确标签的鲁棒近似。

Result: 在ACDC、MSCMRseg和UK Biobank两个公开心脏图像数据集上验证了该方法，实验结果表明其性能优于现有弱监督方法，并与全监督方法的效果非常接近。

Conclusion: 该框架能有效利用带噪声的粗粒度标注，通过矩阵建模实现了对精确标签的鲁棒近似，解决了医学图像标注成本高昂的问题，并在分割任务中取得了卓越的性能。

Abstract: High-quality pixel-level annotations of medical images are essential for
supervised segmentation tasks, but obtaining such annotations is costly and
requires medical expertise. To address this challenge, we propose a novel
coarse-to-fine segmentation framework that relies entirely on coarse-level
annotations, encompassing both target and complementary drawings, despite their
inherent noise. The framework works by introducing transition matrices in order
to model the inaccurate and incomplete regions in the coarse annotations. By
jointly training on multiple sets of coarse annotations, it progressively
refines the network's outputs and infers the true segmentation distribution,
achieving a robust approximation of precise labels through matrix-based
modeling. To validate the flexibility and effectiveness of the proposed method,
we demonstrate the results on two public cardiac imaging datasets, ACDC and
MSCMRseg, and further evaluate its performance on the UK Biobank dataset.
Experimental results indicate that our approach surpasses the state-of-the-art
weakly supervised methods and closely matches the fully supervised approach.

</details>


### [57] [MIDAR: Mimicking LiDAR Detection for Traffic Applications with a Lightweight Plug-and-Play Model](https://arxiv.org/abs/2508.02858)
*Tianheng Zhu,Yiheng Feng*

Main category: cs.CV

TL;DR: MIDAR是一个LiDAR检测模拟模型，旨在弥合高保真但不可伸缩的游戏引擎模拟器与可伸缩但缺乏感知建模的微观交通模拟器之间的鸿沟。它利用车辆级特征和基于图的方法（RM-LoS, GRU-enhanced APPNP）来预测LiDAR检测结果中的真阳性和假阴性，实现了对真实检测的有效逼近。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术发展中，合作感知数据对交通应用至关重要。然而，大规模真实世界自动驾驶部署不切实际，模拟成为主要方法。现有游戏引擎模拟器（如CARLA）虽能生成高保真传感器数据，但在多自动驾驶场景中缺乏可伸缩性；而微观交通模拟器（如SUMO）虽高效可伸缩，却缺乏感知建模能力。因此，需要一种方法利用微观交通模拟器中现有的车辆特征来近似真实的LiDAR检测结果，以弥补这一空白。

Method: 本文提出了MIDAR模型，用于模拟LiDAR检测结果。MIDAR根据周围车辆的空间布局和尺寸，从理想LiDAR检测结果中预测真阳性（TPs）和假阴性（FNs）。它构建了一个改进多跳视线（RM-LoS）图来编码车辆间的遮挡关系。在此图的基础上，MIDAR采用GRU增强的APPNP架构，从自我自动驾驶车辆和遮挡车辆向预测目标传播特征。

Result: MIDAR在nuScenes AD数据集上，以0.909的AUC值成功逼近了主流3D LiDAR检测模型CenterPoint生成的检测结果。通过两个基于合作感知的交通应用进一步验证了这种现实检测建模的必要性，尤其对于需要准确个体车辆观测（如位置、速度、车道索引）的任务。实验表明MIDAR可以无缝集成到交通模拟器和轨迹数据集中。

Conclusion: MIDAR模型有效弥合了可伸缩的微观交通模拟器与现实感知建模之间的差距。它能提供逼真的LiDAR检测近似，这对于依赖精确个体车辆数据的合作感知交通应用至关重要。MIDAR可轻松集成并计划开源，为未来研究提供便利。

Abstract: As autonomous driving (AD) technology advances, increasing research has
focused on leveraging cooperative perception (CP) data collected from multiple
AVs to enhance traffic applications. Due to the impracticality of large-scale
real-world AV deployments, simulation has become the primary approach in most
studies. While game-engine-based simulators like CARLA generate high-fidelity
raw sensor data (e.g., LiDAR point clouds) which can be used to produce
realistic detection outputs, they face scalability challenges in multi-AV
scenarios. In contrast, microscopic traffic simulators such as SUMO scale
efficiently but lack perception modeling capabilities. To bridge this gap, we
propose MIDAR, a LiDAR detection mimicking model that approximates realistic
LiDAR detections using vehicle-level features readily available from
microscopic traffic simulators. Specifically, MIDAR predicts true positives
(TPs) and false negatives (FNs) from ideal LiDAR detection results based on the
spatial layouts and dimensions of surrounding vehicles. A Refined Multi-hop
Line-of-Sight (RM-LoS) graph is constructed to encode the occlusion
relationships among vehicles, upon which MIDAR employs a GRU-enhanced APPNP
architecture to propagate features from the ego AV and occluding vehicles to
the prediction target. MIDAR achieves an AUC of 0.909 in approximating the
detection results generated by CenterPoint, a mainstream 3D LiDAR detection
model, on the nuScenes AD dataset. Two CP-based traffic applications further
validate the necessity of such realistic detection modeling, particularly for
tasks requiring accurate individual vehicle observations (e.g., position,
speed, lane index). As demonstrated in the applications, MIDAR can be
seamlessly integrated into traffic simulators and trajectory datasets and will
be open-sourced upon publication.

</details>


### [58] [Evaluation and Analysis of Deep Neural Transformers and Convolutional Neural Networks on Modern Remote Sensing Datasets](https://arxiv.org/abs/2508.02871)
*J. Alex Hurt,Trevor M. Bajkowski,Grant J. Scott,Curt H. Davis*

Main category: cs.CV

TL;DR: 本文对比了基于Transformer的网络与卷积神经网络在遥感图像目标检测中的性能，发现Transformer在卫星图像上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络在计算机视觉和遥感领域曾占据主导地位，但随着视觉Transformer的兴起，迫切需要了解其在卫星图像上的表现，因为此前缺乏大规模的比较研究。

Method: 研究在高分辨率光电卫星图像上，对比了11种边界框检测和定位算法（包括5种Transformer和6种卷积网络），在3个最先进的开源高分辨率遥感图像数据集上训练并评估了33个深度神经网络模型。随后，分析了不同特征提取方法和检测算法的模型性能。

Result: 基于Transformer的神经网络在高分辨率光电卫星图像的目标检测任务上，在多个公开基准数据集上展现了最先进的性能。

Conclusion: 本研究证实了Transformer架构在处理高分辨率卫星图像目标检测方面的卓越能力，达到了当前最佳水平，为遥感领域的应用提供了新的高效解决方案。

Abstract: In 2012, AlexNet established deep convolutional neural networks (DCNNs) as
the state-of-the-art in CV, as these networks soon led in visual tasks for many
domains, including remote sensing. With the publication of Visual Transformers,
we are witnessing the second modern leap in computational vision, and as such,
it is imperative to understand how various transformer-based neural networks
perform on satellite imagery. While transformers have shown high levels of
performance in natural language processing and CV applications, they have yet
to be compared on a large scale to modern remote sensing data. In this paper,
we explore the use of transformer-based neural networks for object detection in
high-resolution electro-optical satellite imagery, demonstrating
state-of-the-art performance on a variety of publicly available benchmark data
sets. We compare eleven distinct bounding-box detection and localization
algorithms in this study, of which seven were published since 2020, and all
eleven since 2015. The performance of five transformer-based architectures is
compared with six convolutional networks on three state-of-the-art opensource
high-resolution remote sensing imagery datasets ranging in size and complexity.
Following the training and evaluation of thirty-three deep neural models, we
then discuss and analyze model performance across various feature extraction
methodologies and detection algorithms.

</details>


### [59] [VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction](https://arxiv.org/abs/2508.02890)
*Rongxin Jiang,Robert Long,Chenghao Gu,Mingrui Yan*

Main category: cs.CV

TL;DR: 本文提出了VisuCraft框架，通过集成多模态结构信息提取器和动态提示生成模块，显著提升了大型视觉-语言模型（LVLMs）在视觉引导创意内容生成方面的视觉保真度、创造性和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉-语言模型（LVLMs）在生成长篇文本时，难以保持高视觉保真度、真正的创造力以及精确遵循细致的用户指令。

Method: VisuCraft框架包含两个核心模块：1. 多模态结构信息提取器（E），用于从输入图像中提取细粒度视觉属性并将其转化为丰富的结构化表示；2. 动态提示生成模块（G），将提取的信息与用户指令结合，为底层LVLMs（如LLaVA、InstructBLIP）生成高度优化的提示。

Result: 在自建的ImageStoryGen-500K数据集和VisuGen评估指标（视觉基础、创造力、指令遵循）上进行评估，VisuCraft在故事生成和诗歌创作等任务中持续优于基线LVLMs，尤其在创造力和指令遵循方面展现出显著提升。

Conclusion: 研究结果验证了VisuCraft在生成富有想象力、视觉基础良好且用户对齐的长篇创意文本方面的有效性，为LVLMs在复杂的创意AI应用中解锁了新的潜力。

Abstract: This paper introduces VisuCraft, a novel framework designed to significantly
enhance the capabilities of Large Vision-Language Models (LVLMs) in complex
visual-guided creative content generation. Existing LVLMs often exhibit
limitations in maintaining high visual fidelity, genuine creativity, and
precise adherence to nuanced user instructions when generating long-form texts.
VisuCraft addresses these challenges by integrating a multimodal structured
information extractor (E) and a dynamic prompt generation module (G). The
extractor distills fine-grained visual attributes from input images into a
rich, structured representation, which the dynamic prompt module then combines
with user instructions to create highly optimized prompts for underlying LVLMs
(e.g., LLaVA, InstructBLIP). Evaluated on the self-constructed
ImageStoryGen-500K dataset using VisuGen Metrics (Visual Grounding, Creativity,
and Instruction Adherence), VisuCraft consistently outperforms baseline LVLMs
across tasks like story generation and poetry composition. Our results
demonstrate remarkable improvements, particularly in creativity and instruction
adherence, validating VisuCraft's effectiveness in producing imaginative,
visually grounded, and user-aligned long-form creative text. This work unlocks
new potential for LVLMs in sophisticated creative AI applications.

</details>


### [60] [RDDPM: Robust Denoising Diffusion Probabilistic Model for Unsupervised Anomaly Segmentation](https://arxiv.org/abs/2508.02903)
*Mehrdad Moradi,Kamran Paynabar*

Main category: cs.CV

TL;DR: 针对无监督异常分割中扩散模型需纯净正常数据训练的限制，本文提出了鲁棒去噪扩散模型(RDDPM)，使其能在包含正常和异常混合的受污染数据上进行有效训练，并在性能上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在无监督异常分割中需纯净的正常数据进行训练，这限制了其在真实世界场景中的应用，因为实际数据往往是正常与异常混合的（受污染数据）。

Method: 本文提出了一种新型的鲁棒去噪扩散模型。通过将数据的最大似然估计转化为非线性回归问题，作者们重新诠释了去噪扩散概率模型（DDPM），并利用鲁棒回归技术推导出了DDPM的鲁棒版本。

Result: 实验表明，在仅有受污染数据可用的情况下，该方法在无监督异常分割方面优于当前最先进的扩散模型。在MVTec数据集上，相较于现有基于扩散的方法，AUROC提高了高达8.08%，AUPRC提高了高达10.37%。

Conclusion: 所提出的鲁棒去噪扩散模型解决了现有扩散模型需要纯净正常数据训练的关键限制，使其能够在受污染数据上进行训练，从而显著扩展了其在真实场景中进行无监督异常分割的适用性，并展现出卓越的性能。

Abstract: Recent advancements in diffusion models have demonstrated significant success
in unsupervised anomaly segmentation. For anomaly segmentation, these models
are first trained on normal data; then, an anomalous image is noised to an
intermediate step, and the normal image is reconstructed through backward
diffusion. Unlike traditional statistical methods, diffusion models do not rely
on specific assumptions about the data or target anomalies, making them
versatile for use across different domains. However, diffusion models typically
assume access to normal data for training, limiting their applicability in
realistic settings. In this paper, we propose novel robust denoising diffusion
models for scenarios where only contaminated (i.e., a mix of normal and
anomalous) unlabeled data is available. By casting maximum likelihood
estimation of the data as a nonlinear regression problem, we reinterpret the
denoising diffusion probabilistic model through a regression lens. Using robust
regression, we derive a robust version of denoising diffusion probabilistic
models. Our novel framework offers flexibility in constructing various robust
diffusion models. Our experiments show that our approach outperforms current
state of the art diffusion models, for unsupervised anomaly segmentation when
only contaminated data is available. Our method outperforms existing
diffusion-based approaches, achieving up to 8.08\% higher AUROC and 10.37\%
higher AUPRC on MVTec datasets. The implementation code is available at:
https://github.com/mehrdadmoradi124/RDDPM

</details>


### [61] [How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes](https://arxiv.org/abs/2508.02905)
*Mahnoor Fatima Saad,Ziad Al-Halah*

Main category: cs.CV

TL;DR: 研究了一种基于用户定义材料配置生成室内声学特性的方法，通过编码器-解码器模型实现高保真房间冲击响应（RIR）的预测，并创建了新数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以预测室内声学特性如何随不同材料配置变化。研究旨在引入并解决“材料控制声学配置文件生成”任务，即根据用户在推理时定义的材料配置，生成目标声学特性。

Method: 提出一种新颖的编码器-解码器方法。该方法从视听观察中编码场景的关键属性，并根据用户指定的材料信息生成目标房间冲击响应（RIR）。为支持此任务，研究者创建了新的基准数据集“Acoustic Wonderland Dataset”。

Result: 所提出的模型能够根据动态定义的各种材料配置生成多样化的RIR。实验结果表明，该模型有效编码了材料信息，生成了高保真RIR，并且性能优于多个基线和现有先进方法。

Conclusion: 该研究成功实现了材料控制的声学特性生成，提供了一个有效的模型和专用的数据集，能够根据用户动态定义的材料配置预测高保真房间冲击响应，为室内声学设计和模拟提供了新的工具和可能性。

Abstract: How would the sound in a studio change with a carpeted floor and acoustic
tiles on the walls? We introduce the task of material-controlled acoustic
profile generation, where, given an indoor scene with specific audio-visual
characteristics, the goal is to generate a target acoustic profile based on a
user-defined material configuration at inference time. We address this task
with a novel encoder-decoder approach that encodes the scene's key properties
from an audio-visual observation and generates the target Room Impulse Response
(RIR) conditioned on the material specifications provided by the user. Our
model enables the generation of diverse RIRs based on various material
configurations defined dynamically at inference time. To support this task, we
create a new benchmark, the Acoustic Wonderland Dataset, designed for
developing and evaluating material-aware RIR prediction methods under diverse
and challenging settings. Our results demonstrate that the proposed model
effectively encodes material information and generates high-fidelity RIRs,
outperforming several baselines and state-of-the-art methods.

</details>


### [62] [Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces](https://arxiv.org/abs/2508.02917)
*Vebjørn Haug Kåsene,Pierre Lison*

Main category: cs.CV

TL;DR: 研究评估了预训练的大型视觉语言模型（LVLMs）在视觉-语言导航（VLN）任务中的适用性，以及其对低级和全景动作空间的支持能力。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言导航（VLN）系统多依赖于专门设计和优化的模型，预训练LVLMs的潜力尚未被充分探索。此外，不确定这些LVLMs能否同时支持低级和全景两种不同的动作范式。

Method: 将开源模型Qwen2.5-VL-3B-Instruct在Room-to-Room（R2R）数据集上进行微调（未进行架构修改或基于模拟器的训练），并在低级和全景动作空间下评估其经验性能。

Result: 最佳模型在R2R测试集上取得了41%的成功率。

Conclusion: 预训练LVLMs能够学习执行视觉-语言导航任务，但其性能仍落后于专门为该任务设计的模型。

Abstract: Vision-and-Language Navigation (VLN) refers to the task of enabling
autonomous robots to navigate unfamiliar environments by following natural
language instructions. While recent Large Vision-Language Models (LVLMs) have
shown promise in this task, most current VLM systems rely on models
specifically designed and optimized for navigation, leaving the potential of
off-the-shelf LVLMs underexplored. Furthermore, while older VLN approaches used
low-level action spaces with egocentric views and atomic actions (such as "turn
left" or "move forward"), newer models tend to favor panoramic action spaces
with discrete navigable viewpoints. This paper investigates (1) whether
off-the-shelf LVLMs (fine-tuned without architectural modifications or
simulator-based training) can effectively support VLN tasks and (2) whether
such models can support both low-level and panoramic action paradigms. To this
end, we fine-tune the open-source model Qwen2.5-VL-3B-Instruct on the
Room-to-Room (R2R) dataset and evaluate its empirical performance across both
low-level and panoramic action spaces. The best resulting model achieves a 41%
success rate on the R2R test set, demonstrating that while off-the-shelf LVLMs
can learn to perform Vision-and-Language Navigation, they still lag behind
models specifically designed for this task.

</details>


### [63] [How Diffusion Prior Landscapes Shape the Posterior in Blind Deconvolution](https://arxiv.org/abs/2508.02923)
*Minh-Hai Nguyen,Edouard Pauwels,Pierre Weiss*

Main category: cs.CV

TL;DR: MAP估计在盲去卷积中易导致模糊结果，本文发现后验分布的局部极小值而非全局最大值才能得到清晰图像，需良好初始化以克服MAP局限。


<details>
  <summary>Details</summary>
Motivation: 最大后验（MAP）估计在盲去卷积中被广泛使用，但与稀疏性先验结合时，它倾向于产生模糊解，限制了其有效性。

Method: 本文利用基于扩散的先验（一类能捕捉真实图像分布的模型），通过实证分析先验的似然景观，并进行盲去卷积后验分布的理论分析。最终通过数值实验验证了分析结果。

Result: 研究发现，在基于扩散的先验中，模糊图像倾向于具有更高的似然性，但似然景观包含众多对应自然图像的局部极小值。理论分析揭示MAP估计倾向于产生锐利滤波器和模糊解。然而，后验分布的局部极小值（可通过梯度下降获得）对应着真实自然的图像，能有效解决盲去卷积问题。

Conclusion: 克服MAP估计的局限性需要对后验景观中的局部极小值进行良好的局部初始化。这些发现对设计改进的先验和优化技术具有指导意义。

Abstract: The Maximum A Posteriori (MAP) estimation is a widely used framework in blind
deconvolution to recover sharp images from blurred observations. The estimated
image and blur filter are defined as the maximizer of the posterior
distribution. However, when paired with sparsity-promoting image priors, MAP
estimation has been shown to favors blurry solutions, limiting its
effectiveness. In this paper, we revisit this result using diffusion-based
priors, a class of models that capture realistic image distributions. Through
an empirical examination of the prior's likelihood landscape, we uncover two
key properties: first, blurry images tend to have higher likelihoods; second,
the landscape contains numerous local minimizers that correspond to natural
images. Building on these insights, we provide a theoretical analysis of the
blind deblurring posterior. This reveals that the MAP estimator tends to
produce sharp filters (close to the Dirac delta function) and blurry solutions.
However local minimizers of the posterior, which can be obtained with gradient
descent, correspond to realistic, natural images, effectively solving the blind
deconvolution problem. Our findings suggest that overcoming MAP's limitations
requires good local initialization to local minima in the posterior landscape.
We validate our analysis with numerical experiments, demonstrating the
practical implications of our insights for designing improved priors and
optimization techniques.

</details>


### [64] [Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?](https://arxiv.org/abs/2508.02927)
*Srikanth Muralidharan,Heitor R. Medeiros,Masih Aminbeidokhti,Eric Granger,Marco Pedersoli*

Main category: cs.CV

TL;DR: 研究ImageNet预训练对超小型模型在红外目标检测中分布外鲁棒性的影响，发现预训练仍有用但收益递减，建议避免过小的模型。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用需要模型在有限硬件的嵌入式设备上运行，同时对不同操作条件和模态具有鲁棒性。尽管预训练对大型模型在准确性和鲁棒性方面益处显著，但其对小型模型（适用于嵌入式和边缘设备）的影响尚不明确。

Method: 研究了ImageNet预训练对参数小于1M的超小型骨干网络在红外视觉模态下游目标检测任务中鲁棒性的影响。利用标准目标识别架构的缩放律构建了两种超小型骨干网络系列，并在三个不同数据集上系统地研究了它们的性能。

Result: 实验结果表明，ImageNet预训练仍然有用，但在超过一定容量阈值后，其在分布外检测鲁棒性方面的收益递减。

Conclusion: 建议从业者仍使用预训练。同时，尽可能避免使用过小的模型，因为它们虽然可能在域内问题上表现良好，但在工作条件不同时会显得脆弱。

Abstract: Many real-world applications require recognition models that are robust to
different operational conditions and modalities, but at the same time run on
small embedded devices, with limited hardware. While for normal size models,
pre-training is known to be very beneficial in accuracy and robustness, for
small models, that can be employed for embedded and edge devices, its effect is
not clear. In this work, we investigate the effect of ImageNet pretraining on
increasingly small backbone architectures (ultra-small models, with $<$1M
parameters) with respect to robustness in downstream object detection tasks in
the infrared visual modality. Using scaling laws derived from standard object
recognition architectures, we construct two ultra-small backbone families and
systematically study their performance. Our experiments on three different
datasets reveal that while ImageNet pre-training is still useful, beyond a
certain capacity threshold, it offers diminishing returns in terms of
out-of-distribution detection robustness. Therefore, we advise practitioners to
still use pre-training and, when possible avoid too small models as while they
might work well for in-domain problems, they are brittle when working
conditions are different.

</details>


### [65] [X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio](https://arxiv.org/abs/2508.02944)
*Chenxu Zhang,Zenan Li,Hongyi Xu,You Xie,Xiaochen Zhao,Tianpei Gu,Guoxian Song,Xin Chen,Chao Liang,Jianwen Jiang,Linjie Luo*

Main category: cs.CV

TL;DR: X-Actor是一个音频驱动的人像动画框架，能从音频和单张图像生成逼真、富有情感的说话头部视频，通过两阶段解耦扩散模型实现长程、富有表现力的面部动作。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注唇部同步和短期视觉保真度，难以捕捉长程、动态演变且与语音内容连贯的情感表达，无法达到“演员级”的肖像表演质量。

Method: 采用两阶段解耦生成流程：1) 音频条件自回归扩散模型，预测长时序上下文窗口内富有表现力且与身份无关的面部动作潜在令牌；2) 基于扩散的视频合成模块，将这些动作转化为高保真视频动画。该方法在紧凑的面部动作潜在空间中操作，通过扩散强制训练范式捕获音频与面部动态的长程关联，实现无限长且情感丰富的运动预测而无误差累积。

Result: X-Actor生成引人入胜、电影风格的表演，超越了标准说话头部动画。在长程、音频驱动的情感肖像表演方面取得了最先进的结果。

Conclusion: X-Actor通过其创新的两阶段解耦扩散方法，成功解决了现有音频驱动人像动画在情感表达和长程连贯性方面的局限，实现了“演员级”的、逼真且情感丰富的长篇说话头部视频生成，代表了该领域的重大进展。

Abstract: We present X-Actor, a novel audio-driven portrait animation framework that
generates lifelike, emotionally expressive talking head videos from a single
reference image and an input audio clip. Unlike prior methods that emphasize
lip synchronization and short-range visual fidelity in constrained speaking
scenarios, X-Actor enables actor-quality, long-form portrait performance
capturing nuanced, dynamically evolving emotions that flow coherently with the
rhythm and content of speech. Central to our approach is a two-stage decoupled
generation pipeline: an audio-conditioned autoregressive diffusion model that
predicts expressive yet identity-agnostic facial motion latent tokens within a
long temporal context window, followed by a diffusion-based video synthesis
module that translates these motions into high-fidelity video animations. By
operating in a compact facial motion latent space decoupled from visual and
identity cues, our autoregressive diffusion model effectively captures
long-range correlations between audio and facial dynamics through a
diffusion-forcing training paradigm, enabling infinite-length emotionally-rich
motion prediction without error accumulation. Extensive experiments demonstrate
that X-Actor produces compelling, cinematic-style performances that go beyond
standard talking head animations and achieves state-of-the-art results in
long-range, audio-driven emotional portrait acting.

</details>


### [66] [Towards Robust Image Denoising with Scale Equivariance](https://arxiv.org/abs/2508.02967)
*Dawei Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 提出一个鲁棒的盲去噪框架，通过引入尺度等变性、异构归一化模块(HNM)和交互门控模块(IGM)，有效解决了图像去噪中分布外(OOD)空间变异噪声的泛化挑战，并超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像去噪模型在处理分布外(OOD)噪声模式，特别是空间变异噪声时，泛化能力不足，存在一个基本但未被充分探索的泛化鸿沟。

Method: 引入尺度等变性作为核心归纳偏置以提高OOD鲁棒性。提出一个鲁棒的盲去噪框架，包含：1. 异构归一化模块(HNM)，用于稳定特征分布并动态校正不同噪声强度下的特征；2. 交互门控模块(IGM)，通过信号和特征路径间的门控交互促进有效信息调制。

Result: 在合成和真实世界基准测试中，尤其是在空间异构噪声条件下，该模型持续优于最先进的去噪方法。

Conclusion: 本工作通过结合尺度等变性与特有的HNM和IGM组件，成功构建了一个对空间异构噪声具有卓越鲁棒性的盲去噪模型，有效弥补了现有模型的泛化能力不足问题。

Abstract: Despite notable advances in image denoising, existing models often struggle
to generalize beyond in-distribution noise patterns, particularly when
confronted with out-of-distribution (OOD) conditions characterized by spatially
variant noise. This generalization gap remains a fundamental yet underexplored
challenge. In this work, we investigate \emph{scale equivariance} as a core
inductive bias for improving OOD robustness. We argue that incorporating
scale-equivariant structures enables models to better adapt from training on
spatially uniform noise to inference on spatially non-uniform degradations.
Building on this insight, we propose a robust blind denoising framework
equipped with two key components: a Heterogeneous Normalization Module (HNM)
and an Interactive Gating Module (IGM). HNM stabilizes feature distributions
and dynamically corrects features under varying noise intensities, while IGM
facilitates effective information modulation via gated interactions between
signal and feature paths. Extensive evaluations demonstrate that our model
consistently outperforms state-of-the-art methods on both synthetic and
real-world benchmarks, especially under spatially heterogeneous noise. Code
will be made publicly available.

</details>


### [67] [Diffusion Models with Adaptive Negative Sampling Without External Resources](https://arxiv.org/abs/2508.02973)
*Alakh Desai,Nuno Vasconcelos*

Main category: cs.CV

TL;DR: 提出一种名为ANSWER的训练无关方法，通过整合负向提示与无分类器指导（CFG），使扩散模型能从单一提示中处理正负条件，无需显式负向提示，显著提高生成图像与文本提示的符合度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成上表现出色，但其提示词遵循性和生成质量存在显著差异。现有的负向提示方法虽能改善依从性，但存在损耗和不完整性。因此，需要一种更有效、准确地提高图像与文本提示（包括否定概念）一致性的方法。

Method: 本文研究了负向提示与无分类器指导（CFG）之间的关系，并在此基础上开发了一种名为“无需外部资源的自适应负采样”（ANSWER）的采样过程。该方法利用扩散模型对否定概念的内部理解，从单个提示中同时处理正面和负面条件，从而无需显式负向提示。ANSWER是一种无需训练的技术，可应用于任何支持CFG的扩散模型。

Result: 实验结果表明，将ANSWER应用于现有扩散模型后，在多个基准测试中均优于现有基线方法。此外，在人工评估中，ANSWER生成的图像比其他方法获得了2倍的偏好。

Conclusion: ANSWER是一种有效、通用且无需训练的采样过程，它能通过利用扩散模型内部的否定理解来显著提高生成图像对文本提示的忠实度，解决了传统负向提示的局限性，并在性能和用户偏好方面取得了显著提升。

Abstract: Diffusion models (DMs) have demonstrated an unparalleled ability to create
diverse and high-fidelity images from text prompts. However, they are also
well-known to vary substantially regarding both prompt adherence and quality.
Negative prompting was introduced to improve prompt compliance by specifying
what an image must not contain. Previous works have shown the existence of an
ideal negative prompt that can maximize the odds of the positive prompt. In
this work, we explore relations between negative prompting and classifier-free
guidance (CFG) to develop a sampling procedure, {\it Adaptive Negative Sampling
Without External Resources} (ANSWER), that accounts for both positive and
negative conditions from a single prompt. This leverages the internal
understanding of negation by the diffusion model to increase the odds of
generating images faithful to the prompt. ANSWER is a training-free technique,
applicable to any model that supports CFG, and allows for negative grounding of
image concepts without an explicit negative prompts, which are lossy and
incomplete. Experiments show that adding ANSWER to existing DMs outperforms the
baselines on multiple benchmarks and is preferred by humans 2x more over the
other methods.

</details>


### [68] [Separating Shared and Domain-Specific LoRAs for Multi-Domain Learning](https://arxiv.org/abs/2508.02978)
*Yusaku Takama,Ning Ding,Tatsuya Yokota,Toru Tamaki*

Main category: cs.CV

TL;DR: 提出一种基于子空间隔离的多领域学习方法，以更好地区分共享和领域特有LoRA。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA（低秩适应）在多领域学习中包含共享和领域特有适配器，但其能否有效捕获领域特有信息尚不明确。

Method: 本研究提出一种新方法，确保共享LoRA和领域特有LoRA分别存在于预训练权重的列空间和左零空间中，从而实现它们在不同子空间中的隔离。

Result: 将所提方法应用于动作识别任务，并在UCF101、Kinetics400和HMDB51三个数据集上进行了实验。结果表明，在某些情况下，该方法是有效的，并且还对LoRA权重的维度进行了分析。

Conclusion: 通过将共享和领域特有LoRA强制分离到不同的子空间，可以提高多领域学习中领域信息捕获的有效性，为多领域适配器设计提供了新的视角。

Abstract: Existing architectures of multi-domain learning have two types of adapters:
shared LoRA for all domains and domain-specific LoRA for each particular
domain. However, it remains unclear whether this structure effectively captures
domain-specific information. In this paper, we propose a method that ensures
that shared and domain-specific LoRAs exist in different subspaces;
specifically, the column and left null subspaces of the pre-trained weights. We
apply the proposed method to action recognition with three datasets (UCF101,
Kinetics400, and HMDB51) and demonstrate its effectiveness in some cases along
with the analysis of the dimensions of LoRA weights.

</details>


### [69] [MoExDA: Domain Adaptation for Edge-based Action Recognition](https://arxiv.org/abs/2508.02981)
*Takuya Sugimoto,Ning Ding,Toru Tamaki*

Main category: cs.CV

TL;DR: 针对动作识别模型静态偏差问题，本文提出MoExDA，一种利用RGB和边缘信息进行轻量级域适应的方法，有效提升了动作识别的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现代动作识别模型存在静态偏差，导致泛化性能下降，限制了其应用。

Method: 提出MoExDA，一种轻量级的域适应方法，该方法在RGB帧的基础上，额外利用边缘帧信息进行RGB与边缘信息间的域适应，以对抗静态偏差。

Result: 实验结果表明，所提出的MoExDA方法能有效抑制静态偏差，具有较低的计算成本，并实现了比现有方法更鲁棒的动作识别性能。

Conclusion: MoExDA成功解决了动作识别中的静态偏差问题，显著提升了模型的鲁棒性与泛化能力，同时降低了计算开销。

Abstract: Modern action recognition models suffer from static bias, leading to reduced
generalization performance. In this paper, we propose MoExDA, a lightweight
domain adaptation between RGB and edge information using edge frames in
addition to RGB frames to counter the static bias issue. Experiments
demonstrate that the proposed method effectively suppresses static bias with a
lower computational cost, allowing for more robust action recognition than
previous approaches.

</details>


### [70] [Adversarial Attention Perturbations for Large Object Detection Transformers](https://arxiv.org/abs/2508.02987)
*Zachary Yahn,Selim Furkan Tekin,Fatih Ilhan,Sihao Hu,Tiansheng Huang,Yichang Xu,Margaret Loper,Ling Liu*

Main category: cs.CV

TL;DR: 提出一种名为AFOG的新型注意力聚焦对抗攻击，能够高效且隐蔽地攻击基于Transformer和CNN的目标检测器。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测对抗攻击方法对基于CNN的检测器有效，但对基于Transformer的检测器效果有限或较弱，无法普适。

Method: 提出了“注意力聚焦攻击梯度（AFOG）”方法，该方法与神经网络架构无关，可统一攻击Transformer和CNN检测器。AFOG利用可学习的注意力机制将扰动集中于图像的脆弱区域，并整合两种特征损失通过可学习注意力更新和迭代扰动注入来构建攻击损失。它能生成策略性且视觉上不可察觉的扰动。

Result: AFOG将攻击性能相较于非注意力基线提升高达30.6%。在COCO数据集上对12个大型检测Transformer进行的广泛实验证明了AFOG的有效性。实验结果表明，AFOG在攻击Transformer和CNN检测器方面，性能优于现有攻击高达83%，且速度更快，隐蔽性更佳。

Conclusion: AFOG是一种高效、隐蔽且普适的对抗攻击方法，能有效发现并利用基于Transformer和CNN的目标检测模型的脆弱点，为未来模型鲁棒性研究提供重要工具。

Abstract: Adversarial perturbations are useful tools for exposing vulnerabilities in
neural networks. Existing adversarial perturbation methods for object detection
are either limited to attacking CNN-based detectors or weak against
transformer-based detectors. This paper presents an Attention-Focused Offensive
Gradient (AFOG) attack against object detection transformers. By design, AFOG
is neural-architecture agnostic and effective for attacking both large
transformer-based object detectors and conventional CNN-based detectors with a
unified adversarial attention framework. This paper makes three original
contributions. First, AFOG utilizes a learnable attention mechanism that
focuses perturbations on vulnerable image regions in multi-box detection tasks,
increasing performance over non-attention baselines by up to 30.6%. Second,
AFOG's attack loss is formulated by integrating two types of feature loss
through learnable attention updates with iterative injection of adversarial
perturbations. Finally, AFOG is an efficient and stealthy adversarial
perturbation method. It probes the weak spots of detection transformers by
adding strategically generated and visually imperceptible perturbations which
can cause well-trained object detection models to fail. Extensive experiments
conducted with twelve large detection transformers on COCO demonstrate the
efficacy of AFOG. Our empirical results also show that AFOG outperforms
existing attacks on transformer-based and CNN-based object detectors by up to
83% with superior speed and imperceptibility. Code is available at
https://github.com/zacharyyahn/AFOG.

</details>


### [71] [Seeing It Before It Happens: In-Generation NSFW Detection for Diffusion-Based Text-to-Image Models](https://arxiv.org/abs/2508.03006)
*Fan Yang,Yihao Huang,Jiayi Zhu,Ling Shi,Geguang Pu,Jin Song Dong,Kailong Wang*

Main category: cs.CV

TL;DR: 本文提出一种名为IGD的生成中检测方法，通过利用文本到图像扩散模型中预测噪声作为内部信号来识别NSFW内容，在多种NSFW类别上取得了91.32%的平均检测准确率，并优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成文本到图像（T2I）内容存在生成不安全（NSFW）内容的滥用风险。现有检测方法多集中于生成前过滤或生成后审核，而扩散模型在“生成中”阶段的NSFW检测鲜有研究。初步发现预测噪声可能包含区分NSFW与良性提示的语义线索，即使是面对对抗性提示。

Method: 提出“生成中检测（In-Generation Detection, IGD）”方法。该方法利用扩散过程中模型预测的噪声作为内部信号来识别NSFW内容。

Result: 实验结果显示，IGD在七种NSFW类别上，对朴素和对抗性NSFW提示的平均检测准确率达到91.32%，并优于七种基线方法。

Conclusion: IGD是一种简单而有效的生成中NSFW内容检测方法，通过利用扩散模型的内部信号，能够准确识别NSFW内容，并在性能上超越现有方法，为解决T2I模型的滥用风险提供了新思路。

Abstract: Diffusion-based text-to-image (T2I) models enable high-quality image
generation but also pose significant risks of misuse, particularly in producing
not-safe-for-work (NSFW) content. While prior detection methods have focused on
filtering prompts before generation or moderating images afterward, the
in-generation phase of diffusion models remains largely unexplored for NSFW
detection. In this paper, we introduce In-Generation Detection (IGD), a simple
yet effective approach that leverages the predicted noise during the diffusion
process as an internal signal to identify NSFW content. This approach is
motivated by preliminary findings suggesting that the predicted noise may
capture semantic cues that differentiate NSFW from benign prompts, even when
the prompts are adversarially crafted. Experiments conducted on seven NSFW
categories show that IGD achieves an average detection accuracy of 91.32% over
naive and adversarial NSFW prompts, outperforming seven baseline methods.

</details>


### [72] [Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.03007)
*Xinhui Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: 本文提出MGFC框架，通过多粒度特征校准（从粗到细）来增强视觉基础模型在域泛化语义分割中的鲁棒性，有效提升了性能。


<details>
  <summary>Details</summary>
Motivation: 域泛化语义分割（DGSS）旨在使模型在未知领域具有泛化能力。虽然现有方法利用视觉基础模型（VFMs）进行参数高效微调，但它们大多关注全局特征微调，忽视了对精确密集预测至关重要的跨特征层级的层次适应。

Method: 本文提出多粒度特征校准（MGFC）框架，通过粗到细的VFM特征对齐来增强领域迁移下的鲁棒性。具体地，MGFC首先校准粗粒度特征以捕获全局上下文和场景级结构；接着，通过促进类别级特征判别性来精炼中粒度特征；最后，通过高频空间细节增强来校准细粒度特征。

Result: 在基准数据集上的大量实验表明，MGFC方法优于现有最先进的DGSS方法。

Conclusion: 通过层次化和粒度感知的校准，MGFC有效将VFM的泛化能力转移到DGSS的特定任务中，凸显了多粒度适应对域泛化语义分割任务的有效性。

Abstract: Domain Generalized Semantic Segmentation (DGSS) aims to improve the
generalization ability of models across unseen domains without access to target
data during training. Recent advances in DGSS have increasingly exploited
vision foundation models (VFMs) via parameter-efficient fine-tuning strategies.
However, most existing approaches concentrate on global feature fine-tuning,
while overlooking hierarchical adaptation across feature levels, which is
crucial for precise dense prediction. In this paper, we propose
Multi-Granularity Feature Calibration (MGFC), a novel framework that performs
coarse-to-fine alignment of VFM features to enhance robustness under domain
shifts. Specifically, MGFC first calibrates coarse-grained features to capture
global contextual semantics and scene-level structure. Then, it refines
medium-grained features by promoting category-level feature discriminability.
Finally, fine-grained features are calibrated through high-frequency spatial
detail enhancement. By performing hierarchical and granularity-aware
calibration, MGFC effectively transfers the generalization strengths of VFMs to
the domain-specific task of DGSS. Extensive experiments on benchmark datasets
demonstrate that our method outperforms state-of-the-art DGSS approaches,
highlighting the effectiveness of multi-granularity adaptation for the semantic
segmentation task of domain generalization.

</details>


### [73] [Enhancing Long Video Question Answering with Scene-Localized Frame Grouping](https://arxiv.org/abs/2508.03009)
*Xuyi Yang,Wenhao Zhang,Hongbo Jin,Lin Liu,Hongbo Xu,Yongwei Nie,Fei Yu,Fei Ma*

Main category: cs.CV

TL;DR: 针对多模态大语言模型（MLLMs）在长视频理解中信息提取效率低的问题，本文提出强调场景细节感知的SceneQA任务、LVSQA数据集，并引入SLFG方法，通过将视频帧组合成语义连贯的场景帧，显著提升了MLLMs的长视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在长视频理解上表现不佳，主要受限于资源难以处理所有视频帧及高效提取信息。此外，现有框架和评估任务侧重识别特定核心对象帧，与实际应用场景不符。

Method: 1. 提出新的视频问答场景SceneQA，强调基于场景的细节感知和推理能力。 2. 开发LVSQA数据集以支持SceneQA任务。 3. 引入SLFG方法，受人类认知启发，其核心是将独立帧组合成语义连贯的场景帧，通过场景定位和动态帧重组机制实现，且无需修改原有模型架构，具备即插即用性。

Result: 实验结果表明，SLFG方法在多个长视频基准测试中表现出色，显著增强了现有MLLMs的长视频理解能力。

Conclusion: SLFG方法通过创新的场景帧组合策略，有效解决了MLLMs在长视频中处理效率和理解能力不足的问题，显著提升了其性能，并为未来长视频理解任务提供了更符合实际需求的评估方向和高效解决方案。

Abstract: Current Multimodal Large Language Models (MLLMs) often perform poorly in long
video understanding, primarily due to resource limitations that prevent them
from processing all video frames and their associated information. Efficiently
extracting relevant information becomes a challenging task. Existing frameworks
and evaluation tasks focus on identifying specific frames containing core
objects from a large number of irrelevant frames, which does not align with the
practical needs of real-world applications. To address this issue, we propose a
new scenario under the video question-answering task, SceneQA, which emphasizes
scene-based detail perception and reasoning abilities. And we develop the LVSQA
dataset to support the SceneQA task, which is built upon carefully selected
videos from LVBench and contains a new collection of question-answer pairs to
promote a more fair evaluation of MLLMs' scene perception abilities in long
videos. Inspired by human cognition, we introduce a novel method called SLFG.
The core idea of SLFG is to combine individual frames into semantically
coherent scene frames. By leveraging scene localization methods and dynamic
frame reassembly mechanisms, SLFG significantly enhances the understanding
capabilities of existing MLLMs in long videos. SLFG requires no modification to
the original model architecture and boasts excellent plug-and-play usability.
Experimental results show that this method performs exceptionally well in
several long video benchmark tests. Code and dataset will be released at
http://www.slfg.pkuzwh.cn.

</details>


### [74] [SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting](https://arxiv.org/abs/2508.03017)
*Liheng Zhang,Weihao Yu,Zubo Lu,Haozhi Gu,Jin Huang*

Main category: cs.CV

TL;DR: SA-3DGS旨在解决3D Gaussian Splatting存储需求过大的问题。该方法通过学习重要性分数进行剪枝、重要性感知聚类进行压缩以及码本修复，实现了高达66倍的压缩比，同时保持或提升了渲染质量，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS) 在新颖视角合成中表现出色，但其场景表示需要大量高斯点，导致存储需求高，限制了实际部署。现有压缩方法在识别不重要高斯点方面存在不足，导致剪枝和压缩质量下降，影响渲染性能。

Method: SA-3DGS提出三阶段方法：1) 学习高斯点的重要性分数，识别并剪枝不重要的高斯点，减少冗余；2) 采用重要性感知聚类模块，将高斯属性更精确地压缩到码本中，提升码本表达力并减小模型；3) 利用码本修复模块，基于上下文信息修复码本，恢复高斯属性，弥补信息损失造成的渲染质量下降。

Result: 实验结果表明，SA-3DGS在保持或提升渲染质量的同时，实现了高达66倍的模型压缩。此外，其高斯剪枝方法可兼容并提升其他基于剪枝的方法（如LightGaussian），展示出优异的性能和强大的泛化能力。

Conclusion: SA-3DGS通过创新的剪枝、压缩和修复策略，有效解决了3D Gaussian Splatting模型存储开销大的核心问题。该方法在大幅压缩模型的同时，保持甚至提升了渲染质量，并具有出色的泛化性，为3DGS的实际应用提供了关键支持。

Abstract: Recent advancements in 3D Gaussian Splatting have enhanced efficient and
high-quality novel view synthesis. However, representing scenes requires a
large number of Gaussian points, leading to high storage demands and limiting
practical deployment. The latest methods facilitate the compression of Gaussian
models but struggle to identify truly insignificant Gaussian points in the
scene, leading to a decline in subsequent Gaussian pruning, compression
quality, and rendering performance. To address this issue, we propose SA-3DGS,
a method that significantly reduces storage costs while maintaining rendering
quality. SA-3DGS learns an importance score to automatically identify the least
significant Gaussians in scene reconstruction, thereby enabling effective
pruning and redundancy reduction. Next, the importance-aware clustering module
compresses Gaussians attributes more accurately into the codebook, improving
the codebook's expressive capability while reducing model size. Finally, the
codebook repair module leverages contextual scene information to repair the
codebook, thereby recovering the original Gaussian point attributes and
mitigating the degradation in rendering quality caused by information loss.
Experimental results on several benchmark datasets show that our method
achieves up to 66x compression while maintaining or even improving rendering
quality. The proposed Gaussian pruning approach is not only adaptable to but
also improves other pruning-based methods (e.g., LightGaussian), showcasing
excellent performance and strong generalization ability.

</details>


### [75] [MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention](https://arxiv.org/abs/2508.03034)
*Qi Xie,Yongjia Ma,Donglin Di,Xuehao Gao,Xun Yang*

Main category: cs.CV

TL;DR: 提出MoCA模型，一个基于Diffusion Transformer的视频扩散模型，通过混合交叉注意力机制和新的感知损失，显著提升了文本到视频生成中人物身份的保持和细节一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型取得进展，但ID保持的文本到视频（T2V）生成仍具挑战。现有方法常无法捕捉精细面部动态或保持时间上的身份连贯性。

Method: 提出了MoCA，一个基于Diffusion Transformer（DiT）骨干的新型视频扩散模型，引入了受MoE启发的混合交叉注意力（MoCA）机制。该框架通过在每个DiT块中嵌入MoCA层（包含分层时间池化和时间感知交叉注意力专家）来提高帧间身份一致性。同时，结合潜在视频感知损失（Latent Video Perceptual Loss）以增强身份连贯性和细节。为训练模型，构建了CelebIPVid数据集（10,000个高分辨率视频，来自1,000个个体）。

Result: 在CelebIPVid数据集上进行的大量实验表明，MoCA在面部相似度方面比现有T2V方法高出5%以上。

Conclusion: MoCA模型有效解决了文本到视频生成中身份保持和时间连贯性的挑战，其性能优于现有方法，并促进了跨种族的泛化能力。

Abstract: Achieving ID-preserving text-to-video (T2V) generation remains challenging
despite recent advances in diffusion-based models. Existing approaches often
fail to capture fine-grained facial dynamics or maintain temporal identity
coherence. To address these limitations, we propose MoCA, a novel Video
Diffusion Model built on a Diffusion Transformer (DiT) backbone, incorporating
a Mixture of Cross-Attention mechanism inspired by the Mixture-of-Experts
paradigm. Our framework improves inter-frame identity consistency by embedding
MoCA layers into each DiT block, where Hierarchical Temporal Pooling captures
identity features over varying timescales, and Temporal-Aware Cross-Attention
Experts dynamically model spatiotemporal relationships. We further incorporate
a Latent Video Perceptual Loss to enhance identity coherence and fine-grained
details across video frames. To train this model, we collect CelebIPVid, a
dataset of 10,000 high-resolution videos from 1,000 diverse individuals,
promoting cross-ethnicity generalization. Extensive experiments on CelebIPVid
show that MoCA outperforms existing T2V methods by over 5% across Face
similarity.

</details>


### [76] [VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering](https://arxiv.org/abs/2508.03039)
*Yiran Meng,Junhong Ye,Wei Zhou,Guanghui Yue,Xudong Mao,Ruomei Wang,Baoquan Zhao*

Main category: cs.CV

TL;DR: 本文提出VideoForest框架，通过以人物为中心的层次化推理，解决跨视频问答中多源信息整合和视频间关联的挑战，并取得显著优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的单视频理解无法有效处理跨视频问答中的挑战，特别是难以在不同视频流之间建立有意义的连接，并管理多源信息检索的复杂性。

Method: 引入VideoForest框架，通过以人物特征作为视频间桥梁，实现无需端到端训练的跨视频理解。核心创新包括：1) 基于ReID和追踪算法的人锚定特征提取机制；2) 围绕人物轨迹构建的多粒度生成树结构；3) 用于高效遍历层级结构的多智能体推理框架。为评估模型，还构建了专门用于人物中心跨视频分析的CrossVideoQA基准数据集。

Result: VideoForest在跨视频推理任务中表现出色，人物识别准确率达71.93%，行为分析准确率达83.75%，总结与推理准确率达51.67%，显著优于现有方法。

Conclusion: 该工作通过统一多视频流中的人物级特征，为跨视频理解建立了新范式，实现了对分布式视觉信息的复杂推理，同时保持了计算效率。

Abstract: Cross-video question answering presents significant challenges beyond
traditional single-video understanding, particularly in establishing meaningful
connections across video streams and managing the complexity of multi-source
information retrieval. We introduce VideoForest, a novel framework that
addresses these challenges through person-anchored hierarchical reasoning. Our
approach leverages person-level features as natural bridge points between
videos, enabling effective cross-video understanding without requiring
end-to-end training. VideoForest integrates three key innovations: 1) a
human-anchored feature extraction mechanism that employs ReID and tracking
algorithms to establish robust spatiotemporal relationships across multiple
video sources; 2) a multi-granularity spanning tree structure that
hierarchically organizes visual content around person-level trajectories; and
3) a multi-agent reasoning framework that efficiently traverses this
hierarchical structure to answer complex cross-video queries. To evaluate our
approach, we develop CrossVideoQA, a comprehensive benchmark dataset
specifically designed for person-centric cross-video analysis. Experimental
results demonstrate VideoForest's superior performance in cross-video reasoning
tasks, achieving 71.93% accuracy in person recognition, 83.75% in behavior
analysis, and 51.67% in summarization and reasoning, significantly
outperforming existing methods. Our work establishes a new paradigm for
cross-video understanding by unifying multiple video streams through
person-level features, enabling sophisticated reasoning across distributed
visual information while maintaining computational efficiency.

</details>


### [77] [Multi-human Interactive Talking Dataset](https://arxiv.org/abs/2508.03050)
*Zeyu Zhu,Weijia Wu,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 本文介绍了MIT，一个用于多人对话视频生成的大规模数据集，以及CovOG，一个用于此任务的基线模型，旨在填补现有研究在真实多人互动方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有对话视频生成研究主要集中在单人独白或孤立的面部动画，限制了其在真实多人互动场景中的应用。为了弥补这一空白，需要一个专门针对多人对话视频生成的数据集和方法。

Method: 研究开发了一个自动化流程来收集和标注多人物对话视频，从而构建了MIT数据集。为了演示MIT的潜力，进一步提出了CovOG基线模型，该模型整合了多人物姿态编码器（MPE）来处理可变数量的说话者，并通过聚合个体姿态嵌入；还集成了交互式音频驱动器（IAD），根据特定说话者的音频特征调节头部动态。

Result: MIT数据集包含12小时的高分辨率视频，每个视频有2到4名说话者，并带有精细的身体姿态和语音交互标注，捕捉了多说话者场景中的自然对话动态。CovOG模型展示了生成真实多人对话视频的可行性和挑战，确立了MIT作为未来研究的宝贵基准。

Conclusion: MIT数据集为研究互动视觉行为提供了丰富的资源，并作为未来多人对话视频生成研究的宝贵基准。CovOG基线模型证明了这一新任务的可行性，为该领域未来的发展奠定了基础。

Abstract: Existing studies on talking video generation have predominantly focused on
single-person monologues or isolated facial animations, limiting their
applicability to realistic multi-human interactions. To bridge this gap, we
introduce MIT, a large-scale dataset specifically designed for multi-human
talking video generation. To this end, we develop an automatic pipeline that
collects and annotates multi-person conversational videos. The resulting
dataset comprises 12 hours of high-resolution footage, each featuring two to
four speakers, with fine-grained annotations of body poses and speech
interactions. It captures natural conversational dynamics in multi-speaker
scenario, offering a rich resource for studying interactive visual behaviors.
To demonstrate the potential of MIT, we furthur propose CovOG, a baseline model
for this novel task. It integrates a Multi-Human Pose Encoder (MPE) to handle
varying numbers of speakers by aggregating individual pose embeddings, and an
Interactive Audio Driver (IAD) to modulate head dynamics based on
speaker-specific audio features. Together, these components showcase the
feasibility and challenges of generating realistic multi-human talking videos,
establishing MIT as a valuable benchmark for future research. The code is
avalibale at: https://github.com/showlab/Multi-human-Talking-Video-Dataset.

</details>


### [78] [Uncertainty-Guided Face Matting for Occlusion-Aware Face Transformation](https://arxiv.org/abs/2508.03055)
*Hyebin Cho,Jaehyup Lee*

Main category: cs.CV

TL;DR: 本文提出一种名为“面部抠图”的新任务，旨在解决面部滤镜在面部遮挡（如手、头发）情况下性能下降的问题。为此，作者开发了FaceMat框架，一个免Trimap且感知不确定性的模型，通过师生模型训练和新构建的CelebAMat数据集，显著提升了面部滤镜在复杂遮挡环境下的表现和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有面部滤镜在面对遮挡物（如手、头发、配饰）时，性能会显著下降，影响视觉效果。为提升面部滤镜在短视频内容中的性能和鲁棒性，需要一种方法来精确分离遮挡物与面部区域。

Method: 引入“面部抠图”任务，旨在估计细粒度的Alpha蒙版以分离遮挡元素和面部区域。提出FaceMat框架，该框架无需Trimap且感知不确定性，包含两阶段训练流程：教师模型通过负对数似然(NLL)损失联合估计Alpha蒙版和像素级不确定性；学生模型利用此不确定性通过空间自适应知识蒸馏进行指导，使其专注于模糊或遮挡区域。此外，重新定义抠图目标，将皮肤视为前景，遮挡物视为背景，并构建了大型合成数据集CelebAMat以支持此任务。

Result: FaceMat能在复杂遮挡下预测高质量的Alpha蒙版，有效提升了泛化能力并保持了语义一致性。实验结果表明，FaceMat在多个基准测试中优于现有最先进的方法，显著增强了面部滤镜在真实、无约束视频场景下的视觉质量和鲁棒性。

Conclusion: FaceMat框架及其提出的面部抠图任务，通过创新的不确定性感知训练和专用数据集，成功解决了面部滤镜在遮挡情况下的性能问题。该方法为实时应用提供了高效解决方案，并为面部滤镜的鲁棒性和视觉质量设定了新标准。

Abstract: Face filters have become a key element of short-form video content, enabling
a wide array of visual effects such as stylization and face swapping. However,
their performance often degrades in the presence of occlusions, where objects
like hands, hair, or accessories obscure the face. To address this limitation,
we introduce the novel task of face matting, which estimates fine-grained alpha
mattes to separate occluding elements from facial regions. We further present
FaceMat, a trimap-free, uncertainty-aware framework that predicts high-quality
alpha mattes under complex occlusions. Our approach leverages a two-stage
training pipeline: a teacher model is trained to jointly estimate alpha mattes
and per-pixel uncertainty using a negative log-likelihood (NLL) loss, and this
uncertainty is then used to guide the student model through spatially adaptive
knowledge distillation. This formulation enables the student to focus on
ambiguous or occluded regions, improving generalization and preserving semantic
consistency. Unlike previous approaches that rely on trimaps or segmentation
masks, our framework requires no auxiliary inputs making it well-suited for
real-time applications. In addition, we reformulate the matting objective by
explicitly treating skin as foreground and occlusions as background, enabling
clearer compositing strategies. To support this task, we newly constructed
CelebAMat, a large-scale synthetic dataset specifically designed for
occlusion-aware face matting. Extensive experiments show that FaceMat
outperforms state-of-the-art methods across multiple benchmarks, enhancing the
visual quality and robustness of face filters in real-world, unconstrained
video scenarios. The source code and CelebAMat dataset are available at
https://github.com/hyebin-c/FaceMat.git

</details>


### [79] [CHARM: Collaborative Harmonization across Arbitrary Modalities for Modality-agnostic Semantic Segmentation](https://arxiv.org/abs/2508.03060)
*Lekang Wen,Jing Xiao,Liang Liao,Jiajun Chen,Mi Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CHARM的互补学习框架，用于模态无关语义分割(MaSS)。CHARM通过互感知单元(MPU)实现隐式模态对齐，并采用双路径优化策略，旨在实现模态之间的协同协调而非同质化，从而保留并利用各模态的独特性和互补性。


<details>
  <summary>Details</summary>
Motivation: 现有的模态无关语义分割方法通常依赖显式特征对齐来实现模态同质化，但这会削弱各模态的独特优势并破坏其固有的互补性。研究动机在于开发一种能够实现“协同协调”而非同质化的方法，以在保留模态特有优势的同时进行内容对齐。

Method: 本文提出了CHARM框架，包含两个核心组件：1) 互感知单元(MPU)，通过基于窗口的跨模态交互实现隐式对齐，其中模态既作为查询也作为上下文，以发现模态间对应关系；2) 双路径优化策略，将训练解耦为协作学习策略(CoL)用于互补融合学习，以及个体增强策略(InE)用于保护模态特异性优化。

Result: 在多个数据集和骨干网络上的实验结果表明，CHARM持续优于现有基线方法，尤其在处理脆弱模态时表现出显著的性能提升。

Conclusion: 该工作将研究焦点从模型同质化转向了协调化，通过实现跨模态互补性，从而达到真正的多样性中的和谐，为模态无关语义分割提供了新的视角和有效方法。

Abstract: Modality-agnostic Semantic Segmentation (MaSS) aims to achieve robust scene
understanding across arbitrary combinations of input modality. Existing methods
typically rely on explicit feature alignment to achieve modal homogenization,
which dilutes the distinctive strengths of each modality and destroys their
inherent complementarity. To achieve cooperative harmonization rather than
homogenization, we propose CHARM, a novel complementary learning framework
designed to implicitly align content while preserving modality-specific
advantages through two components: (1) Mutual Perception Unit (MPU), enabling
implicit alignment through window-based cross-modal interaction, where
modalities serve as both queries and contexts for each other to discover
modality-interactive correspondences; (2) A dual-path optimization strategy
that decouples training into Collaborative Learning Strategy (CoL) for
complementary fusion learning and Individual Enhancement Strategy (InE) for
protected modality-specific optimization. Experiments across multiple datasets
and backbones indicate that CHARM consistently outperform the baselines, with
significant increment on the fragile modalities. This work shifts the focus
from model homogenization to harmonization, enabling cross-modal
complementarity for true harmony in diversity.

</details>


### [80] [CORE-ReID: Comprehensive Optimization and Refinement through Ensemble fusion in Domain Adaptation for person re-identification](https://arxiv.org/abs/2508.03064)
*Trinh Quoc Nguyen,Oky Dicky Ardiansyah Prima,Katsuyoshi Hotta*

Main category: cs.CV

TL;DR: 本研究提出CORE-ReID框架，通过CycleGAN数据生成、教师-学生网络结合多级聚类生成伪标签以及可学习的集成融合组件，有效解决了行人重识别中的无监督域适应问题，并在多项任务上取得了显著优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决行人重识别（Person Re-identification, ReID）中的无监督域适应（Unsupervised Domain Adaptation, UDA）问题。

Method: 该研究引入了“全面优化与通过集成融合在域适应中进行行人重识别精炼（CORE-ReID）”框架。在预训练阶段，利用CycleGAN生成多样化数据以协调不同摄像头源的图像特征差异。在微调阶段，基于教师-学生网络，整合多视角特征进行多级聚类以生成多样伪标签。此外，引入了一个可学习的集成融合组件，该组件关注全局特征中的细粒度局部信息，以增强学习全面性并避免多伪标签带来的歧义。框架还通过高效通道注意力块（ECA Block）和双向均值特征归一化等增强，以及基于ResNet模型自适应融合全局和局部特征，进一步强化其性能。

Result: 在三种常见的行人重识别UDA任务上，CORE-ReID框架展示了相比现有最先进方法显著的性能提升。它在Mean Average Precision (mAP)、Top-1、Top-5和Top-10等指标上均实现了高准确率。

Conclusion: 所提出的CORE-ReID框架能够确保融合特征的清晰度，避免歧义，并在行人重识别的无监督域适应任务中被定位为一个先进且有效的解决方案。

Abstract: This study introduces a novel framework, "Comprehensive Optimization and
Refinement through Ensemble Fusion in Domain Adaptation for Person
Re-identification (CORE-ReID)", to address an Unsupervised Domain Adaptation
(UDA) for Person Re-identification (ReID). The framework utilizes CycleGAN to
generate diverse data that harmonizes differences in image characteristics from
different camera sources in the pre-training stage. In the fine-tuning stage,
based on a pair of teacher-student networks, the framework integrates
multi-view features for multi-level clustering to derive diverse pseudo labels.
A learnable Ensemble Fusion component that focuses on fine-grained local
information within global features is introduced to enhance learning
comprehensiveness and avoid ambiguity associated with multiple pseudo-labels.
Experimental results on three common UDAs in Person ReID demonstrate
significant performance gains over state-of-the-art approaches. Additional
enhancements, such as Efficient Channel Attention Block and Bidirectional Mean
Feature Normalization mitigate deviation effects and adaptive fusion of global
and local features using the ResNet-based model, further strengthening the
framework. The proposed framework ensures clarity in fusion features, avoids
ambiguity, and achieves high ac-curacy in terms of Mean Average Precision,
Top-1, Top-5, and Top-10, positioning it as an advanced and effective solution
for the UDA in Person ReID. Our codes and models are available at
https://github.com/TrinhQuocNguyen/CORE-ReID.

</details>


### [81] [SSFMamba: Symmetry-driven Spatial-Frequency Feature Fusion for 3D Medical Image Segmentation](https://arxiv.org/abs/2508.03069)
*Bo Zhang,Yifan Zhang,Shuo Yan,Yu Bai,Zheng Zhang,Wu Liu,Xiuzhuang Zhou,Wendong Wang*

Main category: cs.CV

TL;DR: SSFMamba是一个基于Mamba的空间-频率特征融合网络，通过双分支架构和新的扫描机制，有效融合空间和频率域信息，解决3D医学图像分割中全局上下文建模问题，并在多个数据集上取得超越现有技术水平的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D医学图像分割的空间域方法在建模全局上下文方面存在局限性。新兴的频率域方法虽然有所帮助，但通常忽略频率域的独特属性（如共轭对称性）以及与空间域的数据分布差异，导致频率域的互补优势未能充分发挥或被掩盖。

Method: 提出SSFMamba网络，该网络采用互补的双分支架构，分别从空间域和频率域提取特征。它利用Mamba模块融合这些异构特征，以同时保留全局上下文并增强局部细节。在频率域分支中，结合Mamba出色的全局上下文提取能力和频率域特征的协同效应，进一步增强全局建模。此外，设计了一个3D多向扫描机制，以加强局部和全局信息的融合。

Result: 在BraTS2020和BraTS2023数据集上进行的广泛实验表明，SSFMamba在各项评估指标上均持续优于现有最先进的方法。

Conclusion: SSFMamba通过创新性地融合空间域和频率域特征，并有效利用Mamba结构和多向扫描机制，成功解决了3D医学图像分割中全局上下文建模的挑战，显著提升了分割性能。

Abstract: In light of the spatial domain's limited capacity for modeling global context
in 3D medical image segmentation, emerging approaches have begun to incorporate
frequency domain representations. However, straightforward feature extraction
strategies often overlook the unique properties of frequency domain
information, such as conjugate symmetry. They also fail to account for the
fundamental differences in data distribution between the spatial and frequency
domains, which can ultimately dilute or obscure the complementary strengths
that frequency-based representations offer. In this paper, we propose SSFMamba,
a Mamba based Symmetry-driven Spatial-Frequency feature fusion network for 3D
medical image segmentation. SSFMamba employs a complementary dual-branch
architecture that extracts features from both the spatial and frequency
domains, and leverages a Mamba block to fuse these heterogeneous features to
preserve global context while reinforcing local details. In the frequency
domain branch, we harness Mamba's exceptional capability to extract global
contextual information in conjunction with the synergistic effect of frequency
domain features to further enhance global modeling. Moreover, we design a 3D
multi-directional scanning mechanism to strengthen the fusion of local and
global cues. Extensive experiments on the BraTS2020 and BraTS2023 datasets
demonstrate that our approach consistently outperforms state-of-the-art methods
across various evaluation metrics.

</details>


### [82] [RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions](https://arxiv.org/abs/2508.03077)
*Anran Wu,Long Peng,Xin Di,Xueyuan Dai,Chen Wu,Yang Wang,Xueyang Fu,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出RobustGS，一个多视图特征增强模块，旨在提升前向3D Gaussian Splatting（3DGS）在恶劣成像条件下的鲁棒性，实现高质量3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有前向3DGS方法假设输入多视图图像是干净且高质量的，但在真实世界中，图像常受噪声、低光或雨水等影响，导致3D重建几何不准确和质量下降。

Method: 提出通用且高效的多视图特征增强模块RobustGS，可即插即用集成到现有预训练流程中。它包含：1) 广义退化学习器，用于从多视图输入中提取通用退化表示和分布；2) 语义感知状态空间模型，首先利用退化表示增强特征空间中受损的输入，然后采用语义感知策略聚合跨视图的语义相似信息，以提取精细的跨视图对应关系。

Result: 广泛实验证明，将RobustGS集成到现有方法后，在各种退化类型下均能持续实现最先进的重建质量。

Conclusion: RobustGS通过其创新的模块设计，有效解决了前向3DGS在真实世界恶劣成像条件下的鲁棒性问题，为高质量3D重建提供了一个通用、高效且可插拔的解决方案。

Abstract: Feedforward 3D Gaussian Splatting (3DGS) overcomes the limitations of
optimization-based 3DGS by enabling fast and high-quality reconstruction
without the need for per-scene optimization. However, existing feedforward
approaches typically assume that input multi-view images are clean and
high-quality. In real-world scenarios, images are often captured under
challenging conditions such as noise, low light, or rain, resulting in
inaccurate geometry and degraded 3D reconstruction. To address these
challenges, we propose a general and efficient multi-view feature enhancement
module, RobustGS, which substantially improves the robustness of feedforward
3DGS methods under various adverse imaging conditions, enabling high-quality 3D
reconstruction. The RobustGS module can be seamlessly integrated into existing
pretrained pipelines in a plug-and-play manner to enhance reconstruction
robustness. Specifically, we introduce a novel component, Generalized
Degradation Learner, designed to extract generic representations and
distributions of multiple degradations from multi-view inputs, thereby
enhancing degradation-awareness and improving the overall quality of 3D
reconstruction. In addition, we propose a novel semantic-aware state-space
model. It first leverages the extracted degradation representations to enhance
corrupted inputs in the feature space. Then, it employs a semantic-aware
strategy to aggregate semantically similar information across different views,
enabling the extraction of fine-grained cross-view correspondences and further
improving the quality of 3D representations. Extensive experiments demonstrate
that our approach, when integrated into existing methods in a plug-and-play
manner, consistently achieves state-of-the-art reconstruction quality across
various types of degradations.

</details>


### [83] [Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models](https://arxiv.org/abs/2508.03079)
*Zaiying Zhao,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: 研究发现大型视觉语言模型(LVLMs)在更广泛的细粒度属性（如文化、环境、行为）上存在偏见，且这些因素的影响比传统人口统计学属性更显著。


<details>
  <summary>Details</summary>
Motivation: 随着大型视觉语言模型(LVLMs)应用快速增长，对其公平性的担忧日益增加。现有研究多集中于种族和性别等人口统计学属性，但对更广泛属性的公平性探索不足。

Method: 本研究利用大型语言模型(LLMs)构建了一个开放集偏见属性知识库，并以此评估了LVLMs在更细粒度属性上的公平性。

Result: 实验结果表明，LVLMs在多样化的属性上表现出偏见输出，并且文化、环境和行为因素对LVLM决策的影响比传统人口统计学属性更为显著。

Conclusion: LVLMs不仅在传统人口统计学属性上存在偏见，在文化、环境和行为等细粒度属性上也表现出明显偏见，提示未来公平性研究需考虑更广泛、更深层的影响因素。

Abstract: The rapid expansion of applications using Large Vision-Language Models
(LVLMs), such as GPT-4o, has raised significant concerns about their fairness.
While existing studies primarily focus on demographic attributes such as race
and gender, fairness across a broader range of attributes remains largely
unexplored. In this study, we construct an open-set knowledge base of bias
attributes leveraging Large Language Models (LLMs) and evaluate the fairness of
LVLMs across finer-grained attributes. Our experimental results reveal that
LVLMs exhibit biased outputs across a diverse set of attributes and further
demonstrate that cultural, environmental, and behavioral factors have a more
pronounced impact on LVLM decision-making than traditional demographic
attributes.

</details>


### [84] [Contrastive Cross-Bag Augmentation for Multiple Instance Learning-based Whole Slide Image Classification](https://arxiv.org/abs/2508.03081)
*Bo Zhang,Xu Xinan,Shuo Yan,Yu Bai,Zheng Zhang,Wufan Wang,Wendong Wang*

Main category: cs.CV

TL;DR: 针对MIL-WSI分类中伪包多样性不足问题，提出`C^2Aug`以增加实例多样性，并结合包级和组级对比学习框架增强特征判别能力，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于多实例学习（MIL）的全玻片图像（WSI）分类中的伪包增强方法，由于仅从有限的包中采样实例，导致多样性受限，从而限制了模型性能。

Method: 提出对比跨包增强（`C^2Aug`）方法，从所有同类包中采样实例以增加伪包多样性。为解决`C^2Aug`可能导致关键实例增多和在小肿瘤区域性能受限的问题，引入包级和组级对比学习框架，以增强具有不同语义特征的判别能力。

Result: `C^2Aug`在多项评估指标上均持续优于现有的最先进方法。

Conclusion: 所提出的`C^2Aug`结合对比学习框架，有效解决了MIL-WSI分类中伪包多样性受限的问题，并显著提升了模型性能，尤其对小肿瘤区域的测试玻片表现更佳。

Abstract: Recent pseudo-bag augmentation methods for Multiple Instance Learning
(MIL)-based Whole Slide Image (WSI) classification sample instances from a
limited number of bags, resulting in constrained diversity. To address this
issue, we propose Contrastive Cross-Bag Augmentation ($C^2Aug$) to sample
instances from all bags with the same class to increase the diversity of
pseudo-bags. However, introducing new instances into the pseudo-bag increases
the number of critical instances (e.g., tumor instances). This increase results
in a reduced occurrence of pseudo-bags containing few critical instances,
thereby limiting model performance, particularly on test slides with small
tumor areas. To address this, we introduce a bag-level and group-level
contrastive learning framework to enhance the discrimination of features with
distinct semantic meanings, thereby improving model performance. Experimental
results demonstrate that $C^2Aug$ consistently outperforms state-of-the-art
approaches across multiple evaluation metrics.

</details>


### [85] [Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts](https://arxiv.org/abs/2508.03094)
*Jiantao Tan,Peixian Ma,Kanghao Chen,Zhiming Dai,Ruixuan Wang*

Main category: cs.CV

TL;DR: 该研究提出一种新颖的持续学习框架，利用大型语言模型（LLMs）生成的视觉概念作为判别性语义指导，并通过跨模态图像-概念注意力模块集成，以增强医学图像分类的持续学习能力，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类系统需要持续学习以适应动态临床环境。多模态信息可以增强图像类别的持续学习，但现有方法仅依赖简单的文本模板（如仅使用类名），忽略了更丰富的语义信息。

Method: 该方法利用LLMs生成的视觉概念作为判别性语义指导。它动态构建一个视觉概念池，并采用基于相似度的过滤机制防止冗余。随后，通过一个跨模态图像-概念注意力模块，结合注意力损失，将这些概念整合到持续学习过程中，从而利用相关视觉概念的语义知识生成具有类代表性的融合特征进行分类。

Result: 在医学和自然图像数据集上的实验表明，该方法实现了最先进的性能，证明了其有效性和优越性。

Conclusion: 该研究成功地通过引入LLMs生成的丰富视觉概念并有效整合到持续学习框架中，显著提升了医学图像分类的持续学习能力，克服了现有方法在语义信息利用上的局限性。

Abstract: Continual learning is essential for medical image classification systems to
adapt to dynamically evolving clinical environments. The integration of
multimodal information can significantly enhance continual learning of image
classes. However, while existing approaches do utilize textual modality
information, they solely rely on simplistic templates with a class name,
thereby neglecting richer semantic information. To address these limitations,
we propose a novel framework that harnesses visual concepts generated by large
language models (LLMs) as discriminative semantic guidance. Our method
dynamically constructs a visual concept pool with a similarity-based filtering
mechanism to prevent redundancy. Then, to integrate the concepts into the
continual learning process, we employ a cross-modal image-concept attention
module, coupled with an attention loss. Through attention, the module can
leverage the semantic knowledge from relevant visual concepts and produce
class-representative fused features for classification. Experiments on medical
and natural image datasets show our method achieves state-of-the-art
performance, demonstrating the effectiveness and superiority of our method. We
will release the code publicly.

</details>


### [86] [AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video](https://arxiv.org/abs/2508.03100)
*Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: 本文提出AVATAR框架，通过离策略训练和时间优势塑造，解决了长视频多模态推理中现有方法的数据效率低下、优势消失和均匀信用分配问题，显著提升了性能和样本效率。


<details>
  <summary>Details</summary>
Motivation: 长视频多模态推理因需要精确的时空融合和跨模态对齐而具有挑战性。尽管现有方法如GRPO有前景，但其存在三个主要局限：数据效率低下（策略内设计）、优势消失问题（奖励差异小导致学习信号缺失）以及均匀信用分配（未能强调关键推理步骤）。

Method: 引入了AVATAR（Audio-Video Agent for Alignment and Reasoning）框架，通过两个核心组件解决上述问题：1) 离策略训练架构，通过重用过去具有更多奖励多样性的经验，提高样本效率并解决优势消失问题；2) 时间优势塑造（Temporal Advantage Shaping, TAS），一种新颖的信用分配策略，在学习过程中上调关键推理阶段的权重。

Result: AVATAR在多个基准测试中表现出色，在MMVU、OmniBench和Video-Holmes上分别超越Qwen2.5-Omni基线+5.4、+4.9和+4.5，同时展示了超过35%的样本效率提升。

Conclusion: AVATAR通过创新的离策略训练和时间优势塑造策略，有效解决了长视频多模态推理中的关键挑战，显著提升了模型性能、鲁棒性和样本效率，为该领域提供了新的解决方案。

Abstract: Multimodal reasoning over long-horizon video is challenging due to the need
for precise spatiotemporal fusion and alignment across modalities. While recent
methods such as Group Relative Policy Optimization (GRPO) have shown promise in
this domain, they suffer from three key limitations: (1) data inefficiency from
their on-policy design, (2) a vanishing advantage problem, where identical or
near-identical rewards within a group eliminate the learning signal by
producing zero-valued advantages, and (3) uniform credit assignment that fails
to emphasize critical reasoning steps. We introduce AVATAR (Audio-Video Agent
for Alignment and Reasoning), a framework that addresses these limitations
through two core components: (1) an off-policy training architecture that
improves sample efficiency and resolves vanishing advantages by reusing past
experiences with greater reward diversity, and (2) Temporal Advantage Shaping
(TAS), a novel credit assignment strategy that upweights key reasoning phases
during learning. AVATAR achieves strong performance across various benchmarks,
outperforming the Qwen2.5-Omni baseline by +5.4on MMVU, +4.9 on OmniBench, and
+4.5 on Video-Holmes, while demonstrating over 35% higher sample efficiency.

</details>


### [87] [Causal Disentanglement and Cross-Modal Alignment for Enhanced Few-Shot Learning](https://arxiv.org/abs/2508.03102)
*Tianjiao Jiang,Zhen Zhang,Yuhang Liu,Javen Qinfeng Shi*

Main category: cs.CV

TL;DR: 本文提出Causal CLIP Adapter (CCA)框架，通过无监督独立成分分析(ICA)显式解耦CLIP视觉特征，并结合单向文本分类器和双向交叉注意力机制增强跨模态对齐，显著提升了少样本学习性能和分布偏移鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有少样本学习(FSL)方法多依赖纠缠表示，需模型在有限监督下隐式恢复解耦过程，阻碍了有效适应。鉴于多模态对比学习（如CLIP）能实现潜在表示的线性解耦，本研究旨在显式解耦特征以提升FSL性能并缓解过拟合。

Method: 所提出的Causal CLIP Adapter (CCA)框架首先利用无监督独立成分分析 (ICA) 显式解耦从CLIP提取的视觉特征，从而减少训练参数并缓解过拟合。为弥补ICA可能破坏CLIP模态内和模态间对齐的问题，CCA通过两种方式增强CLIP固有的跨模态对齐：一是通过微调基于CLIP的文本分类器进行单向增强；二是通过交叉注意力机制进行双向增强，使视觉和文本表示相互丰富。最终，将单模态和跨模态分类输出线性结合以提高分类精度。

Result: 在11个基准数据集上进行的大量实验表明，所提出的方法在少样本学习性能和对分布偏移的鲁棒性方面持续优于现有最先进方法，同时保持了计算效率。

Conclusion: CCA框架通过结合显式特征解耦和强化的跨模态对齐，有效解决了少样本学习中的挑战，实现了卓越的性能和鲁棒性，为少样本学习提供了一种高效且有效的新范式。

Abstract: Few-shot learning (FSL) often requires effective adaptation of models using
limited labeled data. However, most existing FSL methods rely on entangled
representations, requiring the model to implicitly recover the unmixing process
to obtain disentangled representations using only limited supervision, which
hinders effective adaptation. Recent theoretical studies show that multimodal
contrastive learning methods, such as CLIP, can disentangle latent
representations up to linear transformations. In light of this, we propose the
Causal CLIP Adapter (CCA), a novel framework that explicitly disentangles
visual features extracted from CLIP using unsupervised Independent Component
Analysis (ICA). This removes the need to learn the unmixing process from the
labeled data, thereby reducing the number of trainable parameters and
mitigating overfitting. Taking a step further, while ICA can obtain visual
disentangled representations, it may also disrupt CLIP's intra- and inter-modal
alignment. To counteract this, CCA further leverages CLIP's inherent
cross-modal alignment by enhancing it in two ways: unidirectionally, through
fine-tuning a CLIP-based text classifier, and bidirectionally, via a
cross-attention mechanism that enriches visual and textual representations
through mutual interaction. Both unimodal and cross-modal classification
outputs can be effectively combined linearly to improve classification
accuracy. Extensive experiments on 11 benchmark datasets demonstrate that our
method consistently outperforms state-of-the-art approaches in terms of
few-shot performance and robustness to distributional shifts, while maintaining
computational efficiency. Code will be available at
https://github.com/tianjiao-j/CCA.

</details>


### [88] [H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction](https://arxiv.org/abs/2508.03118)
*Heng Jia,Linchao Zhu,Na Zhao*

Main category: cs.CV

TL;DR: H3R是一个混合框架，通过融合体素潜在融合和注意力特征聚合，解决了可泛化3D重建中多视角对应建模的挑战，实现了更快的收敛和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管前馈3D高斯辐射场取得进展，但可泛化的3D重建仍具挑战，尤其在多视角对应建模方面。现有方法存在根本性权衡：显式方法几何精度高但难以处理模糊区域，隐式方法鲁棒但收敛慢。

Method: 提出H3R混合框架，整合体素潜在融合与注意力特征聚合。该框架包含两个互补组件：一个高效的潜在体素，通过对极几何约束强制几何一致性；一个相机感知Transformer，利用普吕克坐标进行自适应对应精炼。

Result: 该方法增强了泛化能力，收敛速度比现有方法快2倍。实验表明，空间对齐的基础模型（如SD-VAE）在空间重建方面显著优于语义对齐模型（如DINOv2）。方法支持可变数量和高分辨率输入视图，并展现了鲁棒的跨数据集泛化能力。在RealEstate10K、ACID和DTU数据集上，PSNR分别提升了0.59 dB、1.06 dB和0.22 dB，达到了最先进的性能。

Conclusion: H3R框架通过创新的混合方法，有效解决了可泛化3D重建中多视角对应建模的挑战，显著提升了重建质量、泛化能力和收敛速度，并验证了空间对齐基础模型的重要性。

Abstract: Despite recent advances in feed-forward 3D Gaussian Splatting, generalizable
3D reconstruction remains challenging, particularly in multi-view
correspondence modeling. Existing approaches face a fundamental trade-off:
explicit methods achieve geometric precision but struggle with ambiguous
regions, while implicit methods provide robustness but suffer from slow
convergence. We present H3R, a hybrid framework that addresses this limitation
by integrating volumetric latent fusion with attention-based feature
aggregation. Our framework consists of two complementary components: an
efficient latent volume that enforces geometric consistency through epipolar
constraints, and a camera-aware Transformer that leverages Pl\"ucker
coordinates for adaptive correspondence refinement. By integrating both
paradigms, our approach enhances generalization while converging 2$\times$
faster than existing methods. Furthermore, we show that spatial-aligned
foundation models (e.g., SD-VAE) substantially outperform semantic-aligned
models (e.g., DINOv2), resolving the mismatch between semantic representations
and spatial reconstruction requirements. Our method supports variable-number
and high-resolution input views while demonstrating robust cross-dataset
generalization. Extensive experiments show that our method achieves
state-of-the-art performance across multiple benchmarks, with significant PSNR
improvements of 0.59 dB, 1.06 dB, and 0.22 dB on the RealEstate10K, ACID, and
DTU datasets, respectively. Code is available at
https://github.com/JiaHeng-DLUT/H3R.

</details>


### [89] [Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery](https://arxiv.org/abs/2508.03127)
*Sai Ma,Zhuang Li,John A Taylor*

Main category: cs.CV

TL;DR: 为解决现有视觉语言模型（VLMs）在卫星图像处理中对长期、低分辨率数据的不足，本研究构建了Landsat30-AU大型数据集，并发现现有VLMs性能不佳，但通过轻量级微调可显著提升其对卫星图像的理解能力。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）能通过自然语言与卫星图像交互，有助于加速地球观测、普及数据并实现全球自动化。然而，现有数据集主要关注短期、高分辨率图像，忽略了对全球经济高效且鲁棒监测至关重要的低分辨率、多卫星、长期存档数据（如Landsat）。

Method: 本研究构建了Landsat30-AU数据集，包含来自四颗Landsat卫星（5, 7, 8, 9）在澳大利亚36年间收集的30米分辨率图像。数据集包含两部分：Landsat30-AU-Cap（196,262对图像-标题）和Landsat30-AU-VQA（17,725个人工验证的视觉问答样本）。数据通过引导式流水线生成，结合通用VLM、迭代精炼和人工验证确保质量。研究还评估了8个VLM，并对Qwen2.5-VL-7B进行了轻量级微调。

Result: 评估结果显示，现成VLM难以理解卫星图像，开源遥感VLM EarthDial在标题生成上SPIDEr仅0.07，VQA准确率0.48。令人鼓舞的是，对Qwen2.5-VL-7B在Landsat30-AU上进行轻量级微调后，标题生成性能从0.11 SPIDEr提升至0.31，VQA准确率从0.74提升至0.87。

Conclusion: 现有视觉语言模型在处理卫星图像方面存在显著局限性。本研究所构建的Landsat30-AU数据集填补了长期、低分辨率卫星图像数据的空白，并证明了通过特定数据集进行轻量级微调能够有效提升VLMs对卫星图像的理解能力。

Abstract: Vision language models (VLMs) that enable natural language interaction with
satellite imagery can democratize Earth observation by accelerating expert
workflows, making data accessible to non-specialists, and enabling planet-scale
automation. However, existing datasets focus mainly on short-term,
high-resolution imagery from a limited number of satellites, overlooking
low-resolution, multi-satellite, long-term archives, such as Landsat, that are
essential for affordable and bias-robust global monitoring. We address this gap
with Landsat30-AU, a large-scale vision-language dataset built from 30-meter
resolution imagery collected by four Landsat satellites (5, 7, 8, and 9) over
Australia, spanning more than 36 years. The dataset includes two components:
Landsat30-AU-Cap, containing 196,262 image-caption pairs, and Landsat30-AU-VQA,
comprising 17,725 human-verified visual question answering (VQA) samples across
eight remote sensing domains. Both datasets are curated through a bootstrapped
pipeline that leverages generic VLMs with iterative refinement and human
verification to ensure quality. Our evaluation of eight VLMs on our benchmark
reveals that off-the-shelf models struggle to understand satellite imagery. The
open-source remote-sensing VLM EarthDial achieves only 0.07 SPIDEr in
captioning and a VQA accuracy of 0.48, highlighting the limitations of current
approaches. Encouragingly, lightweight fine-tuning of Qwen2.5-VL-7B on
Landsat30-AU improves captioning performance from 0.11 to 0.31 SPIDEr and
boosts VQA accuracy from \textbf{0.74} to 0.87. Code and data are available at
https://github.com/papersubmit1/landsat30-au.

</details>


### [90] [COFFEE: A Shadow-Resilient Real-Time Pose Estimator for Unknown Tumbling Asteroids using Sparse Neural Networks](https://arxiv.org/abs/2508.03132)
*Arion Zimmermann,Soon-Jo Chung,Fred Hadaegh*

Main category: cs.CV

TL;DR: COFFEE是一种实时、无偏、高精度的小行星姿态估计算法，它利用太阳相位角信息，通过结合稀疏神经网络和图神经网络来处理阴影影响，比现有方法更快更准确。


<details>
  <summary>Details</summary>
Motivation: 太空未知物体（如空间碎片、小行星）的准确姿态估计至关重要。现有方法（如SIFT、ORB、AKAZE等）虽然能实时处理，但姿态估计精度不高；现代深度学习方法能提供更高质量的特征，但计算资源需求大，不适用于空间硬件。更重要的是，无论是传统还是数据驱动方法，都难以应对物体自身投射的阴影，这些阴影会导致姿态估计产生大的偏差，从而可能导致任务失败，特别是对于混沌翻滚的物体。

Method: 本文提出了COFFEE（Celestial Occlusion Fast FEature Extractor），一个用于小行星的实时姿态估计框架。该方法利用航天器上常见的太阳追踪传感器提供的太阳相位角先验信息。它通过将显著轮廓与投影阴影关联起来，检测出一组对阴影运动不变的稀疏特征。随后，一个稀疏神经网络和一个基于注意力机制的图神经网络特征匹配模型被联合训练，以提供连续帧之间的对应关系。

Result: 实验结果表明，COFFEE姿态估计管道：1) 无偏差；2) 比经典姿态估计管道更准确；3) 在合成数据以及翻滚小行星Apophis的渲染图上，比其他最先进的深度学习管道快一个数量级。

Conclusion: COFFEE提供了一种有效、高效且对阴影鲁棒的解决方案，能够克服太空物体姿态估计中阴影带来的挑战，实现对未知太空物体实时、无偏、高精度的姿态估计，为空间任务提供了关键能力。

Abstract: The accurate state estimation of unknown bodies in space is a critical
challenge with applications ranging from the tracking of space debris to the
shape estimation of small bodies. A necessary enabler to this capability is to
find and track features on a continuous stream of images. Existing methods,
such as SIFT, ORB and AKAZE, achieve real-time but inaccurate pose estimates,
whereas modern deep learning methods yield higher quality features at the cost
of more demanding computational resources which might not be available on
space-qualified hardware. Additionally, both classical and data-driven methods
are not robust to the highly opaque self-cast shadows on the object of
interest. We show that, as the target body rotates, these shadows may lead to
large biases in the resulting pose estimates. For these objects, a bias in the
real-time pose estimation algorithm may mislead the spacecraft's state
estimator and cause a mission failure, especially if the body undergoes a
chaotic tumbling motion. We present COFFEE, the Celestial Occlusion Fast
FEature Extractor, a real-time pose estimation framework for asteroids designed
to leverage prior information on the sun phase angle given by sun-tracking
sensors commonly available onboard spacecraft. By associating salient contours
to their projected shadows, a sparse set of features are detected, invariant to
the motion of the shadows. A Sparse Neural Network followed by an
attention-based Graph Neural Network feature matching model are then jointly
trained to provide a set of correspondences between successive frames. The
resulting pose estimation pipeline is found to be bias-free, more accurate than
classical pose estimation pipelines and an order of magnitude faster than other
state-of-the-art deep learning pipelines on synthetic data as well as on
renderings of the tumbling asteroid Apophis.

</details>


### [91] [Uint: Building Uint Detection Dataset](https://arxiv.org/abs/2508.03139)
*Haozhou Zhai,Yanzhe Gao,Tianjiang Hu*

Main category: cs.CV

TL;DR: 提出一个合成的无人机视角火灾单元数据集，以解决现有火灾单元标注数据不足的问题，并提升火灾检测模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有火灾场景数据集中，专门针对建筑单元的标注数据严重缺乏，而这类数据对训练火灾早期预警和紧急救援的计算机视觉模型至关重要。

Method: 构建了一个包含多种增强技术的无人机视角建筑单元标注数据集。具体方法包括：使用真实多层场景构建背景，结合运动模糊和亮度调整提升图像真实性，模拟不同无人机拍摄条件，并利用大型模型在不同位置生成火灾效果。

Result: 生成了一个包含1,978张图像的合成数据集，覆盖多种建筑场景。该数据集能够有效提升火灾单元检测模型的泛化能力，提供多场景、可扩展的数据，并降低收集真实火灾数据的风险与成本。

Conclusion: 该合成数据集成功解决了火灾单元标注数据稀缺的难题，为火灾单元检测提供了宝贵、可扩展且低成本的数据资源，对提升相关计算机视觉模型的性能和应用具有重要意义。

Abstract: Fire scene datasets are crucial for training robust computer vision models,
particularly in tasks such as fire early warning and emergency rescue
operations. However, among the currently available fire-related data, there is
a significant shortage of annotated data specifically targeting building
units.To tackle this issue, we introduce an annotated dataset of building units
captured by drones, which incorporates multiple enhancement techniques. We
construct backgrounds using real multi-story scenes, combine motion blur and
brightness adjustment to enhance the authenticity of the captured images,
simulate drone shooting conditions under various circumstances, and employ
large models to generate fire effects at different locations.The synthetic
dataset generated by this method encompasses a wide range of building
scenarios, with a total of 1,978 images. This dataset can effectively improve
the generalization ability of fire unit detection, providing multi-scenario and
scalable data while reducing the risks and costs associated with collecting
real fire data. The dataset is available at
https://github.com/boilermakerr/FireUnitData.

</details>


### [92] [UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying](https://arxiv.org/abs/2508.03142)
*Chengyu Bai,Jintao Chen,Xiang Bai,Yilong Chen,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: 本文提出UniEdit-I，一个免训练的框架，通过理解、编辑和验证三步迭代，为统一视觉-语言模型（VLMs）提供高保真图像编辑能力，并在GEdit-Bench上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管统一视觉-语言模型（VLMs）在视觉理解和生成任务上取得了显著进展，且OpenAI GPT-4o提出了有前景的生成管道，但如何轻松实现图像编辑能力，特别是免训练的编辑方法，仍是一个未被探索的挑战。

Method: 本文引入了UniEdit-I框架，通过以下三个迭代步骤实现图像编辑：1. **理解步骤**：通过结构化语义分析从源图像生成源提示，并根据编辑指令进行少量词替换以形成目标提示。2. **编辑步骤**：引入时间自适应偏移，在去噪过程中实现从粗到细的连贯编辑。3. **验证步骤**：检查目标提示与中间编辑图像的一致性，提供自动一致性分数和纠正反馈，并决定是否提前停止或继续编辑循环。此循环迭代至收敛。

Result: 基于最新的BLIP3-o实现了所提出的方法，并在GEdit-Bench基准测试中取得了最先进（SOTA）的性能。

Conclusion: UniEdit-I提供了一种新颖、高效且免训练的方法，为统一视觉-语言模型带来了高保真图像编辑能力，解决了现有生成管道中图像编辑能力缺失的问题，并展现了优秀的性能。

Abstract: In recent years, unified vision-language models (VLMs) have rapidly advanced,
effectively tackling both visual understanding and generation tasks within a
single design. While many unified VLMs have explored various design choices,
the recent hypothesis from OpenAI's GPT-4o suggests a promising generation
pipeline: Understanding VLM->Visual Feature->Projector->Diffusion Model->Image.
The understanding VLM is frozen, and only the generation-related modules are
trained. This pipeline maintains the strong capability of understanding VLM
while enabling the image generation ability of the unified VLM. Although this
pipeline has shown very promising potential for the future development of
unified VLM, how to easily enable image editing capability is still unexplored.
In this paper, we introduce a novel training-free framework named UniEdit-I to
enable the unified VLM with image editing capability via three iterative steps:
understanding, editing, and verifying. 1. The understanding step analyzes the
source image to create a source prompt through structured semantic analysis and
makes minimal word replacements to form the target prompt based on the editing
instruction. 2. The editing step introduces a time-adaptive offset, allowing
for coherent editing from coarse to fine throughout the denoising process. 3.
The verification step checks the alignment between the target prompt and the
intermediate edited image, provides automatic consistency scores and corrective
feedback, and determines whether to stop early or continue the editing loop.
This understanding, editing, and verifying loop iterates until convergence,
delivering high-fidelity editing in a training-free manner. We implemented our
method based on the latest BLIP3-o and achieved state-of-the-art (SOTA)
performance on the GEdit-Bench benchmark.

</details>


### [93] [SARD: Segmentation-Aware Anomaly Synthesis via Region-Constrained Diffusion with Discriminative Mask Guidance](https://arxiv.org/abs/2508.03143)
*Yanshu Wang,Xichen Xu,Xiaoning Lei,Guoyang Xie*

Main category: cs.CV

TL;DR: 本文提出SARD，一种新颖的扩散模型，用于生成空间精确的工业异常。它通过区域约束扩散和判别性掩码引导，克服了现有方法在空间控制和区域保真度方面的不足，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为提升工业异常检测系统的鲁棒性，需要合成真实且空间精确的异常。现有扩散模型虽能模拟复杂缺陷，但常缺乏空间可控性并难以保持细粒度区域保真度。

Method: 本文提出SARD（Segmentation-Aware anomaly synthesis via Region-constrained Diffusion with discriminative mask Guidance）框架。该方法引入了：1) 区域约束扩散（RCD）过程，通过冻结背景并仅更新前景异常区域来减少背景伪影；2) 判别性掩码引导（DMG）模块，融入判别器中，以像素级掩码引导，共同评估全局真实性和局部异常保真度。

Result: 在MVTec-AD和BTAD数据集上的大量实验表明，SARD在分割精度和视觉质量上均超越现有方法。

Conclusion: SARD为像素级异常合成设定了新的技术水平（State-of-the-Art）。

Abstract: Synthesizing realistic and spatially precise anomalies is essential for
enhancing the robustness of industrial anomaly detection systems. While recent
diffusion-based methods have demonstrated strong capabilities in modeling
complex defect patterns, they often struggle with spatial controllability and
fail to maintain fine-grained regional fidelity. To overcome these limitations,
we propose SARD (Segmentation-Aware anomaly synthesis via Region-constrained
Diffusion with discriminative mask Guidance), a novel diffusion-based framework
specifically designed for anomaly generation. Our approach introduces a
Region-Constrained Diffusion (RCD) process that preserves the background by
freezing it and selectively updating only the foreground anomaly regions during
the reverse denoising phase, thereby effectively reducing background artifacts.
Additionally, we incorporate a Discriminative Mask Guidance (DMG) module into
the discriminator, enabling joint evaluation of both global realism and local
anomaly fidelity, guided by pixel-level masks. Extensive experiments on the
MVTec-AD and BTAD datasets show that SARD surpasses existing methods in
segmentation accuracy and visual quality, setting a new state-of-the-art for
pixel-level anomaly synthesis.

</details>


### [94] [LORE: Latent Optimization for Precise Semantic Control in Rectified Flow-based Image Editing](https://arxiv.org/abs/2508.03144)
*Liangyang Ouyang,Jiafeng Mao*

Main category: cs.CV

TL;DR: 针对文本驱动图像编辑中反演方法存在的语义偏差问题，本文提出LORE，通过优化反演噪声实现无需训练、稳定、通用的概念替换，显著提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于反演的文本驱动图像编辑方法，在源目标语义差异较大时，由于对源概念的语义偏置，导致对目标概念的注意力不足，常造成编辑失败或非目标区域的意外修改。

Method: 本文系统分析并验证了该结构性缺陷，并提出LORE方法。LORE是一种无需训练、高效的图像编辑方法，通过直接优化反演噪声，解决了现有方法在泛化性和可控性方面的核心局限，实现了稳定、可控、通用的概念替换，且无需修改架构或模型微调。

Result: 在PIEBench、SmartEdit和GapEdit三个挑战性基准测试上进行了全面评估。实验结果表明，LORE在语义对齐、图像质量和背景保真度方面显著优于强基线方法。

Conclusion: 该研究证明了潜在空间优化对于通用图像编辑的有效性和可扩展性。

Abstract: Text-driven image editing enables users to flexibly modify visual content
through natural language instructions, and is widely applied to tasks such as
semantic object replacement, insertion, and removal. While recent
inversion-based editing methods using rectified flow models have achieved
promising results in image quality, we identify a structural limitation in
their editing behavior: the semantic bias toward the source concept encoded in
the inverted noise tends to suppress attention to the target concept. This
issue becomes particularly critical when the source and target semantics are
dissimilar, where the attention mechanism inherently leads to editing failure
or unintended modifications in non-target regions. In this paper, we
systematically analyze and validate this structural flaw, and introduce LORE, a
training-free and efficient image editing method. LORE directly optimizes the
inverted noise, addressing the core limitations in generalization and
controllability of existing approaches, enabling stable, controllable, and
general-purpose concept replacement, without requiring architectural
modification or model fine-tuning. We conduct comprehensive evaluations on
three challenging benchmarks: PIEBench, SmartEdit, and GapEdit. Experimental
results show that LORE significantly outperforms strong baselines in terms of
semantic alignment, image quality, and background fidelity, demonstrating the
effectiveness and scalability of latent-space optimization for general-purpose
image editing.

</details>


### [95] [ChartCap: Mitigating Hallucination of Dense Chart Captioning](https://arxiv.org/abs/2508.03164)
*Junyoung Lim,Jaewoo Ahn,Gunhee Kim*

Main category: cs.CV

TL;DR: 研究人员推出了ChartCap数据集和视觉一致性得分，显著提升了视觉语言模型生成图表标题的准确性和信息量，并减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型难以生成准确、信息丰富、无幻觉的图表标题，主要由于缺乏高质量大规模真实世界图表数据集，且现有数据集存在冗余信息和未能充分捕捉结构与关键洞察的问题。

Method: 1. 构建了ChartCap数据集（56.5万张真实世界图表图像及其类型特定、密集且无冗余信息的标题）。2. 设计了四阶段流水线，仅用图表可辨数据生成标题，并采用基于循环一致性的人工验证加速质控。3. 提出了新的评估指标“视觉一致性得分”，通过比较标题重建图表与原始图表的相似性来评估标题质量。

Result: 在ChartCap上微调的模型能持续生成更准确、信息更丰富、幻觉更少的标题，性能超越了开源模型、专有模型乃至人工标注的标题。

Conclusion: ChartCap数据集及其构建方法有效解决了图表标题生成的数据集瓶颈，显著提升了视觉语言模型在该领域的性能，并提供了新的评估范式。

Abstract: Generating accurate, informative, and hallucination-free captions for charts
remains challenging for vision language models, primarily due to the lack of
large-scale, high-quality datasets of real-world charts. However, existing
real-world chart datasets suffer from the inclusion of extraneous information
that cannot be inferred from the chart and failure to sufficiently capture
structural elements and key insights. Therefore, we introduce ChartCap, a
large-scale dataset of 565K real-world chart images paired with type-specific,
dense captions that exclude extraneous information and highlight both
structural elements and key insights in detail. To build ChartCap, we design a
four-stage pipeline that generates captions using only the discernible data
from the chart and employ a cycle consistency-based human verification, which
accelerates quality control without sacrificing accuracy. Additionally, we
propose a novel metric, the Visual Consistency Score, which evaluates caption
quality by measuring the similarity between the chart regenerated from a
caption and the original chart, independent of reference captions. Extensive
experiments confirms that models fine-tuned on ChartCap consistently generate
more accurate and informative captions with reduced hallucinations, surpassing
both open-source and proprietary models and even human-annotated captions.

</details>


### [96] [SAVER: Mitigating Hallucinations in Large Vision-Language Models via Style-Aware Visual Early Revision](https://arxiv.org/abs/2508.03177)
*Zhaoxu Li,Chenqi Kong,Yi Yu,Qiangqiang Wu,Xinghao Jiang,Ngai-Man Cheung,Bihan Wen,Alex Kot,Xudong Jiang*

Main category: cs.CV

TL;DR: 本文关注大型视觉-语言模型（LVLMs）在风格化图像上的幻觉问题。研究发现风格化图像更容易导致幻觉，并提出SAVER机制，通过早期层反馈和注意力模式动态调整，有效缓解了LV觉在多种模型和任务上的幻觉问题，达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（LVLMs）在理解复杂视觉-文本上下文方面取得显著进展，但幻觉问题限制了其实际应用。现有缓解幻觉的方法主要针对摄影图像，却忽略了风格化图像带来的潜在风险，而风格化图像在游戏、艺术教育和医疗分析等关键场景中扮演重要角色。

Method: 1. 构建了一个包含摄影图像及其对应风格化版本，并带有详细标注的字幕标签的数据集。2. 在该数据集上，对13个先进的LVLMs在判别和生成任务上进行了头对头基准测试。3. 提出了一种名为Style-Aware Visual Early Revision (SAVER) 的新颖机制，该机制通过利用早期层反馈，并基于令牌级视觉注意力模式动态调整LVLMs的最终输出，以缓解风格化图像引起的幻觉。

Result: 1. 研究发现，风格化图像比其摄影图像对应物更容易引起LVLMs产生显著更多的幻觉。2. 大量实验证明，SAVER机制在各种模型、数据集和任务上，都实现了最先进的幻觉缓解性能。

Conclusion: LVLMs在处理风格化图像时存在显著的幻觉问题，这限制了它们在特定关键领域的应用。本文提出的SAVER机制能有效利用早期视觉反馈来动态修正输出，成功缓解了LVLMs在风格化图像上的幻觉，显著提升了模型的稳健性和实用性。

Abstract: Large Vision-Language Models (LVLMs) recently achieve significant
breakthroughs in understanding complex visual-textual contexts. However,
hallucination issues still limit their real-world applicability. Although
previous mitigation methods effectively reduce hallucinations in photographic
images, they largely overlook the potential risks posed by stylized images,
which play crucial roles in critical scenarios such as game scene
understanding, art education, and medical analysis. In this work, we first
construct a dataset comprising photographic images and their corresponding
stylized versions with carefully annotated caption labels. We then conduct
head-to-head comparisons on both discriminative and generative tasks by
benchmarking 13 advanced LVLMs on the collected datasets. Our findings reveal
that stylized images tend to induce significantly more hallucinations than
their photographic counterparts. To address this issue, we propose Style-Aware
Visual Early Revision SAVER, a novel mechanism that dynamically adjusts LVLMs'
final outputs based on the token-level visual attention patterns, leveraging
early-layer feedback to mitigate hallucinations caused by stylized images.
Extensive experiments demonstrate that SAVER achieves state-of-the-art
performance in hallucination mitigation across various models, datasets, and
tasks.

</details>


### [97] [Advancing Precision in Multi-Point Cloud Fusion Environments](https://arxiv.org/abs/2508.03179)
*Ulugbek Alibekov,Vanessa Staderini,Philipp Schneider,Doris Antensteiner*

Main category: cs.CV

TL;DR: 本研究通过评估点云匹配方法并开发CloudCompare插件，提升了视觉工业检测的自动化与效率。


<details>
  <summary>Details</summary>
Motivation: 旨在解决视觉工业检测中点云评估和多点云匹配的挑战，以提高自动化检测系统的准确性和效率。

Method: 1. 评估了点云和多点云匹配方法。2. 引入了用于定量评估配准方法和点云比较距离度量的合成数据集。3. 开发了CloudCompare插件，用于合并多点云和可视化表面缺陷。

Result: 1. 成功引入了合成数据集，用于定量评估配准方法和距离度量。2. 开发的CloudCompare插件能够有效合并多点云并可视化表面缺陷，显著提升了自动化检测系统的准确性和效率。

Conclusion: 本研究通过深入评估点云技术和开发创新的CloudCompare插件，为提高自动化工业检测的准确性和效率提供了有效途径。

Abstract: This research focuses on visual industrial inspection by evaluating point
clouds and multi-point cloud matching methods. We also introduce a synthetic
dataset for quantitative evaluation of registration method and various distance
metrics for point cloud comparison. Additionally, we present a novel
CloudCompare plugin for merging multiple point clouds and visualizing surface
defects, enhancing the accuracy and efficiency of automated inspection systems.

</details>


### [98] [Duplex-GS: Proxy-Guided Weighted Blending for Real-Time Order-Independent Gaussian Splatting](https://arxiv.org/abs/2508.03180)
*Weihang Liu,Yuke Li,Yuxuan Li,Jingyi Yu,Xin Lou*

Main category: cs.CV

TL;DR: Duplex-GS提出一种双层级框架，结合代理高斯和顺序无关渲染（OIT）技术，显著提升了3D Gaussian Splatting的渲染效率和质量，解决了传统方法计算开销大和伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D Gaussian Splatting (3DGS) 方法依赖计算昂贵的顺序alpha混合操作，尤其在资源受限平台上开销巨大；此外，视图自适应基数排序也带来显著开销，导致“弹出”和“透明度”伪影。

Method: 提出Duplex-GS，一个双层级框架。该框架整合代理高斯表示与顺序无关渲染(OIT)技术，以实现光照真实感和实时性能。为减轻基数排序开销，引入单元代理管理局部高斯，并提出单元搜索光栅化加速。结合OIT，开发了一种物理启发式加权求和渲染技术。

Result: 实验证明Duplex-GS在多尺度训练视图和大规模环境等多种真实世界场景中表现出鲁棒性。与现有基于OIT的高斯溅射方法相比，渲染速度提升1.5到4倍，并将基数排序开销降低52.2%至86.9%，同时不降低质量。成功消除“弹出”和“透明度”伪影。

Conclusion: 研究结果验证了OIT渲染范式在高斯溅射中的优势。Duplex-GS通过创新的双层级架构和OIT结合方法，有效解决了现有3DGS的效率和质量瓶颈，实现了高性能、高质量的渲染。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
rendering fidelity and efficiency. However, these methods still rely on
computationally expensive sequential alpha-blending operations, resulting in
significant overhead, particularly on resource-constrained platforms. In this
paper, we propose Duplex-GS, a dual-hierarchy framework that integrates proxy
Gaussian representations with order-independent rendering techniques to achieve
photorealistic results while sustaining real-time performance. To mitigate the
overhead caused by view-adaptive radix sort, we introduce cell proxies for
local Gaussians management and propose cell search rasterization for further
acceleration. By seamlessly combining our framework with Order-Independent
Transparency (OIT), we develop a physically inspired weighted sum rendering
technique that simultaneously eliminates "popping" and "transparency"
artifacts, yielding substantial improvements in both accuracy and efficiency.
Extensive experiments on a variety of real-world datasets demonstrate the
robustness of our method across diverse scenarios, including multi-scale
training views and large-scale environments. Our results validate the
advantages of the OIT rendering paradigm in Gaussian Splatting, achieving
high-quality rendering with an impressive 1.5 to 4 speedup over existing OIT
based Gaussian Splatting approaches and 52.2% to 86.9% reduction of the radix
sort overhead without quality degradation.

</details>


### [99] [Monocular Depth Estimation with Global-Aware Discretization and Local Context Modeling](https://arxiv.org/abs/2508.03186)
*Heng Wu,Qian Zhang,Guixu Zhang*

Main category: cs.CV

TL;DR: 本文提出一种新的单目深度估计算法，通过Gated Large Kernel Attention Module (GLKAM)捕获局部信息，并引入Global Bin Prediction Module (GBPM)增强全局感知，显著提升了深度预测精度，在NYU-V2和KITTI数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计是一项具有挑战性的任务，因为从单一视图恢复三维结构存在固有的模糊性，即多种深度配置可能产生相同的二维投影。

Method: 本文提出一种结合局部和全局线索的新型深度估计算法。具体方法包括：
1. 提出Gated Large Kernel Attention Module (GLKAM)：利用大核卷积和门控机制有效捕获多尺度局部结构信息。
2. 引入Global Bin Prediction Module (GBPM)：估计深度箱的全局分布，为深度回归提供结构指导。

Result: 在NYU-V2和KITTI数据集上进行的广泛实验表明，该方法取得了有竞争力的性能，并优于现有方法，同时验证了所提出每个组件的有效性。

Conclusion: 所提出的结合局部和全局线索的单目深度估计算法，通过GLKAM和GBPM模块，有效解决了深度估计中的模糊性问题，显著提升了预测精度，并在主流数据集上表现卓越。

Abstract: Accurate monocular depth estimation remains a challenging problem due to the
inherent ambiguity that stems from the ill-posed nature of recovering 3D
structure from a single view, where multiple plausible depth configurations can
produce identical 2D projections. In this paper, we present a novel depth
estimation method that combines both local and global cues to improve
prediction accuracy. Specifically, we propose the Gated Large Kernel Attention
Module (GLKAM) to effectively capture multi-scale local structural information
by leveraging large kernel convolutions with a gated mechanism. To further
enhance the global perception of the network, we introduce the Global Bin
Prediction Module (GBPM), which estimates the global distribution of depth bins
and provides structural guidance for depth regression. Extensive experiments on
the NYU-V2 and KITTI dataset demonstrate that our method achieves competitive
performance and outperforms existing approaches, validating the effectiveness
of each proposed component.

</details>


### [100] [Unifying Locality of KANs and Feature Drift Compensation for Data-free Continual Face Forgery Detection](https://arxiv.org/abs/2508.03189)
*Tianshuo Zhang,Siran Peng,Li Gao,Haoyuan Zhang,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 提出基于KAN的持续人脸伪造检测 (KAN-CFD) 框架，有效缓解在高维图像数据中学习新伪造类型时出现的灾难性遗忘问题，且无需回放旧数据。


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测需要持续学习新方法，但现有检测器在学习新类型时常遭遇“灾难性遗忘”问题。虽然Kolmogorov-Arnold Networks (KANs) 因其局部可塑性理论上适合处理此问题，但其难以有效处理高维图像，且在持续学习中存在不同领域特征映射区域重叠导致模型崩溃的局限性。

Method: 本文提出KAN-CFD (KAN-based Continual Face Forgery Detection) 框架，包含两大部分：
1. 域组KAN检测器 (DG-KD)：使KAN能够处理高维图像输入，同时保持其局部性和局部可塑性。
2. 无数据回放的特征分离策略 (FS-KDCP)：避免KAN的输入空间在持续学习中因不同域特征重叠而发生映射区域崩溃。

Result: 实验结果表明，所提出的KAN-CFD方法在性能上表现优越，并显著减少了灾难性遗忘。

Conclusion: KAN-CFD框架通过克服KAN处理高维图像和域特征重叠的限制，为持续人脸伪造检测中的灾难性遗忘问题提供了一个有效且新颖的解决方案。

Abstract: The rapid advancements in face forgery techniques necessitate that detectors
continuously adapt to new forgery methods, thus situating face forgery
detection within a continual learning paradigm. However, when detectors learn
new forgery types, their performance on previous types often degrades rapidly,
a phenomenon known as catastrophic forgetting. Kolmogorov-Arnold Networks
(KANs) utilize locally plastic splines as their activation functions, enabling
them to learn new tasks by modifying only local regions of the functions while
leaving other areas unaffected. Therefore, they are naturally suitable for
addressing catastrophic forgetting. However, KANs have two significant
limitations: 1) the splines are ineffective for modeling high-dimensional
images, while alternative activation functions that are suitable for images
lack the essential property of locality; 2) in continual learning, when
features from different domains overlap, the mapping of different domains to
distinct curve regions always collapses due to repeated modifications of the
same regions. In this paper, we propose a KAN-based Continual Face Forgery
Detection (KAN-CFD) framework, which includes a Domain-Group KAN Detector
(DG-KD) and a data-free replay Feature Separation strategy via KAN Drift
Compensation Projection (FS-KDCP). DG-KD enables KANs to fit high-dimensional
image inputs while preserving locality and local plasticity. FS-KDCP avoids the
overlap of the KAN input spaces without using data from prior tasks.
Experimental results demonstrate that the proposed method achieves superior
performance while notably reducing forgetting.

</details>


### [101] [Neovascularization Segmentation via a Multilateral Interaction-Enhanced Graph Convolutional Network](https://arxiv.org/abs/2508.03197)
*Tao Chen,Dan Zhang,Da Chen,Huazhu Fu,Kai Jin,Shanshan Wang,Laurent D. Cohen,Yitian Zhao,Quanyong Yi,Jiong Zhang*

Main category: cs.CV

TL;DR: 本文构建了首个公开的脉络膜新生血管（CNV）数据集CNVSeg，并提出了MTG-Net（一种多边图卷积交互增强网络），用于OCTA图像中CNV区域和血管的精确分割，在性能上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 脉络膜新生血管（CNV）是湿性年龄相关性黄斑变性（湿性AMD）的主要特征，导致全球失明。OCTA图像中CNV区域和血管的准确分割对临床评估至关重要。然而，CNV形状不规则、图像存在伪影、噪声和边界模糊等问题，且缺乏公开数据集，给精确分割带来了挑战。

Method: 为解决上述挑战，研究构建了首个公开的CNV数据集CNVSeg。提出了一种新颖的多边图卷积交互增强CNV分割网络（MTG-Net）。该网络整合了区域和血管的形态信息，探索图域中的语义和几何对偶约束。MTG-Net包含一个多任务框架（编码病灶几何特征）以及两个基于图的跨任务模块：多边交互图推理（MIGR）和多边强化图推理（MRGR），通过图机制迭代推理任务间高阶关系。此外，还引入了不确定性加权损失以减轻伪影和噪声的影响。

Result: 实验结果表明，MTG-Net优于现有方法，在区域分割上Dice分数达到87.21%，在血管分割上达到88.12%。

Conclusion: 本研究通过提供公共数据集和先进的分割网络MTG-Net，显著提升了OCTA图像中CNV区域和血管的分割精度，为湿性AMD的临床评估提供了有力支持。

Abstract: Choroidal neovascularization (CNV), a primary characteristic of wet
age-related macular degeneration (wet AMD), represents a leading cause of
blindness worldwide. In clinical practice, optical coherence tomography
angiography (OCTA) is commonly used for studying CNV-related pathological
changes, due to its micron-level resolution and non-invasive nature. Thus,
accurate segmentation of CNV regions and vessels in OCTA images is crucial for
clinical assessment of wet AMD. However, challenges existed due to irregular
CNV shapes and imaging limitations like projection artifacts, noises and
boundary blurring. Moreover, the lack of publicly available datasets
constraints the CNV analysis. To address these challenges, this paper
constructs the first publicly accessible CNV dataset (CNVSeg), and proposes a
novel multilateral graph convolutional interaction-enhanced CNV segmentation
network (MTG-Net). This network integrates both region and vessel morphological
information, exploring semantic and geometric duality constraints within the
graph domain. Specifically, MTG-Net consists of a multi-task framework and two
graph-based cross-task modules: Multilateral Interaction Graph Reasoning (MIGR)
and Multilateral Reinforcement Graph Reasoning (MRGR). The multi-task framework
encodes rich geometric features of lesion shapes and surfaces, decoupling the
image into three task-specific feature maps. MIGR and MRGR iteratively reason
about higher-order relationships across tasks through a graph mechanism,
enabling complementary optimization for task-specific objectives. Additionally,
an uncertainty-weighted loss is proposed to mitigate the impact of artifacts
and noise on segmentation accuracy. Experimental results demonstrate that
MTG-Net outperforms existing methods, achieving a Dice socre of 87.21\% for
region segmentation and 88.12\% for vessel segmentation.

</details>


### [102] [AlignCAT: Visual-Linguistic Alignment of Category and Attributefor Weakly Supervised Visual Grounding](https://arxiv.org/abs/2508.03201)
*Yidan Wang,Chenyi Zhuang,Wutao Liu,Pan Gao,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出AlignCAT框架，通过粗粒度与细粒度对齐模块，增强弱监督视觉定位中的视觉-语言匹配能力，解决类别和属性歧义问题，并取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视觉定位方法在区分文本描述中细微语义差异时存在不足，主要源于类别和属性的歧义，导致跨模态推理能力弱。

Method: 引入AlignCAT，一个新颖的基于查询的语义匹配框架。它包含：1. 粗粒度对齐模块：利用类别信息和全局上下文，减少类别不一致对象的干扰。2. 细粒度对齐模块：利用描述信息和词级文本特征，实现属性一致性。该框架通过充分利用语言线索，逐步过滤错位视觉查询并提高对比学习效率。

Result: AlignCAT在RefCOCO、RefCOCO+和RefCOCOg三个视觉定位基准数据集的两项任务中，均展现出优于现有弱监督方法的性能。

Conclusion: AlignCAT通过其独特的多粒度对齐机制，有效解决了弱监督视觉定位中因类别和属性歧义导致的语义匹配挑战，显著提升了模型性能。

Abstract: Weakly supervised visual grounding (VG) aims to locate objects in images
based on text descriptions. Despite significant progress, existing methods lack
strong cross-modal reasoning to distinguish subtle semantic differences in text
expressions due to category-based and attribute-based ambiguity. To address
these challenges, we introduce AlignCAT, a novel query-based semantic matching
framework for weakly supervised VG. To enhance visual-linguistic alignment, we
propose a coarse-grained alignment module that utilizes category information
and global context, effectively mitigating interference from
category-inconsistent objects. Subsequently, a fine-grained alignment module
leverages descriptive information and captures word-level text features to
achieve attribute consistency. By exploiting linguistic cues to their fullest
extent, our proposed AlignCAT progressively filters out misaligned visual
queries and enhances contrastive learning efficiency. Extensive experiments on
three VG benchmarks, namely RefCOCO, RefCOCO+, and RefCOCOg, verify the
superiority of AlignCAT against existing weakly supervised methods on two VG
tasks. Our code is available at: https://github.com/I2-Multimedia-Lab/AlignCAT.

</details>


### [103] [Open-Vocabulary HOI Detection with Interaction-aware Prompt and Concept Calibration](https://arxiv.org/abs/2508.03207)
*Ting Lei,Shaofeng Yin,Qingchao Chen,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 针对开放词汇人-物交互（HOI）检测中视觉-语言模型（VLM）的挑战，本文提出INP-CC模型，通过交互感知提示和概念校准，显著超越现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 当前开放词汇HOI检测方法依赖VLMs，但存在两大挑战：1. 图像编码器次优，因图像级预训练与HOI所需的细粒度区域级检测不匹配；2. 难以有效编码视觉外观的文本描述，限制了模型捕获详细HOI关系的能力。

Method: 提出端到端开放词汇HOI检测器INteraction-aware Prompting with Concept Calibration (INP-CC)。具体方法包括：1. 交互感知提示生成器，根据输入场景动态生成提示，关注关键交互模式；2. 语言模型引导的概念校准，通过视觉相似性优化HOI概念表示；3. 负采样策略，改进模态间相似性建模，区分视觉相似但语义不同的动作。

Result: 在SWIG-HOI和HICO-DET数据集上，INP-CC显著优于现有最先进的模型。

Conclusion: INP-CC通过改进细粒度特征学习和概念表示，有效解决了开放词汇HOI检测的挑战，达到了优异的性能。

Abstract: Open Vocabulary Human-Object Interaction (HOI) detection aims to detect
interactions between humans and objects while generalizing to novel interaction
classes beyond the training set. Current methods often rely on Vision and
Language Models (VLMs) but face challenges due to suboptimal image encoders, as
image-level pre-training does not align well with the fine-grained region-level
interaction detection required for HOI. Additionally, effectively encoding
textual descriptions of visual appearances remains difficult, limiting the
model's ability to capture detailed HOI relationships. To address these issues,
we propose INteraction-aware Prompting with Concept Calibration (INP-CC), an
end-to-end open-vocabulary HOI detector that integrates interaction-aware
prompts and concept calibration. Specifically, we propose an interaction-aware
prompt generator that dynamically generates a compact set of prompts based on
the input scene, enabling selective sharing among similar interactions. This
approach directs the model's attention to key interaction patterns rather than
generic image-level semantics, enhancing HOI detection. Furthermore, we refine
HOI concept representations through language model-guided calibration, which
helps distinguish diverse HOI concepts by investigating visual similarities
across categories. A negative sampling strategy is also employed to improve
inter-modal similarity modeling, enabling the model to better differentiate
visually similar but semantically distinct actions. Extensive experimental
results demonstrate that INP-CC significantly outperforms state-of-the-art
models on the SWIG-HOI and HICO-DET datasets. Code is available at
https://github.com/ltttpku/INP-CC.

</details>


### [104] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
*Chengyu Bai,Yuming Li,Zhongyu Zhao,Jintao Chen,Peidong Jia,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastInit提出了一种无需迭代的快速噪声初始化方法，通过学习VNPNet在单次前向传递中生成细化噪声，显著提升了视频生成的时间一致性和效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频生成中取得了进展，但高时间一致性仍是挑战。现有方法如FreeInit通过迭代细化改善一致性，但计算成本高昂，存在训练与推理之间的差距。

Method: 本文提出了FastInit，一种快速噪声初始化方法，旨在消除迭代细化需求。它学习一个视频噪声预测网络（VNPNet），以随机噪声和文本提示为输入，在单次前向传递中生成细化噪声。为训练VNPNet，作者创建了一个包含文本提示、随机噪声和细化噪声对的大规模数据集。

Result: 对各种文本到视频模型进行的广泛实验表明，FastInit持续提高了生成视频的质量和时间一致性。

Conclusion: FastInit不仅显著改善了视频生成效果，还提供了一个可在推理阶段直接应用的实用解决方案，有效解决了视频生成的时间一致性和效率问题。

Abstract: Video generation has made significant strides with the development of
diffusion models; however, achieving high temporal consistency remains a
challenging task. Recently, FreeInit identified a training-inference gap and
introduced a method to iteratively refine the initial noise during inference.
However, iterative refinement significantly increases the computational cost
associated with video generation. In this paper, we introduce FastInit, a fast
noise initialization method that eliminates the need for iterative refinement.
FastInit learns a Video Noise Prediction Network (VNPNet) that takes random
noise and a text prompt as input, generating refined noise in a single forward
pass. Therefore, FastInit greatly enhances the efficiency of video generation
while achieving high temporal consistency across frames. To train the VNPNet,
we create a large-scale dataset consisting of pairs of text prompts, random
noise, and refined noise. Extensive experiments with various text-to-video
models show that our method consistently improves the quality and temporal
consistency of the generated videos. FastInit not only provides a substantial
improvement in video generation but also offers a practical solution that can
be applied directly during inference. The code and dataset will be released.

</details>


### [105] [GeoShield: Safeguarding Geolocation Privacy from Vision-Language Models via Adversarial Perturbations](https://arxiv.org/abs/2508.03209)
*Xinwei Liu,Xiaojun Jia,Yuan Xun,Simeng Qin,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出GeoShield框架，利用对抗性扰动保护用户地理隐私，防止先进视觉语言模型通过图像推断位置。


<details>
  <summary>Details</summary>
Motivation: 先进视觉语言模型（如GPT-4o）能从公开图像推断用户位置，对地理隐私构成重大风险。现有对抗性防御方法在高分辨率图像和低扰动预算下表现不佳，且可能引入无关语义内容，因此需要更鲁棒的解决方案。

Method: 本文提出了GeoShield，一个新颖的对抗性框架，旨在实现真实世界场景中的地理隐私保护。GeoShield包含三个核心模块：特征解耦模块（分离地理和非地理信息）、暴露元素识别模块（识别图像中泄露地理位置的区域）和尺度自适应增强模块（在全局和局部层面共同优化扰动，确保跨分辨率的有效性）。

Result: 在具有挑战性的基准测试中进行的大量实验表明，GeoShield在黑盒设置下持续超越现有方法，在实现强大隐私保护的同时，对视觉和语义质量的影响最小。

Conclusion: 该工作首次探索了利用对抗性扰动来防御先进视觉语言模型的地理位置推断，为日益增长的隐私担忧提供了一个实用且有效的解决方案。

Abstract: Vision-Language Models (VLMs) such as GPT-4o now demonstrate a remarkable
ability to infer users' locations from public shared images, posing a
substantial risk to geoprivacy. Although adversarial perturbations offer a
potential defense, current methods are ill-suited for this scenario: they often
perform poorly on high-resolution images and low perturbation budgets, and may
introduce irrelevant semantic content. To address these limitations, we propose
GeoShield, a novel adversarial framework designed for robust geoprivacy
protection in real-world scenarios. GeoShield comprises three key modules: a
feature disentanglement module that separates geographical and non-geographical
information, an exposure element identification module that pinpoints
geo-revealing regions within an image, and a scale-adaptive enhancement module
that jointly optimizes perturbations at both global and local levels to ensure
effectiveness across resolutions. Extensive experiments on challenging
benchmarks show that GeoShield consistently surpasses prior methods in
black-box settings, achieving strong privacy protection with minimal impact on
visual or semantic quality. To our knowledge, this work is the first to explore
adversarial perturbations for defending against geolocation inference by
advanced VLMs, providing a practical and effective solution to escalating
privacy concerns.

</details>


### [106] [The Power of Many: Synergistic Unification of Diverse Augmentations for Efficient Adversarial Robustness](https://arxiv.org/abs/2508.03213)
*Wang Yu-Hang,Shiwei Li,Jianxiang Liao,Li Bohan,Jian Liu,Wenfei Yin*

Main category: cs.CV

TL;DR: 论文提出通用对抗性增强器（UAA）框架，通过离线预计算通用变换实现高效且鲁棒的对抗性防御，并在多个基准测试上达到基于数据增强方法的SOTA。


<details>
  <summary>Details</summary>
Motivation: 对抗性扰动对深度学习模型构成重大威胁。主流防御方法（对抗训练）计算成本高且会降低标准性能。现有数据增强技术在提升鲁棒性方面效果有限或训练开销大。因此，开发一种高效且鲁棒的防御机制至关重要。

Method: 首先系统分析现有数据增强技术，发现多种策略协同作用对提升鲁棒性至关重要。基于此，提出通用对抗性增强器（UAA）框架。UAA通过离线预计算通用变换，将耗时的扰动生成过程与模型训练解耦，从而在训练期间高效地为每个样本生成独特的对抗性扰动。

Result: 在多个基准测试上，UAA验证了其有效性。实验结果表明，UAA在基于数据增强的对抗性防御策略中达到了新的最先进水平（SOTA），且无需在训练过程中在线生成对抗性样本。

Conclusion: UAA框架为构建鲁棒模型提供了一种实用且高效的途径。

Abstract: Adversarial perturbations pose a significant threat to deep learning models.
Adversarial Training (AT), the predominant defense method, faces challenges of
high computational costs and a degradation in standard performance. While data
augmentation offers an alternative path, existing techniques either yield
limited robustness gains or incur substantial training overhead. Therefore,
developing a defense mechanism that is both highly efficient and strongly
robust is of paramount importance.In this work, we first conduct a systematic
analysis of existing augmentation techniques, revealing that the synergy among
diverse strategies -- rather than any single method -- is crucial for enhancing
robustness. Based on this insight, we propose the Universal Adversarial
Augmenter (UAA) framework, which is characterized by its plug-and-play nature
and training efficiency. UAA decouples the expensive perturbation generation
process from model training by pre-computing a universal transformation
offline, which is then used to efficiently generate unique adversarial
perturbations for each sample during training.Extensive experiments conducted
on multiple benchmarks validate the effectiveness of UAA. The results
demonstrate that UAA establishes a new state-of-the-art (SOTA) for
data-augmentation-based adversarial defense strategies , without requiring the
online generation of adversarial examples during training. This framework
provides a practical and efficient pathway for building robust models,Our code
is available in the supplementary materials.

</details>


### [107] [ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow](https://arxiv.org/abs/2508.03218)
*Shanshan Guo,Xiwen Liang,Junfan Lin,Yuzheng Zhuang,Liang Lin,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出了一种名为ActionSink的机器人操作框架，通过将机器人动作重新表述为“动作流”（action flow）并进行自监督学习和迭代整合，显著提升了低层动作估计的精度，从而改善了机器人的操作性能。


<details>
  <summary>Details</summary>
Motivation: 在语言指令机器人操作中，尽管高层感知和规划问题已随大型预训练模型的发展得到解决，但低层动作估计的精度不足已成为限制操作性能的关键因素。

Method: ActionSink框架将机器人动作重新定义为视频中的“动作流”（action-caused optical flows），并采用自监督学习方式。该框架包含两个核心模块：1. 粗到精的动作流匹配器，通过迭代检索和去噪持续优化动作流精度。2. 动态动作流整合器，利用工作记忆池有效管理历史动作流，并通过多层融合模块整合直接估计与当前及记忆中的动作流，以实现高精度动作估计。

Result: ActionSink框架在LIBERO基准测试上将成功率提高了7.9%，并在具有挑战性的长时程视觉任务LIBERO-Long上获得了近8%的精度提升，超越了先前的SOTA方法。

Conclusion: ActionSink为学习型机器人操作中的精确动作估计开辟了新途径，通过创新的动作流建模和整合方法，显著提升了机器人在复杂任务中的操作精度和性能。

Abstract: Language-instructed robot manipulation has garnered significant interest due
to the potential of learning from collected data. While the challenges in
high-level perception and planning are continually addressed along the progress
of general large pre-trained models, the low precision of low-level action
estimation has emerged as the key limiting factor in manipulation performance.
To this end, this paper introduces a novel robot manipulation framework, i.e.,
ActionSink, to pave the way toward precise action estimations in the field of
learning-based robot manipulation. As the name suggests, ActionSink
reformulates the actions of robots as action-caused optical flows from videos,
called "action flow", in a self-supervised manner, which are then used to be
retrieved and integrated to enhance the action estimation. Specifically,
ActionSink incorporates two primary modules. The first module is a
coarse-to-fine action flow matcher, which continuously refines the accuracy of
action flow via iterative retrieval and denoising process. The second module is
a dynamic action flow integrator, which employs a working memory pool that
dynamically and efficiently manages the historical action flows that should be
used to integrate to enhance the current action estimation. In this module, a
multi-layer fusion module is proposed to integrate direct estimation and action
flows from both the current and the working memory, achieving highly accurate
action estimation through a series of estimation-integration processes. Our
ActionSink framework outperformed prior SOTA on the LIBERO benchmark by a 7.9\%
success rate, and obtained nearly an 8\% accuracy gain on the challenging
long-horizon visual task LIBERO-Long.

</details>


### [108] [Trace3D: Consistent Segmentation Lifting via Gaussian Instance Tracing](https://arxiv.org/abs/2508.03227)
*Hongyu Shen,Junfeng Ni,Yixin Chen,Weishuo Li,Mingtao Pei,Siyuan Huang*

Main category: cs.CV

TL;DR: 本文提出高斯实例追踪（GIT）方法，通过引入实例权重矩阵和自适应密度控制，解决了高斯飞溅中2D到3D分割存在的视图不一致和边界噪声问题，实现了更清晰的3D资产和一致的3D分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将2D视觉分割提升到3D高斯飞溅时，常面临跨视点2D掩码不一致和分割边界噪声的问题，原因是它们忽略了语义线索来优化高斯。

Method: 1. 引入高斯实例追踪（Gaussian Instance Tracing, GIT），通过在标准高斯表示中增加一个跨输入视图的实例权重矩阵。
2. 利用3D高斯的固有一致性，使用该矩阵识别并纠正2D分割的不一致性。
3. 提出一种GIT引导的自适应密度控制机制，在训练期间分裂和修剪模糊的高斯，以获得更清晰的分割边界。

Result: 实验结果表明，我们的方法能够提取出清晰的3D资产，并在在线（如自提示）和离线（如对比提升）设置中持续改进3D分割效果，生成了更清晰、更连贯的2D和3D分割边界。

Conclusion: 所提出的GIT方法有效解决了2D到3D分割中的一致性和边界噪声问题，显著提升了3D分割质量，并支持分层分割、对象提取和场景编辑等多种应用。

Abstract: We address the challenge of lifting 2D visual segmentation to 3D in Gaussian
Splatting. Existing methods often suffer from inconsistent 2D masks across
viewpoints and produce noisy segmentation boundaries as they neglect these
semantic cues to refine the learned Gaussians. To overcome this, we introduce
Gaussian Instance Tracing (GIT), which augments the standard Gaussian
representation with an instance weight matrix across input views. Leveraging
the inherent consistency of Gaussians in 3D, we use this matrix to identify and
correct 2D segmentation inconsistencies. Furthermore, since each Gaussian
ideally corresponds to a single object, we propose a GIT-guided adaptive
density control mechanism to split and prune ambiguous Gaussians during
training, resulting in sharper and more coherent 2D and 3D segmentation
boundaries. Experimental results show that our method extracts clean 3D assets
and consistently improves 3D segmentation in both online (e.g., self-prompting)
and offline (e.g., contrastive lifting) settings, enabling applications such as
hierarchical segmentation, object extraction, and scene editing.

</details>


### [109] [Zero-shot Shape Classification of Nanoparticles in SEM Images using Vision Foundation Models](https://arxiv.org/abs/2508.03235)
*Freida Barnatan,Emunah Goldstein,Einav Kalimian,Orchen Madar,Avi Huri,David Zitoun,Ya'akov Mandelbaum,Moshe Amitay*

Main category: cs.CV

TL;DR: 提出一种利用SAM和DINOv2基础模型对SEM图像中纳米颗粒形态进行零样本分类的高效管道，优于传统深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 准确高效的纳米颗粒形态表征对产品质量和研发至关重要，但传统深度学习方法因需要大量标注数据和计算资源而限制了其可及性。

Method: 本研究引入了一种零样本分类流程，利用SAM进行目标分割和DINOv2进行特征嵌入，并结合轻量级分类器，无需大量参数微调即可实现高精度形态分类。此外，还通过DINOv2特征的PCA图聚类评估了化学合成进展。

Result: 该方法在三个形态多样的纳米颗粒数据集上实现了高精度形态分类，性能优于微调后的YOLOv11和ChatGPT o4-mini-high基线，并展示了对小数据集、细微形态变化和域迁移的鲁棒性。

Conclusion: 本工作强调了基础模型在推动自动化显微图像分析方面的潜力，为纳米颗粒研究中的传统深度学习管道提供了一种更高效、更易于用户使用的新选择。

Abstract: Accurate and efficient characterization of nanoparticle morphology in
Scanning Electron Microscopy (SEM) images is critical for ensuring product
quality in nanomaterial synthesis and accelerating development. However,
conventional deep learning methods for shape classification require extensive
labeled datasets and computationally demanding training, limiting their
accessibility to the typical nanoparticle practitioner in research and
industrial settings. In this study, we introduce a zero-shot classification
pipeline that leverages two vision foundation models: the Segment Anything
Model (SAM) for object segmentation and DINOv2 for feature embedding. By
combining these models with a lightweight classifier, we achieve high-precision
shape classification across three morphologically diverse nanoparticle datasets
- without the need for extensive parameter fine-tuning. Our methodology
outperforms a fine-tuned YOLOv11 and ChatGPT o4-mini-high baselines,
demonstrating robustness to small datasets, subtle morphological variations,
and domain shifts from natural to scientific imaging. Quantitative clustering
metrics on PCA plots of the DINOv2 features are discussed as a means of
assessing the progress of the chemical synthesis. This work highlights the
potential of foundation models to advance automated microscopy image analysis,
offering an alternative to traditional deep learning pipelines in nanoparticle
research which is both more efficient and more accessible to the user.

</details>


### [110] [FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles](https://arxiv.org/abs/2508.03241)
*Xingchao Yang,Shiori Ueda,Yuantian Huang,Tomoya Akiyama,Takafumi Taketomi*

Main category: cs.CV

TL;DR: 该研究提出了FFHQ-Makeup，一个高质量合成裸妆-化妆配对图像数据集，旨在解决美容相关任务中缺乏此类数据的挑战。


<details>
  <summary>Details</summary>
Motivation: 配对的裸妆-化妆面部图像对于虚拟试妆、面部隐私保护和面部美学分析等美容任务至关重要。然而，收集大规模高质量真实世界配对数据极具挑战，而现有合成方法常面临真实性不足或裸妆与化妆图像之间一致性差（如扭曲面部几何、改变身份/表情）的问题。

Method: 该工作基于FFHQ数据集构建了FFHQ-Makeup。其核心方法是引入一种改进的妆容迁移技术，该技术能够解耦身份和妆容，从而将现有数据集中的真实世界妆容风格迁移到18K个FFHQ身份上，同时保持面部身份和表情的一致性。

Result: 通过将每个身份与5种不同妆容风格配对，共生成了90K个高质量裸妆-化妆图像对。该数据集在保证面部一致性的同时，提供了丰富的裸妆与化妆配对图像。

Conclusion: FFHQ-Makeup是首个专门针对构建妆容数据集的工作，旨在填补高质量裸妆-化妆配对数据集的空白，并期望成为未来美容相关研究的宝贵资源。

Abstract: Paired bare-makeup facial images are essential for a wide range of
beauty-related tasks, such as virtual try-on, facial privacy protection, and
facial aesthetics analysis. However, collecting high-quality paired makeup
datasets remains a significant challenge. Real-world data acquisition is
constrained by the difficulty of collecting large-scale paired images, while
existing synthetic approaches often suffer from limited realism or
inconsistencies between bare and makeup images. Current synthetic methods
typically fall into two categories: warping-based transformations, which often
distort facial geometry and compromise the precision of makeup; and
text-to-image generation, which tends to alter facial identity and expression,
undermining consistency. In this work, we present FFHQ-Makeup, a high-quality
synthetic makeup dataset that pairs each identity with multiple makeup styles
while preserving facial consistency in both identity and expression. Built upon
the diverse FFHQ dataset, our pipeline transfers real-world makeup styles from
existing datasets onto 18K identities by introducing an improved makeup
transfer method that disentangles identity and makeup. Each identity is paired
with 5 different makeup styles, resulting in a total of 90K high-quality
bare-makeup image pairs. To the best of our knowledge, this is the first work
that focuses specifically on constructing a makeup dataset. We hope that
FFHQ-Makeup fills the gap of lacking high-quality bare-makeup paired datasets
and serves as a valuable resource for future research in beauty-related tasks.

</details>


### [111] [MVTOP: Multi-View Transformer-based Object Pose-Estimation](https://arxiv.org/abs/2508.03243)
*Lukas Ranftl,Felix Brendel,Bertram Drost,Carsten Steger*

Main category: cs.CV

TL;DR: MVTOP是一种新型的基于Transformer的多视角刚性物体姿态估计方法，通过早期特征融合和视线几何建模，有效解决传统单视角或后处理方法无法处理的姿态模糊问题，实现端到端训练并展现卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有单视角或后处理方法无法可靠地解决多视角场景中存在的姿态模糊问题，需要一种能够通过整体多视角信息来有效处理这些模糊的鲁棒方法。

Method: 提出MVTOP，一种基于Transformer的多视角刚性物体姿态估计方法。通过早期融合视角特定特征来解决姿态模糊。利用从各相机中心发出的视线来建模多视角几何。该方法假定相机内参和相对方向已知但每次推理可变，增强了通用性。模型支持端到端训练，且无需额外的深度等数据。

Result: 在为解决姿态模糊而创建的合成数据集上，MVTOP的性能超越了所有单视角和现有多视角方法。在YCB-V数据集上也取得了有竞争力的结果。研究证明MVTOP能够通过融合多视角信息准确预测正确姿态，有效解决了姿态模糊问题。

Conclusion: MVTOP是一种有效且通用的多视角姿态估计算法，能够可靠地解决传统方法无法处理的姿态模糊问题，填补了该领域缺乏可靠的整体多视角方法的空白。

Abstract: We present MVTOP, a novel transformer-based method for multi-view rigid
object pose estimation. Through an early fusion of the view-specific features,
our method can resolve pose ambiguities that would be impossible to solve with
a single view or with a post-processing of single-view poses. MVTOP models the
multi-view geometry via lines of sight that emanate from the respective camera
centers. While the method assumes the camera interior and relative orientations
are known for a particular scene, they can vary for each inference. This makes
the method versatile. The use of the lines of sight enables MVTOP to correctly
predict the correct pose with the merged multi-view information. To show the
model's capabilities, we provide a synthetic data set that can only be solved
with such holistic multi-view approaches since the poses in the dataset cannot
be solved with just one view. Our method outperforms single-view and all
existing multi-view approaches on our dataset and achieves competitive results
on the YCB-V dataset. To the best of our knowledge, no holistic multi-view
method exists that can resolve such pose ambiguities reliably. Our model is
end-to-end trainable and does not require any additional data, e.g., depth.

</details>


### [112] [Ultralight Polarity-Split Neuromorphic SNN for Event-Stream Super-Resolution](https://arxiv.org/abs/2508.03244)
*Chuanzhi Xu,Haoxian Zhou,Langyi Chen,Yuk Ying Chung,Qiang Qu*

Main category: cs.CV

TL;DR: 本文提出一种基于脉冲神经网络（SNN）的超轻量级事件相机超分辨率方法，旨在解决事件相机空间分辨率有限的问题，并实现资源受限设备上的实时部署。


<details>
  <summary>Details</summary>
Motivation: 事件相机虽拥有高时间分辨率、低延迟和高动态范围等优势，但其有限的空间分辨率限制了其在精细感知任务中的应用。

Method: 本研究提出一种基于SNN的超轻量级流式事件到事件超分辨率方法。为进一步减小模型尺寸，引入了新颖的“双前向极性分离事件编码”策略，通过共享SNN将正负事件分离处理。此外，提出了一种“可学习时空极性感知损失（LearnSTPLoss）”，利用可学习的不确定性权重自适应地平衡时间、空间和极性的一致性。

Result: 实验结果表明，该方法在多个数据集上取得了具有竞争力的超分辨率性能，同时显著减小了模型尺寸并缩短了推理时间。

Conclusion: 该方法的轻量化设计使其能够嵌入事件相机内部，或作为下游视觉任务的高效前端预处理模块使用。

Abstract: Event cameras offer unparalleled advantages such as high temporal resolution,
low latency, and high dynamic range. However, their limited spatial resolution
poses challenges for fine-grained perception tasks. In this work, we propose an
ultra-lightweight, stream-based event-to-event super-resolution method based on
Spiking Neural Networks (SNNs), designed for real-time deployment on
resource-constrained devices. To further reduce model size, we introduce a
novel Dual-Forward Polarity-Split Event Encoding strategy that decouples
positive and negative events into separate forward paths through a shared SNN.
Furthermore, we propose a Learnable Spatio-temporal Polarity-aware Loss
(LearnSTPLoss) that adaptively balances temporal, spatial, and polarity
consistency using learnable uncertainty-based weights. Experimental results
demonstrate that our method achieves competitive super-resolution performance
on multiple datasets while significantly reducing model size and inference
time. The lightweight design enables embedding the module into event cameras or
using it as an efficient front-end preprocessing for downstream vision tasks.

</details>


### [113] [Robust Single-Stage Fully Sparse 3D Object Detection via Detachable Latent Diffusion](https://arxiv.org/abs/2508.03252)
*Wentao Qu,Guofeng Mei,Jing Wang,Yujiao Wu,Xiaoshui Huang,Liang Xiao*

Main category: cs.CV

TL;DR: RSDNet是一种基于可分离潜在框架DDPM的单阶段、全稀疏3D目标检测网络，通过在潜在空间去噪、重构DDPM机制和引入语义几何引导，实现了鲁棒高效的3D检测，并达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于DDPMs的3D目标检测方法虽然鲁棒，但在推理时通常需要多步迭代，这限制了其效率。

Method: 本文提出了RSDNet，一个鲁棒的单阶段全稀疏3D目标检测网络，其核心是DDPMs的可分离潜在框架（DLF）。RSDNet通过轻量级去噪网络（如多层去噪自编码器）在潜在特征空间学习去噪过程，以理解多级扰动下的场景分布。该方法还重新制定了DDPMs的加噪和去噪机制，使其能构建多类型、多级噪声样本和目标，增强鲁棒性。此外，引入了语义-几何条件引导来感知物体边界和形状，解决了稀疏表示中中心特征缺失的问题。DLF的可分离去噪网络设计使得RSDNet能进行单步推理，提升了检测效率。

Result: 在公共基准测试中的大量实验表明，RSDNet的性能优于现有方法，实现了最先进的3D目标检测。

Conclusion: RSDNet通过其创新的DLF和多项改进，成功解决了现有DDPMs在3D检测中的效率问题，并实现了鲁棒、高效且性能卓越的单阶段、全稀疏3D目标检测，达到了SOTA水平。

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have shown success in robust
3D object detection tasks. Existing methods often rely on the score matching
from 3D boxes or pre-trained diffusion priors. However, they typically require
multi-step iterations in inference, which limits efficiency. To address this,
we propose a \textbf{R}obust single-stage fully \textbf{S}parse 3D object
\textbf{D}etection \textbf{Net}work with a Detachable Latent Framework (DLF) of
DDPMs, named RSDNet. Specifically, RSDNet learns the denoising process in
latent feature spaces through lightweight denoising networks like multi-level
denoising autoencoders (DAEs). This enables RSDNet to effectively understand
scene distributions under multi-level perturbations, achieving robust and
reliable detection. Meanwhile, we reformulate the noising and denoising
mechanisms of DDPMs, enabling DLF to construct multi-type and multi-level noise
samples and targets, enhancing RSDNet robustness to multiple perturbations.
Furthermore, a semantic-geometric conditional guidance is introduced to
perceive the object boundaries and shapes, alleviating the center feature
missing problem in sparse representations, enabling RSDNet to perform in a
fully sparse detection pipeline. Moreover, the detachable denoising network
design of DLF enables RSDNet to perform single-step detection in inference,
further enhancing detection efficiency. Extensive experiments on public
benchmarks show that RSDNet can outperform existing methods, achieving
state-of-the-art detection.

</details>


### [114] [V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models](https://arxiv.org/abs/2508.03254)
*Jisoo Kim,Wooseok Seo,Junwan Kim,Seungho Park,Sooyeon Park,Youngjae Yu*

Main category: cs.CV

TL;DR: 本文提出ReDPO蒸馏方法（结合DPO和SFT）及V.I.P.高质量数据集构建框架，旨在高效剪枝文本到视频（T2V）模型，同时保持或超越原模型性能，以适应资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 文本到视频（T2V）模型计算成本高昂，难以在资源受限环境下部署。现有剪枝和知识蒸馏方法主要依赖监督微调（SFT），但由于容量受限的模型难以直接匹配教师模型输出，常导致模式崩溃和质量下降。

Method: 1. 提出ReDPO蒸馏方法，融合DPO和SFT：DPO引导学生模型专注于恢复目标属性而非被动模仿教师模型，SFT则增强整体性能。2. 提出V.I.P.框架，用于筛选和整理高质量配对数据集。3. 采用逐步在线校准训练方法。4. 在VideoCrafter2和AnimateDiff两种主流T2V模型上进行验证。

Result: 1. 成功将VideoCrafter2和AnimateDiff模型的参数分别减少36.2%和67.5%。2. 性能保持甚至超越了完整模型。3. 进一步实验证明ReDPO和V.I.P.框架能有效实现高效高质量的视频生成。

Conclusion: ReDPO蒸馏方法和V.I.P.数据集框架的结合，有效解决了T2V模型在资源受限环境下的部署挑战，通过大幅参数削减同时保持或提升生成质量，实现了高效且高质量的视频生成。

Abstract: With growing interest in deploying text-to-video (T2V) models in
resource-constrained environments, reducing their high computational cost has
become crucial, leading to extensive research on pruning and knowledge
distillation methods while maintaining performance. However, existing
distillation methods primarily rely on supervised fine-tuning (SFT), which
often leads to mode collapse as pruned models with reduced capacity fail to
directly match the teacher's outputs, ultimately resulting in degraded quality.
To address this challenge, we propose an effective distillation method, ReDPO,
that integrates DPO and SFT. Our approach leverages DPO to guide the student
model to focus on recovering only the targeted properties, rather than
passively imitating the teacher, while also utilizing SFT to enhance overall
performance. We additionally propose V.I.P., a novel framework for filtering
and curating high-quality pair datasets, along with a step-by-step online
approach for calibrated training. We validate our method on two leading T2V
models, VideoCrafter2 and AnimateDiff, achieving parameter reduction of 36.2%
and 67.5% each, while maintaining or even surpassing the performance of full
models. Further experiments demonstrate the effectiveness of both ReDPO and
V.I.P. framework in enabling efficient and high-quality video generation. Our
code and videos are available at https://jiiiisoo.github.io/VIP.github.io/.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [115] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 本文系统研究了大型语言模型（LLM）驱动代理系统的效率与效果权衡，旨在开发成本效益高且性能优秀的代理框架，并提出了"Efficient Agents"。


<details>
  <summary>Details</summary>
Motivation: LLM驱动代理系统虽然功能强大，但其高昂的运行成本限制了可扩展性和可及性。研究旨在解决如何在不牺牲性能的前提下，实现成本效益高的设计。

Method: 通过在GAIA基准上进行实证分析，评估了LLM骨干模型选择、代理框架设计和测试时扩展策略的影响。使用“通过成本”（cost-of-pass）指标量化效率-性能权衡。研究关注代理任务所需的复杂性、额外模块的边际效益以及高效框架设计的效率增益。

Result: 研究成果促成了“Efficient Agents”框架的开发。该框架在保留领先开源框架OWL 96.7%性能的同时，将运行成本从0.398美元降至0.228美元，使“通过成本”提高了28.4%。

Conclusion: 本工作为设计高效、高性能的代理系统提供了实用见解，有助于提升人工智能驱动解决方案的可及性和可持续性。

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [116] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: 本文提出了一种在动态对象集环境下，无需领域闭合假设（DCA）的有限长规划问题解决方法，并证明了其完备性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 经典的规划（包括一致性规划）通常依赖于领域闭合假设（DCA），即预设有限且固定的对象集。然而，实际规划问题中常遇到对象动态变化（创建或销毁）的情况，这使得DCA不再适用。

Method: 研究者将规划问题表述为一阶逻辑，假设初始理论为有限且一致的流利文字集。他们讨论了在何种条件下能确保在每种情境下只有有限多的可能动作，并对计划长度施加了有限整数边界。核心方法是组织对在规划时进行接地的动作序列的搜索。

Result: 该方法被证明是可靠且完备的。它能够解决属于序列广义规划（无感知动作）与一致性规划交集、且排除了流利文字析取情况的、没有DCA的有限规划问题。

Conclusion: 研究成功地提出了在对象集动态变化的场景下解决有限规划问题的方法，无需依赖领域闭合假设，并通过实验性实现验证了其可行性。

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [117] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: 提出VSNIT模型，用于从稀疏的位置服务数据中恢复不完整的个体活动序列。


<details>
  <summary>Details</summary>
Motivation: 位置服务（LBS）数据虽对人类移动性洞察至关重要，但其稀疏性导致出行和活动序列不完整，难以进行准确推断。研究旨在解决如何利用高质量LBS数据恢复个体层面的不完整活动序列这一问题。

Method: 本研究提出了一种名为“可变选择网络融合插入Transformer”（VSNIT）的新解决方案。该方案整合了Insertion Transformer的灵活序列构建能力和Variable Selection Network的动态协变量处理能力，旨在恢复不完整活动序列中缺失的部分，同时保留现有数据。

Result: 研究发现，VSNIT能够插入更多样化、更真实的活动模式，更紧密地匹配真实世界的变异性，并能更有效地恢复中断的活动转换，使其与目标对齐。此外，VSNIT在所有指标上均显著优于基线模型。

Conclusion: 这些结果突显了VSNIT在活动序列恢复任务中卓越的准确性和多样性，证明了其在增强LBS数据用于移动性分析方面的潜力。该方法为未来的基于位置的研究和应用提供了一个有前景的框架。

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [118] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: 这篇综述全面分析了应用于数据科学任务的基于大型语言模型（LLM）的智能体，从智能体设计和数据科学工作流的双重视角总结了最新研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的快速发展推动了跨领域的新应用，其中基于LLM的智能体成为一个关键的探索领域。本研究旨在对LLM智能体在数据科学任务中的应用进行系统性的梳理和分析。

Method: 本研究采用综述（survey）形式，对近期研究进行了全面分析。方法论上，采用了双重视角框架：1) 从智能体视角，讨论了关键设计原则，包括智能体角色、执行、知识和反思方法；2) 从数据科学视角，识别了LLM智能体在数据预处理、模型开发、评估和可视化等关键过程中的应用。

Result: 本工作提供了两项主要贡献：1) 全面回顾了LLM智能体应用于数据科学任务的最新进展；2) 提出了一个双重视角框架，将通用智能体设计原则与数据科学的实际工作流程联系起来。

Conclusion: 本综述通过全面的回顾和提出的双重视角框架，系统地整理了LLM智能体在数据科学领域的应用，为理解和进一步发展该领域提供了结构化分析。

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [119] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: 本文介绍了一种名为CLIO的新型AI方法，通过提供精确控制和透明度，显著提升了大型语言模型在科学问题推理方面的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在应用于科学发现时，无法为科学家提供所需的推理准确性、透明度及最重要的可控性。

Method: 引入了“认知循环原位优化（CLIO）”方法。该方法允许大型语言模型自我制定问题解决方法、根据不确定性调整行为，并提供最终答案。CLIO的开放设计使科学家能够观察不确定性、通过图结构理解信念形成过程并进行干预纠正。

Result: 结合CLIO的GPT-4.1在“人类的最后考试（HLE）”文本生物医学问题上取得了22.37%的准确率，相较于基础GPT-4.1模型，净提升了13.82%（或相对提升161.64%），并超越了OpenAI的o3性能。此外，研究发现内部不确定性测量的波动是CLIO结果准确性的关键决定因素。

Conclusion: CLIO的开放设计和内部机制为科学决策过程提供了深入的洞察和精确的控制，证明了其在科学发现中的巨大潜力。

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [120] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: 针对放射科视觉问答(RVQA)中的准确性与可靠性问题，本文提出了一种多智能体系统(MAS)，通过多智能体协作实现复杂推理，显著优于现有MLLM基线。


<details>
  <summary>Details</summary>
Motivation: 放射科视觉问答(RVQA)旨在通过回答胸部X光图像相关问题来减轻放射科医生的工作负担。然而，尽管当前基于多模态大语言模型(MLLM)和检索增强生成(RAG)的方法已取得进展，它们在事实准确性、幻觉和跨模态错位方面仍面临挑战。

Method: 引入了一个多智能体系统(MAS)，该系统包含专门的智能体，分别负责上下文理解、多模态推理和答案验证，以支持RVQA中的复杂推理。该系统在一个通过模型分歧过滤而精心策划的、包含多MLLM困难案例的挑战性RVQA数据集上进行评估。

Result: 广泛的实验表明，该系统在强大的MLLM基线上表现出卓越的性能和有效性。通过案例研究，进一步证明了其可靠性和可解释性。

Conclusion: 这项工作强调了多智能体方法在支持需要复杂推理的可解释且值得信赖的临床AI应用方面的巨大潜力。

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [121] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: 针对大模型长时规划能力不足且现有基准不佳的问题，本文提出了一种基于“Countdown”游戏的动态规划基准，并证明该基准对现有大语言模型（LLM）方法极具挑战性。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型和智能体的长时规划能力是其主要限制之一。然而，现有规划基准普遍不足以有效衡量其规划能力，它们要么定义松散难以验证，要么是为传统的自动化规划器设计，未能充分挑战大语言模型（LLM）的能力。

Method: 本文提出了一种围绕“Countdown”游戏创建规划基准的程序。该问题具有直观的自然语言描述，计算上具有挑战性（NP-完全），并且实例空间足够丰富以避免模型记忆。研究人员进行了广泛的理论分析，确立了计算复杂度结果，并展示了其实例生成程序相对于公共基准的优势。

Result: 研究团队评估了各种现有LLM辅助规划方法在他们生成的实例上的表现。结果表明，与24点游戏（Countdown的特例）等其他领域不同，本文提出的动态基准对现有基于LLM的方法而言仍然极具挑战性。

Conclusion: 所提出的基于Countdown游戏的新型规划基准成功地为评估当前LLM的规划能力提供了更严格、更真实的测试环境，揭示了它们在复杂规划任务中的局限性，有效弥补了现有规划基准的不足。

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [122] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: 主流LLM后训练效果好但日文LLM受资源限制难实现。本文受任务向量启发，从通用推理LLM中提取“推理向量”并应用于日文LLM，以简单有效的方式提升其性能。


<details>
  <summary>Details</summary>
Motivation: 主流大型语言模型（LLMs）通过后训练方法提升了性能和推理能力，但日文LLMs因所需资源巨大而难以实现同等提升。

Method: 受从训练前后权重变化中提取任务向量的启发，研究者从具有推理能力的LLMs中获取“推理向量”，并将其应用于日文LLMs以提升其性能。

Result: 尽管资源有限，该方法为日文LLMs提供了一种简单有效的方式，实现了显著的性能提升。

Conclusion: 该研究提供了一种简单、有效且资源友好的方法来改进日文LLMs，并有望为其他语言的LLMs改进提供启发。

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [123] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: PentestJudge是一个基于大型语言模型（LLM）的评估系统，用于判断渗透测试代理行为是否符合操作标准。该系统通过分层评分准则进行评估，并与人类专家对比，实现了0.83的F1分数。研究发现，验证渗透测试行为可能比生成行为更容易，且工具使用能力强的模型表现更佳。


<details>
  <summary>Details</summary>
Motivation: 由于传统编程方式难以评估渗透测试代理的复杂操作行为和特定标准，需要一种能够全面、可扩展地评估AI信息安全代理过程质量的方法，以确保它们能被自信地应用于敏感生产环境。

Method: 引入PentestJudge系统，该系统利用LLM作为判断器，通过分析代理的状态轨迹和工具调用历史进行评估。开发了树状分层评估规则，将复杂的渗透测试任务分解为简单的“是/否”判断，并分类为操作目标、操作安全和技艺。LLM的评估结果与人类领域专家进行比较，使用F1分数等标准指标来衡量其性能。

Result: 最佳模型的F1分数达到了0.83。研究发现，工具使用能力更强的模型其表现更接近人类专家。通过分层分析，发现不同模型在不同类型的评估问题上表现各异。此外，较弱且成本较低的模型能够有效判断由更强更昂贵模型执行的渗透测试轨迹，这表明对于渗透测试任务而言，验证可能比生成更容易。

Conclusion: 该研究提供了一种评估AI驱动信息安全代理过程质量的方法论，旨在促进未来的研究，使其能够被全面且可扩展地评估，从而在敏感生产环境中得到可靠应用。研究暗示了验证渗透测试行为的难度可能低于生成行为。

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [124] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: AQUAH是首个基于语言的端到端水文建模代理，它利用视觉增强型大语言模型，能从自然语言指令自动完成数据检索、模型配置、模拟运行，并生成水文报告。


<details>
  <summary>Details</summary>
Motivation: 简化复杂环境建模流程，降低地球观测数据、物理工具与决策者之间的壁垒，以解决当前水文建模中数据处理、模型配置和结果解释的人工依赖和复杂性。

Method: 引入AQUAH，一个由视觉增强型大型语言模型驱动的语言代理。该代理通过自然语言提示启动，自动检索地形、强迫和测量数据，配置水文模型，运行模拟，并生成PDF报告。视觉能力使LLM能够实时解释地图和栅格数据，并指导关键决策（如出口选择、参数初始化和不确定性评论）。

Result: 初步实验表明，AQUAH能在无需人工干预的情况下完成冷启动模拟，并生成分析师可用文档。水文学家评价其结果清晰、透明且符合物理规律。

Conclusion: AQUAH的早期成果展示了以LLM为中心、视觉为基础的代理在简化复杂环境建模方面的巨大潜力，有望弥合地球观测数据、物理工具与决策者之间的鸿沟，尽管仍需进一步校准和验证以实现操作部署。

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [125] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: 当前多模态语言模型在基础医学图像感知任务上表现不佳，急需加强其视觉基础能力以实现临床应用。


<details>
  <summary>Details</summary>
Motivation: 多模态语言模型虽在临床决策支持方面有前景，但若在图像方向、对比增强识别等简单感知任务上出错，将难以被临床医生采纳。因此，有必要评估其在这些基本感知能力上的表现。

Method: 引入Medblink基准测试，涵盖8项临床相关任务，涉及多种成像模式和解剖区域，包含1,429道多选题和1,605张图像。评估了19个最先进的多模态语言模型（包括通用型和领域特定型）。

Result: 人类标注者在Medblink上达到96.4%的准确率，而表现最佳的模型仅达到65%。这表明当前模型在常规感知检查中频繁出错。

Conclusion: 现有多模态语言模型在基础视觉感知方面存在明显不足，急需加强其视觉基础能力，方能支持其在临床环境中的广泛应用。

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [126] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: 本文提出Polymath，一个自优化智能体，通过动态分层工作流和无标注数据优化方法，解决了现有LLM工作流自动化方法对标注数据的依赖问题，在多种任务上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）擅长通过代理工作流解决复杂任务，但手动构建通用代理的效率和可扩展性受限。现有自动化工作流生成和优化方法普遍依赖标注数据集，这在缺乏标注数据的真实世界动态问题中是无效且不灵活的。

Method: 引入Polymath，一个自优化智能体，其核心是动态分层工作流，结合了任务流图的灵活性和代码表示工作流的表现力。其优化方法集成了一种多网格启发式图优化技术与自反思引导的进化算法，旨在无需标注数据的情况下优化和完善工作流。

Result: 在包括编码、数学和多轮问答在内的六个基准数据集上进行实验，Polymath相较于现有最先进的基线方法，平均性能提升了8.1%。

Conclusion: Polymath通过其创新的无标注数据自优化能力，有效克服了现有LLM工作流自动化方法的局限性，显著提高了LLM在处理广泛真实世界动态问题时的表现和适用性。

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [127] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 提出一种基于LLM自我意识的新型防御机制，以对抗提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部分类器，作者旨在利用大型语言模型（LLM）的内在推理能力，开发一种自保护机制来应对提示注入攻击。

Method: 引入包含元认知和仲裁模块的自我意识框架，使LLM能够自主评估和调节自身输出。在七个先进LLM模型及AdvBench、Prompt-Injection-Mixed-Techniques-2024两个数据集上进行评估。

Result: 实验表明，在不同模型和数据集上防御成功率显著提升，部分模型在增强模式下实现完美或接近完美的防御。研究还分析了防御成功率提升与计算开销的权衡。

Conclusion: 该自我意识方法为增强LLM伦理提供了一种轻量、经济高效的解决方案，对各类生成式AI应用尤其有益。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [128] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: 针对工具增强型LLM生态系统的碎片化问题，本文提出一种统一的、协议无关的工具集成方法，显著降低开发开销并提升执行性能。


<details>
  <summary>Details</summary>
Motivation: 当前工具增强型大语言模型（LLM）生态系统碎片化，开发者需要处理多种协议、手动模式定义和复杂的执行工作流，导致开发效率低下。

Method: 本文提出一种统一的工具集成方法，旨在抽象协议差异并优化执行性能。该方法通过实现自动化模式生成、双模式并发执行和无缝多源工具管理来降低开发开销。

Result: 实验结果显示，该方法在集成场景中可减少60-80%的代码量，通过优化的并发性实现高达3.1倍的性能提升，并与现有函数调用标准完全兼容。

Conclusion: 这项工作为工具集成架构提供了理论见解，并为现实世界中的LLM应用开发提供了实用的解决方案。

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [129] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: 本文综述了“智能体作为评判者”范式，探讨了利用AI智能体评估大型语言模型（LLMs）输出的演变、优缺点、应用及未来挑战，指出其能补充而非取代人类评估。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能力和自主性增强，评估其输出（尤其在开放复杂任务中）成为关键瓶颈。传统人工评估难以规模化且缺乏细致性，促使研究人员探索利用AI智能体自身作为评估者。

Method: 本文通过综述的方式，定义了“智能体作为评判者”概念，追溯了其从单模型评判到多智能体辩论框架的演变，批判性地分析了其优缺点。研究比较了不同方法的可靠性、成本和人类对齐度，并调查了其在医学、法律、金融、教育等领域的实际部署案例。最后，指出了当前面临的挑战并展望了未来研究方向。

Result: 研究展示了智能体作为评判者如何演进，具备了评估其他模型输出的推理和换位思考能力。其优势包括提供可扩展且细致的评估，能在特定领域进行实际部署。尽管存在偏见、鲁棒性等挑战，但它能有效辅助评估工作。

Conclusion: 智能体作为评判者是实现下一代LLMs可信、可扩展评估的重要一步，它可以有效补充（但不能完全取代）人类监督，有助于解决当前LLM评估的瓶颈问题。

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [130] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph是一个代理驱动的系统，使非技术用户能够通过自然语言直观地与知识图谱交互，进行多轮对话和动态更新，并在教育场景中展现了优异性能。


<details>
  <summary>Details</summary>
Motivation: 解决非技术用户在管理领域特定数据和构建知识库时面临的挑战，尤其是避免使用专业查询语言，提供一个完整的、可视化的解决方案。

Method: AGENTiGraph采用代理驱动设计，包含意图分类、任务规划和自动知识集成，以支持通过自然语言对知识图谱进行操作、多轮对话和动态更新。

Result: 在包含3500个查询的教育场景基准测试中，系统表现优于强大的零样本基线，分类准确率达到95.12%，执行成功率达到90.45%。

Conclusion: AGENTiGraph提供了一种强大的多轮企业知识管理新范式，有效地桥接了大型语言模型（LLMs）和结构化图谱，并显示出在法律和医疗等合规性关键领域的可扩展潜力。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [131] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: 提出BPO三阶段自改进框架，解决大型语言模型在稀疏奖励、长序列智能体规划中的信用分配与计算开销问题，实现SOTA性能和高token效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言推理模型在交互式多轮智能体规划中面临两大基本挑战：稀疏奖励下难以有效进行信用分配，以及详细推理历史带来过高的计算开销。

Method: 提出BPO三阶段框架（自举、外推、精炼），建立自改进数据飞轮。自举阶段通过规划四元数和长短思维链融合启动高效推理；外推阶段通过复杂性分层课程学习泛化到分布外任务；精炼阶段通过奖励门控拒绝采样选择经验进行迭代自我完善。

Result: 在ALFWorld、ScienceWorld和WebShop上的实验表明，该方法实现了最先进的性能，并显著提升了token效率。

Conclusion: BPO框架为智能体规划中的推理模型提供了一种新的有效范式，成功解决了现有大型语言模型在复杂交互环境应用中的核心挑战。

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [132] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: 本研究提出了一个名为Collab-Solver的新型多智能体策略学习框架，用于混合整数线性规划（MILP）。它通过将模块间的协作建模为Stackelberg博弈并采用两阶段学习范式，协同优化MILP求解器中不同模块（如切分选择和分支）的策略，显著提升了求解性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的MILP方法独立地处理各个求解模块的策略学习，忽视了它们之间的相互依赖性，这严重损害了求解速度和质量。研究动机在于解决这一关键问题，通过协同优化来提升性能。

Method: 提出了Collab-Solver，一个基于多智能体的MILP策略学习框架。该框架将MILP求解中的切分选择和分支的协作建模为Stackelberg博弈。在此建模下，开发了一个两阶段学习范式：第一阶段实现数据通信的策略预训练；第二阶段进一步协调各模块的策略学习。

Result: 通过Collab-Solver联合学习的策略显著提升了在合成数据集和大规模真实世界MILP数据集上的求解性能。此外，Collab-Solver学习到的策略在不同实例集上展示了出色的泛化能力。

Conclusion: Collab-Solver框架成功地通过协同优化解决了MILP求解器中模块策略独立学习的问题，从而大幅提升了MILP的求解性能，并展现了优秀的泛化能力，证明了考虑模块间相互依赖性的重要性与有效性。

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>


### [133] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
*Ziyang Ma,Baojian Zhou,Deqing Yang,Yanghua Xiao*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型（LLMs）在语境学习（ICL）设置下求解常微分方程（ODEs）的能力。结果表明，GPT-2模型能有效学习元ODE算法，其性能与传统方法相当或更优，并能泛化到分布外问题。


<details>
  <summary>Details</summary>
Motivation: 语境学习（ICL）在大型语言模型中展现出强大的能力，但其在自然语言处理任务中的高度非线性行为尚不明确。为深入理解ICL的底层机制，本文旨在探究LLMs是否能在ICL设置下求解常微分方程。

Method: 将标准的常微分方程问题及其解格式化为序列提示，并使用GPT-2模型在这些任务上进行评估。

Result: 实验发现，GPT-2模型能有效学习元ODE算法，其收敛行为与欧拉法相当或更优，且随着演示示例数量的增加，精度呈现指数级提升。此外，模型还能泛化到分布外（OOD）问题，展现出强大的外推能力。

Conclusion: 这些实证发现为理解ICL在自然语言处理中的机制及其解决非线性数值问题的潜力提供了新的见解。

Abstract: In-Context Learning (ICL) has emerged as a new paradigm in large language
models (LLMs), enabling them to perform novel tasks by conditioning on a few
examples embedded in the prompt. Yet, the highly nonlinear behavior of ICL for
NLP tasks remains poorly understood. To shed light on its underlying
mechanisms, this paper investigates whether LLMs can solve ordinary
differential equations (ODEs) under the ICL setting. We formulate standard ODE
problems and their solutions as sequential prompts and evaluate GPT-2 models on
these tasks. Experiments on two types of ODEs show that GPT-2 can effectively
learn a meta-ODE algorithm, with convergence behavior comparable to, or better
than, the Euler method, and achieve exponential accuracy gains with increasing
numbers of demonstrations. Moreover, the model generalizes to
out-of-distribution (OOD) problems, demonstrating robust extrapolation
capabilities. These empirical findings provide new insights into the mechanisms
of ICL in NLP and its potential for solving nonlinear numerical problems.

</details>


### [134] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
*Qi Peng,Jialin Cui,Jiayuan Xie,Yi Cai,Qing Li*

Main category: cs.AI

TL;DR: LLMs在复杂医疗诊断中推理深度不足导致错误，本文提出ToR多智能体框架，通过树形结构记录推理路径和交叉验证机制，有效提升了诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在处理复杂真实世界医疗诊断任务时表现不佳，主要原因是推理深度不足，导致处理大量专业医疗数据时信息丢失或逻辑跳跃，从而引发诊断错误。

Method: 提出Tree-of-Reasoning (ToR) 多智能体框架。该框架引入树形结构，清晰记录大型语言模型的推理路径和对应的临床证据；同时，提出交叉验证机制，确保多智能体决策的一致性，从而增强其在复杂医疗场景下的临床推理能力。

Result: 在真实世界医疗数据上的实验结果表明，所提出的框架比现有基线方法取得了更好的性能。

Conclusion: ToR框架通过提升LLMs的推理深度和决策一致性，有效解决了复杂医疗诊断中的挑战，并超越了现有方法，为医疗领域应用提供了新思路。

Abstract: Large language models (LLMs) have shown great potential in the medical
domain. However, existing models still fall short when faced with complex
medical diagnosis task in the real world. This is mainly because they lack
sufficient reasoning depth, which leads to information loss or logical jumps
when processing a large amount of specialized medical data, leading to
diagnostic errors. To address these challenges, we propose Tree-of-Reasoning
(ToR), a novel multi-agent framework designed to handle complex scenarios.
Specifically, ToR introduces a tree structure that can clearly record the
reasoning path of LLMs and the corresponding clinical evidence. At the same
time, we propose a cross-validation mechanism to ensure the consistency of
multi-agent decision-making, thereby improving the clinical reasoning ability
of multi-agents in complex medical scenarios. Experimental results on
real-world medical data show that our framework can achieve better performance
than existing baseline methods.

</details>


### [135] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
*Rui Pu,Chaozhuo Li,Rui Ha,Litian Zhang,Lirong Qiu,Xi Zhang*

Main category: cs.AI

TL;DR: 本文提出认知驱动防御（CDD）框架，通过模仿人类认知推理和结合强化学习，有效防御大语言模型（LLMs）的越狱攻击，并展现出对未知攻击的强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 保护大语言模型（LLMs）免受越狱攻击对于其安全可靠部署至关重要。现有防御方法多依赖浅层模式匹配，难以泛化到新颖和未见的攻击策略。

Method: 本文提出认知驱动防御（CDD）框架。CDD通过应用元操作（隐藏有害意图的基本操作）来针对越狱提示的底层结构，并模拟人类认知推理，包括全局感知和局部分析的结构化推理链。CDD利用监督微调学习识别和推理已知操纵模式，并引入熵引导强化学习算法（EG-GRPO）以鼓励探索新类型和变体的元操作，从而增强对未知威胁的泛化能力。

Result: 实验证明CDD能够实现最先进的防御性能，并对未见的越狱攻击表现出强大的泛化能力。

Conclusion: CDD框架通过其独特的认知驱动方法和强化学习机制，显著提升了LLMs抵御越狱攻击的能力，尤其在应对新型和未知威胁方面表现出色，有望促进LLMs的安全部署。

Abstract: Defending large language models (LLMs) against jailbreak attacks is essential
for their safe and reliable deployment. Existing defenses often rely on shallow
pattern matching, which struggles to generalize to novel and unseen attack
strategies. To address this challenge, we propose the Cognitive-Driven Defense
(CDD) framework, which targets the underlying structure of jailbreak prompts by
applying meta-operations, defined as basic manipulations that conceal harmful
intent.CDD emulates human cognitive reasoning through a structured reasoning
chain. It begins with a global perception of the prompt and follows with a
localized analysis to uncover hidden manipulations. By applying supervised
fine-tuning on this structured chain, the model learns to identify and reason
about known manipulation patterns. To enhance generalization to unseen threats,
an entropy-guided reinforcement learning algorithm (EG-GRPO) is introduced to
encourage exploration of new types and variants of meta-operations. Experiments
demonstrate that CDD can achieve state-of-the-art defense performance and
exhibit strong generalization to unseen jailbreak attacks.

</details>


### [136] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
*Shuang Liu,Zelong Li,Ruoyun Ma,Haiyan Zhao,Mengnan Du*

Main category: cs.AI

TL;DR: 本研究引入ContractEval基准测试，评估了开源与专有大型语言模型（LLM）在识别商业合同法律风险方面的表现，发现专有模型更优，开源模型虽有潜力但需定向微调。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在法律风险分析等专业领域的潜力尚未充分探索。为响应本地部署开源LLM以执行法律任务并保护数据机密性的日益增长的需求，本研究旨在评估开源LLM在识别商业合同中条款级法律风险方面是否能与专有LLM匹敌。

Method: 引入了ContractEval，这是首个全面评估开源LLM在识别商业合同中条款级法律风险方面表现的基准测试。利用Contract Understanding Atticus Dataset (CUAD)，评估了4个专有LLM和15个开源LLM。

Result: 研究得出五个主要发现：(1) 专有模型在正确性和输出有效性上优于开源模型，尽管部分开源模型在特定维度具有竞争力。(2) 较大的开源模型通常表现更好，但性能提升随模型增大而放缓。(3) 推理（“思考”）模式提高了输出有效性但降低了正确性。(4) 开源模型即使存在相关条款，也更频繁地生成“无相关条款”响应，这可能表明其“懒惰”或信心不足。(5) 模型量化可加速推理但会导致性能下降，显示了效率与准确性之间的权衡。

Conclusion: 研究结果表明，多数LLM的表现与初级法律助理相当，但开源模型在要求严苛的法律环境中需要有针对性的微调以确保其正确性和有效性。ContractEval为未来法律领域LLM的开发提供了坚实的基准。

Abstract: The potential of large language models (LLMs) in specialized domains such as
legal risk analysis remains underexplored. In response to growing interest in
locally deploying open-source LLMs for legal tasks while preserving data
confidentiality, this paper introduces ContractEval, the first benchmark to
thoroughly evaluate whether open-source LLMs could match proprietary LLMs in
identifying clause-level legal risks in commercial contracts. Using the
Contract Understanding Atticus Dataset (CUAD), we assess 4 proprietary and 15
open-source LLMs. Our results highlight five key findings: (1) Proprietary
models outperform open-source models in both correctness and output
effectiveness, though some open-source models are competitive in certain
specific dimensions. (2) Larger open-source models generally perform better,
though the improvement slows down as models get bigger. (3) Reasoning
("thinking") mode improves output effectiveness but reduces correctness, likely
due to over-complicating simpler tasks. (4) Open-source models generate "no
related clause" responses more frequently even when relevant clauses are
present. This suggests "laziness" in thinking or low confidence in extracting
relevant content. (5) Model quantization speeds up inference but at the cost of
performance drop, showing the tradeoff between efficiency and accuracy. These
findings suggest that while most LLMs perform at a level comparable to junior
legal assistants, open-source models require targeted fine-tuning to ensure
correctness and effectiveness in high-stakes legal settings. ContractEval
offers a solid benchmark to guide future development of legal-domain LLMs.

</details>


### [137] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
*Fei Liu,Yilu Liu,Qingfu Zhang,Xialiang Tong,Mingxuan Yuan*

Main category: cs.AI

TL;DR: LLM驱动的自动化启发式设计(AHD)面临泛化性差的问题。本文提出自动化启发式集合设计(AHSD)范式和EoH-S方法，旨在生成一个互补的启发式集合，以服务于多样化的问题实例，实验证明其性能显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型(LLM)的自动化启发式设计(AHD)方法仅为所有问题实例设计单一启发式，导致在不同分布或设置下泛化能力差。

Method: 本文提出自动化启发式集合设计(AHSD)新范式，旨在生成一个小型互补启发式集合。证明AHSD的目标函数是单调和超模的。为实现AHSD，提出进化启发式集合(EoH-S)方法，该方法包含互补种群管理和互补感知模因搜索两种新颖机制。

Result: 在三个AHD任务上，针对不同规模和分布的实例进行了综合实验。结果表明，EoH-S持续优于现有最先进的AHD方法，性能提升高达60%。

Conclusion: EoH-S方法能够有效生成高质量且互补的启发式集合，显著提升了LLM驱动的自动化启发式设计的泛化性和整体性能。

Abstract: Automated Heuristic Design (AHD) using Large Language Models (LLMs) has
achieved notable success in recent years. Despite the effectiveness of existing
approaches, they only design a single heuristic to serve all problem instances,
often inducing poor generalization across different distributions or settings.
To address this issue, we propose Automated Heuristic Set Design (AHSD), a new
formulation for LLM-driven AHD. The aim of AHSD is to automatically generate a
small-sized complementary heuristic set to serve diverse problem instances,
such that each problem instance could be optimized by at least one heuristic in
this set. We show that the objective function of AHSD is monotone and
supermodular. Then, we propose Evolution of Heuristic Set (EoH-S) to apply the
AHSD formulation for LLM-driven AHD. With two novel mechanisms of complementary
population management and complementary-aware memetic search, EoH-S could
effectively generate a set of high-quality and complementary heuristics.
Comprehensive experimental results on three AHD tasks with diverse instances
spanning various sizes and distributions demonstrate that EoH-S consistently
outperforms existing state-of-the-art AHD methods and achieves up to 60\%
performance improvements.

</details>


### [138] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.AI

TL;DR: 现有扩散模型（DDPMs）在缺失数据插补中存在推理延迟高和输出变异性大的问题。本文提出MissDDIM，一个基于DDIM的条件扩散框架，用于表格数据插补，以解决这些缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基于DDPM的扩散模型在缺失数据插补时，面临推理延迟高和输出变异性大的问题，这限制了它们在实际表格数据场景中的应用。

Method: 本文提出了MissDDIM，这是一个条件扩散框架，它将去噪扩散隐式模型（DDIM）应用于表格数据插补。

Result: （抽象中未明确给出具体量化结果）该方法旨在解决现有基于DDPM的缺失数据插补方法的推理延迟和输出变异性问题，通过采用DDIM，预计能提供更稳定或更快速的插补结果。

Conclusion: MissDDIM通过将DDIM应用于表格数据插补，有望解决现有DDPM在推理速度和输出稳定性方面的不足，从而提高缺失数据插补在实际应用中的有效性。

Abstract: Diffusion models have recently emerged as powerful tools for missing data
imputation by modeling the joint distribution of observed and unobserved
variables. However, existing methods, typically based on stochastic denoising
diffusion probabilistic models (DDPMs), suffer from high inference latency and
variable outputs, limiting their applicability in real-world tabular settings.
To address these deficiencies, we present in this paper MissDDIM, a conditional
diffusion framework that adapts Denoising Diffusion Implicit Models (DDIM) for
tabular imputation. While stochastic sampling enables diverse completions, it
also introduces output variability that complicates downstream processing.

</details>


### [139] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
*Xingjun Ma,Hanxun Huang,Tianwei Song,Ye Sun,Yifeng Gao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 为解决数据隐私保护中用户需暴露数据的问题，本文提出T2UE框架，允许用户仅通过文本描述生成不可学习样本（UEs），实现“零接触数据保护”，有效阻止模型从受保护数据中学习。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型（如CLIP）依赖含有用户隐私数据的网络抓取数据集，引发滥用担忧。现有不可学习样本（UEs）生成方法计算成本高昂，常需依赖第三方服务，导致用户为保护数据反而先暴露数据，形成隐私悖论，严重阻碍了实用可扩展数据保护方案的发展。

Method: 本文提出Text-to-Unlearnable Example (T2UE) 框架，允许用户仅使用文本描述生成不可学习样本。T2UE通过文本到图像（T2I）模型将文本描述映射到图像（噪声）空间，并结合误差最小化框架生成有效的不可学习噪声，从而规避了对原始图像数据的需求。

Result: 实验证明，T2UE保护的数据能显著降低最先进模型在下游任务（如跨模态检索）中的性能。值得注意的是，这种保护效果能够泛化到不同的模型架构，甚至在监督学习设置中也有效。

Conclusion: 本研究展示了“零接触数据保护”的可行性，即仅基于文本描述即可保护个人数据，消除了直接暴露数据的需要，为解决数据隐私保护中的核心矛盾提供了新途径。

Abstract: Large-scale pre-training frameworks like CLIP have revolutionized multimodal
learning, but their reliance on web-scraped datasets, frequently containing
private user data, raises serious concerns about misuse. Unlearnable Examples
(UEs) have emerged as a promising countermeasure against unauthorized model
training, employing carefully crafted unlearnable noise to disrupt the learning
of meaningful representations from protected data. Current approaches typically
generate UEs by jointly optimizing unlearnable noise for both images and their
associated text descriptions (or labels). However, this optimization process is
often computationally prohibitive for on-device execution, forcing reliance on
external third-party services. This creates a fundamental privacy paradox:
users must initially expose their data to these very services to achieve
protection, thereby compromising privacy in the process. Such a contradiction
has severely hindered the development of practical, scalable data protection
solutions. To resolve this paradox, we introduce \textbf{Text-to-Unlearnable
Example (T2UE)}, a novel framework that enables users to generate UEs using
only text descriptions. T2UE circumvents the need for original image data by
employing a text-to-image (T2I) model to map text descriptions into the image
(noise) space, combined with an error-minimization framework to produce
effective unlearnable noise. Extensive experiments show that T2UE-protected
data substantially degrades performance in downstream tasks (e.g., cross-modal
retrieval) for state-of-the-art models. Notably, the protective effect
generalizes across diverse architectures and even to supervised learning
settings. Our work demonstrates the feasibility of "zero-contact data
protection", where personal data can be safeguarded based solely on their
textual descriptions, eliminating the need for direct data exposure.

</details>


### [140] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: 本文提出一个创新的可验证大型语言模型（LLM）智能体，通过与网络资源动态交互、评估来源和综合证据，提供超越传统二元判断的完整可验证推理过程，并在误报信息检测中表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的普及，误报信息的检测变得日益重要且复杂，需要一种能够超越传统真/假二元判断的更高级、更可信的检测方法。

Method: 研究提出了一个创新的可验证误报信息检测LLM智能体。该智能体通过动态交互多样化网络来源、评估信息来源可信度、综合证据，并提供完整的可验证推理过程。其核心架构包含三个工具：精确网络搜索工具、来源可信度评估工具和数值声明验证工具。该智能体使用标准误报信息数据集（如FakeNewsNet）进行评估，并与传统机器学习模型和LLMs进行比较，评估指标涵盖标准分类指标、推理过程质量和内容重写后的鲁棒性。

Result: 实验结果表明，所提出的智能体在误报信息检测准确性、推理透明度和对抗信息重写能力方面均优于基线方法。

Conclusion: 该研究为可信赖的AI辅助事实核查提供了一种新范式，显著提升了误报信息检测的性能、透明度和抵抗信息篡改的能力。

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [141] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
*Wen-Xi Yang,Tian-Fang Zhao*

Main category: cs.AI

TL;DR: 本论文提出了AgentSME，一个基于LLM的智能教育生成代理框架，探讨了三种通信模式（Solo、Mono、Echo），并评估了它们在不同LLM下的准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 智能教育领域的生成代理模型至关重要但发展滞后。主要挑战在于教育背景的复杂性，包括学习者多样的认知行为以及个性化人际交流的教学核心。

Method: 本文提出了AgentSME，一个统一的基于LLM的生成代理框架。该模型考虑了Solo、Mono和Echo三种定向通信模式，以反映代理的自主性和交流互惠性。评估指标主要为准确性，并辅以三个多样性指数来评估推理内容的多样性。测试了六个主流LLM（分为基础容量和高容量配置）以验证通信模式的鲁棒性。

Result: 研究结果显示，采用Echo通信模式的生成代理实现了最高的准确性得分，而DeepSeek模型展现出最大的多样性。

Conclusion: 这项研究为提升代理学习能力和启发智能教育模型提供了宝贵信息。

Abstract: Generative agent models specifically tailored for smart education are
critical, yet remain relatively underdeveloped. A key challenge stems from the
inherent complexity of educational contexts: learners are human beings with
various cognitive behaviors, and pedagogy is fundamentally centered on
personalized human-to-human communication. To address this issue, this paper
proposes AgentSME, a unified generative agent framework powered by LLM. Three
directional communication modes are considered in the models, namely Solo,
Mono, and Echo, reflecting different types of agency autonomy and communicative
reciprocity. Accuracy is adopted as the primary evaluation metric, complemented
by three diversity indices designed to assess the diversity of reasoning
contents. Six widely used LLMs are tested to validate the robustness of
communication modes across different model tiers, which are equally divided
into base-capacity and high-capacity configurations. The results show that
generative agents that employ the Echo communication mode achieve the highest
accuracy scores, while DeepSeek exhibits the greatest diversity. This study
provides valuable information to improve agent learning capabilities and
inspire smart education models.

</details>


### [142] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
*Vinicius Lima,Dzung T. Phan,Jayant Kalagnanam,Dhaval Patel,Nianjun Zhou*

Main category: cs.AI

TL;DR: 本文提出一个基于可验证合成数据生成流程，用于训练可信赖大型语言模型（LLM）优化代理的框架，并引入了性能卓越的OptiTrust代理。


<details>
  <summary>Details</summary>
Motivation: 旨在为优化任务构建可靠且可信赖的LLM代理，解决现有方法在数据可验证性和模型可靠性方面的挑战，特别是在缺乏高质量训练数据的情况下。

Method: 研究提出一个可验证的合成数据生成流程，从结构化符号表示系统地生成优化问题的自然语言描述、数学公式和求解器可执行代码。通过编程方式构建具有已知最优解的实例，确保数据的完全可验证性并自动过滤低质量演示。这些数据集用于监督微调开源LLM。为实现此流程，引入了OptiTrust——一个模块化LLM代理，通过分步演示、多语言推理和多数投票交叉验证，实现从自然语言到可求解代码的多阶段转换。

Result: OptiTrust代理在标准基准测试中取得了最先进（SOTA）的性能。在7个数据集中，它在6个数据集上达到了最高准确率，并在其中3个数据集上比次优算法高出至少8个百分点。

Conclusion: 该研究为构建用于实际优化应用的可靠LLM代理提供了一条可扩展、可验证且有原则的路径，增强了LLM在复杂优化任务中的信任度和实用性。

Abstract: We present a framework for training trustworthy large language model (LLM)
agents for optimization modeling via a verifiable synthetic data generation
pipeline. Focusing on linear and mixed-integer linear programming, our approach
begins with structured symbolic representations and systematically produces
natural language descriptions, mathematical formulations, and solver-executable
code. By programmatically constructing each instance with known optimal
solutions, the pipeline ensures full verifiability and enables automatic
filtering of low-quality demonstrations generated by teacher models. Each
dataset instance includes a structured representation of the optimization
problem, a corresponding natural language description, the verified optimal
solution, and step-by-step demonstrations - generated by a teacher model - that
show how to model and solve the problem across multiple optimization modeling
languages. This enables supervised fine-tuning of open-source LLMs specifically
tailored to optimization tasks. To operationalize this pipeline, we introduce
OptiTrust, a modular LLM agent that performs multi-stage translation from
natural language to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation. Our agent
achieves state-of-the-art performance on standard benchmarks. Out of 7
datasets, it achieves the highest accuracy on six and outperforms the next-best
algorithm by at least 8 percentage on three of them. Our approach provides a
scalable, verifiable, and principled path toward building reliable LLM agents
for real-world optimization applications.

</details>


### [143] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
*Linda Smail,David Santandreu Calonge,Firuz Kamalov,Nur H. Orak*

Main category: cs.AI

TL;DR: 本研究评估了人工智能模型在弥补大学生环境教育知识鸿沟方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在探讨并利用AI模型（特别是大型语言模型LLMs）的能力，以有效弥补大学生的环境教育知识差距。

Method: 研究选取了GPT-3.5、GPT-4、GPT-4o、Gemini、Claude Sonnet和Llama 2等主流LLMs，并采用标准化工具环境知识测试（EKT-19）结合补充问题，对比评估大学生与AI模型在环境知识方面的表现。

Result: 研究结果表明，AI模型拥有庞大、易获取且有效的知识库，有潜力赋能学生和学术人员进行环境学习。

Conclusion: 尽管AI模型具备强大能力，但在环境科学领域，仍可能需要人类学科专家来验证其提供信息的准确性。

Abstract: This research investigates the potential of Artificial Intelligence (AI)
models to bridge the knowledge gap in environmental education among university
students. By focusing on prominent large language models (LLMs) such as
GPT-3.5, GPT-4, GPT-4o, Gemini, Claude Sonnet, and Llama 2, the study assesses
their effectiveness in conveying environmental concepts and, consequently,
facilitating environmental education. The investigation employs a standardized
tool, the Environmental Knowledge Test (EKT-19), supplemented by targeted
questions, to evaluate the environmental knowledge of university students in
comparison to the responses generated by the AI models. The results of this
study suggest that while AI models possess a vast, readily accessible, and
valid knowledge base with the potential to empower both students and academic
staff, a human discipline specialist in environmental sciences may still be
necessary to validate the accuracy of the information provided.

</details>


### [144] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
*Charles Tapley Hoyt,Craig Bakker,Richard J. Callahan,Joseph Cottam,August George,Benjamin M. Gyori,Haley M. Hummel,Nathaniel Merrill,Sara Mohammad Taheri,Pruthvi Prakash Navada,Marc-Antoine Parent,Adam Rupe,Olga Vitek,Jeremy Zucker*

Main category: cs.AI

TL;DR: $Y_0$是一个Python包，旨在帮助研究者定性判断因果关系是否可从现有数据中识别，并指导如何将其转化为可非参数估计的符号表达式。


<details>
  <summary>Details</summary>
Motivation: 在因果推断中，研究人员在量化因果效应强度之前，通常更需要解决“因果关系是否可从现有数据中识别”这一核心定性问题。尤其在面对随机对照试验、观察性研究或混合数据，以及存在未观测混杂因素时，缺乏统一工具来定性分析因果可识别性并指导估计量的推导。

Method: 本文介绍了$Y_0$ Python包。该包通过以下方式实现目标：
1. 实现因果识别算法，处理干预、反事实和可迁移性查询。
2. 支持对来自随机对照试验、观察性研究或混合数据进行分析。
3. 提供领域特定语言（DSL）以符号概率表达式表示因果查询和估计量。
4. 提供工具使用如非循环有向混合图（ADMGs）等表示包含未观测混杂因素的因果图模型。
5. 集成了近期因果推断文献中的多种识别算法。
6. 提供指导将因果查询转化为可非参数估计的符号估计量。

Result: 论文推出了$Y_0$ Python包，该包能够帮助研究人员定性地判断因果关系是否可从现有数据中估计，并提供将因果查询转化为可非参数估计的符号估计量的方法和工具。该包支持多种数据源和复杂的因果图模型，集成了先进的识别算法，并以MIT许可开源。

Conclusion: $Y_0$包为因果推断领域提供了一个实用且重要的工具，通过在进行因果效应强度量化估计之前，解决因果关系的可识别性问题，极大地增强了研究人员进行严谨因果分析的能力，提高了因果推断的可靠性和效率。

Abstract: We present the $Y_0$ Python package, which implements causal identification
algorithms that apply interventional, counterfactual, and transportability
queries to data from (randomized) controlled trials, observational studies, or
mixtures thereof. $Y_0$ focuses on the qualitative investigation of causation,
helping researchers determine whether a causal relationship can be estimated
from available data before attempting to estimate how strong that relationship
is. Furthermore, $Y_0$ provides guidance on how to transform the causal query
into a symbolic estimand that can be non-parametrically estimated from the
available data. $Y_0$ provides a domain-specific language for representing
causal queries and estimands as symbolic probabilistic expressions, tools for
representing causal graphical models with unobserved confounders, such as
acyclic directed mixed graphs (ADMGs), and implementations of numerous
identification algorithms from the recent causal inference literature. The
$Y_0$ source code can be found under the MIT License at
https://github.com/y0-causal-inference/y0 and it can be installed with pip
install y0.

</details>


### [145] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
*Jingxuan Wei,Caijun Jia,Qi Chen,Honghao He,Linzhuang Sun,Conghui He,Lijun Wu,Bihui Yu,Cheng Tan*

Main category: cs.AI

TL;DR: 本文提出了Geoint-R1多模态推理框架，旨在解决现有模型在形式化几何推理，尤其是在辅助元素构建方面的不足。通过整合辅助元素构建、Lean4形式化推理和交互式可视化，并在新建的Geoint基准测试集上，Geoint-R1在复杂几何问题上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在处理形式化几何推理时面临挑战，尤其是在动态构建和验证辅助几何元素方面表现不佳。

Method: 引入Geoint-R1多模态推理框架，该框架独特地集成了辅助元素构建、基于Lean4的形式化推理以及交互式可视化。同时，构建了包含1,885个严谨标注几何问题的Geoint基准测试集，用于系统评估和推进形式化几何推理。

Result: 广泛的实验表明，Geoint-R1显著超越了现有多模态和数学专用推理模型，特别是在需要显式辅助元素构建的挑战性问题上表现突出。

Conclusion: Geoint-R1框架通过其创新的集成方法，有效解决了形式化几何推理中辅助元素构建的难题，并在新的基准测试上取得了显著的性能提升，为该领域的研究树立了新标杆。

Abstract: Mathematical geometric reasoning is essential for scientific discovery and
educational development, requiring precise logic and rigorous formal
verification. While recent advances in Multimodal Large Language Models (MLLMs)
have improved reasoning tasks, existing models typically struggle with formal
geometric reasoning, particularly when dynamically constructing and verifying
auxiliary geometric elements. To address these challenges, we introduce
Geoint-R1, a multimodal reasoning framework designed to generate formally
verifiable geometric solutions from textual descriptions and visual diagrams.
Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning
represented via Lean4, and interactive visualization. To systematically
evaluate and advance formal geometric reasoning, we propose the Geoint
benchmark, comprising 1,885 rigorously annotated geometry problems across
diverse topics such as plane, spatial, and solid geometry. Each problem
includes structured textual annotations, precise Lean4 code for auxiliary
constructions, and detailed solution steps verified by experts. Extensive
experiments demonstrate that Geoint-R1 significantly surpasses existing
multimodal and math-specific reasoning models, particularly on challenging
problems requiring explicit auxiliary element constructions.

</details>


### [146] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
*Tian-Fang Zhao,Wen-Xi Yang*

Main category: cs.AI

TL;DR: 本研究提出InqEduAgent，一个由大型语言模型（LLM）赋能的智能体模型，用于模拟和选择探究式学习的协作伙伴，通过结合生成式智能体和自适应匹配算法，在实验中表现出优异的性能。


<details>
  <summary>Details</summary>
Motivation: 在探究式教育中，学习伙伴的选择通常依赖经验或基于规则的机器助手，这导致缺乏科学规划、知识扩展受限和灵活性不足的问题。

Method: 本研究提出了InqEduAgent模型。该模型利用LLM赋能的生成式智能体来捕捉学习者的认知和评估特征，并结合一个高斯过程增强的自适应匹配算法，根据先验知识模式为学习者提供最优的学习伙伴匹配。

Result: 实验结果表明，InqEduAgent在大多数知识学习场景和不同能力水平的LLM环境中均表现出最佳性能。

Conclusion: 本研究促进了人类学习伙伴的智能分配，并为未来AI学习伙伴的构建提供了新的思路。

Abstract: Collaborative partnership matters in inquiry-oriented education. However,
most study partners are selected either rely on experience-based assignments
with little scientific planning or build on rule-based machine assistants,
encountering difficulties in knowledge expansion and inadequate flexibility.
This paper proposes an LLM-empowered agent model for simulating and selecting
learning partners tailored to inquiry-oriented learning, named InqEduAgent.
Generative agents are designed to capture cognitive and evaluative features of
learners in real-world scenarios. Then, an adaptive matching algorithm with
Gaussian process augmentation is formulated to identify patterns within prior
knowledge. Optimal learning-partner matches are provided for learners facing
different exercises. The experimental results show the optimal performance of
InqEduAgent in most knowledge-learning scenarios and LLM environment with
different levels of capabilities. This study promotes the intelligent
allocation of human-based learning partners and the formulation of AI-based
learning partners. The code, data, and appendix are publicly available at
https://github.com/InqEduAgent/InqEduAgent.

</details>


### [147] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
*Osama Mohammed,Jiaxin Pan,Mojtaba Nayyeri,Daniel Hernández,Steffen Staab*

Main category: cs.AI

TL;DR: 本文提出ETDNet，一个新型时间图神经网络，它通过引入“全历史图”和分离时间步内、时间步间边来建模演化交互。在驾驶员意图预测和欺诈检测任务上，ETDNet显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务中（如驾驶员行为预测、金融欺诈检测）建模实体间随时间演变的关系至关重要，但传统方法和现有时间图方法在明确表示关系及其演变方面存在局限，需要更有效的时间图表示和学习方法。

Method: 引入“全历史图”表示，为每个时间步的每个实体实例化一个节点，并分离时间步内边（intra-time-step edges）和时间步间边（inter-time-step edges）。在此图上设计了边类型解耦网络（ETDNet），包含并行模块：一个图注意力模块处理时间步内边，一个多头时间注意力模块处理时间步间历史，以及一个融合模块。

Result: 在Waymo驾驶员意图预测和Elliptic++比特币欺诈检测任务上，ETDNet性能均超越强基线。Waymo联合准确率提升至75.6%（对比74.1%），Elliptic++非法类别F1值提高至88.1%（对比60.4%）。

Conclusion: 实验结果表明，将结构关系和时间关系表示为单一图中的不同类型边，对于建模实体间随时间演化的交互具有显著优势。

Abstract: Modeling evolving interactions among entities is critical in many real-world
tasks. For example, predicting driver maneuvers in traffic requires tracking
how neighboring vehicles accelerate, brake, and change lanes relative to one
another over consecutive frames. Likewise, detecting financial fraud hinges on
following the flow of funds through successive transactions as they propagate
through the network. Unlike classic time-series forecasting, these settings
demand reasoning over who interacts with whom and when, calling for a
temporal-graph representation that makes both the relations and their evolution
explicit. Existing temporal-graph methods typically use snapshot graphs to
encode temporal evolution. We introduce a full-history graph that instantiates
one node for every entity at every time step and separates two edge sets: (i)
intra-time-step edges that capture relations within a single frame and (ii)
inter-time-step edges that connect an entity to itself at consecutive steps. To
learn on this graph we design an Edge-Type Decoupled Network (ETDNet) with
parallel modules: a graph-attention module aggregates information along
intra-time-step edges, a multi-head temporal-attention module attends over an
entity's inter-time-step history, and a fusion module combines the two messages
after every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin
fraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,
lifting Waymo joint accuracy to 75.6\% (vs. 74.1\%) and raising Elliptic++
illicit-class F1 to 88.1\% (vs. 60.4\%). These gains demonstrate the benefit of
representing structural and temporal relations as distinct edges in a single
graph.

</details>


### [148] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
*Shaofeng Yin,Ting Lei,Yang Liu*

Main category: cs.AI

TL;DR: 引入ToolVQA，一个大规模多模态数据集，旨在提升大型基础模型在真实世界多步工具使用中的能力与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型视觉问答在真实世界、功能多样、多模态且需要多步推理的工具使用场景中仍存在显著能力差距。

Method: 构建了包含23K实例的ToolVQA数据集，其特点是真实世界视觉上下文和多步推理任务。为构建该数据集，提出了ToolEngine数据生成流水线，利用深度优先搜索(DFS)和动态上下文示例匹配机制来模拟人类工具使用推理。

Result: 在ToolVQA上微调的7B大型基础模型表现优异，并在各种分布外(OOD)数据集上超越GPT-3.5-turbo，证明其在真实世界工具使用场景中的强大泛化能力。

Conclusion: ToolVQA数据集成功弥补了现有LFM在真实世界多步、多模态工具使用能力上的不足，显著提升了大型基础模型在复杂实际场景中的推理与泛化能力。

Abstract: Integrating external tools into Large Foundation Models (LFMs) has emerged as
a promising approach to enhance their problem-solving capabilities. While
existing studies have demonstrated strong performance in tool-augmented Visual
Question Answering (VQA), recent benchmarks reveal significant gaps in
real-world tool-use proficiency, particularly in functionally diverse
multimodal settings requiring multi-step reasoning. In this work, we introduce
ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to
bridge this gap. Unlike previous datasets that rely on synthetic scenarios and
simplified queries, ToolVQA features real-world visual contexts and challenging
implicit multi-step reasoning tasks, better aligning with real user
interactions. To construct this dataset, we propose ToolEngine, a novel data
generation pipeline that employs Depth-First Search (DFS) with a dynamic
in-context example matching mechanism to simulate human-like tool-use
reasoning. ToolVQA encompasses 10 multimodal tools across 7 diverse task
domains, with an average inference length of 2.78 reasoning steps per instance.
The fine-tuned 7B LFMs on ToolVQA not only achieve impressive performance on
our test set but also surpass the large close-sourced model GPT-3.5-turbo on
various out-of-distribution (OOD) datasets, demonstrating strong
generalizability to real-world tool-use scenarios.

</details>


### [149] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: 针对LLMs在长期交互中记忆缺失和现有记忆系统局限性问题，本文提出了Nemori，一种受人类认知启发的自组织记忆架构，通过两步对齐和预测校准原则，显著提升了LLMs在长上下文中的记忆能力和自主学习进化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长上下文交互中难以保持持久记忆，限制了它们作为自主代理的有效性。现有记忆系统存在记忆单元粒度定义随意和知识提取机制被动、基于规则的局限，阻碍了真正的学习和演化。

Method: 本文提出了Nemori，一种受人类认知原理启发的自组织记忆架构。其核心创新有两点：1. **两步对齐原则**：受事件分割理论启发，提供了一种原则性的自上而下方法，将原始对话流组织成语义连贯的片段，解决了记忆粒度问题。2. **预测校准原则**：受自由能原理启发，使代理能够主动从预测差距中学习，超越预定义启发式方法，实现自适应知识演化。

Result: 在LoCoMo和LongMemEval基准测试上的广泛实验表明，Nemori显著优于现有的最先进系统，尤其在更长的上下文环境中优势更为明显。

Conclusion: Nemori为处理自主代理的长期、动态工作流程提供了一条可行的途径。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


### [150] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
*Xingdan Wang,Jiayi He,Zhiqing Tang,Jianxiong Guo,Jiong Lou,Liping Qian,Tian Wang,Weijia Jia*

Main category: cs.AI

TL;DR: 本文提出首个针对动态边缘环境中LLM驱动AI代理的系统部署和管理方案，通过自适应框架结合蚁群算法和LLM优化，实现高效代理放置和轻量级迁移，显著降低部署延迟和迁移成本。


<details>
  <summary>Details</summary>
Motivation: 随着LLM（如ChatGPT）的兴起，对实时处理任务的AI代理需求增加。然而，在传统云数据中心部署数据密集型、多模态边缘工作负载会导致显著延迟。将AI代理部署至边缘虽能提升效率，但边缘环境资源受限且异构，同时复杂的AI代理（需协调LLM、任务规划等）的迁移难度大，难以维持移动用户服务质量。

Method: 本文提出了一个新颖的自适应框架，用于边缘智能系统中AI代理的放置和迁移。该方法对资源约束、延迟和成本进行建模，并利用蚁群算法和基于LLM的优化进行高效决策。它能够自主放置代理以优化资源利用率和服务质量，并通过仅传输必要状态实现轻量级代理迁移。

Result: 该解决方案基于AgentScope在分布式系统上实现，并经全球分布式边缘服务器验证。结果显示，该方案显著降低了部署延迟和迁移成本。

Conclusion: 本文为LLM驱动的AI代理在动态边缘环境中的部署和管理提供了首个系统性解决方案，通过创新的自适应框架有效解决了资源受限和复杂迁移问题，显著提升了边缘AI代理的效率和性能。

Abstract: The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents
capable of real-time task handling. However, migrating data-intensive,
multi-modal edge workloads to cloud data centers, traditionally used for agent
deployment, introduces significant latency. Deploying AI agents at the edge
improves efficiency and reduces latency. However, edge environments present
challenges due to limited and heterogeneous resources. Maintaining QoS for
mobile users necessitates agent migration, which is complicated by the
complexity of AI agents coordinating LLMs, task planning, memory, and external
tools. This paper presents the first systematic deployment and management
solution for LLM-based AI agents in dynamic edge environments. We propose a
novel adaptive framework for AI agent placement and migration in edge
intelligence systems. Our approach models resource constraints and
latency/cost, leveraging ant colony algorithms and LLM-based optimization for
efficient decision-making. It autonomously places agents to optimize resource
utilization and QoS and enables lightweight agent migration by transferring
only essential state. Implemented on a distributed system using AgentScope and
validated across globally distributed edge servers, our solution significantly
reduces deployment latency and migration costs.

</details>


### [151] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
*Zeju Li,Jianyuan Zhong,Ziyang Zheng,Xiangyu Wen,Zhijian Xu,Yingying Cheng,Fan Zhang,Qiang Xu*

Main category: cs.AI

TL;DR: 本文提出一种基于步长熵的CoT压缩框架，通过识别并剪枝冗余步骤，可减少80%的中间步骤而不显著影响精度。并设计两阶段训练策略，使LLM自主生成压缩CoT，大幅提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）使用思维链（CoT）提示进行复杂推理时，会生成冗长且包含大量冗余的思维过程，导致推理成本增加和效率降低。

Method: 1. 引入基于“步长熵”的CoT压缩框架，该指标量化单个推理步骤的信息贡献以识别冗余。2. 通过理论分析和在数学推理基准上的实证验证，证明低熵步骤的高度冗余性。3. 提出一种结合监督微调（SFT）和组相对策略优化（GRPO）强化学习的两阶段训练策略。4. 该策略使LLM能够自主学习，通过策略性地纳入[SKIP]标记在推理过程中生成压缩的CoT。

Result: 1. 实验发现，在DeepSeek-R1-7B, 14B和Qwen3-8B上，80%的低熵中间步骤可在最终答案准确性略微下降的情况下被剪枝。2. 这与随机或高熵剪枝形成鲜明对比，后者会严重损害推理性能。3. 该方法显著提高了LLM的推理效率，同时严格保持了准确性。

Conclusion: 基于步长熵的CoT压缩方法能够有效减少LLM推理冗余，显著提升效率并保持精度。这对于LLM的实际部署和对推理结构的深入理解具有重要意义。

Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at
complex reasoning but generate verbose thought processes with considerable
redundancy, leading to increased inference costs and reduced efficiency. We
introduce a novel CoT compression framework based on step entropy, a metric
that quantifies the informational contribution of individual reasoning steps to
identify redundancy. Through theoretical analysis and extensive empirical
validation on mathematical reasoning benchmarks, we demonstrate that steps with
low entropy are indeed highly redundant. Our experiments reveal that an
astonishing 80\% of low-entropy intermediate steps can be pruned with minor
degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and
Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning,
which severely impairs reasoning performance. Building on this, we propose a
novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and
Group Relative Policy Optimization (GRPO) reinforcement learning. This approach
enables LLMs to autonomously learn to generate compressed COTs during inference
by strategically incorporating [SKIP] tokens. Our method significantly enhances
LLM inference efficiency while rigorously preserving accuracy, offering
profound implications for practical LLM deployment and a deeper understanding
of reasoning structures.

</details>


### [152] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
*Feng Rui,Zhiyao Luo,Wei Wang,Yuting Song,Yong Liu,Tingting Zhu,Jianqing Li,Xingyao Wang*

Main category: cs.AI

TL;DR: 本研究提出了CogBench基准，评估大型语言模型（LLMs）在跨语言、跨站点语音认知障碍评估中的泛化能力，并发现LLMs结合思维链提示和LoRA微调可显著提升泛化性。


<details>
  <summary>Details</summary>
Motivation: 自动语音认知障碍评估是一种有前景的早期筛查方法，但现有方法在不同语言和临床设置中泛化性差，限制了其实用性。

Method: 提出了CogBench基准，用于评估LLMs在语音认知障碍评估中的跨语言和跨站点泛化能力。采用统一的多模态流程，在英语和普通话的三大数据集（ADReSSo, NCMMSC2021-AD, CIR-E）上评估模型性能，并探索了LLMs结合思维链提示和Low-Rank Adaptation (LoRA) 轻量级微调的效果。

Result: 传统深度学习模型在跨域迁移时性能显著下降。LLMs结合思维链提示表现出更好的适应性，但其性能仍受提示设计影响。通过LoRA对LLMs进行轻量级微调，显著提升了模型在目标领域的泛化能力。

Conclusion: 研究结果为构建具有临床实用性且语言鲁棒的语音认知评估工具迈出了关键一步。

Abstract: Automatic assessment of cognitive impairment from spontaneous speech offers a
promising, non-invasive avenue for early cognitive screening. However, current
approaches often lack generalizability when deployed across different languages
and clinical settings, limiting their practical utility. In this study, we
propose CogBench, the first benchmark designed to evaluate the cross-lingual
and cross-site generalizability of large language models (LLMs) for
speech-based cognitive impairment assessment. Using a unified multimodal
pipeline, we evaluate model performance on three speech datasets spanning
English and Mandarin: ADReSSo, NCMMSC2021-AD, and a newly collected test set,
CIR-E. Our results show that conventional deep learning models degrade
substantially when transferred across domains. In contrast, LLMs equipped with
chain-of-thought prompting demonstrate better adaptability, though their
performance remains sensitive to prompt design. Furthermore, we explore
lightweight fine-tuning of LLMs via Low-Rank Adaptation (LoRA), which
significantly improves generalization in target domains. These findings offer a
critical step toward building clinically useful and linguistically robust
speech-based cognitive assessment tools.

</details>


### [153] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: 大语言模型（LLMs）在通用逻辑推理方面面临挑战。本文比较了神经符号AI中的两种主要方法（集成式和混合式），发现混合式方法在开发通用逻辑推理方面更具前景，因为它更可解释且保留了LLM优势。研究还提出了一个通用的混合式框架。


<details>
  <summary>Details</summary>
Motivation: LLMs在领域无关的通用逻辑推理（确定性和可解释性）方面存在显著不足。神经符号AI作为一种结合逻辑和神经网络的方法，被认为是解决此问题的一个方向。然而，对于哪种神经符号方法（集成式或混合式）更适合开发通用逻辑推理，目前尚缺乏系统的比较研究。

Method: 本文首先识别并分类了神经符号AI在逻辑推理上的两种主要方法：集成式（符号推理内嵌于神经网络）和混合式（独立的符号求解器）。随后，选取了代表性的领域无关模型（集成式代表LNN，混合式代表LLM-Symbolic Solver, LLM-SS）进行案例研究和对比分析。基于分析结果，提出了一个通用、模块化、模型及领域无关且低人工输入的混合式框架。

Result: 研究分析表明，混合式方法在开发通用逻辑推理方面比集成式方法更有前景。其优势体现在：1) 推理链更具可解释性；2) 能保留现有LLM的能力和优点。因此，LLM-Symbolic Solver (LLM-SS) 代表的混合式路径被认为是更优的选择。

Conclusion: 混合式神经符号AI方法（特别是基于LLM-SS的方案）在提升LLM的通用逻辑推理能力方面展现出更大的潜力，因为它提供了更好的可解释性并能有效利用现有LLM的优势。未来的工作应着重于发展和应用基于此方法的通用框架。

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


### [154] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
*Lucia Cipolina-Kun,Marianna Nezhurina,Jenia Jitsev*

Main category: cs.AI

TL;DR: 一个名为Board Game Arena的库，提供了一个框架，用于通过战略棋盘游戏评估大型语言模型（LLM）的决策能力，支持LLM与其他类型智能体的系统比较，并提供分析工具。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在战略棋盘游戏中的决策能力、推理过程和博弈论行为。

Method: 开发了基于Google OpenSpiel的Board Game Arena库；集成了多种棋盘和矩阵游戏；支持LLM、随机、人类和强化学习等多种智能体类型进行系统比较；利用LiteLLM、vLLM和Ray进行模型访问、本地部署和分布式执行；提供LLM推理轨迹分析工具。

Result: 成功构建了一个功能全面的框架，能够系统地评估和比较LLM在各种棋盘游戏中的表现，并深入分析其推理过程，为LLM的行为研究提供了技术支持。

Conclusion: 该框架为LLM的推理能力和博弈论行为的实证评估提供了重要贡献，是一个强大而多功能的工具，有助于推动该领域的研究。

Abstract: The Board Game Arena library provides a framework for evaluating the decision
making abilities of large language models (LLMs) through strategic board games
implemented in Google OpenSpiel library. The framework enables systematic
comparisons between LLM based agents and other agents (random, human,
reinforcement learning agents, etc.) in various game scenarios by wrapping
multiple board and matrix games and supporting different agent types. It
integrates API access to models via LiteLLM, local model deployment via vLLM,
and offers distributed execution through Ray. Additionally it provides
extensive analysis tools for the LLM reasoning traces. This paper summarizes
the structure, key characteristics, and motivation of the repository,
highlighting how it contributes to the empirical evaluation of the reasoning of
LLM and game-theoretic behavior

</details>


### [155] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
*Wenxin Mao,Zhitao Wang Long Wang,Sirong Chen,Cuiyun Gao,Luyang Cao,Ziming Liu,Qiming Zhang,Jun Zhou,Zhi Jin*

Main category: cs.AI

TL;DR: LLMs代码生成面对复杂需求时，自然语言描述存在歧义。本文提出UML2Dep框架，通过增强UML序列图和数据依赖推理，利用正式规约解决此问题，提升LLM代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）擅长代码生成，但自然语言描述固有歧义，无法准确捕捉复杂系统要求（如行为、逻辑、架构约束），且服务导向架构中隐式数据依赖难以推断。

Method: 提出UML2Dep分步代码生成框架：1. 引入增强型UML序列图：集成决策表和API规范，形式化服务交互，消除歧义。2. 引入数据依赖推理（DDI）：在代码合成前构建显式数据依赖图，将DDI形式化为约束数学推理任务，并结合静态解析和依赖剪枝，提高推理准确性。

Result: 该框架通过增强的UML和数据依赖推理，能将复杂且无歧义的正式规约转化为代码，有效消除语言歧义，构建明确的数据依赖，并提高LLM处理复杂规约时推理的准确性和效率。

Conclusion: UML2Dep框架通过利用形式化规约和显式数据依赖推理，解决了LLM从复杂、歧义性自然语言描述生成代码的挑战，特别适用于服务导向架构，有望实现更准确可靠的代码生成。

Abstract: Large language models (LLMs) excel at generating code from natural language
(NL) descriptions. However, the plain textual descriptions are inherently
ambiguous and often fail to capture complex requirements like intricate system
behaviors, conditional logic, and architectural constraints; implicit data
dependencies in service-oriented architectures are difficult to infer and
handle correctly. To bridge this gap, we propose a novel step-by-step code
generation framework named UML2Dep by leveraging unambiguous formal
specifications of complex requirements. First, we introduce an enhanced Unified
Modeling Language (UML) sequence diagram tailored for service-oriented
architectures. This diagram extends traditional visual syntax by integrating
decision tables and API specifications, explicitly formalizing structural
relationships and business logic flows in service interactions to rigorously
eliminate linguistic ambiguity. Second, recognizing the critical role of data
flow, we introduce a dedicated data dependency inference (DDI) task. DDI
systematically constructs an explicit data dependency graph prior to actual
code synthesis. To ensure reliability, we formalize DDI as a constrained
mathematical reasoning task through novel prompting strategies, aligning with
LLMs' excellent mathematical strengths. Additional static parsing and
dependency pruning further reduce context complexity and cognitive load
associated with intricate specifications, thereby enhancing reasoning accuracy
and efficiency.

</details>


### [156] [Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis](https://arxiv.org/abs/2508.03396)
*Rui Zou,Mengqi Wei,Yutao Zhu,Jirong Wen,Xin Zhao,Jing Chen*

Main category: cs.AI

TL;DR: 为解决大语言模型在诊断复杂错误方面的不足，本文提出了Hide and Seek Game (HSG)这一动态对抗性框架，显著提升了数学推理任务中的错误诊断准确率，超越了GPT-4o等基线模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在推理和生成方面表现出色，但难以识别和诊断复杂错误。这主要源于其训练目标优先考虑正确答案，导致错误暴露和学习不足。现有研究引入错误信号，但多依赖浅层、静态错误，限制了深层诊断能力的提升。

Method: 提出了Hide and Seek Game (HSG)，一个动态对抗性框架，用于错误生成和诊断。HSG包含两个对抗角色：Sneaky（生成微妙、欺骗性的推理错误）和Diagnosis（准确检测这些错误）。通过对抗性协同演化，同时增强错误隐蔽性和诊断精确度，并在数学问题解决上进行了评估。

Result: 实验表明，HSG显著提升了错误诊断能力，在多项数学推理任务上的准确率比GPT-4o等基线模型高出16.8%—31.4%。研究团队还发布了一个包含欺骗性错误和诊断注释的挑战性数据集，作为未来研究的基准。

Conclusion: HSG框架通过动态对抗性学习，有效解决了大语言模型在诊断复杂错误方面的局限性。它大幅提升了诊断能力，并为该领域的未来研究提供了新的基准和资源。

Abstract: Large Language Models (LLMs) excel in reasoning and generation across
domains, but still struggle with identifying and diagnosing complex errors.
This stems mainly from training objectives that prioritize correct answers,
limiting exposure to and learning from errors. While recent studies have begun
to address this by introducing error signals, most rely on shallow, static
errors, restricting improvement in deep diagnostic ability. To overcome this,
we propose Hide and Seek Game (HSG), a dynamic adversarial framework for error
generation and diagnosis, and evaluate it on mathematical problem-solving. HSG
involves two adversarial roles: Sneaky, which "hides" by generating subtle,
deceptive reasoning errors, and Diagnosis, which "seeks" to accurately detect
them. Through adversarial co-evolution, both error stealth and diagnostic
precision are enhanced. Experiments on several math reasoning tasks show that
HSG significantly boosts error diagnosis, achieving 16.8\%--31.4\% higher
accuracy than baselines like GPT-4o. We also release a challenging dataset of
deceptive errors and diagnostic annotations as a benchmark for future research.

</details>


### [157] [Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](https://arxiv.org/abs/2508.03406)
*Kai Li,Ruihao Zheng,Xinye Hao,Zhenkun Wang*

Main category: cs.AI

TL;DR: MOID结合LLM与多目标优化，为不可行路由问题提供多样化、可操作的诊断建议，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实路由问题中，用户需求冲突或不合理导致模型不可行；现有LLM方法在诊断不可行模型时，未能考虑多种潜在调整方案。

Method: 提出MOID（多目标不可行性诊断）框架，结合LLM智能体和多目标优化。MOID利用多目标优化权衡路径成本和约束违反以生成一系列折衷解；LLM智能体分析这些解，生成诊断函数，为不可行模型提供多样化诊断见解和建议。该方法在50种不可行路由问题上与现有LLM方法进行了对比。

Result: MOID能够自动一次性生成多项诊断建议，相比现有方法，为模型恢复可行性及决策提供了更实用的洞察。

Conclusion: MOID通过融合LLM和多目标优化，有效解决了路由模型不可行性的诊断难题，并提供了比现有方法更全面、实用的解决方案，增强了决策支持能力。

Abstract: In real-world routing problems, users often propose conflicting or
unreasonable requirements, which result in infeasible optimization models due
to overly restrictive or contradictory constraints, leading to an empty
feasible solution set. Existing Large Language Model (LLM)-based methods
attempt to diagnose infeasible models, but modifying such models often involves
multiple potential adjustments that these methods do not consider. To fill this
gap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which
combines LLM agents and multi-objective optimization within an automatic
routing solver, to provide a set of representative actionable suggestions.
Specifically, MOID employs multi-objective optimization to consider both path
cost and constraint violation, generating a set of trade-off solutions, each
encompassing varying degrees of model adjustments. To extract practical
insights from these solutions, MOID utilizes LLM agents to generate a solution
analysis function for the infeasible model. This function analyzes these
distinct solutions to diagnose the original infeasible model, providing users
with diverse diagnostic insights and suggestions. Finally, we compare MOID with
several LLM-based methods on 50 types of infeasible routing problems. The
results indicate that MOID automatically generates multiple diagnostic
suggestions in a single run, providing more practical insights for restoring
model feasibility and decision-making compared to existing methods.

</details>


### [158] [Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](https://arxiv.org/abs/2508.03438)
*Taine J. Elliott,Stephen P. Levitt,Ken Nixon,Martin Bekker*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的信息抽取与知识图谱（KG）生成方法，旨在从医学文献中自动识别和连接生物医学知识，通过引入上下文变量增强抽取效果，并验证了其高准确性，为医疗专业人员提供集中、实时的知识源。


<details>
  <summary>Details</summary>
Motivation: 随着公开医学数据的快速增长，科学文献的数量与应用之间存在日益扩大的差距。医疗专业人员面临知识过载，难以系统地审阅和理解最新知识，从而阻碍了其获取最新发现的能力。

Method: 研究构建了一个基于大语言模型（LLM）代理的管道，将44篇PubMed摘要分解为语义命题句，并从中提取知识图谱三元组。这些三元组通过结合开放域和本体论的信息抽取方法进行增强，以纳入本体论类别。此外，抽取过程中还包含一个上下文变量，使三元组变为“四元组”。研究还探索了LLM推断新关系和连接知识图谱中簇的能力。

Result: 通过将增强三元组生成的自然语言句子与原始命题进行比较，验证了LLM的抽取准确性，平均余弦相似度达到0.874。结果显示，引入上下文变量后，增强三元组生成句子的相似度相较于普通三元组有所提高。

Conclusion: 该方法为医疗从业者提供了一个集中、实时更新且可持续的知识来源，并可能成为在其他广泛领域实现类似成果的基础。

Abstract: The rapid expansion of publicly-available medical data presents a challenge
for clinicians and researchers alike, increasing the gap between the volume of
scientific literature and its applications. The steady growth of studies and
findings overwhelms medical professionals at large, hindering their ability to
systematically review and understand the latest knowledge. This paper presents
an approach to information extraction and automatic knowledge graph (KG)
generation to identify and connect biomedical knowledge. Through a pipeline of
large language model (LLM) agents, the system decomposes 44 PubMed abstracts
into semantically meaningful proposition sentences and extracts KG triples from
these sentences. The triples are enhanced using a combination of open domain
and ontology-based information extraction methodologies to incorporate
ontological categories. On top of this, a context variable is included during
extraction to allow the triple to stand on its own - thereby becoming
`quadruples'. The extraction accuracy of the LLM is validated by comparing
natural language sentences generated from the enhanced triples to the original
propositions, achieving an average cosine similarity of 0.874. The similarity
for generated sentences of enhanced triples were compared with generated
sentences of ordinary triples showing an increase as a result of the context
variable. Furthermore, this research explores the ability for LLMs to infer new
relationships and connect clusters in the knowledge base of the knowledge
graph. This approach leads the way to provide medical practitioners with a
centralised, updated in real-time, and sustainable knowledge source, and may be
the foundation of similar gains in a wide variety of fields.

</details>


### [159] [Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence](https://arxiv.org/abs/2508.03465)
*Saleh Nikooroo*

Main category: cs.AI

TL;DR: 论文提出一种将信念系统建模为有向加权图的新形式主义，以更好地分析信念的内部结构，区分外部可信度与内部置信度。


<details>
  <summary>Details</summary>
Motivation: 现有信念系统模型（如全局一致命题集或标量概率分布）无法揭示信念的内部结构，混淆外部可信度与内部一致性，且不能模拟碎片化或矛盾的认知状态。

Method: 论文提出一个将信念系统建模为有向加权图的最小形式主义。其中，节点代表单个信念，边表示认知关系（如支持或矛盾）。该框架定义了两个独立函数：一个分配信念的“可信度”（反映来源信任），另一个分配“置信度”（源自内部结构支持）。该模型是纯静态的，不假设预先一致性或要求信念更新，也不涉及推理或修正过程。

Result: 该模型通过区分信念结构与信念强度，为分析信念系统的内部组织（包括一致性条件、认知张力和表征限制）提供了一个基础。与现有概率、逻辑或基于论证的方法相比，它能够实现对认知状态更丰富的分类。

Conclusion: 该形式主义提供了一个基础，用于深入分析信念系统的内部结构和组织，能够处理现有模型难以处理的复杂认知状态，如碎片化和矛盾，并能更细致地分类认知状态。

Abstract: Belief systems are often treated as globally consistent sets of propositions
or as scalar-valued probability distributions. Such representations tend to
obscure the internal structure of belief, conflate external credibility with
internal coherence, and preclude the modeling of fragmented or contradictory
epistemic states. This paper introduces a minimal formalism for belief systems
as directed, weighted graphs. In this framework, nodes represent individual
beliefs, edges encode epistemic relationships (e.g., support or contradiction),
and two distinct functions assign each belief a credibility (reflecting source
trust) and a confidence (derived from internal structural support). Unlike
classical probabilistic models, our approach does not assume prior coherence or
require belief updating. Unlike logical and argumentation-based frameworks, it
supports fine-grained structural representation without committing to binary
justification status or deductive closure. The model is purely static and
deliberately excludes inference or revision procedures. Its aim is to provide a
foundational substrate for analyzing the internal organization of belief
systems, including coherence conditions, epistemic tensions, and
representational limits. By distinguishing belief structure from belief
strength, this formalism enables a richer classification of epistemic states
than existing probabilistic, logical, or argumentation-based approaches.

</details>


### [160] [Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes](https://arxiv.org/abs/2508.03484)
*Zhiyao Xu,Dan Zhao,Qingsong Zou,Qing Li,Yong Jiang,Yuhang Wang,Jingyu Xiao*

Main category: cs.AI

TL;DR: SmartGen是一个基于LLM的框架，通过合成上下文感知的智能家居用户行为数据，以应对行为漂移导致的下游模型适应性差问题，并显著提升了异常检测和行为预测的性能。


<details>
  <summary>Details</summary>
Motivation: 智能家居模型通常在静态数据集上训练，难以适应由季节、生活方式变化等引起的用户行为漂移。然而，收集新的行为数据进行模型再训练因其缓慢、高成本和隐私问题而不切实际。

Method: 本文提出了SmartGen框架，一个基于LLM的解决方案，用于合成上下文感知的用户行为数据。它包含四个关键组件：1) 时间与语义感知分割模块，用于将长序列分割为可管理的子序列；2) 语义感知序列压缩，通过聚类减少输入长度并保留语义；3) 图引导序列合成，构建行为关系图并编码频繁转换到LLM提示中以生成数据；4) 两阶段异常值过滤器，用于识别和移除不合理或语义不一致的生成序列。

Result: 在三个真实世界数据集上的实验表明，SmartGen显著提升了在行为漂移情况下的模型性能。异常检测任务平均提升85.43%，行为预测任务平均提升70.51%。

Conclusion: SmartGen通过高效生成高质量、上下文感知的用户行为数据，成功解决了智能家居模型在行为漂移下的持续适应性问题，从而大幅提高了异常检测和行为预测任务的性能。

Abstract: As smart homes become increasingly prevalent, intelligent models are widely
used for tasks such as anomaly detection and behavior prediction. These models
are typically trained on static datasets, making them brittle to behavioral
drift caused by seasonal changes, lifestyle shifts, or evolving routines.
However, collecting new behavior data for retraining is often impractical due
to its slow pace, high cost, and privacy concerns. In this paper, we propose
SmartGen, an LLM-based framework that synthesizes context-aware user behavior
data to support continual adaptation of downstream smart home models. SmartGen
consists of four key components. First, we design a Time and Semantic-aware
Split module to divide long behavior sequences into manageable, semantically
coherent subsequences under dual time-span constraints. Second, we propose
Semantic-aware Sequence Compression to reduce input length while preserving
representative semantics by clustering behavior mapping in latent space. Third,
we introduce Graph-guided Sequence Synthesis, which constructs a behavior
relationship graph and encodes frequent transitions into prompts, guiding the
LLM to generate data aligned with contextual changes while retaining core
behavior patterns. Finally, we design a Two-stage Outlier Filter to identify
and remove implausible or semantically inconsistent outputs, aiming to improve
the factual coherence and behavioral validity of the generated sequences.
Experiments on three real-world datasets demonstrate that SmartGen
significantly enhances model performance on anomaly detection and behavior
prediction tasks under behavioral drift, with anomaly detection improving by
85.43% and behavior prediction by 70.51% on average. The code is available at
https://github.com/horizonsinzqs/SmartGen.

</details>


### [161] [VQA support to Arabic Language Learning Educational Tool](https://arxiv.org/abs/2508.03488)
*Khaled Bachir Delassi,Lakhdar Zeggane,Hadda Cherroun,Abdelhamid Haouhat,Kaoutar Bouzouad*

Main category: cs.AI

TL;DR: 开发并评估了一个基于AI的阿拉伯语学习工具，通过视觉问答和大型语言模型生成互动测验，旨在填补现代教学工具的空白，并取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语学习工具稀缺，尤其缺乏支持主动学习等现代教学模式的工具，这影响了学习者语言熟练度的提升。

Method: 设计并评估了一个AI驱动的教育工具，旨在增强初级至中级非母语学习者的阿拉伯语学习能力。该工具利用先进的AI模型（如视觉语言预训练模型生成图像描述，大型语言模型通过提示生成定制测验）来生成互动式视觉测验，并以视觉问答作为主要活动。它采用建构主义学习方法，通过真实的视觉测验和基于图像的问题鼓励主动学习，以提高词汇、语法和理解能力。该工具的有效性通过包含1266个真实视觉测验的手动标注基准以及人类参与者的反馈进行评估。

Result: 评估结果显示该工具具有合适的准确率，验证了其在弥补阿拉伯语教育空白方面的潜力。

Conclusion: 该AI驱动的工具被证明是一个可靠且有前景的阿拉伯语学习资源，能为学习者提供个性化、互动式的学习体验，有望有效提升阿拉伯语能力。

Abstract: We address the problem of scarcity of educational Arabic Language Learning
tools that advocate modern pedagogical models such as active learning which
ensures language proficiency. In fact, we investigate the design and evaluation
of an AI-powered educational tool designed to enhance Arabic language learning
for non-native speakers with beginner-to-intermediate proficiency level. The
tool leverages advanced AI models to generate interactive visual quizzes,
deploying Visual Question Answering as the primary activity. Adopting a
constructivist learning approach, the system encourages active learning through
real-life visual quizzes, and image-based questions that focus on improving
vocabulary, grammar, and comprehension. The system integrates Vision-Language
Pretraining models to generate contextually relevant image description from
which Large Language Model generate assignments based on customized Arabic
language Learning quizzes thanks to prompting.
  The effectiveness of the tool is evaluated through a manual annotated
benchmark consisting of 1266 real-life visual quizzes, with human participants
providing feedback. The results show a suitable accuracy rates, validating the
tool's potential to bridge the gap in Arabic language education and
highlighting the tool's promise as a reliable, AI-powered resource for Arabic
learners, offering personalized and interactive learning experiences.

</details>


### [162] [Error Detection and Correction for Interpretable Mathematics in Large Language Models](https://arxiv.org/abs/2508.03500)
*Yijin Yang,Cristina Cornelio,Mario Leiva,Paulo Shakarian*

Main category: cs.AI

TL;DR: 本文提出EDCIM，一种针对可解释数学任务的错误检测与修正方法，它结合LLM生成、符号错误检测和反馈修正，旨在解决LLM在多步推理中的错误传播、幻觉及格式依从性问题，并在降低成本的同时保持甚至提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在多步推理（如思维链）中常出现中间步骤错误，导致最终预测不准确。此外，LLMs还面临幻觉问题，并且难以遵循预设的输出格式，这在生成数学表达式或源代码等任务中尤为突出。

Method: EDCIM（Error Detection and Correction for Interpretable Mathematics）方法首先利用LLM生成问题的方程组，然后通过一个符号错误检测框架识别错误并提供定向反馈，以供LLM进行修正。为优化效率，EDCIM整合了轻量级开源LLM和强大的专有模型，并通过一个超参数来平衡成本与准确性。

Result: 实验结果显示，在不同数据集上，EDCIM在配置得当时能显著降低计算和财务成本，同时保持甚至提升预测准确性。

Conclusion: EDCIM通过结合LLM生成能力与符号错误检测机制，有效解决了LLM在可解释数学任务中存在的错误和效率问题，提供了一种在成本与准确性之间取得良好平衡的解决方案。

Abstract: Recent large language models (LLMs) have demonstrated the ability to perform
explicit multi-step reasoning such as chain-of-thought prompting. However,
their intermediate steps often contain errors that can propagate leading to
inaccurate final predictions. Additionally, LLMs still struggle with
hallucinations and often fail to adhere to prescribed output formats, which is
particularly problematic for tasks like generating mathematical expressions or
source code. This work introduces EDCIM (Error Detection and Correction for
Interpretable Mathematics), a method for detecting and correcting these errors
in interpretable mathematics tasks, where the model must generate the exact
functional form that explicitly solve the problem (expressed in natural
language) rather than a black-box solution. EDCIM uses LLMs to generate a
system of equations for a given problem, followed by a symbolic error-detection
framework that identifies errors and provides targeted feedback for LLM-based
correction. To optimize efficiency, EDCIM integrates lightweight, open-source
LLMs with more powerful proprietary models, balancing cost and accuracy. This
balance is controlled by a single hyperparameter, allowing users to control the
trade-off based on their cost and accuracy requirements. Experimental results
across different datasets show that EDCIM significantly reduces both
computational and financial costs, while maintaining, and even improving,
prediction accuracy when the balance is properly configured.

</details>


### [163] [Hidden Dynamics of Massive Activations in Transformer Training](https://arxiv.org/abs/2508.03616)
*Jorge Gallego-Feliciano,S. Aaron McClendon,Juan Morinelli,Stavros Zervoudakis,Antonios Saravanos*

Main category: cs.AI

TL;DR: 本研究首次全面分析了Transformer模型中巨量激活在训练过程中的出现动态，发现其遵循可预测的数学模式，并开发了机器学习框架，能仅凭架构设计预测这些模式，从而使设计者能在训练前预测并可能控制巨量激活。


<details>
  <summary>Details</summary>
Motivation: Transformer模型中的巨量激活对模型功能至关重要，但其在训练过程中出现的时间动态仍未被充分理解，阻碍了对其特性和影响的深入认识。

Method: 研究以Pythia模型家族为测试平台，通过系统分析不同模型尺寸在多个训练检查点上的数据，首次全面分析了巨量激活的发展过程。在此基础上，开发了一个机器学习框架，能够仅凭模型架构规格预测巨量激活的数学参数。

Result: 研究发现，巨量激活的出现遵循可预测的数学模式，并可使用具有五个关键参数的指数调制对数函数进行精确建模。所开发的机器学习框架在预测稳态行为方面实现了高精度，在预测出现时间和幅度方面也达到了中等精度。

Conclusion: 这些发现表明，巨量激活的出现受模型设计控制，可以在训练开始前进行预测并可能控制。这为模型设计者通过设计选择来影响巨量激活的关键方面提供了可能性，对提高模型稳定性、优化训练周期、增强可解释性等方面具有重要意义。

Abstract: Massive activations are scalar values in transformer hidden states that
achieve values orders of magnitude larger than typical activations and have
been shown to be critical for model functionality. While prior work has
characterized these phenomena in fully trained models, the temporal dynamics of
their emergence during training remain poorly understood. We present the first
comprehensive analysis of massive activation development throughout transformer
training, using the Pythia model family as our testbed. Through systematic
analysis of various model sizes across multiple training checkpoints, we
demonstrate that massive activation emergence follows predictable mathematical
patterns that can be accurately modeled using an exponentially-modulated
logarithmic function with five key parameters. We develop a machine learning
framework to predict these mathematical parameters from architectural
specifications alone, achieving high accuracy for steady-state behavior and
moderate accuracy for emergence timing and magnitude. These findings enable
architects to predict and potentially control key aspects of massive activation
emergence through design choices, with significant implications for model
stability, training cycle length, interpretability, and optimization. Our
findings demonstrate that the emergence of massive activations is governed by
model design and can be anticipated, and potentially controlled, before
training begins.

</details>


### [164] [Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework](https://arxiv.org/abs/2508.03622)
*Jialin Li,Jinzhe Li,Gengxu Li,Yi Chang,Yuan Wu*

Main category: cs.AI

TL;DR: 大模型在错误前提下生成代码时极易产生幻觉，揭示其自我审查能力不足。本文提出了首个针对错误前提的代码生成评估框架FPBench，并评估发现大多数模型在此情境下性能差、缺乏主动验证前提的能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)代码生成能力增强，其对输入前提的依赖加剧。当用户提供包含错误前提的输入时，代码生成幻觉显著增加，暴露出LLMs自我审查能力的缺陷。

Method: 提出了首个针对错误前提的代码生成评估框架FPBench。该框架通过系统构建三类错误前提，并整合多维度评估指标，对15个代表性LLMs进行了深入评估。

Result: (1) 大多数模型在错误前提下推理能力差、代码生成性能不佳，严重依赖显式提示进行错误检测，自我审查能力有限；(2) 错误前提引发资源投入的边际效应递减，盲目增加输入长度无法提升质量；(3) 三类错误前提分别激活模型不同的缺陷模式，揭示了代码生成模型认知机制的三重分离。

Conclusion: 本研究强调了LLMs在代码生成中主动验证前提的紧迫性，并为开发可靠、以人为中心的代码生成模型提供了理论基础和实践路径。

Abstract: With the advancement of code generation capabilities in large language models
(LLMs), their reliance on input premises has intensified. When users provide
inputs containing faulty premises, the probability of code generation
hallucinations rises significantly, exposing deficiencies in their
self-scrutiny capabilities. This paper proposes Faulty Premises Bench
(FPBench), the first code generation evaluation framework targeting faulty
premises. By systematically constructing three categories of faulty premises
and integrating multi-dimensional evaluation metrics, it conducts in-depth
assessments of 15 representative LLMs. The key findings are as follows: (1)
Most models exhibit poor reasoning abilities and suboptimal code generation
performance under faulty premises, heavily relying on explicit prompts for
error detection, with limited self-scrutiny capabilities; (2) Faulty premises
trigger a point of diminishing returns in resource investment, leading to
blindly increasing length fails to enhance quality; (3) The three types of
faulty premises respectively activate distinct defect patterns in models,
revealing a triple dissociation in the cognitive mechanisms of code generation
models. This study not only highlights the urgent need for LLMs to proactively
verify premises in code generation but also, through the proposed FPBench
framework and multi-dimensional evaluation system, provides a theoretical
foundation and practical pathway for developing reliable, human-centric code
generation models.

</details>


### [165] [Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search](https://arxiv.org/abs/2508.03661)
*He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: 本文提出Evo-MCTS框架，通过结合树搜索、进化优化和LLM启发式，解决引力波信号识别中现有算法（MF和DNN）的局限性，并在MLGWSC-1数据集上实现了显著性能提升，同时生成可解释的算法路径。


<details>
  <summary>Details</summary>
Motivation: 计算科学发现，特别是引力波信号识别，面临挑战。现有算法如匹配滤波（MF）计算成本高且依赖预定义模板，而深度神经网络（DNNs）存在“黑箱”问题，缺乏决策逻辑可解释性并引入隐藏偏差。

Method: 提出进化蒙特卡洛树搜索（Evo-MCTS）框架。该方法通过领域感知物理约束指导系统性算法空间探索，结合树结构搜索、进化优化以及大语言模型（LLM）启发式，旨在创建可解释的算法解决方案。

Result: Evo-MCTS框架在MLGWSC-1基准数据集上，比最先进的引力波探测算法性能提高了20.2%。高性能算法变体持续超越阈值，并生成揭示独特性能模式的人类可解释算法路径。

Conclusion: 除了性能提升，Evo-MCTS框架还发现了新颖的算法组合，建立了一种可转移的自动化算法发现方法，适用于计算科学领域的其他应用。

Abstract: Computational scientific discovery increasingly relies on algorithms to
process complex data and identify meaningful patterns - yet faces persistent
challenges in gravitational-wave signal identification. While existing
algorithmic approaches like matched filtering (MF) and deep neural networks
(DNNs) have achieved partial success, their limitations directly stem from
fundamental limitations: MF's excessive computational demands arise from its
reliance on predefined theoretical waveform templates, while DNNs' black-box
architectures obscure decision logic and introduce hidden biases. We propose
Evolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses
these limitations through systematic algorithm space exploration guided by
domain-aware physical constraints. Our approach combines tree-structured search
with evolutionary optimization and large language model heuristics to create
interpretable algorithmic solutions. Our Evo-MCTS framework demonstrates
substantial improvements, achieving a 20.2\% improvement over state-of-the-art
gravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.
High-performing algorithm variants consistently exceed thresholds. The
framework generates human-interpretable algorithmic pathways that reveal
distinct performance patterns. Beyond performance improvements, our framework
discovers novel algorithmic combinations, thereby establishing a transferable
methodology for automated algorithmic discovery across computational science
domains.

</details>


### [166] [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680)
*Xufang Luo,Yuge Zhang,Zhiyuan He,Zilong Wang,Siyun Zhao,Dongsheng Li,Luna K. Qiu,Yuqing Yang*

Main category: cs.AI

TL;DR: Agent Lightning是一个解耦的强化学习（RL）训练框架，专为大型语言模型（LLM）代理设计，能与现有代理无缝集成，并通过统一接口和分层RL算法实现稳定性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的RL训练方法通常与代理执行紧密耦合，或依赖序列拼接与掩码，导致集成困难且灵活性不足。需要一个能将代理执行与训练完全解耦、易于集成现有代理的通用框架。

Method: 本文提出了Agent Lightning框架。它将代理执行建模为马尔可夫决策过程（MDP），并定义了一个统一的数据接口。核心是提出分层RL算法LightningRL，包含信用分配模块，能够将任意代理生成的轨迹分解为训练转换。系统设计上，引入了训练-代理分离架构（Training-Agent Disaggregation architecture），并将代理可观测性框架引入代理运行时，提供标准化的代理微调接口。

Result: 在text-to-SQL、检索增强生成（RAG）和数学工具使用等任务上的实验表明，该框架能实现稳定且持续的性能提升。

Conclusion: Agent Lightning框架展示了其在真实世界代理训练和部署方面的巨大潜力，能够有效提升LLM代理在复杂任务中的性能表现。

Abstract: We present Agent Lightning, a flexible and extensible framework that enables
Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for
any AI agent. Unlike existing methods that tightly couple RL training with
agent or rely on sequence concatenation with masking, Agent Lightning achieves
complete decoupling between agent execution and training, allowing seamless
integration with existing agents developed via diverse ways (e.g., using
frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from
scratch) with almost ZERO code modifications. By formulating agent execution as
Markov decision process, we define an unified data interface and propose a
hierarchical RL algorithm, LightningRL, which contains a credit assignment
module, allowing us to decompose trajectories generated by ANY agents into
training transition. This enables RL to handle complex interaction logic, such
as multi-agent scenarios and dynamic workflows. For the system design, we
introduce a Training-Agent Disaggregation architecture, and brings agent
observability frameworks into agent runtime, providing a standardized agent
finetuning interface. Experiments across text-to-SQL, retrieval-augmented
generation, and math tool-use tasks demonstrate stable, continuous
improvements, showcasing the framework's potential for real-world agent
training and deployment.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [167] [A Bayesian Hybrid Parameter-Efficient Fine-Tuning Method for Large Language Models](https://arxiv.org/abs/2508.02711)
*Yidong Chai,Yang Liu,Yonghang Zhou,Jiaheng Xie,Daniel Dajun Zeng*

Main category: cs.LG

TL;DR: 本文提出BH-PEFT，一种贝叶斯混合参数高效微调方法，用于解决大型语言模型在特定业务应用微调中缺乏不确定性量化和动态适应性的问题，并验证了其在多种业务任务上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）需要领域特定微调以优化业务应用性能。尽管混合参数高效微调（PEFT）方法表现最佳，但现有方法存在两大挑战：1) 依赖点估计，无法量化不确定性以支持可靠决策；2) 难以动态适应新数据，不适用于真实世界情境。

Method: 提出贝叶斯混合参数高效微调（BH-PEFT），将贝叶斯学习融入混合PEFT。BH-PEFT结合了Adapter、LoRA和Prefix-tuning，对Transformer的Feedforward和Attention层进行微调。通过将可学习参数建模为分布，实现不确定性量化。此外，提出一种贝叶斯动态微调方法，将上一轮的后验分布作为下一轮的先验，以有效适应新数据。

Result: BH-PEFT在情感分析、新闻分类和常识推理等业务任务上进行了评估。结果表明，该方法优于现有PEFT基线，能够量化不确定性以实现更可靠的决策，并提高了在动态场景中的适应性。

Conclusion: 本研究通过提出新颖的BH-PEFT方法和动态微调方法，为商业分析和数据科学做出了贡献，支持在真实世界情境中进行不确定性感知和自适应决策。

Abstract: Large Language Models (LLMs) have demonstrated transformative potential in
reshaping the world. As these models are pretrained on general corpora, they
often require domain-specific fine-tuning to optimize performance in
specialized business applications. Due to their massive scale,
parameter-efficient fine-tuning (PEFT) methods are widely used to reduce
training costs. Among them, hybrid PEFT methods that combine multiple PEFT
techniques have achieved the best performance. However, existing hybrid PEFT
methods face two main challenges when fine-tuning LLMs for specialized
applications: (1) relying on point estimates, lacking the ability to quantify
uncertainty for reliable decision-making, and (2) struggling to dynamically
adapt to emerging data, lacking the ability to suit real-world situations. We
propose Bayesian Hybrid Parameter-Efficient Fine-Tuning (BH-PEFT), a novel
method that integrates Bayesian learning into hybrid PEFT. BH-PEFT combines
Adapter, LoRA, and prefix-tuning to fine-tune feedforward and attention layers
of the Transformer. By modeling learnable parameters as distributions, BH-PEFT
enables uncertainty quantification. We further propose a Bayesian dynamic
fine-tuning approach where the last posterior serves as the prior for the next
round, enabling effective adaptation to new data. We evaluated BH-PEFT on
business tasks such as sentiment analysis, news categorization, and commonsense
reasoning. Results show that our method outperforms existing PEFT baselines,
enables uncertainty quantification for more reliable decisions, and improves
adaptability in dynamic scenarios. This work contributes to business analytics
and data science by proposing a novel BH-PEFT method and dynamic fine-tuning
approach that support uncertainty-aware and adaptive decision-making in
real-world situations.

</details>


### [168] [ZetA: A Riemann Zeta-Scaled Extension of Adam for Deep Learning](https://arxiv.org/abs/2508.02719)
*Samiksha BC*

Main category: cs.LG

TL;DR: ZetA是一个新型深度学习优化器，通过集成黎曼zeta函数动态缩放和多项高级机制，在多个图像分类任务中展现出优于Adam的泛化性和鲁棒性，尤其适用于噪声或高粒度数据。


<details>
  <summary>Details</summary>
Motivation: 旨在改进Adam优化器的泛化性和鲁棒性，并首次探索将黎曼zeta函数应用于深度学习梯度缩放，填补了该领域的空白。

Method: 提出ZetA优化器，扩展Adam，核心在于引入基于黎曼zeta函数的动态梯度缩放。其混合更新机制还包括自适应阻尼、基于余弦相似度的动量提升、熵正则化损失和Sharpness-Aware Minimization (SAM)-风格扰动。在多种图像分类数据集（如SVHN、CIFAR系列）上使用轻量级全连接网络进行评估。

Result: 在SVHN、CIFAR10、CIFAR100、STL10和噪声CIFAR10等数据集上，ZetA的测试准确性持续超越Adam。实验证明ZetA是计算高效且鲁棒的Adam替代方案，特别适用于噪声或高粒度分类任务。

Conclusion: ZetA是一种有效且计算高效的深度学习优化器，通过结合黎曼zeta函数缩放与先进更新机制，显著提升了模型在噪声或高粒度分类任务中的泛化性和鲁棒性，为Adam提供了一个优秀的替代选择。

Abstract: This work introduces ZetA, a novel deep learning optimizer that extends Adam
by incorporating dynamic scaling based on the Riemann zeta function. To the
best of our knowledge, ZetA is the first optimizer to apply zeta-based gradient
scaling within deep learning optimization. The method improves generalization
and robustness through a hybrid update mechanism that integrates adaptive
damping, cosine similarity-based momentum boosting, entropy-regularized loss,
and Sharpness-Aware Minimization (SAM)-style perturbations. Empirical
evaluations on SVHN, CIFAR10, CIFAR100, STL10, and noisy CIFAR10 consistently
show test accuracy improvements over Adam. All experiments employ a lightweight
fully connected network trained for five epochs under mixed-precision settings.
The results demonstrate that ZetA is a computationally efficient and robust
alternative to Adam, particularly effective in noisy or high-granularity
classification tasks.

</details>


### [169] [ECGTwin: Personalized ECG Generation Using Controllable Diffusion Model](https://arxiv.org/abs/2508.02720)
*Yongfan Lai,Bo Liu,Xinyan Guan,Qinghao Zhao,Hongyan Li,Shenda Hong*

Main category: cs.LG

TL;DR: ECGTwin是一个双阶段框架，通过对比学习提取个体特征并使用新型注入器整合条件，实现高保真、多样化且保留个人特性的个性化心电图生成，有望提升精准医疗。


<details>
  <summary>Details</summary>
Motivation: 旨在通过模拟患者个性化心电图数字孪生来将传统医疗转变为更精准的个体化范式，同时解决在无真实标签下提取个体特征以及在不混淆生成模型的情况下注入多种条件的挑战。

Method: 提出ECGTwin双阶段框架。第一阶段，通过对比学习训练的个体基础提取器(Individual Base Extractor)从参考心电图捕获个人特征。第二阶段，通过新颖的AdaX条件注入器(AdaX Condition Injector)将提取的个体特征和目标心脏状况集成到基于扩散的生成过程中，该注入器通过两条专用通路注入信号。

Result: 定性和定量实验证明，该模型不仅能生成高保真、多样性且具有精细粒度控制的心电图信号，还能保留个体特异性特征。此外，ECGTwin在下游应用中显示出增强心电图自动诊断的潜力。

Conclusion: 证实了实现精准个性化医疗解决方案的可能性。

Abstract: Personalized electrocardiogram (ECG) generation is to simulate a patient's
ECG digital twins tailored to specific conditions. It has the potential to
transform traditional healthcare into a more accurate individualized paradigm,
while preserving the key benefits of conventional population-level ECG
synthesis. However, this promising task presents two fundamental challenges:
extracting individual features without ground truth and injecting various types
of conditions without confusing generative model. In this paper, we present
ECGTwin, a two-stage framework designed to address these challenges. In the
first stage, an Individual Base Extractor trained via contrastive learning
robustly captures personal features from a reference ECG. In the second stage,
the extracted individual features, along with a target cardiac condition, are
integrated into the diffusion-based generation process through our novel AdaX
Condition Injector, which injects these signals via two dedicated and
specialized pathways. Both qualitative and quantitative experiments have
demonstrated that our model can not only generate ECG signals of high fidelity
and diversity by offering a fine-grained generation controllability, but also
preserving individual-specific features. Furthermore, ECGTwin shows the
potential to enhance ECG auto-diagnosis in downstream application, confirming
the possibility of precise personalized healthcare solutions.

</details>


### [170] [Mathematical Foundations of Geometric Deep Learning](https://arxiv.org/abs/2508.02723)
*Haitz Sáez de Ocáriz Borde,Michael Bronstein*

Main category: cs.LG

TL;DR: 综述几何深度学习所需的关键数学概念。


<details>
  <summary>Details</summary>
Motivation: 为理解和研究几何深度学习提供必要的数学基础。

Method: 通过回顾和整理，对相关数学概念进行综述。

Result: 系统性地总结了学习几何深度学习所需的核心数学概念。

Conclusion: 本综述为几何深度学习领域的研究和学习提供了重要的数学基础指南。

Abstract: We review the key mathematical concepts necessary for studying Geometric Deep
Learning.

</details>


### [171] [Forecasting NCAA Basketball Outcomes with Deep Learning: A Comparative Study of LSTM and Transformer Models](https://arxiv.org/abs/2508.02725)
*Md Imtiaz Habib*

Main category: cs.LG

TL;DR: 本研究利用LSTM和Transformer深度学习模型，结合丰富的特征工程（如GLM、Elo等级分），预测NCAA篮球锦标赛结果。结果显示，Transformer在判别能力上更优，而LSTM在概率校准上表现更佳。


<details>
  <summary>Details</summary>
Motivation: 预测2025年NCAA男子和女子篮球锦标赛的结果，并探索先进深度学习方法在此领域的应用潜力。

Method: 利用历史NCAA比赛数据，实施LSTM和Transformer两种序列模型。通过特征工程增强预测能力，特征包括GLM衍生的球队质量指标、Elo等级分、种子差异和聚合盒式数据统计。使用二元交叉熵（BCE）和Brier损失函数训练和评估模型。

Result: 经BCE优化的Transformer架构展现出卓越的判别能力（最高AUC为0.8473）。而经Brier损失训练的LSTM模型在概率校准方面表现更优（最低Brier分数为0.1589）。

Conclusion: 选择合适的模型架构和损失函数对于预测任务至关重要。本研究提出的分析流程可作为体育分析及其他领域未来预测建模任务的可复现框架。

Abstract: In this research, I explore advanced deep learning methodologies to forecast
the outcomes of the 2025 NCAA Division 1 Men's and Women's Basketball
tournaments. Leveraging historical NCAA game data, I implement two
sophisticated sequence-based models: Long Short-Term Memory (LSTM) and
Transformer architectures. The predictive power of these models is augmented
through comprehensive feature engineering, including team quality metrics
derived from Generalized Linear Models (GLM), Elo ratings, seed differences,
and aggregated box-score statistics. To evaluate the robustness and reliability
of predictions, I train each model variant using both Binary Cross-Entropy
(BCE) and Brier loss functions, providing insights into classification
performance and probability calibration. My comparative analysis reveals that
while the Transformer architecture optimized with BCE yields superior
discriminative power (highest AUC of 0.8473), the LSTM model trained with Brier
loss demonstrates superior probabilistic calibration (lowest Brier score of
0.1589). These findings underscore the importance of selecting appropriate
model architectures and loss functions based on the specific requirements of
forecasting tasks. The detailed analytical pipeline presented here serves as a
reproducible framework for future predictive modeling tasks in sports analytics
and beyond.

</details>


### [172] [Embedding-Enhanced Probabilistic Modeling of Ferroelectric Field Effect Transistors (FeFETs)](https://arxiv.org/abs/2508.02737)
*Tasnia Nobi Afee,Jack Hutchins,Md Mazharul Islam,Thomas Kampfe,Ahmedullah Aziz*

Main category: cs.LG

TL;DR: 本文提出了一种增强的概率建模框架，用于捕获FeFETs的全部随机行为，以解决现有模型在变异性捕获和电路集成平滑性方面的不足。


<details>
  <summary>Details</summary>
Motivation: FeFETs在存储和逻辑技术中有巨大潜力，但其固有的操作周期和制造变异性导致建模困难。现有确定性和基于机器学习的紧凑模型未能充分捕捉这种变异性，或缺乏集成到电路级所需的数学平滑性。

Method: 该研究提出了一种基于混合密度网络（MDN）的增强型概率建模框架。该框架集成了C-infinity连续激活函数以实现平滑稳定的学习，并引入了设备特定的嵌入层以捕捉设备间的内在物理变异性。通过从学习到的嵌入分布中采样，可以生成用于变异性感知仿真的合成设备实例。

Result: 该模型在捕获FeFET电流行为的变异性方面表现出高精度，R2值达到0.92。该框架能够生成合成设备实例以进行变异性感知仿真。

Conclusion: 该框架为FeFETs的随机行为建模提供了一个可扩展、数据驱动的解决方案，并为未来的紧凑模型开发和电路仿真集成奠定了坚实基础。

Abstract: FeFETs hold strong potential for advancing memory and logic technologies, but
their inherent randomness arising from both operational cycling and fabrication
variability poses significant challenges for accurate and reliable modeling.
Capturing this variability is critical, as it enables designers to predict
behavior, optimize performance, and ensure reliability and robustness against
variations in manufacturing and operating conditions. Existing deterministic
and machine learning-based compact models often fail to capture the full extent
of this variability or lack the mathematical smoothness required for stable
circuit-level integration. In this work, we present an enhanced probabilistic
modeling framework for FeFETs that addresses these limitations. Building upon a
Mixture Density Network (MDN) foundation, our approach integrates C-infinity
continuous activation functions for smooth, stable learning and a
device-specific embedding layer to capture intrinsic physical variability
across devices. Sampling from the learned embedding distribution enables the
generation of synthetic device instances for variability-aware simulation. With
an R2 of 0.92, the model demonstrates high accuracy in capturing the
variability of FeFET current behavior. Altogether, this framework provides a
scalable, data-driven solution for modeling the full stochastic behavior of
FeFETs and offers a strong foundation for future compact model development and
circuit simulation integration.

</details>


### [173] [DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening](https://arxiv.org/abs/2508.02741)
*Zhixiang Lu,Yulong Li,Feilong Tang,Zhengyong Jiang,Chong Li,Mian Zhou,Tenglong Li,Jionglong Su*

Main category: cs.LG

TL;DR: DeepGB-TB是一种基于咳嗽音频和人口统计数据的非侵入式结核病风险评估系统，通过创新的跨模态注意力机制和风险平衡损失实现了0.903的AUROC和0.851的F1分数，达到了新的技术水平，并可在移动设备上高效运行，适用于大规模筛查。


<details>
  <summary>Details</summary>
Motivation: 传统结核病筛查诊断成本高昂且操作复杂，限制了大规模应用。因此，亟需开发人工智能解决方案来应对这些挑战。

Method: 提出了DeepGB-TB系统，利用咳嗽音频和基本人口统计数据进行结核病风险评分。该模型结合了用于音频处理的轻量级一维卷积神经网络和用于表格特征的梯度提升决策树。主要创新包括：1. 跨模态双向交叉注意力模块（CM-BCA），用于模拟临床医生整合症状和风险因素的方式，迭代交换模态间信息。2. 结核病风险平衡损失（TRBL），对假阴性预测施以更强惩罚，以减少高风险误分类。

Result: DeepGB-TB在来自七个国家的1,105名患者的多元化数据集上进行了评估，实现了0.903的AUROC和0.851的F1分数，达到了新的SOTA。该系统计算效率高，支持在普通移动设备上进行实时离线推理，非常适合资源匮乏地区。此外，它能提供经过临床验证的解释，提升了信任度和采纳度。

Conclusion: DeepGB-TB将AI创新与公共卫生对速度、可负担性和可靠性的要求相结合，为推进全球结核病控制提供了一个重要工具。

Abstract: Large-scale tuberculosis (TB) screening is limited by the high cost and
operational complexity of traditional diagnostics, creating a need for
artificial-intelligence solutions. We propose DeepGB-TB, a non-invasive system
that instantly assigns TB risk scores using only cough audio and basic
demographic data. The model couples a lightweight one-dimensional convolutional
neural network for audio processing with a gradient-boosted decision tree for
tabular features. Its principal innovation is a Cross-Modal Bidirectional
Cross-Attention module (CM-BCA) that iteratively exchanges salient cues between
modalities, emulating the way clinicians integrate symptoms and risk factors.
To meet the clinical priority of minimizing missed cases, we design a
Tuberculosis Risk-Balanced Loss (TRBL) that places stronger penalties on
false-negative predictions, thereby reducing high-risk misclassifications.
DeepGB-TB is evaluated on a diverse dataset of 1,105 patients collected across
seven countries, achieving an AUROC of 0.903 and an F1-score of 0.851,
representing a new state of the art. Its computational efficiency enables
real-time, offline inference directly on common mobile devices, making it ideal
for low-resource settings. Importantly, the system produces clinically
validated explanations that promote trust and adoption by frontline health
workers. By coupling AI innovation with public-health requirements for speed,
affordability, and reliability, DeepGB-TB offers a tool for advancing global TB
control.

</details>


### [174] [Considering Spatial Structure of the Road Network in Pavement Deterioration Modeling](https://arxiv.org/abs/2508.02749)
*Lu Gao,Ke Yu,Pan Lu*

Main category: cs.LG

TL;DR: 本研究利用图神经网络（GNN）将道路网络的空间依赖性纳入路面劣化建模，并发现考虑空间关系能显著提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 路面劣化建模对于道路网络的未来状态预测和维护决策至关重要。使用图神经网络（GNN）的动机是其能够轻松直接地利用道路网络中丰富的结构信息，从而期望提高路面劣化模型的预测性能。

Method: 研究通过图神经网络（GNN）将道路网络的空间依赖性整合到路面劣化建模中。使用了来自德克萨斯州交通部路面管理信息系统（PMIS）的超过五十万条观测数据的大型路面状况数据集。

Result: 通过对比结果表明，在考虑道路网络的空间关系时，路面劣化预测模型的性能有所提高。

Conclusion: 研究得出结论，考虑道路网络的空间结构能够改进路面劣化模型的预测性能。

Abstract: Pavement deterioration modeling is important in providing information
regarding the future state of the road network and in determining the needs of
preventive maintenance or rehabilitation treatments. This research incorporated
spatial dependence of road network into pavement deterioration modeling through
a graph neural network (GNN). The key motivation of using a GNN for pavement
performance modeling is the ability to easily and directly exploit the rich
structural information in the network. This paper explored if considering
spatial structure of the road network will improve the prediction performance
of the deterioration models. The data used in this research comprises a large
pavement condition data set with more than a half million observations taken
from the Pavement Management Information System (PMIS) maintained by the Texas
Department of Transportation. The promising comparison results indicates that
pavement deterioration prediction models perform better when spatial
relationship is considered.

</details>


### [175] [Pulse Shape Discrimination Algorithms: Survey and Benchmark](https://arxiv.org/abs/2508.02750)
*Haoran Liu,Yihan Zhan,Mingzhe Liu,Yanhua Liu,Peng Li,Zhuo Zuo,Bingqi Liu,Runxi Liu*

Main category: cs.LG

TL;DR: 该综述对近六十种脉冲形状鉴别（PSD）算法进行了全面调查和基准测试，发现深度学习模型在辐射探测中表现优于传统方法，并发布了开源工具包和数据集以促进研究。


<details>
  <summary>Details</summary>
Motivation: 对辐射探测中的脉冲形状鉴别（PSD）算法进行全面调研和基准测试，分类并评估现有方法，以识别高性能算法并推动PSD研究的发展。

Method: 将近六十种PSD算法分为统计（时域、频域、神经网络）和先验知识（机器学习、深度学习）范式。在两个标准化数据集（非标记241Am-9Be和带标记238Pu-9Be）上实现并评估所有算法，使用FOM、F1-score、ROC-AUC和方法间相关性等指标。

Result: 深度学习模型（特别是多层感知器和结合统计特征的混合方法）通常优于传统方法。分析还讨论了架构适用性、FOM的局限性、替代评估指标以及在不同能量阈值下的性能。

Conclusion: 深度学习模型在PSD领域具有显著潜力。通过发布开源工具包和数据集，该研究旨在提高PSD研究的复现性并促进其进一步发展。

Abstract: This review presents a comprehensive survey and benchmark of pulse shape
discrimination (PSD) algorithms for radiation detection, classifying nearly
sixty methods into statistical (time-domain, frequency-domain, neural
network-based) and prior-knowledge (machine learning, deep learning) paradigms.
We implement and evaluate all algorithms on two standardized datasets: an
unlabeled set from a 241Am-9Be source and a time-of-flight labeled set from a
238Pu-9Be source, using metrics including Figure of Merit (FOM), F1-score,
ROC-AUC, and inter-method correlations. Our analysis reveals that deep learning
models, particularly Multi-Layer Perceptrons (MLPs) and hybrid approaches
combining statistical features with neural regression, often outperform
traditional methods. We discuss architectural suitabilities, the limitations of
FOM, alternative evaluation metrics, and performance across energy thresholds.
Accompanying this work, we release an open-source toolbox in Python and MATLAB,
along with the datasets, to promote reproducibility and advance PSD research.

</details>


### [176] [SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference](https://arxiv.org/abs/2508.02751)
*Yi Zhao,Yajuan Peng,Cam-Tu Nguyen,Zuchao Li,Xiaoliang Wang,Hai Zhao,Xiaoming Fu*

Main category: cs.LG

TL;DR: 现有KV缓存逐出方法无法适应动态注意力并可能过度压缩边缘信息。本文提出SmallKV，利用小模型辅助大模型进行KV缓存压缩，通过注意力匹配提升性能和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长上下文场景中面临资源限制，KV缓存逐出是有效解决方案。然而，现有令牌级逐出方法存在两个主要问题：1) 不可逆逐出策略无法适应解码期间动态注意力模式（显著性转移问题）；2) 未能区分对待边缘重要令牌和真正不重要令牌，导致边缘信息过度压缩。

Method: 本文提出了SmallKV，一种小模型辅助的KV缓存压缩方法。该方法基于不同规模LLM之间注意力矩阵的高度相似性，设计了两种补偿机制。SmallKV通过维持不同规模LLM之间的注意力匹配来：1) 辅助大模型感知全局重要的注意力信息；2) 利用小模型的注意力分数近似大模型中边缘令牌的分数。

Result: 在GSM8K、BBH、MT-Bench和LongBench等基准测试上的大量实验证明了SmallKV的有效性。此外，效率评估显示，SmallKV的吞吐量比基线方法高出1.75至2.56倍。

Conclusion: SmallKV在资源受限的环境下，为LLM推理提供了一种高效且高性能的KV缓存逐出方案，能够有效缓解长上下文场景下的资源瓶颈。

Abstract: KV cache eviction has emerged as an effective solution to alleviate resource
constraints faced by LLMs in long-context scenarios. However, existing
token-level eviction methods often overlook two critical aspects: (1) their
irreversible eviction strategy fails to adapt to dynamic attention patterns
during decoding (the saliency shift problem), and (2) they treat both
marginally important tokens and truly unimportant tokens equally, despite the
collective significance of marginal tokens to model performance (the marginal
information over-compression problem). To address these issues, we design two
compensation mechanisms based on the high similarity of attention matrices
between LLMs of different scales. We propose SmallKV, a small model assisted
compensation method for KV cache compression. SmallKV can maintain attention
matching between different-scale LLMs to: 1) assist the larger model in
perceiving globally important information of attention; and 2) use the smaller
model's attention scores to approximate those of marginal tokens in the larger
model. Extensive experiments on benchmarks including GSM8K, BBH, MT-Bench, and
LongBench demonstrate the effectiveness of SmallKV. Moreover, efficiency
evaluations show that SmallKV achieves 1.75 - 2.56 times higher throughput than
baseline methods, highlighting its potential for efficient and performant LLM
inference in resource constrained environments.

</details>


### [177] [DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting](https://arxiv.org/abs/2508.02753)
*Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DMSC的动态多尺度协调框架，通过多尺度切片分解、三元交互和自适应尺度路由MoE来解决时间序列预测中复杂的时序依赖建模挑战，并在多个真实世界基准测试中达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在建模复杂的多尺度时序依赖方面面临持续挑战。尽管现有方法（如基于CNN、MLP或Transformer的分解操作和新颖架构）有所进展，但仍存在静态分解策略、碎片化依赖建模和不灵活的融合机制，限制了它们建模复杂时序依赖的能力。

Method: 该论文提出了一个动态多尺度协调框架（DMSC），包含三个关键组件：1. **多尺度切片分解模块（EMPD）**：动态地将序列分割成具有指数级粒度的分层切片，消除预定义尺度限制。2. **三元交互模块（TIB）**：在每一层的分解表示中联合建模切片内、切片间和跨变量依赖。EMPD和TIB共同集成到多层渐进级联架构中，粗粒度表示指导后续层的细粒度特征提取。3. **自适应尺度路由MoE模块（ASR-MoE）**：利用专业的全局和局部专家，通过时序感知加权动态融合多尺度预测。

Result: 在十三个真实世界基准测试上的综合实验表明，DMSC在时间序列预测任务中持续保持最先进（SOTA）的性能和卓越的计算效率。

Conclusion: DMSC框架通过其创新的动态多尺度处理能力，有效解决了时间序列预测中复杂时序依赖建模的挑战，达到了行业领先的预测精度和效率。

Abstract: Time Series Forecasting (TSF) faces persistent challenges in modeling
intricate temporal dependencies across different scales. Despite recent
advances leveraging different decomposition operations and novel architectures
based on CNN, MLP or Transformer, existing methods still struggle with static
decomposition strategies, fragmented dependency modeling, and inflexible fusion
mechanisms, limiting their ability to model intricate temporal dependencies. To
explicitly solve the mentioned three problems respectively, we propose a novel
Dynamic Multi-Scale Coordination Framework (DMSC) with Multi-Scale Patch
Decomposition block (EMPD), Triad Interaction Block (TIB) and Adaptive Scale
Routing MoE block (ASR-MoE). Specifically, EMPD is designed as a built-in
component to dynamically segment sequences into hierarchical patches with
exponentially scaled granularities, eliminating predefined scale constraints
through input-adaptive patch adjustment. TIB then jointly models intra-patch,
inter-patch, and cross-variable dependencies within each layer's decomposed
representations. EMPD and TIB are jointly integrated into layers forming a
multi-layer progressive cascade architecture, where coarse-grained
representations from earlier layers adaptively guide fine-grained feature
extraction in subsequent layers via gated pathways. And ASR-MoE dynamically
fuses multi-scale predictions by leveraging specialized global and local
experts with temporal-aware weighting. Comprehensive experiments on thirteen
real-world benchmarks demonstrate that DMSC consistently maintains
state-of-the-art (SOTA) performance and superior computational efficiency for
TSF tasks. Code is available at https://github.com/1327679995/DMSC.

</details>


### [178] [Heterogeneity-Oblivious Robust Federated Learning](https://arxiv.org/abs/2508.03579)
*Weiyao Zhang,Jinyang Li,Qi Song,Miao Wang,Chungang Lin,Haitong Luo,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: Horus是一个针对联邦学习中毒攻击的鲁棒框架，通过聚合低秩适应（LoRA）并利用LoRA-A的稳定性进行恶意客户端检测和投影感知聚合，显著提升了异构环境下的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）易受中毒攻击，尤其在数据分布、通信能力和模型架构高度异构的真实世界场景下。这种异构性不仅削弱了聚合策略的有效性，还使攻击更难被检测。此外，高维模型增大了攻击面。

Method: 我们提出了Horus框架，核心是使用低秩适应（LoRA）。Horus将LoRA插入经验稳定的层中，仅聚合LoRA以减少攻击面。我们发现LoRA-A（输入投影）在异构性和中毒攻击下比LoRA-B（输出投影）更稳定。利用此发现，我们设计了使用LoRA-A特征的异构无关中毒分数来过滤恶意客户端。对于良性客户端，我们提出了投影感知聚合机制，通过根据与全局方向的一致性重新加权客户端更新来保留协作信号并抑制漂移。

Result: 在多种数据集、模型架构和攻击类型下的广泛实验表明，Horus在鲁棒性和准确性方面持续优于现有最先进的基线方法。

Conclusion: Horus通过聚合低秩适应（LoRA）并利用LoRA-A的稳定性进行客户端过滤和投影感知聚合，有效解决了联邦学习在高度异构环境下中毒攻击的挑战，显著提升了模型的鲁棒性和准确性。

Abstract: Federated Learning (FL) remains highly vulnerable to poisoning attacks,
especially under real-world hyper-heterogeneity, where clients differ
significantly in data distributions, communication capabilities, and model
architectures. Such heterogeneity not only undermines the effectiveness of
aggregation strategies but also makes attacks more difficult to detect.
Furthermore, high-dimensional models expand the attack surface. To address
these challenges, we propose Horus, a heterogeneity-oblivious robust FL
framework centered on low-rank adaptations (LoRAs). Rather than aggregating
full model parameters, Horus inserts LoRAs into empirically stable layers and
aggregates only LoRAs to reduce the attack surface.We uncover a key empirical
observation that the input projection (LoRA-A) is markedly more stable than the
output projection (LoRA-B) under heterogeneity and poisoning. Leveraging this,
we design a Heterogeneity-Oblivious Poisoning Score using the features from
LoRA-A to filter poisoned clients. For the remaining benign clients, we propose
projection-aware aggregation mechanism to preserve collaborative signals while
suppressing drifts, which reweights client updates by consistency with the
global directions. Extensive experiments across diverse datasets, model
architectures, and attacks demonstrate that Horus consistently outperforms
state-of-the-art baselines in both robustness and accuracy.

</details>


### [179] [Context-Adaptive Multi-Prompt LLM Embedding for Vision-Language Alignment](https://arxiv.org/abs/2508.02762)
*Dahun Kim,Anelia Angelova*

Main category: cs.LG

TL;DR: 本文提出一种上下文自适应多提示嵌入方法，通过使用多个结构化提示增强视觉-语言对比学习的语义表示，并在图像/视频-文本检索任务中取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 标准CLIP模型依赖单一文本嵌入，难以充分捕获输入文本的多样语义信息，导致语义表示不够丰富。

Method: 引入上下文自适应多提示嵌入，利用多个结构化提示（每个含独立自适应标记）捕获文本多样语义。所有提示在一次前向传播中联合处理，其嵌入被组合成统一文本表示。为促进语义多样性和表示质量，还引入了多样性正则化损失和否定感知损失。

Result: 在图像-文本和视频-文本检索基准测试中均实现了持续的性能提升。

Conclusion: 所提出的上下文自适应多提示嵌入方法，通过丰富语义表示并结合专门的损失函数，有效提升了视觉-语言对比学习的效果，并在多模态检索任务中展现出优越性。

Abstract: We propose Context-Adaptive Multi-Prompt Embedding, a novel approach to
enrich semantic representations in vision-language contrastive learning. Unlike
standard CLIP-style models that rely on a single text embedding, our method
introduces multiple structured prompts, each containing a distinct adaptive
token that captures diverse semantic aspects of the input text. We process all
prompts jointly in a single forward pass. The resulting prompt embeddings are
combined into a unified text representation, enabling semantically richer
alignment with visual features. To further promote semantic diversity and
representation quality, we incorporate a diversity regularization loss and a
negation-aware loss, encouraging specialization across prompts and improving
contrastive discrimination. Our method achieves consistent improvements on both
image-text and video-text retrieval benchmarks.

</details>


### [180] [Synthetic medical data generation: state of the art and application to trauma mechanism classification](https://arxiv.org/abs/2508.02771)
*Océane Doremus,Ariel Guerra-Adames,Marta Avalos-Fernandez,Vianney Jouhet,Cédric Gil-Jardiné,Emmanuel Lagarde*

Main category: cs.LG

TL;DR: 针对医疗机器学习中的隐私和可重复性挑战，本文提出了一种生成结合表格与非结构化文本的高质量合成医疗记录的方法。


<details>
  <summary>Details</summary>
Motivation: 医疗机器学习研究面临患者隐私保护和科学可重复性的挑战，因此转向开发合成医疗数据库以应对这些问题。

Method: 首先概述了生成合成表格和文本数据的最新机器学习方法；随后，提出了作者自己的方法，用于生成结合表格和非结构化文本数据的高质量合成医疗记录，并将其应用于创伤机制的自动分类。

Result: 摘要中未提供具体的实验结果。

Conclusion: 本文提出了一种有效整合表格和文本数据来生成高质量合成医疗记录的方法，为解决医疗机器学习领域的数据隐私和可重复性难题提供了新途径。

Abstract: Faced with the challenges of patient confidentiality and scientific
reproducibility, research on machine learning for health is turning towards the
conception of synthetic medical databases. This article presents a brief
overview of state-of-the-art machine learning methods for generating synthetic
tabular and textual data, focusing their application to the automatic
classification of trauma mechanisms, followed by our proposed methodology for
generating high-quality, synthetic medical records combining tabular and
unstructured text data.

</details>


### [181] [Uncertainty Sets for Distributionally Robust Bandits Using Structural Equation Models](https://arxiv.org/abs/2508.02812)
*Katherine Avery,Chinmay Pendse,David Jensen*

Main category: cs.LG

TL;DR: 针对当前分布鲁棒评估和学习方法过于保守的问题，本文提出一种基于结构方程模型（SEM）的匪徒评估与学习算法，能获得更准确的评估和低方差策略。


<details>
  <summary>Details</summary>
Motivation: 现有分布鲁棒评估和学习方法会产生过于保守的评估和策略。

Method: 提出一种实用的匪徒评估与学习算法，通过受结构方程模型（SEM）约束的数学规划来定制不确定性集。同时，利用条件独立性测试检测模型中的偏移变量。

Result: 结构方程模型（SEM）方法比传统方法能提供更准确的评估，并学习到方差更低的策略，尤其是在存在较大偏移时。在模型充分指定的情况下，SEM方法还能学习到最优策略。

Conclusion: 基于SEM的方法有效解决了现有分布鲁棒评估和学习的保守性问题，提供了更优越的评估准确性及策略性能。

Abstract: Distributionally robust evaluation estimates the worst-case expected return
over an uncertainty set of possible covariate and reward distributions, and
distributionally robust learning finds a policy that maximizes that worst-case
return across that uncertainty set. Unfortunately, current methods for
distributionally robust evaluation and learning create overly conservative
evaluations and policies. In this work, we propose a practical bandit
evaluation and learning algorithm that tailors the uncertainty set to specific
problems using mathematical programs constrained by structural equation models.
Further, we show how conditional independence testing can be used to detect
shifted variables for modeling. We find that the structural equation model
(SEM) approach gives more accurate evaluations and learns lower-variance
policies than traditional approaches, particularly for large shifts. Further,
the SEM approach learns an optimal policy, assuming the model is sufficiently
well-specified.

</details>


### [182] [On the Theory and Practice of GRPO: A Trajectory-Corrected Approach with Fast Convergence](https://arxiv.org/abs/2508.02833)
*Lei Pang,Ruinan Jin*

Main category: cs.LG

TL;DR: 分析了Group Relative Policy Optimization (GRPO)的梯度估计偏差，发现其影响有限，并基于此提出了一种新的无偏算法TIC GRPO，同时提供了GRPO类方法的首次理论收敛分析。


<details>
  <summary>Details</summary>
Motivation: 研究DeepSeek提出的GRPO算法，发现其更新规则实际上估计的是旧策略的梯度而非当前策略的梯度，尽管这种偏差在实践中影响有限。受此启发，旨在提出一种改进的、无偏的GRPO变体。

Method: 分析GRPO的更新规则以识别梯度估计的偏差；进行消融研究，移除重要性采样并使用固定旧策略梯度更新，以验证偏差影响；提出Trajectory level Importance Corrected GRPO (TIC GRPO)，用轨迹级别概率比取代token级别重要性比以实现无偏梯度估计；首次为GRPO类方法（包括原始GRPO和TIC GRPO）提供理论收敛分析。

Result: GRPO的更新规则估计的是旧策略的梯度；实践中，由于旧策略的频繁刷新，这种偏差的影响很小；移除重要性采样并使用固定旧策略梯度的简化方法与标准GRPO性能相当；TIC GRPO能够提供当前策略梯度的无偏估计，同时保持critic-free结构；首次为GRPO类方法建立了理论收敛性分析。

Conclusion: GRPO的梯度估计存在对旧策略的偏置，但这种偏置在实际应用中影响有限。通过将token级别重要性比替换为轨迹级别概率比，所提出的TIC GRPO算法能提供无偏的当前策略梯度估计，且性能良好。此外，本文为GRPO类方法奠定了理论基础，首次给出了收敛性分析。

Abstract: Group Relative Policy Optimization (GRPO), recently proposed by DeepSeek, is
a critic-free reinforcement learning algorithm for fine tuning large language
models. It replaces the value function in Proximal Policy Optimization (PPO)
with group normalized rewards, while retaining PPO style token level importance
sampling based on an old policy. We show that GRPO update rule in fact
estimates the policy gradient at the old policy rather than the current one.
However, since the old policy is refreshed every few steps, the discrepancy
between the two remains small limiting the impact of this bias in practice. We
validate this through an ablation study in which importance sampling is
entirely removed, and updates are instead performed using the gradient
estimated at a fixed old policy across multiple optimization steps. Remarkably,
this simplification results in performance comparable to standard GRPO.
  Motivated by these findings, we propose a new algorithm: Trajectory level
Importance Corrected GRPO (TIC GRPO). TIC GRPO replaces token level importance
ratios with a single trajectory level probability ratio, yielding an unbiased
estimate of the current policy gradient while preserving the critic free
structure. Furthermore, we present the first theoretical convergence analysis
for GRPO style methods, covering both the original GRPO and our proposed
variant.

</details>


### [183] [Learning from B Cell Evolution: Adaptive Multi-Expert Diffusion for Antibody Design via Online Optimization](https://arxiv.org/abs/2508.02834)
*Hanqi Feng,Peng Qiu,Mengchun Zhang,Yiran Tao,You Fan,Jingtao Xu,Barnabas Poczos*

Main category: cs.LG

TL;DR: 本文提出一种受B细胞亲和力成熟启发的、基于在线元学习和多专家系统的抗体扩散模型设计框架，通过迭代反馈实现个性化优化，显著提升抗体设计质量和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在抗体设计中采用统一生成策略，无法适应每个抗原的独特需求；受B细胞亲和力成熟中抗体通过平衡亲和力、稳定性和自避性进行多目标优化的启发。

Method: 提出首个生物学驱动框架，结合物理学领域知识和在线元学习系统。该方法采用多个专业专家（如范德华力、分子识别、能量平衡、界面几何），其参数在生成过程中根据迭代反馈动态演化，模仿自然抗体精炼周期，为每个靶点发现个性化优化策略。

Result: (1) 无需预训练即可为不同抗原类别发现最佳SE(3)等变引导策略，并保持分子对称性；(2) 通过靶点特异性适应显著增强热点覆盖和界面质量，实现治疗性抗体所需的平衡多目标优化；(3) 建立了迭代精炼范式，使每个抗体-抗原系统通过在线评估学习其独特的优化配置文件；(4) 在从小型表位到大型蛋白质界面的多样化设计挑战中均能有效泛化，实现针对个体靶点的精准设计。

Conclusion: 本研究提出的框架通过在线元学习和多专家系统实现了抗体设计的个性化和自适应优化，克服了现有方法的局限性，显著提升了抗体设计质量、效率和泛化能力，为治疗性抗体的开发提供了新范式。

Abstract: Recent advances in diffusion models have shown remarkable potential for
antibody design, yet existing approaches apply uniform generation strategies
that cannot adapt to each antigen's unique requirements. Inspired by B cell
affinity maturation, where antibodies evolve through multi-objective
optimization balancing affinity, stability, and self-avoidance, we propose the
first biologically-motivated framework that leverages physics-based domain
knowledge within an online meta-learning system. Our method employs multiple
specialized experts (van der Waals, molecular recognition, energy balance, and
interface geometry) whose parameters evolve during generation based on
iterative feedback, mimicking natural antibody refinement cycles. Instead of
fixed protocols, this adaptive guidance discovers personalized optimization
strategies for each target. Our experiments demonstrate that this approach: (1)
discovers optimal SE(3)-equivariant guidance strategies for different antigen
classes without pre-training, preserving molecular symmetries throughout
optimization; (2) significantly enhances hotspot coverage and interface quality
through target-specific adaptation, achieving balanced multi-objective
optimization characteristic of therapeutic antibodies; (3) establishes a
paradigm for iterative refinement where each antibody-antigen system learns its
unique optimization profile through online evaluation; (4) generalizes
effectively across diverse design challenges, from small epitopes to large
protein interfaces, enabling precision-focused campaigns for individual
targets.

</details>


### [184] [Defending Against Knowledge Poisoning Attacks During Retrieval-Augmented Generation](https://arxiv.org/abs/2508.02835)
*Kennedy Edemacu,Vinay M. Shashidhar,Micheal Tuape,Dan Abudu,Beakcheol Jang,Jong Wook Kim*

Main category: cs.LG

TL;DR: 本文提出并评估了FilterRAG和ML-FilterRAG两种防御方法，旨在减轻针对检索增强生成（RAG）系统的知识投毒攻击（PoisonedRAG），通过识别并过滤受污染的知识源文本来实现。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然能增强大型语言模型（LLM）的能力，但易受知识投毒攻击（如PoisonedRAG），攻击者通过污染知识源来误导模型生成，这构成了RAG系统的一个潜在漏洞。

Method: 首先，提出了一种新属性以区分知识数据源中的对抗性文本和干净文本。其次，利用该属性从知识源中过滤出对抗性文本。在此基础上，设计并提出了两种防御方法：FilterRAG和ML-FilterRAG。

Result: 通过使用基准数据集进行评估，结果表明所提出的防御方法是有效的，其性能接近于原始的RAG系统。

Conclusion: 所提出的FilterRAG和ML-FilterRAG防御方法能够有效缓解PoisonedRAG攻击，同时保持与原始RAG系统相近的性能，增强了RAG系统的鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to
boost the capabilities of large language models (LLMs) by incorporating
external, up-to-date knowledge sources. However, this introduces a potential
vulnerability to knowledge poisoning attacks, where attackers can compromise
the knowledge source to mislead the generation model. One such attack is the
PoisonedRAG in which the injected adversarial texts steer the model to generate
an attacker-chosen response to a target question. In this work, we propose
novel defense methods, FilterRAG and ML-FilterRAG, to mitigate the PoisonedRAG
attack. First, we propose a new property to uncover distinct properties to
differentiate between adversarial and clean texts in the knowledge data source.
Next, we employ this property to filter out adversarial texts from clean ones
in the design of our proposed approaches. Evaluation of these methods using
benchmark datasets demonstrate their effectiveness, with performances close to
those of the original RAG systems.

</details>


### [185] [Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization](https://arxiv.org/abs/2508.02840)
*Chaoyang Gao,Xiang Chen,Jiyu Wang,Jibin Wang,Guang Yang*

Main category: cs.LG

TL;DR: 本文提出一种结合知识蒸馏与粒子群优化的资源高效框架，用于自动化漏洞评估，显著减小模型尺寸并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 日益复杂的软件系统导致网络安全漏洞激增，需要高效可扩展的漏洞评估方案。然而，大型预训练模型因其高计算和存储需求，难以在实际场景中部署。

Method: 本文提出一个两阶段的资源高效框架：首先，利用粒子群优化（PSO）来优化紧凑型学生模型的架构，以平衡计算效率和模型容量；其次，应用知识蒸馏（KD）将大型教师模型的关键漏洞评估知识迁移到优化后的学生模型。

Result: 在增强型MegaVul数据集上，该方法实现了99.4%的模型尺寸缩减，同时保留了89.3%的原始模型精度。与现有最佳基线相比，精度提高1.7%，参数量减少60%。此外，训练时间减少72.1%，架构搜索时间比传统遗传算法减少34.88%。

Conclusion: 该框架通过结合粒子群优化和知识蒸馏，有效解决了自动化漏洞评估中大型模型资源消耗大的问题，实现了高效率、高性能且资源节约的漏洞评估。

Abstract: The increasing complexity of software systems has led to a surge in
cybersecurity vulnerabilities, necessitating efficient and scalable solutions
for vulnerability assessment. However, the deployment of large pre-trained
models in real-world scenarios is hindered by their substantial computational
and storage demands. To address this challenge, we propose a novel
resource-efficient framework that integrates knowledge distillation and
particle swarm optimization to enable automated vulnerability assessment. Our
framework employs a two-stage approach: First, particle swarm optimization is
utilized to optimize the architecture of a compact student model, balancing
computational efficiency and model capacity. Second, knowledge distillation is
applied to transfer critical vulnerability assessment knowledge from a large
teacher model to the optimized student model. This process significantly
reduces the model size while maintaining high performance. Experimental results
on an enhanced MegaVul dataset, comprising 12,071 CVSS (Common Vulnerability
Scoring System) v3 annotated vulnerabilities, demonstrate the effectiveness of
our approach. Our approach achieves a 99.4% reduction in model size while
retaining 89.3% of the original model's accuracy. Furthermore, it outperforms
state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The
framework also reduces training time by 72.1% and architecture search time by
34.88% compared to traditional genetic algorithms.

</details>


### [186] [Comparative Evaluation of Kolmogorov-Arnold Autoencoders and Orthogonal Autoencoders for Fault Detection with Varying Training Set Sizes](https://arxiv.org/abs/2508.02860)
*Enrique Luna Villagómez,Vladimir Mahalec*

Main category: cs.LG

TL;DR: 本研究评估了基于KAN的自编码器（KAN-AEs）在化工过程无监督故障检测中的性能，发现WavKAN-AE和EfficientKAN-AE在数据效率和故障检测率方面表现出色，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov-Arnold Networks (KANs)作为传统神经网络的替代品表现出灵活性和参数效率，但在无监督故障检测领域的应用尚未充分探索。

Method: 本研究比较了四种KAN-AE变体（EfficientKAN、FastKAN、FourierKAN、WavKAN）在田纳西-伊士曼过程（Tennessee Eastman Process）上的无监督故障检测能力，并将其与正交自编码器（OAE）进行基准测试。模型在不同大小的正常运行数据集上训练，并使用故障检测率（FDR）评估其对21种故障类型的检测性能。

Result: WavKAN-AE在仅4,000个训练样本时达到最高的总体故障检测率（≥92%），并保持最佳性能。EfficientKAN-AE在仅500个样本时即可达到≥90%的FDR，显示出在低数据量设置下的鲁棒性。FastKAN-AE在数据量较大时（≥50,000样本）具有竞争力，而FourierKAN-AE性能持续不佳。OAE基线需要更多数据才能与顶级KAN-AE相媲美。

Conclusion: KAN-AEs能够结合数据效率和强大的故障检测性能，其使用结构化基函数有望提高模型透明度，使其成为数据受限工业环境的理想选择。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a flexible and
parameter-efficient alternative to conventional neural networks. Unlike
standard architectures that use fixed node-based activations, KANs place
learnable functions on edges, parameterized by different function families.
While they have shown promise in supervised settings, their utility in
unsupervised fault detection remains largely unexplored. This study presents a
comparative evaluation of KAN-based autoencoders (KAN-AEs) for unsupervised
fault detection in chemical processes. We investigate four KAN-AE variants,
each based on a different KAN implementation (EfficientKAN, FastKAN,
FourierKAN, and WavKAN), and benchmark them against an Orthogonal Autoencoder
(OAE) on the Tennessee Eastman Process. Models are trained on normal operating
data across 13 training set sizes and evaluated on 21 fault types, using Fault
Detection Rate (FDR) as the performance metric. WavKAN-AE achieves the highest
overall FDR ($\geq$92\%) using just 4,000 training samples and remains the top
performer, even as other variants are trained on larger datasets.
EfficientKAN-AE reaches $\geq$90\% FDR with only 500 samples, demonstrating
robustness in low-data settings. FastKAN-AE becomes competitive at larger
scales ($\geq$50,000 samples), while FourierKAN-AE consistently underperforms.
The OAE baseline improves gradually but requires substantially more data to
match top KAN-AE performance. These results highlight the ability of KAN-AEs to
combine data efficiency with strong fault detection performance. Their use of
structured basis functions suggests potential for improved model transparency,
making them promising candidates for deployment in data-constrained industrial
settings.

</details>


### [187] [Beyond Least Squares: Robust Regression Transformer (R2T)](https://arxiv.org/abs/2508.02874)
*Roman Gutierrez,Tony Kai Tang,Isabel Gutierrez*

Main category: cs.LG

TL;DR: 针对非对称结构化噪声，提出一种混合神经-符号架构，通过神经网络估计符号参数以恢复原始序列，在合成数据上回归MSE显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的稳健回归技术（基于最小二乘优化）在处理高斯噪声时有效，但面对非对称结构化噪声时会失效。

Method: 提出一种混合神经-符号架构。该架构包含一个Transformer编码器处理数值序列，一个压缩神经网络预测符号参数，以及一个固定的符号方程重构原始序列。训练目标是学习一个由神经参数估计指导的符号拟合，以从添加了非对称结构化噪声的数据中恢复原始序列。

Result: 在合成可穿戴数据上，该模型的中位数回归MSE为6e-6到3.5e-5。这比普通最小二乘拟合和Huber损失或SoftL1等稳健回归技术提高了10-300倍。

Conclusion: 该混合神经-符号架构能有效处理非对称结构化噪声，并通过神经参数估计实现精确的符号拟合，显著超越现有稳健回归技术。

Abstract: Robust regression techniques rely on least-squares optimization, which works
well for Gaussian noise but fails in the presence of asymmetric structured
noise. We propose a hybrid neural-symbolic architecture where a transformer
encoder processes numerical sequences, a compression NN predicts symbolic
parameters, and a fixed symbolic equation reconstructs the original sequence.
Using synthetic data, the training objective is to recover the original
sequence after adding asymmetric structured noise, effectively learning a
symbolic fit guided by neural parameter estimation. Our model achieves a median
regression MSE of 6e-6 to 3.5e-5 on synthetic wearable data, which is a 10-300
times improvement when compared with ordinary least squares fit and robust
regression techniques such as Huber loss or SoftL1.

</details>


### [188] [CauKer: classification time series foundation models can be pretrained on synthetic data only](https://arxiv.org/abs/2508.02879)
*Shifeng Xie,Vasilii Feofanov,Marius Alonso,Ambroise Odonnat,Jianfeng Zhang,Themis Palpanas,Ievgen Redko*

Main category: cs.LG

TL;DR: 提出CauKer算法，通过结合高斯过程核组合和结构因果模型生成合成时间序列，以实现时间序列基础模型（TSFMs）的样本高效预训练，并发现其生成的数据集展示清晰的缩放法则。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型（TSFMs）的预训练成本高昂，需要大规模、精心策划的真实世界序列数据，因此亟需一种样本高效的预训练方法。

Method: 提出了一种名为CauKer的新算法，它结合了高斯过程（GP）核组合和结构因果模型（SCM），以生成具有真实趋势、季节性和非线性交互作用的、多样化且因果连贯的合成时间序列。

Result: CauKer生成的合成数据能够实现最先进分类TSFM的样本高效预训练。此外，实验表明，与真实世界数据集不同，CauKer生成的数据集在数据集大小和模型容量上都表现出清晰的缩放法则。

Conclusion: CauKer为TSFMs提供了一种样本高效的预训练数据生成方案，并通过合成数据揭示了模型和数据集的清晰缩放行为，有助于优化模型的训练过程。

Abstract: Time series foundation models (TSFMs) have recently gained significant
attention due to their strong zero-shot capabilities and widespread real-world
applications. Such models typically require a computationally costly
pretraining on large-scale, carefully curated collections of real-world
sequences. To allow for a sample-efficient pretraining of TSFMs, we propose
CauKer, a novel algorithm designed to generate diverse, causally coherent
synthetic time series with realistic trends, seasonality, and nonlinear
interactions. CauKer combines Gaussian Process (GP) kernel composition with
Structural Causal Models (SCM) to produce data for sample-efficient pretraining
of state-of-the-art classification TSFMs having different architectures and
following different pretraining approaches. Additionally, our experiments
reveal that CauKer-generated datasets exhibit clear scaling laws for both
dataset size (10K to 10M samples) and model capacity (1M to 783M parameters),
unlike real-world datasets, which display irregular scaling behavior.

</details>


### [189] [Neural Networks with Orthogonal Jacobian](https://arxiv.org/abs/2508.02882)
*Alex Massucco,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 该研究提出一个统一的数学框架，用于构建雅可比矩阵正交的深度神经网络，有效解决了梯度问题，实现了深层网络的稳定高效训练，甚至无需传统跳跃连接。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽能提取丰富的分层特征并实现最先进的性能，但通过反向传播训练时常受到梯度消失或爆炸的阻碍。

Method: 引入一个统一的数学框架，描述一类输入到输出雅可比矩阵几乎处处正交的非线性前馈和残差网络。此方法还扩展到雅可比矩阵表示部分等距的网络。

Result: ['所提出的网络强制实现完美的动态等距，即使非常深也能高效训练。', '该框架不仅能恢复标准架构，还能产生新的网络设计，在不依赖传统跳跃连接的情况下匹配残差网络的可训练性。', '实验证据表明，初始化时完美的雅可比正交性足以稳定训练并取得具有竞争力的性能。', '与通过正则化维持雅可比正交性的网络相比，该策略取得了可比的结果。', '推广后的模型（雅可比表示部分等距）也保持了有利的可训练性属性。']

Conclusion: 通过确保网络雅可比矩阵的正交性（即使仅在初始化时），可以有效解决深度神经网络的训练稳定性问题，实现高效且高性能的深层模型训练，并提供无需传统跳跃连接的新型网络架构。

Abstract: Very deep neural networks achieve state-of-the-art performance by extracting
rich, hierarchical features. Yet, training them via backpropagation is often
hindered by vanishing or exploding gradients. Existing remedies, such as
orthogonal or variance-preserving initialisation and residual architectures,
allow for a more stable gradient propagation and the training of deeper models.
In this work, we introduce a unified mathematical framework that describes a
broad class of nonlinear feedforward and residual networks, whose
input-to-output Jacobian matrices are exactly orthogonal almost everywhere.
Such a constraint forces the resulting networks to achieve perfect dynamical
isometry and train efficiently despite being very deep. Our formulation not
only recovers standard architectures as particular cases but also yields new
designs that match the trainability of residual networks without relying on
conventional skip connections. We provide experimental evidence that perfect
Jacobian orthogonality at initialisation is sufficient to stabilise training
and achieve competitive performance. We compare this strategy to networks
regularised to maintain the Jacobian orthogonality and obtain comparable
results. We further extend our analysis to a class of networks
well-approximated by those with orthogonal Jacobians and introduce networks
with Jacobians representing partial isometries. These generalized models are
then showed to maintain the favourable trainability properties.

</details>


### [190] [Physics-Embedded Neural ODEs for Sim2Real Edge Digital Twins of Hybrid Power Electronics Systems](https://arxiv.org/abs/2508.02887)
*Jialin Zheng,Haoyu Wang,Yangbin Zeng,Di Mou,Xin Zhang,Hong Li,Sergio Vazquez,Leopoldo G. Franquelo*

Main category: cs.LG

TL;DR: 针对电力电子系统边缘数字孪生（EDT）在捕捉混合动态和资源受限边缘部署上的挑战，本文提出一种物理嵌入式神经常微分方程（PENODE）模型。该模型结合事件自动机和已知常微分方程，实现了高精度、物理可解释性、低计算量，并支持高效FPGA部署，提升了EDT的Sim-to-Real泛化能力和实时控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有用于电力电子系统（PES）监控和控制的边缘数字孪生（EDT）建模方法难以一致性地捕捉PES中固有的持续演变的混合动态，这导致在资源受限的边缘设备上Sim-to-Real泛化能力下降。

Method: 本文提出一种物理嵌入式神经常微分方程（PENODE）模型。该模型通过以下方式实现：(i) 将混合运行机制嵌入为事件自动机以明确控制离散切换；(ii) 将已知的控制常微分方程组件直接注入到未建模动态的神经参数化中。这种统一设计形成了一个可微分的端到端可训练架构，同时保留了物理可解释性并减少了冗余，并支持云到边的工具链以实现高效的FPGA部署。

Result: 实验结果表明，PENODE在白盒、灰盒和黑盒场景的基准测试中取得了显著更高的精度，同时神经元数量减少了75%。

Conclusion: 所提出的PENODE模型验证了其保持物理可解释性、高效边缘部署能力以及实时控制增强的优势。

Abstract: Edge Digital Twins (EDTs) are crucial for monitoring and control of Power
Electronics Systems (PES). However, existing modeling approaches struggle to
consistently capture continuously evolving hybrid dynamics that are inherent in
PES, degrading Sim-to-Real generalization on resource-constrained edge devices.
To address these challenges, this paper proposes a Physics-Embedded Neural ODEs
(PENODE) that (i) embeds the hybrid operating mechanism as an event automaton
to explicitly govern discrete switching and (ii) injects known governing ODE
components directly into the neural parameterization of unmodeled dynamics.
This unified design yields a differentiable end-to-end trainable architecture
that preserves physical interpretability while reducing redundancy, and it
supports a cloud-to-edge toolchain for efficient FPGA deployment. Experimental
results demonstrate that PENODE achieves significantly higher accuracy in
benchmarks in white-box, gray-box, and black-box scenarios, with a 75%
reduction in neuron count, validating that the proposed PENODE maintains
physical interpretability, efficient edge deployment, and real-time control
enhancement.

</details>


### [191] [Clus-UCB: A Near-Optimal Algorithm for Clustered Bandits](https://arxiv.org/abs/2508.02909)
*Aakash Gore,Prasanna Chaporkar*

Main category: cs.LG

TL;DR: 本文研究了带有已知聚类结构的多臂老虎机问题，其中簇内臂的平均奖励差异有限。作者推导了更优的渐近后悔下界，并提出了Clus-UCB算法，该算法利用聚类结构和信息共享，渐近地匹配了下界，并在模拟中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有经典多臂老虎机模型未能充分捕捉臂之间存在依赖关系（如聚类）的场景，导致其后悔界限不够紧凑。本研究旨在为多因素影响（如在线广告、临床试验）下的决策场景建模，并在已知聚类结构和簇内臂平均奖励差异有限的条件下，寻求更优的后悔性能。

Method: 1. 建立了具有已知聚类和簇内平均奖励差异限制的随机多臂老虎机模型。 2. 推导了改进的渐近后悔下界，优于Lai & Robbins (1985)的经典下界。 3. 提出了Clus-UCB算法，该算法通过引入一种新的依赖于簇内其他臂的评估指标，利用聚类结构促进臂之间信息共享。 4. 通过仿真实验，将Clus-UCB的性能与KL-UCB及其他针对相关臂的算法进行了比较。

Result: 1. 得到了比Lai & Robbins (1985)经典下界更优的渐近后悔下界。 2. 提出的Clus-UCB算法能够渐近地匹配所推导的下界。 3. 仿真结果表明，Clus-UCB在性能上优于KL-UCB和其他已知的针对相关臂的老虎机算法。

Conclusion: 本研究成功地在带有已知聚类结构和簇内臂平均奖励差异限制的多臂老虎机设定下，推导了更紧的后悔下界，并开发了高效的Clus-UCB算法。该算法通过利用聚类内部的信息共享机制，实现了优异的渐近性能。研究为处理多因素影响的决策场景提供了有效工具，并指出了未来的研究方向。

Abstract: We study a stochastic multi-armed bandit setting where arms are partitioned
into known clusters, such that the mean rewards of arms within a cluster differ
by at most a known threshold. While the clustering structure is known a priori,
the arm means are unknown. This framework models scenarios where outcomes
depend on multiple factors -- some with significant and others with minor
influence -- such as online advertising, clinical trials, and wireless
communication. We derive asymptotic lower bounds on the regret that improve
upon the classical bound of Lai & Robbins (1985). We then propose Clus-UCB, an
efficient algorithm that closely matches this lower bound asymptotically.
Clus-UCB is designed to exploit the clustering structure and introduces a new
index to evaluate an arm, which depends on other arms within the cluster. In
this way, arms share information among each other. We present simulation
results of our algorithm and compare its performance against KL-UCB and other
well-known algorithms for bandits with dependent arms. Finally, we address some
limitations of this work and conclude by mentioning possible future research.

</details>


### [192] [Neural Approximators for Low-Thrust Trajectory Transfer Cost and Reachability](https://arxiv.org/abs/2508.02911)
*Zhong Zhang,Francesco Topputo*

Main category: cs.LG

TL;DR: 提出了通用的预训练神经网络，能够高精度预测低推力任务的燃料消耗和轨迹可达性，并具备强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在低推力任务设计中，燃料消耗和轨迹可达性是两个关键性能指标。需要一种通用且准确的方法来预测这些指标。

Method: 首先，基于低推力轨迹近似的标度律，使用同伦射线法构建了迄今最大的数据集。其次，将数据转换到自相似空间，使得神经网络能够适应任意半长轴、倾角和中心天体，实现跨任务场景的泛化预测。最后，训练并应用这些通用预训练神经网络进行指标预测。

Result: 所提出的神经网络在预测速度增量方面实现了0.78%的相对误差，在最短转移时间估计方面实现了0.63%的相对误差。模型已在第三方数据集、多飞越任务设计问题和任务分析场景中得到验证，展示了其优异的泛化能力、预测精度和计算效率。这是目前最通用和准确的低推力轨迹近似器，并提供了C++、Python和MATLAB的实现。

Conclusion: 本研究开发的通用预训练神经网络为低推力任务的燃料消耗和轨迹可达性预测提供了当前最通用、最准确且高效的解决方案，能够广泛应用于不同的任务场景而无需重新训练，极大地促进了低推力轨迹设计和分析。

Abstract: In trajectory design, fuel consumption and trajectory reachability are two
key performance indicators for low-thrust missions. This paper proposes
general-purpose pretrained neural networks to predict these metrics. The
contributions of this paper are as follows: Firstly, based on the confirmation
of the Scaling Law applicable to low-thrust trajectory approximation, the
largest dataset is constructed using the proposed homotopy ray method, which
aligns with mission-design-oriented data requirements. Secondly, the data are
transformed into a self-similar space, enabling the neural network to adapt to
arbitrary semi-major axes, inclinations, and central bodies. This extends the
applicability beyond existing studies and can generalize across diverse mission
scenarios without retraining. Thirdly, to the best of our knowledge, this work
presents the current most general and accurate low-thrust trajectory
approximator, with implementations available in C++, Python, and MATLAB. The
resulting neural network achieves a relative error of 0.78% in predicting
velocity increments and 0.63% in minimum transfer time estimation. The models
have also been validated on a third-party dataset, multi-flyby mission design
problem, and mission analysis scenario, demonstrating their generalization
capability, predictive accuracy, and computational efficiency.

</details>


### [193] [BoostTransformer: Enhancing Transformer Models with Subgrid Selection and Importance Sampling](https://arxiv.org/abs/2508.02924)
*Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan*

Main category: cs.LG

TL;DR: BoostTransformer通过引入boosting原理和高效采样，解决了传统Transformer计算资源消耗大、调参复杂的问题，实现了更快的收敛和更高的精度。


<details>
  <summary>Details</summary>
Motivation: 传统的Transformer架构在NLP领域占据主导地位，但存在计算资源需求大和超参数调优复杂的挑战。

Method: 提出BoostTransformer框架，通过子网格Token选择和重要性加权采样，将boosting原理融入Transformer，具体是将最小二乘boosting目标直接整合到Transformer管道中。

Result: 在多个细粒度文本分类基准测试中，BoostTransformer展现出更快的收敛速度和更高的准确性，超越了标准Transformer，并显著减少了架构搜索开销。

Conclusion: BoostTransformer通过结合boosting原理，有效提升了Transformer的训练效率和性能，是解决其计算资源和调参难题的有效方案。

Abstract: Transformer architectures dominate modern NLP but often demand heavy
computational resources and intricate hyperparameter tuning. To mitigate these
challenges, we propose a novel framework, BoostTransformer, that augments
transformers with boosting principles through subgrid token selection and
importance-weighted sampling. Our method incorporates a least square boosting
objective directly into the transformer pipeline, enabling more efficient
training and improved performance. Across multiple fine-grained text
classification benchmarks, BoostTransformer demonstrates both faster
convergence and higher accuracy, surpassing standard transformers while
minimizing architectural search overhead.

</details>


### [194] [GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics](https://arxiv.org/abs/2508.02926)
*Arthur Cho*

Main category: cs.LG

TL;DR: GrandJury提出一种动态、多元、可追溯的人工评估协议，旨在解决生成式AI模型在复杂应用中缺乏绝对真值评估标准的问题，以更好地反映用户需求和模型演进。


<details>
  <summary>Details</summary>
Motivation: 生成式机器学习模型在现代AI系统中日益重要，但其可接受的响应是多元且高度依赖上下文的。然而，现有的评估机制多依赖静态基准测试，导致模型优化偏向排行榜分数，而非动态的用户需求或不断变化的现实。

Method: GrandJury引入了一种正式的评估协议，结合了时间衰减聚合、完整的可追溯性、动态透明的任务评估标准归因以及多评审员的人工判断。项目提供了开源实现（grandjury PyPI包）和LLM推理输出的公共集合来验证其方法。

Result: GrandJury能够实现多元化、负责任的评估，有效捕捉不断演进的共识并揭示分歧。它为在没有绝对真值的情况下评估机器学习输出提供了一种新的范式。

Conclusion: GrandJury为AI从业者评估无绝对真值的机器学习输出提供了一个创新范式，通过其动态、多元化和可追溯的评估机制，能更好地反映模型与不断变化的用户需求和实际情况的对齐程度。

Abstract: Generative Machine Learning models have become central to modern systems,
powering applications in creative writing, summarization, multi-hop reasoning,
and context-aware dialogue. These models underpin large-scale AI assistants,
workflow automation, and autonomous decision-making. In such domains,
acceptable response is rarely absolute or static, but plural and highly
context-dependent. Yet standard evaluation regimes still rely on static,
benchmark-style tests, incentivizing optimization toward leaderboard scores
rather than alignment with dynamic user needs or evolving realities. GrandJury
introduces a formal evaluation protocol combining time-decayed aggregation,
complete traceability, with the support of dynamic, transparent task rubric
attribution, and multi-rater human judgment. Together, these elements enable
pluralistic, accountable evaluation that captures evolving consensus and
surfaces disagreement. We provide an open-source implementation (grandjury PyPI
package) and a public collection of Large Language Model (LLM) inference
outputs to illustrate the need and method. GrandJury provides a new paradigm
for AI practitioners when evaluating machine learning outputs without absolute
ground truth.

</details>


### [195] [PLoRA: Efficient LoRA Hyperparameter Tuning for Large Models](https://arxiv.org/abs/2508.02932)
*Minghao Yan,Zhuang Wang,Zhen Jia,Shivaram Venkataraman,Yida Wang*

Main category: cs.LG

TL;DR: 本文提出PLoRA系统，通过自动化并发LoRA微调和优化内核，显著提升LoRA训练效率，缩短训练时间并提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA训练范式未能有效利用硬件资源，且获取高性能LoRA的开销较高。

Method: 提出PLoRA系统，该系统能自动编排并发LoRA微调任务以适应硬件和模型约束，并开发高效内核以提高训练效率。

Result: PLoRA在给定超参数搜索空间下，将LoRA微调的完工时间缩短高达7.52倍，并将训练吞吐量提高高达12.8倍。

Conclusion: PLoRA通过优化LoRA训练过程，显著提高了资源利用率和训练效率，从而加速了高性能LoRA的获取。

Abstract: Low-rank Adaptation (LoRA) has gained popularity as a fine-tuning approach
for Large Language Models (LLMs) due to its low resource requirements and good
performance. While a plethora of work has investigated improving LoRA serving
efficiency by serving multiple LoRAs concurrently, existing methods assume that
a wide range of LoRA adapters are available for serving. In our work, we
conduct extensive empirical studies to identify that current training paradigms
do not utilize hardware resources efficiently and require high overhead to
obtain a performant LoRA. Leveraging these insights, we propose PLoRA, which
automatically orchestrates concurrent LoRA fine-tuning jobs under given
hardware and model constraints and develops performant kernels to improve
training efficiency. Our experimental studies show that PLoRA reduces the
makespan of LoRA fine-tuning over a given hyperparameter search space by up to
7.52x and improves training throughput by up to 12.8x across a range of
state-of-the-art LLMs.

</details>


### [196] [Online Robust Multi-Agent Reinforcement Learning under Model Uncertainties](https://arxiv.org/abs/2508.02948)
*Zain Ulabedeen Farhat,Debamita Ghosh,George K. Atia,Yue Wang*

Main category: cs.LG

TL;DR: 针对多智能体系统在不确定环境中部署时的鲁棒性问题，本文首次提出了分布鲁棒马尔可夫博弈的在线学习方法，并引入RONAVI算法，理论证明其在无先验数据下能实现低遗憾和找到最优鲁棒策略。


<details>
  <summary>Details</summary>
Motivation: 已训练的多智能体系统在现实环境中因训练与部署环境不匹配（由环境不确定性引起）而失效，现有分布鲁棒马尔可夫博弈（DRMGs）方法依赖于不可用的模拟器或大量离线数据，缺乏在线学习能力。

Method: 引入了“Robust Optimistic Nash Value Iteration (RONAVI)”算法，使智能体能够在没有先验数据的情况下，直接通过与环境交互进行在线学习，以优化最坏情况性能。

Result: 提供了DRMGs在线学习设置的首个可证明保证。理论分析表明，RONAVI算法实现了低遗憾，并能有效地找到全变分散度（Total Variation divergence）和KL散度（Kullback-Leibler divergence）测量的不确定性集下的最优鲁棒策略。

Conclusion: 本研究为开发真正鲁棒的多智能体系统开辟了一条新的、实用的在线学习路径。

Abstract: Well-trained multi-agent systems can fail when deployed in real-world
environments due to model mismatches between the training and deployment
environments, caused by environment uncertainties including noise or
adversarial attacks. Distributionally Robust Markov Games (DRMGs) enhance
system resilience by optimizing for worst-case performance over a defined set
of environmental uncertainties. However, current methods are limited by their
dependence on simulators or large offline datasets, which are often
unavailable. This paper pioneers the study of online learning in DRMGs, where
agents learn directly from environmental interactions without prior data. We
introduce the {\it Robust Optimistic Nash Value Iteration (RONAVI)} algorithm
and provide the first provable guarantees for this setting. Our theoretical
analysis demonstrates that the algorithm achieves low regret and efficiently
finds the optimal robust policy for uncertainty sets measured by Total
Variation divergence and Kullback-Leibler divergence. These results establish a
new, practical path toward developing truly robust multi-agent systems.

</details>


### [197] [Injecting Measurement Information Yields a Fast and Noise-Robust Diffusion-Based Inverse Problem Solver](https://arxiv.org/abs/2508.02964)
*Jonathan Patsenker,Henry Li,Myeongseob Ko,Ruoxi Jia,Yuval Kluger*

Main category: cs.LG

TL;DR: 提出一种新的方法，通过直接估计包含测量信息的条件后验均值，改进了扩散模型在逆问题中的求解能力，使其更快速、内存高效且对噪声鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在求解逆问题时，虽利用Tweedie公式估计后验均值，但未直接考虑测量值（y）的信息，需在下游阶段才能集成，限制了其效率和准确性。

Method: 本研究提出直接估计条件后验均值 $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$，并将其公式化为轻量级、单参数的最大似然估计问题。该预测结果可集成到任何标准采样器中，形成快速且内存高效的逆问题求解器。此外，还引入了对测量噪声具有鲁棒性的噪声感知、基于似然的停止准则。

Result: 实验结果表明，所提出的方法在多个数据集和任务上，与一系列当代逆问题求解器相比，展现出相当或更优的性能。它实现了更快速、内存高效的逆问题求解，并且对测量噪声具有鲁棒性。

Conclusion: 通过直接估计包含测量信息的条件后验均值，本研究显著提升了扩散模型在逆问题求解中的效率、鲁棒性和性能，使其成为一种有竞争力且实用的新型逆问题求解方案。

Abstract: Diffusion models have been firmly established as principled zero-shot solvers
for linear and nonlinear inverse problems, owing to their powerful image prior
and iterative sampling algorithm. These approaches often rely on Tweedie's
formula, which relates the diffusion variate $\mathbf{x}_t$ to the posterior
mean $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t]$, in order to guide the
diffusion trajectory with an estimate of the final denoised sample
$\mathbf{x}_0$. However, this does not consider information from the
measurement $\mathbf{y}$, which must then be integrated downstream. In this
work, we propose to estimate the conditional posterior mean $\mathbb{E}
[\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$, which can be formulated as the
solution to a lightweight, single-parameter maximum likelihood estimation
problem. The resulting prediction can be integrated into any standard sampler,
resulting in a fast and memory-efficient inverse solver. Our optimizer is
amenable to a noise-aware likelihood-based stopping criteria that is robust to
measurement noise in $\mathbf{y}$. We demonstrate comparable or improved
performance against a wide selection of contemporary inverse solvers across
multiple datasets and tasks.

</details>


### [198] [Scalable Varied-Density Clustering via Graph Propagation](https://arxiv.org/abs/2508.02989)
*Ninh Pham,Yingtao Zheng,Hugo Phibbs*

Main category: cs.LG

TL;DR: 提出一种新颖的变密度聚类方法，通过将高维数据聚类视为邻域图上的标签传播过程，实现高效且高质量的聚类。


<details>
  <summary>Details</summary>
Motivation: 旨在通过将密度聚类与图连接性结合，利用高效图传播技术，为高维数据变密度聚类提供一种可扩展且计算成本低的新视角。

Method: 将变密度聚类问题框架化为在适应局部密度变化的邻域图中的标签传播过程。引入密度感知邻域传播算法，并利用高级随机投影方法构建近似邻域图。

Result: 显著降低了计算成本，同时保持了聚类质量。经验证，该方法可在数分钟内扩展到包含数百万个点的数据集，并达到与现有基线相当的精度。

Conclusion: 所提出的方法通过结合密度聚类与图连通性，为高维数据提供了一种高效、可扩展且准确的变密度聚类解决方案。

Abstract: We propose a novel perspective on varied-density clustering for
high-dimensional data by framing it as a label propagation process in
neighborhood graphs that adapt to local density variations. Our method formally
connects density-based clustering with graph connectivity, enabling the use of
efficient graph propagation techniques developed in network science. To ensure
scalability, we introduce a density-aware neighborhood propagation algorithm
and leverage advanced random projection methods to construct approximate
neighborhood graphs. Our approach significantly reduces computational cost
while preserving clustering quality. Empirically, it scales to datasets with
millions of points in minutes and achieves competitive accuracy compared to
existing baselines.

</details>


### [199] [On the Fast Adaptation of Delayed Clients in Decentralized Federated Learning: A Centroid-Aligned Distillation Approach](https://arxiv.org/abs/2508.02993)
*Jiahui Bai,Hai Dong,A. K. Qin*

Main category: cs.LG

TL;DR: 本文提出DFedCAD框架，通过质心对齐蒸馏解决去中心化联邦学习（DFL）中迟滞客户端适应慢和高通信成本问题，实现了快速适应、通信效率提升和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习（DFL）在异步环境中面临迟滞客户端适应缓慢和高通信成本的挑战，这些限制严重阻碍了整体性能。

Method: 本文提出DFedCAD框架，首先通过加权簇剪枝（WCP）将模型压缩为代表性质心以大幅降低通信开销；其次，利用新颖的结构距离度量和可微分k-means蒸馏模块，使迟滞客户端能够智能地权衡并与对等知识对齐，从而实现高效的端到端知识转移。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的广泛实验表明，DFedCAD在所有评估设置中均持续达到最先进的性能，获得了最高准确率，并减少了超过86%的通信开销。

Conclusion: DFedCAD框架为动态真实场景中的高效去中心化学习提供了一个可扩展且实用的解决方案。

Abstract: Decentralized Federated Learning (DFL) struggles with the slow adaptation of
late-joining delayed clients and high communication costs in asynchronous
environments. These limitations significantly hinder overall performance. To
address this, we propose DFedCAD, a novel framework for rapid adaptation via
Centroid-Aligned Distillation. DFedCAD first employs Weighted Cluster Pruning
(WCP) to compress models into representative centroids, drastically reducing
communication overhead. It then enables delayed clients to intelligently weigh
and align with peer knowledge using a novel structural distance metric and a
differentiable k-means distillation module, facilitating efficient end-to-end
knowledge transfer. Extensive experiments on CIFAR-10, CIFAR-100, and
Tiny-ImageNet show that DFedCAD consistently achieves state-of-the-art
performance, attaining the highest accuracy across all evaluated settings while
reducing communication overhead by over 86%. Our framework provides a scalable
and practical solution for efficient decentralized learning in dynamic,
real-world scenarios.

</details>


### [200] [Where and How to Enhance: Discovering Bit-Width Contribution for Mixed Precision Quantization](https://arxiv.org/abs/2508.03002)
*Haidong Kang,Lianbo Ma,Guo Yu,Shangce Gao*

Main category: cs.LG

TL;DR: 本文提出一种基于Shapley值的混合精度量化（SMPQ）方法，纠正了现有方法在位宽选择上依赖参数幅度的缺陷，通过直接衡量位宽贡献实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的混合精度量化（MPQ）方法在位宽选择时，隐含假设量化参数的幅度反映了其对精度的贡献，但这种假设不一定成立，且位宽选择过程缺乏充分关注。

Method: 提出Shapley-based MPQ (SMPQ) 方法，通过Shapley值直接衡量位宽操作对MPQ任务的贡献。为降低计算成本，采用基于蒙特卡洛采样的近似策略进行Shapley值计算。

Result: 在主流基准测试中，所提出的SMPQ方法持续优于基于梯度的竞争方法，实现了最先进的性能。

Conclusion: SMPQ通过更准确地衡量位宽对任务性能的直接贡献，有效改进了混合精度量化中的位宽选择过程，并展现出卓越的性能。

Abstract: Mixed precision quantization (MPQ) is an effective quantization approach to
achieve accuracy-complexity trade-off of neural network, through assigning
different bit-widths to network activations and weights in each layer. The
typical way of existing MPQ methods is to optimize quantization policies (i.e.,
bit-width allocation) in a gradient descent manner, termed as Differentiable
(DMPQ). At the end of the search, the bit-width associated to the quantization
parameters which has the largest value will be selected to form the final mixed
precision quantization policy, with the implicit assumption that the values of
quantization parameters reflect the operation contribution to the accuracy
improvement. While much has been discussed about the MPQ improvement, the
bit-width selection process has received little attention. We study this
problem and argue that the magnitude of quantization parameters does not
necessarily reflect the actual contribution of the bit-width to the task
performance. Then, we propose a Shapley-based MPQ (SMPQ) method, which measures
the bit-width operation direct contribution on the MPQ task. To reduce
computation cost, a Monte Carlo sampling-based approximation strategy is
proposed for Shapley computation. Extensive experiments on mainstream
benchmarks demonstrate that our SMPQ consistently achieves state-of-the-art
performance than gradient-based competitors.

</details>


### [201] [Urban In-Context Learning: Bridging Pretraining and Inference through Masked Diffusion for Urban Profiling](https://arxiv.org/abs/2508.03042)
*Ruixing Zhang,Bo Wang,Tongyu Zhu,Leilei Sun,Weifeng Lv*

Main category: cs.LG

TL;DR: 本文提出一种名为Urban In-Context Learning (UICL)的单阶段城市画像预测框架，通过掩码自编码和扩散模型统一了预训练与推理，并在实验中超越了现有双阶段方法。


<details>
  <summary>Details</summary>
Motivation: 现有城市画像预测遵循两阶段范式，需额外微调。受GPT启发，研究者希望开发能统一预训练和推理的单阶段模型以直接应用于下游任务，但城市数据结构与语言不同，实现此目标存在挑战。

Method: 提出了Urban In-Context Learning (UICL)框架，通过城市区域的掩码自编码过程统一预训练和推理。核心组件包括：Urban Masked Diffusion Transformer (UMDT)用于捕获城市画像分布，将预测表示为分布；Urban Representation Alignment Mechanism (URAM)通过对齐模型中间特征与经典方法来稳定扩散训练。

Result: 在两个城市的三项指标上的广泛实验表明，所提出的单阶段方法持续优于现有的最先进双阶段方法。消融研究和案例研究进一步验证了每个模块的有效性，特别是扩散模型的使用。

Conclusion: 提出的Urban In-Context Learning框架成功地为城市画像任务设计了统一预训练和推理的单阶段模型，显著提高了预测性能，并展示了扩散模型在城市数据建模中的潜力。

Abstract: Urban profiling aims to predict urban profiles in unknown regions and plays a
critical role in economic and social censuses. Existing approaches typically
follow a two-stage paradigm: first, learning representations of urban areas;
second, performing downstream prediction via linear probing, which originates
from the BERT era. Inspired by the development of GPT style models, recent
studies have shown that novel self-supervised pretraining schemes can endow
models with direct applicability to downstream tasks, thereby eliminating the
need for task-specific fine-tuning. This is largely because GPT unifies the
form of pretraining and inference through next-token prediction. However, urban
data exhibit structural characteristics that differ fundamentally from
language, making it challenging to design a one-stage model that unifies both
pretraining and inference. In this work, we propose Urban In-Context Learning,
a framework that unifies pretraining and inference via a masked autoencoding
process over urban regions. To capture the distribution of urban profiles, we
introduce the Urban Masked Diffusion Transformer, which enables each region' s
prediction to be represented as a distribution rather than a deterministic
value. Furthermore, to stabilize diffusion training, we propose the Urban
Representation Alignment Mechanism, which regularizes the model's intermediate
features by aligning them with those from classical urban profiling methods.
Extensive experiments on three indicators across two cities demonstrate that
our one-stage method consistently outperforms state-of-the-art two-stage
approaches. Ablation studies and case studies further validate the
effectiveness of each proposed module, particularly the use of diffusion
modeling.

</details>


### [202] [A Novel Multimodal Framework for Early Detection of Alzheimers Disease Using Deep Learning](https://arxiv.org/abs/2508.03046)
*Tatwadarshi P Nagarhalli,Sanket Patil,Vishal Pande,Uday Aswalekar,Prafulla Patil*

Main category: cs.LG

TL;DR: 本文提出一个多模态AI框架，整合MRI、认知评估和生物标志物数据（分别使用CNN和LSTM），旨在提高阿尔茨海默病（AD）的早期诊断准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期诊断面临挑战，传统单一模态方法难以捕捉疾病多方面特性，导致治疗延误和预后不佳。

Method: 开发了一种新颖的多模态框架，整合MRI图像（使用CNN分析）、认知评估和生物标志物数据（使用LSTM处理）。该系统通过加权平均等高级技术聚合来自不同模态的结果，即使在数据不完整的情况下也能增强诊断准确性和可靠性。

Result: 该多模态方法不仅提高了检测过程的鲁棒性，还能够在疾病最早阶段识别AD，比传统方法具有显著优势。结合生物标志物和认知测试尤其关键，因为它们可以在临床症状出现前检测出AD。

Conclusion: 所提出的框架有潜力彻底改变AD的早期检测，为更及时和有效的治疗铺平道路。

Abstract: Alzheimers Disease (AD) is a progressive neurodegenerative disorder that
poses significant challenges in its early diagnosis, often leading to delayed
treatment and poorer outcomes for patients. Traditional diagnostic methods,
typically reliant on single data modalities, fall short of capturing the
multifaceted nature of the disease. In this paper, we propose a novel
multimodal framework for the early detection of AD that integrates data from
three primary sources: MRI imaging, cognitive assessments, and biomarkers. This
framework employs Convolutional Neural Networks (CNN) for analyzing MRI images
and Long Short-Term Memory (LSTM) networks for processing cognitive and
biomarker data. The system enhances diagnostic accuracy and reliability by
aggregating results from these distinct modalities using advanced techniques
like weighted averaging, even in incomplete data. The multimodal approach not
only improves the robustness of the detection process but also enables the
identification of AD at its earliest stages, offering a significant advantage
over conventional methods. The integration of biomarkers and cognitive tests is
particularly crucial, as these can detect Alzheimer's long before the onset of
clinical symptoms, thereby facilitating earlier intervention and potentially
altering the course of the disease. This research demonstrates that the
proposed framework has the potential to revolutionize the early detection of
AD, paving the way for more timely and effective treatments

</details>


### [203] [VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision](https://arxiv.org/abs/2508.03058)
*Dingwei Zhu,Shihan Dou,Zhiheng Xi,Senjie Jin,Guoqiang Zhang,Jiazheng Zhang,Junjie Ye,Mingxu Chai,Enyu Zhou,Ming Zhang,Caishuang Huang,Yunke Zhang,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: 针对RLHF中奖励监督噪声问题，本文提出VRPO框架，通过强化价值模型来吸收噪声并提供更可靠的优势估计，从而实现鲁棒的PPO训练。


<details>
  <summary>Details</summary>
Motivation: RLHF在真实世界中常受噪声或不完美奖励监督影响，导致策略不稳定和泛化能力差。现有工作多关注奖励去噪或数据过滤，却忽视了价值模型在策略优化中的关键作用。

Method: 提出VRPO框架，一个以价值为中心的鲁棒PPO训练方法，包含两项核心设计：(1) 由冻结语言模型的熵和困惑度引导的辅助损失；(2) 变分信息瓶颈。这些机制增强了价值模型过滤噪声和捕获上下文关键词的能力，使其从被动预测器转变为主动噪声调节器。

Result: 在数学推理、科学问答和多轮对话等任务上，使用基于规则和基于模型的噪声奖励进行实验，VRPO始终优于PPO和GRPO基线。

Conclusion: 研究强调了价值模型在RLHF中常被忽视的重要性，并为在噪声真实世界环境中进行鲁棒策略优化提供了一种原则性且实用的方法。

Abstract: Reinforcement Learning from Human Feedback (RLHF) often suffers from noisy or
imperfect reward supervision in real-world settings, which undermines policy
stability and generalization. Such noise may cause models to lose attention on
key words during advantage estimation. While prior work focuses on reward
denoising or filtering poor data, it often overlooks the critical role of the
value model in policy optimization. In this work, we show that a strong value
model is essential for mitigating noise by absorbing unstable signals and
enabling more reliable advantage estimation. We propose VRPO, a value-centric
framework for robust PPO training under noisy supervision. VRPO combines two
core designs: (1) an auxiliary loss guided by entropy and perplexity from a
frozen language model, and (2) a variational information bottleneck. These
mechanisms enhance the value model's ability to filter out noise and capture
key words from the context during advantage estimation, transforming it from a
passive predictor into an active regulator of noise. Experiments on math
reasoning, science QA, and multi-turn dialogue, under both rule-based and
model-based noisy rewards, show that VRPO consistently outperforms PPO and GRPO
baselines. Our findings underscore the often-overlooked importance of the value
model in RLHF and offer a principled and practical approach to robust policy
optimization in noisy real-world environments.

</details>


### [204] [Achieving Limited Adaptivity for Multinomial Logistic Bandits](https://arxiv.org/abs/2508.03072)
*Sukruta Prakash Midigeshi,Tanmay Goyal,Gaurav Sinha*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multinomial Logistic Bandits have recently attracted much attention due to
their ability to model problems with multiple outcomes. In this setting, each
decision is associated with many possible outcomes, modeled using a multinomial
logit function. Several recent works on multinomial logistic bandits have
simultaneously achieved optimal regret and computational efficiency. However,
motivated by real-world challenges and practicality, there is a need to develop
algorithms with limited adaptivity, wherein we are allowed only $M$ policy
updates. To address these challenges, we present two algorithms, B-MNL-CB and
RS-MNL, that operate in the batched and rarely-switching paradigms,
respectively. The batched setting involves choosing the $M$ policy update
rounds at the start of the algorithm, while the rarely-switching setting can
choose these $M$ policy update rounds in an adaptive fashion. Our first
algorithm, B-MNL-CB extends the notion of distributional optimal designs to the
multinomial setting and achieves $\tilde{O}(\sqrt{T})$ regret assuming the
contexts are generated stochastically when presented with $\Omega(\log \log T)$
update rounds. Our second algorithm, RS-MNL works with adversarially generated
contexts and can achieve $\tilde{O}(\sqrt{T})$ regret with $\tilde{O}(\log T)$
policy updates. Further, we conducted experiments that demonstrate that our
algorithms (with a fixed number of policy updates) are extremely competitive
(and often better) than several state-of-the-art baselines (which update their
policy every round), showcasing the applicability of our algorithms in various
practical scenarios.

</details>


### [205] [HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation](https://arxiv.org/abs/2508.03104)
*Mengting Pan,Fan Li,Xiaoyang Wang,Wenjie Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: HiTeC是一种针对文本属性超图（TAHG）的两阶段分层对比学习框架，通过结构感知预训练、语义感知数据增强和多尺度对比损失，有效解决了现有方法在表示质量和可扩展性上的局限。


<details>
  <summary>Details</summary>
Motivation: 当前对比学习方法在处理包含文本信息的超图（TAHG）时存在三方面局限：1) 常用图无关文本编码器忽视文本与超图拓扑关联，导致表示次优；2) 依赖随机数据增强引入噪声，削弱对比目标；3) 主要关注节点和超边级别信号，难以捕捉长程依赖。此外，现有先驱HyperBERT因协同训练而可扩展性差。亟需一种可扩展且有效的TAHG自监督学习方法。

Method: 提出HiTeC框架，采用两阶段设计：
1.  **第一阶段：文本编码器预训练**。通过结构感知对比目标预训练文本编码器，以克服传统方法的图无关性。
2.  **第二阶段：超图对比学习**。引入两种语义感知增强策略：提示增强文本增强和语义感知超边丢弃，以生成信息视图。同时，提出多尺度对比损失，通过s-walk基的子图级别对比，更好地捕捉长程依赖。
该两阶段设计通过解耦文本编码器预训练与超图对比学习，提升了可扩展性。

Result: 广泛的实验证实了HiTeC的有效性。

Conclusion: HiTeC通过其创新的两阶段分层对比学习框架、语义感知增强和多尺度对比损失，成功解决了文本属性超图自监督学习中表示质量和可扩展性的关键挑战。

Abstract: Contrastive learning (CL) has become a dominant paradigm for self-supervised
hypergraph learning, enabling effective training without costly labels.
However, node entities in real-world hypergraphs are often associated with rich
textual information, which is overlooked in prior works. Directly applying
existing CL-based methods to such text-attributed hypergraphs (TAHGs) leads to
three key limitations: (1) The common use of graph-agnostic text encoders
overlooks the correlations between textual content and hypergraph topology,
resulting in suboptimal representations. (2) Their reliance on random data
augmentations introduces noise and weakens the contrastive objective. (3) The
primary focus on node- and hyperedge-level contrastive signals limits the
ability to capture long-range dependencies, which is essential for expressive
representation learning. Although HyperBERT pioneers CL on TAHGs, its
co-training paradigm suffers from poor scalability. To fill the research gap,
we introduce HiTeC, a two-stage hierarchical contrastive learning framework
with semantic-aware augmentation for scalable and effective self-supervised
learning on TAHGs. In the first stage, we pre-train the text encoder with a
structure-aware contrastive objective to overcome the graph-agnostic nature of
conventional methods. In the second stage, we introduce two semantic-aware
augmentation strategies, including prompt-enhanced text augmentation and
semantic-aware hyperedge drop, to facilitate informative view generation.
Furthermore, we propose a multi-scale contrastive loss that extends existing
objectives with an $s$-walk-based subgraph-level contrast to better capture
long-range dependencies. By decoupling text encoder pretraining from hypergraph
contrastive learning, this two-stage design enhances scalability without
compromising representation quality. Extensive experiments confirm the
effectiveness of HiTeC.

</details>


### [206] [Accelerating SGDM via Learning Rate and Batch Size Schedules: A Lyapunov-Based Analysis](https://arxiv.org/abs/2508.03105)
*Yuichi Kondo,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 本文提出一种新型Lyapunov函数，统一分析了SGDM在动态学习率和批次大小调度下的收敛性，发现特定策略（如批次和学习率同增）可显著加速收敛，并经实验验证，提供了理论和实践指导。


<details>
  <summary>Details</summary>
Motivation: 现有随机梯度下降带动量（SGDM）算法在动态学习率和批次大小调度下的收敛性分析复杂且缺乏统一性，难以理解其行为并指导实际应用，因此需要一个更简单、统一的理论框架。

Method: 引入一种新型且结构更简单的Lyapunov函数，用于分析SGDM在动态调度下的收敛行为。将此理论框架应用于三种常见调度策略：(i) 固定批次+衰减学习率，(ii) 增加批次+衰减学习率，(iii) 增加批次+增加学习率。通过理论分析推导收敛性质，并结合实证实验进行验证。

Result: 理论结果表明，收敛行为存在清晰的层次：策略(i)不保证期望梯度范数收敛，而策略(ii)和(iii)则能保证。特别是，策略(iii)实现了比(i)和(ii)更快的理论收敛速度。实证结果验证了理论，显示动态调度的SGDM在收敛速度上优于固定超参数基线。实验中，热身（warm-up）调度表现出最优的收敛行为。

Conclusion: 本研究为理解SGDM的收敛性提供了统一的理论基础，并为现代深度学习中设计高效稳定的训练过程提供了实用的指导，尤其推荐采用批次和学习率同步增加的调度策略，以及热身机制。

Abstract: We analyze the convergence behavior of stochastic gradient descent with
momentum (SGDM) under dynamic learning rate and batch size schedules by
introducing a novel Lyapunov function. This Lyapunov function has a simpler
structure compared with existing ones, facilitating the challenging convergence
analysis of SGDM and a unified analysis across various dynamic schedules.
Specifically, we extend the theoretical framework to cover three practical
scheduling strategies commonly used in deep learning: (i) constant batch size
with a decaying learning rate, (ii) increasing batch size with a decaying
learning rate, and (iii) increasing batch size with an increasing learning
rate. Our theoretical results reveal a clear hierarchy in convergence behavior:
while (i) does not guarantee convergence of the expected gradient norm, both
(ii) and (iii) do. Moreover, (iii) achieves a provably faster decay rate than
(i) and (ii), demonstrating theoretical acceleration even in the presence of
momentum. Empirical results validate our theory, showing that dynamically
scheduled SGDM significantly outperforms fixed-hyperparameter baselines in
convergence speed. We also evaluated a warm-up schedule in experiments, which
empirically outperformed all other strategies in convergence behavior. These
findings provide a unified theoretical foundation and practical guidance for
designing efficient and stable training procedures in modern deep learning.

</details>


### [207] [Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection](https://arxiv.org/abs/2508.03108)
*Tarhib Al Azad,Faizul Rakib Sayem,Shahana Ibrahim*

Main category: cs.LG

TL;DR: 针对现有OOD检测方法对特征空间假设严格的问题，本文提出一种基于伪标签诱导子空间表示的新型OOD检测框架，并结合创新的学习准则，有效提升了域内（ID）与域外（OOD）样本的可分性。


<details>
  <summary>Details</summary>
Motivation: 现有基于特征表示的OOD检测方法往往对特征空间施加限制性假设，这极大地约束了域内（ID）和域外（OOD）样本之间的可分性。

Method: 提出一种基于伪标签诱导子空间表示的新型OOD检测框架，该框架在更宽松和自然的假设下运行。此外，引入了一个简单而有效的学习准则，该准则将基于交叉熵的ID分类损失与基于子空间距离的正则化损失相结合，以增强ID-OOD可分性。

Result: 通过大量实验验证了所提框架的有效性。

Conclusion: 所提出的框架在更自然假设下有效提升ID-OOD可分性，解决了现有OOD检测方法的局限性，从而增强了AI的鲁棒性。

Abstract: Out-of-distribution (OOD) detection lies at the heart of robust artificial
intelligence (AI), aiming to identify samples from novel distributions beyond
the training set. Recent approaches have exploited feature representations as
distinguishing signatures for OOD detection. However, most existing methods
rely on restrictive assumptions on the feature space that limit the
separability between in-distribution (ID) and OOD samples. In this work, we
propose a novel OOD detection framework based on a pseudo-label-induced
subspace representation, that works under more relaxed and natural assumptions
compared to existing feature-based techniques. In addition, we introduce a
simple yet effective learning criterion that integrates a cross-entropy-based
ID classification loss with a subspace distance-based regularization loss to
enhance ID-OOD separability. Extensive experiments validate the effectiveness
of our framework.

</details>


### [208] [GEDAN: Learning the Edit Costs for Graph Edit Distance](https://arxiv.org/abs/2508.03111)
*Francesco Leonardi,Markus Orsi,Jean-Louis Reymond,Kaspar Riesen*

Main category: cs.LG

TL;DR: 图编辑距离(GED)计算复杂且现有NN方法假设单位成本不切实际。本文提出一种新型GNN框架，通过整合广义加性模型(GAM)学习上下文感知编辑成本，并支持无监督训练，在近似GED的同时显著提高适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 图编辑距离(GED)的计算是NP-hard问题。现有基于神经网络的近似方法大多假设编辑操作为单位成本，这在实际应用中是不切实际的，限制了其在真实世界场景中的实用性。

Method: 本文提出了一个新颖的图神经网络(GNN)框架来近似GED。它支持监督和无监督训练，其中无监督训练采用梯度引导的自组织机制。该架构的核心组件是整合了广义加性模型(GAM)，以灵活且可解释地学习上下文感知的编辑成本。

Result: 实验结果表明，所提出的方法在性能上与最先进的参考方法相当，但显著提高了适应性和可解释性。学习到的成本函数能够为复杂的图结构提供深入的洞察。

Conclusion: 本工作提出的GNN框架通过学习上下文感知的编辑成本并支持无监督训练，有效解决了GED近似计算中单位成本假设的局限性，显著提升了方法的适应性和可解释性，在分子分析和结构模式发现等领域具有重要价值。

Abstract: Graph Edit Distance (GED) is defined as the minimum cost transformation of
one graph into another and is a widely adopted metric for measuring the
dissimilarity between graphs. The major problem of GED is that its computation
is NP-hard, which has in turn led to the development of various approximation
methods, including approaches based on neural networks (NN). Most of these
NN-based models simplify the problem of GED by assuming unit-cost edit
operations, a rather unrealistic constraint in real-world applications. In this
work, we present a novel Graph Neural Network framework that approximates GED
using both supervised and unsupervised training. In the unsupervised setting,
it employs a gradient-only self-organizing mechanism that enables optimization
without ground-truth distances. Moreover, a core component of our architecture
is the integration of a Generalized Additive Model, which allows the flexible
and interpretable learning of context-aware edit costs. Experimental results
show that the proposed method achieves similar results as state-of-the-art
reference methods, yet significantly improves both adaptability and
interpretability. That is, the learned cost function offers insights into
complex graph structures, making it particularly valuable in domains such as
molecular analysis and structural pattern discovery.

</details>


### [209] [RegMean++: Enhancing Effectiveness and Generalization of Regression Mean for Model Merging](https://arxiv.org/abs/2508.03121)
*The-Hai Nguyen,Dang Huu-Tien,Takeshi Suzuki,Le-Minh Nguyen*

Main category: cs.LG

TL;DR: RegMean++通过在RegMean的目标函数中引入层内和层间依赖关系，显著提升了模型合并性能，在多种任务中超越RegMean并达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: RegMean作为一种模型合并方法，独立处理每个线性层，忽略了特征和信息在层间的传播及其对最终预测的影响，限制了其捕获合并模型行为的能力。

Method: 本文提出了RegMean++，它在RegMean的现有目标函数中明确地整合了合并模型层之间的层内（intra-layer）和层间（cross-layer）依赖关系。

Result: 实验证明，RegMean++在域内(ID)和域外(OOD)泛化、顺序合并、大规模任务以及不同分布偏移下的鲁棒性方面持续优于RegMean。此外，RegMean++与最新的高级模型合并方法相比，也取得了具有竞争力甚至是最先进的性能。

Conclusion: RegMean++通过有效纳入层内和层间依赖，克服了RegMean的局限性，提供了更精确捕捉合并模型行为的能力，并在各种复杂模型合并场景下展现出卓越的性能和普适性。

Abstract: Regression Mean (RegMean), an approach that formulates model merging as a
linear regression problem, aims to find the optimal weights for each linear
layer in the merge model by minimizing the discrepancy in predictions between
the merge and candidate models. RegMean provides a precise closed-form solution
for the merging problem; therefore, it offers explainability and computational
efficiency. However, RegMean merges each linear layer independently,
overlooking how the features and information in the earlier layers propagate
through the layers and influence the final prediction in the merge model. In
this paper, we introduce RegMean++, a simple yet effective alternative to
RegMean, that explicitly incorporates both intra- and cross-layer dependencies
between merge models' layers into RegMean's objective. By accounting for these
dependencies, RegMean++ better captures the behaviors of the merge model.
Extensive experiments demonstrate that RegMean++ consistently outperforms
RegMean across diverse settings, including in-domain (ID) and out-of-domain
(OOD) generalization, sequential merging, large-scale tasks, and robustness
under several types of distribution shifts. Furthermore, RegMean++ achieves
competitive or state-of-the-art performance compared to various recent advanced
model merging methods. Our code is available at
https://github.com/nthehai01/RegMean-plusplus.

</details>


### [210] [Frontier: Simulating the Next Generation of LLM Inference Systems](https://arxiv.org/abs/2508.03148)
*Yicheng Feng,Xin Tan,Kin Hang Sew,Yimin Jiang,Yibo Zhu,Hong Xu*

Main category: cs.LG

TL;DR: 引入Frontier模拟器，旨在解决现有工具无法模拟MoE模型和解耦架构下复杂LLM推理系统动态的问题，并支持其大规模设计与优化。


<details>
  <summary>Details</summary>
Motivation: 随着MoE模型和解耦架构（如预填充/解码、注意力/FFN分离）的兴起，大型语言模型（LLM）推理日益复杂。然而，现有模拟器主要为协同部署的密集模型设计，无法捕捉这些新兴范式的精细系统动态。

Method: 本文提出了Frontier，一个从头开始设计的高保真模拟器。它引入了统一框架来模拟协同部署和解耦系统，原生支持带有专家并行（EP）的MoE推理。Frontier能够模拟复杂的跨集群专家路由和高级流水线策略，并融入了改进的算子模型以提高准确性。

Result: Frontier模拟器成功克服了现有模拟器在处理MoE和解耦LLM推理复杂性方面的局限性，提供了高保真的模拟能力，支持复杂工作流的模拟和优化，并提升了模拟准确性。

Conclusion: Frontier模拟器赋能社区设计和优化未来大规模的LLM推理系统，为应对新兴复杂推理范式提供了关键工具。

Abstract: Large Language Model (LLM) inference is growing increasingly complex with the
rise of Mixture-of-Experts (MoE) models and disaggregated architectures that
decouple components like prefill/decode (PD) or attention/FFN (AF) for
heterogeneous scaling. Existing simulators, architected for co-located, dense
models, are unable to capture the intricate system dynamics of these emerging
paradigms. We present Frontier, a high-fidelity simulator designed from the
ground up for this new landscape. Frontier introduces a unified framework to
model both co-located and disaggregated systems, providing native support for
MoE inference with expert parallelism (EP). It enables the simulation of
complex workflows like cross-cluster expert routing and advanced pipelining
strategies for latency hiding. To ensure fidelity and usability, Frontier
incorporates refined operator models for improved accuracy. Frontier empowers
the community to design and optimize the future of LLM inference at scale.

</details>


### [211] [Estimating Worst-Case Frontier Risks of Open-Weight LLMs](https://arxiv.org/abs/2508.03153)
*Eric Wallace,Olivia Watkins,Miles Wang,Kai Chen,Chris Koch*

Main category: cs.LG

TL;DR: 评估开源GPT模型（gpt-oss）在生物和网络安全领域的潜在最坏情况风险。


<details>
  <summary>Details</summary>
Motivation: 识别和量化开源GPT模型可能带来的最坏情况前沿风险，特别是在恶意使用方面，以指导模型发布决策。

Method: 引入“恶意微调（MFT）”方法，通过强化学习与网络浏览（生物风险）和智能体编码环境解决CTF（网络安全风险）来最大限度地提升gpt-oss的能力。将MFT模型与现有开源和闭源大型语言模型进行前沿风险评估对比。

Result: 与前沿闭源模型相比，MFT gpt-oss在生物和网络安全风险方面表现不如OpenAI o3。与开源模型相比，gpt-oss可能略微增加生物能力，但未显著推动前沿。

Conclusion: 研究结果支持了发布该模型的决定，并期望恶意微调（MFT）方法能为未来开源模型发布时的危害评估提供有益指导。

Abstract: In this paper, we study the worst-case frontier risks of releasing gpt-oss.
We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum
capabilities by fine-tuning gpt-oss to be as capable as possible in two
domains: biology and cybersecurity. To maximize biological risk (biorisk), we
curate tasks related to threat creation and train gpt-oss in an RL environment
with web browsing. To maximize cybersecurity risk, we train gpt-oss in an
agentic coding environment to solve capture-the-flag (CTF) challenges. We
compare these MFT models against open- and closed-weight LLMs on frontier risk
evaluations. Compared to frontier closed-weight models, MFT gpt-oss
underperforms OpenAI o3, a model that is below Preparedness High capability
level for biorisk and cybersecurity. Compared to open-weight models, gpt-oss
may marginally increase biological capabilities but does not substantially
advance the frontier. Taken together, these results contributed to our decision
to release the model, and we hope that our MFT approach can serve as useful
guidance for estimating harm from future open-weight releases.

</details>


### [212] [Unveiling Location-Specific Price Drivers: A Two-Stage Cluster Analysis for Interpretable House Price Predictions](https://arxiv.org/abs/2508.03156)
*Paul Gümmer,Julian Rosenberger,Mathias Kraus,Patrick Zschech,Nico Hambauer*

Main category: cs.LG

TL;DR: 本文提出一种结合两阶段聚类和可解释模型的机器学习方法，用于改进房产估价，有效解决了市场异质性和模型可解释性不足的问题，并在德国房产数据上取得了显著的精度提升。


<details>
  <summary>Details</summary>
Motivation: 房产估价因市场局部差异大而充满挑战。现有方法要么是缺乏可解释性的黑盒机器学习模型，要么是无法捕捉市场异质性的简单线性回归模型。

Method: 提出一种机器学习方法，通过两阶段聚类对房产进行分组：首先基于最小位置特征，然后加入额外特征。每个聚类再分别使用线性回归（LR）或广义加性模型（GAM）进行建模，以平衡预测性能和可解释性。

Result: 在2023年43,309个德国房产数据上，相较于未聚类模型，GAM的平均绝对误差（MAE）提高了36%，LR提高了58%。此外，图形分析揭示了聚类之间存在模式差异。

Conclusion: 研究结果强调了聚类特定洞察的重要性，这不仅增强了模型可解释性，也为寻求更可靠房产估价的买家、卖家和房地产分析师提供了实际价值。

Abstract: House price valuation remains challenging due to localized market variations.
Existing approaches often rely on black-box machine learning models, which lack
interpretability, or simplistic methods like linear regression (LR), which fail
to capture market heterogeneity. To address this, we propose a machine learning
approach that applies two-stage clustering, first grouping properties based on
minimal location-based features before incorporating additional features. Each
cluster is then modeled using either LR or a generalized additive model (GAM),
balancing predictive performance with interpretability. Constructing and
evaluating our models on 43,309 German house property listings from 2023, we
achieve a 36% improvement for the GAM and 58% for LR in mean absolute error
compared to models without clustering. Additionally, graphical analyses unveil
pattern shifts between clusters. These findings emphasize the importance of
cluster-specific insights, enhancing interpretability and offering practical
value for buyers, sellers, and real estate analysts seeking more reliable
property valuations.

</details>


### [213] [Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach](https://arxiv.org/abs/2508.03158)
*Yiyi Wang,Jian'an Zhang,Hongyi Duan,Haoyang Liu,Qingyang Li*

Main category: cs.LG

TL;DR: 本研究提出了一种基于“预测充分性原则”的新型状态空间模型（MPS-SSM），通过优化信息理论准则来指导选择机制，以提高序列建模的性能和鲁棒性，特别是在长程预测和噪声场景下。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型（如Mamba）的选择机制多为启发式设计，缺乏严格的第一性原理推导，导致其最优性和对虚假关联的鲁棒性存疑。

Method: 引入“预测充分性原则”，即理想的隐藏状态应是过去对预测未来而言的最小充分统计量。基于此原则，提出最小预测充分性状态空间模型（MPS-SSM），其选择机制通过优化源自该原则的目标函数来引导，旨在最大化压缩历史信息而不损失预测能力。

Result: MPS-SSM在广泛的基准数据集上表现出最先进的性能，在长程预测和噪声场景中显著优于现有模型，并展现出卓越的鲁棒性。此外，MPS原则还可作为通用正则化框架应用于其他架构。

Conclusion: 通过引入预测充分性原则并开发MPS-SSM，本研究为状态空间模型提供了一个理论上更坚实的基础，并展示了其在性能和鲁棒性上的显著提升，同时该原则具有广泛的适用性。

Abstract: State Space Models (SSMs), particularly recent selective variants like Mamba,
have emerged as a leading architecture for sequence modeling, challenging the
dominance of Transformers. However, the success of these state-of-the-art
models largely relies on heuristically designed selective mechanisms, which
lack a rigorous first-principle derivation. This theoretical gap raises
questions about their optimality and robustness against spurious correlations.
To address this, we introduce the Principle of Predictive Sufficiency, a novel
information-theoretic criterion stipulating that an ideal hidden state should
be a minimal sufficient statistic of the past for predicting the future. Based
on this principle, we propose the Minimal Predictive Sufficiency State Space
Model (MPS-SSM), a new framework where the selective mechanism is guided by
optimizing an objective function derived from our principle. This approach
encourages the model to maximally compress historical information without
losing predictive power, thereby learning to ignore non-causal noise and
spurious patterns. Extensive experiments on a wide range of benchmark datasets
demonstrate that MPS-SSM not only achieves state-of-the-art performance,
significantly outperforming existing models in long-term forecasting and noisy
scenarios, but also exhibits superior robustness. Furthermore, we show that the
MPS principle can be extended as a general regularization framework to enhance
other popular architectures, highlighting its broad potential.

</details>


### [214] [CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction](https://arxiv.org/abs/2508.03159)
*Jueon Park,Yein Park,Minju Song,Soyon Park,Donghyeon Lee,Seungheun Baek,Jaewoo Kang*

Main category: cs.LG

TL;DR: 提出CoTox框架，结合LLM和CoT推理，整合化学、生物数据进行可解释的多毒性预测。它优于传统模型，并通过IUPAC命名和生物背景增强性能，有望改进早期药物安全评估。


<details>
  <summary>Details</summary>
Motivation: 药物毒性是药物开发的主要挑战。现有机器学习模型受限于数据依赖、缺乏可解释性，且难以捕捉器官特异性毒性。现有大语言模型（LLM）方法则缺乏生物学背景和透明推理。

Method: CoTox框架整合大语言模型（LLM）与思维链（CoT）推理，用于多毒性预测。它结合化学结构（使用IUPAC命名而非SMILES）、生物通路和基因本体（GO）术语，通过分步推理生成可解释的预测。使用GPT-4o进行验证，并模拟相关细胞类型处理以融入生物学背景。

Result: CoTox性能优于传统机器学习和深度学习模型。IUPAC命名能增强LLM的推理能力并提升预测性能。案例研究表明，CoTox的毒性预测结果与生理反应一致。

Conclusion: CoTox展示了基于LLM的框架在提高药物毒性预测的可解释性，以及支持早期药物安全性评估方面的巨大潜力。

Abstract: Drug toxicity remains a major challenge in pharmaceutical development. Recent
machine learning models have improved in silico toxicity prediction, but their
reliance on annotated data and lack of interpretability limit their
applicability. This limits their ability to capture organ-specific toxicities
driven by complex biological mechanisms. Large language models (LLMs) offer a
promising alternative through step-by-step reasoning and integration of textual
data, yet prior approaches lack biological context and transparent rationale.
To address this issue, we propose CoTox, a novel framework that integrates LLM
with chain-of-thought (CoT) reasoning for multi-toxicity prediction. CoTox
combines chemical structure data, biological pathways, and gene ontology (GO)
terms to generate interpretable toxicity predictions through step-by-step
reasoning. Using GPT-4o, we show that CoTox outperforms both traditional
machine learning and deep learning model. We further examine its performance
across various LLMs to identify where CoTox is most effective. Additionally, we
find that representing chemical structures with IUPAC names, which are easier
for LLMs to understand than SMILES, enhances the model's reasoning ability and
improves predictive performance. To demonstrate its practical utility in drug
development, we simulate the treatment of relevant cell types with drug and
incorporated the resulting biological context into the CoTox framework. This
approach allow CoTox to generate toxicity predictions aligned with
physiological responses, as shown in case study. This result highlights the
potential of LLM-based frameworks to improve interpretability and support
early-stage drug safety assessment. The code and prompt used in this work are
available at https://github.com/dmis-lab/CoTox.

</details>


### [215] [Overcoming Algorithm Aversion with Transparency: Can Transparent Predictions Change User Behavior?](https://arxiv.org/abs/2508.03168)
*Lasse Bohlen,Sven Kruschel,Julian Rosenberger,Patrick Zschech,Mathias Kraus*

Main category: cs.LG

TL;DR: 用户调整能力能有效减少对算法的厌恶，而透明度对此影响较小且独立。


<details>
  <summary>Details</summary>
Motivation: 以往研究表明用户调整机器学习模型预测可减少对不完善算法决策的厌恶，但这些结果是在用户不了解模型推理的情况下获得的。因此，仍不清楚可解释的机器学习模型是否能进一步减少算法厌恶，甚至使可调整性变得多余。

Method: 本研究概念性地复制了一项检验可调整预测对算法厌恶影响的知名研究，并通过引入一个视觉化展示决策逻辑的可解释机器学习模型进行扩展。通过一项预注册的280名参与者用户研究，探讨了透明度与可调整性在减少算法决策厌恶方面的交互作用。

Result: 研究结果复制了可调整性效应，表明允许用户修改算法预测可以减轻厌恶。透明度的影响比预期小，且在样本中不显著。此外，透明度和可调整性的影响似乎比预期更独立。

Conclusion: 用户对算法预测的调整能力仍然是减少算法厌恶的有效手段。尽管引入了透明度，其影响不如预期显著，且与可调整性的作用相对独立。这表明可调整性在减少算法厌恶中仍扮演关键角色，即便在模型决策逻辑变得透明的情况下。

Abstract: Previous work has shown that allowing users to adjust a machine learning (ML)
model's predictions can reduce aversion to imperfect algorithmic decisions.
However, these results were obtained in situations where users had no
information about the model's reasoning. Thus, it remains unclear whether
interpretable ML models could further reduce algorithm aversion or even render
adjustability obsolete. In this paper, we conceptually replicate a well-known
study that examines the effect of adjustable predictions on algorithm aversion
and extend it by introducing an interpretable ML model that visually reveals
its decision logic. Through a pre-registered user study with 280 participants,
we investigate how transparency interacts with adjustability in reducing
aversion to algorithmic decision-making. Our results replicate the
adjustability effect, showing that allowing users to modify algorithmic
predictions mitigates aversion. Transparency's impact appears smaller than
expected and was not significant for our sample. Furthermore, the effects of
transparency and adjustability appear to be more independent than expected.

</details>


### [216] [Quantum Spectral Reasoning: A Non-Neural Architecture for Interpretable Machine Learning](https://arxiv.org/abs/2508.03170)
*Andrew Kiruluta*

Main category: cs.LG

TL;DR: 提出一种基于量子谱方法（Pade近似、Lanczos算法）的新型机器学习架构，实现可解释的信号分析和符号推理，作为深度学习的替代方案。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种透明、物理可解释、数据高效且具备推理能力的机器学习模型，以解决传统深度学习模型缺乏可解释性、数据密集型和黑盒性质的问题。

Method: 该架构通过量子谱方法将时域信号转换为稀疏、物理有意义的谱表示，通过有理谱近似提取共振结构，然后通过核投影函数映射为符号谓词，最后通过基于规则的推理引擎进行逻辑推理。该方法避免了反向传播、高维嵌入和大量数据。

Result: 研究开发了完整的数学形式和模块化算法实现，并在时间序列异常检测、符号分类和混合推理任务上进行了评估。结果显示，该谱-符号架构在保持可解释性和数据效率的同时，实现了有竞争力的准确性。

Conclusion: 该研究为物理信息、推理型机器学习开辟了新的方向，提供了一种透明、有物理基础且具备推理能力的机器学习模型，是深度学习模型的有前景替代方案。

Abstract: We propose a novel machine learning architecture that departs from
conventional neural network paradigms by leveraging quantum spectral methods,
specifically Pade approximants and the Lanczos algorithm, for interpretable
signal analysis and symbolic reasoning. The core innovation of our approach
lies in its ability to transform raw time-domain signals into sparse,
physically meaningful spectral representations without the use of
backpropagation, high-dimensional embeddings, or data-intensive black-box
models. Through rational spectral approximation, the system extracts resonant
structures that are then mapped into symbolic predicates via a kernel
projection function, enabling logical inference through a rule-based reasoning
engine. This architecture bridges mathematical physics, sparse approximation
theory, and symbolic artificial intelligence, offering a transparent and
physically grounded alternative to deep learning models. We develop the full
mathematical formalism underlying each stage of the pipeline, provide a modular
algorithmic implementation, and demonstrate the system's effectiveness through
comparative evaluations on time-series anomaly detection, symbolic
classification, and hybrid reasoning tasks. Our results show that this
spectral-symbolic architecture achieves competitive accuracy while maintaining
interpretability and data efficiency, suggesting a promising new direction for
physically-informed, reasoning-capable machine learning.

</details>


### [217] [Adaptive Sparse Softmax: An Effective and Efficient Softmax Variant](https://arxiv.org/abs/2508.03175)
*Qi Lv,Lei Geng,Ziqiang Cao,Min Cao,Sujian Li,Wenjie Li,Guohong Fu*

Main category: cs.LG

TL;DR: 提出AS-Softmax，通过稀疏学习和自适应梯度累积解决标准Softmax的训练无限持续、过拟合及效率低下问题，实现性能提升和训练加速。


<details>
  <summary>Details</summary>
Motivation: 标准Softmax的训练目标（目标分数趋近1）无法达成，导致训练无限持续和过拟合；同时，模型浪费时间在已高置信度正确分类的样本上，与测试目标（目标类别得分最大）不符。

Method: 提出自适应稀疏Softmax (AS-Softmax)，在Softmax基础上设计了匹配测试目标的转换。它在训练时丢弃得分远低于实际类别的类别，使模型专注于区分目标类别与强劲对手。为加速训练，针对AS-Softmax中简单样本损失趋近于0的特性，开发了基于掩蔽样本比例的自适应梯度累积策略。

Result: AS-Softmax在多种文本、图像和音频分类任务上持续优于Softmax及其变体。AS-Softmax的损失与验证分类性能显著相关。自适应梯度累积策略可使训练速度提高约1.2倍，同时保持分类效果。

Conclusion: AS-Softmax有效解决了标准Softmax的局限性，实现了更高的分类性能和更快的训练速度，且其损失更好地反映了实际分类表现。

Abstract: Softmax with the cross entropy loss is the standard configuration for current
neural classification models. The gold score for a target class is supposed to
be 1, but it is never reachable under the softmax schema. Such a problem makes
the training process continue forever and leads to overfitting. Moreover, the
"target-approach-1" training goal forces the model to continuously learn all
samples, leading to a waste of time in handling some samples which have already
been classified correctly with high confidence, while the test goal simply
requires the target class of each sample to hold the maximum score. To solve
the above weaknesses, we propose the Adaptive Sparse softmax (AS-Softmax) which
designs a reasonable and test-matching transformation on top of softmax. For
more purposeful learning, we discard the classes with far smaller scores
compared with the actual class during training. Then the model could focus on
learning to distinguish the target class from its strong opponents, which is
also the great challenge in test. In addition, since the training losses of
easy samples will gradually drop to 0 in AS-Softmax, we develop an adaptive
gradient accumulation strategy based on the masked sample ratio to speed up
training. We verify the proposed AS-Softmax on a variety of text multi-class,
text multi-label, text token classification, image classification and audio
classification tasks with class sizes ranging from 5 to 5000+. The results show
that AS-Softmax consistently outperforms softmax and its variants, and the loss
of AS-Softmax is remarkably correlated with classification performance in
validation. Furthermore, adaptive gradient accumulation strategy can bring
about 1.2x training speedup comparing with the standard softmax while
maintaining classification effectiveness.

</details>


### [218] [Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies](https://arxiv.org/abs/2508.03194)
*Yi Ma,Hongyao Tang,Chenjun Xiao,Yaodong Yang,Wei Wei,Jianye Hao,Jiye Liang*

Main category: cs.LG

TL;DR: 本综述系统分析了深度强化学习（DRL）中数据、网络和训练预算三个维度的扩展策略，旨在弥补扩展法则在DRL应用中的空白，并为未来研究提供路线图，以充分释放DRL在决策任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管扩展法则在计算机视觉和自然语言处理领域推动了深度学习的显著进步，但在深度强化学习（DRL）中的应用仍相对未被充分探索，其提升性能的潜力尚未完全实现。

Method: 本综述通过系统分析DRL中的扩展策略，将其分为三个维度进行探讨：数据扩展（优化数据效率、并行采样、数据生成），网络扩展（架构增强、集成与MoE方法、智能体数量扩展），以及训练预算扩展（分布式训练、高回放比率、大批量大小、辅助训练）。

Result: 研究分析揭示，数据、网络和训练预算的扩展策略在推进深度强化学习的决策能力方面具有协同作用。

Conclusion: 本综述不仅强调了这些扩展策略的协同作用，也为DRL的未来研究提供了路线图，强调了平衡可扩展性与计算效率的重要性，并指出了在机器人控制、自动驾驶和LLM训练等任务中利用扩展性发挥DRL全部潜力的前景方向。

Abstract: In recent years, the expansion of neural network models and training data has
driven remarkable progress in deep learning, particularly in computer vision
and natural language processing. This advancement is underpinned by the concept
of Scaling Laws, which demonstrates that scaling model parameters and training
data enhances learning performance. While these fields have witnessed
breakthroughs, such as the development of large language models like GPT-4 and
advanced vision models like Midjourney, the application of scaling laws in deep
reinforcement learning (DRL) remains relatively unexplored. Despite its
potential to improve performance, the integration of scaling laws into DRL for
decision making has not been fully realized. This review addresses this gap by
systematically analyzing scaling strategies in three dimensions: data, network,
and training budget. In data scaling, we explore methods to optimize data
efficiency through parallel sampling and data generation, examining the
relationship between data volume and learning outcomes. For network scaling, we
investigate architectural enhancements, including monolithic expansions,
ensemble and MoE methods, and agent number scaling techniques, which
collectively enhance model expressivity while posing unique computational
challenges. Lastly, in training budget scaling, we evaluate the impact of
distributed training, high replay ratios, large batch sizes, and auxiliary
training on training efficiency and convergence. By synthesizing these
strategies, this review not only highlights their synergistic roles in
advancing DRL for decision making but also provides a roadmap for future
research. We emphasize the importance of balancing scalability with
computational efficiency and outline promising directions for leveraging
scaling to unlock the full potential of DRL in various tasks such as robot
control, autonomous driving and LLM training.

</details>


### [219] [Convergence of Deterministic and Stochastic Diffusion-Model Samplers: A Simple Analysis in Wasserstein Distance](https://arxiv.org/abs/2508.03210)
*Eliot Beyler,Francis Bach*

Main category: cs.LG

TL;DR: 该研究为基于扩散的生成模型（包括DDPM和DDIM）提供了新的Wasserstein距离收敛性保证，并通过分析离散化、初始化和分数估计误差，首次推导了Heun采样器的收敛界限，并改进了Euler采样器的现有结果。


<details>
  <summary>Details</summary>
Motivation: 为扩散模型提供更严格的Wasserstein距离收敛性保证，并深入分析离散化、初始化和分数估计等关键误差来源。

Method: 引入了一个分析离散化、初始化和分数估计误差的简单框架；强调学习分数函数的空间正则性；主张根据真实逆过程控制分数误差（与去噪分数匹配一致）；并结合平滑Wasserstein距离的最新结果来提高初始化误差界的精度。

Result: 提供了基于扩散的生成模型（包括随机和确定性采样方法）在Wasserstein距离下的新收敛性保证；首次推导了Heun采样器的Wasserstein收敛界限；改进了概率流ODE的Euler采样器的现有收敛结果。

Conclusion: 该研究通过提供新的Wasserstein收敛性保证和全面的误差分析，加深了对扩散模型的理论理解。它强调了学习分数函数的空间正则性和分数误差控制的重要性，有助于提升扩散模型的性能和可靠性。

Abstract: We provide new convergence guarantees in Wasserstein distance for
diffusion-based generative models, covering both stochastic (DDPM-like) and
deterministic (DDIM-like) sampling methods. We introduce a simple framework to
analyze discretization, initialization, and score estimation errors. Notably,
we derive the first Wasserstein convergence bound for the Heun sampler and
improve existing results for the Euler sampler of the probability flow ODE. Our
analysis emphasizes the importance of spatial regularity of the learned score
function and argues for controlling the score error with respect to the true
reverse process, in line with denoising score matching. We also incorporate
recent results on smoothed Wasserstein distances to sharpen initialization
error bounds.

</details>


### [220] [Revisiting Deep Information Propagation: Fractal Frontier and Finite-size Effects](https://arxiv.org/abs/2508.03222)
*Giuseppe Alessio D'Inverno,Zhiyuan Hu,Leo Davy,Michael Unser,Gianluigi Rozza,Jonathan Dong*

Main category: cs.LG

TL;DR: 本研究分析了有限宽度神经网络（包括卷积神经网络）中的信息传播，发现有序和混沌区域的边界呈现分形结构，揭示了神经网络动力学的复杂性，并强调了有限网络深度对分离性和鲁棒性权衡的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有关于深度神经网络信息传播的均场理论假设网络宽度无限，这不适用于实际的有限尺寸网络，因此有必要研究有限宽度网络中的信息传播特性。

Method: 1. 研究随机初始化有限宽度神经网络中的信息传播。2. 引入基于傅里叶变换的结构化转换，将分析扩展到卷积神经网络。

Result: 1. 有限宽度神经网络中，有序和混沌区域之间的边界表现出分形结构。2. 卷积神经网络的信息传播也遵循相同的行为。3. 这些发现揭示了神经网络动力学的基本复杂性，且与输入数据和优化过程无关。

Conclusion: 本研究强调了有限网络深度在神经网络分离性（separation）与鲁棒性（robustness）权衡方面的重要性。

Abstract: Information propagation characterizes how input correlations evolve across
layers in deep neural networks. This framework has been well studied using
mean-field theory, which assumes infinitely wide networks. However, these
assumptions break down for practical, finite-size networks. In this work, we
study information propagation in randomly initialized neural networks with
finite width and reveal that the boundary between ordered and chaotic regimes
exhibits a fractal structure. This shows the fundamental complexity of neural
network dynamics, in a setting that is independent of input data and
optimization. To extend this analysis beyond multilayer perceptrons, we
leverage recently introduced Fourier-based structured transforms, and show that
information propagation in convolutional neural networks also follow the same
behavior. Our investigation highlights the importance of finite network depth
with respect to the tradeoff between separation and robustness.

</details>


### [221] [On Conformal Machine Unlearning](https://arxiv.org/abs/2508.03245)
*Yahya Alkhatib,Wee Peng Tay*

Main category: cs.LG

TL;DR: 针对现有机器学习遗忘方法缺乏统计保证和评估效率低的问题，本文提出一种基于共形预测（CP）的新定义和方法，提供严格的统计保证、高效的评估指标，并有效移除目标数据。


<details>
  <summary>Details</summary>
Motivation: 随着GDPR和CCPA等法规推动数据隐私需求增长，机器学习遗忘（MU）成为关键技术。然而，现有MU方法普遍缺乏严格的统计保证，依赖启发式指标，并且需要计算成本高昂的再训练基线。

Method: 本文基于共形预测（CP）提出了机器学习遗忘的新定义，提供了统计上可靠、具备不确定性感知的保证，无需依赖朴素再训练。具体方法包括：形式化共形准则来量化遗忘样本被CP集合排除的频率；提出经验指标“高效覆盖频率”（ECF）及其补数“高效未覆盖频率”（EuCF）来衡量遗忘效果；并进一步提出一种实用遗忘方法来优化这些共形指标。

Result: 在多种遗忘场景、数据集和模型上的大量实验结果表明，该方法在移除目标数据方面表现出显著的有效性。

Conclusion: 该方法通过引入基于共形预测的新框架，成功克服了现有机器学习遗忘方法的局限性，提供了严格的统计保证和高效的评估手段，并被证明能够有效实现目标数据移除。

Abstract: The increasing demand for data privacy, driven by regulations such as GDPR
and CCPA, has made Machine Unlearning (MU) essential for removing the influence
of specific training samples from machine learning models while preserving
performance on retained data. However, most existing MU methods lack rigorous
statistical guarantees, rely on heuristic metrics, and often require
computationally expensive retraining baselines. To overcome these limitations,
we introduce a new definition for MU based on Conformal Prediction (CP),
providing statistically sound, uncertainty-aware guarantees without the need
for the concept of naive retraining. We formalize conformal criteria that
quantify how often forgotten samples are excluded from CP sets, and propose
empirical metrics,the Efficiently Covered Frequency (ECF at c) and its
complement, the Efficiently Uncovered Frequency (EuCF at d), to measure the
effectiveness of unlearning. We further present a practical unlearning method
designed to optimize these conformal metrics. Extensive experiments across
diverse forgetting scenarios, datasets and models demonstrate the efficacy of
our approach in removing targeted data.

</details>


### [222] [HALO: Hindsight-Augmented Learning for Online Auto-Bidding](https://arxiv.org/abs/2508.03267)
*Pusen Dong,Chenglong Cao,Xinyu Zhou,Jirong You,Linhe Xu,Feifan Xu,Shuo Yuan*

Main category: cs.LG

TL;DR: 提出HALO，通过回溯增强学习和B样条函数表示，解决实时竞价中多约束自动出价的样本效率低和泛化性差问题，有效处理广告主多样性并提升表现。


<details>
  <summary>Details</summary>
Motivation: 实时竞价（RTB）系统因广告主预算和ROI目标差异巨大，导致多约束出价（MCB）面临复杂适应挑战。传统自动出价方案存在样本效率低下（探索结果不可复用）和约束变化下泛化能力不足（忽略约束与出价系数的物理关系）的问题。

Method: 提出HALO（Hindsight-Augmented Learning for Online Auto-Bidding）。该方法引入理论上完善的回溯机制，通过轨迹重定向将所有探索转化为任意约束配置的训练数据；并采用B样条函数表示，实现跨约束空间的连续、导数感知出价映射。

Result: 在工业数据集上的评估显示，HALO在处理多尺度约束方面表现出优越性，显著减少了约束违规，并提高了GMV（商品交易总额）。

Conclusion: HALO能够确保即使预算/ROI要求与训练场景存在巨大差异时也能实现稳健的自适应，有效应对实时竞价中广告主异质性带来的挑战。

Abstract: Digital advertising platforms operate millisecond-level auctions through
Real-Time Bidding (RTB) systems, where advertisers compete for ad impressions
through algorithmic bids. This dynamic mechanism enables precise audience
targeting but introduces profound operational complexity due to advertiser
heterogeneity: budgets and ROI targets span orders of magnitude across
advertisers, from individual merchants to multinational brands. This diversity
creates a demanding adaptation landscape for Multi-Constraint Bidding (MCB).
Traditional auto-bidding solutions fail in this environment due to two critical
flaws: 1) severe sample inefficiency, where failed explorations under specific
constraints yield no transferable knowledge for new budget-ROI combinations,
and 2) limited generalization under constraint shifts, as they ignore physical
relationships between constraints and bidding coefficients. To address this, we
propose HALO: Hindsight-Augmented Learning for Online Auto-Bidding. HALO
introduces a theoretically grounded hindsight mechanism that repurposes all
explorations into training data for arbitrary constraint configuration via
trajectory reorientation. Further, it employs B-spline functional
representation, enabling continuous, derivative-aware bid mapping across
constraint spaces. HALO ensures robust adaptation even when budget/ROI
requirements differ drastically from training scenarios. Industrial dataset
evaluations demonstrate the superiority of HALO in handling multi-scale
constraints, reducing constraint violations while improving GMV.

</details>


### [223] [Towards Interpretable Concept Learning over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2508.03269)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: 提出一个神经符号框架，通过信号时序逻辑（STL）概念，实现可解释且高精度的时间序列分类。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类在安全关键应用中至关重要，但现有深度学习方法是黑箱模型，难以理解其决策原因，这在关键应用中是重大挑战。

Method: 本文提出一种神经符号框架，通过将时间序列轨迹直接嵌入到信号时序逻辑（STL）概念空间中，统一了分类和解释功能。该方法引入了一种新的受STL启发的核心（kernel），将原始时间序列映射到其与预定义STL公式的一致性，从而在优化分类准确性的同时，也优化了模型的可解释性。

Result: 早期结果显示，该框架在分类性能上具有竞争力，同时能为模型决策提供高质量的逻辑解释，包括局部和全局的符号解释。

Conclusion: 该框架能够实现基于人类可解释的时间模式的分类，并为模型决策提供清晰的逻辑依据，有效解决了时间序列分类中黑箱模型解释性不足的问题。

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a neuro-symbolic framework that unifies classification and explanation
through direct embedding of trajectories into a space of Signal Temporal Logic
(STL) concepts. By introducing a novel STL-inspired kernel that maps raw time
series to their alignment with predefined STL formulae, our model jointly
optimises for accuracy and interpretability, as each prediction is accompanied
by the most relevant logical concepts that characterise it. This enables
classification grounded in human-interpretable temporal patterns and produces
both local and global symbolic explanations. Early results show competitive
performance while offering high-quality logical justifications for model
decisions.

</details>


### [224] [The alpha-beta divergence for real and complex data](https://arxiv.org/abs/2508.03272)
*Sergio Cruces*

Main category: cs.LG

TL;DR: 本文提出了一种将alpha-beta散度扩展至复数数据的新方法，该方法构建了一个通用的框架，能够概括现有常见距离，并为信号处理提供了实用工具。


<details>
  <summary>Details</summary>
Motivation: 现有的alpha-beta散度主要针对非负数据设计，但许多信号处理领域的数据本质上是复数。因此，有必要将这种多功能的散度家族扩展，以适应和处理复数向量数据。

Method: 研究者扩展了alpha-beta散度的定义，使其能够处理复数向量。这种新公式在超参数设定为单位时，可特化为欧几里得和马哈拉诺比斯平方距离。其他超参数选择则能产生多种经典散度的可分离和不可分离扩展。此外，研究还展示了在逼近复数随机向量的问题中，优化alpha-beta均值失真可以得到质心的闭合形式表达式。

Result: 成功构建了适用于复数数据的alpha-beta散度新定义。该新公式能够泛化已知的欧几里得和马哈拉诺比斯平方距离，并能产生多种实用且可分离/不可分离的经典散度扩展。在复数随机向量逼近的背景下，优化所得的质心具有闭合形式表达式，有助于阐明散度超参数的独特作用。

Conclusion: 所提出的复数alpha-beta散度为信号处理领域提供了一个重要且多功能的工具，尤其在涉及固有复数数据的情境下具有广泛的潜在应用价值。

Abstract: Divergences are fundamental to the information criteria that underpin most
signal processing algorithms. The alpha-beta family of divergences, designed
for non-negative data, offers a versatile framework that parameterizes and
continuously interpolates several separable divergences found in existing
literature. This work extends the definition of alpha-beta divergences to
accommodate complex data, specifically when the arguments of the divergence are
complex vectors. This novel formulation is designed in such a way that, by
setting the divergence hyperparameters to unity, it particularizes to the
well-known Euclidean and Mahalanobis squared distances. Other choices of
hyperparameters yield practical separable and non-separable extensions of
several classical divergences. In the context of the problem of approximating a
complex random vector, the centroid obtained by optimizing the alpha-beta mean
distortion has a closed-form expression, which interpretation sheds light on
the distinct roles of the divergence hyperparameters. These contributions may
have wide potential applicability, as there are many signal processing domains
in which the underlying data are inherently complex.

</details>


### [225] [Understanding the Embedding Models on Hyper-relational Knowledge Graph](https://arxiv.org/abs/2508.03280)
*Yubo Wang,Shimin Di,Zhili Wang,Haoyang Li,Fei Teng,Hao Xin,Lei Chen*

Main category: cs.LG

TL;DR: 论文首先探究HKGE模型性能来源并指出现有模型不足，通过将HKG转换为KG进行评估，随后提出FormerGNN框架，该框架通过保留拓扑、捕获长距离依赖和改进信息整合，实现了优于现有HKGE模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有超关系知识图谱嵌入（HKGE）模型的性能来源尚不明确（是基础模型还是修饰符模块），且其在拓扑保持、长距离依赖捕获及主三元组与修饰符信息整合方面存在局限性。

Method: 1. 将超关系知识图谱（HKGs）通过三种分解方法转换为传统知识图谱（KGs）格式，并评估几种经典KGE模型在其上的性能。2. 提出FormerGNN框架，该框架采用修饰符集成器以保留原始HKG拓扑，使用基于GNN的图编码器捕获长距离依赖，并通过改进的方法整合主三元组和修饰符信息以缓解信息压缩问题。

Result: 1. 部分经典KGE模型在分解后的HKG数据上表现出与HKGE模型相当的性能。2. 分解方法改变了原始HKG拓扑且未能完全保留信息。3. 现有HKGE模型在捕获图的长距离依赖或整合主三元组和修饰符信息时存在不足。4. FormerGNN框架的实验结果表明其性能优于现有HKGE模型。

Conclusion: 本研究揭示了现有HKGE模型及其分解方法的局限性，并成功开发了FormerGNN框架。该框架有效解决了现有模型在拓扑保持、长距离依赖捕获和信息整合方面的问题，为未来的HKGE研究提供了新的方向和更优的解决方案。

Abstract: Recently, Hyper-relational Knowledge Graphs (HKGs) have been proposed as an
extension of traditional Knowledge Graphs (KGs) to better represent real-world
facts with additional qualifiers. As a result, researchers have attempted to
adapt classical Knowledge Graph Embedding (KGE) models for HKGs by designing
extra qualifier processing modules. However, it remains unclear whether the
superior performance of Hyper-relational KGE (HKGE) models arises from their
base KGE model or the specially designed extension module. Hence, in this
paper, we data-wise convert HKGs to KG format using three decomposition methods
and then evaluate the performance of several classical KGE models on HKGs. Our
results show that some KGE models achieve performance comparable to that of
HKGE models. Upon further analysis, we find that the decomposition methods
alter the original HKG topology and fail to fully preserve HKG information.
Moreover, we observe that current HKGE models are either insufficient in
capturing the graph's long-range dependency or struggle to integrate
main-triple and qualifier information due to the information compression issue.
To further justify our findings and offer a potential direction for future HKGE
research, we propose the FormerGNN framework. This framework employs a
qualifier integrator to preserve the original HKG topology, and a GNN-based
graph encoder to capture the graph's long-range dependencies, followed by an
improved approach for integrating main-triple and qualifier information to
mitigate compression issues. Our experimental results demonstrate that
FormerGNN outperforms existing HKGE models.

</details>


### [226] [Online Continual Graph Learning](https://arxiv.org/abs/2508.03283)
*Giovanni Donghi,Luca Pasa,Daniele Zambon,Cesare Alippi,Nicolò Navarin*

Main category: cs.LG

TL;DR: 提出图上在线持续学习的通用框架、明确定义与评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有图持续学习研究鲜少关注在线流式数据，而真实世界图数据持续演变需在线预测。缺乏清晰的图上在线持续学习定义，导致现有方法与标准设定不符。

Method: 提出图上在线持续学习的通用公式，强调图拓扑批处理的效率要求，并提供明确的评估设定。引入一套基准数据集，并报告了多种现有持续学习方法在该设定下的表现。

Result: 本研究建立了图上在线持续学习的通用公式和明确的评估设定，并引入了基准数据集，报告了现有方法的性能。

Conclusion: 该工作为图上在线持续学习提供了一个明确的通用框架、定义和系统评估基准，有助于推动该领域的研究。

Abstract: The aim of Continual Learning (CL) is to learn new tasks incrementally while
avoiding catastrophic forgetting. Online Continual Learning (OCL) specifically
focuses on learning efficiently from a continuous stream of data with shifting
distribution. While recent studies explore Continual Learning on graphs
exploiting Graph Neural Networks (GNNs), only few of them focus on a streaming
setting. Yet, many real-world graphs evolve over time, often requiring timely
and online predictions. Current approaches, however, are not well aligned with
the standard OCL setting, partly due to the lack of a clear definition of
online Continual Learning on graphs. In this work, we propose a general
formulation for online Continual Learning on graphs, emphasizing the efficiency
requirements on batch processing over the graph topology, and providing a
well-defined setting for systematic model evaluation. Finally, we introduce a
set of benchmarks and report the performance of several methods in the CL
literature, adapted to our setting.

</details>


### [227] [Strategic Hypothesis Testing](https://arxiv.org/abs/2508.03289)
*Safwan Hossain,Yatong Chen,Yiling Chen*

Main category: cs.LG

TL;DR: 本文在委托-代理框架下，通过博弈论模型分析了战略性代理人影响假设检验决策的问题。研究揭示了委托人最优p值阈值的可解释特性，并得到了药品审批数据的实证支持。


<details>
  <summary>Details</summary>
Motivation: 在委托-代理框架下的假设检验中，如何选择一个最优的p值阈值，以平衡I类和II类错误，并同时考虑到战略性代理人为了最大化利润而可能采取的参与和报告行为，是本研究的动机。

Method: 构建了一个博弈论模型，以捕捉代理人的参与和报告行为如何响应委托人的统计决策规则。该模型分析了复杂交互下的错误行为。此外，研究利用公开的药品审批数据对模型及关键发现进行了实证验证。

Result: 研究发现，委托人的错误率在通过高效计算的临界p值阈值分割时，呈现出清晰的单调行为。这使得委托人最优p值阈值的特征变得可解释。模型和洞察已通过药品审批数据得到经验验证。

Conclusion: 本研究为假设检验框架内的战略交互提供了全面视角，并为相关的技术和监管政策提供了重要的理论和实践见解。

Abstract: We examine hypothesis testing within a principal-agent framework, where a
strategic agent, holding private beliefs about the effectiveness of a product,
submits data to a principal who decides on approval. The principal employs a
hypothesis testing rule, aiming to pick a p-value threshold that balances false
positives and false negatives while anticipating the agent's incentive to
maximize expected profitability. Building on prior work, we develop a
game-theoretic model that captures how the agent's participation and reporting
behavior respond to the principal's statistical decision rule. Despite the
complexity of the interaction, we show that the principal's errors exhibit
clear monotonic behavior when segmented by an efficiently computable critical
p-value threshold, leading to an interpretable characterization of their
optimal p-value threshold. We empirically validate our model and these insights
using publicly available data on drug approvals. Overall, our work offers a
comprehensive perspective on strategic interactions within the hypothesis
testing framework, providing technical and regulatory insights.

</details>


### [228] [Bridging ocean wave physics and deep learning: Physics-informed neural operators for nonlinear wavefield reconstruction in real-time](https://arxiv.org/abs/2508.03315)
*Svenja Ehlers,Merten Stender,Norbert Hoffmann*

Main category: cs.LG

TL;DR: 本研究提出一种物理信息神经网络算子（PINO）框架，无需真值数据即可从稀疏测量中实时准确重建非线性海浪场，为实际海洋环境中的波浪预测提供新方法。


<details>
  <summary>Details</summary>
Motivation: 实时精确预测相分辨海浪场是一个关键但尚未解决的问题，主要原因是没有实用的数据同化方法来从稀疏或间接波浪测量中重建初始条件。此外，现有监督深度学习方法需要大量带标签的真实波浪数据，这在实际场景中难以获取。

Method: 提出一种物理信息神经网络算子（PINO）框架，通过将海洋重力波自由表面边界条件的残差嵌入其损失函数中，从而以软约束方式限制解空间，实现在训练期间无需真实数据的情况下，从稀疏测量中重建空间和时间上的相分辨非线性海浪场。

Result: 通过使用高度逼真的合成波浪数据验证了该方法，结果表明，PINO能够从浮标时间序列和雷达快照中准确重建非线性波浪场，并能在各种波浪条件下实现准确、实时的重建和稳健的泛化。

Conclusion: PINO框架的成功应用为在现实海洋环境中进行可操作的、数据驱动的波浪重建和预测开辟了道路。

Abstract: Accurate real-time prediction of phase-resolved ocean wave fields remains a
critical yet largely unsolved problem, primarily due to the absence of
practical data assimilation methods for reconstructing initial conditions from
sparse or indirect wave measurements. While recent advances in supervised deep
learning have shown potential for this purpose, they require large labelled
datasets of ground truth wave data, which are infeasible to obtain in
real-world scenarios. To overcome this limitation, we propose a
Physics-Informed Neural Operator (PINO) framework for reconstructing spatially
and temporally phase-resolved, nonlinear ocean wave fields from sparse
measurements, without the need for ground truth data during training. This is
achieved by embedding residuals of the free surface boundary conditions of
ocean gravity waves into the loss function of the PINO, constraining the
solution space in a soft manner. After training, we validate our approach using
highly realistic synthetic wave data and demonstrate the accurate
reconstruction of nonlinear wave fields from both buoy time series and radar
snapshots. Our results indicate that PINOs enable accurate, real-time
reconstruction and generalize robustly across a wide range of wave conditions,
thereby paving the way for operational, data-driven wave reconstruction and
prediction in realistic marine environments.

</details>


### [229] [Software Fairness Dilemma: Is Bias Mitigation a Zero-Sum Game?](https://arxiv.org/abs/2508.03323)
*Zhenpeng Chen,Xinyue Li,Jie M. Zhang,Weisong Sun,Ying Xiao,Tianlin Li,Yiling Lou,Yang Liu*

Main category: cs.LG

TL;DR: 研究发现表格数据偏见缓解方法呈零和博弈，即弱势群体的改善与特权群体收益的减少相关。但提出仅对弱势群体应用缓解方法可避免零和效应，提升公平性而不影响整体性能。


<details>
  <summary>Details</summary>
Motivation: 以往研究发现计算机视觉和自然语言处理（NLP）任务中的偏见缓解存在“拉低效应”，即公平性通过降低所有群体的性能而非提升弱势群体来实现。然而，对于表格数据任务（公平性研究的关键领域，具有重要实际应用），这种效应是否适用尚不明确。

Method: 本研究评估了八种表格数据偏见缓解方法（包括常用和前沿方法），在五个真实世界数据集和四种常见机器学习模型上进行了44项任务的实验。为探索替代方案，研究还调查了仅将最先进的偏见缓解方法应用于弱势群体的效果。

Result: 1. 与早期发现相反，结果显示表格数据的偏见缓解方法通常以零和方式运行，即弱势群体的改善与特权群体收益的减少相关。
2. 通过将最先进的偏见缓解方法仅应用于弱势群体，可以提升弱势群体的利益，而不会对特权群体或整体机器学习性能产生负面影响。

Conclusion: 本研究揭示了实现公平性改进的潜在途径，即避免零和权衡，这可能有助于促进偏见缓解方法的广泛采用。

Abstract: Fairness is a critical requirement for Machine Learning (ML) software,
driving the development of numerous bias mitigation methods. Previous research
has identified a leveling-down effect in bias mitigation for computer vision
and natural language processing tasks, where fairness is achieved by lowering
performance for all groups without benefiting the unprivileged group. However,
it remains unclear whether this effect applies to bias mitigation for tabular
data tasks, a key area in fairness research with significant real-world
applications. This study evaluates eight bias mitigation methods for tabular
data, including both widely used and cutting-edge approaches, across 44 tasks
using five real-world datasets and four common ML models. Contrary to earlier
findings, our results show that these methods operate in a zero-sum fashion,
where improvements for unprivileged groups are related to reduced benefits for
traditionally privileged groups. However, previous research indicates that the
perception of a zero-sum trade-off might complicate the broader adoption of
fairness policies. To explore alternatives, we investigate an approach that
applies the state-of-the-art bias mitigation method solely to unprivileged
groups, showing potential to enhance benefits of unprivileged groups without
negatively affecting privileged groups or overall ML performance. Our study
highlights potential pathways for achieving fairness improvements without
zero-sum trade-offs, which could help advance the adoption of bias mitigation
methods.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [230] [A Reinforcement Learning Framework for Mobility Control of gNBs in Dynamic Radio Access Networks](https://arxiv.org/abs/2508.02960)
*Pedro Duarte,André Coelho,Manuel Ricardo*

Main category: cs.NI

TL;DR: 本文针对动态无线环境中视距（LoS）连接维护的挑战，提出一个3D仿真器CC-SIM，并基于此开发了DQN智能体，实现了移动基站的自主重定位，有效减少LoS阻塞时间。


<details>
  <summary>Details</summary>
Motivation: 在复杂且动态的无线环境中，用户移动和障碍物导致视距（LoS）连接难以维持。移动基站（gNBs）虽能通过物理重定位来恢复或保持LoS，但这需要开发智能算法来实现自主移动控制。

Method: 1. 开发了CONVERGE Chamber Simulator (CC-SIM)，一个3D仿真环境，用于开发、训练和验证移动gNB的移动控制算法，该模拟器能模拟用户和障碍物移动、视觉遮挡及射频(RF)传播，并支持离线强化学习和与5G系统集成进行实时测试。2. 基于CC-SIM，开发了一个深度Q网络(DQN)智能体，学习根据动态环境变化主动重定位gNB。

Result: 通过在三个代表性用例中的实验，训练后的DQN智能体与静态部署相比，显著减少了LoS阻塞时间，最高可达42%。

Conclusion: 研究结果表明，基于学习的移动控制在自适应下一代无线网络中是有效的，能显著提升连接性能。

Abstract: The increasing complexity of wireless environments, characterized by user
mobility and dynamic obstructions, poses challenges for the maintenance of
Line-of-Sight (LoS) connectivity. Mobile base stations (gNBs) stand as a
promising solution by physically relocating to restore or sustain LoS, thereby
necessitating the development of intelligent algorithms for autonomous movement
control.
  As part of the CONVERGE research project, which is developing an experimental
chamber to integrate computer vision (CV) into mobile networks and enhance
Quality of Service (QoS) in dynamic wireless environments, this paper presents
two key contributions. First, we introduce the CONVERGE Chamber Simulator
(CC-SIM), a 3D simulation environment for developing, training, and validating
mobility control algorithms for mobile gNBs. CC-SIM models user and obstacle
mobility, visual occlusion, and Radio Frequency (RF) propagation behavior. It
supports both offline reinforcement learning and real-time testing through
tight integration with a standalone 5G system via the OpenAirInterface (OAI) RF
simulator, enabling validation under realistic network conditions.
  Second, leveraging CC-SIM, we develop a Deep Q-Network (DQN) agent that
learns to reposition the gNB proactively in response to dynamic environmental
changes. Experiments across three representative use cases show that the
trained agent significantly reduces LoS blockage time - by up to 42% - when
compared to static deployments. These results highlight the effectiveness of
learning-based mobility control in adaptive next-generation wireless networks.

</details>


### [231] [A Survey of AI Agent Registry Solutions](https://arxiv.org/abs/2508.03095)
*Aditi Singh,Abul Ehtesham,Ramesh Raskar,Mahesh Lambe,Pradyumna Chari,Jared James Grogan,Abhishek Singh,Saket Kumar*

Main category: cs.NI

TL;DR: 本文调查并比较了三种主要的AI代理注册系统方法：MCP、A2A和NANDA，旨在为AI代理的发现、身份和能力共享提供标准化指导。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理在云、企业和去中心化环境中大规模部署，对支持发现、身份识别和能力共享的标准化注册系统的需求变得至关重要。

Method: 论文通过调研三种独特的元数据模型（MCP的mcp.json、A2A的Agent Card和NANDA的AgentFacts），对它们在安全性、可伸缩性、认证和可维护性四个维度上进行了比较分析。

Result: 论文分析了MCP（集中式注册表，GitHub认证）、A2A（去中心化，JSON-based Agent Card）和NANDA（加密可验证，隐私保护AgentFacts）三种方法各自的特点和发现机制，并进行了多维度对比。

Conclusion: 论文提出了关于未来AI代理互联网注册系统设计和采纳的建议与推荐。

Abstract: As As autonomous AI agents scale across cloud, enterprise, and decentralized
environments, the need for standardized registry systems to support discovery,
identity, and capability sharing has become essential. This paper surveys three
prominent registry approaches each defined by a unique metadata model: MCP's
mcp.json, A2A's Agent Card, and NANDA's AgentFacts. MCP uses a centralized
metaregistry with GitHub authenticated publishing and structured metadata for
server discovery. A2A enables decentralized interaction via JSON-based Agent
Cards, discoverable through well-known URIs, curated catalogs, or direct
configuration. NANDA Index introduces AgentFacts, a cryptographically
verifiable and privacy-preserving metadata model designed for dynamic
discovery, credentialed capabilities, and cross-domain interoperability. These
approaches are compared across four dimensions: security, scalability,
authentication, and maintainability. The paper concludes with suggestions and
recommendations to guide future design and adoption of registry systems for the
Internet of AI Agents.

</details>


### [232] [Using the NANDA Index Architecture in Practice: An Enterprise Perspective](https://arxiv.org/abs/2508.03101)
*Sichao Wang,Ramesh Raskar,Mahesh Lambe,Pradyumna Chari,Rekha Singhal,Shailja Gupta,Rajesh Ranjan,Ken Huang*

Main category: cs.NI

TL;DR: 本文提出NANDA框架，旨在为自主AI代理构建安全、可信、可互操作的去中心化生态系统，解决现有架构的不足，并通过零信任和能力验证实现大规模部署。


<details>
  <summary>Details</summary>
Motivation: 当前传统网络架构无法满足自主AI代理在发现、认证、能力验证及跨协议安全协作方面的需求，存在安全、可扩展多代理协作的基础设施空白。

Method: 引入NANDA（去中心化架构中的网络化AI代理）框架，实现全球代理发现、通过AgentFacts进行加密可验证能力证明，支持跨多种协议的互操作性。该框架还实施零信任代理访问（ZTAA）原则，并定义代理可见性和控制（AVC）机制以满足企业治理和合规性。

Result: 将孤立的AI代理转化为一个可验证、可信赖的互联智能服务生态系统，为企业和消费者环境中的大规模自主代理部署奠定了基础。

Conclusion: NANDA框架通过解决AI代理能力与安全、可扩展多代理协作所需基础设施之间的关键差距，为下一代自主智能系统奠定了基础。

Abstract: The proliferation of autonomous AI agents represents a paradigmatic shift
from traditional web architectures toward collaborative intelligent systems
requiring sophisticated mechanisms for discovery, authentication, capability
verification, and secure collaboration across heterogeneous protocol
environments. This paper presents a comprehensive framework addressing the
fundamental infrastructure requirements for secure, trustworthy, and
interoperable AI agent ecosystems. We introduce the NANDA (Networked AI Agents
in a Decentralized Architecture) framework, providing global agent discovery,
cryptographically verifiable capability attestation through AgentFacts, and
cross-protocol interoperability across Anthropic's Modal Context Protocol
(MCP), Google's Agent-to-Agent (A2A), Microsoft's NLWeb, and standard HTTPS
communications. NANDA implements Zero Trust Agentic Access (ZTAA) principles,
extending traditional Zero Trust Network Access (ZTNA) to address autonomous
agent security challenges including capability spoofing, impersonation attacks,
and sensitive data leakage. The framework defines Agent Visibility and Control
(AVC) mechanisms enabling enterprise governance while maintaining operational
autonomy and regulatory compliance. Our approach transforms isolated AI agents
into an interconnected ecosystem of verifiable, trustworthy intelligent
services, establishing foundational infrastructure for large-scale autonomous
agent deployment across enterprise and consumer environments. This work
addresses the critical gap between current AI agent capabilities and
infrastructure requirements for secure, scalable, multi-agent collaboration,
positioning the foundation for next-generation autonomous intelligent systems.

</details>


### [233] [NANDA Adaptive Resolver: Architecture for Dynamic Resolution of AI Agent Names](https://arxiv.org/abs/2508.03113)
*John Zinky,Hema Seshadri,Mahesh Lambe,Pradyumna Chari,Ramesh Raskar*

Main category: cs.NI

TL;DR: AdaptiveResolver是一种动态微服务架构，旨在为AI智能体在分布式、异构环境中的通信提供上下文感知、实时的端点解析，从而实现灵活、安全、可扩展的智能体间交互。


<details>
  <summary>Details</summary>
Motivation: 传统的静态端点解析（如DNS或静态URL）在AI智能体于分布式、异构环境中进行通信时存在局限性，无法满足动态和上下文感知的需求。

Method: 智能体通过Agent Registry/Index发布包含其名称和上下文需求的Agent Fact卡片。请求智能体通过注册中心发现目标智能体后，AdaptiveResolver会根据地理位置、系统负载、智能体能力和安全威胁等实际环境上下文，实时解析并获取定制化的通信通道。该架构还支持信任、服务质量和资源约束的协商。

Result: AdaptiveResolver促进了灵活、安全、可扩展的智能体间交互，这些交互超越了经典的客户端-服务器模型。

Conclusion: AdaptiveResolver为稳健、面向未来的智能体通信奠定了基础，使其能够随着生态系统复杂性的增加而不断发展和适应。

Abstract: AdaptiveResolver is a dynamic microservice architecture designed to address
the limitations of static endpoint resolution for AI agent communication in
distributed, heterogeneous environments. Unlike traditional DNS or static URLs,
AdaptiveResolver enables context-aware, real-time selection of communication
endpoints based on factors such as geographic location, system load, agent
capabilities, and security threats. Agents advertise their Agent Name and
context requirements through Agent Fact cards in an Agent Registry/Index. A
requesting Agent discovers a Target Agent using the registry. The Requester
Agent can then resolve the Target Agent Name to obtain a tailored communication
channel to the agent based on actual environmental context between the agents.
The architecture supports negotiation of trust, quality of service, and
resource constraints, facilitating flexible, secure, and scalable
agent-to-agent interactions that go beyond the classic client-server model.
AdaptiveResolver provides a foundation for robust, future-proof agent
communication that can evolve with increasing ecosystem complexity.

</details>


### [234] [Scalability and Performance Evaluation of IEEE 802.11ah IoT Deployments: A Testbed Approach](https://arxiv.org/abs/2508.03146)
*Kostas Chounos,Katerina Kyriakou,Thanasis Korakis*

Main category: cs.NI

TL;DR: 本文构建并评估了IEEE 802.11ah（WiFi Halow）办公测试平台，以研究实际物联网网络中的性能和可扩展性，揭示了网络争用和邻道干扰导致的吞吐量显著下降问题，并分析了能耗。


<details>
  <summary>Details</summary>
Motivation: 分析日益增长的数据需求及其对现代无线物联网架构的影响，特别是针对新兴的5G及未来应用；揭示IEEE 802.11ah网络在复杂现实场景中的实际性能和可扩展性限制，因为这是首次针对此类复杂现实部署的研究。

Method: 构建了一个IEEE 802.11ah（WiFi Halow）办公测试平台进行实地实验；利用该部署在各种挑战性场景下揭示实际性能和可扩展性限制；同时分析了测试设备的能耗。

Result: 研究发现，强烈的网络争用和邻道干扰（ACI）严重影响无线链路性能，导致密集部署的无线链路吞吐量显著下降。

Conclusion: 有效揭示这些意外现象有助于在物联网到云的整个连续体中制定更完善的决策并优化能耗。

Abstract: This work focuses on the development and assessment of modern wireless
Internet of Things (IoT) architectures, with relevance to emerging 5G and
beyond applications. To analyze the growing demands for data, and their impact,
we built an IEEE 802.11ah (WiFi Halow) office testbed for real-world
experimentation. This deployment allows us to uncover the practical performance
and scalability limitations of such networks under various challenging
scenarios. To the best of our knowledge, this is the first study to consider
complex real-world IEEE 802.11ah implementations, aiming specifically to reveal
unexpected performance behaviors, such as significant throughput degradation
arising in closely deployed wireless links. Our findings show that intense
network contention and Adjacent Channel Interference (ACI), drastically impact
the performance of the wireless links involved. Beyond evaluating network
performance, our experimental analysis also considers the energy consumption of
the devices under test, offering a more holistic perspective on the feasibility
of IEEE 802.11ah in real-world deployments. The effective disclosure of such
unexpected phenomena, can lead to well planned decisions and energy consumption
optimization across the IoT to Cloud continuum.

</details>


### [235] [Energy-efficient Federated Learning for UAV Communications](https://arxiv.org/abs/2508.03171)
*Chien-Wei Fu,Meng-Lin Ku*

Main category: cs.NI

TL;DR: 提出了一种无人机辅助联邦学习框架，通过联合优化多参数来最小化系统能耗，并设计了ECO算法。


<details>
  <summary>Details</summary>
Motivation: 在无人机辅助联邦学习中，通过联合优化无人机轨迹、用户参与、功率分配和数据量，以最小化系统总能耗。

Method: 提出了一个联合优化框架，涉及无人机轨迹、用户参与、功率分配和数据量控制。首先推导了多局部更新下FL模型的收敛精度。针对非凸优化问题，采用交替优化（AO）和逐次凸逼近（SCA）技术，设计了迭代能耗优化（ECO）算法。

Result: 仿真结果表明，所提出的ECO算法持续优于现有基线方案。

Conclusion: 所提出的无人机辅助联邦学习框架及其ECO算法能有效降低系统总能耗。

Abstract: In this paper, we propose an unmanned aerial vehicle (UAV)-assisted federated
learning (FL) framework that jointly optimizes UAV trajectory, user
participation, power allocation, and data volume control to minimize overall
system energy consumption. We begin by deriving the convergence accuracy of the
FL model under multiple local updates, enabling a theoretical understanding of
how user participation and data volume affect FL learning performance. The
resulting joint optimization problem is non-convex; to address this, we employ
alternating optimization (AO) and successive convex approximation (SCA)
techniques to convexify the non-convex constraints, leading to the design of an
iterative energy consumption optimization (ECO) algorithm. Simulation results
confirm that ECO consistently outperform existing baseline schemes.

</details>


### [236] [Directives for Function Offloading in 5G Networks Based on a Performance Characteristics Analysis](https://arxiv.org/abs/2508.03287)
*Falk Dettinger,Matthias Weiß,Daniel Baumann,Martin Sommer,Michael Weyrich*

Main category: cs.NI

TL;DR: 本研究在真实环境中评估了5G非独立组网在车辆AI算法云端卸载中的性能，发现连接稳定、错误率低，并指出了传输和处理时间的影响因素，提出云端卸载在往返时间超过150毫秒时更适用。


<details>
  <summary>Details</summary>
Motivation: 尽管5G低延迟、高带宽特性支持车云集成，但目前只有非独立组网（NSA 5G）可用。与理论研究相比，5G非独立组网在车辆功能云端执行方面的实际应用和性能（如延迟、往返时间、数据包传输）仍缺乏深入的实地探索。

Method: 本研究评估了5G非独立组网在车辆功能云端执行中的延迟、往返时间（RTT）和数据包传输。测试使用了两种AI算法（情感识别和目标识别），在德国巴登-符腾堡州一条8.8公里的城市、乡村和森林混合路线上进行。分析平台包括法兰克福的边缘云（cloudlet）和曼海姆的云端（cloud），并采用了多种部署策略，包括传统应用、容器化和容器编排。

Result: 平均信号质量达到84%，尽管在建成区有轻微下降，但未出现连接中断。两种AI算法的数据包错误率（PER）均低于0.1%。传输时间受地理位置和后端服务器网络连接显著影响，而处理时间主要取决于所使用的计算硬件。此外，研究发现云端卸载仅在往返时间（RTT）可能超过150毫秒时才是一个合适的选择。

Conclusion: 5G非独立组网在车辆功能云端卸载中表现出良好的连接稳定性和低数据包错误率。传输和处理性能受到地理位置、网络连接和计算硬件的综合影响。研究结论是，当往返时间（RTT）超过150毫秒时，云端卸载才是一个可行的选项，这为未来车辆AI应用部署提供了实证参考。

Abstract: Cloud-based offloading helps address energy consumption and performance
challenges in executing resource-intensive vehicle algorithms. Utilizing 5G,
with its low latency and high bandwidth, enables seamless vehicle-to-cloud
integration. Currently, only non-standalone 5G is publicly available, and
real-world applications remain underexplored compared to theoretical studies.
This paper evaluates 5G non-standalone networks for cloud execution of vehicle
functions, focusing on latency, Round Trip Time, and packet delivery. Tests
used two AI-based algorithms -- emotion recognition and object recognition --
along an 8.8 km route in Baden-W\"urttemberg, Germany, encompassing urban,
rural, and forested areas. Two platforms were analyzed: a cloudlet in Frankfurt
and a cloud in Mannheim, employing various deployment strategies like
conventional applications and containerized and container-orchestrated setups.
Key findings highlight an average signal quality of 84 %, with no connectivity
interruptions despite minor drops in built-up areas. Packet analysis revealed a
Packet Error Rate below 0.1 % for both algorithms. Transfer times varied
significantly depending on the geographical location and the backend servers'
network connections, while processing times were mainly influenced by the
computation hardware in use. Additionally, cloud offloading seems only be a
suitable option, when a round trip time of more than 150 ms is possible.

</details>


### [237] [Bidirectional TLS Handshake Caching for Constrained Industrial IoT Scenarios](https://arxiv.org/abs/2508.03321)
*Jörn Bodenhausen,Simon Mangel,Thomas Vogt,Martin Henze*

Main category: cs.NI

TL;DR: 针对TLS在资源受限的工业物联网中握手开销大的问题，本文提出BiTHaC方案，通过双向缓存TLS握手中的静态部分（如证书），显著降低了带宽和计算开销，同时保持了TLS的安全保障。


<details>
  <summary>Details</summary>
Motivation: TLS虽是端到端安全的标准，但在资源受限的工业物联网（IIoT）场景中，其应用受到设备和网络资源限制。特别是TLS握手过程会产生显著的带宽和处理开销，这在受限环境中难以承受。

Method: 本文提出BiTHaC（双向TLS握手缓存）方案。该方法利用TLS重复握手（尤其是证书）中存在的静态部分，避免重复传输冗余信息和执行重复计算，从而节省宝贵的带宽和处理资源。

Result: 通过在wolfSSL上实现BiTHaC，实验表明TLS握手带宽消耗最高可减少61.1%，计算开销最高可减少8.5%。同时，仅产生可管理的内存开销，并保持了TLS严格的安全保障。

Conclusion: BiTHaC通过优化TLS握手过程，成功解决了其在资源受限工业物联网环境中的性能瓶颈，显著降低了资源消耗，且不牺牲安全性，为关键通信提供了更高效的加密保护。

Abstract: While TLS has become the de-facto standard for end-to-end security, its use
to secure critical communication in evolving industrial IoT scenarios is
severely limited by prevalent resource constraints of devices and networks.
Most notably, the TLS handshake to establish secure connections incurs
significant bandwidth and processing overhead that often cannot be handled in
constrained environments. To alleviate this situation, we present BiTHaC which
realizes bidirectional TLS handshake caching by exploiting that significant
parts of repeated TLS handshakes, especially certificates, are static. Thus,
redundant information neither needs to be transmitted nor corresponding
computations performed, saving valuable bandwidth and processing resources. By
implementing BiTHaC for wolfSSL, we show that we can reduce the bandwidth
consumption of TLS handshakes by up to 61.1% and the computational overhead by
up to 8.5%, while incurring only well-manageable memory overhead and preserving
the strict security guarantees of TLS.

</details>


### [238] [Morphlux: Programmable chip-to-chip photonic fabrics in multi-accelerator servers for ML](https://arxiv.org/abs/2508.03674)
*Abhishek Vijaya Kumar,Eric Ding,Arjun Devraj,Rachee Singh*

Main category: cs.NI

TL;DR: 该研究开发了一种名为Morphlux的服务器级可编程光子互连结构，用以在计算服务器内光学互连加速器芯片，旨在解决现有电互连带来的带宽瓶颈，从而提高机器学习训练吞吐量和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 当前商业多加速器计算服务器依赖电互连，但加速器浮点运算能力（FLOPS）的增长速度快于片间互连带宽的增长，导致“互连带宽墙”，造成云数据中心中GPU资源利用率低下和闲置。

Method: 开发并实现了一个名为Morphlux的服务器级可编程光子互连结构，用于服务器内加速器芯片的光学互连。构建了Morphlux的端到端硬件原型以验证其性能优势。

Result: 将Morphlux应用于最先进的ML数据中心，可将租户计算分配的带宽提高达66%，计算碎片化降低达70%。这转化为ML模型训练吞吐量提高1.72倍。此外，通过快速编程，Morphlux能在1.2秒内逻辑替换发生故障的加速器芯片。

Conclusion: Morphlux作为一种服务器级可编程光子互连方案，有效解决了多加速器服务器中的带宽瓶颈问题，显著提升了机器学习模型的训练性能和资源利用效率，并提供了快速的故障恢复能力。

Abstract: We optically interconnect accelerator chips (e.g., GPUs, TPUs) within compute
servers using newly viable programmable chip-to-chip photonic fabrics. In
contrast, today, commercial multi-accelerator compute servers that are
workhorses of ML, use electrical interconnects to network accelerator chips in
the server. However, recent trends have shown an interconnect bandwidth wall
caused by accelerator FLOPS scaling at a faster rate than the bandwidth of the
interconnect between accelerators in the same server. This has led to
under-utilization and idling of GPU resources in cloud datacenters. We develop
Morphlux, a server-scale programmable photonic fabric, to interconnect
accelerators within servers. We show that augmenting state-of-the-art photonic
ML-centric datacenters with Morphlux can improve the bandwidth of tenant
compute allocations by up to 66% and reduce compute fragmentation by up to 70%.
We develop a novel end-to-end hardware prototype of Morphlux to demonstrate
these performance benefits, which translate to 1.72x improvement in training
throughput of ML models. By rapidly programming the server-scale fabric in our
hardware testbed, Morphlux can logically replace a failed accelerator chip in
1.2 seconds.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [239] [What If, But Privately: Private Counterfactual Retrieval](https://arxiv.org/abs/2508.03681)
*Shreya Meel,Mohamed Nomeir,Pasan Dissanayake,Sanghamitra Dutta,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文提出一种在不泄露用户特征向量给机构的前提下，安全检索反事实解释的框架，并探讨了不可变特征和用户偏好等场景下的隐私保护方案。


<details>
  <summary>Details</summary>
Motivation: 在敏感应用中使用黑箱机器学习模型时，提供反事实解释可能导致机构和用户的隐私泄露。本研究主要关注用户如何在不泄露自身特征向量给机构的情况下，安全地获取反事实解释，以保护用户隐私。

Method: 1. 引入并提出私有反事实检索（PCR）问题，设计了一个基线PCR方案，确保用户特征向量的信息理论隐私。在此基础上，提出另外两种方案以减少数据库信息泄露。2. 放松了特征可变性假设，提出不可变PCR（I-PCR）设置，用户可在不改变私有不可变特征子集的情况下检索反事实，并提出了两种保护用户隐私和不同程度数据库隐私的方案。3. 扩展PCR和I-PCR方案以结合用户对属性转换的偏好，以提供更具可操作性的解释。

Result: 所提出的框架能够在确保用户完美信息理论隐私的前提下，从数据库中检索到精确的最近邻反事实解释。数值结果支持了理论发现，并对不同方案的数据库泄露程度进行了比较。

Conclusion: 本研究成功解决了反事实解释中的用户隐私问题，通过提出的PCR和I-PCR方案，用户可以在不泄露敏感特征信息的情况下获取有用的反事实解释，同时兼顾了不可变特征和用户偏好，为隐私保护下的模型可解释性提供了有效方法。

Abstract: Transparency and explainability are two important aspects to be considered
when employing black-box machine learning models in high-stake applications.
Providing counterfactual explanations is one way of catering this requirement.
However, this also poses a threat to the privacy of the institution that is
providing the explanation, as well as the user who is requesting it. In this
work, we are primarily concerned with the user's privacy who wants to retrieve
a counterfactual instance, without revealing their feature vector to the
institution. Our framework retrieves the exact nearest neighbor counterfactual
explanation from a database of accepted points while achieving perfect,
information-theoretic, privacy for the user. First, we introduce the problem of
private counterfactual retrieval (PCR) and propose a baseline PCR scheme that
keeps the user's feature vector information-theoretically private from the
institution. Building on this, we propose two other schemes that reduce the
amount of information leaked about the institution database to the user,
compared to the baseline scheme. Second, we relax the assumption of mutability
of all features, and consider the setting of immutable PCR (I-PCR). Here, the
user retrieves the nearest counterfactual without altering a private subset of
their features, which constitutes the immutable set, while keeping their
feature vector and immutable set private from the institution. For this, we
propose two schemes that preserve the user's privacy information-theoretically,
but ensure varying degrees of database privacy. Third, we extend our PCR and
I-PCR schemes to incorporate user's preference on transforming their
attributes, so that a more actionable explanation can be received. Finally, we
present numerical results to support our theoretical findings, and compare the
database leakage of the proposed schemes.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [240] [SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec](https://arxiv.org/abs/2508.02849)
*Chunyu Qiang,Haoyu Wang,Cheng Gong,Tianrui Wang,Ruibo Fu,Tao Wang,Ruilong Chen,Jiangyan Yi,Zhengqi Wen,Chen Zhang,Longbiao Wang,Jianwu Dang,Jianhua Tao*

Main category: eess.AS

TL;DR: SecoustiCodec是一种创新的低码率流式语音编解码器，能够有效解耦语音中的语义和非语言信息，并在极低码率下实现最先进的语音重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码器在语义编码方面存在诸多挑战，包括：残留非语言信息（如音色、情感）、语义完整性不足、重建能力受限以及缺乏对流式传输的支持。

Method: 本文提出SecoustiCodec，它在单一码本空间中解耦语义和非语言信息。核心方法包括：引入非语言编码以弥合信息鸿沟；基于VAE和FSQ提出高效的语义量化方法，以优化词元分布和码本利用率；基于对比学习实现语义解耦，在多模态帧级空间对齐文本和语音，从而去除非语言信息；采用声学约束的多阶段优化策略以确保稳定收敛。

Result: SecoustiCodec在0.27/1 kbps的码率下，实现了1.77/2.58的SOTA（最先进）PESQ语音重建质量。

Conclusion: SecoustiCodec通过其创新的信息解耦、高效量化和跨模态对齐策略，成功解决了现有语音编解码器在低码率流式传输中的核心挑战，实现了卓越的语义编码和语音重建性能。

Abstract: Speech codecs serve as a crucial bridge in unifying speech and text language
models. Existing codec methods face several challenges in semantic encoding,
such as residual paralinguistic information (e.g., timbre, emotion),
insufficient semantic completeness, limited reconstruction capability, and lack
of support for streaming. To address these challenges, we propose
SecoustiCodec, a cross-modal aligned low-bitrate streaming speech codec that
disentangles semantic and paralinguistic information in a single-codebook
space. To ensure semantic completeness and reconstruction fidelity,
paralinguistic encoding is introduced to bridge the information gap between
semantic and acoustic encoding. A semantic-only efficient quantization method
based on VAE (Variational Autoencoder) and FSQ (Finite Scalar Quantization) is
proposed. This approach alleviates the long-tail distribution problem of tokens
while maintaining high codebook utilization. A semantic disentanglement method
based on contrastive learning is proposed, which aligns text and speech in a
joint multimodal frame-level space, effectively removing paralinguistic
information from semantic encoding. An acoustic-constrained multi-stage
optimization strategy is proposed to ensure robust and stable convergence.
Figure~\ref{fig:pesq_kbps_below_2kbps} shows SecoustiCodec achieves SOTA
(state-of-the-art) reconstruction quality (PESQ) of 1.77/2.58 at 0.27/1 kbps.
The code and model weights for SecoustiCodec will be open-sourced upon the
completion of the peer-review process. We've open-sourced SecoustiCodec's demo,
code, and model weights.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [241] [Reliable Evaluation Protocol for Low-Precision Retrieval](https://arxiv.org/abs/2508.03306)
*Kisu Yang,Yoonna Jang,Hwanseok Jang,Kenneth Choi,Isabelle Augenstein,Heuiseok Lim*

Main category: cs.IR

TL;DR: 针对低精度检索系统中因分数平局导致的评估不可靠问题，本文提出了一种包含高精度评分（HPS）和平局感知检索指标（TRM）的新型评估协议，以提高评估的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 在低精度检索系统中，计算查询与文档相关性分数时，精度降低会导致虚假平局，这使得评估结果的变异性高且不可靠。

Method: 提出一个更鲁棒的检索评估协议，包括：1) 高精度评分（HPS），通过提升最终评分步骤的精度来解决平局，且计算成本极低；2) 平局感知检索指标（TRM），报告预期分数、范围和偏差，以量化平局候选者的排序不确定性。

Result: 实验证明，HPS 显著降低了由平局引起的不稳定性，并且 TRM 能够准确恢复预期的度量值。

Conclusion: HPS 和 TRM 的结合为低精度检索提供了一个更一致、更可靠的评估系统。

Abstract: Lowering the numerical precision of model parameters and computations is
widely adopted to improve the efficiency of retrieval systems. However, when
computing relevance scores between the query and documents in low-precision, we
observe spurious ties due to the reduced granularity. This introduces high
variability in the results based on tie resolution, making the evaluation less
reliable. To address this, we propose a more robust retrieval evaluation
protocol designed to reduce score variation. It consists of: (1) High-Precision
Scoring (HPS), which upcasts the final scoring step to higher precision to
resolve tied candidates with minimal computational cost; and (2) Tie-aware
Retrieval Metrics (TRM), which report expected scores, range, and bias to
quantify order uncertainty of tied candidates. Our experiments test multiple
models with three scoring functions on two retrieval datasets to demonstrate
that HPS dramatically reduces tie-induced instability, and TRM accurately
recovers expected metric values. This combination enables a more consistent and
reliable evaluation system for lower-precision retrievals.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [242] [Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks](https://arxiv.org/abs/2508.02856)
*Seyed Bagher Hashemi Natanzi,Hossein Mohammadi,Bo Tang,Vuk Marojevic*

Main category: eess.SP

TL;DR: 针对毫米波通信系统中高级波束窃取攻击，本文提出一种基于深度强化学习（DRL）和集成感知与通信（ISAC）的框架，实现主动自适应防御，并在检测率和通信性能上表现出色。


<details>
  <summary>Details</summary>
Motivation: 毫米波（mmWave）通信系统面临日益增加的高级波束窃取攻击威胁，对物理层安全构成重大挑战。

Method: 引入一个新颖的框架，利用先进的深度强化学习（DRL）代理进行主动和自适应防御。核心创新是利用集成感知与通信（ISAC）能力进行主动、智能的威胁评估。DRL代理基于近端策略优化（PPO）算法构建，动态控制ISAC探测行为。引入了密集的课程学习策略，以克服探索挑战并确保代理在训练中成功检测。

Result: 数值结果表明，该框架实现了92.8%的平均攻击者检测率，同时保持了超过13 dB的平均用户信噪比（SINR）。

Conclusion: 该框架学习到一种鲁棒且自适应的策略，能够智能地平衡安全性和通信性能，有效应对高级波束窃取攻击。

Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility
to advanced beam-stealing attacks, posing a significant physical layer security
threat. This paper introduces a novel framework employing an advanced Deep
Reinforcement Learning (DRL) agent for proactive and adaptive defense against
these sophisticated attacks. A key innovation is leveraging Integrated Sensing
and Communications (ISAC) capabilities for active, intelligent threat
assessment. The DRL agent, built on a Proximal Policy Optimization (PPO)
algorithm, dynamically controls ISAC probing actions to investigate suspicious
activities. We introduce an intensive curriculum learning strategy that
guarantees the agent experiences successful detection during training to
overcome the complex exploration challenges inherent to such a
security-critical task. Consequently, the agent learns a robust and adaptive
policy that intelligently balances security and communication performance.
Numerical results demonstrate that our framework achieves a mean attacker
detection rate of 92.8% while maintaining an average user SINR of over 13 dB.

</details>


### [243] [Decoding and Engineering the Phytobiome Communication for Smart Agriculture](https://arxiv.org/abs/2508.03584)
*Fatih Gulec,Hamdan Awan,Nigel Wallbridge,Andrew W. Eckford*

Main category: eess.SP

TL;DR: 本文提出将通信工程（特别是分子通信）应用于理解植物生物群落的内部通信，并概念化其为通信网络，以此为基础提出创新的智能农业应用，旨在实现高效可持续的农业生产。


<details>
  <summary>Details</summary>
Motivation: 为应对粮食需求增长、环境污染和水资源短缺等现代农业挑战，研究旨在运用通信工程视角，全面理解植物生物群落（phytobiome）的通信机制，并将其与智能农业相结合。

Method: 首先，概述了通过分子和电生理信号进行的植物生物群落通信，并提出了一个将植物生物群落建模为通信网络的多尺度框架。接着，通过植物实验演示了该框架如何用于建模电生理信号。此外，还提出了通过工程化植物生物群落通信（结合机器学习/人工智能和生物纳米物联）实现智能灌溉、农用化学品靶向投送等智能农业应用的设想。

Result: 成功概念化并初步演示了一个将植物生物群落建模为通信网络的多尺度框架，并验证了其在模拟电生理信号方面的可行性。提出了基于工程化植物生物群落通信的智能农业应用，这些应用有望推动实现更高效、可持续和环保的农业生产。

Conclusion: 通过将通信工程特别是分子通信理论应用于植物生物群落研究，本文为发展先进的智能农业应用奠定了基础，有望显著提升农业生产的效率、可持续性和环境友好性。文章还探讨了这些应用面临的实施挑战、开放研究问题及工业前景。

Abstract: Smart agriculture applications, integrating technologies like the Internet of
Things and machine learning/artificial intelligence (ML/AI) into agriculture,
hold promise to address modern challenges of rising food demand, environmental
pollution, and water scarcity. Alongside the concept of the phytobiome, which
defines the area including the plant, its environment, and associated
organisms, and the recent emergence of molecular communication (MC), there
exists an important opportunity to advance agricultural science and practice
using communication theory. In this article, we motivate to use the
communication engineering perspective for developing a holistic understanding
of the phytobiome communication and bridge the gap between the phytobiome
communication and smart agriculture. Firstly, an overview of phytobiome
communication via molecular and electrophysiological signals is presented and a
multi-scale framework modeling the phytobiome as a communication network is
conceptualized. Then, how this framework is used to model electrophysiological
signals is demonstrated with plant experiments. Furthermore, possible smart
agriculture applications, such as smart irrigation and targeted delivery of
agrochemicals, through engineering the phytobiome communication are proposed.
These applications merge ML/AI methods with the Internet of Bio-Nano-Things
enabled by MC and pave the way towards more efficient, sustainable, and
eco-friendly agricultural production. Finally, the implementation challenges,
open research issues, and industrial outlook for these applications are
discussed.

</details>


### [244] [Evaluation of Deep Learning Models for LBBB Classification in ECG Signals](https://arxiv.org/abs/2508.02710)
*Beatriz Macas Ordóñez,Diego Vinicio Orellana Villavicencio,José Manuel Ferrández,Paula Bonomini*

Main category: eess.SP

TL;DR: 本研究探索不同的神经网络架构，以从心电图（ECG）信号中提取时空模式，并将其分为健康、左束支传导阻滞（LBBB）和严格左束支传导阻滞（sLBBB）三类。


<details>
  <summary>Details</summary>
Motivation: 优化左束支传导阻滞（LBBB）患者的分类，以利用创新技术选择心脏再同步治疗（CRT）的合适候选者，从而提高临床相关性。

Method: 探索并使用不同的神经网络架构来提取心电图（ECG）信号的时空模式，并进行分类。

Result: 抽象中未提及具体研究结果。

Conclusion: 抽象中未提及具体研究结论。

Abstract: This study explores different neural network architectures to evaluate their
ability to extract spatial and temporal patterns from electrocardiographic
(ECG) signals and classify them into three groups: healthy subjects, Left
Bundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB).
  Clinical Relevance, Innovative technologies enable the selection of
candidates for Cardiac Resynchronization Therapy (CRT) by optimizing the
classification of subjects with Left Bundle Branch Block (LBBB).

</details>


### [245] [SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG](https://arxiv.org/abs/2508.02718)
*Zahra Mohammadi,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 本文提出并评估了SleepLiteCNN，一种基于单导联心电图（ECG）的节能型卷积神经网络，用于可穿戴设备高精度实时检测睡眠呼吸暂停亚型。


<details>
  <summary>Details</summary>
Motivation: 准确、高时间分辨率地检测睡眠呼吸暂停（包括阻塞性、中枢性、混合性）的亚型对有效治疗至关重要，且需满足可穿戴设备的实时和能效需求。

Method: 研究评估了多种机器学习和深度学习算法，基于1秒心电图窗口进行睡眠呼吸暂停亚型分类。最终，提出SleepLiteCNN，一个为可穿戴平台设计的紧凑型节能卷积神经网络，并通过8位量化和FPGA综合进行评估。

Result: SleepLiteCNN实现了超过95%的准确率和92%的macro-F1分数，每次推理仅需1.8微焦耳（8位量化后）。FPGA综合显示硬件资源占用显著减少，证实其适用于能源受限环境的持续实时监测。

Conclusion: SleepLiteCNN是一种实用且有效的解决方案，适用于可穿戴设备上的睡眠呼吸暂停亚型检测。

Abstract: Apnea is a common sleep disorder characterized by breathing interruptions
lasting at least ten seconds and occurring more than five times per hour.
Accurate, high-temporal-resolution detection of sleep apnea subtypes -
Obstructive, Central, and Mixed - is crucial for effective treatment and
management. This paper presents an energy-efficient method for classifying
these subtypes using a single-lead electrocardiogram (ECG) with high temporal
resolution to address the real-time needs of wearable devices. We evaluate a
wide range of classical machine learning algorithms and deep learning
architectures on 1-second ECG windows, comparing their accuracy, complexity,
and energy consumption. Based on this analysis, we introduce SleepLiteCNN, a
compact and energy-efficient convolutional neural network specifically designed
for wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92%
macro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit
quantization. Field Programmable Gate Array (FPGA) synthesis further
demonstrates significant reductions in hardware resource usage, confirming its
suitability for continuous, real-time monitoring in energy-constrained
environments. These results establish SleepLiteCNN as a practical and effective
solution for wearable device sleep apnea subtype detection.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [246] [NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification](https://arxiv.org/abs/2508.02823)
*Wenshuo Zhang,Leixian Shen,Shuchang Xu,Jindu Wang,Jian Zhao,Huamin Qu,Linping Yuan*

Main category: cs.HC

TL;DR: 针对对话式LLM在代码生成中用户意图与生成代码不匹配的问题，本文提出并实现了“直接意图-任务匹配”这一新的人机交互范式（NeuroSync），通过可视化外部化LLM的理解并允许用户直接操纵，以提高对齐度、降低认知负荷并提升编码效率。


<details>
  <summary>Details</summary>
Motivation: 对话式大型语言模型（LLMs）已被非编程专业领域用户广泛采用解决问题，但他们常面临其意图与LLM生成代码之间的不匹配问题，这导致用户沮丧并需要反复澄清。本研究发现其根本原因在于双向歧义：用户意图和编码任务本质上都是非线性的，但却必须通过线性的提示和代码序列进行表达和解释。

Method: 本文提出了一种名为“直接意图-任务匹配”的新型人机交互范式，该范式旨在将LLM在代码生成前对编码任务及其关系的理解外部化，并允许用户直接操纵这些理解。作为概念验证，该范式被实现在NeuroSync系统中。NeuroSync采用知识蒸馏管线来提取LLM的理解、用户意图及其映射，并通过可视化方式使用户能够直观地检查和编辑它们，从而增强意图与任务的对齐。

Result: 通过技术实验评估了NeuroSync的算法组件，并通过一项用户研究（N=12）评估了其整体可用性和有效性。结果表明，NeuroSync显著增强了用户意图与代码任务的对齐度，降低了用户的认知负荷，并提高了编码效率。

Conclusion: 本研究揭示了对话式LLM在代码生成过程中意图与代码不匹配的根本原因，并成功地通过提出的“直接意图-任务匹配”范式及其实现系统NeuroSync解决了这一问题。这证明了通过外部化并允许用户干预LLM的内部理解，可以显著提升人机协作的效率和用户体验。

Abstract: Conversational LLMs have been widely adopted by domain users with limited
programming experience to solve domain problems. However, these users often
face misalignment between their intent and generated code, resulting in
frustration and rounds of clarification. This work first investigates the cause
of this misalignment, which dues to bidirectional ambiguity: both user intents
and coding tasks are inherently nonlinear, yet must be expressed and
interpreted through linear prompts and code sequences. To address this, we
propose direct intent-task matching, a new human-LLM interaction paradigm that
externalizes and enables direct manipulation of the LLM understanding, i.e.,
the coding tasks and their relationships inferred by the LLM prior to code
generation. As a proof-of-concept, this paradigm is then implemented in
NeuroSync, which employs a knowledge distillation pipeline to extract LLM
understanding, user intents, and their mappings, and enhances the alignment by
allowing users to intuitively inspect and edit them via visualizations. We
evaluate the algorithmic components of NeuroSync via technical experiments, and
assess its overall usability and effectiveness via a user study (N=12). The
results show that it enhances intent-task alignment, lowers cognitive effort,
and improves coding efficiency.

</details>


### [247] [AnnoSense: A Framework for Physiological Emotion Data Collection in Everyday Settings for AI](https://arxiv.org/abs/2508.02680)
*Pragya Singh,Ankush Gupta,Mohan Kumar,Pushpendra Singh*

Main category: cs.HC

TL;DR: 本文探讨了在日常环境中为AI收集情绪数据的挑战，并基于多方利益相关者的见解，提出并评估了一个名为AnnoSense的框架，旨在改进情绪数据收集。


<details>
  <summary>Details</summary>
Motivation: 情绪和心理健康对生活质量至关重要。随着智能设备的普及，AI情绪监测潜力巨大，但高质量的真实世界情绪数据和准确的标注是关键。由于在现实环境中收集情绪数据以捕捉真实情感体验日益复杂，研究旨在理解和解决这一过程中的挑战。

Method: 研究方法包括：收集75份调查问卷回复，对32名公众进行访谈，以及与12名心理健康专业人员进行3次焦点小组讨论。综合来自119名利益相关者的见解，开发了AnnoSense框架。随后，由25位情绪AI专家对AnnoSense的清晰度、实用性和适应性进行了评估。

Result: 研究从119名利益相关者那里获得了关于日常情绪数据收集挑战的深入见解。基于这些见解，开发了AnnoSense框架，旨在支持AI的日常情绪数据收集。该框架经过情绪AI专家的评估，证实其在清晰度、实用性和适应性方面表现良好。

Conclusion: AnnoSense框架有望增强现实世界中情绪数据的收集和分析能力。这项工作为情绪AI的未来研究提供了潜在的方向和影响，强调了AnnoSense在改进真实情绪数据收集方面的潜力。

Abstract: Emotional and mental well-being are vital components of quality of life, and
with the rise of smart devices like smartphones, wearables, and artificial
intelligence (AI), new opportunities for monitoring emotions in everyday
settings have emerged. However, for AI algorithms to be effective, they require
high-quality data and accurate annotations. As the focus shifts towards
collecting emotion data in real-world environments to capture more authentic
emotional experiences, the process of gathering emotion annotations has become
increasingly complex. This work explores the challenges of everyday emotion
data collection from the perspectives of key stakeholders. We collected 75
survey responses, performed 32 interviews with the public, and 3 focus group
discussions (FGDs) with 12 mental health professionals. The insights gained
from a total of 119 stakeholders informed the development of our framework,
AnnoSense, designed to support everyday emotion data collection for AI. This
framework was then evaluated by 25 emotion AI experts for its clarity,
usefulness, and adaptability. Lastly, we discuss the potential next steps and
implications of AnnoSense for future research in emotion AI, highlighting its
potential to enhance the collection and analysis of emotion data in real-world
contexts.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [248] [Teaching at Scale: Leveraging AI to Evaluate and Elevate Engineering Education](https://arxiv.org/abs/2508.02731)
*Jean-Francois Chamberland,Martin C. Carlisle,Arul Jayaraman,Krishna R. Narayanan,Sunay Palsole,Karan Watson*

Main category: cs.CY

TL;DR: 本文提出一个可扩展的、AI支持的框架，利用大型语言模型分析学生定性反馈，以解决大规模大学教学效果评估的挑战。该框架已成功部署并验证，证明其能可靠支持形成性评估和教师专业发展。


<details>
  <summary>Details</summary>
Motivation: 大型大学（特别是工程学院）大规模评估教学效果面临持续挑战。传统的人工审查学生评价方法不切实际，导致洞察力被忽视和数据使用不一致。

Method: 该研究提出了一个AI支持的、基于大型语言模型（LLM）的框架，用于综合定性学生反馈。该系统采用分层摘要、匿名化和异常处理来提取可操作的主题，并通过可视化分析（基于百分位比较、历史趋势和教学负荷）来情境化数字分数。该方法整合了学生、同行和自我反思的输入，但不自动化人事决策。

Result: 该框架已成功部署于一所大型工程学院。初步验证结果（通过与人工评审员比较、教师反馈和纵向分析）表明，LLM生成的摘要能可靠地支持形成性评估和专业发展。

Conclusion: 本研究展示了AI系统，在透明和共享治理的设计下，如何在大规模学术机构中促进教学卓越和持续改进。

Abstract: Evaluating teaching effectiveness at scale remains a persistent challenge for
large universities, particularly within engineering programs that enroll tens
of thousands of students. Traditional methods, such as manual review of student
evaluations, are often impractical, leading to overlooked insights and
inconsistent data use. This article presents a scalable, AI-supported framework
for synthesizing qualitative student feedback using large language models. The
system employs hierarchical summarization, anonymization, and exception
handling to extract actionable themes from open-ended comments while upholding
ethical safeguards. Visual analytics contextualize numeric scores through
percentile-based comparisons, historical trends, and instructional load. The
approach supports meaningful evaluation and aligns with best practices in
qualitative analysis and educational assessment, incorporating student, peer,
and self-reflective inputs without automating personnel decisions. We report on
its successful deployment across a large college of engineering. Preliminary
validation through comparisons with human reviewers, faculty feedback, and
longitudinal analysis suggests that LLM-generated summaries can reliably
support formative evaluation and professional development. This work
demonstrates how AI systems, when designed with transparency and shared
governance, can promote teaching excellence and continuous improvement at scale
within academic institutions.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [249] [CreditARF: A Framework for Corporate Credit Rating with Annual Report and Financial Feature Integration](https://arxiv.org/abs/2508.02738)
*Yumeng Shi,Zhongliang Yang,DiYang Lu,Yisi Wang,Yiting Zhou,Linna Zhou*

Main category: q-fin.ST

TL;DR: 本研究提出一个整合财务数据和年报文本（通过FinBERT提取）的企业信用评级框架，并构建了包含两类数据的大型数据集CCRD，将评级准确率提高了8-12%。


<details>
  <summary>Details</summary>
Motivation: 现有企业信用评级模型主要依赖财务指标和深度学习，但常常忽略来自企业年报等非财务数据的洞察力。

Method: 引入了一个整合财务数据与使用FinBERT从年报中提取特征的企业信用评级框架。此外，开发了一个大型综合企业评级数据集（CCRD），该数据集结合了传统财务数据和年报中的文本数据。

Result: 所提出的方法将评级预测的准确性提高了8-12%。

Conclusion: 该研究显著提高了企业信用评级的有效性和可靠性，充分利用了非结构化文本数据的潜在价值。

Abstract: Corporate credit rating serves as a crucial intermediary service in the
market economy, playing a key role in maintaining economic order. Existing
credit rating models rely on financial metrics and deep learning. However, they
often overlook insights from non-financial data, such as corporate annual
reports. To address this, this paper introduces a corporate credit rating
framework that integrates financial data with features extracted from annual
reports using FinBERT, aiming to fully leverage the potential value of
unstructured text data. In addition, we have developed a large-scale dataset,
the Comprehensive Corporate Rating Dataset (CCRD), which combines both
traditional financial data and textual data from annual reports. The
experimental results show that the proposed method improves the accuracy of the
rating predictions by 8-12%, significantly improving the effectiveness and
reliability of corporate credit ratings.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [250] [ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs](https://arxiv.org/abs/2507.10593)
*Peng Ding*

Main category: cs.SE

TL;DR: Toolregistry是一个协议无关的工具管理库，旨在简化LLM的外部工具集成，显著减少开发代码、提高性能并增强可维护性。


<details>
  <summary>Details</summary>
Motivation: LLM应用日益依赖外部工具扩展能力，但现有工具集成方法存在碎片化、协议限制和实现复杂性，导致大量开发开销。

Method: 提出Toolregistry，一个协议无关的工具管理库，通过统一接口简化工具的注册、表示、执行和生命周期管理。

Result: Toolregistry将工具集成代码减少60-80%，通过并发执行将性能提升高达3.1倍，与OpenAI函数调用标准100%兼容。实际案例表明其显著提高了开发效率和代码可维护性。

Conclusion: Toolregistry有效解决了LLM工具集成的痛点，通过提供统一、高效、兼容的解决方案，大幅提升了开发效率和系统性能及可维护性。

Abstract: Large Language Model (LLM) applications are increasingly relying on external
tools to extend their capabilities beyond text generation. However, current
tool integration approaches suffer from fragmentation, protocol limitations,
and implementation complexity, leading to substantial development overhead.
This paper presents Toolregistry, a protocol-agnostic tool management library
that simplifies tool registration, representation, execution, and lifecycle
management via a unified interface. Our evaluation demonstrates that
\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x
performance improvements through concurrent execution, and 100% compatibility
with OpenAI function calling standards. Real-world case studies show
significant improvements in development efficiency and code maintainability
across diverse integration scenarios. \toolregistry is open-source and
available at https://github.com/Oaklight/ToolRegistry, with comprehensive
documentation at https://toolregistry.readthedocs.io/.

</details>


### [251] [Blueprint First, Model Second: A Framework for Deterministic LLM Workflow](https://arxiv.org/abs/2508.02721)
*Libin Qiu,Yuhang Ye,Zhirong Gao,Xide Zou,Junfu Chen,Ziming Gui,Weizhi Huang,Xiaobo Xue,Wenkai Qiu,Kun Zhao*

Main category: cs.SE

TL;DR: 本文提出Source Code Agent框架，通过将工作流逻辑与LLM解耦，实现LLM代理在结构化环境中的确定性执行，并在基准测试中显著提升性能和效率，达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理的固有非确定性限制了它们在需要严格程序保真度和可预测执行的结构化操作环境中的应用。这源于当前架构将概率性、高层规划与低层动作执行混为一谈。

Method: 引入“Source Code Agent”框架，遵循“蓝图优先，模型其次”（Blueprint First, Model Second）的理念。该框架将工作流逻辑与生成模型解耦。专家定义的规程首先被编码为基于源代码的“执行蓝图”，由确定性引擎执行。LLM仅作为专业工具被战略性地调用，处理工作流中有限、复杂的子任务，但从不决定工作流路径。

Result: 在面向复杂用户-工具-规则场景的tau-bench基准测试中，Source Code Agent达到了新的最先进水平，平均Pass^1分数比最强基线高出10.1个百分点，同时显著提高了执行效率。

Conclusion: 这项工作使得自主代理能够在受严格程序逻辑约束的应用中实现可验证和可靠的部署。

Abstract: While powerful, the inherent non-determinism of large language model (LLM)
agents limits their application in structured operational environments where
procedural fidelity and predictable execution are strict requirements. This
limitation stems from current architectures that conflate probabilistic,
high-level planning with low-level action execution within a single generative
process. To address this, we introduce the Source Code Agent framework, a new
paradigm built on the "Blueprint First, Model Second" philosophy. Our framework
decouples the workflow logic from the generative model. An expert-defined
operational procedure is first codified into a source code-based Execution
Blueprint, which is then executed by a deterministic engine. The LLM is
strategically invoked as a specialized tool to handle bounded, complex
sub-tasks within the workflow, but never to decide the workflow's path. We
conduct a comprehensive evaluation on the challenging tau-bench benchmark,
designed for complex user-tool-rule scenarios. Our results demonstrate that the
Source Code Agent establishes a new state-of-the-art, outperforming the
strongest baseline by 10.1 percentage points on the average Pass^1 score while
dramatically improving execution efficiency. Our work enables the verifiable
and reliable deployment of autonomous agents in applications governed by strict
procedural logic.

</details>
