{"id": "2504.17974", "pdf": "https://arxiv.org/pdf/2504.17974", "abs": "https://arxiv.org/abs/2504.17974", "authors": ["Sabur Butt", "Fazlourrahman Balouchzahi", "Ahmad Imam Amjad", "Maaz Amjad", "Hector G. Ceballos", "Salud Maria Jimenez-Zafra"], "title": "Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English", "categories": ["cs.CL"], "comment": null, "summary": "Hope is a complex and underexplored emotional state that plays a significant\nrole in education, mental health, and social interaction. Unlike basic\nemotions, hope manifests in nuanced forms ranging from grounded optimism to\nexaggerated wishfulness or sarcasm, making it difficult for Natural Language\nProcessing systems to detect accurately. This study introduces PolyHope V2, a\nmultilingual, fine-grained hope speech dataset comprising over 30,000 annotated\ntweets in English and Spanish. This resource distinguishes between four hope\nsubtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhances\nexisting datasets by explicitly labeling sarcastic instances. We benchmark\nmultiple pretrained transformer models and compare them with large language\nmodels (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.\nOur findings show that fine-tuned transformers outperform prompt-based LLMs,\nespecially in distinguishing nuanced hope categories and sarcasm. Through\nqualitative analysis and confusion matrices, we highlight systematic challenges\nin separating closely related hope subtypes. The dataset and results provide a\nrobust foundation for future emotion recognition tasks that demand greater\nsemantic and contextual sensitivity across languages.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86PolyHope V2\uff0c\u4e00\u4e2a\u591a\u8bed\u8a00\u3001\u7ec6\u7c92\u5ea6\u7684\u5e0c\u671b\u8a00\u8bed\u6570\u636e\u96c6\uff0c\u5e76\u53d1\u73b0\u5fae\u8c03\u7684Transformer\u6a21\u578b\u5728\u533a\u5206\u5e0c\u671b\u5b50\u7c7b\u578b\u548c\u8bbd\u523a\u65b9\u9762\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5e0c\u671b\u60c5\u7eea\u590d\u6742\u3001\u7814\u7a76\u4e0d\u8db3\u4f46\u91cd\u8981\uff0c\u5176\u7ec6\u5fae\u5f62\u5f0f\uff08\u5305\u62ec\u8bbd\u523a\uff09\u96be\u4ee5\u88ab\u73b0\u6709NLP\u7cfb\u7edf\u51c6\u786e\u68c0\u6d4b\uff0c\u7f3a\u4e4f\u533a\u5206\u8bbd\u523a\u7684\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3\u4e07\u591a\u6761\u82f1/\u897f\u8bed\u63a8\u6587\u7684\u591a\u8bed\u8a00\u7ec6\u7c92\u5ea6\u5e0c\u671b\u8a00\u8bed\u6570\u636e\u96c6PolyHope V2\uff08\u533a\u5206\u56db\u79cd\u7c7b\u578b\uff1a\u5e7f\u4e49\u3001\u73b0\u5b9e\u3001\u4e0d\u73b0\u5b9e\u3001\u8bbd\u523a\uff09\uff1b\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u5bf9\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u4e0eGPT-4\u3001Llama 3\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u57fa\u51c6\u6bd4\u8f83\uff1b\u8fdb\u884c\u4e86\u5b9a\u6027\u5206\u6790\u548c\u6df7\u6dc6\u77e9\u9635\u5206\u6790\u3002", "result": "\u5fae\u8c03\u7684Transformer\u6a21\u578b\u5728\u5e0c\u671b\u8a00\u8bed\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u533a\u5206\u7ec6\u5fae\u7684\u5e0c\u671b\u7c7b\u522b\u548c\u8bbd\u523a\u65b9\u9762\uff1b\u5206\u6790\u63ed\u793a\u4e86\u533a\u5206\u76f8\u5173\u5e0c\u671b\u5b50\u7c7b\u578b\u7684\u7cfb\u7edf\u6027\u6311\u6218\u3002", "conclusion": "PolyHope V2\u6570\u636e\u96c6\u548c\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u9700\u8981\u66f4\u9ad8\u8bed\u4e49\u548c\u8bed\u5883\u654f\u611f\u5ea6\u7684\u8de8\u8bed\u8a00\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2504.17993", "pdf": "https://arxiv.org/pdf/2504.17993", "abs": "https://arxiv.org/abs/2504.17993", "authors": ["Brihi Joshi", "Xiang Ren", "Swabha Swayamdipta", "Rik Koncel-Kedziorski", "Tim Paek"], "title": "Improving LLM Personas via Rationalization with Psychological Scaffolds", "categories": ["cs.CL"], "comment": null, "summary": "Language models prompted with a user description or persona can predict a\nuser's preferences and opinions, but existing approaches to building personas\n-- based solely on a user's demographic attributes and/or prior judgments --\nfail to capture the underlying reasoning behind said user judgments. We\nintroduce PB&J (Psychology of Behavior and Judgments), a framework that\nimproves LLM personas by incorporating rationales of why a user might make\nspecific judgments. These rationales are LLM-generated, and aim to reason about\na user's behavior on the basis of their experiences, personality traits or\nbeliefs. This is done using psychological scaffolds -- structured frameworks\ngrounded in theories such as the Big 5 Personality Traits and Primal World\nBeliefs -- that help provide structure to the generated rationales. Experiments\non public opinion and movie preference prediction tasks demonstrate that LLM\npersonas augmented with PB&J rationales consistently outperform methods using\nonly a user's demographics and/or judgments. Additionally, LLM personas\nconstructed using scaffolds describing user beliefs perform competitively with\nthose using human-written rationales.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51faPB&J\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u63a8\u7406\uff0c\u4ee5\u589e\u5f3a\u7528\u6237\u753b\u50cf\uff0c\u4ece\u800c\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u7528\u6237\u504f\u597d\u3002", "motivation": "\u73b0\u6709\u6784\u5efa\u7528\u6237\u753b\u50cf\u7684\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u7528\u6237\u7684\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u6216\u8fc7\u5f80\u5224\u65ad\uff0c\u672a\u80fd\u6355\u6349\u7528\u6237\u5224\u65ad\u80cc\u540e\u7684\u6df1\u5c42\u539f\u56e0\u3002", "method": "\u5f15\u5165PB&J\u6846\u67b6\uff1a\u4f7f\u7528LLM\u7ed3\u5408\u5fc3\u7406\u5b66\u652f\u67b6\uff08\u5982\u5927\u4e94\u4eba\u683c\u3001\u539f\u59cb\u4e16\u754c\u4fe1\u5ff5\u7b49\u7406\u8bba\uff09\u751f\u6210\u7528\u6237\u884c\u4e3a\uff08\u7ecf\u9a8c\u3001\u4e2a\u6027\u3001\u4fe1\u5ff5\uff09\u7684\u63a8\u7406\uff0c\u5e76\u5c06\u8fd9\u4e9b\u63a8\u7406\u6574\u5408\u8fdb\u7528\u6237\u753b\u50cf\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u516c\u5171\u89c2\u70b9\u548c\u7535\u5f71\u504f\u597d\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528PB&J\u63a8\u7406\u589e\u5f3a\u7684LLM\u7528\u6237\u753b\u50cf\u59cb\u7ec8\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u548c/\u6216\u7528\u6237\u5224\u65ad\u7684\u65b9\u6cd5\u3002\u57fa\u4e8e\u7528\u6237\u4fe1\u5ff5\u652f\u67b6\u6784\u5efa\u7684\u753b\u50cf\u6548\u679c\u4e0e\u4f7f\u7528\u4eba\u7c7b\u64b0\u5199\u63a8\u7406\u7684\u753b\u50cf\u76f8\u5f53\u3002", "conclusion": "\u5c06LLM\u751f\u6210\u4e14\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u63a8\u7406\uff08PB&J\uff09\u878d\u5165\u7528\u6237\u753b\u50cf\uff0c\u80fd\u663e\u8457\u63d0\u9ad8LLM\u9884\u6d4b\u7528\u6237\u504f\u597d\u7684\u80fd\u529b\u3002"}}
{"id": "2504.18012", "pdf": "https://arxiv.org/pdf/2504.18012", "abs": "https://arxiv.org/abs/2504.18012", "authors": ["Zhuang Yu", "Shiliang Sun", "Jing Zhao", "Tengfei Song", "Hao Yang"], "title": "Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal Machine Translation (MMT) aims to improve translation quality by\nleveraging auxiliary modalities such as images alongside textual input. While\nrecent advances in large-scale pre-trained language and vision models have\nsignificantly benefited unimodal natural language processing tasks, their\neffectiveness and role in MMT remain underexplored. In this work, we conduct a\nsystematic study on the impact of pre-trained encoders and decoders in\nmultimodal translation models. Specifically, we analyze how different training\nstrategies, from training from scratch to using pre-trained and partially\nfrozen components, affect translation performance under a unified MMT\nframework. Experiments are carried out on the Multi30K and CoMMuTE dataset\nacross English-German and English-French translation tasks. Our results reveal\nthat pre-training plays a crucial yet asymmetrical role in multimodal settings:\npre-trained decoders consistently yield more fluent and accurate outputs, while\npre-trained encoders show varied effects depending on the quality of\nvisual-text alignment. Furthermore, we provide insights into the interplay\nbetween modality fusion and pre-trained components, offering guidance for\nfuture architecture design in multimodal translation systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u5730\u63a2\u8ba8\u4e86\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5728\u591a\u6a21\u6001\u673a\u5668\u7ffb\u8bd1\uff08MMT\uff09\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u80fd\u7a33\u5b9a\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u800c\u7f16\u7801\u5668\u7684\u6548\u679c\u5219\u4f9d\u8d56\u4e8e\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5355\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b83\u4eec\u5728\u5229\u7528\u56fe\u50cf\u8f85\u52a9\u6587\u672c\u8fdb\u884c\u7ffb\u8bd1\u7684\u591a\u6a21\u6001\u673a\u5668\u7ffb\u8bd1\uff08MMT\uff09\u4e2d\u7684\u6709\u6548\u6027\u548c\u4f5c\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5728\u7edf\u4e00\u7684MMT\u6846\u67b6\u4e0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\uff08\u4ece\u96f6\u8bad\u7ec3\u3001\u4f7f\u7528\u9884\u8bad\u7ec3\u7ec4\u4ef6\u3001\u90e8\u5206\u51bb\u7ed3\u7ec4\u4ef6\uff09\u5bf9\u7ffb\u8bd1\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u5728Multi30K\u548cCoMMuTE\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\uff0c\u6db5\u76d6\u82f1\u5fb7\u548c\u82f1\u6cd5\u7ffb\u8bd1\u4efb\u52a1\u3002", "result": "\u9884\u8bad\u7ec3\u5728MMT\u4e2d\u626e\u6f14\u7740\u5173\u952e\u4f46\u4e0d\u5747\u8861\u7684\u89d2\u8272\uff1a\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u59cb\u7ec8\u80fd\u4ea7\u751f\u66f4\u6d41\u7545\u51c6\u786e\u7684\u8bd1\u6587\uff1b\u800c\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u7684\u6548\u679c\u5219\u56e0\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u7684\u8d28\u91cf\u800c\u5f02\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u9884\u8bad\u7ec3\u7ec4\u4ef6\u4e0e\u6a21\u6001\u878d\u5408\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u4e3a\u672a\u6765\u591a\u6a21\u6001\u7ffb\u8bd1\u7cfb\u7edf\u7684\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u662f\u63d0\u5347MMT\u6027\u80fd\u7684\u5173\u952e\u3002"}}
{"id": "2504.18041", "pdf": "https://arxiv.org/pdf/2504.18041", "abs": "https://arxiv.org/abs/2504.18041", "authors": ["Bang An", "Shiyue Zhang", "Mark Dredze"], "title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "NAACL 2025", "summary": "Efforts to ensure the safety of large language models (LLMs) include safety\nfine-tuning, evaluation, and red teaming. However, despite the widespread use\nof the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses\non standard LLMs, which means we know little about how RAG use cases change a\nmodel's safety profile. We conduct a detailed comparative analysis of RAG and\nnon-RAG frameworks with eleven LLMs. We find that RAG can make models less safe\nand change their safety profile. We explore the causes of this change and find\nthat even combinations of safe models with safe documents can cause unsafe\ngenerations. In addition, we evaluate some existing red teaming methods for RAG\nsettings and show that they are less effective than when used for non-RAG\nsettings. Our work highlights the need for safety research and red-teaming\nmethods specifically tailored for RAG LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u4f1a\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u5373\u4f7f\u662f\u5b89\u5168\u7684\u6a21\u578b\u548c\u6587\u6863\u7ec4\u5408\u4e5f\u53ef\u80fd\u4ea7\u751f\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u73b0\u6709\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5bf9RAG\u6548\u679c\u8f83\u5dee\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u73b0\u6709\u7684\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u6807\u51c6\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u5bf9RAG\u5982\u4f55\u6539\u53d8\u6a21\u578b\u5b89\u5168\u7279\u6027\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u901a\u8fc7\u5bf9\u5341\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884cRAG\u548c\u975eRAG\u6846\u67b6\u7684\u8be6\u7ec6\u6bd4\u8f83\u5206\u6790\uff0c\u63a2\u7a76RAG\u5bf9\u6a21\u578b\u5b89\u5168\u6027\u7684\u5f71\u54cd\u53ca\u5176\u539f\u56e0\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5728RAG\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0RAG\u4f1a\u4f7f\u6a21\u578b\u53d8\u5f97\u66f4\u4e0d\u5b89\u5168\u5e76\u6539\u53d8\u5176\u5b89\u5168\u7279\u6027\u3002\u5373\u4f7f\u662f\u5b89\u5168\u6a21\u578b\u4e0e\u5b89\u5168\u6587\u6863\u7684\u7ec4\u5408\u4e5f\u53ef\u80fd\u5bfc\u81f4\u4e0d\u5b89\u5168\u7684\u751f\u6210\u5185\u5bb9\u3002\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5728RAG\u573a\u666f\u4e0b\u7684\u6548\u679c\u4e0d\u5982\u5728\u975eRAG\u573a\u666f\u4e0b\u6709\u6548\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u9488\u5bf9RAG\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e13\u95e8\u7684\u5b89\u5168\u7814\u7a76\u548c\u5f00\u53d1\u7279\u5b9a\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2504.17795", "pdf": "https://arxiv.org/pdf/2504.17795", "abs": "https://arxiv.org/abs/2504.17795", "authors": ["Mohd Adnan"], "title": "Fuzzy Based Secure Clustering Schemes for Wireless Sensor Networks", "categories": ["cs.NI"], "comment": "Master's thesis", "summary": "This dissertation presents three independent novel approaches for distinct\nscenarios to solve one or more open challenges. The first concern explains the\nfocus on the lifetime of the networks: this dissertation will utilize a fuzzy\nlogic-based clustering protocol with multi-hop transmission for load balancing,\nenergy consumption minimization, and network lifetime prolongation. The\nprotocol forms unequal clusters with cluster head (CH) being selected by fuzzy\nlogic with competition radius. Node distance to the base station,\nconcentration, and residual energy are input variables. The second concern\nfocuses on network stability: we design a type 2 fuzzy logic-based clustering\nschemes in a multi-hop WSN to reduce energy consumption and improve network\nscalability. In this clustering scheme, we propose a cluster head (CH)\nselection strategy where a sensor node is elected as a CH based on type 2 fuzzy\nlogic inputs. To balance the load of CHs we also select their radius size based\non the fuzzy logic inputs. Finally, the third concern is focus on the utility\nof game theory in defensive Wireless Sensor Networks (WSN) from selfish nodes\nand malicious behavior. Game theory can effectively model WSNs malicious\nattacks because of their low complexity and scalability. The study, thus,\nexplores different WSN defense strategies from both external attackers and\ninternal nodes acting selfishly or maliciously using the game theory approach.\nAlso, the chapter highlights the general trust model for decision-making using\nthe game theory framework. Besides, the chapter demonstrates the significance\nof the theory in ensuring WSN security from acute attacks and its role in\nenhancing trustworthiness in data and cooperation of nodes in various WSN\narchitectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc (WSN) \u4e2d\u7684\u6311\u6218\uff1a\u4f7f\u7528\u6a21\u7cca\u903b\u8f91\u805a\u7c7b\u5ef6\u957f\u7f51\u7edc\u5bff\u547d\uff0c\u4f7f\u7528\u7c7b\u578b 2 \u6a21\u7cca\u903b\u8f91\u805a\u7c7b\u63d0\u9ad8\u7f51\u7edc\u7a33\u5b9a\u6027\uff0c\u4ee5\u53ca\u5229\u7528\u535a\u5f08\u8bba\u9632\u5fa1\u81ea\u79c1\u548c\u6076\u610f\u8282\u70b9\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\u3002", "motivation": "\u89e3\u51b3 WSN \u4e2d\u7684\u5f00\u653e\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u7f51\u7edc\u5bff\u547d\u6709\u9650\u3001\u7f51\u7edc\u7a33\u5b9a\u6027\u4e0d\u8db3\u4ee5\u53ca\u6613\u53d7\u81ea\u79c1\u8282\u70b9\u548c\u6076\u610f\u653b\u51fb\u5f71\u54cd\u7684\u95ee\u9898\u3002", "method": "1. \u9488\u5bf9\u7f51\u7edc\u5bff\u547d\uff1a\u91c7\u7528\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\uff08\u8f93\u5165\u53d8\u91cf\uff1a\u8282\u70b9\u5230\u57fa\u7ad9\u8ddd\u79bb\u3001\u96c6\u4e2d\u5ea6\u3001\u5269\u4f59\u80fd\u91cf\uff09\u548c\u7ade\u4e89\u534a\u5f84\u7684\u975e\u5747\u5300\u5206\u7c07\u534f\u8bae\u4e0e\u591a\u8df3\u4f20\u8f93\u3002 2. \u9488\u5bf9\u7f51\u7edc\u7a33\u5b9a\u6027\uff1a\u8bbe\u8ba1\u57fa\u4e8e\u7c7b\u578b 2 \u6a21\u7cca\u903b\u8f91\u8f93\u5165\u7684\u7c07\u5934 (CH) \u9009\u62e9\u7b56\u7565\u548c\u7c07\u534a\u5f84\u9009\u62e9\u65b9\u6848\u7684\u591a\u8df3 WSN \u805a\u7c7b\u673a\u5236\u3002 3. \u9488\u5bf9\u7f51\u7edc\u5b89\u5168\uff1a\u5e94\u7528\u535a\u5f08\u8bba\u65b9\u6cd5\u6765\u5efa\u6a21\u6076\u610f\u653b\u51fb\u3001\u63a2\u7d22\u9632\u5fa1\u7b56\u7565\uff08\u9488\u5bf9\u5916\u90e8\u653b\u51fb\u8005\u548c\u5185\u90e8\u6076\u610f/\u81ea\u79c1\u8282\u70b9\uff09\uff0c\u5e76\u5efa\u7acb\u4fe1\u4efb\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u7cca\u903b\u8f91\u65b9\u6cd5\u65e8\u5728\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u3001\u6700\u5c0f\u5316\u80fd\u8017\u3001\u5ef6\u957f\u7f51\u7edc\u5bff\u547d\u548c\u63d0\u9ad8\u7f51\u7edc\u53ef\u6269\u5c55\u6027\u3002\u535a\u5f08\u8bba\u65b9\u6cd5\u88ab\u7528\u6765\u6709\u6548\u5efa\u6a21\u653b\u51fb\u3001\u5236\u5b9a\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u786e\u4fdd WSN \u5b89\u5168\u3001\u589e\u5f3a\u6570\u636e\u53ef\u4fe1\u5ea6\u548c\u8282\u70b9\u534f\u4f5c\u65b9\u9762\u7684\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6a21\u7cca\u903b\u8f91\u805a\u7c7b\u548c\u535a\u5f08\u8bba\u8fd9\u4e24\u79cd\u4e0d\u540c\u7684\u6280\u672f\u9014\u5f84\uff0c\u5206\u522b\u9488\u5bf9\u6027\u5730\u89e3\u51b3\u4e86 WSN \u5728\u7f51\u7edc\u5bff\u547d\u3001\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4f18\u5316\u7f51\u7edc\u6027\u80fd\u548c\u9632\u5fa1\u6076\u610f\u884c\u4e3a\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2504.17974", "pdf": "https://arxiv.org/pdf/2504.17974", "abs": "https://arxiv.org/abs/2504.17974", "authors": ["Sabur Butt", "Fazlourrahman Balouchzahi", "Ahmad Imam Amjad", "Maaz Amjad", "Hector G. Ceballos", "Salud Maria Jimenez-Zafra"], "title": "Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English", "categories": ["cs.CL"], "comment": null, "summary": "Hope is a complex and underexplored emotional state that plays a significant\nrole in education, mental health, and social interaction. Unlike basic\nemotions, hope manifests in nuanced forms ranging from grounded optimism to\nexaggerated wishfulness or sarcasm, making it difficult for Natural Language\nProcessing systems to detect accurately. This study introduces PolyHope V2, a\nmultilingual, fine-grained hope speech dataset comprising over 30,000 annotated\ntweets in English and Spanish. This resource distinguishes between four hope\nsubtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhances\nexisting datasets by explicitly labeling sarcastic instances. We benchmark\nmultiple pretrained transformer models and compare them with large language\nmodels (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.\nOur findings show that fine-tuned transformers outperform prompt-based LLMs,\nespecially in distinguishing nuanced hope categories and sarcasm. Through\nqualitative analysis and confusion matrices, we highlight systematic challenges\nin separating closely related hope subtypes. The dataset and results provide a\nrobust foundation for future emotion recognition tasks that demand greater\nsemantic and contextual sensitivity across languages.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00\u7ec6\u7c92\u5ea6\u5e0c\u671b\u8bed\u97f3\u6570\u636e\u96c6PolyHope V2\uff0c\u5305\u542b\u56db\u79cd\u5e0c\u671b\u5b50\u7c7b\u578b\uff08\u542b\u8bbd\u523a\uff09\uff0c\u5e76\u53d1\u73b0\u5fae\u8c03\u7684Transformer\u6a21\u578b\u5728\u68c0\u6d4b\u8fd9\u4e9b\u7ec6\u5fae\u7c7b\u522b\u65b9\u9762\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5e0c\u671b\u662f\u4e00\u79cd\u590d\u6742\u4e14\u91cd\u8981\u7684\u60c5\u611f\uff0c\u5176\u7ec6\u5fae\u5f62\u5f0f\uff08\u5982\u73b0\u5b9e\u5e0c\u671b\u3001\u4e0d\u73b0\u5b9e\u5e0c\u671b\u3001\u8bbd\u523a\uff09\u96be\u4ee5\u88ab\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u51c6\u786e\u68c0\u6d4b\uff0c\u4e14\u7f3a\u4e4f\u533a\u5206\u8fd9\u4e9b\u5b50\u7c7b\u578b\uff08\u5c24\u5176\u662f\u8bbd\u523a\uff09\u7684\u6570\u636e\u96c6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc73\u4e07\u6761\u82f1/\u897f\u8bed\u63a8\u6587\u7684\u591a\u8bed\u8a00\u7ec6\u7c92\u5ea6\u5e0c\u671b\u6570\u636e\u96c6PolyHope V2\uff0c\u6807\u6ce8\u4e86\u56db\u79cd\u5e0c\u671b\u5b50\u7c7b\u578b\uff1b\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u5bf9\u591a\u79cd\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0eGPT-4\u3001Llama 3\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u6bd4\u8f83\uff1b\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u548c\u6df7\u6dc6\u77e9\u9635\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5fae\u8c03\u7684Transformer\u6a21\u578b\u5728\u533a\u5206\u7ec6\u5fae\u5e0c\u671b\u7c7b\u522b\u548c\u8bbd\u523a\u65b9\u9762\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff1b\u7814\u7a76\u4e5f\u63ed\u793a\u4e86\u5728\u533a\u5206\u76f8\u8fd1\u5e0c\u671b\u5b50\u7c7b\u578b\u65b9\u9762\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u6311\u6218\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u6570\u636e\u96c6PolyHope V2\u548c\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4e3a\u672a\u6765\u9700\u8981\u66f4\u9ad8\u8bed\u4e49\u548c\u8bed\u5883\u654f\u611f\u6027\u7684\u8de8\u8bed\u8a00\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2504.17993", "pdf": "https://arxiv.org/pdf/2504.17993", "abs": "https://arxiv.org/abs/2504.17993", "authors": ["Brihi Joshi", "Xiang Ren", "Swabha Swayamdipta", "Rik Koncel-Kedziorski", "Tim Paek"], "title": "Improving LLM Personas via Rationalization with Psychological Scaffolds", "categories": ["cs.CL"], "comment": null, "summary": "Language models prompted with a user description or persona can predict a\nuser's preferences and opinions, but existing approaches to building personas\n-- based solely on a user's demographic attributes and/or prior judgments --\nfail to capture the underlying reasoning behind said user judgments. We\nintroduce PB&J (Psychology of Behavior and Judgments), a framework that\nimproves LLM personas by incorporating rationales of why a user might make\nspecific judgments. These rationales are LLM-generated, and aim to reason about\na user's behavior on the basis of their experiences, personality traits or\nbeliefs. This is done using psychological scaffolds -- structured frameworks\ngrounded in theories such as the Big 5 Personality Traits and Primal World\nBeliefs -- that help provide structure to the generated rationales. Experiments\non public opinion and movie preference prediction tasks demonstrate that LLM\npersonas augmented with PB&J rationales consistently outperform methods using\nonly a user's demographics and/or judgments. Additionally, LLM personas\nconstructed using scaffolds describing user beliefs perform competitively with\nthose using human-written rationales.", "AI": {"tldr": "\u63d0\u51faPB&J\u6846\u67b6\uff0c\u901a\u8fc7LLM\u751f\u6210\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u201c\u884c\u4e3a\u539f\u56e0\u89e3\u91ca\u201d\u6765\u589e\u5f3a\u7528\u6237\u753b\u50cf\uff0c\u4ece\u800c\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u7528\u6237\u504f\u597d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u6216\u8fc7\u5f80\u5224\u65ad\u6784\u5efa\u7684\u7528\u6237\u753b\u50cf\u65b9\u6cd5\uff0c\u672a\u80fd\u6355\u6349\u7528\u6237\u5224\u65ad\u80cc\u540e\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u5f15\u5165PB&J\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7528\u6237\u884c\u4e3a\u7684\u201c\u539f\u56e0\u89e3\u91ca\u201d\u3002\u8fd9\u4e9b\u89e3\u91ca\u57fa\u4e8e\u7528\u6237\u7684\u7ecf\u9a8c\u3001\u4eba\u683c\u7279\u8d28\u6216\u4fe1\u5ff5\uff0c\u5e76\u5229\u7528\u5fc3\u7406\u5b66\u652f\u67b6\uff08\u5982\u5927\u4e94\u4eba\u683c\u3001\u539f\u59cb\u4e16\u754c\u4fe1\u5ff5\uff09\u8fdb\u884c\u7ed3\u6784\u5316\uff0c\u4ee5\u589e\u5f3aLLM\u7528\u6237\u753b\u50cf\u3002", "result": "\u5728\u516c\u4f17\u8206\u8bba\u548c\u7535\u5f71\u504f\u597d\u9884\u6d4b\u5b9e\u9a8c\u4e2d\uff0c\u7ecfPB&J\u201c\u539f\u56e0\u89e3\u91ca\u201d\u589e\u5f3a\u7684LLM\u7528\u6237\u753b\u50cf\u8868\u73b0\u59cb\u7ec8\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4eba\u53e3\u7edf\u8ba1\u548c/\u6216\u7528\u6237\u5224\u65ad\u7684\u65b9\u6cd5\u3002\u4f7f\u7528\u63cf\u8ff0\u7528\u6237\u4fe1\u5ff5\u7684\u652f\u67b6\u6784\u5efa\u7684\u753b\u50cf\uff0c\u5176\u6548\u679c\u4e0e\u4f7f\u7528\u4eba\u7c7b\u64b0\u5199\u89e3\u91ca\u7684\u753b\u50cf\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "PB&J\u6846\u67b6\u901a\u8fc7\u878d\u5165\u7528\u6237\u5224\u65ad\u80cc\u540e\u7684\u63a8\u7406\u8fc7\u7a0b\uff08\u539f\u56e0\u89e3\u91ca\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7528\u6237\u753b\u50cf\u9884\u6d4b\u7528\u6237\u504f\u597d\u548c\u89c2\u70b9\u7684\u80fd\u529b\u3002"}}
{"id": "2504.18012", "pdf": "https://arxiv.org/pdf/2504.18012", "abs": "https://arxiv.org/abs/2504.18012", "authors": ["Zhuang Yu", "Shiliang Sun", "Jing Zhao", "Tengfei Song", "Hao Yang"], "title": "Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal Machine Translation (MMT) aims to improve translation quality by\nleveraging auxiliary modalities such as images alongside textual input. While\nrecent advances in large-scale pre-trained language and vision models have\nsignificantly benefited unimodal natural language processing tasks, their\neffectiveness and role in MMT remain underexplored. In this work, we conduct a\nsystematic study on the impact of pre-trained encoders and decoders in\nmultimodal translation models. Specifically, we analyze how different training\nstrategies, from training from scratch to using pre-trained and partially\nfrozen components, affect translation performance under a unified MMT\nframework. Experiments are carried out on the Multi30K and CoMMuTE dataset\nacross English-German and English-French translation tasks. Our results reveal\nthat pre-training plays a crucial yet asymmetrical role in multimodal settings:\npre-trained decoders consistently yield more fluent and accurate outputs, while\npre-trained encoders show varied effects depending on the quality of\nvisual-text alignment. Furthermore, we provide insights into the interplay\nbetween modality fusion and pre-trained components, offering guidance for\nfuture architecture design in multimodal translation systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff09\u5bf9\u591a\u6a21\u6001\u673a\u5668\u7ffb\u8bd1\uff08MMT\uff09\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u80fd\u7a33\u5b9a\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u800c\u7f16\u7801\u5668\u7684\u6548\u679c\u4f9d\u8d56\u4e8e\u56fe\u6587\u5bf9\u9f50\u3002", "motivation": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5355\u6a21\u6001NLP\u4efb\u52a1\u4e2d\u6548\u679c\u663e\u8457\uff0c\u4f46\u5728\u591a\u6a21\u6001\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u4f5c\u7528\u548c\u6709\u6548\u6027\u4ecd\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5728\u4e00\u4e2a\u7edf\u4e00\u7684MMT\u6846\u67b6\u4e0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\uff08\u4ece\u5934\u8bad\u7ec3\u3001\u4f7f\u7528\u9884\u8bad\u7ec3\u53ca\u90e8\u5206\u51bb\u7ed3\u7ec4\u4ef6\uff09\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5728Multi30K\u548cCoMMuTE\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u82f1\u5fb7\u3001\u82f1\u6cd5\u7ffb\u8bd1\u5b9e\u9a8c\u3002", "result": "\u9884\u8bad\u7ec3\u5728MMT\u4e2d\u4f5c\u7528\u5173\u952e\u4f46\u4e0d\u5747\u8861\uff1a\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u59cb\u7ec8\u5e26\u6765\u66f4\u6d41\u7545\u51c6\u786e\u7684\u7ffb\u8bd1\uff1b\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u7684\u6548\u679c\u5219\u968f\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u8d28\u91cf\u53d8\u5316\u800c\u4e0d\u540c\u3002", "conclusion": "\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u5bf9MMT\u6709\u663e\u8457\u76ca\u5904\uff0c\u7f16\u7801\u5668\u7684\u9009\u62e9\u9700\u8003\u8651\u56fe\u6587\u5bf9\u9f50\u8d28\u91cf\u3002\u7814\u7a76\u4e3a\u672a\u6765MMT\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2504.18041", "pdf": "https://arxiv.org/pdf/2504.18041", "abs": "https://arxiv.org/abs/2504.18041", "authors": ["Bang An", "Shiyue Zhang", "Mark Dredze"], "title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "NAACL 2025", "summary": "Efforts to ensure the safety of large language models (LLMs) include safety\nfine-tuning, evaluation, and red teaming. However, despite the widespread use\nof the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses\non standard LLMs, which means we know little about how RAG use cases change a\nmodel's safety profile. We conduct a detailed comparative analysis of RAG and\nnon-RAG frameworks with eleven LLMs. We find that RAG can make models less safe\nand change their safety profile. We explore the causes of this change and find\nthat even combinations of safe models with safe documents can cause unsafe\ngenerations. In addition, we evaluate some existing red teaming methods for RAG\nsettings and show that they are less effective than when used for non-RAG\nsettings. Our work highlights the need for safety research and red-teaming\nmethods specifically tailored for RAG LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0RAG\u6846\u67b6\u4f1a\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u5373\u4f7f\u7ed3\u5408\u5b89\u5168\u6587\u6863\u4e5f\u53ef\u80fd\u4ea7\u751f\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u4e14\u73b0\u6709\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u4e9f\u9700\u9488\u5bf9RAG\u7684\u4e13\u5c5e\u5b89\u5168\u7814\u7a76\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u73b0\u6709\u7684AI\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6807\u51c6\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0a\uff0c\u5bf9\u4e8eRAG\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u5b89\u5168\u6027\u7684\u4e86\u89e3\u975e\u5e38\u6709\u9650\u3002", "method": "\u7814\u7a76\u5bf911\u4e2aLLM\u5728RAG\u548c\u975eRAG\u6846\u67b6\u4e0b\u7684\u5b89\u5168\u6027\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u63a2\u7a76\u4e86\u5b89\u5168\u6027\u53d8\u5316\u7684\u539f\u56e0\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5728RAG\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0RAG\u4f1a\u964d\u4f4e\u6a21\u578b\u7684\u5b89\u5168\u6027\u5e76\u6539\u53d8\u5176\u5b89\u5168\u7279\u6027\uff1b\u5373\u4f7f\u662f\u5b89\u5168\u6a21\u578b\u4e0e\u5b89\u5168\u6587\u6863\u7684\u7ec4\u5408\u4e5f\u53ef\u80fd\u5bfc\u81f4\u4e0d\u5b89\u5168\u7684\u751f\u6210\u7ed3\u679c\uff1b\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5728RAG\u573a\u666f\u4e0b\u7684\u6548\u679c\u4e0d\u5982\u5728\u975eRAG\u573a\u666f\u4e0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\uff0c\u9700\u8981\u9488\u5bf9RAG LLM\u8fdb\u884c\u4e13\u95e8\u7684\u5b89\u5168\u7814\u7a76\uff0c\u5e76\u5f00\u53d1\u91cf\u8eab\u5b9a\u5236\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u3002"}}
{"id": "2504.17795", "pdf": "https://arxiv.org/pdf/2504.17795", "abs": "https://arxiv.org/abs/2504.17795", "authors": ["Mohd Adnan"], "title": "Fuzzy Based Secure Clustering Schemes for Wireless Sensor Networks", "categories": ["cs.NI"], "comment": "Master's thesis", "summary": "This dissertation presents three independent novel approaches for distinct\nscenarios to solve one or more open challenges. The first concern explains the\nfocus on the lifetime of the networks: this dissertation will utilize a fuzzy\nlogic-based clustering protocol with multi-hop transmission for load balancing,\nenergy consumption minimization, and network lifetime prolongation. The\nprotocol forms unequal clusters with cluster head (CH) being selected by fuzzy\nlogic with competition radius. Node distance to the base station,\nconcentration, and residual energy are input variables. The second concern\nfocuses on network stability: we design a type 2 fuzzy logic-based clustering\nschemes in a multi-hop WSN to reduce energy consumption and improve network\nscalability. In this clustering scheme, we propose a cluster head (CH)\nselection strategy where a sensor node is elected as a CH based on type 2 fuzzy\nlogic inputs. To balance the load of CHs we also select their radius size based\non the fuzzy logic inputs. Finally, the third concern is focus on the utility\nof game theory in defensive Wireless Sensor Networks (WSN) from selfish nodes\nand malicious behavior. Game theory can effectively model WSNs malicious\nattacks because of their low complexity and scalability. The study, thus,\nexplores different WSN defense strategies from both external attackers and\ninternal nodes acting selfishly or maliciously using the game theory approach.\nAlso, the chapter highlights the general trust model for decision-making using\nthe game theory framework. Besides, the chapter demonstrates the significance\nof the theory in ensuring WSN security from acute attacks and its role in\nenhancing trustworthiness in data and cooperation of nodes in various WSN\narchitectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u9488\u5bf9\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\uff08WSN\uff09\u4e0d\u540c\u6311\u6218\u7684\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u805a\u7c7b\u534f\u8bae\u4ee5\u5ef6\u957f\u7f51\u7edc\u5bff\u547d\uff1b2) \u57fa\u4e8e\u4e8c\u578b\u6a21\u7cca\u903b\u8f91\u7684\u805a\u7c7b\u65b9\u6848\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u53ef\u6269\u5c55\u6027\uff1b3) \u5e94\u7528\u535a\u5f08\u8bba\u9632\u5fa1\u81ea\u79c1/\u6076\u610f\u8282\u70b9\u548c\u653b\u51fb\u3002", "motivation": "\u89e3\u51b3WSN\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u5ef6\u957f\u7f51\u7edc\u751f\u547d\u5468\u671f\u3001\u63d0\u9ad8\u7f51\u7edc\u7a33\u5b9a\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u4ee5\u53ca\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u6027\u4ee5\u62b5\u5fa1\u5185\u90e8\uff08\u81ea\u79c1/\u6076\u610f\u8282\u70b9\uff09\u548c\u5916\u90e8\u653b\u51fb\u3002", "method": "1) \u4f7f\u7528\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\uff08\u8f93\u5165\uff1a\u5230\u57fa\u7ad9\u8ddd\u79bb\u3001\u8282\u70b9\u96c6\u4e2d\u5ea6\u3001\u5269\u4f59\u80fd\u91cf\uff09\u548c\u7ade\u4e89\u534a\u5f84\u7684\u591a\u8df3\u4f20\u8f93\u975e\u5747\u8861\u5206\u7c07\u534f\u8bae\u8fdb\u884c\u7c07\u5934\u9009\u62e9\uff0c\u4ee5\u5e73\u8861\u8d1f\u8f7d\u3001\u6700\u5c0f\u5316\u80fd\u8017\u3002 2) \u8bbe\u8ba1\u57fa\u4e8e\u4e8c\u578b\u6a21\u7cca\u903b\u8f91\u7684\u591a\u8df3WSN\u5206\u7c07\u65b9\u6848\uff0c\u901a\u8fc7\u4e8c\u578b\u6a21\u7cca\u903b\u8f91\u9009\u62e9\u7c07\u5934\uff0c\u5e76\u901a\u8fc7\u6a21\u7cca\u903b\u8f91\u786e\u5b9a\u7c07\u5934\u534a\u5f84\u4ee5\u5e73\u8861\u8d1f\u8f7d\u3002 3) \u8fd0\u7528\u535a\u5f08\u8bba\u65b9\u6cd5\u5efa\u6a21\u548c\u5206\u6790\u9488\u5bf9WSN\u5185\u5916\u90e8\u653b\u51fb\u7684\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u63a2\u7d22\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u901a\u7528\u4fe1\u4efb\u6a21\u578b\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\uff1a1) \u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u805a\u7c7b\u80fd\u6709\u6548\u5e73\u8861\u8d1f\u8f7d\u3001\u964d\u4f4e\u80fd\u8017\u3001\u5ef6\u957f\u7f51\u7edc\u5bff\u547d\u3002 2) \u57fa\u4e8e\u4e8c\u578b\u6a21\u7cca\u903b\u8f91\u7684\u805a\u7c7b\u80fd\u964d\u4f4e\u80fd\u8017\u3001\u63d0\u5347\u7f51\u7edc\u53ef\u6269\u5c55\u6027\u3002 3) \u535a\u5f08\u8bba\u53ef\u6709\u6548\u5efa\u6a21WSN\u653b\u51fb\uff0c\u5206\u6790\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u80fd\u63d0\u5347\u6570\u636e\u53ef\u4fe1\u5ea6\u548c\u8282\u70b9\u534f\u4f5c\uff0c\u589e\u5f3aWSN\u5b89\u5168\u6027\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u63d0\u51fa\u4e86\u5229\u7528\u6a21\u7cca\u903b\u8f91\uff08\u4e00\u578b\u548c\u4e8c\u578b\uff09\u4f18\u5316WSN\u805a\u7c7b\u4ee5\u6539\u5584\u7f51\u7edc\u5bff\u547d\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u5e94\u7528\u535a\u5f08\u8bba\u6765\u589e\u5f3aWSN\u5bf9\u591a\u79cd\u5a01\u80c1\u7684\u5b89\u5168\u9632\u5fa1\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u89e3\u51b3\u7279\u5b9a\u6311\u6218\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.17804", "pdf": "https://arxiv.org/pdf/2504.17804", "abs": "https://arxiv.org/abs/2504.17804", "authors": ["Andrew Kiruluta"], "title": "Spectral Dictionary Learning for Generative Image Modeling", "categories": ["cs.CV"], "comment": null, "summary": "We propose a novel spectral generative model for image synthesis that departs\nradically from the common variational, adversarial, and diffusion paradigms. In\nour approach, images, after being flattened into one-dimensional signals, are\nreconstructed as linear combinations of a set of learned spectral basis\nfunctions, where each basis is explicitly parameterized in terms of frequency,\nphase, and amplitude. The model jointly learns a global spectral dictionary\nwith time-varying modulations and per-image mixing coefficients that quantify\nthe contributions of each spectral component. Subsequently, a simple\nprobabilistic model is fitted to these mixing coefficients, enabling the\ndeterministic generation of new images by sampling from the latent space. This\nframework leverages deterministic dictionary learning, offering a highly\ninterpretable and physically meaningful representation compared to methods\nrelying on stochastic inference or adversarial training. Moreover, the\nincorporation of frequency-domain loss functions, computed via the short-time\nFourier transform (STFT), ensures that the synthesized images capture both\nglobal structure and fine-grained spectral details, such as texture and edge\ninformation. Experimental evaluations on the CIFAR-10 benchmark demonstrate\nthat our approach not only achieves competitive performance in terms of\nreconstruction quality and perceptual fidelity but also offers improved\ntraining stability and computational efficiency. This new type of generative\nmodel opens up promising avenues for controlled synthesis, as the learned\nspectral dictionary affords a direct handle on the intrinsic frequency content\nof the images, thus providing enhanced interpretability and potential for novel\napplications in image manipulation and analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u9891\u8c31\u7684\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u9891\u8c31\u57fa\u51fd\u6570\u53ca\u5176\u6df7\u5408\u7cfb\u6570\u6765\u5408\u6210\u56fe\u50cf\uff0c\u4e0e\u5e38\u89c1\u7684\u53d8\u5206\u3001\u5bf9\u6297\u6216\u6269\u6563\u6a21\u578b\u4e0d\u540c\u3002", "motivation": "\u5bfb\u6c42\u4e00\u79cd\u4e0d\u540c\u4e8e\u73b0\u6709\u4e3b\u6d41\u8303\u5f0f\uff08VAE\u3001GAN\u3001\u6269\u6563\u6a21\u578b\uff09\u7684\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u7269\u7406\u610f\u4e49\u3001\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u5c06\u56fe\u50cf\u5c55\u5e73\u4e3a\u4e00\u7ef4\u4fe1\u53f7\uff0c\u5c06\u5176\u91cd\u6784\u4e3a\u4e00\u7ec4\u5b66\u4e60\u5230\u7684\u9891\u8c31\u57fa\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u3002\u8fd9\u4e9b\u57fa\u51fd\u6570\u7531\u9891\u7387\u3001\u76f8\u4f4d\u548c\u5e45\u5ea6\u663e\u5f0f\u53c2\u6570\u5316\u3002\u6a21\u578b\u8054\u5408\u5b66\u4e60\u4e00\u4e2a\u5168\u5c40\u9891\u8c31\u5b57\u5178\uff08\u542b\u65f6\u53d8\u8c03\u5236\uff09\u548c\u6bcf\u5e45\u56fe\u50cf\u7684\u6df7\u5408\u7cfb\u6570\u3002\u7136\u540e\uff0c\u5bf9\u6df7\u5408\u7cfb\u6570\u62df\u5408\u4e00\u4e2a\u7b80\u5355\u7684\u6982\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u4ece\u6f5c\u7a7a\u95f4\u91c7\u6837\u6765\u786e\u5b9a\u6027\u5730\u751f\u6210\u65b0\u56fe\u50cf\u3002\u8be5\u6846\u67b6\u5229\u7528\u786e\u5b9a\u6027\u5b57\u5178\u5b66\u4e60\uff0c\u5e76\u7ed3\u5408\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\uff08STFT\uff09\u8ba1\u7b97\u7684\u9891\u57df\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728CIFAR-10\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u611f\u77e5\u4fdd\u771f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u578b\u9891\u8c31\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u5ea6\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u7531\u4e8e\u5176\u76f4\u63a5\u5904\u7406\u56fe\u50cf\u7684\u5185\u5728\u9891\u7387\u5185\u5bb9\uff0c\u4e3a\u53ef\u63a7\u5408\u6210\u3001\u56fe\u50cf\u64cd\u7eb5\u548c\u5206\u6790\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
