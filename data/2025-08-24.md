<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 11]
- [cs.CV](#cs.CV) [Total: 8]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training](https://arxiv.org/abs/2508.14904)
*Jianfeng Si,Lin Sun,Zhewen Tan,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 针对现有LLM内容安全方法复杂且缺乏细粒度控制的痛点，本文提出了一种统一的协同训练框架。该框架在一个SFT阶段内集成多种安全行为，通过“魔法令牌”在推理时动态切换，实现了精细控制，并在降低成本的同时显著提升了安全性能，甚至超越了更大的模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM内容安全方法（如SFT和RLHF）普遍依赖多阶段训练流程，并且部署后缺乏细粒度的可控性。

Method: 提出了一种统一的协同训练框架，在一个单阶段的SFT过程中有效整合了多种安全行为（积极、消极和拒绝）。每个行为通过一个简单的系统级指令（“魔法令牌”）在推理时动态激活，实现了高效的行为切换和细粒度控制。

Result: 实验表明，该方法在安全对齐质量上与SFT+DPO相当，其8B模型在安全性能上显著超越了DeepSeek-R1（671B），同时显著降低了训练复杂度和部署成本。此外，协同训练策略在输出空间诱导了独特的安全对齐裕度，证明了模型安全鲁棒性并实现了前所未有的精细控制。

Conclusion: 本研究为LLM内容安全提供了一个可扩展、高效且高度可控的解决方案。

Abstract: Current methods for content safety in Large Language Models (LLMs), such as
Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback
(RLHF), often rely on multi-stage training pipelines and lack fine-grained,
post-deployment controllability. To address these limitations, we propose a
unified co-training framework that efficiently integrates multiple safety
behaviors: positive (lawful/prosocial), negative (unfiltered/risk-prone) and
rejective (refusal-oriented/conservative) within a single SFT stage. Notably,
each behavior is dynamically activated via a simple system-level instruction,
or magic token, enabling stealthy and efficient behavioral switching at
inference time. This flexibility supports diverse deployment scenarios, such as
positive for safe user interaction, negative for internal red-teaming, and
rejective for context-aware refusals triggered by upstream moderation signals.
This co-training strategy induces a distinct Safety Alignment Margin in the
output space, characterized by well-separated response distributions
corresponding to each safety mode. The existence of this margin provides
empirical evidence for the model's safety robustness and enables unprecedented
fine-grained control. Experiments show that our method matches the safety
alignment quality of SFT+DPO, with our 8B model notably surpassing DeepSeek-R1
(671B) in safety performance, while significantly reducing both training
complexity and deployment costs. This work presents a scalable, efficient, and
highly controllable solution for LLM content safety.

</details>


### [2] [Preliminary Ranking of WMT25 General Machine Translation Systems](https://arxiv.org/abs/2508.14909)
*Tom Kocmi,Eleftherios Avramidis,Rachel Bawden,Ondřej Bojar,Konstantin Dranch,Anton Dvorkovich,Sergey Dukanov,Natalia Fedorova,Mark Fishel,Markus Freitag,Thamme Gowda,Roman Grundkiewicz,Barry Haddow,Marzena Karpinska,Philipp Koehn,Howard Lakougna,Jessica Lundin,Kenton Murray,Masaaki Nagata,Stefano Perrella,Lorenzo Proietti,Martin Popel,Maja Popović,Parker Riley,Mariya Shmatova,Steinþór Steingrímsson,Lisa Yankovskaya,Vilém Zouhar*

Main category: cs.CL

TL;DR: 该报告发布了WMT25通用机器翻译共享任务的初步自动评估排名，指出其可能存在的偏见，并强调最终排名将基于人工评估。


<details>
  <summary>Details</summary>
Motivation: 向任务参与者分享WMT25通用机器翻译共享任务的初步结果，以帮助他们准备系统提交论文，尽管这些结果并非最终结论。

Method: 初步排名是通过自动评估指标对机器翻译系统进行评估得到的。

Result: 发布了WMT25通用机器翻译共享任务的初步排名。该排名基于自动评估，可能偏向于使用重排技术的系统。

Conclusion: 该报告的排名是初步的，基于自动评估，因此可能存在偏见，不代表最终结果。官方的、更可靠的排名将基于人工评估，并取代此自动排名。

Abstract: We present the preliminary ranking of the WMT25 General Machine Translation
Shared Task, in which MT systems have been evaluated using automatic metrics.
As this ranking is based on automatic evaluations, it may be biased in favor of
systems that employ re-ranking techniques, such as Quality Estimation
re-ranking or Minimum Bayes Risk decoding. The official WMT25 ranking will be
based on human evaluation, which is more reliable and will supersede the
automatic ranking.
  The purpose of this report is not to present the final findings of the
General MT task, but rather to share preliminary results with task
participants, which may be useful when preparing their system submission
papers.

</details>


### [3] [Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages](https://arxiv.org/abs/2508.14913)
*Israel Abebe Azime,Tadesse Destaw Belay,Dietrich Klakow,Philipp Slusallek,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 针对低资源语言中数学应用题缺乏本土化、文化背景数据集的问题，本文提出了一个LLM驱动的框架，用于自动构建包含本地实体（人名、组织、货币）的数学应用题数据集，以减少英语中心偏见并提高多语言数学推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在英语数学问题解决方面表现出色，但低资源语言中的多语言和文化背景数学推理能力滞后。现有基准多为翻译而来，保留了英语中心实体，缺乏反映真实本土实体的社会文化任务数据集，而人工和自动化本地化成本高昂且受限。

Method: 引入了一个LLM驱动的文化本地化框架，该框架能从现有来源自动构建包含本土人名、组织和货币的数学应用题数据集。

Result: 发现翻译的基准在适当的社会文化背景下可能会掩盖真实的多语言数学能力。通过大量实验证明，该框架能有效缓解英语中心实体偏见，并在引入各种语言的本土实体时提高模型的鲁棒性。

Conclusion: LLM驱动的文化本地化框架能够成功解决低资源语言中缺乏本土化数学应用题数据集的问题，有效减少英语中心实体偏见，并提升多语言数学推理模型的鲁棒性。

Abstract: Large language models (LLMs) have demonstrated significant capabilities in
solving mathematical problems expressed in natural language. However,
multilingual and culturally-grounded mathematical reasoning in low-resource
languages lags behind English due to the scarcity of socio-cultural task
datasets that reflect accurate native entities such as person names,
organization names, and currencies. Existing multilingual benchmarks are
predominantly produced via translation and typically retain English-centric
entities, owing to the high cost associated with human annotater-based
localization. Moreover, automated localization tools are limited, and hence,
truly localized datasets remain scarce. To bridge this gap, we introduce a
framework for LLM-driven cultural localization of math word problems that
automatically constructs datasets with native names, organizations, and
currencies from existing sources. We find that translated benchmarks can
obscure true multilingual math ability under appropriate socio-cultural
contexts. Through extensive experiments, we also show that our framework can
help mitigate English-centric entity bias and improves robustness when native
entities are introduced across various languages.

</details>


### [4] [Improving LLMs for Machine Translation Using Synthetic Preference Data](https://arxiv.org/abs/2508.14951)
*Dario Vajda,Domen Vreš,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 本文旨在通过DPO训练和少量易于生成的排名数据，提升通用指令微调大型语言模型（以斯洛文尼亚语为例）的机器翻译性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用相对较少的、易于生产的数据资源，有效改进通用指令微调大型语言模型在机器翻译任务中的表现。

Method: 以斯洛文尼亚语为应用案例，使用GaMS-9B-Instruct模型。通过两个LLM（GaMS-9B-Instruct和EuroLLM-9B-Instruct）翻译英文维基百科文章，并结合启发式方法及COMET等自动评估指标对翻译结果进行质量排名，从而生成DPO所需的训练数据集。随后，利用这个程序化策划和增强的数据子集，对GaMS-9B-Instruct模型进行直接偏好优化（DPO）训练。

Result: 微调后的模型在翻译维基百科文章时，其COMET得分比用于数据集生成的两个基线模型分别提高了约0.04和0.02。同时，该模型在避免语言和格式错误方面表现出更高的一致性。

Conclusion: 通过DPO训练和相对少量精心策划的数据，能够有效提升通用指令微调大型语言模型在机器翻译方面的性能，使其在准确性和错误规避方面超越原始模型。

Abstract: Large language models have emerged as effective machine translation systems.
In this paper, we explore how a general instruction-tuned large language model
can be improved for machine translation using relatively few easily produced
data resources. Using Slovene as a use case, we improve the GaMS-9B-Instruct
model using Direct Preference Optimization (DPO) training on a programmatically
curated and enhanced subset of a public dataset. As DPO requires pairs of
quality-ranked instances, we generated its training dataset by translating
English Wikipedia articles using two LLMs, GaMS-9B-Instruct and
EuroLLM-9B-Instruct. We ranked the resulting translations based on heuristics
coupled with automatic evaluation metrics such as COMET. The evaluation shows
that our fine-tuned model outperforms both models involved in the dataset
generation. In comparison to the baseline models, the fine-tuned model achieved
a COMET score gain of around 0.04 and 0.02, respectively, on translating
Wikipedia articles. It also more consistently avoids language and formatting
errors.

</details>


### [5] [Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems](https://arxiv.org/abs/2508.14982)
*Qianli Wang,Tatiana Anikina,Nils Feldhus,Simon Ostermann,Fedor Splitt,Jiaao Li,Yoana Tsoneva,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 为解决ConvXAI系统多语言泛化和自定义输入支持不足的问题，本研究引入了MultiCoXQL和Compass两个多语言数据集，并提出新的解析方法，以提升多语言意图识别和自由形式输入提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLMs）的会话式可解释人工智能（ConvXAI）系统在英语意图识别上表现良好，但由于训练数据稀缺，难以实现多语言泛化。此外，对用户定义的自由形式自定义输入的支持也十分有限。

Method: ['引入MultiCoXQL，一个CoXQL数据集的多语言扩展，涵盖五种语言（包括一种低资源语言）。', '提出一种新的解析方法，旨在提高多语言解析性能，并在MultiCoXQL上评估了三种大语言模型，采用多种解析策略。', '提出Compass，一个针对ConvXAI系统中自定义输入提取的新多语言数据集，涵盖与MultiCoXQL相同的五种语言的11种意图。', '在Compass上使用三种不同规模的大语言模型和BERT类型模型进行了单语言、跨语言和多语言评估。']

Result: 研究引入了多语言数据集MultiCoXQL和Compass，并提出了一种旨在提升多语言解析性能的新解析方法。文章对多种大语言模型在MultiCoXQL和Compass数据集上的解析策略和性能进行了单语言、跨语言和多语言评估。

Conclusion: 本研究通过创建创新的多语言数据集和新的解析方法，有效弥补了ConvXAI系统在多语言泛化和自由形式自定义输入支持方面的关键不足，为构建更通用、用户友好的ConvXAI系统奠定了基础。

Abstract: Conversational explainable artificial intelligence (ConvXAI) systems based on
large language models (LLMs) have garnered considerable attention for their
ability to enhance user comprehension through dialogue-based explanations.
Current ConvXAI systems often are based on intent recognition to accurately
identify the user's desired intention and map it to an explainability method.
While such methods offer great precision and reliability in discerning users'
underlying intentions for English, a significant challenge in the scarcity of
training data persists, which impedes multilingual generalization. Besides, the
support for free-form custom inputs, which are user-defined data distinct from
pre-configured dataset instances, remains largely limited. To bridge these
gaps, we first introduce MultiCoXQL, a multilingual extension of the CoXQL
dataset spanning five typologically diverse languages, including one
low-resource language. Subsequently, we propose a new parsing approach aimed at
enhancing multilingual parsing performance, and evaluate three LLMs on
MultiCoXQL using various parsing strategies. Furthermore, we present Compass, a
new multilingual dataset designed for custom input extraction in ConvXAI
systems, encompassing 11 intents across the same five languages as MultiCoXQL.
We conduct monolingual, cross-lingual, and multilingual evaluations on Compass,
employing three LLMs of varying sizes alongside BERT-type models.

</details>


### [6] [Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner](https://arxiv.org/abs/2508.15044)
*Bolian Li,Yanran Wu,Xinyu Luo,Ruqi Zhang*

Main category: cs.CL

TL;DR: 本文提出奖励偏移推测采样（SSS）算法，以解决测试时LLM对齐的高昂推理成本问题。SSS利用已对齐的草稿模型和未改变的目标模型，通过修改采样标准，在显著降低推理成本的同时，取得了更优的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）测试时对齐技术虽能提升模型安全性和推理能力，但会产生高昂的推理成本，限制了其实际应用。

Method: 受推测采样加速技术启发，本文引入了奖励偏移推测采样（SSS）算法。该算法利用一个已与人类偏好对齐的草稿模型和一个未改变的目标模型。通过理论分析，SSS利用对齐草稿模型与未对齐目标模型之间的分布差异，并修改接受准则和奖励token分布，从而在不直接获取RLHF最优解的情况下恢复该解。

Result: 在测试时弱到强对齐实验中，SSS算法在显著降低推理成本的同时，实现了更优的“黄金奖励分数”。

Conclusion: SSS算法在提高测试时LLM对齐的效率和效果方面都表现出色，验证了其有效性和高效性。

Abstract: Aligning large language models (LLMs) with human preferences has become a
critical step in their development. Recent research has increasingly focused on
test-time alignment, where additional compute is allocated during inference to
enhance LLM safety and reasoning capabilities. However, these test-time
alignment techniques often incur substantial inference costs, limiting their
practical application. We are inspired by the speculative sampling
acceleration, which leverages a small draft model to efficiently predict future
tokens, to address the efficiency bottleneck of test-time alignment. We
introduce the reward-Shifted Speculative Sampling (SSS) algorithm, in which the
draft model is aligned with human preferences, while the target model remains
unchanged. We theoretically demonstrate that the distributional shift between
the aligned draft model and the unaligned target model can be exploited to
recover the RLHF optimal solution without actually obtaining it, by modifying
the acceptance criterion and bonus token distribution. Our algorithm achieves
superior gold reward scores at a significantly reduced inference cost in
test-time weak-to-strong alignment experiments, thereby validating both its
effectiveness and efficiency.

</details>


### [7] [LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text](https://arxiv.org/abs/2508.15085)
*MohamamdJavad Ardestani,Ehsan Kamalloo,Davood Rafiei*

Main category: cs.CL

TL;DR: LongRecall是一个三阶段的召回率评估框架，通过事实分解、筛选和结构化蕴含检查，克服了现有词汇重叠和LLM法官方法的缺陷，显著提高了长文本问答的召回率准确性。


<details>
  <summary>Details</summary>
Motivation: 现有召回率指标（基于词汇重叠）在处理未经证实实体和转述答案时容易出错；LLM-as-a-Judge方法虽然捕捉更广语义，但缺乏结构化验证时易出现偏差和幻觉。在医学、法律等关键领域，文本完整性至关重要，遗漏可能导致严重后果。

Method: LongRecall采用三阶段评估框架：1) 将答案分解为独立事实；2) 通过词汇和语义过滤逐步缩小候选匹配；3) 通过结构化蕴含检查验证事实对齐。该设计旨在减少假阳性和假阴性，并适应多样化的表达和上下文变体。

Result: 在三个具有挑战性的长文本问答基准测试中，LongRecall结合人类标注和LLM法官进行评估，结果显示其召回率准确性较现有强大的词汇和LLM-as-a-Judge基线有显著提升。

Conclusion: LongRecall为系统性召回率评估提供了一个基础构建模块，有效解决了机器生成文本完整性评估中的现有挑战，提高了评估的准确性和鲁棒性。

Abstract: LongRecall. The completeness of machine-generated text, ensuring that it
captures all relevant information, is crucial in domains such as medicine and
law and in tasks like list-based question answering (QA), where omissions can
have serious consequences. However, existing recall metrics often depend on
lexical overlap, leading to errors with unsubstantiated entities and
paraphrased answers, while LLM-as-a-Judge methods with long holistic prompts
capture broader semantics but remain prone to misalignment and hallucinations
without structured verification. We introduce LongRecall, a general three-stage
recall evaluation framework that decomposes answers into self-contained facts,
successively narrows plausible candidate matches through lexical and semantic
filtering, and verifies their alignment through structured entailment checks.
This design reduces false positives and false negatives while accommodating
diverse phrasings and contextual variations, serving as a foundational building
block for systematic recall assessment. We evaluate LongRecall on three
challenging long-form QA benchmarks using both human annotations and LLM-based
judges, demonstrating substantial improvements in recall accuracy over strong
lexical and LLM-as-a-Judge baselines.

</details>


### [8] [Mapping the Course for Prompt-based Structured Prediction](https://arxiv.org/abs/2508.15090)
*Matt Pauk,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: 为解决LLM幻觉和推理难题，本文将LLM与组合推理结合用于结构化预测，证明其能提高预测的一致性和准确性，并指出结构化学习在LLM时代仍有价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理幻觉和复杂推理问题时表现不足，特别是在结构化预测领域，其自回归特性导致缺乏结构一致性。

Method: 提出将LLM与组合推理相结合，以融合LLM的预测能力和推理方法的结构一致性。研究了不同提示策略下LLM置信度估计与符号推理的结合，并采用结构化预测目标进行校准和微调。

Result: 1. 无论提示策略如何，结合符号推理能使预测更一致和准确。2. 采用结构化预测目标进行校准和微调能显著提升模型在挑战性任务上的性能。

Conclusion: 结合LLM与组合推理可提升结构化预测的准确性和一致性。结果表明，结构化学习（如校准和微调）在LLM时代对于提高模型性能仍至关重要。

Abstract: LLMs have been shown to be useful for a variety of language tasks, without
requiring task-specific fine-tuning. However, these models often struggle with
hallucinations and complex reasoning problems due to their autoregressive
nature. We propose to address some of these issues, specifically in the area of
structured prediction, by combining LLMs with combinatorial inference in an
attempt to marry the predictive power of LLMs with the structural consistency
provided by inference methods. We perform exhaustive experiments in an effort
to understand which prompting strategies can effectively estimate LLM
confidence values for use with symbolic inference, and show that, regardless of
the prompting strategy, the addition of symbolic inference on top of prompting
alone leads to more consistent and accurate predictions. Additionally, we show
that calibration and fine-tuning using structured prediction objectives leads
to increased performance for challenging tasks, showing that structured
learning is still valuable in the era of LLMs.

</details>


### [9] [Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset](https://arxiv.org/abs/2508.15096)
*Rabeeh Karimi Mahabadi,Sanjeev Satheesh,Shrimai Prabhumoye,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro*

Main category: cs.CL

TL;DR: 本文介绍了一个新的、高质量的数学语料库Nemotron-CC-Math，它通过一种新颖、鲁棒的管道从Common Crawl中提取，显著提高了大型语言模型在数学、代码和通用推理方面的性能，并发布了数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Common Crawl构建的数学数据集质量低下，原因在于提取启发式方法脆弱、HTML-到-文本转换有损以及未能可靠地保留数学结构，这限制了它们增强LLM推理能力的效果。

Method: 开发了一个新颖的、领域无关的管道，专门用于鲁棒的科学文本提取。该管道利用`lynx`进行布局感知渲染和LLM驱动的清理阶段，恢复了多种格式（如MathJax, KaTeX, MathML）的数学内容。它能保留方程和代码块的结构完整性，移除模板，将符号标准化为LaTeX表示，并纠正不一致性。

Result: 构建了Nemotron-CC-Math-3+（133B tokens）和Nemotron-CC-Math-4+（52B tokens）两个高质量数学语料库。Nemotron-CC-Math-4+超越了所有先前的开放数学数据集，并且包含的token数量是先前最高质量数据集FineMath-4+的5.5倍。使用该语料库预训练Nemotron-T 8B模型后，在MATH上实现了+4.8至+12.6的提升，在MBPP+上实现了+4.6至+14.3的提升，并同时改善了MMLU和MMLU-Stem上的通用领域性能。

Conclusion: 首次提出了一个能够从嘈杂网络数据中可靠提取科学内容（包括数学）的管道，从而在数学、代码和通用推理方面取得了可衡量的收益，并为开放数学预训练语料库设定了新的技术水平。为支持开源工作，我们发布了代码和数据集。

Abstract: Pretraining large language models (LLMs) on high-quality, structured data
such as mathematics and code substantially enhances reasoning capabilities.
However, existing math-focused datasets built from Common Crawl suffer from
degraded quality due to brittle extraction heuristics, lossy HTML-to-text
conversion, and the failure to reliably preserve mathematical structure. In
this work, we introduce Nemotron-CC-Math, a large-scale, high-quality
mathematical corpus constructed from Common Crawl using a novel,
domain-agnostic pipeline specifically designed for robust scientific text
extraction.
  Unlike previous efforts, our pipeline recovers math across various formats
(e.g., MathJax, KaTeX, MathML) by leveraging layout-aware rendering with lynx
and a targeted LLM-based cleaning stage. This approach preserves the structural
integrity of equations and code blocks while removing boilerplate,
standardizing notation into LaTeX representation, and correcting
inconsistencies.
  We collected a large, high-quality math corpus, namely Nemotron-CC-Math-3+
(133B tokens) and Nemotron-CC-Math-4+ (52B tokens). Notably,
Nemotron-CC-Math-4+ not only surpasses all prior open math datasets-including
MegaMath, FineMath, and OpenWebMath-but also contains 5.5 times more tokens
than FineMath-4+, which was previously the highest-quality math pretraining
dataset. When used to pretrain a Nemotron-T 8B model, our corpus yields +4.8 to
+12.6 gains on MATH and +4.6 to +14.3 gains on MBPP+ over strong baselines,
while also improving general-domain performance on MMLU and MMLU-Stem.
  We present the first pipeline to reliably extract scientific
content--including math--from noisy web-scale data, yielding measurable gains
in math, code, and general reasoning, and setting a new state of the art among
open math pretraining corpora. To support open-source efforts, we release our
code and datasets.

</details>


### [10] [Identifying and Answering Questions with False Assumptions: An Interpretable Approach](https://arxiv.org/abs/2508.15139)
*Zijie Wang,Eduardo Blanco*

Main category: cs.CL

TL;DR: 本文提出一种通过事实核查和利用外部证据的方法，以识别并回答含有错误假设的问题，有效提升大型语言模型（LLMs）的性能和答案可解释性。


<details>
  <summary>Details</summary>
Motivation: 人们常提出含有错误假设的问题，这类问题需先识别出错误假设才能正确回答。然而，LLMs常因幻觉生成误导性答案。因此，研究旨在解决LLMs在处理此类问题时的局限性。

Method: 将问题识别简化为事实核查任务，并提出一种利用外部证据来缓解LLMs幻觉的方法。具体做法是生成并验证原子级的假设。

Result: 对五种LLMs的实验表明，(1) 结合检索到的外部证据是有效的，(2) 生成和验证原子级假设能带来更大改进，并通过明确错误假设提供可解释的答案。

Conclusion: 通过事实核查和利用外部证据，尤其是通过生成和验证原子级假设，可以有效识别和回答含有错误假设的问题，同时提高LLMs的准确性和答案的可解释性。

Abstract: People often ask questions with false assumptions, a type of question that
does not have regular answers. Answering such questions require first
identifying the false assumptions. Large Language Models (LLMs) often generate
misleading answers because of hallucinations. In this paper, we focus on
identifying and answering questions with false assumptions in several domains.
We first investigate to reduce the problem to fact verification. Then, we
present an approach leveraging external evidence to mitigate hallucinations.
Experiments with five LLMs demonstrate that (1) incorporating retrieved
evidence is beneficial and (2) generating and validating atomic assumptions
yields more improvements and provides an interpretable answer by specifying the
false assumptions.

</details>


### [11] [ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following](https://arxiv.org/abs/2508.15164)
*Seungmin Han,Haeun Kwon,Ji-jun Park,Taeyang Yoon*

Main category: cs.CL

TL;DR: 本文提出了MMDR-Bench，一个多模态多轮对话推理基准，并引入了CoLVLM Agent，一个无需重训练即可增强现有大型视觉语言模型（LVLMs）的框架。CoLVLM Agent在复杂多轮多模态任务中表现优越，超越了GPT-4o和Gemini 1.5 Pro等现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）和大型视觉语言模型（LVLMs）在处理需要深度推理、持续上下文理解、实体追踪和多步骤指令遵循的复杂、多轮、视觉接地任务时面临挑战，且现有基准无法捕捉真实世界多模态交互的动态性和复杂性，导致上下文丢失和视觉幻觉。

Method: 引入MMDR-Bench（多模态对话推理基准），一个包含300个复杂多轮对话场景的数据集，平均5-7轮，并在六个核心维度上进行评估。同时提出了CoLVLM Agent（上下文LVLM智能体），一个通过“记忆-感知-规划-执行”迭代循环来增强现有LVLMs的框架，无需大规模重训练。

Result: CoLVLM Agent在MMDR-Bench上表现出色，平均人工评估得分4.03，显著超越了GPT-4o（3.92）和Gemini 1.5 Pro（3.85）。该框架在推理深度、指令遵循和错误抑制方面具有显著优势，并在扩展对话轮次中保持稳健性能。

Conclusion: CoLVLM Agent的模块化设计和迭代方法有效解决了复杂多模态交互中的挑战，提升了LVLMs在深度推理和指令遵循方面的能力，验证了其在复杂多模态任务中的有效性。

Abstract: Despite significant advancements in Large Language Models (LLMs) and Large
Vision-Language Models (LVLMs), current models still face substantial
challenges in handling complex, multi-turn, and visually-grounded tasks that
demand deep reasoning, sustained contextual understanding, entity tracking, and
multi-step instruction following. Existing benchmarks often fall short in
capturing the dynamism and intricacies of real-world multi-modal interactions,
leading to issues such as context loss and visual hallucinations. To address
these limitations, we introduce MMDR-Bench (Multi-Modal Dialogue Reasoning
Benchmark), a novel dataset comprising 300 meticulously designed complex
multi-turn dialogue scenarios, each averaging 5-7 turns and evaluated across
six core dimensions including visual entity tracking and reasoning depth.
Furthermore, we propose CoLVLM Agent (Contextual LVLM Agent), a holistic
framework that enhances existing LVLMs with advanced reasoning and instruction
following capabilities through an iterative
"memory-perception-planning-execution" cycle, requiring no extensive
re-training of the underlying models. Our extensive experiments on MMDR-Bench
demonstrate that CoLVLM Agent consistently achieves superior performance,
attaining an average human evaluation score of 4.03, notably surpassing
state-of-the-art commercial models like GPT-4o (3.92) and Gemini 1.5 Pro
(3.85). The framework exhibits significant advantages in reasoning depth,
instruction adherence, and error suppression, and maintains robust performance
over extended dialogue turns, validating the effectiveness of its modular
design and iterative approach for complex multi-modal interactions.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [Heatmap Regression without Soft-Argmax for Facial Landmark Detection](https://arxiv.org/abs/2508.14929)
*Chiao-An Yang,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 本文提出一种基于经典结构化预测框架的替代训练目标，用于面部关键点检测，避免使用Soft-argmax，实现了最先进的性能和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 基于热图的面部关键点检测方法普遍依赖Soft-argmax解决argmax的不可微问题。作者旨在重新审视这一长期选择，并证明存在其他方法也能实现高性能。

Method: 作者提出一种基于经典结构化预测框架的替代训练目标，取代了传统的Soft-argmax，以实现深度网络的端到端训练。

Result: 该方法在WFLW、COFW和300W三个面部关键点基准测试中取得了最先进的性能，训练收敛速度提高2.2倍，同时保持了更好或具有竞争力的准确性。

Conclusion: 本研究表明，Soft-argmax并非实现基于热图的面部关键点检测高性能的唯一途径。所提出的基于结构化预测的替代目标展现出卓越的训练效率和竞争力，为该领域的训练方法提供了新的选择。

Abstract: Facial landmark detection is an important task in computer vision with
numerous applications, such as head pose estimation, expression analysis, face
swapping, etc. Heatmap regression-based methods have been widely used to
achieve state-of-the-art results in this task. These methods involve computing
the argmax over the heatmaps to predict a landmark. Since argmax is not
differentiable, these methods use a differentiable approximation, Soft-argmax,
to enable end-to-end training on deep-nets. In this work, we revisit this
long-standing choice of using Soft-argmax and demonstrate that it is not the
only way to achieve strong performance. Instead, we propose an alternative
training objective based on the classic structured prediction framework.
Empirically, our method achieves state-of-the-art performance on three facial
landmark benchmarks (WFLW, COFW, and 300W), converging 2.2x faster during
training while maintaining better/competitive accuracy. Our code is available
here: https://github.com/ca-joe-yang/regression-without-softarg.

</details>


### [13] [Fast Graph Neural Network for Image Classification](https://arxiv.org/abs/2508.14958)
*Mustafa Mohammadi Gharasuie,Luis Rueda*

Main category: cs.CV

TL;DR: 本研究提出了一种结合图卷积网络（GCNs）和Voronoi图的新方法，通过将图像表示为图并利用Delaunay三角剖分进行优化，显著提升了图像分类的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 图像分类领域由GCNs的进步推动，它们擅长处理复杂数据结构。研究旨在通过整合GCNs与Voronoi图，利用它们建模关系数据的能力来增强图像分类，以克服传统卷积神经网络（CNNs）的局限性。

Method: 该方法将图像表示为图，其中像素或区域作为顶点。这些图随后通过相应的Delaunay三角剖分进行优化和细化，并将图卷积网络（GCNs）与Voronoi图相结合应用于图像分类任务。

Result: 所提出的模型在多种基准数据集上取得了预处理效率和分类准确性的显著提升，超越了现有最先进的方法，尤其在处理复杂场景和细粒度类别时表现突出。实验结果通过交叉验证得到了验证。

Conclusion: 结合GCNs和Voronoi图能够有效推进图像分类技术，为图像分类提供了新颖的视角，并拓展了图基学习范式在计算机视觉和非结构化数据分析中的潜在应用。

Abstract: The rapid progress in image classification has been largely driven by the
adoption of Graph Convolutional Networks (GCNs), which offer a robust framework
for handling complex data structures. This study introduces a novel approach
that integrates GCNs with Voronoi diagrams to enhance image classification by
leveraging their ability to effectively model relational data. Unlike
conventional convolutional neural networks (CNNs), our method represents images
as graphs, where pixels or regions function as vertices. These graphs are then
refined using corresponding Delaunay triangulations, optimizing their
representation. The proposed model achieves significant improvements in both
preprocessing efficiency and classification accuracy across various benchmark
datasets, surpassing state-of-the-art approaches, particularly in challenging
scenarios involving intricate scenes and fine-grained categories. Experimental
results, validated through cross-validation, underscore the effectiveness of
combining GCNs with Voronoi diagrams for advancing image classification. This
research not only presents a novel perspective on image classification but also
expands the potential applications of graph-based learning paradigms in
computer vision and unstructured data analysis.

</details>


### [14] [You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation](https://arxiv.org/abs/2508.14965)
*Hakjin Lee,Junghoon Seo,Jaehoon Sim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurately recovering the full 9-DoF pose of unseen instances within specific
categories from a single RGB image remains a core challenge for robotics and
automation. Most existing solutions still rely on pseudo-depth, CAD models, or
multi-stage cascades that separate 2D detection from pose estimation. Motivated
by the need for a simpler, RGB-only alternative that learns directly at the
category level, we revisit a longstanding question: Can object detection and
9-DoF pose estimation be unified with high performance, without any additional
data? We show that they can with our method, YOPO, a single-stage, query-based
framework that treats category-level 9-DoF estimation as a natural extension of
2D detection. YOPO augments a transformer detector with a lightweight pose
head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian
matching cost. The model is trained end-to-end only with RGB images and
category-level pose labels. Despite its minimalist design, YOPO sets a new
state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%
$\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing
prior RGB-only methods and closing much of the gap to RGB-D systems. The code,
models, and additional qualitative results can be found on our project.

</details>


### [15] [Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection](https://arxiv.org/abs/2508.14980)
*Andrei Balykin,Anvar Ganiev,Denis Kondranin,Kirill Polevoda,Nikolai Liudkevich,Artem Petrov*

Main category: cs.CV

TL;DR: 提出一个统一的配对采样对比框架，通过学习模态无关的活体线索，有效检测物理和数字人脸欺骗攻击，并在基准测试中取得了领先的性能，同时保持轻量和高效。


<details>
  <summary>Details</summary>
Motivation: 现代人脸识别系统容易受到物理和数字欺骗攻击。传统方法使用独立模型处理这两种攻击，导致系统复杂性增加、推理延迟，并且无法有效应对组合攻击。

Method: 提出“配对采样对比框架”（Paired-Sampling Contrastive Framework），这是一种统一的训练方法。它利用自动匹配的真实和攻击自拍对，来学习与模态无关的活体特征线索。

Result: 在第6届人脸反欺骗挑战赛统一物理-数字攻击检测基准上，该方法实现了2.10%的平均分类错误率（ACER），优于现有解决方案。该框架轻量级（4.46 GFLOPs）且训练时间不到一小时。

Conclusion: 该框架为物理和数字人脸欺骗攻击提供了一个统一、高性能、轻量级且快速训练的解决方案，非常适合实际部署。

Abstract: Modern face recognition systems remain vulnerable to spoofing attempts,
including both physical presentation attacks and digital forgeries.
Traditionally, these two attack vectors have been handled by separate models,
each targeting its own artifacts and modalities. However, maintaining distinct
detectors increases system complexity and inference latency and leaves systems
exposed to combined attack vectors. We propose the Paired-Sampling Contrastive
Framework, a unified training approach that leverages automatically matched
pairs of genuine and attack selfies to learn modality-agnostic liveness cues.
Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital
Attack Detection benchmark, our method achieves an average classification error
rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is
lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for
real-world deployment. Code and pretrained models are available at
https://github.com/xPONYx/iccv2025_deepfake_challenge.

</details>


### [16] [TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](https://arxiv.org/abs/2508.15020)
*Susim Roy,Anubhooti Jain,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: TAIGen提出了一种无需训练的黑盒方法，通过扩散模型高效生成高质量对抗样本，仅需3-20个采样步，速度比现有方法快10倍，同时保持视觉质量和高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型生成的对抗样本质量低且计算资源消耗大。扩散模型虽能生成高质量图像，但用于对抗攻击时需要数百个采样步。因此，需要一种高效、高质量、黑盒的对抗图像生成方法。

Method: 论文介绍TAIGen，一种无需训练的黑盒方法，利用无条件扩散模型仅通过3-20个采样步生成对抗样本。核心创新是在“混合步间隔”期间注入扰动，避免处理所有时间步。该方法采用选择性RGB通道策略：对红色通道应用注意力图，对绿色和蓝色通道使用GradCAM引导的扰动，以在保持图像结构的同时最大化目标模型的误分类。

Result: TAIGen生成的图像视觉质量高，PSNR超过30 dB。在ImageNet数据集上，以VGGNet为源模型，对ResNet、MNASNet和ShuffleNet的攻击成功率分别为70.6%、80.8%和97.8%。该方法比现有基于扩散的攻击方法快10倍。此外，它实现了最低的鲁棒准确率，表明其攻击效果最强，防御机制难以净化其生成的图像。

Conclusion: TAIGen是一种高效、无需训练的黑盒方法，能够利用扩散模型生成高质量的对抗性图像。它显著减少了所需的采样步数，提高了生成速度，保持了视觉质量，并取得了强大的攻击性能，证明了其对防御机制的巨大影响。

Abstract: Adversarial attacks from generative models often produce low-quality images
and require substantial computational resources. Diffusion models, though
capable of high-quality generation, typically need hundreds of sampling steps
for adversarial generation. This paper introduces TAIGen, a training-free
black-box method for efficient adversarial image generation. TAIGen produces
adversarial examples using only 3-20 sampling steps from unconditional
diffusion models. Our key finding is that perturbations injected during the
mixing step interval achieve comparable attack effectiveness without processing
all timesteps. We develop a selective RGB channel strategy that applies
attention maps to the red channel while using GradCAM-guided perturbations on
green and blue channels. This design preserves image structure while maximizing
misclassification in target models. TAIGen maintains visual quality with PSNR
above 30 dB across all tested datasets. On ImageNet with VGGNet as source,
TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8%
against ShuffleNet. The method generates adversarial examples 10x faster than
existing diffusion-based attacks. Our method achieves the lowest robust
accuracy, indicating it is the most impactful attack as the defense mechanism
is least successful in purifying the images generated by TAIGen.

</details>


### [17] [Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement](https://arxiv.org/abs/2508.15027)
*Chunming He,Fengyang Xiao,Rihan Zhang,Chengyu Fang,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: 本文提出RUN++网络，用于隐匿视觉感知（CVP），通过在掩码和RGB域应用可逆建模，并结合目标扩散模型来解决不确定性，从而提高分割精度并减少误报和漏报。


<details>
  <summary>Details</summary>
Motivation: 现有隐匿视觉感知（CVP）方法多利用可逆策略减少不确定性，但通常局限于掩码域，未充分探索RGB域的潜力。本研究旨在解决此问题，在掩码和RGB域均应用可逆建模并解决不确定性。

Method: 本文提出RUN++（可逆展开生成精化网络）。首先将CVP任务公式化为数学优化问题，并将其迭代解展开为多阶段深度网络，实现在掩码和RGB域应用可逆建模，并利用扩散模型解决不确定性。网络每个阶段包含三个模块：1) CORE模块在掩码域进行可逆建模以识别核心目标区域；2) CARE模块将此原理扩展到RGB域以促进更好的前景-背景分离；3) FINE模块引入目标伯努利扩散模型，仅精化分割掩码的不确定区域，利用生成能力恢复细节，同时避免全图处理的高计算成本。此外，还提出了构建在真实世界退化下仍有效CVP系统的新范式，并将其扩展为双层优化框架。

Result: 通过展开网络为扩散模型提供强不确定性先验的独特协同作用，RUN++能有效将注意力集中在模糊区域，显著减轻了误报和漏报。

Conclusion: RUN++通过在掩码和RGB域集成可逆建模与目标扩散精化，为隐匿视觉感知提供了一种有效方法，实现了更精确的分割和减少误报/漏报。同时，本文还提出了一种在真实世界退化下构建鲁棒CVP系统的新范式和双层优化框架。

Abstract: Existing methods for concealed visual perception (CVP) often leverage
reversible strategies to decrease uncertainty, yet these are typically confined
to the mask domain, leaving the potential of the RGB domain underexplored. To
address this, we propose a reversible unfolding network with generative
refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as
a mathematical optimization problem and unfolds the iterative solution into a
multi-stage deep network. This approach provides a principled way to apply
reversible modeling across both mask and RGB domains while leveraging a
diffusion model to resolve the resulting uncertainty. Each stage of the network
integrates three purpose-driven modules: a Concealed Object Region Extraction
(CORE) module applies reversible modeling to the mask domain to identify core
object regions; a Context-Aware Region Enhancement (CARE) module extends this
principle to the RGB domain to foster better foreground-background separation;
and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a
final refinement. The FINE module introduces a targeted Bernoulli diffusion
model that refines only the uncertain regions of the segmentation mask,
harnessing the generative power of diffusion for fine-detail restoration
without the prohibitive computational cost of a full-image process. This unique
synergy, where the unfolding network provides a strong uncertainty prior for
the diffusion model, allows RUN++ to efficiently direct its focus toward
ambiguous areas, significantly mitigating false positives and negatives.
Furthermore, we introduce a new paradigm for building robust CVP systems that
remain effective under real-world degradations and extend this concept into a
broader bi-level optimization framework.

</details>


### [18] [GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging](https://arxiv.org/abs/2508.15057)
*Toqi Tahamid Sarker,Mohamed Embaby,Taminul Islam,Amer AbuGhazaleh,Khaled R Ahmed*

Main category: cs.CV

TL;DR: GasTwinFormer是一种新颖的混合视觉Transformer，通过光学气体成像技术，实现了实时牲畜甲烷排放分割和饮食分类，具备高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 牲畜甲烷排放占人类活动导致甲烷产量的32%，因此自动化监测对气候缓解策略至关重要。

Method: 引入GasTwinFormer，一个混合视觉Transformer，采用新型Mix Twin编码器（交替使用空间缩减的全局注意力和局部分组注意力）和轻量级LR-ASPP解码器。该模型在统一框架下实现甲烷分割和饮食分类。同时，作者构建了首个全面的肉牛OGI甲烷排放数据集。

Result: GasTwinFormer在甲烷分割上达到74.47% mIoU和83.63% mF1，同时保持卓越效率（3.348M参数, 3.428G FLOPs, 114.9 FPS）。饮食分类准确率达100%，证明了利用饮食-排放相关性的有效性。

Conclusion: GasTwinFormer是实时牲畜排放监测的实用解决方案，其各组件通过广泛的消融研究验证，并能有效利用饮食-排放相关性。

Abstract: Livestock methane emissions represent 32% of human-caused methane production,
making automated monitoring critical for climate mitigation strategies. We
introduce GasTwinFormer, a hybrid vision transformer for real-time methane
emission segmentation and dietary classification in optical gas imaging through
a novel Mix Twin encoder alternating between spatially-reduced global attention
and locally-grouped attention mechanisms. Our architecture incorporates a
lightweight LR-ASPP decoder for multi-scale feature aggregation and enables
simultaneous methane segmentation and dietary classification in a unified
framework. We contribute the first comprehensive beef cattle methane emission
dataset using OGI, containing 11,694 annotated frames across three dietary
treatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation
while maintaining exceptional efficiency with only 3.348M parameters, 3.428G
FLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect
dietary classification accuracy (100%), demonstrating the effectiveness of
leveraging diet-emission correlations. Extensive ablation studies validate each
architectural component, establishing GasTwinFormer as a practical solution for
real-time livestock emission monitoring. Please see our project page at
gastwinformer.github.io.

</details>


### [19] [CurveFlow: Curvature-Guided Flow Matching for Image Generation](https://arxiv.org/abs/2508.15093)
*Yan Luo,Drake Du,Hao Huang,Yi Fang,Mengyu Wang*

Main category: cs.CV

TL;DR: 本文提出CurveFlow，一个通过引入曲率指导来学习平滑、非线性轨迹的流匹配框架，显著提升了文本到图像生成的语义一致性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有的整流流模型基于数据与噪声之间的线性轨迹，强制零曲率，可能导致生成过程穿过数据流形的低概率区域。文章旨在探索轨迹曲率与生成图像的语义对齐（即指令依从性）之间的关系，认为此问题尚未被充分研究。

Method: 引入CurveFlow，一种新颖的流匹配框架，通过直接将曲率指导融入流路径来学习平滑、非线性轨迹。该方法采用了一种鲁棒的曲率正则化技术，惩罚轨迹内在动力学中的突然变化。

Result: 在MS COCO 2014和2017上的大量实验表明，CurveFlow在文本到图像生成方面达到了最先进的性能，显著优于标准整流流变体和其他非线性基线（如Rectified Diffusion）。尤其在BLEU、METEOR、ROUGE和CLAIR等语义一致性指标上，改进尤为明显。

Conclusion: 研究证实，曲率感知建模显著增强了模型忠实遵循复杂指令的能力，同时保持了高图像质量，从而改进了文本到图像的生成效果。

Abstract: Existing rectified flow models are based on linear trajectories between data
and noise distributions. This linearity enforces zero curvature, which can
inadvertently force the image generation process through low-probability
regions of the data manifold. A key question remains underexplored: how does
the curvature of these trajectories correlate with the semantic alignment
between generated images and their corresponding captions, i.e., instructional
compliance? To address this, we introduce CurveFlow, a novel flow matching
framework designed to learn smooth, non-linear trajectories by directly
incorporating curvature guidance into the flow path. Our method features a
robust curvature regularization technique that penalizes abrupt changes in the
trajectory's intrinsic dynamics.Extensive experiments on MS COCO 2014 and 2017
demonstrate that CurveFlow achieves state-of-the-art performance in
text-to-image generation, significantly outperforming both standard rectified
flow variants and other non-linear baselines like Rectified Diffusion. The
improvements are especially evident in semantic consistency metrics such as
BLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling
substantially enhances the model's ability to faithfully follow complex
instructions while simultaneously maintaining high image quality. The code is
made publicly available at
https://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 本文提出一种基于图信号处理（GSP）的完全谱域神经-符号推理架构，将整个推理流程在图谱域中实现，并在多个基准测试中提升了逻辑一致性、可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的推理模型将谱图方法视为辅助组件，而本研究旨在以图信号处理（GSP）为核心计算骨干，深度整合符号逻辑与神经网络推理，以提供一个数学严谨、计算高效且更具可解释性的推理系统。

Method: 该方法构建了一个完全谱域的神经-符号推理架构，将整个推理流程置于图谱域中。逻辑实体和关系被编码为图信号，通过可学习的谱滤波器进行处理以控制多尺度信息传播，并最终映射为符号谓词用于基于规则的推理。文章提出了包括图傅里叶变换、频带选择性注意力机制和谱规则接地在内的完整数学框架。

Result: 在ProofWriter、EntailmentBank、bAbI、CLUTRR和ARC-Challenge等基准推理数据集上的实验表明，该方法在逻辑一致性、可解释性和计算效率方面均优于现有最先进的神经-符号模型。

Conclusion: 研究结果表明，图信号处理（GSP）为构建稳健且可解释的推理系统提供了一个数学上严谨且计算高效的底层基础。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [21] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 本文提出一个计算框架，认为世界模型的描述性（状态表征）和规范性（奖励函数）方面并非独立，而是从智能体与环境的交互经验中共同涌现。引入“目的状态”（telic states）概念，以简化目标导向学习的解释。


<details>
  <summary>Details</summary>
Motivation: 现有计算模型（如强化学习）将世界模型的描述性（状态表征）和规范性（奖励函数）视为独立组件。本研究的动机是探索一种尚未在计算上得到阐述的替代可能性：这两种方面从智能体的目标中相互依存地共同涌现。

Method: 提出一个认知智能体中目标导向状态表征的计算框架。该框架认为世界模型的描述性和规范性方面从智能体-环境交互序列（即经验）中共同涌现。借鉴佛教认识论，引入了目标导向的“目的状态”（telic states）概念，将其定义为目标等价经验分布的类别。

Result: “目的状态”提供了一种精简的目标导向学习解释，将其定义为行为策略与期望经验特征之间的统计差异。文章回顾了支持这一新颖视角的经验和理论文献。

Conclusion: 提出的新视角和“目的状态”概念有望为不同基质中有目的行为的行为、现象学和神经维度提供统一的解释。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [22] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: 本文提出了Collab-REC，一个多智能体框架，通过结合LLM智能体和非LLM协调器，解决旅游推荐中的流行度偏差，提升推荐多样性和整体相关性。


<details>
  <summary>Details</summary>
Motivation: 解决旅游推荐系统中流行的流行度偏差问题，增强推荐多样性，并应对过度旅游的挑战，同时更好地满足用户特定需求。

Method: Collab-REC框架包含三个基于LLM的智能体（个性化、流行度、可持续性），它们从互补视角生成城市建议。一个非LLM协调器通过多轮协商机制，合并并精炼这些建议，确保各方观点被采纳并过滤无效信息。

Result: 在欧洲城市查询的实验中，Collab-REC相比单智能体基线，显著提升了推荐的多样性和整体相关性，成功地推荐了许多常被忽视的、访问量较少的地点。

Conclusion: Collab-REC提供了一种平衡且上下文感知的旅游推荐方法，有效解决了过度旅游问题并更好地满足用户约束。研究强调了在LLM驱动的推荐系统中，多利益相关者协作的巨大潜力。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [23] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 本文提出一种利用大型语言模型（LLMs）进行人群模拟的新方法，通过集成对话系统和语言驱动导航，使智能体能基于感知输入和实时对话做出运动决策，从而生成更真实、具有自然涌现群体行为的人群动画。


<details>
  <summary>Details</summary>
Motivation: 现有基于智能体的人群模拟方法，其智能体间的交互和智能体与环境的交互主要局限于转向和预设目标，未能充分考虑人类导航和移动中受语言和对话驱动的复杂社会及环境互动。这导致动画效果不够真实，缺乏关键的人类行为维度。

Method: 本研究提出了一种利用LLMs控制智能体运动的新方法，包含两个主要组件：1. 对话系统：根据智能体的个性、角色、愿望及与邻近智能体的空间和社会关系，周期性地查询以智能体为中心的LLMs，生成智能体间的对话。2. 语言驱动导航：利用对话内容、智能体的个性、情绪状态、视觉和物理状态来控制每个智能体的导航和转向。该模型使智能体能够基于感知输入和实时对话做出运动决策。

Result: 该方法在两个复杂场景中得到验证，展示了社会交互、转向和人群拥挤之间的相互作用。实验观察到智能体的自动分组和解组行为。此外，研究表明该方法充当了人群内部的信息传递机制。这些结果使得框架能够生成更真实的人群模拟。

Conclusion: 本框架通过将LLMs引入人群模拟，使其能够产生更真实的人群模拟，其中群体行为能够自然地从任何环境设置中涌现。这表明对话和语言驱动的导航显著提升了人群模拟的现实性。

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [24] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: LLMs在知识密集型任务中进行置信度评估时，深度推理预算反而导致过度自信，而通过检索增强生成能显著提高准确性，表明信息获取是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为问答工具部署时需要可靠的校准以避免过度自信。本研究旨在系统评估推理能力和预算如何影响置信度评估的准确性。

Method: 研究人员使用ClimateX数据集并将其扩展到人类和地球健康领域，系统评估了推理能力和预算对置信度评估准确性的影响。他们比较了纯推理LLM与搜索增强生成模型在评估专家置信度方面的表现。

Result: 最新的推理LLMs在评估专家置信度方面的准确率为48.7%。然而，增加推理预算反而会损害校准，导致系统性过度自信，且随着思考预算的增加而恶化。相反，搜索增强生成模型通过检索相关证据，准确率达到了89.3%，显著优于纯推理模型。

Conclusion: 本研究结果挑战了“测试时间扩展”范式，并表明对于知识密集型任务，信息获取而非推理深度或推理预算，可能是提高置信度校准的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [25] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: JPL与Ubotica正在CogniSAT-6/HAMMER (CS-6)卫星上演示先进的星载数据分析，利用其高光谱仪器和神经网络加速硬件。


<details>
  <summary>Details</summary>
Motivation: 在边缘（如星载）进行数据分析能够实现新的地球科学测量和响应。

Method: 利用CS-6的可见光和近红外高光谱仪器以及神经网络加速硬件，采用深度学习和光谱分析算法进行星载数据分析和推理。

Result: 在CS-6上成功演示了最先进的星载数据分析能力，并将针对多种应用进行数据分析和推理的演示。

Conclusion: 星载数据分析是实现新地球科学测量和快速响应的关键技术。

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [26] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: LoRA微调大语言模型(LLMs)可能损害安全对齐。本文提出S3LoRA，一个轻量级、数据无关、模型独立的框架，通过分析LoRA微调后的权重更新，识别并剪枝潜在不安全层，从而提高LLM代理的安全性、保持实用性并降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 使用参数高效微调(PEFT)技术（如LoRA）适应LLM可以赋能强大的LLM代理，但可能无意中损害安全对齐，导致不安全行为，尤其是在代理规划任务中。现有安全感知适应方法通常需要基础模型和指令微调模型的检查点，这些在实践中往往不可用，限制了其适用性。

Method: 本文提出S3LoRA (Safe Spectral Sharpness-Guided Pruning LoRA)框架。首先引入“幅度感知球形归一化SVD (MAS-SVD)”来鲁棒分析LoRA更新的结构属性并保留全局幅度信息。接着设计“谱锐度指数 (SSI)”作为锐度感知指标，用于检测具有高度集中且可能不安全更新的层。最后，对这些层进行事后剪枝以降低安全风险，同时不牺牲任务性能。

Result: 在代理规划和语言生成任务上进行的广泛实验和消融研究表明，S3LoRA能够持续改进安全指标，同时保持或提升实用性指标，并显著降低推理成本。

Conclusion: S3LoRA为在真实世界、资源受限和安全关键环境中安全部署基于LLM的代理提供了一种实用且可扩展的解决方案。

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [27] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出将劳动力管理问题建模为抽象论证，以应对执行时变化并提供解释。用户研究表明，该方法比传统手动解决方案能更快、更准确地解决问题。


<details>
  <summary>Details</summary>
Motivation: 劳动力管理面临一个关键挑战：在执行时难以适应变化，并且无法为所有利益相关者提供充分的解释。

Method: 将劳动力管理理解为工业应用中的“抽象论证”（abstract argumentation）。

Result: 通过一项用户研究表明，开发的工具和解释比传统手工解决方案能带来更快、更准确的问题解决。

Conclusion: 通过将劳动力管理视为抽象论证，能够有效应对变化并提供忠实解释，从而提高问题解决的效率和准确性。

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving](https://arxiv.org/abs/2508.14926)
*Dianzhao Li,Ostap Okhrin*

Main category: cs.LG

TL;DR: 本文提出了一个分层的安全强化学习（Safe RL）框架，用于在真实世界场景中为自动驾驶汽车整合道德考量与驾驶目标，有效降低伦理风险并保持驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的广泛应用取决于其在常规和紧急操作中嵌入强大的道德推理能力，以减少交通事故并提高交通效率。

Method: 采用分层Safe RL框架：决策层使用结合碰撞概率和伤害严重性的复合伦理风险成本训练Safe RL智能体，并通过动态优先经验回放机制强化学习；执行层利用多项式路径规划结合PID和Stanley控制器将决策转换为平滑可行的轨迹。

Result: 在包含多样化真实世界交通数据集上验证，该方法在降低伦理风险和保持驾驶性能方面优于基线方法。这是首次在真实场景中通过Safe RL研究自动驾驶汽车的伦理决策。

Conclusion: 结合形式化控制理论和数据驱动学习的方法，有潜力在复杂的人车混合交通环境中推进伦理责任型自动驾驶技术的发展。

Abstract: Autonomous vehicles hold great promise for reducing traffic fatalities and
improving transportation efficiency, yet their widespread adoption hinges on
embedding robust ethical reasoning into routine and emergency maneuvers. Here,
we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that
explicitly integrates moral considerations with standard driving objectives. At
the decision level, a Safe RL agent is trained using a composite ethical risk
cost, combining collision probability and harm severity, to generate high-level
motion targets. A dynamic Prioritized Experience Replay mechanism amplifies
learning from rare but critical, high-risk events. At the execution level,
polynomial path planning coupled with Proportional-Integral-Derivative (PID)
and Stanley controllers translates these targets into smooth, feasible
trajectories, ensuring both accuracy and comfort. We train and validate our
approach on rich, real-world traffic datasets encompassing diverse vehicles,
cyclists, and pedestrians, and demonstrate that it outperforms baseline methods
in reducing ethical risk and maintaining driving performance. To our knowledge,
this is the first study of ethical decision-making for autonomous vehicles via
Safe RL in real-world scenarios. Our results highlight the potential of
combining formal control theory and data-driven learning to advance ethically
accountable autonomy in complex, human-mixed traffic environments.

</details>


### [29] [Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework](https://arxiv.org/abs/2508.14940)
*Chongyu Qu,Allen J. Luna,Thomas Z. Li,Junchao Zhu,Junlin Guo,Juming Xiong,Kim L. Sandler,Bennett A. Landman,Yuankai Huo*

Main category: cs.LG

TL;DR: 提出一个利用FAISS检索和LLM推理的个性化代理，根据患者特征动态选择最优肺癌风险预测模型，以解决现有模型在不同群体中表现不一的挑战。


<details>
  <summary>Details</summary>
Motivation: 肺癌风险预测因患者群体和临床环境的显著差异而面临挑战，没有单一模型能在所有队列中表现最佳。

Method: 本研究提出一个个性化肺癌风险预测代理：1. **队列检索**：给定患者CT扫描和结构化元数据，使用FAISS基于相似性搜索，从九个多机构数据库中的真实世界队列中识别最相关的患者群体。2. **模型推理**：利用大型语言模型（LLM）结合检索到的队列及其性能指标，从八种代表性预测模型（包括经典线性模型、时序感知模型和多模态计算机视觉模型）中推荐最佳算法。该方法是一个FAISS检索与LLM推理相结合的两阶段管道。

Result: 所提出的两阶段代理管道（通过FAISS检索和通过LLM推理）实现了动态的、队列感知的风险预测，能够根据每位患者的特征进行个性化。

Conclusion: 该代理架构支持跨不同临床人群的灵活、队列驱动的模型选择，为现实世界肺癌筛查中的个体化风险评估提供了一条实用途径。

Abstract: Accurate lung cancer risk prediction remains challenging due to substantial
variability across patient populations and clinical settings -- no single model
performs best for all cohorts. To address this, we propose a personalized lung
cancer risk prediction agent that dynamically selects the most appropriate
model for each patient by combining cohort-specific knowledge with modern
retrieval and reasoning techniques. Given a patient's CT scan and structured
metadata -- including demographic, clinical, and nodule-level features -- the
agent first performs cohort retrieval using FAISS-based similarity search
across nine diverse real-world cohorts to identify the most relevant patient
population from a multi-institutional database. Second, a Large Language Model
(LLM) is prompted with the retrieved cohort and its associated performance
metrics to recommend the optimal prediction algorithm from a pool of eight
representative models, including classical linear risk models (e.g., Mayo,
Brock), temporally-aware models (e.g., TDVIT, DLSTM), and multi-modal computer
vision-based approaches (e.g., Liao, Sybil, DLS, DLI). This two-stage agent
pipeline -- retrieval via FAISS and reasoning via LLM -- enables dynamic,
cohort-aware risk prediction personalized to each patient's profile. Building
on this architecture, the agent supports flexible and cohort-driven model
selection across diverse clinical populations, offering a practical path toward
individualized risk assessment in real-world lung cancer screening.

</details>


### [30] [Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction](https://arxiv.org/abs/2508.14942)
*Jiacheng Hu,Bo Zhang,Ting Xu,Haifeng Yang,Min Gao*

Main category: cs.LG

TL;DR: 本研究提出一种统一的帕金森病进展预测框架，结合图神经网络和Transformer，有效整合症状结构关系与动态时间特征，并在真实数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 帕金森病进展预测面临症状演变复杂且时间依赖建模不足的挑战，现有方法难以有效捕捉多模态症状间的结构关系和动态时间特征。

Method: 本研究提出一个统一的预测框架，整合结构感知和时间建模。具体方法包括：1. 利用图神经网络（GNN）建模多模态临床症状的结构关系和语义依赖。2. 采用Transformer架构建模疾病进展中的动态时间特征。3. 设计结构感知门控机制，动态融合结构编码与时间特征，以识别关键进展阶段。4. 框架包含图构建、时间编码和预测输出层等模块，以提高准确性和稳定性。5. 在真实纵向帕金森病数据上进行评估，并与主流模型进行比较。

Result: 所提方法在AUC、RMSE和IPW-F1等指标上均优于现有方法。它能有效区分疾病进展阶段，并提升模型捕捉个性化症状轨迹的能力。

Conclusion: 该统一框架展现出强大的泛化能力和结构可扩展性，为帕金森病等慢性进行性疾病的智能建模提供了可靠支持。

Abstract: This study addresses the challenges of symptom evolution complexity and
insufficient temporal dependency modeling in Parkinson's disease progression
prediction. It proposes a unified prediction framework that integrates
structural perception and temporal modeling. The method leverages graph neural
networks to model the structural relationships among multimodal clinical
symptoms and introduces graph-based representations to capture semantic
dependencies between symptoms. It also incorporates a Transformer architecture
to model dynamic temporal features during disease progression. To fuse
structural and temporal information, a structure-aware gating mechanism is
designed to dynamically adjust the fusion weights between structural encodings
and temporal features, enhancing the model's ability to identify key
progression stages. To improve classification accuracy and stability, the
framework includes a multi-component modeling pipeline, consisting of a graph
construction module, a temporal encoding module, and a prediction output layer.
The model is evaluated on real-world longitudinal Parkinson's disease data. The
experiments involve comparisons with mainstream models, sensitivity analysis of
hyperparameters, and graph connection density control. Results show that the
proposed method outperforms existing approaches in AUC, RMSE, and IPW-F1
metrics. It effectively distinguishes progression stages and improves the
model's ability to capture personalized symptom trajectories. The overall
framework demonstrates strong generalization and structural scalability,
providing reliable support for intelligent modeling of chronic progressive
diseases such as Parkinson's disease.

</details>


### [31] [HHNAS-AM: Hierarchical Hybrid Neural Architecture Search using Adaptive Mutation Policies](https://arxiv.org/abs/2508.14946)
*Anurag Tripathi,Ajeet Kumar Singh,Rajsabi Surya,Aum Gupta,Sahiinii Lemaina Veikho,Dorien Herremans,Sudhir Bisane*

Main category: cs.LG

TL;DR: 针对文本分类中NAS模型搜索空间巨大且冗余的问题，本文提出HHNAS-AM，通过引入分层混合结构、架构模板和基于Q学习的自适应变异策略，有效探索架构配置，并在Spider数据集上实现了8%的测试准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的文本分类神经架构搜索（NAS）模型缺乏混合分层结构和架构限制，导致搜索空间巨大、冗余且无组织，使得现有强化学习模型难以有效导航和遍历。

Method: 本文提出HHNAS-AM（分层混合神经架构搜索与自适应变异策略），该方法通过以下方式高效探索：1. 引入基于领域特定线索的架构模板来组织搜索空间。2. 采用基于Q学习的自适应变异策略，根据前期性能反馈动态调整，实现更有效、加速的搜索空间遍历。3. 该模型是完全概率性的，能有效探索搜索空间。

Result: 在database id (db_id) 预测任务上，HHNAS-AM持续发现高性能架构。在Spider数据集上，本文方法比现有基线在测试准确率上提高了8%。

Conclusion: HHNAS-AM通过引入分层混合结构和自适应变异策略，有效解决了文本分类中NAS模型搜索空间巨大且无组织的问题，成功发现了高性能架构，并在关键数据集上实现了显著的性能提升。

Abstract: Neural Architecture Search (NAS) has garnered significant research interest
due to its capability to discover architectures superior to manually designed
ones. Learning text representation is crucial for text classification and other
language-related tasks. The NAS model used in text classification does not have
a Hybrid hierarchical structure, and there is no restriction on the
architecture structure, due to which the search space becomes very large and
mostly redundant, so the existing RL models are not able to navigate the search
space effectively. Also, doing a flat architecture search leads to an
unorganised search space, which is difficult to traverse. For this purpose, we
propose HHNAS-AM (Hierarchical Hybrid Neural Architecture Search with Adaptive
Mutation Policies), a novel approach that efficiently explores diverse
architectural configurations. We introduce a few architectural templates to
search on which organise the search spaces, where search spaces are designed on
the basis of domain-specific cues. Our method employs mutation strategies that
dynamically adapt based on performance feedback from previous iterations using
Q-learning, enabling a more effective and accelerated traversal of the search
space. The proposed model is fully probabilistic, enabling effective
exploration of the search space. We evaluate our approach on the database id
(db_id) prediction task, where it consistently discovers high-performing
architectures across multiple experiments. On the Spider dataset, our method
achieves an 8% improvement in test accuracy over existing baselines.

</details>


### [32] [Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization](https://arxiv.org/abs/2508.14947)
*Rui Wang,Qianguo Sun,Chao Song,Junlong Wu,Tianrong Chen,Zhiyun Zeng,Yu Li*

Main category: cs.LG

TL;DR: 本文提出LPO（线性偏好优化）框架，通过梯度解耦、稳定性改进和可控拒绝抑制，解决了DPO的过拟合和崩溃问题，并在多项任务上展现了持续的性能提升。


<details>
  <summary>Details</summary>
Motivation: DPO（直接偏好优化）算法虽然简单稳定，但存在易过拟合和模型崩溃的问题。

Method: 提出LPO（线性偏好优化）框架，包含三项创新：1) 梯度解耦，用绝对差损失替换log-sigmoid函数；2) 稳定性改进，通过偏移约束和正向正则化保持优质响应；3) 可控拒绝抑制，利用梯度分离和可调系数线性调节拒绝概率下降。

Result: LPO在通用文本、数学和文本转语音（TTS）等多种任务上持续改进了性能。

Conclusion: LPO被确立为一种鲁棒且可调的偏好对齐范式，并已公开源代码、模型和训练数据。

Abstract: DPO (Direct Preference Optimization) has become a widely used offline
preference optimization algorithm due to its simplicity and training stability.
However, DPO is prone to overfitting and collapse. To address these challenges,
we propose Linear Preference Optimization (LPO), a novel alignment framework
featuring three key innovations. First, we introduce gradient decoupling by
replacing the log-sigmoid function with an absolute difference loss, thereby
isolating the optimization dynamics. Second, we improve stability through an
offset constraint combined with a positive regularization term to preserve the
chosen response quality. Third, we implement controllable rejection suppression
using gradient separation with straightforward estimation and a tunable
coefficient that linearly regulates the descent of the rejection probability.
Through extensive experiments, we demonstrate that LPO consistently improves
performance on various tasks, including general text tasks, math tasks, and
text-to-speech (TTS) tasks. These results establish LPO as a robust and tunable
paradigm for preference alignment, and we release the source code, models, and
training data publicly.

</details>


### [33] [Large Foundation Model for Ads Recommendation](https://arxiv.org/abs/2508.14948)
*Shangyu Zhang,Shijie Quan,Zhongren Wang,Junwei Pan,Tianqu Zhuang,Bo Fu,Yilong Sun,Jieying Lin,Jushuo Chen,Xiaotian Li,Zhixiang Feng,Xian Hu,Huiting Deng,Hua Lu,Jinpeng Wang,Boqi Dai,Xiaoyu Chen,Bin Hu,Lili Huang,Yanwen Wu,Yeshou Cai,Qi Zhou,Huang Tang,Chunfeng Yang,Chengguo Yin,Tingyu Jiang,Lifeng Wang,Shudong Huang,Dapeng Liu,Lei Xiao,Haijie Gu,Shu-Tao Xia,Jie Jiang*

Main category: cs.LG

TL;DR: 本文提出了LFM4Ads，一个针对广告推荐的“全表示多粒度”迁移框架，通过全面利用预训练基础模型的各种表示并采用多粒度迁移机制，显著提升了广告效果，并已在工业界成功部署。


<details>
  <summary>Details</summary>
Motivation: 现有广告推荐模型在利用预训练大模型时存在局限性：它们仅提取并迁移用户表示（URs），忽略了有价值的物品表示（IRs）和用户-物品交叉表示（CRs）；并且简单地将UR作为下游应用的特征，未能有效弥合上下游差距，也忽视了更细致的迁移粒度。

Method: 本文提出了LFM4Ads框架。首先，它全面迁移预训练基础模型中所有可用的表示，包括URs、IRs和CRs。为有效利用CRs，LFM4Ads识别最佳提取层并将其聚合为可迁移的粗粒度形式。此外，通过多粒度机制增强迁移能力：使用非线性适配器实现特征级迁移，同构交互模块实现模块级迁移，以及独立检索实现模型级迁移。

Result: LFM4Ads已成功部署在腾讯的工业级广告平台，处理日均数百亿样本，维护TB级模型参数和数十亿稀疏嵌入键。自2024年第四季度部署以来，已在微信朋友圈和视频号等10多个主要广告场景成功上线，使整个平台的GMV提升了2.45%，预计每年带来数亿美元的收入增长。

Conclusion: LFM4Ads通过其创新性的“全表示多粒度”迁移框架，有效解决了现有方法的局限性，显著提升了广告推荐的准确性和经济效益，并在大规模工业应用中得到了成功验证，展示了其巨大的实用价值和商业潜力。

Abstract: Online advertising relies on accurate recommendation models, with recent
advances using pre-trained large-scale foundation models (LFMs) to capture
users' general interests across multiple scenarios and tasks. However, existing
methods have critical limitations: they extract and transfer only user
representations (URs), ignoring valuable item representations (IRs) and
user-item cross representations (CRs); and they simply use a UR as a feature in
downstream applications, which fails to bridge upstream-downstream gaps and
overlooks more transfer granularities. In this paper, we propose LFM4Ads, an
All-Representation Multi-Granularity transfer framework for ads recommendation.
It first comprehensively transfers URs, IRs, and CRs, i.e., all available
representations in the pre-trained foundation model. To effectively utilize the
CRs, it identifies the optimal extraction layer and aggregates them into
transferable coarse-grained forms. Furthermore, we enhance the transferability
via multi-granularity mechanisms: non-linear adapters for feature-level
transfer, an Isomorphic Interaction Module for module-level transfer, and
Standalone Retrieval for model-level transfer. LFM4Ads has been successfully
deployed in Tencent's industrial-scale advertising platform, processing tens of
billions of daily samples while maintaining terabyte-scale model parameters
with billions of sparse embedding keys across approximately two thousand
features. Since its production deployment in Q4 2024, LFM4Ads has achieved 10+
successful production launches across various advertising scenarios, including
primary ones like Weixin Moments and Channels. These launches achieve an
overall GMV lift of 2.45% across the entire platform, translating to estimated
annual revenue increases in the hundreds of millions of dollars.

</details>


### [34] [Quantum Long Short-term Memory with Differentiable Architecture Search](https://arxiv.org/abs/2508.14955)
*Samuel Yen-Chi Chen,Prayag Tiwari*

Main category: cs.LG

TL;DR: 本文提出了DiffQAS-QLSTM，一个端到端可微分框架，用于自动化量子循环神经网络（QLSTM）中的变分量子电路（VQC）设计，其性能优于手动设计基线，有望实现可扩展的量子序列学习。


<details>
  <summary>Details</summary>
Motivation: 设计高效且针对特定任务的变分量子电路（VQC）对于量子循环模型（如QLSTM）来说仍然是一个挑战。

Method: 提出了DiffQAS-QLSTM，一个端到端可微分框架，在训练过程中同时优化VQC参数和架构选择。

Result: DiffQAS-QLSTM在不同的测试设置中始终优于手工设计的基线，并取得了更低的损失。

Conclusion: 该方法为可扩展和自适应的量子序列学习开辟了道路。

Abstract: Recent advances in quantum computing and machine learning have given rise to
quantum machine learning (QML), with growing interest in learning from
sequential data. Quantum recurrent models like QLSTM are promising for
time-series prediction, NLP, and reinforcement learning. However, designing
effective variational quantum circuits (VQCs) remains challenging and often
task-specific. To address this, we propose DiffQAS-QLSTM, an end-to-end
differentiable framework that optimizes both VQC parameters and architecture
selection during training. Our results show that DiffQAS-QLSTM consistently
outperforms handcrafted baselines, achieving lower loss across diverse test
settings. This approach opens the door to scalable and adaptive quantum
sequence learning.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [35] [Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer](https://arxiv.org/abs/2508.15058)
*Kaiqiang Lin,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文提出并评估了一种新的空-天-地-下综合网络（SAGUIN）架构，该架构结合LoRaWAN和无线能量传输（WET）技术，旨在解决恶劣地下环境中无线地下传感器网络（WUSNs）可持续大规模机器类通信（mMTC）的挑战。


<details>
  <summary>Details</summary>
Motivation: 无线地下传感器网络（WUSNs）在地下资源监测方面潜力巨大，但受制于恶劣的地下环境、稀缺的网络资源和有限的通信覆盖，难以在偏远、灾区等困难区域支持可持续的大规模机器类通信（mMTC）。

Method: 本研究概念化了一种新颖的空-天-地-下综合网络（SAGUIN）架构，该架构无缝整合了卫星系统、空中平台、地面网络和地下通信。在此基础上，将LoRaWAN和无线能量传输（WET）技术集成到SAGUIN中。通过仿真模拟远程地下管道监测场景，评估了SAGUIN在不同地下条件、时间分配、LoRaWAN扩频因子（SF）配置、报告周期和能量收集水平等参数下的可行性和性能。

Result: 仿真结果表明，所提出的SAGUIN系统，结合推导出的时间分配策略和适当的扩频因子，能够有效延长地下设备的运行寿命，从而促进可持续的地下大规模机器类通信（mMTC）。

Conclusion: SAGUIN系统与LoRaWAN和WET技术的结合，通过延长地下设备的运行寿命，为实现可持续的地下大规模机器类通信（mMTC）提供了有效的解决方案。研究还指出了SAGUIN面临的关键挑战和未来的研究方向。

Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing
and monitoring of underground resources by underground devices (UDs), hold
great promise for delivering substantial social and economic benefits across
various verticals. However, due to the harsh subterranean environment, scarce
network resources, and restricted communication coverage, WUSNs face
significant challenges in supporting sustainable massive machine-type
communications (mMTC), particularly in remote, disaster-stricken, and
hard-to-reach areas. To complement this, we conceptualize in this study a novel
space-air-ground-underground integrated network (SAGUIN) architecture that
seamlessly incorporates satellite systems, aerial platforms, terrestrial
networks, and underground communications. On this basis, we integrate LoRaWAN
and wireless energy transfer (WET) technologies into SAGUIN to enable
sustainable subterranean mMTC. We begin by reviewing the relevant technical
background and presenting the architecture and implementation challenges of
SAGUIN. Then, we employ simulations to model a remote underground pipeline
monitoring scenario to evaluate the feasibility and performance of SAGUIN based
on LoRaWAN and WET technologies, focusing on the effects of parameters such as
underground conditions, time allocation, LoRaWAN spread factor (SF)
configurations, reporting periods, and harvested energy levels. Our results
evidence that the proposed SAGUIN system, when combined with the derived time
allocation strategy and an appropriate SF, can effectively extend the
operational lifetime of UDs, thereby facilitating sustainable subterranean
mMTC. Finally, we pinpoint key challenges and future research directions for
SAGUIN.

</details>


### [36] [From 5G RAN Queue Dynamics to Playback: A Performance Analysis for QUIC Video Streaming](https://arxiv.org/abs/2508.15087)
*Jashanjot Singh Sidhu,Jorge Ignacio Sandoval,Abdelhak Bentaleb,Sandra Cespedes*

Main category: cs.NI

TL;DR: 在5G QUIC视频流中，QoE优化面临挑战，因应用层、传输层和链路层间存在复杂交互，单独优化不足以解决问题。


<details>
  <summary>Details</summary>
Motivation: 尽管5G网络和QUIC协议提升了视频传输能力，但在移动网络中优化高分辨率视频的QoE仍面临挑战。这是由于应用层ABR、传输层CC算法和链路层RLC队列在5G环境中存在复杂的相互作用。现有研究大多孤立地分析这些组件。

Method: 本文对RED和L4S等现代AQM策略在不同QUIC实现下对视频流的影响进行了全面分析。研究重点关注AQM与5G环境下RLC缓冲区的交互作用，以及CC算法与ABR方案之间的相互作用。

Result: 研究表明，AQM策略在改善视频流QoE方面的有效性与它们和QUIC实现、CC算法及ABR方案的动态交互紧密相关。结果指出，孤立的优化方案不足以有效提升QoE。

Conclusion: 为充分发挥5G网络提供高质量视频流的潜力，需要建立能够实时协调网络、传输和应用层的整体性、跨层自适应机制。

Abstract: The rapid adoption of QUIC as a transport protocol has transformed content
delivery by reducing latency, enhancing congestion control (CC), and enabling
more efficient multiplexing. With the advent of 5G networks, which support
ultra-low latency and high bandwidth, streaming high-resolution video at 4K and
beyond has become increasingly viable. However, optimizing Quality of
Experience (QoE) in mobile networks remains challenging due to the complex
interactions among Adaptive Bit Rate (ABR) schemes at the application layer, CC
algorithms at the transport layer, and Radio Link Control (RLC) queuing at the
link layer in the 5G network. While prior studies have largely examined these
components in isolation, this work presents a comprehensive analysis of the
impact of modern active queue management (AQM) strategies, such as RED and L4S,
on video streaming over diverse QUIC implementations--focusing particularly on
their interaction with the RLC buffer in 5G environments and the interplay
between CC algorithms and ABR schemes. Our findings demonstrate that the
effectiveness of AQM strategies in improving video streaming QoE is
intrinsically linked to their dynamic interaction with QUIC implementations, CC
algorithms and ABR schemes-highlighting that isolated optimizations are
insufficient. This intricate interdependence necessitates holistic, cross-layer
adaptive mechanisms capable of real-time coordination between network,
transport and application layers, which are crucial for fully leveraging the
capabilities of 5G networks to deliver robust, adaptive, and high-quality video
streaming.

</details>


### [37] [Toward Autonomous Digital Populations for Communication-Sensing-Computation Ecosystem](https://arxiv.org/abs/2508.15268)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出一个受自然启发的架构框架，利用数字孪生技术在边缘构建数字种群并在云端集成形成数字生态系统，以解决未来通信网络在分布式决策、自适应和演进能力方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前通信网络过度依赖中心化控制、静态设计和人工干预，严重制约了网络功能和应用的演进，并限制了其在复杂环境中的适应性和弹性，无法满足未来通信、感知、计算深度融合的需求。

Method: 本文提出一个受自然启发的架构框架，该框架利用数字孪生技术将边缘连接设备组织成功能性数字种群，并通过在云端集成多数字种群，实现可演进的数字生态系统。

Result: 该框架为构建具备动态协调、分布式决策、持续适应和演进能力的新一代通信网络奠定了理论基础。

Conclusion: 该框架结合了工程方法和社会技术洞察，为构建下一代深度融合通信、感知、计算的网络提供了理论支撑，旨在实现网络的动态协调、分布式决策、持续适应和演进能力。

Abstract: Future communication networks are expected to achieve deep integration of
communication, sensing, and computation, forming a tightly coupled and
autonomously operating infrastructure system. However, current reliance on
centralized control, static design, and human intervention continues to
constrain the multidimensional evolution of network functions and applications,
limiting adaptability and resilience in large-scale, layered, and complex
environments. To address these challenges, this paper proposes a
nature-inspired architectural framework that leverages digital twin technology
to organize connected devices at the edge into functional digital populations,
while enabling the emergence of an evolvable digital ecosystem through
multi-population integration at the cloud. We believe that this framework,
which combines engineering methodologies with sociotechnical insights, lays the
theoretical foundation for building next-generation communication networks with
dynamic coordination, distributed decision-making, continuous adaptation, and
evolutionary capabilities.

</details>


### [38] [Unlocking the Performance Potential of Mega-Constellation Networks: An Exploration of Structure-Building Paradigms](https://arxiv.org/abs/2508.15307)
*Xiangtong Wang,Wei Li,Menglong Yang,Songchen Han*

Main category: cs.NI

TL;DR: 本文提出SML（结构=基元+格点）MCN结构设计范式和SMLOP启发式算法，旨在优化巨型星座网络（MCN）结构，通过提高星间链路（ISL）可用性并降低传输延迟，显著提升网络性能。


<details>
  <summary>Details</summary>
Motivation: 巨型星座网络（MCN）中的一个关键问题是如何设计最优网络控制结构，通过配置最稳定的星间链路（ISL），在有限的平均传输延迟下实现高可用MCN，以确保未来空间无线通信网络的效率和可靠性。

Method: 引入“结构=基元+格点”（SML）的MCN结构设计范式，将MCN设计解耦为局部基元设计和全局格点设计。具体地，提出了高可用低延迟巨型星座设计（HALLMD）问题，旨在最大化ISL可用性并最小化传输延迟。为解决HALLMD问题，提出了一种名为SMLOP的启发式算法，能在多项式时间内高效找到最优网络结构。

Result: 在四个公共的现有星座上的实验验证表明，该方法显著提升了网络性能，包括容量增强5%~18%，吞吐量增加1%~12%，路径伸缩比降低12%~23%，往返时间（RTT）缩短8%~77%。

Conclusion: 通过SML范式和SMLOP算法，能够高效设计并优化巨型星座网络结构，显著提升其容量、吞吐量，并大幅降低延迟和路径伸缩比，为未来空间无线通信网络提供高可用、低延迟的解决方案。

Abstract: The network structure design plays a vital role in the mega-constellation
network (MSN) to coordinate massive network nodes to ensure the effectiveness
and reliability of operations and services for future space wireless
communications networks.
  One of the critical issues in MCN is how to design an optimal network control
structure by configuring the most stable inter-satellite link (ISL) to achieve
high available MCN within a limited average transmission delays.
  To address this problem, this paper introduces a novel MCN structure design
paradigm: Structure = Motif + Lattice (SML), which decouples MCN design into
local motifs design and global lattices design. Specifically, we formulate the
High-Availability and Low-Latency Mega-Constellation Design (HALLMD) problem,
aimed at maximizing ISL availability while minimizing the transmission latency.
To solve HALLMD, we propose SMLOP, a heuristic algorithm that efficiently finds
optimal network structures in polynomial time. Experimental validation on four
public state-of-the-art constellations demonstrates significant improvements,
including enhanced capacity by $5\sim 18\%$, increased throughput by $1\sim
12\%$, reduced path stretch by $12\sim 23\%$, and Round-Trip Time (RTT) by
$8\sim 77\%$.

</details>


### [39] [Interface on demand: Towards AI native Control interfaces for 6G](https://arxiv.org/abs/2508.15595)
*Abhishek Dandekar,Prashiddha D. Thapa,Ashrafur Rahman,Julius Schulz-Zander*

Main category: cs.NI

TL;DR: 本文提出一个基于LLM的多智能体框架，用于动态生成网络功能间的控制接口，以解决传统接口的兼容性和适应性问题，并通过模拟环境验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 传统的标准化网络接口面临供应商不兼容、设计僵化以及对新功能缺乏适应性等显著局限。

Method: 提出一个利用大型语言模型（LLMs）的多智能体框架，按需在网络功能（NFs）之间生成控制接口。该框架包括一个匹配智能体（对齐功能与NF能力）和一个代码生成智能体（生成必要的API服务器）。

Result: 通过模拟多供应商gNB和WLAN AP环境验证了所提方法。性能评估揭示了在接口生成任务中，不同LLM的成本与延迟之间的权衡。

Conclusion: 该工作为AI原生动态控制接口生成奠定了基础，有望显著提升未来移动网络的互操作性和适应性。

Abstract: Traditional standardized network interfaces face significant limitations,
including vendor-specific incompatibilities, rigid design assumptions, and lack
of adaptability for new functionalities. We propose a multi-agent framework
leveraging large language models (LLMs) to generate control interfaces on
demand between network functions (NFs). This includes a matching agent, which
aligns required control functionalities with NF capabilities, and a
code-generation agent, which generates the necessary API server for interface
realization. We validate our approach using simulated multi-vendor gNB and WLAN
AP environments. The performance evaluations highlight the trade-offs between
cost and latency across LLMs for interface generation tasks. Our work sets the
foundation for AI-native dynamic control interface generation, paving the way
for enhanced interoperability and adaptability in future mobile networks.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [40] [Holo-Artisan: A Personalized Multi-User Holographic Experience for Virtual Museums on the Edge Intelligence](https://arxiv.org/abs/2508.14956)
*Nan-Hong Kuo,Hojjat Baghban*

Main category: cs.MM

TL;DR: Holo-Artisan是一个通过全息显示和边缘智能，为虚拟博物馆提供沉浸式多用户体验的系统，使数字艺术品能实时个性化响应每位参观者，并利用联邦学习保护隐私。


<details>
  <summary>Details</summary>
Motivation: 将静态博物馆展品转化为动态、生动的艺术品，以实现与参观者的个性化对话，开创文化遗产互动的新范式。

Method: 采用本地边缘计算节点实时处理多用户数据（姿态、面部表情、语音）；利用生成式AI模型驱动数字艺术品对每位观众进行独特响应；通过云辅助协作平台结合共享场景并使用光线追踪渲染高保真、个性化的无眼镜全息显示视图；集成联邦学习以在保护用户隐私的同时持续提升个性化，通过边缘设备本地微调AI模型并共享模型更新。

Result: 实现了沉浸式多用户虚拟博物馆体验，数字艺术品能实时个性化响应每位参观者（如蒙娜丽莎对不同观众微笑或进行问答）；通过边缘中心化方法最小化了延迟和带宽使用，确保了同步的共享体验和个体定制化；将静态博物馆展品转变为动态、生动的艺术品。

Conclusion: Holo-Artisan系统通过全息显示和个性化边缘智能，将静态博物馆展品转化为与每位参观者进行个人对话的动态艺术品，预示着文化遗产互动的新范式。

Abstract: We present Holo-Artisan, a novel system architecture enabling immersive
multi-user experiences in virtual museums through true holographic displays and
personalized edge intelligence. In our design, local edge computing nodes
process real-time user data -- including pose, facial expression, and voice --
for multiple visitors concurrently. Generative AI models then drive digital
artworks (e.g., a volumetric Mona Lisa) to respond uniquely to each viewer. For
instance, the Mona Lisa can return a smile to one visitor while engaging in a
spoken Q\&A with another, all in real time. A cloud-assisted collaboration
platform composes these interactions in a shared scene using a universal scene
description, and employs ray tracing to render high-fidelity, personalized
views with a direct pipeline to glasses-free holographic displays. To preserve
user privacy and continuously improve personalization, we integrate federated
learning (FL) -- edge devices locally fine-tune AI models and share only model
updates for aggregation. This edge-centric approach minimizes latency and
bandwidth usage, ensuring a synchronized shared experience with individual
customization. Through Holo-Artisan, static museum exhibits are transformed
into dynamic, living artworks that engage each visitor in a personal dialogue,
heralding a new paradigm of cultural heritage interaction.

</details>
