<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 4]
- [cs.NI](#cs.NI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English](https://arxiv.org/abs/2504.17974)
*Sabur Butt,Fazlourrahman Balouchzahi,Ahmad Imam Amjad,Maaz Amjad,Hector G. Ceballos,Salud Maria Jimenez-Zafra*

Main category: cs.CL

TL;DR: 本研究介绍了PolyHope V2，一个多语言、细粒度的希望言语数据集，并发现微调的Transformer模型在区分希望子类型和讽刺方面优于大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 希望情绪复杂、研究不足但重要，其细微形式（包括讽刺）难以被现有NLP系统准确检测，缺乏区分讽刺的细粒度数据集。

Method: 构建了一个包含3万多条英/西语推文的多语言细粒度希望言语数据集PolyHope V2（区分四种类型：广义、现实、不现实、讽刺）；使用该数据集对预训练Transformer模型进行微调，并与GPT-4、Llama 3等大型语言模型在零样本和少样本设置下进行基准比较；进行了定性分析和混淆矩阵分析。

Result: 微调的Transformer模型在希望言语检测任务中表现优于基于提示的大型语言模型，尤其是在区分细微的希望类别和讽刺方面；分析揭示了区分相关希望子类型的系统性挑战。

Conclusion: PolyHope V2数据集和研究结果为未来需要更高语义和语境敏感度的跨语言情感识别任务提供了坚实的基础。

Abstract: Hope is a complex and underexplored emotional state that plays a significant
role in education, mental health, and social interaction. Unlike basic
emotions, hope manifests in nuanced forms ranging from grounded optimism to
exaggerated wishfulness or sarcasm, making it difficult for Natural Language
Processing systems to detect accurately. This study introduces PolyHope V2, a
multilingual, fine-grained hope speech dataset comprising over 30,000 annotated
tweets in English and Spanish. This resource distinguishes between four hope
subtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhances
existing datasets by explicitly labeling sarcastic instances. We benchmark
multiple pretrained transformer models and compare them with large language
models (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.
Our findings show that fine-tuned transformers outperform prompt-based LLMs,
especially in distinguishing nuanced hope categories and sarcasm. Through
qualitative analysis and confusion matrices, we highlight systematic challenges
in separating closely related hope subtypes. The dataset and results provide a
robust foundation for future emotion recognition tasks that demand greater
semantic and contextual sensitivity across languages.

</details>


### [2] [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org/abs/2504.17993)
*Brihi Joshi,Xiang Ren,Swabha Swayamdipta,Rik Koncel-Kedziorski,Tim Paek*

Main category: cs.CL

TL;DR: 该研究提出PB&J框架，利用大型语言模型（LLM）生成基于心理学理论的推理，以增强用户画像，从而更准确地预测用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有构建用户画像的方法仅依赖用户的人口统计信息或过往判断，未能捕捉用户判断背后的深层原因。

Method: 引入PB&J框架：使用LLM结合心理学支架（如大五人格、原始世界信念等理论）生成用户行为（经验、个性、信念）的推理，并将这些推理整合进用户画像中。

Result: 实验表明，在公共观点和电影偏好预测任务中，使用PB&J推理增强的LLM用户画像始终优于仅使用人口统计信息和/或用户判断的方法。基于用户信念支架构建的画像效果与使用人类撰写推理的画像相当。

Conclusion: 将LLM生成且基于心理学理论的推理（PB&J）融入用户画像，能显著提高LLM预测用户偏好的能力。

Abstract: Language models prompted with a user description or persona can predict a
user's preferences and opinions, but existing approaches to building personas
-- based solely on a user's demographic attributes and/or prior judgments --
fail to capture the underlying reasoning behind said user judgments. We
introduce PB&J (Psychology of Behavior and Judgments), a framework that
improves LLM personas by incorporating rationales of why a user might make
specific judgments. These rationales are LLM-generated, and aim to reason about
a user's behavior on the basis of their experiences, personality traits or
beliefs. This is done using psychological scaffolds -- structured frameworks
grounded in theories such as the Big 5 Personality Traits and Primal World
Beliefs -- that help provide structure to the generated rationales. Experiments
on public opinion and movie preference prediction tasks demonstrate that LLM
personas augmented with PB&J rationales consistently outperform methods using
only a user's demographics and/or judgments. Additionally, LLM personas
constructed using scaffolds describing user beliefs perform competitively with
those using human-written rationales.

</details>


### [3] [Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation](https://arxiv.org/abs/2504.18012)
*Zhuang Yu,Shiliang Sun,Jing Zhao,Tengfei Song,Hao Yang*

Main category: cs.CL

TL;DR: 该研究系统地探讨了预训练编码器和解码器在多模态机器翻译（MMT）中的作用，发现预训练解码器能稳定提升翻译质量，而编码器的效果则依赖于视觉-文本对齐。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练模型在单模态任务上表现优异，但它们在利用图像辅助文本进行翻译的多模态机器翻译（MMT）中的有效性和作用尚未得到充分探索。

Method: 在统一的MMT框架下，系统比较了不同训练策略（从零训练、使用预训练组件、部分冻结组件）对翻译性能的影响。实验在Multi30K和CoMMuTE数据集上进行，涵盖英德和英法翻译任务。

Result: 预训练在MMT中扮演着关键但不均衡的角色：预训练解码器始终能产生更流畅准确的译文；而预训练编码器的效果则因视觉-文本对齐的质量而异。

Conclusion: 研究揭示了预训练组件与模态融合之间的相互作用，并为未来多模态翻译系统的架构设计提供了指导。预训练解码器是提升MMT性能的关键。

Abstract: Multimodal Machine Translation (MMT) aims to improve translation quality by
leveraging auxiliary modalities such as images alongside textual input. While
recent advances in large-scale pre-trained language and vision models have
significantly benefited unimodal natural language processing tasks, their
effectiveness and role in MMT remain underexplored. In this work, we conduct a
systematic study on the impact of pre-trained encoders and decoders in
multimodal translation models. Specifically, we analyze how different training
strategies, from training from scratch to using pre-trained and partially
frozen components, affect translation performance under a unified MMT
framework. Experiments are carried out on the Multi30K and CoMMuTE dataset
across English-German and English-French translation tasks. Our results reveal
that pre-training plays a crucial yet asymmetrical role in multimodal settings:
pre-trained decoders consistently yield more fluent and accurate outputs, while
pre-trained encoders show varied effects depending on the quality of
visual-text alignment. Furthermore, we provide insights into the interplay
between modality fusion and pre-trained components, offering guidance for
future architecture design in multimodal translation systems.

</details>


### [4] [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org/abs/2504.18041)
*Bang An,Shiyue Zhang,Mark Dredze*

Main category: cs.CL

TL;DR: 研究发现，检索增强生成（RAG）框架会降低大语言模型的安全性，即使是安全的模型和文档组合也可能产生不安全内容，现有红队测试方法对RAG效果较差。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）框架被广泛使用，但现有的人工智能安全工作主要集中在标准大语言模型上，对RAG如何改变模型安全特性知之甚少。

Method: 通过对十一个大型语言模型进行RAG和非RAG框架的详细比较分析，探究RAG对模型安全性的影响及其原因，并评估现有红队测试方法在RAG环境下的有效性。

Result: 研究发现RAG会使模型变得更不安全并改变其安全特性。即使是安全模型与安全文档的组合也可能导致不安全的生成内容。现有的红队测试方法在RAG场景下的效果不如在非RAG场景下有效。

Conclusion: 强调了针对RAG大语言模型进行专门的安全研究和开发特定红队测试方法的必要性。

Abstract: Efforts to ensure the safety of large language models (LLMs) include safety
fine-tuning, evaluation, and red teaming. However, despite the widespread use
of the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses
on standard LLMs, which means we know little about how RAG use cases change a
model's safety profile. We conduct a detailed comparative analysis of RAG and
non-RAG frameworks with eleven LLMs. We find that RAG can make models less safe
and change their safety profile. We explore the causes of this change and find
that even combinations of safe models with safe documents can cause unsafe
generations. In addition, we evaluate some existing red teaming methods for RAG
settings and show that they are less effective than when used for non-RAG
settings. Our work highlights the need for safety research and red-teaming
methods specifically tailored for RAG LLMs.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [5] [Fuzzy Based Secure Clustering Schemes for Wireless Sensor Networks](https://arxiv.org/abs/2504.17795)
*Mohd Adnan*

Main category: cs.NI

TL;DR: 该论文提出了三种不同的方法来解决无线传感器网络 (WSN) 中的挑战：使用模糊逻辑聚类延长网络寿命，使用类型 2 模糊逻辑聚类提高网络稳定性，以及利用博弈论防御自私和恶意节点以增强安全性。


<details>
  <summary>Details</summary>
Motivation: 解决 WSN 中的开放性挑战，特别是网络寿命有限、网络稳定性不足以及易受自私节点和恶意攻击影响的问题。

Method: 1. 针对网络寿命：采用基于模糊逻辑（输入变量：节点到基站距离、集中度、剩余能量）和竞争半径的非均匀分簇协议与多跳传输。 2. 针对网络稳定性：设计基于类型 2 模糊逻辑输入的簇头 (CH) 选择策略和簇半径选择方案的多跳 WSN 聚类机制。 3. 针对网络安全：应用博弈论方法来建模恶意攻击、探索防御策略（针对外部攻击者和内部恶意/自私节点），并建立信任模型。

Result: 提出的模糊逻辑方法旨在实现负载均衡、最小化能耗、延长网络寿命和提高网络可扩展性。博弈论方法被用来有效建模攻击、制定防御策略，并证明了其在确保 WSN 安全、增强数据可信度和节点协作方面的作用。

Conclusion: 该研究通过模糊逻辑聚类和博弈论这两种不同的技术途径，分别针对性地解决了 WSN 在网络寿命、稳定性和安全性方面的关键挑战，展示了这些方法在优化网络性能和防御恶意行为方面的有效性和潜力。

Abstract: This dissertation presents three independent novel approaches for distinct
scenarios to solve one or more open challenges. The first concern explains the
focus on the lifetime of the networks: this dissertation will utilize a fuzzy
logic-based clustering protocol with multi-hop transmission for load balancing,
energy consumption minimization, and network lifetime prolongation. The
protocol forms unequal clusters with cluster head (CH) being selected by fuzzy
logic with competition radius. Node distance to the base station,
concentration, and residual energy are input variables. The second concern
focuses on network stability: we design a type 2 fuzzy logic-based clustering
schemes in a multi-hop WSN to reduce energy consumption and improve network
scalability. In this clustering scheme, we propose a cluster head (CH)
selection strategy where a sensor node is elected as a CH based on type 2 fuzzy
logic inputs. To balance the load of CHs we also select their radius size based
on the fuzzy logic inputs. Finally, the third concern is focus on the utility
of game theory in defensive Wireless Sensor Networks (WSN) from selfish nodes
and malicious behavior. Game theory can effectively model WSNs malicious
attacks because of their low complexity and scalability. The study, thus,
explores different WSN defense strategies from both external attackers and
internal nodes acting selfishly or maliciously using the game theory approach.
Also, the chapter highlights the general trust model for decision-making using
the game theory framework. Besides, the chapter demonstrates the significance
of the theory in ensuring WSN security from acute attacks and its role in
enhancing trustworthiness in data and cooperation of nodes in various WSN
architectures.

</details>
