<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 8]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English](https://arxiv.org/abs/2504.17974)
*Sabur Butt,Fazlourrahman Balouchzahi,Ahmad Imam Amjad,Maaz Amjad,Hector G. Ceballos,Salud Maria Jimenez-Zafra*

Main category: cs.CL

TL;DR: 本研究介绍了PolyHope V2，一个多语言、细粒度的希望言语数据集，并发现微调的Transformer模型在区分希望子类型和讽刺方面优于大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 希望情绪复杂、研究不足但重要，其细微形式（包括讽刺）难以被现有NLP系统准确检测，缺乏区分讽刺的细粒度数据集。

Method: 构建了一个包含3万多条英/西语推文的多语言细粒度希望言语数据集PolyHope V2（区分四种类型：广义、现实、不现实、讽刺）；使用该数据集对预训练Transformer模型进行微调，并与GPT-4、Llama 3等大型语言模型在零样本和少样本设置下进行基准比较；进行了定性分析和混淆矩阵分析。

Result: 微调的Transformer模型在希望言语检测任务中表现优于基于提示的大型语言模型，尤其是在区分细微的希望类别和讽刺方面；分析揭示了区分相关希望子类型的系统性挑战。

Conclusion: PolyHope V2数据集和研究结果为未来需要更高语义和语境敏感度的跨语言情感识别任务提供了坚实的基础。

Abstract: Hope is a complex and underexplored emotional state that plays a significant
role in education, mental health, and social interaction. Unlike basic
emotions, hope manifests in nuanced forms ranging from grounded optimism to
exaggerated wishfulness or sarcasm, making it difficult for Natural Language
Processing systems to detect accurately. This study introduces PolyHope V2, a
multilingual, fine-grained hope speech dataset comprising over 30,000 annotated
tweets in English and Spanish. This resource distinguishes between four hope
subtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhances
existing datasets by explicitly labeling sarcastic instances. We benchmark
multiple pretrained transformer models and compare them with large language
models (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.
Our findings show that fine-tuned transformers outperform prompt-based LLMs,
especially in distinguishing nuanced hope categories and sarcasm. Through
qualitative analysis and confusion matrices, we highlight systematic challenges
in separating closely related hope subtypes. The dataset and results provide a
robust foundation for future emotion recognition tasks that demand greater
semantic and contextual sensitivity across languages.

</details>


### [2] [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org/abs/2504.17993)
*Brihi Joshi,Xiang Ren,Swabha Swayamdipta,Rik Koncel-Kedziorski,Tim Paek*

Main category: cs.CL

TL;DR: 该研究提出PB&J框架，利用大型语言模型（LLM）生成基于心理学理论的推理，以增强用户画像，从而更准确地预测用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有构建用户画像的方法仅依赖用户的人口统计信息或过往判断，未能捕捉用户判断背后的深层原因。

Method: 引入PB&J框架：使用LLM结合心理学支架（如大五人格、原始世界信念等理论）生成用户行为（经验、个性、信念）的推理，并将这些推理整合进用户画像中。

Result: 实验表明，在公共观点和电影偏好预测任务中，使用PB&J推理增强的LLM用户画像始终优于仅使用人口统计信息和/或用户判断的方法。基于用户信念支架构建的画像效果与使用人类撰写推理的画像相当。

Conclusion: 将LLM生成且基于心理学理论的推理（PB&J）融入用户画像，能显著提高LLM预测用户偏好的能力。

Abstract: Language models prompted with a user description or persona can predict a
user's preferences and opinions, but existing approaches to building personas
-- based solely on a user's demographic attributes and/or prior judgments --
fail to capture the underlying reasoning behind said user judgments. We
introduce PB&J (Psychology of Behavior and Judgments), a framework that
improves LLM personas by incorporating rationales of why a user might make
specific judgments. These rationales are LLM-generated, and aim to reason about
a user's behavior on the basis of their experiences, personality traits or
beliefs. This is done using psychological scaffolds -- structured frameworks
grounded in theories such as the Big 5 Personality Traits and Primal World
Beliefs -- that help provide structure to the generated rationales. Experiments
on public opinion and movie preference prediction tasks demonstrate that LLM
personas augmented with PB&J rationales consistently outperform methods using
only a user's demographics and/or judgments. Additionally, LLM personas
constructed using scaffolds describing user beliefs perform competitively with
those using human-written rationales.

</details>


### [3] [Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation](https://arxiv.org/abs/2504.18012)
*Zhuang Yu,Shiliang Sun,Jing Zhao,Tengfei Song,Hao Yang*

Main category: cs.CL

TL;DR: 该研究系统地探讨了预训练编码器和解码器在多模态机器翻译（MMT）中的作用，发现预训练解码器能稳定提升翻译质量，而编码器的效果则依赖于视觉-文本对齐。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练模型在单模态任务上表现优异，但它们在利用图像辅助文本进行翻译的多模态机器翻译（MMT）中的有效性和作用尚未得到充分探索。

Method: 在统一的MMT框架下，系统比较了不同训练策略（从零训练、使用预训练组件、部分冻结组件）对翻译性能的影响。实验在Multi30K和CoMMuTE数据集上进行，涵盖英德和英法翻译任务。

Result: 预训练在MMT中扮演着关键但不均衡的角色：预训练解码器始终能产生更流畅准确的译文；而预训练编码器的效果则因视觉-文本对齐的质量而异。

Conclusion: 研究揭示了预训练组件与模态融合之间的相互作用，并为未来多模态翻译系统的架构设计提供了指导。预训练解码器是提升MMT性能的关键。

Abstract: Multimodal Machine Translation (MMT) aims to improve translation quality by
leveraging auxiliary modalities such as images alongside textual input. While
recent advances in large-scale pre-trained language and vision models have
significantly benefited unimodal natural language processing tasks, their
effectiveness and role in MMT remain underexplored. In this work, we conduct a
systematic study on the impact of pre-trained encoders and decoders in
multimodal translation models. Specifically, we analyze how different training
strategies, from training from scratch to using pre-trained and partially
frozen components, affect translation performance under a unified MMT
framework. Experiments are carried out on the Multi30K and CoMMuTE dataset
across English-German and English-French translation tasks. Our results reveal
that pre-training plays a crucial yet asymmetrical role in multimodal settings:
pre-trained decoders consistently yield more fluent and accurate outputs, while
pre-trained encoders show varied effects depending on the quality of
visual-text alignment. Furthermore, we provide insights into the interplay
between modality fusion and pre-trained components, offering guidance for
future architecture design in multimodal translation systems.

</details>


### [4] [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org/abs/2504.18041)
*Bang An,Shiyue Zhang,Mark Dredze*

Main category: cs.CL

TL;DR: 研究发现，检索增强生成（RAG）框架会降低大语言模型的安全性，即使是安全的模型和文档组合也可能产生不安全内容，现有红队测试方法对RAG效果较差。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）框架被广泛使用，但现有的人工智能安全工作主要集中在标准大语言模型上，对RAG如何改变模型安全特性知之甚少。

Method: 通过对十一个大型语言模型进行RAG和非RAG框架的详细比较分析，探究RAG对模型安全性的影响及其原因，并评估现有红队测试方法在RAG环境下的有效性。

Result: 研究发现RAG会使模型变得更不安全并改变其安全特性。即使是安全模型与安全文档的组合也可能导致不安全的生成内容。现有的红队测试方法在RAG场景下的效果不如在非RAG场景下有效。

Conclusion: 强调了针对RAG大语言模型进行专门的安全研究和开发特定红队测试方法的必要性。

Abstract: Efforts to ensure the safety of large language models (LLMs) include safety
fine-tuning, evaluation, and red teaming. However, despite the widespread use
of the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses
on standard LLMs, which means we know little about how RAG use cases change a
model's safety profile. We conduct a detailed comparative analysis of RAG and
non-RAG frameworks with eleven LLMs. We find that RAG can make models less safe
and change their safety profile. We explore the causes of this change and find
that even combinations of safe models with safe documents can cause unsafe
generations. In addition, we evaluate some existing red teaming methods for RAG
settings and show that they are less effective than when used for non-RAG
settings. Our work highlights the need for safety research and red-teaming
methods specifically tailored for RAG LLMs.

</details>


### [5] [Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English](https://arxiv.org/abs/2504.17974)
*Sabur Butt,Fazlourrahman Balouchzahi,Ahmad Imam Amjad,Maaz Amjad,Hector G. Ceballos,Salud Maria Jimenez-Zafra*

Main category: cs.CL

TL;DR: 介绍了一个多语言细粒度希望语音数据集PolyHope V2，包含四种希望子类型（含讽刺），并发现微调的Transformer模型在检测这些细微类别方面优于大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 希望是一种复杂且重要的情感，其细微形式（如现实希望、不现实希望、讽刺）难以被现有自然语言处理系统准确检测，且缺乏区分这些子类型（尤其是讽刺）的数据集。

Method: 构建了一个包含超过3万条英/西语推文的多语言细粒度希望数据集PolyHope V2，标注了四种希望子类型；使用该数据集对多种预训练Transformer模型进行微调和基准测试，并与GPT-4、Llama 3等大型语言模型在零样本和少样本设置下进行比较；通过定性分析和混淆矩阵评估模型性能。

Result: 微调的Transformer模型在区分细微希望类别和讽刺方面的表现优于基于提示的大型语言模型；研究也揭示了在区分相近希望子类型方面存在的系统性挑战。

Conclusion: 新提出的数据集PolyHope V2和基准测试结果为未来需要更高语义和语境敏感性的跨语言情感识别任务提供了坚实的基础。

Abstract: Hope is a complex and underexplored emotional state that plays a significant
role in education, mental health, and social interaction. Unlike basic
emotions, hope manifests in nuanced forms ranging from grounded optimism to
exaggerated wishfulness or sarcasm, making it difficult for Natural Language
Processing systems to detect accurately. This study introduces PolyHope V2, a
multilingual, fine-grained hope speech dataset comprising over 30,000 annotated
tweets in English and Spanish. This resource distinguishes between four hope
subtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhances
existing datasets by explicitly labeling sarcastic instances. We benchmark
multiple pretrained transformer models and compare them with large language
models (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.
Our findings show that fine-tuned transformers outperform prompt-based LLMs,
especially in distinguishing nuanced hope categories and sarcasm. Through
qualitative analysis and confusion matrices, we highlight systematic challenges
in separating closely related hope subtypes. The dataset and results provide a
robust foundation for future emotion recognition tasks that demand greater
semantic and contextual sensitivity across languages.

</details>


### [6] [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org/abs/2504.17993)
*Brihi Joshi,Xiang Ren,Swabha Swayamdipta,Rik Koncel-Kedziorski,Tim Paek*

Main category: cs.CL

TL;DR: 提出PB&J框架，通过LLM生成基于心理学理论的“行为原因解释”来增强用户画像，从而更准确地预测用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有基于人口统计或过往判断构建的用户画像方法，未能捕捉用户判断背后的根本原因。

Method: 引入PB&J框架，利用大型语言模型（LLM）生成用户行为的“原因解释”。这些解释基于用户的经验、人格特质或信念，并利用心理学支架（如大五人格、原始世界信念）进行结构化，以增强LLM用户画像。

Result: 在公众舆论和电影偏好预测实验中，经PB&J“原因解释”增强的LLM用户画像表现始终优于仅使用人口统计和/或用户判断的方法。使用描述用户信念的支架构建的画像，其效果与使用人类撰写解释的画像具有竞争力。

Conclusion: PB&J框架通过融入用户判断背后的推理过程（原因解释），显著提升了LLM用户画像预测用户偏好和观点的能力。

Abstract: Language models prompted with a user description or persona can predict a
user's preferences and opinions, but existing approaches to building personas
-- based solely on a user's demographic attributes and/or prior judgments --
fail to capture the underlying reasoning behind said user judgments. We
introduce PB&J (Psychology of Behavior and Judgments), a framework that
improves LLM personas by incorporating rationales of why a user might make
specific judgments. These rationales are LLM-generated, and aim to reason about
a user's behavior on the basis of their experiences, personality traits or
beliefs. This is done using psychological scaffolds -- structured frameworks
grounded in theories such as the Big 5 Personality Traits and Primal World
Beliefs -- that help provide structure to the generated rationales. Experiments
on public opinion and movie preference prediction tasks demonstrate that LLM
personas augmented with PB&J rationales consistently outperform methods using
only a user's demographics and/or judgments. Additionally, LLM personas
constructed using scaffolds describing user beliefs perform competitively with
those using human-written rationales.

</details>


### [7] [Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation](https://arxiv.org/abs/2504.18012)
*Zhuang Yu,Shiliang Sun,Jing Zhao,Tengfei Song,Hao Yang*

Main category: cs.CL

TL;DR: 该研究系统分析了预训练模型（编码器和解码器）对多模态机器翻译（MMT）的影响，发现预训练解码器能稳定提升翻译质量，而编码器的效果依赖于图文对齐。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型在单模态NLP任务中效果显著，但在多模态机器翻译中的作用和有效性仍需深入研究。

Method: 在一个统一的MMT框架下，系统比较了不同训练策略（从头训练、使用预训练及部分冻结组件）对模型性能的影响。在Multi30K和CoMMuTE数据集上进行了英德、英法翻译实验。

Result: 预训练在MMT中作用关键但不均衡：预训练解码器始终带来更流畅准确的翻译；预训练编码器的效果则随视觉-文本对齐质量变化而不同。

Conclusion: 预训练解码器对MMT有显著益处，编码器的选择需考虑图文对齐质量。研究为未来MMT架构设计提供了指导。

Abstract: Multimodal Machine Translation (MMT) aims to improve translation quality by
leveraging auxiliary modalities such as images alongside textual input. While
recent advances in large-scale pre-trained language and vision models have
significantly benefited unimodal natural language processing tasks, their
effectiveness and role in MMT remain underexplored. In this work, we conduct a
systematic study on the impact of pre-trained encoders and decoders in
multimodal translation models. Specifically, we analyze how different training
strategies, from training from scratch to using pre-trained and partially
frozen components, affect translation performance under a unified MMT
framework. Experiments are carried out on the Multi30K and CoMMuTE dataset
across English-German and English-French translation tasks. Our results reveal
that pre-training plays a crucial yet asymmetrical role in multimodal settings:
pre-trained decoders consistently yield more fluent and accurate outputs, while
pre-trained encoders show varied effects depending on the quality of
visual-text alignment. Furthermore, we provide insights into the interplay
between modality fusion and pre-trained components, offering guidance for
future architecture design in multimodal translation systems.

</details>


### [8] [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org/abs/2504.18041)
*Bang An,Shiyue Zhang,Mark Dredze*

Main category: cs.CL

TL;DR: 研究发现RAG框架会降低大语言模型的安全性，即使结合安全文档也可能产生不安全内容，且现有红队测试方法效果不佳，亟需针对RAG的专属安全研究。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）框架被广泛使用，但现有的AI安全研究主要集中在标准大语言模型（LLM）上，对于RAG如何影响模型安全性的了解非常有限。

Method: 研究对11个LLM在RAG和非RAG框架下的安全性进行了详细的比较分析，探究了安全性变化的原因，并评估了现有红队测试方法在RAG环境下的有效性。

Result: 研究发现RAG会降低模型的安全性并改变其安全特性；即使是安全模型与安全文档的组合也可能导致不安全的生成结果；现有的红队测试方法在RAG场景下的效果不如在非RAG场景下。

Conclusion: 该研究强调，需要针对RAG LLM进行专门的安全研究，并开发量身定制的红队测试方法。

Abstract: Efforts to ensure the safety of large language models (LLMs) include safety
fine-tuning, evaluation, and red teaming. However, despite the widespread use
of the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses
on standard LLMs, which means we know little about how RAG use cases change a
model's safety profile. We conduct a detailed comparative analysis of RAG and
non-RAG frameworks with eleven LLMs. We find that RAG can make models less safe
and change their safety profile. We explore the causes of this change and find
that even combinations of safe models with safe documents can cause unsafe
generations. In addition, we evaluate some existing red teaming methods for RAG
settings and show that they are less effective than when used for non-RAG
settings. Our work highlights the need for safety research and red-teaming
methods specifically tailored for RAG LLMs.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [9] [Spectral Dictionary Learning for Generative Image Modeling](https://arxiv.org/abs/2504.17804)
*Andrew Kiruluta*

Main category: cs.CV

TL;DR: 提出了一种新颖的基于频谱的图像生成模型，通过学习频谱基函数及其混合系数来合成图像，与常见的变分、对抗或扩散模型不同。


<details>
  <summary>Details</summary>
Motivation: 寻求一种不同于现有主流范式（VAE、GAN、扩散模型）的图像生成方法，旨在提高模型的可解释性、物理意义、训练稳定性和计算效率。

Method: 将图像展平为一维信号，将其重构为一组学习到的频谱基函数的线性组合。这些基函数由频率、相位和幅度显式参数化。模型联合学习一个全局频谱字典（含时变调制）和每幅图像的混合系数。然后，对混合系数拟合一个简单的概率模型，通过从潜空间采样来确定性地生成新图像。该框架利用确定性字典学习，并结合短时傅里叶变换（STFT）计算的频域损失函数。

Result: 在CIFAR-10基准测试上，该方法在重建质量和感知保真度方面取得了有竞争力的性能，同时展现出更好的训练稳定性和计算效率。

Conclusion: 这种新型频谱生成模型提供了一种高度可解释的表示，由于其直接处理图像的内在频率内容，为可控合成、图像操纵和分析开辟了有前景的途径。

Abstract: We propose a novel spectral generative model for image synthesis that departs
radically from the common variational, adversarial, and diffusion paradigms. In
our approach, images, after being flattened into one-dimensional signals, are
reconstructed as linear combinations of a set of learned spectral basis
functions, where each basis is explicitly parameterized in terms of frequency,
phase, and amplitude. The model jointly learns a global spectral dictionary
with time-varying modulations and per-image mixing coefficients that quantify
the contributions of each spectral component. Subsequently, a simple
probabilistic model is fitted to these mixing coefficients, enabling the
deterministic generation of new images by sampling from the latent space. This
framework leverages deterministic dictionary learning, offering a highly
interpretable and physically meaningful representation compared to methods
relying on stochastic inference or adversarial training. Moreover, the
incorporation of frequency-domain loss functions, computed via the short-time
Fourier transform (STFT), ensures that the synthesized images capture both
global structure and fine-grained spectral details, such as texture and edge
information. Experimental evaluations on the CIFAR-10 benchmark demonstrate
that our approach not only achieves competitive performance in terms of
reconstruction quality and perceptual fidelity but also offers improved
training stability and computational efficiency. This new type of generative
model opens up promising avenues for controlled synthesis, as the learned
spectral dictionary affords a direct handle on the intrinsic frequency content
of the images, thus providing enhanced interpretability and potential for novel
applications in image manipulation and analysis.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [10] [Fuzzy Based Secure Clustering Schemes for Wireless Sensor Networks](https://arxiv.org/abs/2504.17795)
*Mohd Adnan*

Main category: cs.NI

TL;DR: 该论文提出了三种不同的方法来解决无线传感器网络 (WSN) 中的挑战：使用模糊逻辑聚类延长网络寿命，使用类型 2 模糊逻辑聚类提高网络稳定性，以及利用博弈论防御自私和恶意节点以增强安全性。


<details>
  <summary>Details</summary>
Motivation: 解决 WSN 中的开放性挑战，特别是网络寿命有限、网络稳定性不足以及易受自私节点和恶意攻击影响的问题。

Method: 1. 针对网络寿命：采用基于模糊逻辑（输入变量：节点到基站距离、集中度、剩余能量）和竞争半径的非均匀分簇协议与多跳传输。 2. 针对网络稳定性：设计基于类型 2 模糊逻辑输入的簇头 (CH) 选择策略和簇半径选择方案的多跳 WSN 聚类机制。 3. 针对网络安全：应用博弈论方法来建模恶意攻击、探索防御策略（针对外部攻击者和内部恶意/自私节点），并建立信任模型。

Result: 提出的模糊逻辑方法旨在实现负载均衡、最小化能耗、延长网络寿命和提高网络可扩展性。博弈论方法被用来有效建模攻击、制定防御策略，并证明了其在确保 WSN 安全、增强数据可信度和节点协作方面的作用。

Conclusion: 该研究通过模糊逻辑聚类和博弈论这两种不同的技术途径，分别针对性地解决了 WSN 在网络寿命、稳定性和安全性方面的关键挑战，展示了这些方法在优化网络性能和防御恶意行为方面的有效性和潜力。

Abstract: This dissertation presents three independent novel approaches for distinct
scenarios to solve one or more open challenges. The first concern explains the
focus on the lifetime of the networks: this dissertation will utilize a fuzzy
logic-based clustering protocol with multi-hop transmission for load balancing,
energy consumption minimization, and network lifetime prolongation. The
protocol forms unequal clusters with cluster head (CH) being selected by fuzzy
logic with competition radius. Node distance to the base station,
concentration, and residual energy are input variables. The second concern
focuses on network stability: we design a type 2 fuzzy logic-based clustering
schemes in a multi-hop WSN to reduce energy consumption and improve network
scalability. In this clustering scheme, we propose a cluster head (CH)
selection strategy where a sensor node is elected as a CH based on type 2 fuzzy
logic inputs. To balance the load of CHs we also select their radius size based
on the fuzzy logic inputs. Finally, the third concern is focus on the utility
of game theory in defensive Wireless Sensor Networks (WSN) from selfish nodes
and malicious behavior. Game theory can effectively model WSNs malicious
attacks because of their low complexity and scalability. The study, thus,
explores different WSN defense strategies from both external attackers and
internal nodes acting selfishly or maliciously using the game theory approach.
Also, the chapter highlights the general trust model for decision-making using
the game theory framework. Besides, the chapter demonstrates the significance
of the theory in ensuring WSN security from acute attacks and its role in
enhancing trustworthiness in data and cooperation of nodes in various WSN
architectures.

</details>


### [11] [Fuzzy Based Secure Clustering Schemes for Wireless Sensor Networks](https://arxiv.org/abs/2504.17795)
*Mohd Adnan*

Main category: cs.NI

TL;DR: 该论文提出了三种针对无线传感器网络（WSN）不同挑战的方法：1) 基于模糊逻辑的聚类协议以延长网络寿命；2) 基于二型模糊逻辑的聚类方案以提高稳定性和可扩展性；3) 应用博弈论防御自私/恶意节点和攻击。


<details>
  <summary>Details</summary>
Motivation: 解决WSN面临的关键挑战，包括延长网络生命周期、提高网络稳定性与可扩展性，以及增强网络安全性以抵御内部（自私/恶意节点）和外部攻击。

Method: 1) 使用基于模糊逻辑（输入：到基站距离、节点集中度、剩余能量）和竞争半径的多跳传输非均衡分簇协议进行簇头选择，以平衡负载、最小化能耗。 2) 设计基于二型模糊逻辑的多跳WSN分簇方案，通过二型模糊逻辑选择簇头，并通过模糊逻辑确定簇头半径以平衡负载。 3) 运用博弈论方法建模和分析针对WSN内外部攻击的防御策略，并探索基于博弈论的通用信任模型。

Result: 研究展示了：1) 基于模糊逻辑的聚类能有效平衡负载、降低能耗、延长网络寿命。 2) 基于二型模糊逻辑的聚类能降低能耗、提升网络可扩展性。 3) 博弈论可有效建模WSN攻击，分析防御策略，并能提升数据可信度和节点协作，增强WSN安全性。

Conclusion: 论文成功提出了利用模糊逻辑（一型和二型）优化WSN聚类以改善网络寿命和稳定性，并应用博弈论来增强WSN对多种威胁的安全防御能力，证明了这些方法在解决特定挑战方面的有效性。

Abstract: This dissertation presents three independent novel approaches for distinct
scenarios to solve one or more open challenges. The first concern explains the
focus on the lifetime of the networks: this dissertation will utilize a fuzzy
logic-based clustering protocol with multi-hop transmission for load balancing,
energy consumption minimization, and network lifetime prolongation. The
protocol forms unequal clusters with cluster head (CH) being selected by fuzzy
logic with competition radius. Node distance to the base station,
concentration, and residual energy are input variables. The second concern
focuses on network stability: we design a type 2 fuzzy logic-based clustering
schemes in a multi-hop WSN to reduce energy consumption and improve network
scalability. In this clustering scheme, we propose a cluster head (CH)
selection strategy where a sensor node is elected as a CH based on type 2 fuzzy
logic inputs. To balance the load of CHs we also select their radius size based
on the fuzzy logic inputs. Finally, the third concern is focus on the utility
of game theory in defensive Wireless Sensor Networks (WSN) from selfish nodes
and malicious behavior. Game theory can effectively model WSNs malicious
attacks because of their low complexity and scalability. The study, thus,
explores different WSN defense strategies from both external attackers and
internal nodes acting selfishly or maliciously using the game theory approach.
Also, the chapter highlights the general trust model for decision-making using
the game theory framework. Besides, the chapter demonstrates the significance
of the theory in ensuring WSN security from acute attacks and its role in
enhancing trustworthiness in data and cooperation of nodes in various WSN
architectures.

</details>
