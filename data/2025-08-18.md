<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 76]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.LG](#cs.LG) [Total: 59]
- [cs.NI](#cs.NI) [Total: 4]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.DB](#cs.DB) [Total: 1]
- [stat.ME](#stat.ME) [Total: 4]
- [cs.IR](#cs.IR) [Total: 4]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.IT](#cs.IT) [Total: 2]
- [stat.ML](#stat.ML) [Total: 2]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.HC](#cs.HC) [Total: 7]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation](https://arxiv.org/abs/2508.10904)
*Jie Lei,Ruofan Jia,J. Andrew Zhang,Hao Zhang*

Main category: cs.CL

TL;DR: A2HCoder是一个基于LLM的分层代理，通过模块化分解和逐步翻译，高效且可靠地将算法转换为硬件描述语言，以解决无线通信中的部署难题。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统对超低延迟和功耗的严格要求增加了高效算法到硬件部署的需求。然而，算法设计（如MATLAB）与硬件实现（如Verilog）之间存在巨大鸿沟，传统方法需要大量专业知识和时间。

Method: A2HCoder是一个基于大型语言模型（LLM）的分层算法到HDL编码代理。它采用：1. 横向分解：将复杂算法分解为模块化功能块，简化代码生成。2. 纵向精细翻译：通过逐步、细粒度翻译，并利用MATLAB和Vitis HLS等外部工具链进行调试和电路级综合，以减少幻觉并确保硬件正确性。

Result: 通过5G无线通信领域的真实部署案例验证了A2HCoder，结果表明其具有良好的实用性、可靠性和部署效率。

Conclusion: A2HCoder为弥合算法设计与硬件实现之间的差距提供了一种有效且可靠的解决方案，尤其适用于对效率和可靠性有高要求的无线通信系统。

Abstract: In wireless communication systems, stringent requirements such as ultra-low
latency and power consumption have significantly increased the demand for
efficient algorithm-to-hardware deployment. However, a persistent and
substantial gap remains between algorithm design and hardware implementation.
Bridging this gap traditionally requires extensive domain expertise and
time-consuming manual development, due to fundamental mismatches between
high-level programming languages like MATLAB and hardware description languages
(HDLs) such as Verilog-in terms of memory access patterns, data processing
manners, and datatype representations. To address this challenge, we propose
A2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large
language models (LLMs), designed to enable agile and reliable
algorithm-to-hardware translation. A2HCoder introduces a hierarchical framework
that enhances both robustness and interpretability while suppressing common
hallucination issues in LLM-generated code. In the horizontal dimension,
A2HCoder decomposes complex algorithms into modular functional blocks,
simplifying code generation and improving consistency. In the vertical
dimension, instead of relying on end-to-end generation, A2HCoder performs
step-by-step, fine-grained translation, leveraging external toolchains such as
MATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured
process significantly mitigates hallucinations and ensures hardware-level
correctness. We validate A2HCoder through a real-world deployment case in the
5G wireless communication domain, demonstrating its practicality, reliability,
and deployment efficiency.

</details>


### [2] [PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins](https://arxiv.org/abs/2508.10906)
*Sihan Chen,John P. Lalor,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: 本文提出PersonaTwin框架，通过整合多源数据构建LLM自适应数字孪生，以弥补LLM在用户建模中对个体细微差别捕捉的不足。在医疗健康数据集上的实验证明，PersonaTwin能生成高保真、公平的用户模拟，且基于其生成的下游模型表现与真实数据训练的模型相当。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）为用户建模和模拟人类行为提供了新可能性，但它们常常无法捕捉个体用户的多维度细微差别。

Method: 研究引入了PersonaTwin，一个多层提示条件框架，通过整合人口统计学、行为和心理测量数据来构建自适应数字孪生。该框架使用包含8,500多名个体的医疗健康数据集进行系统性基准测试，并结合先进的文本相似度指标和专门的人口统计学平等评估，以确保生成响应的准确性和无偏性。

Result: 实验结果表明，PersonaTwin框架生成的模拟保真度与“预言机”（oracle）设置相当。此外，在基于GPT-4o和基于Llama的模型中，使用PersonaTwin训练的下游模型在预测和公平性指标方面与使用真实个体训练的模型近似。

Conclusion: 这些发现共同强调了基于LLM数字孪生方法在生成逼真且情感细致的用户模拟方面的巨大潜力，为个性化数字用户建模和行为分析提供了一个强大的工具。

Abstract: While large language models (LLMs) afford new possibilities for user modeling
and approximation of human behaviors, they often fail to capture the
multidimensional nuances of individual users. In this work, we introduce
PersonaTwin, a multi-tier prompt conditioning framework that builds adaptive
digital twins by integrating demographic, behavioral, and psychometric data.
Using a comprehensive data set in the healthcare context of more than 8,500
individuals, we systematically benchmark PersonaTwin against standard LLM
outputs, and our rigorous evaluation unites state-of-the-art text similarity
metrics with dedicated demographic parity assessments, ensuring that generated
responses remain accurate and unbiased. Experimental results show that our
framework produces simulation fidelity on par with oracle settings. Moreover,
downstream models trained on persona-twins approximate models trained on
individuals in terms of prediction and fairness metrics across both
GPT-4o-based and Llama-based models. Together, these findings underscore the
potential for LLM digital twin-based approaches in producing realistic and
emotionally nuanced user simulations, offering a powerful tool for personalized
digital user modeling and behavior analysis.

</details>


### [3] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
*OpenAI,:,Sandhini Agarwal,Lama Ahmad,Jason Ai,Sam Altman,Andy Applebaum,Edwin Arbus,Rahul K. Arora,Yu Bai,Bowen Baker,Haiming Bao,Boaz Barak,Ally Bennett,Tyler Bertao,Nivedita Brett,Eugene Brevdo,Greg Brockman,Sebastien Bubeck,Che Chang,Kai Chen,Mark Chen,Enoch Cheung,Aidan Clark,Dan Cook,Marat Dukhan,Casey Dvorak,Kevin Fives,Vlad Fomenko,Timur Garipov,Kristian Georgiev,Mia Glaese,Tarun Gogineni,Adam Goucher,Lukas Gross,Katia Gil Guzman,John Hallman,Jackie Hehir,Johannes Heidecke,Alec Helyar,Haitang Hu,Romain Huet,Jacob Huh,Saachi Jain,Zach Johnson,Chris Koch,Irina Kofman,Dominik Kundel,Jason Kwon,Volodymyr Kyrylov,Elaine Ya Le,Guillaume Leclerc,James Park Lennon,Scott Lessans,Mario Lezcano-Casado,Yuanzhi Li,Zhuohan Li,Ji Lin,Jordan Liss,Lily,Liu,Jiancheng Liu,Kevin Lu,Chris Lu,Zoran Martinovic,Lindsay McCallum,Josh McGrath,Scott McKinney,Aidan McLaughlin,Song Mei,Steve Mostovoy,Tong Mu,Gideon Myles,Alexander Neitz,Alex Nichol,Jakub Pachocki,Alex Paino,Dana Palmie,Ashley Pantuliano,Giambattista Parascandolo,Jongsoo Park,Leher Pathak,Carolina Paz,Ludovic Peran,Dmitry Pimenov,Michelle Pokrass,Elizabeth Proehl,Huida Qiu,Gaby Raila,Filippo Raso,Hongyu Ren,Kimmy Richardson,David Robinson,Bob Rotsted,Hadi Salman,Suvansh Sanjeev,Max Schwarzer,D. Sculley,Harshit Sikchi,Kendal Simon,Karan Singhal,Yang Song,Dane Stuckey,Zhiqing Sun,Philippe Tillet,Sam Toizer,Foivos Tsimpourlas,Nikhil Vyas,Eric Wallace,Xin Wang,Miles Wang,Olivia Watkins,Kevin Weil,Amy Wendling,Kevin Whinnery,Cedric Whitney,Hannah Wong,Lin Yang,Yu Yang,Michihiro Yasunaga,Kristen Ying,Wojciech Zaremba,Wenting Zhan,Cyril Zhang,Brian Zhang,Eddie Zhang,Shengjia Zhao*

Main category: cs.CL

TL;DR: 本文介绍了gpt-oss-120b和gpt-oss-20b，两款开源的推理模型，它们在准确性和推理成本方面取得了突破，并具备强大的代理能力。


<details>
  <summary>Details</summary>
Motivation: 旨在开发出在准确性和推理成本方面具有前沿水平的开放权重推理模型，并使其具备强大的代理能力，如深度研究浏览和工具使用。

Method: 模型采用高效的专家混合（Mixture-of-Expert）Transformer架构，通过大规模蒸馏和强化学习进行训练。它们被优化以支持代理能力（包括深度研究浏览、Python工具使用和开发者自定义函数），并使用渲染的聊天格式以实现清晰的指令遵循和角色划分。

Result: 两个模型在数学、编码和安全等多个基准测试中均取得了出色的表现。

Conclusion: 作者发布了模型权重、推理实现、工具环境和分词器，均采用Apache 2.0许可，旨在促进广泛使用和进一步研究。

Abstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models
that push the frontier of accuracy and inference cost. The models use an
efficient mixture-of-expert transformer architecture and are trained using
large-scale distillation and reinforcement learning. We optimize the models to
have strong agentic capabilities (deep research browsing, python tool use, and
support for developer-provided functions), all while using a rendered chat
format that enables clear instruction following and role delineation. Both
models achieve strong results on benchmarks ranging from mathematics, coding,
and safety. We release the model weights, inference implementations, tool
environments, and tokenizers under an Apache 2.0 license to enable broad use
and further research.

</details>


### [4] [Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News](https://arxiv.org/abs/2508.10927)
*Jiaxin Pei,Soumya Vadlamannati,Liang-Kang Huang,Daniel Preotiuc-Pietro,Xinyu Hua*

Main category: cs.CL

TL;DR: 本研究构建了一个计算框架，用于从新闻文章中自动提取公司风险因素，并提出了包含七个方面的风险因素分类方案。实验表明，微调后的预训练语言模型在该任务上表现优于零/少样本的大型语言模型。该模型被应用于分析大量新闻文章，以提供公司和行业的深入洞察。


<details>
  <summary>Details</summary>
Motivation: 识别与公司相关的风险对投资者和金融市场的整体健康至关重要。

Method: 构建了一个计算框架，旨在从新闻文章中自动提取公司风险因素。提出了一套包含七个独特方面的风险分类方案（如供应链、法规、竞争）。抽样并标注了744篇新闻文章，以基准测试各种机器学习模型，包括零样本和少样本的大型语言模型（如LLaMA-2）以及微调后的预训练语言模型。最终，利用表现最佳的模型分析了超过27.7万篇彭博新闻文章。

Result: 实验表明，零样本和少样本提示的先进大型语言模型（如LLaMA-2）在识别风险因素方面的表现仅为中等到低等水平。相比之下，微调后的预训练语言模型在大多数风险因素上表现更优。通过分析大量新闻文章，研究证明从新闻中识别风险因素能够为公司和行业的运营提供广泛的洞察。

Conclusion: 本研究开发的计算框架，特别是采用微调预训练语言模型，能有效从新闻中识别公司风险因素，并为公司及行业运营提供深入洞察，尽管大型语言模型在该任务上直接应用表现有限。

Abstract: Identifying risks associated with a company is important to investors and the
well-being of the overall financial market. In this study, we build a
computational framework to automatically extract company risk factors from news
articles. Our newly proposed schema comprises seven distinct aspects, such as
supply chain, regulations, and competitions. We sample and annotate 744 news
articles and benchmark various machine learning models. While large language
models have achieved huge progress in various types of NLP tasks, our
experiment shows that zero-shot and few-shot prompting state-of-the-art LLMs
(e.g. LLaMA-2) can only achieve moderate to low performances in identifying
risk factors. And fine-tuned pre-trained language models are performing better
on most of the risk factors. Using this model, we analyze over 277K Bloomberg
news articles and demonstrate that identifying risk factors from news could
provide extensive insight into the operations of companies and industries.

</details>


### [5] [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)
*Nasim Shirvani-Mahdavi,Chengkai Li*

Main category: cs.CL

TL;DR: Rule2Text是一个利用大型语言模型为知识图谱逻辑规则生成自然语言解释的框架，显著提高了规则的可理解性和知识图谱的可用性。通过微调和创新的评估方法，实现了高质量的解释生成。


<details>
  <summary>Details</summary>
Motivation: 知识图谱中挖掘的逻辑规则因其复杂性和特有的标签约定，导致人类难以理解，从而限制了知识图谱的可访问性和可用性。

Method: 本文提出Rule2Text框架，利用大语言模型（LLMs）为挖掘的逻辑规则生成自然语言解释。研究在多个数据集（包括Freebase变体和ogbl-biokg）上进行，规则通过AMIE 3.5.1挖掘。系统评估了多种LLMs，并采用零样本、少样本、变量类型整合及思维链等提示策略。通过人工评估和开发LLM-as-a-judge框架（与人工评估高度一致）评估解释质量。利用最佳LLM、LLM裁判和人工反馈构建高质量真值数据集，并用于微调开源Zephyr模型。同时，集成类型推断模块以支持缺少显式类型信息的知识图谱。

Result: 研究结果表明，经过微调后，解释质量显著提升，尤其在领域特定数据集（ogbl-biokg）中取得了显著增益。LLM-as-a-judge框架被验证与人工评估高度一致，有效解决了评估的可扩展性问题。

Conclusion: Rule2Text框架通过将知识图谱中复杂的逻辑规则转化为易于理解的自然语言，显著提升了知识图谱的可访问性和可用性。微调方法的有效性及类型推断模块的集成，进一步强化了该框架的实用性和泛化能力。

Abstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the
resulting logical rules are often difficult for humans to interpret due to
their inherent complexity and the idiosyncratic labeling conventions of
individual KGs. This work presents Rule2Text, a comprehensive framework that
leverages large language models (LLMs) to generate natural language
explanations for mined logical rules, thereby improving KG accessibility and
usability. We conduct extensive experiments using multiple datasets, including
Freebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the
ogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically
evaluate several LLMs across a comprehensive range of prompting strategies,
including zero-shot, few-shot, variable type incorporation, and
Chain-of-Thought reasoning. To systematically assess models' performance, we
conduct a human evaluation of generated explanations on correctness and
clarity. To address evaluation scalability, we develop and validate an
LLM-as-a-judge framework that demonstrates strong agreement with human
evaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,
and human-in-the-loop feedback, we construct high-quality ground truth
datasets, which we use to fine-tune the open-source Zephyr model. Our results
demonstrate significant improvements in explanation quality after fine-tuning,
with particularly strong gains in the domain-specific dataset. Additionally, we
integrate a type inference module to support KGs lacking explicit type
information. All code and data are publicly available at
https://github.com/idirlab/KGRule2NL.

</details>


### [6] [Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling](https://arxiv.org/abs/2508.10995)
*Tejomay Kishor Padole,Suyash P Awate,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本文提出了一种基于验证器的推理时尺度扩展方法，显著提升了掩码扩散语言模型（MDM）的文本生成质量，并证明MDM在文本风格迁移任务中优于自回归语言模型。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散语言模型（MDM）作为一种有前景的自然语言生成框架，因其可扩展性和易训练性而受到关注。扩散模型通常可以通过推理时尺度扩展（如增加去噪步数或使用外部验证器）来提高生成质量。

Method: 本研究提出了一种基于验证器的推理时尺度扩展方法，旨在MDM的去噪过程中寻找更好的候选生成。具体而言，该方法采用了一个简单的基于软值的验证器设置，并利用现成的预训练嵌入模型。

Result: 实验结果表明，MDM可应用于标准文本风格迁移任务，并被确立为比自回归语言模型更好的替代方案。此外，即使在现有文献中典型的无分类器引导设置之上，简单地使用现成预训练嵌入模型的基于软值的验证器设置也能显著提升生成质量。

Conclusion: 所提出的基于验证器的推理时尺度扩展方法能有效提升MDM的文本生成质量，使MDM成为文本生成任务中自回归语言模型的有力替代。

Abstract: Masked diffusion language models (MDMs) have recently gained traction as a
viable generative framework for natural language. This can be attributed to its
scalability and ease of training compared to other diffusion model paradigms
for discrete data, establishing itself as the state-of-the-art
non-autoregressive generator for discrete data. Diffusion models, in general,
have shown excellent ability to improve the generation quality by leveraging
inference-time scaling either by increasing the number of denoising steps or by
using external verifiers on top of the outputs of each step to guide the
generation. In this work, we propose a verifier-based inference-time scaling
method that aids in finding a better candidate generation during the denoising
process of the MDM. Our experiments demonstrate the application of MDMs for
standard text-style transfer tasks and establish MDMs as a better alternative
to autoregressive language models. Additionally, we show that a simple
soft-value-based verifier setup for MDMs using off-the-shelf pre-trained
embedding models leads to significant gains in generation quality even when
used on top of typical classifier-free guidance setups in the existing
literature.

</details>


### [7] [SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth](https://arxiv.org/abs/2508.11009)
*Wenpeng Xing,Lanyi Wei,Haixiao Hu,Rongchang Li,Mohan Li,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: 该研究指出现有大型语言模型（LLMs）安全框架对儿童用户的不足，引入SproutBench新基准测试评估了47个LLMs，揭示了显著的安全漏洞，并提出了儿童AI设计的实用指南。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全框架和LLM安全基准主要面向成年用户，未能充分考虑儿童和青少年独特的发育脆弱性以及不同年龄段（0-6岁、7-12岁、13-18岁）的认知、情感和社会风险。

Method: 开发了名为SproutBench的创新评估套件，包含1,283个基于发育理论设计的对抗性提示，旨在探测情感依赖、隐私侵犯和危险行为模仿等风险。该套件被用于对47个不同的大型语言模型进行了严格的实证评估。

Result: 研究揭示了LLM存在显著的安全漏洞。结果显示，安全性与风险预防之间存在强大的跨维度相关性，并且交互性与年龄适宜性之间存在显著的负相关关系。

Conclusion: 研究成果为推进以儿童为中心的AI设计和部署提供了实用的指导原则，强调需要重新评估并改进针对未成年用户的AI安全框架。

Abstract: The rapid proliferation of large language models (LLMs) in applications
targeting children and adolescents necessitates a fundamental reassessment of
prevailing AI safety frameworks, which are largely tailored to adult users and
neglect the distinct developmental vulnerabilities of minors. This paper
highlights key deficiencies in existing LLM safety benchmarks, including their
inadequate coverage of age-specific cognitive, emotional, and social risks
spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence
(13--18). To bridge these gaps, we introduce SproutBench, an innovative
evaluation suite comprising 1,283 developmentally grounded adversarial prompts
designed to probe risks such as emotional dependency, privacy violations, and
imitation of hazardous behaviors. Through rigorous empirical evaluation of 47
diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by
robust inter-dimensional correlations (e.g., between Safety and Risk
Prevention) and a notable inverse relationship between Interactivity and Age
Appropriateness. These insights yield practical guidelines for advancing
child-centric AI design and deployment.

</details>


### [8] [Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics](https://arxiv.org/abs/2508.11017)
*Carter Blum,Katja Filipova,Ann Yuan,Asma Ghandeharioun,Julian Zimmert,Fred Zhang,Jessica Hoffmann,Tal Linzen,Martin Wattenberg,Lucas Dixon,Mor Geva*

Main category: cs.CL

TL;DR: 本研究通过在受控环境下用小型Transformer模型和合成多语言数据集，深入探究大型语言模型（LLMs）跨语言知识迁移失败（幻觉）的原因。我们发现模型学习过程中存在一个关键的“统一”阶段，该阶段对跨语言迁移至关重要，并受事实与训练数据语言互信息的影响。基于此，我们开发了通过数据分布和分词来调节跨语言迁移的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在跨语言知识迁移方面存在困难，具体表现为当被问及以不同语言表达的事实时会产生幻觉。本研究旨在探究这种现象的根本原因和动态。

Method: 引入受控设置，从头开始在合成多语言数据集上训练小型Transformer模型。开发了通过操纵数据分布和分词来调节跨语言迁移水平的方法，并引入了度量指标和可视化方法来形式化地描述其对“统一”的影响。

Result: 识别出一个学习阶段，在此阶段模型会为相同事实在不同语言之间形成独立或统一的表示，并证明了“统一”对跨语言迁移至关重要。研究发现，统一的程度取决于事实与训练数据语言之间的互信息，以及提取该语言的难易程度。基于这些见解，成功开发了调节跨语言迁移水平的方法。

Conclusion: 受控设置能够阐明预训练动态，本研究为改善大型语言模型中的跨语言迁移提供了新的方向。

Abstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer:
they hallucinate when asked in one language about facts expressed in a
different language during training. This work introduces a controlled setting
to study the causes and dynamics of this phenomenon by training small
Transformer models from scratch on synthetic multilingual datasets. We identify
a learning phase wherein a model develops either separate or unified
representations of the same facts across languages, and show that unification
is essential for cross-lingual transfer. We also show that the degree of
unification depends on mutual information between facts and training data
language, and on how easy it is to extract that language. Based on these
insights, we develop methods to modulate the level of cross-lingual transfer by
manipulating data distribution and tokenization, and we introduce metrics and
visualizations to formally characterize their effects on unification. Our work
shows how controlled settings can shed light on pre-training dynamics and
suggests new directions for improving cross-lingual transfer in LLMs.

</details>


### [9] [Hell or High Water: Evaluating Agentic Recovery from External Failures](https://arxiv.org/abs/2508.11027)
*Andrew Wang,Sophia Hager,Adi Asija,Daniel Khashabi,Nicholas Andrews*

Main category: cs.CL

TL;DR: 研究发现，当语言模型代理在规划任务中遭遇外部失败时，它们难以制定和执行备用计划以适应环境反馈。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型代理被应用于日益复杂的现实世界问题，它们需要在大型搜索空间中制定计划。当这些计划因不可控原因失败时，评估语言代理在多大程度上能够寻找替代方法来实现其目标，是本研究的核心动机。

Method: 本研究设计了一个专门的代理规划基准，以函数调用组合的方式解决规划问题。代理从超过四千个可能的函数中搜索，并观察函数输出或错误消息形式的环境反馈。基准测试中引入了工作流程中的外部失败（如函数突然不可用），同时保证任务仍然可解。

Result: 研究发现，语言代理在响应环境反馈时，难以制定和执行备用计划。尽管最先进的模型通常能够在正确的上下文中识别出正确的函数，但它们难以适应环境反馈，并且常常无法寻求替代行动方案，即使在搜索空间被人为限制的情况下也是如此。研究还对开源和商业模型的失败进行了系统分析，考察了搜索空间大小的影响以及模型规模扩展带来的益处。

Conclusion: 分析揭示了当前生成模型在应对外部失败和适应环境反馈方面的关键挑战，并为未来的研究指明了有前景的方向。

Abstract: As language model agents are applied to real world problems of increasing
complexity, they will be expected to formulate plans across large search
spaces. If those plans fail for reasons beyond their control, how well do
language agents search for alternative ways to achieve their goals? We devise a
specialized agentic planning benchmark to study this question. Each planning
problem is solved via combinations of function calls. The agent searches for
relevant functions from a set of over four thousand possibilities, and observes
environmental feedback in the form of function outputs or error messages. Our
benchmark confronts the agent with external failures in its workflow, such as
functions that suddenly become unavailable. At the same time, even with the
introduction of these failures, we guarantee that the task remains solvable.
Ideally, an agent's performance on the planning task should not be affected by
the presence of external failures. Overall, we find that language agents
struggle to formulate and execute backup plans in response to environment
feedback. While state-of-the-art models are often able to identify the correct
function to use in the right context, they struggle to adapt to feedback from
the environment and often fail to pursue alternate courses of action, even when
the search space is artificially restricted. We provide a systematic analysis
of the failures of both open-source and commercial models, examining the
effects of search space size, as well as the benefits of scaling model size in
our setting. Our analysis identifies key challenges for current generative
models as well as promising directions for future work.

</details>


### [10] [BIPOLAR: Polarization-based granular framework for LLM bias evaluation](https://arxiv.org/abs/2508.11061)
*Martin Pavlíček,Tomáš Filip,Petr Sosík*

Main category: cs.CL

TL;DR: 本研究提出了一个可复用、细粒度、主题无关的框架，用于评估大型语言模型（LLMs）在敏感话题上的极化相关偏见。该框架结合极化敏感情感指标和合成数据集，通过以俄乌战争为例的案例研究，评估了多个LLMs，发现模型普遍对乌克兰表达更积极情绪，并揭示了模型间行为模式的差异，证明了框架在细粒度偏见评估上的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理政治、性别、民族等敏感话题时普遍存在偏见。尽管偏见检测和缓解技术已有显著进展，但某些挑战仍未被充分探索。

Method: 本研究提出了一个可复用、细粒度、主题无关的框架，以评估LLMs（包括开源和闭源）的极化相关偏见。该方法结合了极化敏感情感指标和通过预定义语义类别合成生成的平衡冲突相关陈述数据集。作为案例研究，构建了一个专注于俄乌战争的合成数据集，并评估了Llama-3、Mistral、GPT-4、Claude 3.5和Gemini 1.0等多个LLMs的偏见。

Result: 除了总体的偏见分数（显示模型普遍对乌克兰有更积极的情绪）外，该框架支持进行细粒度分析，揭示了不同语义类别之间显著的差异，并揭示了模型之间不同的行为模式。对提示词修改的适应性测试表明，模型对预设语言和国籍修改表现出进一步的偏见。

Conclusion: 该框架支持自动化数据集生成和细粒度偏见评估，适用于各种极化驱动的场景和主题，并且与许多其他偏见评估策略是正交的（互补的）。

Abstract: Large language models (LLMs) are known to exhibit biases in downstream tasks,
especially when dealing with sensitive topics such as political discourse,
gender identity, ethnic relations, or national stereotypes. Although
significant progress has been made in bias detection and mitigation techniques,
certain challenges remain underexplored. This study proposes a reusable,
granular, and topic-agnostic framework to evaluate polarisation-related biases
in LLM (both open-source and closed-source). Our approach combines
polarisation-sensitive sentiment metrics with a synthetically generated
balanced dataset of conflict-related statements, using a predefined set of
semantic categories.
  As a case study, we created a synthetic dataset that focusses on the
Russia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,
Mistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with
a general trend for more positive sentiment toward Ukraine, the framework
allowed fine-grained analysis with considerable variation between semantic
categories, uncovering divergent behavioural patterns among models. Adaptation
to prompt modifications showed further bias towards preconceived language and
citizenship modification.
  Overall, the framework supports automated dataset generation and fine-grained
bias assessment, is applicable to a variety of polarisation-driven scenarios
and topics, and is orthogonal to many other bias-evaluation strategies.

</details>


### [11] [Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs](https://arxiv.org/abs/2508.11068)
*Nicolas Goulet,Alexandre Blondin Massé,Moussa Abdendi*

Main category: cs.CL

TL;DR: 本文利用预训练大语言模型将数字词典嵌入到AMR有向图中，接着以保持回路空间的方式简化这些图，并分析简化后的图的特性及其与符号接地问题的关系。


<details>
  <summary>Details</summary>
Motivation: 将真实的数字词典知识嵌入到抽象语义表示（AMR）的有向图中，以丰富语义表示并连接现实世界知识。

Method: 首先，利用最先进的预训练大语言模型将真实的数字词典嵌入到AMR有向图中。接着，以合流的方式（即保持其回路空间的转换）简化这些图。

Result: 对简化后的有向图的特性进行了分析。

Conclusion: 分析了简化后的有向图的特性，并将其与符号接地问题进行了讨论。

Abstract: Abstract meaning representation (AMR) is a semantic formalism used to
represent the meaning of sentences as directed acyclic graphs. In this paper,
we describe how real digital dictionaries can be embedded into AMR directed
graphs (digraphs), using state-of-the-art pre-trained large language models.
Then, we reduce those graphs in a confluent manner, i.e. with transformations
that preserve their circuit space. Finally, the properties of these reduces
digraphs are analyzed and discussed in relation to the symbol grounding
problem.

</details>


### [12] [Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](https://arxiv.org/abs/2508.11120)
*Lorenzo Jaime Yu Flores,Junyi Shen,Xiaoyuan Gu*

Main category: cs.CL

TL;DR: 本文提出一个名为RAMP的多智能体框架，结合大语言模型规划、工具调用、迭代验证和长期记忆，以提升市场营销中受众甄选任务的可靠性和准确性，并在实际测试中显著提高了准确性和召回率。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）驱动的AI智能体在规划和工具交互方面取得进展，但其在实际应用中的可靠性仍有待验证。本研究旨在提升LLM智能体在真实营销任务（受众甄选）中的可靠性。

Method: 引入了一个名为RAMP的多智能体框架，该框架能迭代地进行规划、调用工具、验证输出并生成改进建议。此外，模型配备了长期记忆存储，作为包含客户特定事实和历史查询的知识库。

Result: 通过结合LLM规划和记忆，在88个评估查询上将准确率提高了28个百分点。在更模糊的查询上，迭代验证和反思显著提高了召回率（约20个百分点），并带来了更高的用户满意度。

Conclusion: 研究结果为在动态、面向行业的环境中部署可靠的基于LLM的系统提供了实用的见解，证明了LLM规划、记忆和迭代验证在提升系统可靠性方面的有效性。

Abstract: Recent advances in large language models (LLMs) enabled the development of AI
agents that can plan and interact with tools to complete complex tasks.
However, literature on their reliability in real-world applications remains
limited. In this paper, we introduce a multi-agent framework for a marketing
task: audience curation. To solve this, we introduce a framework called RAMP
that iteratively plans, calls tools, verifies the output, and generates
suggestions to improve the quality of the audience generated. Additionally, we
equip the model with a long-term memory store, which is a knowledge base of
client-specific facts and past queries. Overall, we demonstrate the use of LLM
planning and memory, which increases accuracy by 28 percentage points on a set
of 88 evaluation queries. Moreover, we show the impact of iterative
verification and reflection on more ambiguous queries, showing progressively
better recall (roughly +20 percentage points) with more verify/reflect
iterations on a smaller challenge set, and higher user satisfaction. Our
results provide practical insights for deploying reliable LLM-based systems in
dynamic, industry-facing environments.

</details>


### [13] [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)
*Tomer Wolfson,Harsh Trivedi,Mor Geva,Yoav Goldberg,Dan Roth,Tushar Khot,Ashish Sabharwal,Reut Tsarfaty*

Main category: cs.CL

TL;DR: 本文介绍了MoNaCo，一个包含1,315个自然且复杂的查询信息问题的基准测试，旨在解决现有LLM基准缺少人类耗时问题的不足。前沿LLM在此基准上表现不佳，凸显了对更强推理模型的需求。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）基准测试缺乏真正耗时且自然的信息查询问题，无法有效评估LLM在处理复杂现实世界信息查询方面的能力。

Method: 引入了MoNaCo基准测试，包含1,315个需要多步推理的复杂自然问题。为构建此基准，开发了一个分解式标注流程，用于大规模地获取并手动回答这些耗时问题。

Result: 前沿LLM在MoNaCo基准上表现不佳，最高F1分数仅为61.2%，主要受低召回率和幻觉问题的限制。

Conclusion: 研究结果强调，需要开发能更好处理复杂和广泛现实世界信息查询的推理模型；MoNaCo为追踪此类进展提供了有效的资源。

Abstract: Large language models (LLMs) are emerging as a go-to tool for querying
information. However, current LLM benchmarks rarely feature natural questions
that are both information-seeking as well as genuinely time-consuming for
humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural
and complex questions that require dozens, and at times hundreds, of
intermediate steps to solve -- far more than any existing QA benchmark. To
build MoNaCo, we developed a decomposed annotation pipeline to elicit and
manually answer natural time-consuming questions at scale. Frontier LLMs
evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and
hallucinations. Our results underscore the need for reasoning models that
better handle the complexity and sheer breadth of real-world
information-seeking questions -- with MoNaCo providing an effective resource
for tracking such progress. The MONACO benchmark, codebase, prompts and models
predictions are publicly available at: https://tomerwolgithub.github.io/monaco

</details>


### [14] [MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering](https://arxiv.org/abs/2508.11163)
*Hikaru Asano,Hiroki Ouchi,Akira Kasuga,Ryo Yonetani*

Main category: cs.CL

TL;DR: 本文提出了MobQA，一个旨在通过自然语言问答评估大型语言模型（LLMs）对人类移动数据语义理解能力的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有模型在预测人类移动模式方面表现出色，但其在解释模式的潜在原因或语义含义方面的能力尚不明确。

Method: 研究构建了MobQA数据集，包含5800个高质量问答对，涵盖事实检索、多项选择推理和自由解释三种问题类型，这些问题均需要空间、时间及语义推理能力。该数据集用于评估LLM对多样化人类GPS轨迹数据的理解。

Result: 对主流LLMs的评估显示，它们在事实检索方面表现强劲，但在语义推理和解释性问答方面存在显著局限，且轨迹长度对模型的有效性有很大影响。

Conclusion: 这些发现揭示了当前最先进的LLMs在语义移动理解方面的成就和局限性。

Abstract: This paper presents MobQA, a benchmark dataset designed to evaluate the
semantic understanding capabilities of large language models (LLMs) for human
mobility data through natural language question answering.
  While existing models excel at predicting human movement patterns, it remains
unobvious how much they can interpret the underlying reasons or semantic
meaning of those patterns. MobQA provides a comprehensive evaluation framework
for LLMs to answer questions about diverse human GPS trajectories spanning
daily to weekly granularities. It comprises 5,800 high-quality question-answer
pairs across three complementary question types: factual retrieval (precise
data extraction), multiple-choice reasoning (semantic inference), and free-form
explanation (interpretive description), which all require spatial, temporal,
and semantic reasoning. Our evaluation of major LLMs reveals strong performance
on factual retrieval but significant limitations in semantic reasoning and
explanation question answering, with trajectory length substantially impacting
model effectiveness. These findings demonstrate the achievements and
limitations of state-of-the-art LLMs for semantic mobility
understanding.\footnote{MobQA dataset is available at
https://github.com/CyberAgentAILab/mobqa.}

</details>


### [15] [Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification](https://arxiv.org/abs/2508.11166)
*Anusha M D,Deepthi Vikram,Bharathi Raja Chakravarthi,Parameshwar R Hegde*

Main category: cs.CL

TL;DR: 本研究为低资源、语码混合的图卢语社交媒体内容构建了首个冒犯性语言识别基准数据集，并评估了多种深度学习模型，发现BiGRU表现最佳，而多语言Transformer模型效果不佳。


<details>
  <summary>Details</summary>
Motivation: 图卢语作为一种低资源德拉威语，尽管数字化程度日益提高，但计算资源匮乏。目前缺乏针对其语码混合社交媒体内容的冒犯性语言识别计算资源和基准数据集。

Method: 1. 从YouTube评论中收集语码混合的图卢语社交媒体内容，构建了首个冒犯性语言识别（OLI）基准数据集。2. 数据集包含3,845条评论，分为四类，并具有高标注一致性（Krippendorff's alpha = 0.984）。3. 评估了多种深度学习模型（如GRU、LSTM、BiGRU、BiLSTM、CNN及注意力变体）和Transformer架构（mBERT、XLM-RoBERTa）。

Result: 1. 带有自注意力机制的BiGRU模型表现最佳，准确率达82%，宏F1分数为0.81。2. Transformer模型表现不佳，突显了多语言预训练模型在语码混合、低资源语境下的局限性。

Conclusion: 本研究为图卢语及类似低资源、语码混合语言的进一步自然语言处理研究奠定了基础。

Abstract: Tulu, a low-resource Dravidian language predominantly spoken in southern
India, has limited computational resources despite its growing digital
presence. This study presents the first benchmark dataset for Offensive
Language Identification (OLI) in code-mixed Tulu social media content,
collected from YouTube comments across various domains. The dataset, annotated
with high inter-annotator agreement (Krippendorff's alpha = 0.984), includes
3,845 comments categorized into four classes: Not Offensive, Not Tulu,
Offensive Untargeted, and Offensive Targeted. We evaluate a suite of deep
learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based
variants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU
model with self-attention achieves the best performance with 82% accuracy and a
0.81 macro F1-score. Transformer models underperform, highlighting the
limitations of multilingual pretraining in code-mixed, under-resourced
contexts. This work lays the foundation for further NLP research in Tulu and
similar low-resource, code-mixed languages.

</details>


### [16] [Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction](https://arxiv.org/abs/2508.11184)
*Tao Wu,Jingyuan Chen,Wang Lin,Jian Zhan,Mengze Li,Kun Kuang,Fei Wu*

Main category: cs.CL

TL;DR: 本文提出一种无训练的双阶段框架，用于生成个性化干扰项，通过推断学生个体误解来提高诊断性评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型生成的干扰项通常是群体层面的，无法捕捉学生个体的多样化推理错误。个性化干扰项能更有效诊断特定错误，但由于学生答题记录少且缺乏推理过程，实现起来面临挑战。

Method: 提出一个无训练的双阶段框架：第一阶段，利用蒙特卡洛树搜索（MCTS）从学生过去的错误答案中恢复推理轨迹，构建学生特有的误解原型；第二阶段，该原型指导学生在新问题上的推理模拟，生成符合学生反复出现的误解的个性化干扰项。

Result: 实验证明，该方法在为140名学生生成合理且个性化的干扰项方面表现最佳，并能有效推广到群体层面设置。

Conclusion: 该方法具有鲁棒性和适应性，能够有效生成个性化和群体层面的干扰项，从而更好地诊断学生误解。

Abstract: Distractors, incorrect but plausible answer choices in multiple-choice
questions (MCQs), play a critical role in educational assessment by diagnosing
student misconceptions. Recent work has leveraged large language models (LLMs)
to generate shared, group-level distractors by learning common error patterns
across large student populations. However, such distractors often fail to
capture the diverse reasoning errors of individual students, limiting their
diagnostic effectiveness. To address this limitation, we introduce the task of
personalized distractor generation, which aims to generate tailored distractors
based on individual misconceptions inferred from each student's past
question-answering (QA) records, ensuring every student receives options that
effectively exposes their specific reasoning errors. While promising, this task
is challenging because each student typically has only a few QA records, which
often lack the student's underlying reasoning processes, making training-based
group-level approaches infeasible. To overcome this, we propose a training-free
two-stage framework. In the first stage, we construct a student-specific
misconception prototype by applying Monte Carlo Tree Search (MCTS) to recover
the student's reasoning trajectories from past incorrect answers. In the second
stage, this prototype guides the simulation of the student's reasoning on new
questions, enabling the generation of personalized distractors that align with
the student's recurring misconceptions. Experiments show that our approach
achieves the best performance in generating plausible, personalized distractors
for 140 students, and also effectively generalizes to group-level settings,
highlighting its robustness and adaptability.

</details>


### [17] [Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation](https://arxiv.org/abs/2508.11189)
*Chenyang Le,Yinfeng Xia,Huiyan Li,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: 本文提出一种寄生式双尺度方法，结合增强推测采样、模型压缩和知识蒸馏，显著提升Whisper Medium模型在多语种语音翻译中的推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一的多语种语音文本翻译模型参数量巨大，导致推理效率与性能难以平衡，尤其在本地部署场景下。

Method: 提出创新的“寄生式双尺度方法”，结合增强的推测采样、模型压缩和知识蒸馏技术。在Whisper Medium模型基础上，将其增强为whisperM2M，并集成新颖的KVSPN模块。

Result: 在六种流行语言上实现了最先进(SOTA)性能，并显著提升推理效率。KVSPN模块实现了40%的加速且无BLEU分数下降。结合蒸馏方法，相比原始Whisper Medium模型，速度提升了2.6倍且性能更优。

Conclusion: 所提出的寄生式双尺度方法有效解决了多语种语音翻译模型在效率与性能之间的权衡问题，为本地部署提供了高效且高性能的解决方案。

Abstract: Recent advancements in speech-to-text translation have led to the development
of multilingual models capable of handling multiple language pairs
simultaneously. However, these unified models often suffer from large parameter
sizes, making it challenging to balance inference efficiency and performance,
particularly in local deployment scenarios. We propose an innovative Parasitic
Dual-Scale Approach, which combines an enhanced speculative sampling method
with model compression and knowledge distillation techniques. Building on the
Whisper Medium model, we enhance it for multilingual speech translation into
whisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art
(SOTA) performance across six popular languages with improved inference
efficiency. KVSPN enables a 40\% speedup with no BLEU score degradation.
Combined with distillation methods, it represents a 2.6$\times$ speedup over
the original Whisper Medium with superior performance.

</details>


### [18] [E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection](https://arxiv.org/abs/2508.11197)
*Ahmad Mousavi,Yeganeh Abdollahinejad,Roberto Corizzo,Nathalie Japkowicz,Zois Boukouvalas*

Main category: cs.CL

TL;DR: E-CaTCH是一个可解释、可扩展的多模态虚假信息检测框架，通过事件级聚类、模态融合和时间演化建模，有效解决了社交媒体上模态不一致、时间模式变化和类别不平衡等挑战，并在多个数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在社交媒体上检测多模态虚假信息面临挑战，主要源于模态间的不一致性、时间模式的变化以及严重的类别不平衡。现有方法常独立处理帖子，未能捕捉到连接帖子跨时间和模态的事件级结构。

Method: 本文提出E-CaTCH框架。它首先根据文本相似性和时间邻近性将帖子聚类为伪事件。在每个事件内，使用BERT和ResNet提取并融合文本和视觉特征（通过模内自注意力精炼、双向跨模态注意力对齐、软门控机制融合）。为建模时间演变，E-CaTCH将事件分割为重叠时间窗口，并使用增强语义偏移和动量信号的趋势感知LSTM。分类在事件级别进行。为解决类别不平衡，模型集成了自适应类别加权、时间一致性正则化和难例挖掘，总损失聚合所有事件的损失。

Result: 在Fakeddit、IND和COVID-19 MISINFOGRAPH数据集上的大量实验表明，E-CaTCH持续优于最先进的基线方法。跨数据集评估进一步证明了其鲁棒性、泛化能力和在多样虚假信息场景中的实际适用性。

Conclusion: E-CaTCH框架通过其独特的事件级处理、模态融合和时间演化建模能力，成功克服了多模态虚假信息检测的关键挑战，展现出卓越的检测性能、鲁棒性和普适性，为该领域提供了有效且可解释的解决方案。

Abstract: Detecting multimodal misinformation on social media remains challenging due
to inconsistencies between modalities, changes in temporal patterns, and
substantial class imbalance. Many existing methods treat posts independently
and fail to capture the event-level structure that connects them across time
and modality. We propose E-CaTCH, an interpretable and scalable framework for
robustly detecting misinformation. If needed, E-CaTCH clusters posts into
pseudo-events based on textual similarity and temporal proximity, then
processes each event independently. Within each event, textual and visual
features are extracted using pre-trained BERT and ResNet encoders, refined via
intra-modal self-attention, and aligned through bidirectional cross-modal
attention. A soft gating mechanism fuses these representations to form
contextualized, content-aware embeddings of each post. To model temporal
evolution, E-CaTCH segments events into overlapping time windows and uses a
trend-aware LSTM, enhanced with semantic shift and momentum signals, to encode
narrative progression over time. Classification is performed at the event
level, enabling better alignment with real-world misinformation dynamics. To
address class imbalance and promote stable learning, the model integrates
adaptive class weighting, temporal consistency regularization, and hard-example
mining. The total loss is aggregated across all events. Extensive experiments
on Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH
consistently outperforms state-of-the-art baselines. Cross-dataset evaluations
further demonstrate its robustness, generalizability, and practical
applicability across diverse misinformation scenarios.

</details>


### [19] [Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2508.11247)
*Changjian Wang,Weihong Deng,Weili Guan,Quan Lu,Ning Jiang*

Main category: cs.CL

TL;DR: 本文提出HGRAG，一种基于超图的新型RAG方法，用于多跳问答（MHQA）。HGRAG通过超图整合结构化和语义信息，解决了传统RAG忽略结构关联和GraphRAG过度依赖结构的问题，显著提升了问答性能和检索效率。


<details>
  <summary>Details</summary>
Motivation: 多跳问答需要整合分散的知识。传统RAG方法侧重粗粒度文本语义，忽视结构关联，限制了其在MHQA中的效果。GraphRAG虽然利用知识图谱捕获结构关联，但过度依赖结构信息和细粒度检索，未能充分利用文本语义。因此，需要一种能有效整合结构和语义信息，并兼顾不同粒度的方法。

Method: 本文提出HGRAG方法。结构上，构建一个实体超图，将细粒度实体作为节点，粗粒度段落作为超边，通过共享实体建立知识关联。语义上，设计超图检索方法，通过超图扩散整合细粒度实体相似性和粗粒度段落相似性。最后，采用一个检索增强模块，从语义和结构上进一步优化检索结果，为LLM问答生成提供最相关的上下文。

Result: 实验结果表明，HGRAG在基准数据集上的问答性能优于现有最先进方法，并实现了6倍的检索效率提升。

Conclusion: HGRAG通过超图实现了结构和语义信息的跨粒度整合，显著提升了多跳问答的性能和检索效率，为解决MHQA中的知识整合挑战提供了有效方案。

Abstract: Multi-hop question answering (MHQA) requires integrating knowledge scattered
across multiple passages to derive the correct answer. Traditional
retrieval-augmented generation (RAG) methods primarily focus on coarse-grained
textual semantic similarity and ignore structural associations among dispersed
knowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods
address this by leveraging knowledge graphs (KGs) to capture structural
associations, but they tend to overly rely on structural information and
fine-grained word- or phrase-level retrieval, resulting in an underutilization
of textual semantics. In this paper, we propose a novel RAG approach called
HGRAG for MHQA that achieves cross-granularity integration of structural and
semantic information via hypergraphs. Structurally, we construct an entity
hypergraph where fine-grained entities serve as nodes and coarse-grained
passages as hyperedges, and establish knowledge association through shared
entities. Semantically, we design a hypergraph retrieval method that integrates
fine-grained entity similarity and coarse-grained passage similarity via
hypergraph diffusion. Finally, we employ a retrieval enhancement module, which
further refines the retrieved results both semantically and structurally, to
obtain the most relevant passages as context for answer generation with the
LLM. Experimental results on benchmark datasets demonstrate that our approach
outperforms state-of-the-art methods in QA performance, and achieves a
6$\times$ speedup in retrieval efficiency.

</details>


### [20] [UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?](https://arxiv.org/abs/2508.11260)
*Mukund Choudhary,KV Aditya Srivatsa,Gaurja Aeron,Antara Raaghavi Bhattacharya,Dang Khoa Dang Dinh,Ikhlasul Akmal Hanif,Daria Kotova,Ekaterina Kochmar,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本研究分析了大型语言模型（LLMs）在低资源语言的语言学难题上的表现。结果显示，LLMs难以处理形态复杂性高的任务，但对常见于英语的语言特征表现较好。将单词拆分为词素能提升解决能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理任务中展现出潜力，但在语言学难题（特别是低资源语言的语言学奥赛题）上的表现却持续不佳，需要对其语言学推理能力进行深入评估。

Method: 研究分析了LLMs在来自41种低资源语言的629个语言学奥赛题上的表现，并对每个问题标注了语言学特征，以揭示LLMs的弱点。

Result: 研究发现：1. LLMs在涉及更高形态复杂性的难题上表现不佳。2. LLMs在涉及英语中也存在的语言特征的难题上表现更好。3. 将单词预处理为词素可以提高问题的可解性。

Conclusion: 本研究揭示了LLMs在语言学推理和低资源语言建模方面的一些挑战，并强调需要开发更具语言特异性且信息更丰富的分词器。

Abstract: Large language models (LLMs) have demonstrated potential in reasoning tasks,
but their performance on linguistics puzzles remains consistently poor. These
puzzles, often derived from Linguistics Olympiad (LO) contests, provide a
minimal contamination environment to assess LLMs' linguistic reasoning
abilities across low-resource languages. This work analyses LLMs' performance
on 629 problems across 41 low-resource languages by labelling each with
linguistically informed features to unveil weaknesses. Our analyses show that
LLMs struggle with puzzles involving higher morphological complexity and
perform better on puzzles involving linguistic features that are also found in
English. We also show that splitting words into morphemes as a pre-processing
step improves solvability, indicating a need for more informed and
language-specific tokenisers. These findings thus offer insights into some
challenges in linguistic reasoning and modelling of low-resource languages.

</details>


### [21] [LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought](https://arxiv.org/abs/2508.11280)
*Ruiyan Qi,Congding Wen,Weibo Zhou,Shangsong Liang,Lingbo Li*

Main category: cs.CL

TL;DR: 本文提出LETToT框架，利用专家驱动的思维链进行无标注的领域特定（旅游）LLM评估，证明了该方法的有效性，并发现缩放定律在专业领域仍适用，同时推理增强的小模型能缩小与大模型的差距。


<details>
  <summary>Details</summary>
Motivation: 在旅游等特定领域评估大型语言模型（LLM）面临挑战，主要原因在于标注基准数据集成本高昂以及LLM普遍存在的幻觉问题。

Method: 提出LETToT（Label-Free Evaluation of LLM on Tourism using Expert Tree-of-Thought）框架，该框架利用专家推导的推理结构而非标注数据来评估LLM。首先，通过与通用质量维度和专家反馈对齐，迭代优化并验证了分层ToT组件，提升了专家ToT的有效性。其次，将优化后的LETToT应用于评估不同规模（32B-671B）的模型。

Result: 研究结果表明：1) 经过系统优化的专家ToT比基线获得了4.99-14.15%的相对质量增益。2) 缩放定律在专业领域依然存在（DeepSeek-V3表现领先），但推理增强型的小型模型（如DeepSeek-R1-Distill-Llama-70B）能够缩小这一差距。3) 对于72B以下的模型，明确的推理架构在准确性和简洁性方面优于同类模型（p<0.05）。

Conclusion: 本研究建立了一个可扩展、无标注的领域特定LLM评估范式，为传统标注基准提供了一个稳健的替代方案。

Abstract: Evaluating large language models (LLMs) in specific domain like tourism
remains challenging due to the prohibitive cost of annotated benchmarks and
persistent issues like hallucinations. We propose $\textbf{L}$able-Free
$\textbf{E}$valuation of LLM on $\textbf{T}$ourism using Expert
$\textbf{T}$ree-$\textbf{o}$f-$\textbf{T}$hought (LETToT), a framework that
leverages expert-derived reasoning structures-instead of labeled data-to access
LLMs in tourism. First, we iteratively refine and validate hierarchical ToT
components through alignment with generic quality dimensions and expert
feedback. Results demonstrate the effectiveness of our systematically optimized
expert ToT with 4.99-14.15\% relative quality gains over baselines. Second, we
apply LETToT's optimized expert ToT to evaluate models of varying scales
(32B-671B parameters), revealing: (1) Scaling laws persist in specialized
domains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,
DeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit
reasoning architectures outperform counterparts in accuracy and conciseness
($p<0.05$). Our work established a scalable, label-free paradigm for
domain-specific LLM evaluation, offering a robust alternative to conventional
annotated benchmarks.

</details>


### [22] [ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection](https://arxiv.org/abs/2508.11281)
*Axel Delaval,Shujian Yang,Haicheng Wang,Han Qiu,Jialiang Lu*

Main category: cs.CL

TL;DR: 本文发布了大规模法语毒性评论数据集TOXIFRENCH，提出了一种动态加权损失的思维链（CoT）微调策略，并发现小型语言模型在法语毒性检测任务中表现优于大型模型，最终实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管英语毒性内容检测取得了显著进展，但法语领域的检测仍不成熟，主要原因在于缺乏与文化相关的大规模数据集。

Method: 1. 构建了TOXIFRENCH数据集，包含53,622条法语在线评论，采用LLM预标注和人工验证的半自动化流程，将人工标注量减少至10%。2. 提出了一种新颖的思维链（CoT）微调策略，结合动态加权损失，以逐步强调模型的最终决策，显著提高忠实度。

Result: 1. 小型语言模型（SLMs）在毒性检测任务中的鲁棒性和泛化能力优于许多大型模型。2. 经过微调的4B模型实现了最先进的性能，其F1分数比基线提高了13%，并超越了GPT-40和Gemini-2.5等大型语言模型。3. 在跨语言毒性基准测试中也表现出强大的多语言能力。

Conclusion: 该研究方法可有效推广到其他语言和安全关键型分类任务。

Abstract: Detecting toxic content using language models is crucial yet challenging.
While substantial progress has been made in English, toxicity detection in
French remains underdeveloped, primarily due to the lack of culturally
relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new
public benchmark of 53,622 French online comments, constructed via a
semi-automated annotation pipeline that reduces manual labeling to only 10%
through high-confidence LLM-based pre-annotation and human verification. Then,
we benchmark a broad range of models and uncover a counterintuitive insight:
Small Language Models (SLMs) outperform many larger models in robustness and
generalization under the toxicity detection task. Motivated by this finding, we
propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic
weighted loss that progressively emphasizes the model's final decision,
significantly improving faithfulness. Our fine-tuned 4B model achieves
state-of-the-art performance, improving its F1 score by 13% over its baseline
and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a
cross-lingual toxicity benchmark demonstrates strong multilingual ability,
suggesting that our methodology can be effectively extended to other languages
and safety-critical classification tasks.

</details>


### [23] [AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries](https://arxiv.org/abs/2508.11285)
*Arya VarastehNezhad,Reza Tavasoli,Soroush Elyasi,MohammadHossein LotfiNia,Hamed Farbeh*

Main category: cs.CL

TL;DR: 一项研究分析了8个大型语言模型（LLMs）对抑郁症、焦虑症和压力相关问题的回答情绪，发现模型的选择和问题的主题（心理健康状况）对情感表达有显著影响，而用户画像影响甚微。


<details>
  <summary>Details</summary>
Motivation: 抑郁症、焦虑症和压力是普遍的心理健康问题，越来越多的人通过大型语言模型（LLMs）寻求相关信息。因此，研究LLMs如何回应这些问题至关重要。

Method: 研究调查了8个LLMs（Claude Sonnet, Copilot, Gemini Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, Perplexity）对20个关于抑郁症、焦虑症和压力的实用问题的回答。这些问题针对六种用户画像（基线、女性、男性、年轻人、老年人、大学生）进行了构建。共生成了2,880个回答，并使用先进工具对情绪和情感进行了评分分析。

Result: 分析显示，乐观、恐惧和悲伤在所有回答中占据主导，中性情绪保持高位。LLM的选择显著影响情绪表达模式（Mixtral负面情绪最多，Llama最乐观）。心理健康状况类型也极大地塑造了情绪反应（焦虑引发高恐惧，抑郁引发高悲伤和负面情绪，压力引发最乐观）。相比之下，查询的用户画像对情绪语气的变化影响微乎其微。统计分析证实了模型和条件特异性差异显著，而人口统计学影响最小。

Conclusion: 研究结果强调了在心理健康应用中模型选择的至关重要性，因为每个LLM都表现出独特的情感特征，这可能显著影响用户体验和结果。

Abstract: Depression, anxiety, and stress are widespread mental health concerns that
increasingly drive individuals to seek information from Large Language Models
(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini
Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty
pragmatic questions about depression, anxiety, and stress when those questions
are framed for six user profiles (baseline, woman, man, young, old, and
university student). The models generated 2,880 answers, which we scored for
sentiment and emotions using state-of-the-art tools. Our analysis revealed that
optimism, fear, and sadness dominated the emotional landscape across all
outputs, with neutral sentiment maintaining consistently high values.
Gratitude, joy, and trust appeared at moderate levels, while emotions such as
anger, disgust, and love were rarely expressed. The choice of LLM significantly
influenced emotional expression patterns. Mixtral exhibited the highest levels
of negative emotions including disapproval, annoyance, and sadness, while Llama
demonstrated the most optimistic and joyful responses. The type of mental
health condition dramatically shaped emotional responses: anxiety prompts
elicited extraordinarily high fear scores (0.974), depression prompts generated
elevated sadness (0.686) and the highest negative sentiment, while
stress-related queries produced the most optimistic responses (0.755) with
elevated joy and trust. In contrast, demographic framing of queries produced
only marginal variations in emotional tone. Statistical analyses confirmed
significant model-specific and condition-specific differences, while
demographic influences remained minimal. These findings highlight the critical
importance of model selection in mental health applications, as each LLM
exhibits a distinct emotional signature that could significantly impact user
experience and outcomes.

</details>


### [24] [SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory](https://arxiv.org/abs/2508.11290)
*Utsav Maskey,Sumit Yadav,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 研究提出SafeConstellations方法，通过引导LLM嵌入空间轨迹，有效降低多达73%的过度拒绝率，解决模型误拒良性指令问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）普遍存在“过度拒绝”行为，即因安全机制误将良性指令识别为有害内容并拒绝响应，这严重降低了LLM在生产应用中的实用性，尤其是在重复使用常见提示模板或执行特定任务（如情感分析、语言翻译）时。

Method: 通过机制分析，研究发现LLM的表征在嵌入空间中遵循独特的“星座”模式，不同任务的轨迹一致，且在拒绝和非拒绝情况间可预测地转换。基于此，本文引入了SafeConstellations，这是一种推理时轨迹偏移方法，它跟踪特定任务的轨迹模式，并引导模型表征朝非拒绝路径移动。该方法仅选择性地作用于易于过度拒绝的任务，同时保持模型的一般行为。

Result: SafeConstellations方法能够将LLM的过度拒绝率降低高达73%，同时对模型整体实用性影响极小。

Conclusion: SafeConstellations提供了一种原则性的方法来有效缓解大型语言模型的过度拒绝行为，提升其在实际应用中的可靠性和实用性。

Abstract: LLMs increasingly exhibit over-refusal behavior, where safety mechanisms
cause models to reject benign instructions that superficially resemble harmful
content. This phenomena diminishes utility in production applications that
repeatedly rely on common prompt templates or applications that frequently rely
on LLMs for specific tasks (e.g. sentiment analysis, language translation).
Through comprehensive evaluation, we demonstrate that LLMs still tend to refuse
responses to harmful instructions when those instructions are reframed to
appear as benign tasks. Our mechanistic analysis reveal that LLMs follow
distinct "constellation" patterns in embedding space as representations
traverse layers, with each task maintaining consistent trajectories that shift
predictably between refusal and non-refusal cases. We introduce
SafeConstellations, an inference-time trajectory-shifting approach that tracks
task-specific trajectory patterns and guides representations toward non-refusal
pathways. By selectively guiding model behavior only on tasks prone to
over-refusal, and by preserving general model behavior, our method reduces
over-refusal rates by up to 73% with minimal impact on utility-offering a
principled approach to mitigating over-refusals.

</details>


### [25] [SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems](https://arxiv.org/abs/2508.11310)
*Beichen Guo,Zhiyuan Wen,Yu Yang,Peng Gao,Ruosong Yang,Jiaxing Shen*

Main category: cs.CL

TL;DR: 本文提出SGSimEval，一个用于评估自动综述生成（ASG）系统的新基准，它结合了多方面评估和人类偏好，发现现有ASG系统在提纲生成方面表现出色，但在内容和参考文献生成方面仍有显著提升空间。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）推动自动综述生成（ASG）发展，急需鲁棒的评估方法。然而，现有评估方法存在局限性，包括指标偏颇、缺乏人类偏好以及过度依赖LLM作为评判者。

Method: 提出SGSimEval，一个综合性的综述生成评估基准。它通过整合提纲、内容和参考文献评估，并结合基于LLM的评分与定量指标，提供多方面评估框架。SGSimEval还引入了强调内在质量和与人类相似度的人类偏好指标。

Result: 实验显示，当前ASG系统在提纲生成方面表现出与人类相当的优越性，但在内容和参考文献生成方面仍有显著提升空间。此外，SGSimEval的评估指标与人类评估保持高度一致性。

Conclusion: SGSimEval提供了一个全面且与人类评估一致的自动综述生成评估框架，揭示了当前ASG系统在不同生成环节的优势与不足，为未来的研究指明了方向。

Abstract: The growing interest in automatic survey generation (ASG), a task that
traditionally required considerable time and effort, has been spurred by recent
advances in large language models (LLMs). With advancements in
retrieval-augmented generation (RAG) and the rising popularity of multi-agent
systems (MASs), synthesizing academic surveys using LLMs has become a viable
approach, thereby elevating the need for robust evaluation methods in this
domain. However, existing evaluation methods suffer from several limitations,
including biased metrics, a lack of human preference, and an over-reliance on
LLMs-as-judges. To address these challenges, we propose SGSimEval, a
comprehensive benchmark for Survey Generation with Similarity-Enhanced
Evaluation that evaluates automatic survey generation systems by integrating
assessments of the outline, content, and references, and also combines
LLM-based scoring with quantitative metrics to provide a multifaceted
evaluation framework. In SGSimEval, we also introduce human preference metrics
that emphasize both inherent quality and similarity to humans. Extensive
experiments reveal that current ASG systems demonstrate human-comparable
superiority in outline generation, while showing significant room for
improvement in content and reference generation, and our evaluation metrics
maintain strong consistency with human assessments.

</details>


### [26] [LLM Compression: How Far Can We Go in Balancing Size and Performance?](https://arxiv.org/abs/2508.11318)
*Sahil Sk,Debasish Dhal,Sonal Khosla,Sk Shahid,Sambit Shekhar,Akash Dhaka,Shantipriya Parida,Dilip K. Prasad,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本研究评估了在小型LLM（如LLaMA 1B, Qwen 0.5B, PHI 1.5B）上应用4位GSQ和GPTQ量化技术，分析其在多项NLP任务中的性能和效率权衡，旨在为实际部署提供参考。


<details>
  <summary>Details</summary>
Motivation: 量化是提高大型语言模型（LLMs）可访问性的关键技术，它通过降低内存和计算成本来保持性能。本研究旨在评估低位量化技术在现实世界部署中的适用性。

Method: 将4位Group Scaling Quantization (GSQ) 和 Generative Pretrained Transformer Quantization (GPTQ) 应用于LLaMA 1B、Qwen 0.5B和PHI 1.5B模型。在MS MARCO、BoolQ和GSM8K数据集上进行基准测试，评估准确性、推理延迟和吞吐量。

Result: 研究揭示了模型压缩与任务性能之间的权衡，为低位量化在实际部署中的适用性提供了深入见解。同时，讨论了GSQ和GPTQ技术在不同大小模型上的优缺点。

Conclusion: 研究结果可帮助用户根据具体需求做出合适的部署决策。本研究也为未来的量化实验提供了重要的基准。

Abstract: Quantization is an essential and popular technique for improving the
accessibility of large language models (LLMs) by reducing memory usage and
computational costs while maintaining performance. In this study, we apply
4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer
Quantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their
impact across multiple NLP tasks. We benchmark these models on MS MARCO
(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K
(Mathematical Reasoning) datasets, assessing both accuracy and efficiency
across various tasks. The study measures the trade-offs between model
compression and task performance, analyzing key evaluation metrics, namely
accuracy, inference latency, and throughput (total output tokens generated per
second), providing insights into the suitability of low-bit quantization for
real-world deployment. Using the results, users can then make suitable
decisions based on the specifications that need to be met. We discuss the pros
and cons of GSQ and GPTQ techniques on models of different sizes, which also
serve as a benchmark for future experiments.

</details>


### [27] [SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis](https://arxiv.org/abs/2508.11343)
*Haitong Luo,Weiyao Zhang,Suhang Wang,Wenji Zou,Chungang Lin,Xuying Meng,Yujun Zhang*

Main category: cs.CL

TL;DR: 通过将文本检测重构为信号处理问题，该研究发现人类文本在频域具有更高的频谱能量，并基于此开发了名为SpecDetect的高效且可解释的LLM生成文本检测器。


<details>
  <summary>Details</summary>
Motivation: 高质量大型语言模型（LLM）文本的普及要求可靠高效的检测方法。现有训练无关方法通常依赖于表面统计特征，忽略了文本生成过程的基本信号特性。

Method: 将文本检测视为信号处理问题，分析令牌对数概率序列在频域中的特性。系统地使用全局离散傅里叶变换（DFT）和局部短时傅里叶变换（STFT）分析信号的频谱特性。基于DFT总能量构建了检测器SpecDetect，并通过引入采样差异机制提出了增强版本SpecDetect++。

Result: 研究发现人类文本始终表现出显著更高的频谱能量，这反映了人类写作中固有的较大振幅波动，而LLM生成文本的动态被抑制。实验证明，该方法在性能上超越了现有最先进模型，且运行时间缩短近一半。

Conclusion: 该工作为LLM生成文本检测提供了一种新的、高效且可解释的途径，表明经典的信号处理技术可以为这一现代挑战提供出乎意料的强大解决方案。

Abstract: The proliferation of high-quality text from Large Language Models (LLMs)
demands reliable and efficient detection methods. While existing training-free
approaches show promise, they often rely on surface-level statistics and
overlook fundamental signal properties of the text generation process. In this
work, we reframe detection as a signal processing problem, introducing a novel
paradigm that analyzes the sequence of token log-probabilities in the frequency
domain. By systematically analyzing the signal's spectral properties using the
global Discrete Fourier Transform (DFT) and the local Short-Time Fourier
Transform (STFT), we find that human-written text consistently exhibits
significantly higher spectral energy. This higher energy reflects the
larger-amplitude fluctuations inherent in human writing compared to the
suppressed dynamics of LLM-generated text. Based on this key insight, we
construct SpecDetect, a detector built on a single, robust feature from the
global DFT: DFT total energy. We also propose an enhanced version,
SpecDetect++, which incorporates a sampling discrepancy mechanism to further
boost robustness. Extensive experiments demonstrate that our approach
outperforms the state-of-the-art model while running in nearly half the time.
Our work introduces a new, efficient, and interpretable pathway for
LLM-generated text detection, showing that classical signal processing
techniques offer a surprisingly powerful solution to this modern challenge.

</details>


### [28] [Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning](https://arxiv.org/abs/2508.11364)
*Sylvio Rüdian,Yassin Elsir,Marvin Kretschmer,Sabine Cayrou,Niels Pinkwart*

Main category: cs.CL

TL;DR: 本研究利用Llama 3.1大语言模型从学生作业中提取反馈指标，并验证了其与人工评定的高度一致性，为未来自动化生成可解释的形成性反馈奠定基础。


<details>
  <summary>Details</summary>
Motivation: 自动化反馈对学生学习和教师时间管理具有重要潜力，但生成高质量反馈的关键在于有效提取相关指标。本研究旨在解决如何利用大语言模型高效提取这些指标的问题。

Method: 研究使用Llama 3.1大语言模型从语言学习课程的学生提交中提取反馈指标。随后，比较了LLM生成的指标与人工评定在多种反馈标准下的对齐程度，并进行了统计学分析。

Result: 研究结果显示，LLM生成的指标与人工评定之间存在统计学上显著的强相关性，即使在涉及指标与标准意外组合的情况下亦是如此。

Conclusion: 本文提出的方法为使用LLM从学生提交中提取指标提供了一个有前景的基础。这些提取出的指标未来有望用于自动生成可解释且透明的形成性反馈。

Abstract: Automated feedback generation has the potential to enhance students' learning
progress by providing timely and targeted feedback. Moreover, it can assist
teachers in optimizing their time, allowing them to focus on more strategic and
personalized aspects of teaching. To generate high-quality, information-rich
formative feedback, it is essential first to extract relevant indicators, as
these serve as the foundation upon which the feedback is constructed. Teachers
often employ feedback criteria grids composed of various indicators that they
evaluate systematically. This study examines the initial phase of extracting
such indicators from students' submissions of a language learning course using
the large language model Llama 3.1. Accordingly, the alignment between
indicators generated by the LLM and human ratings across various feedback
criteria is investigated. The findings demonstrate statistically significant
strong correlations, even in cases involving unanticipated combinations of
indicators and criteria. The methodology employed in this paper offers a
promising foundation for extracting indicators from students' submissions using
LLMs. Such indicators can potentially be utilized to auto-generate explainable
and transparent formative feedback in future research.

</details>


### [29] [When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs](https://arxiv.org/abs/2508.11383)
*Mikhail Seleznyov,Mikhail Chaichuk,Gleb Ershov,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 大型语言模型对提示词格式敏感，本研究首次系统评估了5种提升提示词鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）对提示词的措辞和格式中细微的非语义变化高度敏感，这导致其性能不稳定。

Method: 本研究在统一的实验框架下，首次系统评估了5种提高提示词鲁棒性的方法。在Llama、Qwen和Gemma系列的8个模型上，利用Natural Instructions数据集的52项任务进行基准测试。评估涵盖了微调和上下文学习范式下的鲁棒性方法，并测试了它们对多种分布偏移的泛化能力。此外，还扩展分析至GPT-4.1和DeepSeek V3，评估前沿模型对格式扰动的鲁棒性。

Result: 研究结果提供了关于这些鲁棒性方法相对有效性的可行见解。

Conclusion: 这些发现能帮助从业者在实际应用中做出明智决策，以实现LLM稳定可靠的性能。

Abstract: Large Language Models (LLMs) are highly sensitive to subtle, non-semantic
variations in prompt phrasing and formatting. In this work, we present the
first systematic evaluation of 5 methods for improving prompt robustness within
a unified experimental framework. We benchmark these techniques on 8 models
from Llama, Qwen and Gemma families across 52 tasks from Natural Instructions
dataset. Our evaluation covers robustness methods from both fine-tuned and
in-context learning paradigms, and tests their generalization against multiple
types of distribution shifts. Finally, we extend our analysis to GPT-4.1 and
DeepSeek V3 to assess frontier models' current robustness to format
perturbations. Our findings offer actionable insights into the relative
effectiveness of these robustness methods, enabling practitioners to make
informed decisions when aiming for stable and reliable LLM performance in
real-world applications. Code:
https://github.com/AIRI-Institute/when-punctuation-matters.

</details>


### [30] [Retrieval-augmented reasoning with lean language models](https://arxiv.org/abs/2508.11386)
*Ryan Sze-Yin Chan,Federico Nanni,Tomas Lazauskas,Rosie Wood,Penelope Yong,Lionel Tarassenko,Mark Girolami,James Geddes,Andrew Duncan*

Main category: cs.CL

TL;DR: 在轻量级语言模型架构中结合推理和检索增强生成（RAG）的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统依赖大型模型和外部API，难以在资源受限或安全环境中部署高性能且保护隐私的解决方案。

Method: 开发了一个检索增强对话代理，该代理使用轻量级骨干模型（Qwen2.5-Instruct）和密集检索器。通过从前沿模型（如DeepSeek-R1）生成的合成查询和推理轨迹，在NHS A-to-Z条件页面语料库上进行微调。研究了基于摘要的文档压缩、合成数据设计和推理感知微调对模型性能的影响。

Result: 与非推理和通用型轻量模型相比，领域特定的微调方法显著提高了答案的准确性和一致性，性能接近前沿模型水平，同时支持本地部署。

Conclusion: 所提出的方法通过领域特定微调，在资源受限环境中实现了接近前沿模型的RAG性能，并具备本地部署可行性，满足了对高性能、隐私保护解决方案的需求。

Abstract: This technical report details a novel approach to combining reasoning and
retrieval augmented generation (RAG) within a single, lean language model
architecture. While existing RAG systems typically rely on large-scale models
and external APIs, our work addresses the increasing demand for performant and
privacy-preserving solutions deployable in resource-constrained or secure
environments. Building on recent developments in test-time scaling and
small-scale reasoning models, we develop a retrieval augmented conversational
agent capable of interpreting complex, domain-specific queries using a
lightweight backbone model. Our system integrates a dense retriever with
fine-tuned Qwen2.5-Instruct models, using synthetic query generation and
reasoning traces derived from frontier models (e.g., DeepSeek-R1) over a
curated corpus, in this case, the NHS A-to-Z condition pages. We explore the
impact of summarisation-based document compression, synthetic data design, and
reasoning-aware fine-tuning on model performance. Evaluation against both
non-reasoning and general-purpose lean models demonstrates that our
domain-specific fine-tuning approach yields substantial gains in answer
accuracy and consistency, approaching frontier-level performance while
remaining feasible for local deployment. All implementation details and code
are publicly released to support reproducibility and adaptation across domains.

</details>


### [31] [Model Interpretability and Rationale Extraction by Input Mask Optimization](https://arxiv.org/abs/2508.11388)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 本研究提出一种基于梯度优化和新型正则化方案的掩码方法，为神经网络的预测生成抽取式解释，旨在实现充分性、全面性和紧凑性。该方法无需训练专门模型，即可在文本和图像数据上提供高质量解释，从而弥合了模型可解释性与理由抽取之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络模型在自然语言处理和计算机视觉等领域的快速发展，对这些黑盒模型预测结果提供解释的需求日益增长。

Method: 提出一种新的抽取式解释生成方法，通过基于梯度的优化结合新型正则化方案来掩盖模型认为与预测类别无关的输入部分。此正则化方案旨在强制解释具有充分性、全面性和紧凑性，这些特性源自自然语言处理中的理由抽取领域。

Result: 该方法成功弥合了模型可解释性与理由抽取之间的鸿沟，证明理由抽取无需训练专门模型，仅基于已训练的分类器即可完成。此外，该方法同样适用于图像输入，能够为图像分类提供高质量解释。

Conclusion: 研究表明，自然语言处理中提出的理由抽取条件更广泛地适用于不同输入类型，如文本和图像，提供了一种通用且不依赖于专门训练模型的可解释性解决方案。

Abstract: Concurrent to the rapid progress in the development of neural-network based
models in areas like natural language processing and computer vision, the need
for creating explanations for the predictions of these black-box models has
risen steadily. We propose a new method to generate extractive explanations for
predictions made by neural networks, that is based on masking parts of the
input which the model does not consider to be indicative of the respective
class. The masking is done using gradient-based optimization combined with a
new regularization scheme that enforces sufficiency, comprehensiveness and
compactness of the generated explanation, three properties that are known to be
desirable from the related field of rationale extraction in natural language
processing. In this way, we bridge the gap between model interpretability and
rationale extraction, thereby proving that the latter of which can be performed
without training a specialized model, only on the basis of a trained
classifier. We further apply the same method to image inputs and obtain high
quality explanations for image classifications, which indicates that the
conditions proposed for rationale extraction in natural language processing are
more broadly applicable to different input types.

</details>


### [32] [Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training](https://arxiv.org/abs/2508.11393)
*Marc Brinner,Sina Zarrieß*

Main category: cs.CL

TL;DR: 提出了一种端到端可微分的训练范式，通过单一模型稳定地训练合理化Transformer分类器，实现同时分类和词元相关性评分，并克服了现有方法的训练不稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有合理化模型（尤其是基于三玩家博弈的方法）存在训练复杂性、效率低下以及常见的训练不稳定问题。

Method: 提出一种端到端可微分的训练范式；通过让单一模型同时承担理由选择器、分类器和互补分类器这三个角色，简化了传统的三玩家博弈训练方法；进一步扩展该范式以生成类别特定理由，并结合了理由参数化和正则化的最新进展。

Result: 实现了单一模型同时进行样本分类和输入词元相关性评分；训练范式更高效，并解决了现有方法普遍存在的训练不稳定性问题；在与人类标注对齐方面取得了显著提升并达到最先进水平，且无需任何显式监督。

Conclusion: 该研究提供了一种稳定、高效且高性能的合理化Transformer分类器训练范式，其单一模型方法克服了现有挑战，并在无需显式监督的情况下实现了领先的解释质量。

Abstract: We propose an end-to-end differentiable training paradigm for stable training
of a rationalized transformer classifier. Our approach results in a single
model that simultaneously classifies a sample and scores input tokens based on
their relevance to the classification. To this end, we build on the widely-used
three-player-game for training rationalized models, which typically relies on
training a rationale selector, a classifier and a complement classifier. We
simplify this approach by making a single model fulfill all three roles,
leading to a more efficient training paradigm that is not susceptible to the
common training instabilities that plague existing approaches. Further, we
extend this paradigm to produce class-wise rationales while incorporating
recent advances in parameterizing and regularizing the resulting rationales,
thus leading to substantially improved and state-of-the-art alignment with
human annotations without any explicit supervision.

</details>


### [33] [Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions](https://arxiv.org/abs/2508.11414)
*Shangrui Nie,Florian Mai,David Kaczér,Charles Welch,Zhixue Zhao,Lucie Flek*

Main category: cs.CL

TL;DR: 研究表明，通过让大型语言模型（LLM）回答价值调查问卷进行微调，可以有效改变其价值系统，并在问卷回答和下游任务行为中实现价值对齐。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）隐式编码人类价值观偏好，但通常需要大量训练数据才能对其进行引导。本研究旨在探究一种更简单的方法：能否通过训练模型回答价值调查问卷来可靠地修改其在下游行为中的价值系统。

Method: 首先构建了开源LLM的价值画像作为基线，通过询问其对20种人类价值观相关描述的评分。然后，通过在这些价值调查问卷上进行微调，研究模型价值系统是否可控。评估微调效果分为两部分：一是衡量模型在域内、未保留的调查问题上的回答变化；二是评估模型在域外情境（如基于Reddit帖子的情境化道德判断数据集和文本冒险游戏）中的行为变化。

Result: 研究证明，所提出的简单方法不仅能改变模型在域内调查问卷上的回答，还能在隐式下游任务行为中产生显著的价值对齐（行为转变）。

Conclusion: 通过让模型回答价值调查问卷进行微调，是一种有效且简化的策略，可以改变LLM的价值系统，并在其下游任务行为中实现价值观的对齐。

Abstract: Large language models implicitly encode preferences over human values, yet
steering them often requires large training data. In this work, we investigate
a simple approach: Can we reliably modify a model's value system in downstream
behavior by training it to answer value survey questions accordingly? We first
construct value profiles of several open-source LLMs by asking them to rate a
series of value-related descriptions spanning 20 distinct human values, which
we use as a baseline for subsequent experiments. We then investigate whether
the value system of a model can be governed by fine-tuning on the value
surveys. We evaluate the effect of finetuning on the model's behavior in two
ways; first, we assess how answers change on in-domain, held-out survey
questions. Second, we evaluate whether the model's behavior changes in
out-of-domain settings (situational scenarios). To this end, we construct a
contextualized moral judgment dataset based on Reddit posts and evaluate
changes in the model's behavior in text-based adventure games. We demonstrate
that our simple approach can not only change the model's answers to in-domain
survey questions, but also produces substantial shifts (value alignment) in
implicit downstream task behavior.

</details>


### [34] [HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor](https://arxiv.org/abs/2508.11429)
*Shivam Dubey*

Main category: cs.CL

TL;DR: 针对LLM幽默生成通用且脱离语境的问题，本文提出HumorPlanSearch，一个融入语境理解的模块化流程，并通过新型评估指标HGS验证了其在提升幽默质量方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）生成的幽默常显得通用、重复或不合时宜，因为幽默深度依赖于听众的文化背景、心态和即时语境，缺乏语境敏感性是主要挑战。

Method: 引入HumorPlanSearch，一个模块化管道，通过以下方式明确建模语境：1) 计划搜索（Plan-Search）以获取多样化的、针对主题的策略；2) 幽默思维链（HuCoT）模板捕获文化和风格推理；3) 知识图谱（Knowledge Graph）检索和适应高性能历史策略；4) 通过语义嵌入进行新颖性过滤；5) 迭代的评委驱动修订循环。为评估语境敏感性和喜剧质量，提出了幽默生成得分（HGS），融合了直接评分、多角色反馈、配对胜率和主题相关性。

Result: 在涵盖九个主题并有13位人类评委参与的实验中，完整管道（知识图谱 + 修订）将平均HGS比强基线提高了15.4%（p < 0.05）。

Conclusion: HumorPlanSearch通过在从策略规划到多信号评估的每个阶段都强调语境，将AI驱动的幽默推向更连贯、适应性更强、更符合文化的喜剧。

Abstract: Automated humor generation with Large Language Models (LLMs) often yields
jokes that feel generic, repetitive, or tone-deaf because humor is deeply
situated and hinges on the listener's cultural background, mindset, and
immediate context. We introduce HumorPlanSearch, a modular pipeline that
explicitly models context through: (1) Plan-Search for diverse, topic-tailored
strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and
stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt
high-performing historical strategies; (4) novelty filtering via semantic
embeddings; and (5) an iterative judge-driven revision loop. To evaluate
context sensitivity and comedic quality, we propose the Humor Generation Score
(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,
and topic relevance. In experiments across nine topics with feedback from 13
human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent
(p < 0.05) over a strong baseline. By foregrounding context at every stage from
strategy planning to multi-signal evaluation, HumorPlanSearch advances
AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.

</details>


### [35] [Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse](https://arxiv.org/abs/2508.11434)
*Aditi Dutta,Susan Banducci*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在内容审核中常将反性别歧视言论误分类为有害，尤其是在政治敏感事件中。这可能压制反对性别歧视的声音，因此作者建议改进审核系统，超越二元分类，并整合人工审核和反抗言论数据。


<details>
  <summary>Details</summary>
Motivation: 反性别歧视言论对在线民主辩论至关重要，但由LLMs驱动的自动化内容审核系统难以区分反性别歧视言论与其所反对的性别歧视内容，存在误判风险。

Method: 研究考察了五个大型语言模型，如何分类来自英国的性别歧视、反性别歧视和中性政治推文。研究重点关注2022年涉及女性议员的突出触发事件。

Result: 分析显示，模型经常将反性别歧视言论错误地分类为有害言论，特别是在修辞风格的伤害和抵抗趋于一致的政治敏感事件期间。

Conclusion: 这种错误分类有压制挑战性别歧视者声音的风险，对边缘化群体造成不成比例的后果。内容审核设计必须超越二元有害/无害模式，在敏感事件中融入人工审核，并在训练数据中明确包含反抗言论，以应对在数字政治空间中保护抵抗言论的社会技术挑战。

Abstract: Anti-sexist speech, i.e., public expressions that challenge or resist
gendered abuse and sexism, plays a vital role in shaping democratic debate
online. Yet automated content moderation systems, increasingly powered by large
language models (LLMs), may struggle to distinguish such resistance from the
sexism it opposes. This study examines how five LLMs classify sexist,
anti-sexist, and neutral political tweets from the UK, focusing on
high-salience trigger events involving female Members of Parliament in the year
2022. Our analysis show that models frequently misclassify anti-sexist speech
as harmful, particularly during politically charged events where rhetorical
styles of harm and resistance converge. These errors risk silencing those who
challenge sexism, with disproportionate consequences for marginalised voices.
We argue that moderation design must move beyond binary harmful/not-harmful
schemas, integrate human-in-the-loop review during sensitive events, and
explicitly include counter-speech in training data. By linking feminist
scholarship, event-based analysis, and model evaluation, this work highlights
the sociotechnical challenges of safeguarding resistance speech in digital
political spaces.

</details>


### [36] [CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity](https://arxiv.org/abs/2508.11442)
*Bowen Zhang,Zixin Song,Chunquan Chen,Qian-Wen Zhang,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: 提出CoDiEmb框架，通过解耦学习信号、动态采样和模型融合，有效解决信息检索（IR）与语义文本相似性（STS）任务联合训练中的负迁移和性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 在表示学习中，学习适用于多种下游任务的统一文本嵌入是一个核心目标，但负迁移是一个长期存在的障碍。特别是对信息检索（IR）和语义文本相似性（STS）这两种本质上不同的任务进行联合训练时，朴素的联合训练会导致显著的性能权衡。

Method: 提出CoDiEmb统一框架，通过系统地解耦任务特定的学习信号来协同处理IR和STS的差异化需求。该框架包含三项关键创新：1) 任务专业化的目标函数（IR采用对比损失，STS采用顺序感知目标）结合动态采样器，形成单任务批次并平衡更新，防止梯度干扰。2) 一种delta引导的模型融合策略，通过分析参数偏离预训练初始化的程度来计算细粒度合并权重。3) 高效、单阶段的训练流程。

Result: 在15个标准IR和STS基准测试集上，使用三种基础编码器对CoDiEmb进行了广泛实验验证。结果表明，该框架不仅能有效缓解跨任务权衡，还能显著改善嵌入空间的几何特性。

Conclusion: CoDiEmb成功解决了信息检索（IR）和语义文本相似性（STS）任务联合训练中的负迁移和性能权衡问题，实现了统一文本嵌入的学习，并提升了嵌入空间的质量。

Abstract: Learning unified text embeddings that excel across diverse downstream tasks
is a central goal in representation learning, yet negative transfer remains a
persistent obstacle. This challenge is particularly pronounced when jointly
training a single encoder for Information Retrieval (IR) and Semantic Textual
Similarity (STS), two essential but fundamentally disparate tasks for which
naive co-training typically yields steep performance trade-offs. We argue that
resolving this conflict requires systematically decoupling task-specific
learning signals throughout the training pipeline. To this end, we introduce
CoDiEmb, a unified framework that reconciles the divergent requirements of IR
and STS in a collaborative yet distinct manner. CoDiEmb integrates three key
innovations for effective joint optimization: (1) Task-specialized objectives
paired with a dynamic sampler that forms single-task batches and balances
per-task updates, thereby preventing gradient interference. For IR, we employ a
contrastive loss with multiple positives and hard negatives, augmented by
cross-device sampling. For STS, we adopt order-aware objectives that directly
optimize correlation and ranking consistency. (2) A delta-guided model fusion
strategy that computes fine-grained merging weights for checkpoints by
analyzing each parameter's deviation from its pre-trained initialization,
proving more effective than traditional Model Soups. (3) An efficient,
single-stage training pipeline that is simple to implement and converges
stably. Extensive experiments on 15 standard IR and STS benchmarks across three
base encoders validate CoDiEmb. Our results and analysis demonstrate that the
framework not only mitigates cross-task trade-offs but also measurably improves
the geometric properties of the embedding space.

</details>


### [37] [Reference Points in LLM Sentiment Analysis: The Role of Structured Context](https://arxiv.org/abs/2508.11454)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 本文展示了通过JSON格式提示向小型LLM提供补充信息可显著改善情感分析，使其能在资源受限设备上实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有NLP研究多仅基于评论文本进行情感分类，而市场营销理论指出顾客评价受实际体验和额外参考点影响。因此，本研究旨在探索补充信息的内容和格式如何影响LLM的情感分析。

Method: 采用轻量级3B参数模型，通过对比自然语言(NL)和JSON格式提示，并添加补充信息，在两个Yelp类别（餐厅和夜生活）的数据上进行情感分析实验。

Result: JSON格式提示（包含补充信息）在未经微调的情况下，在两个Yelp类别上均优于所有基线：Macro-F1分别提升1.6%和4%，RMSE分别下降16%和9.1%，使其适用于资源受限的边缘设备。后续分析证实性能提升源于真实的上下文推理。

Conclusion: 结构化提示能够使小型模型达到具有竞争力的性能，为大规模模型部署提供了一种实用的替代方案。

Abstract: Large language models (LLMs) are now widely used across many fields,
including marketing research. Sentiment analysis, in particular, helps firms
understand consumer preferences. While most NLP studies classify sentiment from
review text alone, marketing theories, such as prospect theory and
expectation--disconfirmation theory, point out that customer evaluations are
shaped not only by the actual experience but also by additional reference
points. This study therefore investigates how the content and format of such
supplementary information affect sentiment analysis using LLMs. We compare
natural language (NL) and JSON-formatted prompts using a lightweight 3B
parameter model suitable for practical marketing applications. Experiments on
two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with
additional information outperforms all baselines without fine-tuning: Macro-F1
rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it
deployable in resource-constrained edge devices. Furthermore, a follow-up
analysis confirms that performance gains stem from genuine contextual reasoning
rather than label proxying. This work demonstrates that structured prompting
can enable smaller models to achieve competitive performance, offering a
practical alternative to large-scale model deployment.

</details>


### [38] [Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models](https://arxiv.org/abs/2508.11534)
*Monika Jotautaitė,Lucius Caviola,David A. Brewster,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）存在物种歧视偏见，尤其体现在对农场动物的合理化伤害上，这反映了主流文化规范。为减少偏见，AI公平性框架应纳入非人类道德主体。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛部署，审查其道德倾向至关重要。本研究旨在探讨LLMs是否表现出基于物种成员的歧视偏见（即物种歧视），以及它们如何评价非人类动物，以扩展AI公平性研究的范畴。

Method: 研究通过三种范式系统地调查了物种歧视问题：1) SpeciesismBench：一个包含1,003个项目的基准测试，评估LLMs对物种歧视性言论的识别和道德评价；2) 已有的心理学测量：比较模型与人类参与者的反应；3) 文本生成任务：探测LLMs对物种歧视性理由的阐述或抵制能力。

Result: 研究结果显示，在基准测试中，LLMs能可靠地检测出物种歧视性言论，但很少谴责它们，常将物种歧视态度视为道德可接受。在心理测量方面结果混杂：LLMs表现出比人类略低的明确物种歧视，但在直接权衡时，它们更常选择拯救一个人而非多只动物。初步解释是LLMs可能更看重认知能力而非物种本身。在开放式文本生成任务中，LLMs频繁将对农场动物的伤害正常化或合理化，但拒绝同样对待非农场动物。这些发现表明，LLMs在反映进步和主流人类观点混合的同时，却也再现了根深蒂固的动物剥削文化规范。

Conclusion: 研究认为，虽然LLMs反映了人类观点，但它们再现了对动物剥削的根深蒂固的文化规范。因此，扩展AI公平性和对齐框架以明确包含非人类道德主体，对于减少这些偏见并防止物种歧视态度在AI系统及其影响的社会中根深蒂固至关重要。

Abstract: As large language models (LLMs) become more widely deployed, it is crucial to
examine their ethical tendencies. Building on research on fairness and
discrimination in AI, we investigate whether LLMs exhibit speciesist bias --
discrimination based on species membership -- and how they value non-human
animals. We systematically examine this issue across three paradigms: (1)
SpeciesismBench, a 1,003-item benchmark assessing recognition and moral
evaluation of speciesist statements; (2) established psychological measures
comparing model responses with those of human participants; (3) text-generation
tasks probing elaboration on, or resistance to, speciesist rationalizations. In
our benchmark, LLMs reliably detected speciesist statements but rarely
condemned them, often treating speciesist attitudes as morally acceptable. On
psychological measures, results were mixed: LLMs expressed slightly lower
explicit speciesism than people, yet in direct trade-offs they more often chose
to save one human over multiple animals. A tentative interpretation is that
LLMs may weight cognitive capacity rather than species per se: when capacities
were equal, they showed no species preference, and when an animal was described
as more capable, they tended to prioritize it over a less capable human. In
open-ended text generation tasks, LLMs frequently normalized or rationalized
harm toward farmed animals while refusing to do so for non-farmed animals.
These findings suggest that while LLMs reflect a mixture of progressive and
mainstream human views, they nonetheless reproduce entrenched cultural norms
around animal exploitation. We argue that expanding AI fairness and alignment
frameworks to explicitly include non-human moral patients is essential for
reducing these biases and preventing the entrenchment of speciesist attitudes
in AI systems and the societies they influence.

</details>


### [39] [Language models align with brain regions that represent concepts across modalities](https://arxiv.org/abs/2508.11536)
*Maria Ryskina,Greta Tuckute,Alexander Fung,Ashley Malkin,Evelina Fedorenko*

Main category: cs.CL

TL;DR: 研究发现语言模型与大脑中意义一致性高的区域对齐更好，暗示语言模型可能内部表示跨模态概念意义。


<details>
  <summary>Details</summary>
Motivation: 认知科学、神经科学以及当前的语言模型都面临区分语言表征与概念意义表征的挑战。本研究旨在探究语言模型与大脑对齐程度，与大脑处理语言和概念意义的神经指标之间的关系。

Method: 通过分析语言模型（包括仅语言和语言-视觉模型）与大脑活动的对齐关系，并结合两个神经指标：句子处理时的大脑激活水平（语言处理）和基于fMRI数据集的跨模态意义一致性度量（衡量大脑区域对同一概念在不同输入模态下响应的一致性）。

Result: 实验结果显示，无论是仅语言模型还是语言-视觉模型，它们都能更好地预测大脑中意义一致性较高的区域的信号，即使这些区域对语言处理的敏感度不高。

Conclusion: 研究表明，语言模型可能在内部表征了跨模态的概念意义。

Abstract: Cognitive science and neuroscience have long faced the challenge of
disentangling representations of language from representations of conceptual
meaning. As the same problem arises in today's language models (LMs), we
investigate the relationship between LM--brain alignment and two neural
metrics: (1) the level of brain activation during processing of sentences,
targeting linguistic processing, and (2) a novel measure of meaning consistency
across input modalities, which quantifies how consistently a brain region
responds to the same concept across paradigms (sentence, word cloud, image)
using an fMRI dataset (Pereira et al., 2018). Our experiments show that both
language-only and language-vision models predict the signal better in more
meaning-consistent areas of the brain, even when these areas are not strongly
sensitive to language processing, suggesting that LMs might internally
represent cross-modal conceptual meaning.

</details>


### [40] [AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment](https://arxiv.org/abs/2508.11567)
*Jinpeng Hu,Ao Wang,Qianqian Xie,Hui Ma,Zhuo Li,Dan Guo*

Main category: cs.CL

TL;DR: 本文提出一个多智能体框架，通过模拟医患对话、自适应提问和树状记忆，实现自动化心理健康评估，并在DAIC-WOZ数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的心理健康评估受限于专业人员短缺。现有自动化评估方法多依赖静态文本分析，难以捕捉动态交互中的深层信息。

Method: 提出一个多智能体框架，模拟临床医患对话，包含提问、充分性评估、评分和更新智能体。引入自适应提问机制，评估智能体根据用户回答的充分性决定是否生成追问。采用树状结构记忆，根节点存储用户基本信息，子节点组织关键症状和交互轮次信息，并动态更新以减少冗余提问，增强信息提取和上下文跟踪能力。

Result: 在DAIC-WOZ数据集上的实验结果表明，所提出的方法比现有方法表现更好，证明了其有效性。

Conclusion: 所提出的多智能体框架通过模拟动态医患对话、自适应提问和创新的记忆管理，有效提升了自动化心理健康评估的准确性和效率，克服了传统和现有AI方法的局限。

Abstract: Mental health assessment is crucial for early intervention and effective
treatment, yet traditional clinician-based approaches are limited by the
shortage of qualified professionals. Recent advances in artificial intelligence
have sparked growing interest in automated psychological assessment, yet most
existing approaches are constrained by their reliance on static text analysis,
limiting their ability to capture deeper and more informative insights that
emerge through dynamic interaction and iterative questioning. Therefore, in
this paper, we propose a multi-agent framework for mental health evaluation
that simulates clinical doctor-patient dialogues, with specialized agents
assigned to questioning, adequacy evaluation, scoring, and updating. We
introduce an adaptive questioning mechanism in which an evaluation agent
assesses the adequacy of user responses to determine the necessity of
generating targeted follow-up queries to address ambiguity and missing
information. Additionally, we employ a tree-structured memory in which the root
node encodes the user's basic information, while child nodes (e.g., topic and
statement) organize key information according to distinct symptom categories
and interaction turns. This memory is dynamically updated throughout the
interaction to reduce redundant questioning and further enhance the information
extraction and contextual tracking capabilities. Experimental results on the
DAIC-WOZ dataset illustrate the effectiveness of our proposed method, which
achieves better performance than existing approaches.

</details>


### [41] [Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2508.11582)
*Qiguang Chen,Dengyun Peng,Jinhao Liu,HuiKang Su,Jiannan Guan,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 为解决LLM长链思维的效率问题，本文提出DR. SAF框架，通过动态调整推理深度，显著降低token消耗和训练时间，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）的长链思维（CoT）虽提升了复杂推理能力，但存在大量冗余，导致计算效率低下和实时应用延迟。现有提高效率的方法依赖于与LLM自感知难度不符的人工定义难度先验，效果不佳。

Method: 本文提出了动态推理边界自感知框架（DR. SAF），该框架使模型能够根据问题复杂性动态评估和调整其推理深度。DR. SAF包含三个核心组件：边界自感知对齐、自适应奖励管理和边界保持机制。

Result: 实验结果显示，DR. SAF在总响应token上减少了49.27%，且准确率损失极小。该框架实现了6.59倍的token效率提升和5倍的训练时间缩减。在极端训练条件下，DR. SAF在token效率上甚至超越了传统基于指令的模型，并获得了超过16%的准确率提升。

Conclusion: DR. SAF通过动态调整LLM的推理深度，有效解决了长链思维的效率问题，显著降低了计算资源和训练时间，同时保持了高准确性，尤其适用于资源受限环境。

Abstract: Recent advancements in large language models (LLMs) have greatly improved
their capabilities on complex reasoning tasks through Long Chain-of-Thought
(CoT). However, this approach often results in substantial redundancy,
impairing computational efficiency and causing significant delays in real-time
applications. To improve the efficiency, current methods often rely on
human-defined difficulty priors, which do not align with the LLM's self-awared
difficulty, leading to inefficiencies. In this paper, we introduce the Dynamic
Reasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models to
dynamically assess and adjust their reasoning depth in response to problem
complexity. DR. SAF integrates three key components: Boundary Self-Awareness
Alignment, Adaptive Reward Management, and a Boundary Preservation Mechanism.
These components allow models to optimize their reasoning processes, balancing
efficiency and accuracy without compromising performance. Our experimental
results demonstrate that DR. SAF achieves a 49.27% reduction in total response
tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain
in token efficiency and a 5x reduction in training time, making it well-suited
to resource-limited settings. During extreme training, DR. SAF can even surpass
traditional instruction-based models in token efficiency with more than 16%
accuracy improvement.

</details>


### [42] [Representing Speech Through Autoregressive Prediction of Cochlear Tokens](https://arxiv.org/abs/2508.11598)
*Greta Tuckute,Klemen Kotar,Evelina Fedorenko,Daniel L. K. Yamins*

Main category: cs.CL

TL;DR: AuriStream是一个受生物学启发的两阶段语音编码模型，能学习有意义的语音表示并高效处理多种语音任务。


<details>
  <summary>Details</summary>
Motivation: 旨在通过受人类听觉处理启发的两阶段框架，开发更像人类的模型，以高效处理各种语音任务，并学习有意义的语音表示。

Method: AuriStream模型采用两阶段框架：第一阶段将原始音频转换为基于人耳蜗的时间-频率表示，并提取离散的“耳蜗令牌”；第二阶段在这些令牌上应用自回归序列模型。

Result: AuriStream学习到有意义的音素和词语表示，获得了最先进的词汇语义，并在多样的SUPERB语音任务中表现出竞争力。它还能生成音频续接，并可视化和解码回音频，提供模型预测的洞察。

Conclusion: 提出的两阶段语音表示学习框架能够推动开发更像人类的模型，高效处理各种语音相关任务。

Abstract: We introduce AuriStream, a biologically inspired model for encoding speech
via a two-stage framework inspired by the human auditory processing hierarchy.
The first stage transforms raw audio into a time-frequency representation based
on the human cochlea, from which we extract discrete \textbf{cochlear tokens}.
The second stage applies an autoregressive sequence model over the cochlear
tokens. AuriStream learns meaningful phoneme and word representations, and
state-of-the-art lexical semantics. AuriStream shows competitive performance on
diverse downstream SUPERB speech tasks. Complementing AuriStream's strong
representational capabilities, it generates continuations of audio which can be
visualized in a spectrogram space and decoded back into audio, providing
insights into the model's predictions. In summary, we present a two-stage
framework for speech representation learning to advance the development of more
human-like models that efficiently handle a range of speech-based tasks.

</details>


### [43] [Dataset Creation for Visual Entailment using Generative AI](https://arxiv.org/abs/2508.11605)
*Rob Reijtenbach,Suzan Verberne,Gijs Wijnholds*

Main category: cs.CL

TL;DR: 提出并验证了一种基于文本生成图像（Stable Diffusion）的合成数据集，用于训练视觉蕴含模型，以解决现有数据集稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉蕴含数据集规模小、稀疏，且手动创建耗时费力，限制了模型的训练。

Method: 基于SNLI文本蕴含数据集，将SNLI前提文本作为Stable Diffusion模型的输入提示，生成图像来替代文本前提。通过使用合成图像数据训练基于CLIP特征向量的视觉蕴含分类器，在SNLI-VE和SICK-VTE数据集上进行外在评估。

Result: 使用合成数据训练的模型在SNLI-VE数据集上F-score为0.686（真实数据为0.703），在SICK-VTE数据集上F-score为0.384（真实数据为0.400），表明性能仅有轻微下降。

Conclusion: 在数据稀疏的情况下，合成数据是训练视觉蕴含模型的一个有前景的解决方案。

Abstract: In this paper we present and validate a new synthetic dataset for training
visual entailment models. Existing datasets for visual entailment are small and
sparse compared to datasets for textual entailment. Manually creating datasets
is labor-intensive. We base our synthetic dataset on the SNLI dataset for
textual entailment. We take the premise text from SNLI as input prompts in a
generative image model, Stable Diffusion, creating an image to replace each
textual premise. We evaluate our dataset both intrinsically and extrinsically.
For extrinsic evaluation, we evaluate the validity of the generated images by
using them as training data for a visual entailment classifier based on CLIP
feature vectors. We find that synthetic training data only leads to a slight
drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when
trained on real data. We also compare the quality of our generated training
data to original training data on another dataset: SICK-VTE. Again, there is
only a slight drop in F-score: from 0.400 to 0.384. These results indicate that
in settings with data sparsity, synthetic data can be a promising solution for
training visual entailment models.

</details>


### [44] [TinyTim: A Family of Language Models for Divergent Generation](https://arxiv.org/abs/2508.11607)
*Christopher J. Agostino*

Main category: cs.CL

TL;DR: 本文介绍了TinyTim，一个基于詹姆斯·乔伊斯《芬尼根守灵夜》微调的大语言模型系列，其生成内容表现出高词汇多样性但低语义连贯性，并被提出作为创意AI架构中的发散知识源。


<details>
  <summary>Details</summary>
Motivation: 旨在探索通过特定文学作品微调的专业大语言模型如何作为更广泛创意架构中的发散知识源，并推动自动化发现机制，同时从创造力与复杂问题解决理论角度解释其独特输出。

Method: 开发并介绍了名为TinyTim的系列大语言模型，该模型在詹姆斯·乔伊斯的《芬尼根守灵夜》上进行了微调。通过与基线模型的定量评估来分析其生成特性。

Result: TinyTim V1生成了一种统计学上独特的文本配置文件，其主要特征是高词汇多样性和低语义连贯性。

Conclusion: 研究结果通过创造力理论和复杂问题解决理论得到解释，表明此类专业模型能够在更广泛的创意架构中充当发散知识源，从而推动多种环境下的自动化发现机制。

Abstract: This work introduces TinyTim, a family of large language models fine-tuned on
James Joyce's `Finnegans Wake'. Through quantitative evaluation against
baseline models, we demonstrate that TinyTim V1 produces a statistically
distinct generative profile characterized by high lexical diversity and low
semantic coherence. These findings are interpreted through theories of
creativity and complex problem-solving, arguing that such specialized models
can function as divergent knowledge sources within more extensive creative
architectures, powering automated discovery mechanisms in diverse settings.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

TL;DR: 本研究提出一种基于潜在噪声自编码器的眼动信号隐私增强机制，旨在防止用户未经同意被重新识别，同时保持数据可用性。


<details>
  <summary>Details</summary>
Motivation: 在眼动追踪系统中，保护敏感的眼动数据隐私，防止用户被未经授权地重新识别，同时确保数据仍可用于良性任务，且能保留生理上合理的眼动模式。

Method: 开发了一种利用潜在噪声自编码器的隐私增强机制，用于处理眼动信号。

Result: 通过评估生物识别和注视预测任务中的隐私-效用权衡，发现该方法显著降低了生物识别可识别性，而效用损失极小。与现有方法不同，该框架保留了生理上合理的注视模式，适用于下游使用，从而实现了更有利的隐私-效用权衡。

Conclusion: 这项工作通过提供一种可用且有效的机制来保护敏感的眼动数据，从而推进了基于眼动的系统中的隐私保护技术。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [46] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

TL;DR: 本综述系统回顾了由多模态大型语言模型（MLLMs）驱动的视频时间定位（VTG-MLLMs）研究，分析了其在架构、训练和特征处理方面的进展，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管基于MLLMs的视频时间定位（VTG-MLLMs）方法在视频理解中表现优异且泛化能力强，但目前缺乏专门针对VTG-MLLMs的全面综述。

Method: 本综述通过一个三维分类法系统地审查了VTG-MLLMs的当前研究：1) MLLMs的功能角色；2) 训练范式；3) 视频特征处理技术。同时，还讨论了基准数据集、评估协议并总结了经验发现。

Result: 通过系统分析，本综述呈现了VTG-MLLMs在功能角色、训练范式和视频特征处理方面的当前研究进展、基准数据集、评估协议及实证结果的总结。

Conclusion: 本综述识别了VTG-MLLMs领域的现有局限性，并提出了有前景的未来研究方向。

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [47] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: VSF是一种简单高效的负面提示引导方法，通过翻转注意力值符号来抑制图像生成模型中的不良内容，尤其在少量步长模型中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少量步长扩散和流匹配图像生成模型中，对负面提示的依从性表现不足，需要更有效的方法来动态抑制不需要的内容。

Method: 本文提出Value Sign Flip (VSF) 方法，通过动态翻转负面提示注意力值的符号来抑制图像中的不期望内容。该方法计算开销小，可有效集成到MMDiT风格（如Stable Diffusion 3.5 Turbo）和交叉注意力模型（如Wan）中。

Result: VSF在复杂提示对的挑战性数据集上进行了验证，在静态图像和视频生成任务中均表现出卓越性能。实验结果表明，VSF在少量步长模型中显著提高了负面提示的依从性，甚至在非少量步长模型中也优于CFG，同时保持了有竞争力的图像质量。

Conclusion: VSF提供了一种简单、高效且实用的负面提示引导方案，显著提升了图像生成模型（尤其是在少量步长场景下）中负面提示的依从性，有效解决了现有方法的局限性，并维持了良好的图像质量。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [48] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

TL;DR: 提出一种基于PAE的相对位姿回归(RPR)方案，用于优化绝对位姿回归(APR)的相机定位精度，且能有效减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 准确的相机定位对现代零售环境至关重要。虽然单图像绝对位姿回归(APR)有潜力，但融入视觉和空间先验的方法（如PAE）能实现更高精度。本研究旨在通过扩展PAE应用，进一步提升APR的定位精度并减轻数据采集负担。

Method: 将相机位姿自编码器（PAE）扩展到相对位姿回归（RPR）任务，并提出一种新颖的重定位方案。该方案利用基于PAE的RPR精炼APR预测，无需额外存储图像或位姿数据。首先引入PAE-based RPR并与同等架构的图像-based RPR模型进行比较以验证其有效性，然后证明了该精炼策略能提高室内基准上的APR定位精度。

Result: 基于PAE的RPR被证实有效。所提出的精炼策略显著提升了APR的定位精度。即使仅用30%的数据进行训练，该方法也能达到具有竞争力的性能，大幅降低了零售部署的数据采集负担。

Conclusion: 本文提出的基于PAE的RPR精炼方案能有效提升APR的相机定位精度，提供了一种数据高效且无需额外存储的解决方案，非常适用于零售环境。

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [49] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

TL;DR: ViPE是一个多功能视频处理引擎，能高效地从各种视频中估计相机参数、运动和深度图，性能超越现有基线，并被用于标注一个大规模视频数据集，该引擎和数据集均已开源，旨在加速空间AI系统发展。


<details>
  <summary>Details</summary>
Motivation: 虽然最先进的空间AI系统依赖大规模训练数据，但从非受限的真实视频中获取一致且精确的3D标注仍然是一个关键挑战。

Method: 本文提出了ViPE（Video Processing Engine），一个用于桥接此鸿沟的视频处理引擎。ViPE能够高效地从无约束的原始视频中估计相机内参、相机运动和接近度量尺度的密集深度图。它对动态自拍、电影镜头或行车记录仪等多种场景具有鲁棒性，并支持针孔、广角和360度全景等多种相机模型。

Result: ViPE在多个基准测试中表现出色：在TUM/KITTI序列上，其非校准姿态估计性能分别优于现有基线18%/50%；在单GPU上处理标准输入分辨率时可达到3-5FPS。研究者还使用ViPE标注了一个包含约10万真实世界互联网视频、100万高质量AI生成视频和2千全景视频的大规模集合，总计约96M帧，所有帧均标注了精确的相机姿态和密集深度图。

Conclusion: ViPE提供了一种有效的解决方案来克服3D几何感知数据标注的挑战。通过开源ViPE工具及其标注的大规模数据集，本文旨在加速空间AI系统的研发进程。

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [50] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

TL;DR: 本文提出HQ-OV3D框架，通过生成和优化高质量伪标签来解决开放词汇3D检测中边界框精度不足的问题，显著提升了新类别的检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的封闭集3D检测框架无法满足开放世界应用需求。现有开放词汇3D检测方法虽然通过VLM提升了伪标签的语义准确性，但其几何质量（特别是边界框精度）常被忽视。

Method: 提出HQ-OV3D框架，专注于生成和优化高质量伪标签。该框架包含两部分：1) 模内交叉验证(IMCV)提议生成器，利用跨模态几何一致性生成高质量初始3D提议；2) 已标注类别辅助(ACA)去噪器，通过基于DDIM的去噪机制，利用已标注类别的几何先验逐步优化3D提议。

Result: 与现有最先进方法相比，使用HQ-OV3D生成的伪标签进行训练，在新类别上的mAP提高了7.37%，证明了其伪标签的卓越质量。

Conclusion: HQ-OV3D不仅可以作为一个强大的独立开放词汇3D检测器，还可以作为现有开放词汇检测或标注流程的高质量伪标签生成插件。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [51] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

TL;DR: 提出首个基于稀疏3D语义高斯溅射的协同3D语义占用预测方法，有效降低通信成本并显著提升感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的3D语义占用预测方法在协同场景中存在局限性：或因依赖密集3D体素导致高通信成本，或因依赖2D平面特征而需精确深度估计或额外监督。

Method: 该研究提出一种利用稀疏3D语义高斯溅射（3D semantic Gaussian splatting）进行协同3D语义占用预测的方法。通过共享和融合中间高斯基元，实现：1) 基于邻域的跨智能体融合以去除重复并抑制噪声；2) 每个基元中几何和语义的联合编码，减少对深度监督的依赖；3) 稀疏、以对象为中心的消息传输，在保留结构信息的同时减少通信量。

Result: 实验证明，该方法在mIoU上比单智能体感知和基线协同方法分别高出+8.42和+3.28点，在IoU上分别高出+5.11和+22.41点。即使仅使用34.6%的通信量，mIoU仍能提升+1.9点，表明在有限通信预算下仍具有稳健性能。

Conclusion: 该方法通过创新性地应用稀疏3D语义高斯溅射，有效解决了协同3D语义占用预测中的通信效率和深度监督依赖问题，显著提升了感知性能，并在通信受限环境下表现出鲁棒性，为协同感知提供了新的高效范式。

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [52] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

TL;DR: 针对极端降质（如8倍以上放大）下人脸超分辨率中身份信息丢失和幻觉问题，本文提出IDFSR方法，通过解耦身份和风格，并利用蒙版、参考图对齐和身份嵌入，显著提升了身份一致性和感知质量。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸超分辨率（FSR）方法在标准设置下表现良好，但在极端降质场景（如放大倍数>8倍）下，输入图像的关键属性和身份（ID）信息严重丢失，导致传统模型难以重建逼真且ID一致的人脸，常生成缺乏真实ID约束的幻觉人脸。

Method: 提出基于身份解耦与拟合的FSR方法（IDFSR），包含三项关键设计：1) 对低分辨率（LR）图像的面部区域进行**蒙版**处理以消除不可靠的ID线索；2) **扭曲**参考图像使其与LR输入对齐，提供风格指导；3) 利用从真值（GT）图像中提取的**ID嵌入**进行细粒度ID建模和个性化适应。具体实现为：先预训练一个基于扩散的模型，通过强制其使用风格和身份嵌入重建蒙版LR人脸区域，显式解耦风格和ID；随后，冻结大部分网络参数，并使用少量目标ID图像对ID嵌入进行轻量级微调，该嵌入编码细粒度面部属性和精确ID信息。

Result: 实验结果表明，IDFSR显著提升了ID一致性和感知质量。大量的定量评估和视觉比较证明，在极端降质条件下，所提出的IDFSR方法显著优于现有方法，尤其在ID一致性方面表现出卓越的性能。

Conclusion: IDFSR有效解决了极端降质下人脸超分辨率中的身份重建挑战，通过其独特的设计理念（蒙版、参考图扭曲、ID嵌入以及身份-风格解耦），成功抑制了幻觉效应并大幅提高了身份一致性，超越了现有方法。

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [53] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

TL;DR: 本研究利用深度学习对越南十种常见木材进行自动化分类，其中ShuffleNetV2表现最佳，以99.29%的准确率和99.35%的F1分数证明了轻量级深度学习模型在资源受限环境下进行高精度木材识别的潜力。


<details>
  <summary>Details</summary>
Motivation: 木材种类准确识别对生态监测、生物多样性保护和森林可持续管理至关重要。传统识别方法耗时、需要专业知识且效率低下。

Method: 构建了一个野外采集木材样本的定制图像数据集。评估了五种先进的卷积神经网络架构（ResNet50、EfficientNet、MobileViT、MobileNetV3和ShuffleNetV2）进行木材分类。

Result: ShuffleNetV2在分类性能和计算效率之间实现了最佳平衡，在20次独立运行中，平均准确率为99.29%，F1分数为99.35%。

Conclusion: 轻量级深度学习模型在资源受限环境下进行高精度实时木材物种识别具有巨大潜力。本研究为自动化木材分类和森林生物多样性评估提供了可扩展的、基于图像的解决方案，有助于生态信息学领域的发展。

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [54] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

TL;DR: 本文提出NIRMAL Pooling，一种结合自适应最大池化和非线性激活函数的新型CNN池化层，旨在提高图像分类的鲁棒性和特征表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有池化方法可能限制CNN的鲁棒性和特征表达能力。研究旨在通过提出一种新型池化层来改进图像分类任务中的这些方面。

Method: 引入NIRMAL Pooling（非线性激活、中间聚合、降维、最大值、自适应和局部化），它将自适应最大池化与池化后的ReLU激活函数结合，并根据期望输出尺寸动态调整池化参数。在MNIST Digits、MNIST Fashion和CIFAR-10数据集上与标准Max Pooling进行性能评估。

Result: NIRMAL Pooling在MNIST Digits上达到99.25%的测试准确率（Max Pooling为99.12%），在MNIST Fashion上达到91.59%（Max Pooling为91.44%），在CIFAR-10上达到70.49%（Max Pooling为68.87%），显示出持续的性能提升，尤其是在复杂数据集上。

Conclusion: NIRMAL Pooling有潜力增强CNN在各种图像识别任务中的性能，为传统池化方法提供了一个灵活可靠的替代方案。

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [55] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

TL;DR: 本文提出了一种基于拓扑结构特征的新方法（方向直方图形状），用于检测可在VR/AR环境中实现交互的特殊编码装饰物——Artcode。


<details>
  <summary>Details</summary>
Motivation: 随着智能手机和VR/AR技术的普及，环境中将出现与虚拟元素连接的物体。识别这些Artcode的存在是促使进一步检查和触发相关数字内容的第一步，从而实现新型交互。

Method: 将Artcode识别定义为一种独特的计算机视觉任务——Artcode候选检测。为此，研究提出了一种新的特征描述符“方向直方图形状”（shape of orientation histogram），用于描述Artcode通用的拓扑结构。研究人员收集了数据集并进行了全面的实验评估。

Result: 实验结果表明，所提出的特征向量在表示拓扑结构方面是可行的，并且基于此新特征向量构建的系统在检测Artcode候选方面是有效的。

Conclusion: 尽管这项工作是开发基于特征的拓扑对象（如Artcode）检测系统的初步尝试，但它将为新的交互机会和拓扑对象检测的潜在应用开启新的方向。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [56] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

TL;DR: 利用低分辨率CT结合3D-UNet模型，开发了一种量化纺织增强复合材料在压实过程中嵌套行为的方法，并成功提取了关键几何特征。


<details>
  <summary>Details</summary>
Motivation: 详细理解多尺度材料结构对纺织增强复合材料的预测建模至关重要。其中，织物层间的嵌套行为（纱线局部互穿和错位）对材料的力学性能（如刚度、渗透性和损伤容限）具有决定性影响，因此需要对其进行量化。

Method: 对不同堆叠配置的干纺织增强材料进行原位压实实验，使用低分辨率CT（20.22 μm/体素）在不同压实阶段（纤维体积含量50-60%）进行扫描。利用定制的3D-UNet模型对基体、纬纱和经纱相进行语义分割。通过两点相关函数$S_2$分析空间结构，以概率方式提取平均层厚度和嵌套度。

Result: 3D-UNet模型在语义分割中取得了至少0.822的平均交并比（IoU）和0.902的F1分数。成功地概率性提取了平均层厚度和嵌套度。研究结果与基于显微照片的验证高度一致。

Conclusion: 该方法为从工业相关CT数据中提取关键几何特征提供了一种稳健的途径，并为复合材料预成型件的逆向建模和基于描述符的结构分析奠定了基础。

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [57] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: 本文提出了一套名为iWatchRoad的端到端系统，用于自动化坑洼检测、GPS标记和实时地图绘制，以解决印度道路坑洼问题。


<details>
  <summary>Details</summary>
Motivation: 道路上的坑洼是一个严重的危害和维护负担，对道路安全和车辆寿命构成重大威胁，尤其是在印度多样化且维护不足的道路上。

Method: 该系统利用超过7,000帧的自标注行车记录仪数据集，该数据集涵盖印度特有的各种路况、光照和天气场景。使用此数据集微调YOLO模型进行实时坑洼检测，并采用自定义OCR模块从视频帧中提取时间戳。时间戳与GPS日志同步以准确地理标记每个检测到的坑洼。处理后的数据及其元数据存储在数据库中，并通过基于OpenStreetMap的用户友好型Web界面进行可视化。

Result: iWatchRoad系统不仅提高了在挑战性条件下的检测准确性，而且通过网站上可见的元数据，提供了与政府兼容的输出，可用于道路评估和维护规划。

Conclusion: 该解决方案成本效益高、硬件效率高且可扩展，为发展中地区的城乡道路管理提供了一个实用的自动化工具。

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [58] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: 本文提出一种名为增量补丁生成（IPG）的新方法，能以高达11.1倍的效率生成对抗性补丁，同时保持相当的攻击性能，并有助于构建更鲁棒的AI模型，适用于防御和实际应用。


<details>
  <summary>Details</summary>
Motivation: 对抗性补丁对AI模型（特别是计算机视觉中的目标检测）的鲁棒性构成了重大挑战，它们通过定位图像特定区域来使AI模型失效，因此需要更有效的方法来生成和理解这些威胁。

Method: 本文提出“增量补丁生成（IPG）”方法，旨在以更高的效率（比现有方法高11.1倍）生成对抗性补丁，同时保持攻击性能。通过实验和消融研究，包括YOLO特征分布可视化和对抗性训练，来评估其有效性。

Result: IPG能够以高达11.1倍的效率生成对抗性补丁，并保持与现有方法相当的攻击性能。IPG生成的补丁具有良好的泛化性，能够有效覆盖更广泛的模型漏洞。此外，IPG生成的数据集可以作为构建鲁棒模型的坚实知识基础。

Conclusion: IPG在对抗性补丁防御以及自动驾驶、安全系统和医学成像等AI模型需在动态高风险环境中保持韧性的实际应用中，都展现出巨大的未来潜力。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [59] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: MedAtlas是一个新型多模态医学推理基准框架，旨在解决现有基准的局限性，通过模拟真实临床场景的多轮、多模态、多任务交互，评估和推动医疗AI的发展。


<details>
  <summary>Details</summary>
Motivation: AI在临床决策中有巨大潜力，但现有医学多模态基准局限于单图像、单轮任务，无法捕捉临床实践中固有的纵向和多模态交互性，无法满足开发适应真实场景并进行复杂诊断推理模型的需求。

Method: 引入MedAtlas框架，具有多轮对话、多模态图像交互、多任务集成和高临床保真度等特点。支持开放/封闭式多轮问答、多图像联合推理和疾病诊断等核心任务。案例源于真实诊断流程，整合文本病史与多种影像模态（CT、MRI、PET、超声、X射线），要求模型进行深度整合推理。提供专家标注的黄金标准，并提出Round Chain Accuracy和Error Propagation Resistance两种新评估指标。

Result: 通过现有模型进行基准测试，发现在多阶段临床推理中存在显著的性能差距。

Conclusion: MedAtlas为推动鲁棒和可信赖的医疗AI发展建立了一个具有挑战性的评估平台。

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [60] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

TL;DR: FastFOD-Net是一个快速深度学习框架，用于增强临床低质量弥散MRI数据中的纤维方向分布（FOD），并在多种神经疾病患者中验证其有效性，从而加速临床神经科学研究。


<details>
  <summary>Details</summary>
Motivation: 纤维方向分布（FOD）的可靠性高度依赖于MRI采集质量。广泛可用的临床协议（单壳、低角度分辨率）难以生成可靠FOD。现有基于深度学习的增强方法主要在健康受试者上评估，限制了其临床应用。

Method: 本文提出并验证了FastFOD-Net，一个优化的加速端到端深度学习框架，用于FOD增强。该框架在健康对照组和六种神经疾病患者中进行了综合临床评估。

Result: FastFOD-Net表现出卓越的性能，其训练/推理效率比前身快60倍。它能加速临床神经科学研究，助力疾病鉴别诊断，提高连接组应用的可解释性，并减少测量误差以降低样本量需求。

Conclusion: 这项工作将促进基于深度学习的弥散MRI增强方法在临床中的广泛采用并建立信任。FastFOD-Net实现了对真实临床弥散MRI数据的鲁棒分析，其效果可与高质量研究级采集数据媲美。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [61] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

TL;DR: 本综述探讨如何通过外部工具（如API、专家模型、知识库）解决多模态大语言模型（MLLMs）面临的数据质量、复杂任务表现和评估协议不足等挑战，以提升其能力和可靠性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在多模态任务中取得巨大成功，但仍受限于多模态数据质量、复杂下游任务表现不佳以及评估协议不完善，这些因素阻碍了其可靠性和广泛应用。受人类利用工具解决问题的启发，研究者提出通过外部工具增强MLLM以克服这些挑战。

Method: 本文进行了一项全面综述，探讨如何利用外部工具增强MLLM性能。讨论围绕四个关键维度展开：1) 工具如何促进高质量多模态数据的获取和标注；2) 工具如何帮助提升MLLM在复杂下游任务上的表现；3) 工具如何实现对MLLM的全面和准确评估；4) 工具增强MLLM的当前局限性与未来发展方向。

Result: 本综述旨在强调外部工具在提升MLLM能力方面的变革性潜力，并对其发展和应用提供一个前瞻性的视角。

Conclusion: 外部工具在解决MLLM当前面临的挑战、提升其能力和可靠性方面具有巨大的潜力，是推动MLLM向通用人工智能发展的关键策略，值得未来深入研究和广泛应用。

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [62] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

TL;DR: 本文评估了视觉-语言模型（VLM）在物体属性推理方面的能力，发现现有基准不足。为此，研究者提出了ORBIT多级推理VQA基准，并测试了12个先进VLM。结果显示，VLM表现远低于人类，尤其在真实图像和复杂推理方面存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLM）在视觉问答（VQA）任务上取得了显著进展，但它们是否能对描绘的物体进行抽象和推理仍不明确。现有VQA基准在物体属性评估方面存在局限性，常混淆感知与推理，且在推理和图像类别上缺乏代表性。

Method: 研究者引入了一个系统评估框架，该框架包含三类代表性图像、三个递增复杂度的推理级别和四个物体属性维度。基于此框架，构建了ORBIT基准，一个多级推理VQA基准，包含360张图片和1080个基于计数的问答。随后，在零样本设置下，对12个最先进的VLM进行了实验评估。

Result: 实验结果显示，与人类相比，现有VLM在物体属性推理方面存在显著局限性，表现最佳的模型准确率仅为40%。VLM尤其难以处理真实（照片）图像、关于物理和功能属性的反事实推理以及高计数问题。

Conclusion: ORBIT基准揭示了VLM在物体抽象和推理能力上的不足，强调了开发可扩展基准、泛化标注指南以及探索更强推理VLM的必要性。研究者已公开ORBIT基准和实验代码以支持未来的研究。

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [63] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本研究利用高光谱成像技术，通过结合信息论和图像质量指标的波段选择策略，有效解决了RGB图像中异谱同色导致的视觉模糊问题，显著提升了弱势道路使用者（VRU）与背景的分离度，为高级驾驶辅助系统和自动驾驶提供了更可靠的感知输入。


<details>
  <summary>Details</summary>
Motivation: 保护弱势道路使用者是汽车感知系统的关键安全挑战。现有系统在视觉模糊（如异谱同色现象，即不同材料在RGB图像中表现相似）下表现不佳，亟需一种能捕捉独特材料特征的方法来克服这一限制。

Method: 研究采用高光谱成像（HSI）来捕获可见光波段之外（特别是近红外）的独特材料光谱特征。为处理高维HSI数据，提出一种波段选择策略，该策略整合了信息论技术（联合互信息最大化、相关性分析）和图像质量指标（对比度信噪比）以识别最具信息量的光谱波段。在Hyperspectral City V2 (H-City) 数据集上，识别出三个信息波段（497 nm, 607 nm, 895 nm），并重构伪彩色图像与RGB进行比较。

Result: 定量结果表明，与RGB相比，所选HSI波段显著提高了VRU与背景的差异性和感知可分离性。在欧氏距离、SAM、T²等差异性指标上分别提升了70.24%、528.46%、1206.83%，在CIE ΔE感知指标上提升了246.62%，有效减少了异谱同色混淆。

Conclusion: 通过提供光谱优化的输入，本方法增强了VRU的可分离性，为高级驾驶辅助系统（ADAS）和自动驾驶（AD）的下游感知任务奠定了坚实基础，最终有助于提高道路安全。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [64] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出EVCtrl，一个轻量级、即插即用的控制适配器，通过空间和时间双重缓存策略，显著加速ControlNet在图像和视频生成中的效率，同时保持生成质量，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 视觉生成对可控性要求提高，而ControlNet虽提供精确控制，但其辅助分支显著增加了延迟，并引入了非受控区域和去噪步骤中的冗余计算，尤其在视频生成中问题更为突出，亟需一个轻量级解决方案来降低开销。

Method: EVCtrl是一个轻量级、即插即用的控制适配器，无需重新训练模型。其核心方法是针对稀疏控制信息提出时空双重缓存策略：针对空间冗余，分析DiT-ControlNet各层对控制的响应，将网络划分为全局和局部功能区，通过局部感知缓存将计算集中于真正需要控制信号的局部区域，跳过全局区域的冗余计算；针对时间冗余，选择性地跳过不必要的去噪步骤以提高效率。

Result: 在CogVideo-Controlnet、Wan2.1-Controlnet和Flux上的大量实验表明，该方法在图像和视频控制生成中有效，且无需训练。例如，在CogVideo-Controlnet和Wan2.1-Controlnet上分别实现了2.16倍和2.05倍的加速，同时生成质量几乎没有下降。

Conclusion: EVCtrl通过创新的时空双重缓存策略，成功解决了ControlNet在视觉生成中存在的计算冗余和高延迟问题，实现了显著的效率提升和良好的生成质量，为可控视觉生成提供了无需训练的轻量级加速方案。

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [65] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

TL;DR: 评估VLMs模拟低视力人群视觉感知的能力。研究发现，结合视力信息和单个开放式/多选混合示例能显著提高VLM模拟的准确性（一致性达0.70），而仅提供少量信息或单一类型信息时效果不佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究未探究视觉语言模型（VLMs）在无障碍领域，特别是模拟低视力人群视觉感知方面的能力，因此本研究旨在填补这一空白。

Method: 1. 通过对40名低视力参与者的调查，收集其视力信息和图片感知响应（开放式与多项选择），构建基准数据集。2. 使用GPT-4o，通过不同提示（包含视力信息及示例响应）创建参与者模拟代理。3. 评估VLM生成响应与参与者原始答案的一致性。

Result: 1. 仅提供少量提示或单独提供视力信息/示例响应时，VLM模拟一致性较低（0.59）。2. 结合视力信息和示例响应能显著提高一致性（0.70）。3. 单个包含开放式和多项选择题的混合示例效果最佳，而额外示例无显著益处。

Conclusion: VLMs能够有效模拟低视力人群的视觉感知。为达到高精度模拟，需要向VLM提供结合了参与者视力信息和至少一个开放式与多项选择题混合的示例。

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [66] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

TL;DR: 本文提出并构建了一个名为ConstructionSite 10k的大型开放数据集，包含10,000张带标注的建筑工地图像，旨在解决视觉语言模型（VLMs）在建筑安全检查领域缺乏评估和微调数据的现状。初步评估表明，当前VLMs具有良好的泛化能力，但仍需进一步训练以适应实际应用。


<details>
  <summary>Details</summary>
Motivation: 建筑安全检查目前主要依靠人工，效率和准确性受限。尽管视觉语言模型（VLMs）在检测工地安全违规方面展现潜力，但缺乏开放、全面的数据集来有效评估和微调VLMs，现有小型监督数据集限制了模型的泛化能力。

Method: 研究者提出了“ConstructionSite 10k”数据集，该数据集包含10,000张建筑工地图像，并针对三个相互关联的任务进行了详细标注：图像标注、安全违规视觉问答（VQA）以及建筑元素视觉定位。

Result: 对现有最先进的预训练大型视觉语言模型进行评估后发现，它们在零样本和少样本设置下表现出显著的泛化能力。然而，为了使这些模型真正适用于实际建筑工地场景，还需要进行额外的训练。

Conclusion: ConstructionSite 10k数据集为研究人员训练和评估采用新架构和技术开发的视觉语言模型提供了宝贵的基准，有助于推动建筑安全检查领域的自动化和智能化发展。

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [67] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

TL;DR: 本研究评估了多模态大语言模型在文档欺诈检测中的有效性，发现顶尖模型展现出色的零样本泛化能力，优于传统方法，但模型大小与准确性关联有限，任务特定微调是关键。


<details>
  <summary>Details</summary>
Motivation: 文档欺诈对依赖安全可验证文档的行业构成重大威胁，因此需要强大、可靠的检测机制。本研究旨在探索先进的多模态大语言模型在该领域的应用潜力。

Method: 研究评估了包括OpenAI O1、4o、Gemini Flash、Deepseek Janus、Grok、Llama 3.2和4、Qwen 2和2.5 VL、Mistral Pixtral、Claude 3.5和3.7 Sonnet在内的多种最先进多模态大语言模型。通过提示优化和对模型推理过程的详细分析，在一个包含真实交易文档的标准数据集上，将这些模型与现有欺诈检测技术进行基准测试，以评估其识别篡改文本、错位格式和不一致交易金额等细微欺诈迹象的能力。

Result: 结果显示，性能顶尖的多模态大语言模型展现出卓越的零样本泛化能力，在分布外数据集上优于传统方法。然而，部分视觉大语言模型表现不稳定或不佳。值得注意的是，模型规模和高级推理能力与检测准确性之间的相关性有限，这表明任务特定的微调至关重要。

Conclusion: 本研究强调了多模态大语言模型在提升文档欺诈检测系统方面的巨大潜力，并为未来探索可解释、可扩展的欺诈缓解策略研究奠定了基础。

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [68] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

TL;DR: 提出MedSAMix，一种免训练的模型融合方法，通过零阶优化结合通用与专用模型优势，在多项医学分割任务上显著提升性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割微调模型（如MedSAM）受限于训练数据异质性、稀缺标注和分布漂移，导致泛化能力不足，难以应对广泛的医学分割任务。

Method: 提出MedSAMix，一种免训练的模型融合方法，旨在整合通用模型（如SAM）和专用模型（如MedSAM）的优点。该方法采用零阶优化自动发现最优的逐层融合方案，并针对临床应用设计了单任务优化和多目标优化两种机制以兼顾领域特异性和泛化性。

Result: 在25项医学分割任务上的评估表明，MedSAMix有效减轻了模型偏差，并持续提升了性能，在专用任务上性能提升6.67%，在多任务评估中提升4.37%。

Conclusion: MedSAMix通过融合通用与专用模型的优势，有效克服了现有医学分割模型在泛化性上的局限，显著提升了医学图像分割的性能和鲁棒性。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [69] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

TL;DR: 针对现有3D视听语言数据集的局限性，本文提出了MV-ScanQA和TripAlign两个新数据集，并开发了LEGO方法，在多视角3D场景理解任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视听语言（3D VL）学习数据集在要求超越近距离单视角物体推理和提供更丰富多物体上下文对齐方面存在局限，这严重阻碍了能够进行深度、多视角3D场景理解的模型发展。

Method: 1. 引入MV-ScanQA数据集，一个新型3D问答数据集，其68%的问题明确要求整合多视角信息，以严格测试多视角组合推理能力。
2. 提出TripAlign数据集，一个大规模、低成本的2D-3D-语言预训练语料库，包含100万个<2D视角, 3D物体集, 文本>三元组，明确对齐上下文相关的物体组与文本，提供更丰富的多模态对齐信号。
3. 开发LEGO基线方法，通过TripAlign将预训练的2D LVLM（视觉语言模型）知识迁移到3D领域，用于解决MV-ScanQA中的多视角推理挑战。

Result: 经验证，在TripAlign上预训练的LEGO方法不仅在所提出的MV-ScanQA数据集上，而且在现有3D密集字幕和问答基准测试上均取得了最先进的性能。

Conclusion: 本研究通过引入新的多视角推理数据集和多模态对齐预训练语料，并开发有效的方法，成功解决了现有3D VL数据集的局限性，显著推动了多视角3D场景理解领域的发展。

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [70] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: 本研究利用AI从腹部CT影像中识别出跨体重类别的2型糖尿病风险和保护性特征，发现其腹部驱动因素具有一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管BMI是2型糖尿病的已知风险因素，但其在瘦人群中的存在和在肥胖人群中的缺失表明，详细的身体成分分析可能揭示2型糖尿病的腹部表型。AI技术能从3D临床影像中大规模提取腹部结构的详细测量数据，为经验性定义与2型糖尿病风险和保护相关的身体成分特征提供了机会。

Method: 研究将1728名受试者（包括瘦体型、超重和肥胖亚组）的临床CT扫描作为数据源。实验设计包括：通过分割将腹部扫描转换为可解释的测量数据；使用交叉验证的随机森林模型对2型糖尿病进行分类；通过SHAP分析测量特征对模型风险或保护的贡献；并通过SHAP聚类对扫描进行分组，再关联到解剖学差异。

Result: 随机森林模型的平均AUC达到0.72-0.74。各组均发现共享的2型糖尿病特征，包括脂肪性骨骼肌、高龄、更多内脏和皮下脂肪，以及较小或脂肪过多的胰腺。单变量逻辑回归证实了各亚组中前20个预测因子中14-18个的方向性（p < 0.05）。

Conclusion: 研究结果表明，2型糖尿病的腹部驱动因素可能在不同体重类别中保持一致。

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [71] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

TL;DR: 提出HierOctFusion，一个部分感知多尺度八叉树扩散模型，通过融合部件级语义信息解决了3D生成中忽视部件层次和高分辨率计算昂贵的问题，显著提升了形状质量和生成效率。


<details>
  <summary>Details</summary>
Motivation: 3D内容生成因数据复杂性而面临挑战。现有八叉树扩散模型忽略语义部件层次，限制了泛化能力；且整体高分辨率建模计算昂贵，而真实世界对象本质上是稀疏和分层的。

Method: 提出HierOctFusion模型，一个部分感知多尺度八叉树扩散模型，旨在增强分层特征交互以生成细粒度稀疏对象结构。引入了交叉注意力条件机制，将部件级信息注入生成过程，促进语义特征在分层级别有效传播。此外，构建了一个带有部件类别标注的3D数据集用于训练和评估。

Result: 实验结果表明，HierOctFusion在形状质量和效率方面均优于现有方法。

Conclusion: HierOctFusion通过结合部件感知和多尺度生成，有效克服了3D内容生成的关键挑战，实现了卓越的形状质量和高效性。

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [72] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

TL;DR: 提出UWB-PostureGuard，一种基于超宽带（UWB）的隐私保护系统，用于连续、非接触式地监测人体工学坐姿。


<details>
  <summary>Details</summary>
Motivation: 长时间电脑使用导致的不良坐姿引发公共健康问题；传统姿态监测方案（如摄像头和可穿戴传感器）存在隐私和用户不适等显著障碍。

Method: 开发UWB-PostureGuard系统，利用商用UWB设备进行综合特征工程以提取坐姿特征；设计PoseGBDT模型来有效捕捉姿态模式的时间依赖性，以克服传统逐帧分类的局限性。

Result: 在10名参与者和19种不同姿势的真实世界评估中，系统达到了99.11%的准确率，并对衣物厚度、附加设备和家具配置等环境变量保持鲁棒性。

Conclusion: UWB-PostureGuard提供了一个可扩展、隐私保护、低成本的移动健康解决方案，用于主动人体工学管理，提高生活质量。

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [73] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

TL;DR: 提出了一种基于残差的高效双向扩散模型（RBDM），能够实现去雾和雾霾生成之间的双向转换，通过双马尔可夫链和图像块学习，在少量采样步数下取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度去雾方法仅专注于移除雾霾，缺乏在有雾和无雾图像之间进行双向转换的能力。

Method: 1. 提出了残差型高效双向扩散模型（RBDM）。2. 设计了双马尔可夫链，有效转移残差并促进双向平滑过渡。3. RBDM在不同时间步对有雾和无雾图像进行扰动，预测噪声以同时学习条件分布。4. 引入统一的分数函数，在图像块而非整图上学习，以提升小型数据集表现并降低计算成本。

Result: RBDM成功实现了无尺寸限制的无雾和有雾图像之间的双向转换，仅需15个采样步。在合成和真实世界数据集上，该方法达到或超越了现有SOTA方法的性能。

Conclusion: RBDM有效解决了双向去雾/生成问题，在性能和效率上表现出色，特别适用于实现图像间的双向转换。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [74] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MICC的跨模态谣言检测新方法，通过对比学习探索多尺度图像与文本内容的相关性，以解决现有方法忽视图像信息和跨尺度关联的问题，并在真实数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测方法忽略了图像内容以及上下文与图像在不同视觉尺度之间的内在关系，导致谣言识别关键信息的丢失。

Method: 本文提出了一种基于对比学习的跨模态谣言检测方案——多尺度图像与上下文相关性探索算法（MICC）。具体方法包括：1) 设计SCLIP编码器，通过对比预训练生成文本和多尺度图像块的统一语义嵌入。2) 引入跨模态多尺度对齐模块，通过互信息最大化、信息瓶颈原则及Top-K选择策略，识别与文本语义最相关的图像区域。3) 设计尺度感知融合网络，根据语义重要性和跨模态相关性为图像区域分配自适应权重，整合高相关多尺度图像特征与全局文本特征。

Result: 该方法在两个真实世界数据集上进行了广泛评估，实验结果表明其在谣言检测方面比现有最先进的方法有显著的性能提升。

Conclusion: 所提出的MICC方法是有效的，并在实际应用中具有巨大潜力，解决了多模态谣言检测中图像信息利用不足的问题。

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [75] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: LEARN是一个布局感知的扩散框架，专为STEM教育生成与教学目标对齐的插图。它利用特定数据集和多项技术，旨在支持高阶思维并减少认知负荷。


<details>
  <summary>Details</summary>
Motivation: 现有教育内容（尤其是短形式媒体）常导致注意力分散和认知负荷过高。需要一种能生成语义对齐、支持高阶推理且能减少认知负荷的STEM教育插图方案。

Method: LEARN框架利用一个精选的BookCover数据集，该数据集提供叙事布局和结构化视觉线索。核心方法包括：布局条件生成、对比视觉-语义训练和提示调制，以生成连贯的视觉序列。

Result: LEARN能生成与教学目标对齐的连贯视觉序列，有效支持布鲁姆分类法中的中高阶推理，并显著减少了额外认知负荷。通过促进空间组织和故事驱动的叙事，它有助于对抗注意力分散并促进持续的概念专注。

Conclusion: LEARN是首个将基于布局的故事叙述、语义结构学习和认知支架相结合的生成式方法，为生成式AI在教育领域开辟了新方向。它展示了与多模态系统及知识图谱集成的巨大潜力，以创建自适应、探索性的教育内容。

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [76] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

TL;DR: 提出一种基于期望最大化和双向布朗桥扩散模型（EM-B3DM）的半监督图像去雾方法，有效解决了真实世界去雾中成对数据缺乏的问题，并取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法难以处理真实世界中的浓雾图像，主要原因是缺乏真实的成对去雾数据和鲁棒的先验知识。

Method: EM-B3DM采用两阶段学习方案：第一阶段，利用EM算法将成对图像的联合分布解耦为条件分布，并使用统一的布朗桥扩散模型捕获图像间的结构和内容关联；第二阶段，利用预训练模型和大规模非成对数据进一步提升性能。此外，引入了细节增强的残差差分卷积块（RDC）以捕获梯度信息，增强模型表示能力。

Result: EM-B3DM在合成和真实世界数据集上，性能均优于或至少媲美现有的最先进方法。

Conclusion: 所提出的EM-B3DM方法能有效应对真实世界去雾中的数据稀缺挑战，并通过创新的模型设计实现了显著的性能提升。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [77] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

TL;DR: 本研究提出VG-DETR，一种用于遥感图像的半监督无源目标检测方法。它通过集成视觉基础模型和少量目标域标注数据，有效缓解了伪标签噪声问题并增强了特征表示，从而在无源跨域检测任务中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 无监督域适应在遥感场景中因数据隐私和传输限制无法访问源域数据而受限。无源目标检测（SFOD）作为替代方案，常受伪标签噪声导致训练崩溃的困扰，尤其在遥感图像中目标密集且背景复杂时。实践中，目标域少量标注数据是可行的，这促使研究者探索利用少量监督信息解决SFOD中的挑战。

Method: 本研究提出Vision foundation-Guided DEtection TRansformer (VG-DETR)，一个基于半监督框架的遥感图像SFOD模型。VG-DETR以“免费午餐”方式整合视觉基础模型（VFM），并利用少量标注数据。具体方法包括：1) **VFM引导的伪标签挖掘策略**：利用VFM的语义先验评估伪标签可靠性，并从低置信度输出中恢复潜在的正确预测，以提高伪标签的质量和数量。2) **双层VFM引导对齐方法**：在实例和图像级别将检测器特征与VFM嵌入进行对齐（通过细粒度原型的对比学习和特征图的相似性匹配），以增强特征表示对域间隙的鲁棒性。

Result: 广泛的实验结果表明，VG-DETR在无源遥感目标检测任务中取得了卓越的性能。

Conclusion: VG-DETR通过有效集成视觉基础模型和利用少量目标域标注数据，成功解决了无源遥感目标检测中因伪标签噪声导致的训练崩溃问题，并显著提升了检测性能和特征表示的鲁棒性。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [78] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

TL;DR: 提出IOVQA，一种针对VLM的微调方法，通过整数标签和目标掩码损失计算，显著提升了视频质量评估的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型(VLM)在视觉内容评估中存在结果不精确和损失计算效率低的问题，限制了模型对关键评估指标的关注。

Method: 提出IOVQA(Integer-only VQA)微调方法。创新点包括：1. 标签构建：将模型输出约束在[10,50]的整数范围，并将Overall_MOS转换为整数标签。2. 目标掩码策略：在计算损失时，仅保留标签的前两位整数，迫使模型学习数值评估的关键部分。

Result: 通过在Qwen2.5-VL模型上进行微调，实验结果显示所提方法显著提高了模型在VQA任务中的准确性和一致性，并在VQualA 2025挑战赛中排名第3。

Conclusion: 仅保留整数标签进行微调是一种有效优化VLM在定量评估场景中性能的策略。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [79] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

TL;DR: 本文提出IDOD方法，通过独立多样性学习、联合新颖性发现和正交增量模块，解决连续类别发现（CCD）中新类发现与分类矛盾、错误累积及遗忘抑制效率低的问题，并在细粒度数据集上优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的连续类别发现（CCD）方法在处理新类发现与分类之间的矛盾时表现不佳，容易在逐渐发现新类的过程中积累错误，且多数通过知识蒸馏和数据回放防止遗忘，占用大量存储空间。

Method: 提出独立多样性与正交判别（IDOD）框架。核心包括：1) 独立多样性丰富模块：使用对比损失单独训练骨干网络，避免其仅关注分类特征。2) 联合新颖性发现模块：将多阶段新类发现转换为单阶段，减少错误累积。3) 正交增量模块：生成相互正交的原型进行分类，并通过代表性表征回放以较低空间开销防止遗忘。

Result: 实验结果表明，在具有挑战性的细粒度数据集上，IDOD方法优于现有最先进（SOTA）方法。

Conclusion: IDOD方法有效解决了连续类别发现中的核心挑战，包括新类发现与分类的矛盾、错误累积问题以及高效的遗忘抑制，并取得了卓越的性能表现。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [80] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: 本文提出LatHAdapter，一种基于双曲学习的新型Adapter，用于微调视觉语言模型以解决少样本分类任务中现有Adapter未能捕捉类别与图像一对多关联及泛化能力不足的问题。LatHAdapter通过学习潜在语义层次和引入属性提示，显著提升了在已知和未知类别上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有Adapter方法在微调预训练视觉语言模型（VLMs）以进行少样本分类时，主要依赖显式空间邻近性来对齐视觉和文本表示。然而，这种方法未能捕捉类别与图像样本之间内在的一对多关联，且难以在未知类别和图像之间建立准确的关联。

Method: 受双曲学习启发，本文开发了Latent Hierarchical Adapter (LatHAdapter)。其核心是利用下游训练数据的潜在语义层次结构来指导Adapter学习。具体而言，LatHAdapter首先引入可学习的“属性”提示作为连接类别和图像的桥梁，然后将类别、属性提示和图像在双曲空间中投影，并通过分层正则化学习它们的潜在语义层次，从而充分建模它们之间内在的一对多关联。

Result: 在四个具有挑战性的少样本任务上进行的广泛实验表明，所提出的LatHAdapter持续优于许多其他微调方法，尤其在适应已知类别和泛化到未知类别方面表现突出。

Conclusion: LatHAdapter通过引入潜在语义层次和双曲空间映射，有效解决了传统Adapter在少样本分类任务中捕捉一对多关联和泛化能力方面的不足，为VLMs的微调提供了一种更有效、性能更优越的解决方案。

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [81] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

TL;DR: 本文提出高斯视频Transformer (GVT)，一种基于生成式2D高斯溅射的视频分词器，通过自适应空间表示和静态/动态内容分离，在视频重建、动作识别和压缩任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的视频分词方法（固定网格、块状分词）通用性有限，存在空间冗余（低信息区域过度编码）和时间冗余（未区分静态/动态内容）问题，导致效率和泛化能力不足。

Method: 本文提出GVT。核心方法包括：1) 通过时空高斯嵌入 (STGE) 机制生成一组2D高斯，以灵活地表示视频内容，通过分配不同的渲染权重实现空间自适应性，并避免逐视频优化。2) 引入高斯集分割 (GSP) 策略，将2D高斯分为静态和动态两部分，分别建模跨时间步的共享内容和特定时间步的内容，以实现紧凑且通用的时间表示。

Result: GVT在视频重建方面达到了最先进的质量，在动作识别方面超越了基线MAGVIT-v2，并在压缩方面表现出可比性能。实验在UCF101、Kinetics和DAVIS数据集上进行。

Conclusion: GVT是一种有效且通用的视频分词方法，通过创新的生成式高斯表示和静态/动态内容分离策略，显著提升了视频重建质量，并在动作识别和压缩任务中展现出优异性能，解决了现有方法在空间和时间通用性方面的局限。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [82] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

TL;DR: 本文针对单目3D目标检测器在不同相机高度下泛化性差的问题，提出CHARM3R模型，通过平均两种深度估计来显著提升其在未见过相机高度上的性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测器在特定相机高度数据上表现良好，但面对未见或分布外的相机高度时性能显著下降。现有方法（如Plucker嵌入、图像变换、数据增强）效果有限。

Method: 首先系统分析了相机高度变化对最先进（SoTA）单目3D模型的影响，发现深度估计是影响性能的主要因素。研究观察并数学证明了回归深度模型和基于地面的深度模型的平均深度误差在相机高度变化下表现出一致的负向和正向趋势。为解决此问题，提出CHARM3R模型，通过在模型内部平均这两种深度估计来缓解深度误差。

Result: CHARM3R模型对未见相机高度的泛化能力提高了45%以上，并在CARLA数据集上达到了当前最佳（SoTA）性能。

Conclusion: 通过深入分析相机高度变化对深度估计的影响，并提出CHARM3R模型，本文成功解决了单目3D目标检测器在不同相机高度下的泛化性问题，显著提升了其鲁棒性。

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [83] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

TL;DR: 该研究利用大型语言模型，将单人教学视频自动转换为双人任务指导对话视频，并创建了一个大型数据集HowToDIV，为现实世界任务协助的AI代理提供资源。


<details>
  <summary>Details</summary>
Motivation: 许多日常任务需要专业知识，但当前AI代理在复杂多步任务协助方面面临数据集稀缺的挑战，特别是缺乏与现实世界任务协助相关的对话-视频数据集。

Method: 提出一种全自动方法，利用大型语言模型将单人教学视频转换为双人任务指导对话，并与细粒度步骤和视频片段对齐。这种方法大大降低了人工数据收集的成本和工作量。

Result: 成功构建了HowToDIV数据集，包含507个对话、6636个问答对和24小时的视频片段，涵盖烹饪、机械和种植等多种任务。该数据集的每个会话都包含专家逐步指导新手用户的多轮对话。同时，该研究还使用Gemma-3模型在HowToDIV数据集上建立了基线性能。

Conclusion: HowToDIV数据集的创建为基于对话的程序性任务协助这一新兴研究领域提供了一个大规模、多样化的资源和基准，将促进未来相关AI代理和对话系统的发展。

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [84] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

TL;DR: 针对现有视觉-语言模型（VLM）在无人机（UAV）图像推理中表现不佳的问题，本文提出轻量级模型UAV-VL-R1，通过结合SFT和基于GRPO的RL进行训练，并引入高分辨率数据集HRVQA-VL，在保持高效的同时显著提升了UAV空中视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在处理UAV图像时，因其高分辨率、复杂空间语义及严格实时性要求而性能下降，限制了其在结构化空中推理任务中的应用。

Method: 提出专为空中视觉推理设计的轻量级VLM模型UAV-VL-R1。该模型采用监督微调（SFT）和多阶段强化学习（RL，利用GRPO算法）的混合训练方法。同时，构建了包含50,019个样本的高分辨率视觉问答数据集HRVQA-VL，用于模型训练与评估。

Result: UAV-VL-R1在零样本准确率上比基线模型Qwen2-VL-2B-Instruct高48.17%，并超越其72B（大36倍）的变体。消融研究表明，SFT提升语义对齐，而GRPO-RL增强了逻辑灵活性和推理鲁棒性。该模型内存占用低（FP16下3.9GB，INT8下2.5GB），支持UAV平台实时部署。

Conclusion: UAV-VL-R1成功解决了VLM在UAV图像推理中的性能和效率挑战，通过创新的混合训练方法和专用数据集，实现了卓越的推理能力和轻量化部署，为资源受限的UAV应用提供了高效可行的解决方案。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [85] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

TL;DR: 提出了一种新颖的粗到精两阶段知识蒸馏框架，通过结构损失和IGP-GCN改进轻量级人体姿态估计器的训练，以实现准确且资源高效的姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态估计方法虽然准确，但计算资源消耗巨大。传统的知识蒸馏框架在将知识从大型教师模型传递给小型学生模型时，未能充分挖掘人体关节间的上下文信息。

Method: 本文提出了一种新颖的粗到精两阶段知识蒸馏框架。第一阶段引入了人体关节结构损失，旨在从教师模型中向学生模型传递高级语义知识和关节结构信息。第二阶段利用Image-Guided Progressive Graph Convolutional Network (IGP-GCN) 对第一阶段获得的初始姿态进行细化，并通过教师模型的最终输出姿态以渐进方式监督IGP-GCN的训练。

Result: 在COCO关键点和CrowdPose基准数据集上的广泛实验表明，所提出的方法优于许多现有先进的人体姿态估计算法，特别是在更复杂的CrowdPose数据集上，模型的性能提升更为显著。

Conclusion: 该两阶段知识蒸馏框架能够有效地为轻量级模型带来高准确度和鲁棒性的人体姿态估计能力，特别是在处理复杂人群场景时表现出显著优势，为资源受限环境下的姿态估计提供了有效方案。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [86] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

TL;DR: 提出轻量级不确定模态建模（UMM）框架，用于在自动驾驶中处理不确定或缺失模态下的行人再识别，实现鲁棒、通用和高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 行人再识别（ReID）是自动驾驶中的关键技术，但面临输入模态不确定或缺失的挑战。同时，大规模预训练模型计算开销大，不适用于资源受限的部署环境。

Method: 提出轻量级不确定模态建模（UMM）框架，该框架整合了多模态令牌映射器、合成模态增强策略和跨模态线索交互学习器。UMM还利用CLIP的视觉-语言对齐能力，无需大量微调即可高效融合多模态输入。

Result: 实验结果表明，UMM在不确定模态条件下，实现了强大的鲁棒性、泛化能力和计算效率。

Conclusion: UMM为自动驾驶场景下，在模态不确定或缺失情况下的行人再识别提供了一个可扩展且实用的解决方案。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [87] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

TL;DR: 本研究提出多模态奖励模型Talking-Critic和大规模多维度偏好数据集Talking-NSQ，并基于此开发TLPO框架，显著提升音视频驱动肖像动画的自然度、唇形同步和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有音视频驱动肖像动画方法难以满足人类对运动自然度、唇形同步准确性和视觉质量等多维度的精细偏好，主要原因是优化竞争性偏好目标困难以及缺乏大规模高质量多维度偏好标注数据集。

Method: 首先，引入多模态奖励模型Talking-Critic，用于量化生成视频满足多维度期望的程度，并利用该模型构建了包含410K偏好对的大规模多维度人类偏好数据集Talking-NSQ。其次，提出时间步-层自适应多专家偏好优化（TLPO）框架，该框架将偏好解耦为专业专家模块，并在时间步和网络层之间融合，实现全面、精细的多维度增强而不互相干扰。

Result: 实验证明，Talking-Critic在与人类偏好评级对齐方面显著优于现有方法。同时，TLPO在唇形同步准确性、运动自然度和视觉质量方面，相较于基线模型取得了实质性提升，在定性和定量评估中均表现出卓越性能。

Conclusion: 本研究通过引入Talking-Critic奖励模型、构建Talking-NSQ数据集以及提出TLPO优化框架，成功解决了音视频驱动肖像动画难以对齐人类多维度精细偏好的问题，显著提升了生成视频的整体质量和用户体验。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [88] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

TL;DR: DeCLIP通过解耦CLIP的自注意力机制以增强内容和上下文特征，解决了CLIP在开放词汇密集感知中局部特征表示不足的问题，并在多项密集感知任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统密集视觉感知任务受限于预定义类别，难以应对现实世界中无限的视觉概念。现有视觉-语言模型（VLMs）如CLIP在开放词汇任务中虽有潜力，但直接应用于密集感知时，因局部特征表示的局限性导致性能不佳。具体观察到CLIP的图像token难以有效聚合空间或语义相关区域的信息，导致特征缺乏局部区分性和空间一致性。

Method: 提出DeCLIP框架，通过解耦CLIP的自注意力模块，分别获得“内容”和“上下文”特征。上下文特征通过联合蒸馏视觉基础模型（VFMs）的语义关联和扩散模型的对象完整性线索进行增强，以提升空间一致性。内容特征则与图像裁剪表示对齐，并受VFMs的区域关联约束，以提高局部区分性。

Result: DeCLIP为开放词汇密集感知奠定了坚实基础，并在包括2D检测和分割、3D实例分割、视频实例分割和6D物体姿态估计在内的广泛任务中，持续达到最先进的性能。

Conclusion: DeCLIP通过其独特的内容与上下文特征解耦增强机制，有效克服了现有VLM在开放词汇密集感知中的局限，显著提升了该领域性能，并为其建立了新的范式。

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [89] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

TL;DR: 本研究探究视觉-语言模型（VLM）嵌入空间中隐藏的性别刻板印象，通过分析面部图像和职业/活动短语的关联性，并提出了一个评估性别偏见的框架。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型虽然能对齐图像和文本，但可能在标准准确性指标不易察觉的方式下编码和放大社会刻板印象，特别是性别关联。因此，需要测试对比学习的视觉-语言编码器是否存在性别相关的联想。

Method: 研究构建了一个包含220张按感知二元性别分类的面部照片和150个描述职业与活动的短语数据集。计算图像和文本的单位范数嵌入，然后定义一个语句级别的关联得分，即男性集合的平均余弦相似度与女性集合的平均余弦相似度之差。通过自举法计算置信区间，并使用标签交换零模型估计无性别结构时的预期平均绝对关联度。

Result: 研究成果是对比视觉-语言空间中性别关联的语句级和类别级映射，附带不确定性、简单的健全性检查以及一个鲁棒的性别偏见评估框架。

Conclusion: 本研究成功创建了一个量化和评估视觉-语言模型嵌入空间中性别关联的框架，揭示了这些模型可能隐含的社会刻板印象，并提供了一种系统性检测这些偏见的方法。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [90] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

TL;DR: 该研究针对三维语义分割中的域泛化挑战，提出了一种类别级几何学习框架，通过类别级几何嵌入（CGE）和几何一致性学习（GCL）来关注领域不变的几何特征，从而提高模型在未知环境下的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 在将三维分割模型部署到未知环境时，域泛化是一个关键挑战。现有方法通过点云数据增强来缓解域偏移，但往往只学习全局几何模式，忽视了类别层面的分布和对齐问题，导致泛化能力受限。

Method: 本文提出一个类别级几何学习框架，旨在探索领域不变的几何特征。具体包括：1. **类别级几何嵌入 (CGE)**：用于感知点云特征的细粒度几何属性，构建各类别几何特性并将其与语义学习耦合。2. **几何一致性学习 (GCL)**：模拟潜在的三维分布并对齐类别级几何嵌入，使模型能够专注于几何不变信息，从而提高泛化能力。

Result: 实验结果证明了所提出方法的有效性。与当前最先进的域泛化点云方法相比，该方法在分割精度方面表现出非常有竞争力的性能。

Conclusion: 该类别级几何学习框架通过结合CGE和GCL，能够有效地学习和利用领域不变的几何特征，显著提高了三维语义分割模型在未知环境中的泛化能力和分割精度。

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [91] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

TL;DR: 本文提出PMTFR框架，通过金字塔补丁增强视觉理解和免训练精炼技术，解决了有监督复合图像检索（CIR）中CoT应用受限及额外训练成本问题，在有监督CIR任务上表现优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 复合图像检索（CIR）任务需同时理解图像和文本，现有两阶段方法常需额外训练排序模型。思维链（CoT）技术在CIR中应用有限，难以在有监督设置下取得满意效果，且常需复杂提示设计或视觉信息文本化。

Method: 本文提出“带有免训练精炼的金字塔匹配模型（PMTFR）”框架。该方法通过“金字塔补丁（Pyramid Patcher）”模块增强对视觉信息多粒度理解。此外，受表示工程启发，该模型从CoT数据中提取表示并注入到大型视觉语言模型（LVLM）中，实现了无需显式文本推理的“免训练精炼（Training-Free Refinement）”，从而获得精炼的检索分数。

Result: PMTFR在CIR基准测试中，在有监督CIR任务上超越了现有最先进的方法。

Conclusion: PMTFR框架通过其独特的金字塔补丁和免训练精炼机制，有效解决了有监督CIR任务中的挑战，显著提升了检索性能。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [92] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

TL;DR: 本研究首次广泛评估了稀疏自编码器（SAEs）在视觉模型中的表现力，发现SAE特征具有语义意义，能提升模型在图像任务上的泛化能力、可控生成和可解释性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）在解释大型语言模型（LLMs）的隐藏状态方面广受欢迎，但它们在视觉领域的研究却鲜有。本研究旨在填补这一空白，深入探讨SAEs在视觉模型中的应用潜力。

Method: 研究对SAEs在视觉模型中的表示能力进行了广泛评估，涉及多种基于图像的任务和三种视觉模型架构：视觉嵌入模型、多模态LLMs和扩散模型。具体方法包括：使用SAE特征进行OOD检测、恢复本体结构；通过文本编码器操纵实现语义引导，并开发自动化管道发现可解释属性；以及探索多模态LLMs中视觉与语言模态的共享表示。

Result: 实验结果表明，SAE特征具有语义意义，能改善域外泛化能力，并在三种视觉模型架构上实现可控生成。在视觉嵌入模型中，SAE特征可用于OOD检测并恢复底层模型的本体结构。在扩散模型中，SAEs实现了语义引导并自动化发现人类可解释属性。在多模态LLMs中，SAE特征揭示了视觉和语言模态之间的共享表示。

Conclusion: 本研究为SAE在视觉模型中的评估奠定了基础，突出显示了SAE在提高视觉领域可解释性、泛化能力和可控性方面的巨大潜力。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [93] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

TL;DR: 该研究提出了一个统一框架，用于单目内窥镜下的3D组织重建，通过结合尺度感知深度预测和时序感知精炼，解决了单目重建的挑战，并实现了优于现有技术的结果。


<details>
  <summary>Details</summary>
Motivation: 现有单目内窥镜姿态估计和3D组织重建面临多重挑战，包括深度模糊、生理组织变形、内窥镜运动不一致、纹理保真度低及视野受限，这些问题制约了精确导航和空间感知。

Method: 提出了一个统一的单目内窥镜组织重建框架，整合了尺度感知深度预测与时序约束感知精炼。具体方法包括：1. **MAPIS-Depth模块**：利用Depth Pro和Depth Anything结合L-BFGS-B优化生成伪度量深度估计。2. **时序精炼**：通过RAFT计算像素对应关系，并基于LPIPS感知相似性自适应融合流扭曲帧，以减少由组织变形和运动引起的伪影。3. **WEMA-RTDL模块**：用于精确配准合成的伪RGBD帧，优化旋转和平移。4. **3D表面重建**：采用基于截断符号距离函数（TSDF）的体素融合和Marching Cubes算法提取完整的3D表面网格。

Result: 在HEVD和SCARED数据集上进行了评估，包括消融研究和对比分析，结果表明该框架具有强大的鲁棒性，且性能优于当前最先进的方法。

Conclusion: 该框架成功克服了单目内窥镜重建的诸多限制，通过提供鲁棒且高精度的3D组织表面重建和姿态估计，显著增强了微创手术中的导航和空间感知能力。

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [94] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

TL;DR: TimeMachine是一个基于扩散模型的人脸年龄编辑框架，能在保持身份的同时实现精细化年龄编辑，并通过引入新模块和构建大型数据集提高了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在人脸图像编辑方面取得了显著进展，但在实现精细化年龄编辑的同时保持个人身份的一致性仍然是一个挑战。

Method: 本文提出了TimeMachine，一个新颖的基于扩散的框架。它通过在多交叉注意力模块中注入高精度年龄信息，显式分离年龄和身份相关特征，以实现更精确的年龄属性解耦。此外，提出了年龄分类器引导（ACG）模块，直接在潜在空间预测年龄以增强编辑精度。为解决大规模高质量人脸年龄数据集的不足，构建了HFFA数据集（包含百万张高分辨率带标注图像）。

Result: 实验结果表明，TimeMachine在精细化年龄编辑方面达到了最先进的性能，同时有效保持了身份一致性。

Conclusion: TimeMachine框架成功解决了人脸精细化年龄编辑中保持身份一致性的难题，并通过创新的模块设计和大规模数据集构建，显著提升了编辑的准确性和控制性。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [95] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本研究探索了高光谱成像(HSI)通过优化波段选择，在解决RGB图像同色异谱问题、提升车载行人分割性能方面的潜力，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在车载感知系统中，RGB图像的同色异谱现象导致行人与背景难以区分，对行人分割构成严重安全挑战。

Method: 研究使用Hyperspectral City v2 (H-City)数据集，将128通道HSI数据通过主成分分析(PCA)和基于对比度信噪比与联合互信息最大化(CSNR-JMIM)的最佳波段选择方法，降维为三通道数据，并与标准RGB数据进行比较。评估了U-Net、DeepLabV3+和SegFormer三种语义分割模型。

Result: CSNR-JMIM方法在行人分割方面表现优于RGB，平均IoU提升1.44%，F1-score提升2.18%。在骑行者分割上，IoU和F1-score也分别提升了1.43%和2.25%。性能提升归因于优化选择的HSI波段增强了光谱辨别能力，有效减少了误报。

Conclusion: 本研究证明通过高光谱图像的最佳波段选择，可以实现鲁棒的行人分割，显示出其在安全关键型汽车应用中的巨大潜力。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [96] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

TL;DR: 针对现有VMR方法编码不相关视频片段的问题，本文提出“先去噪后检索”范式及DRNet模型，通过去除噪声片段并净化视频表示来提升检索精度，实验证明优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动的视频精彩片段检索 (VMR) 方法会编码所有视频片段，包括与文本查询不相关的片段，这会干扰多模态对齐并阻碍模型优化。

Method: 提出“先去噪后检索”范式，首先显式过滤视频中与文本不相关的片段，然后利用净化后的多模态表示进行检索。遵循此范式，引入了去噪后检索网络 (DRNet)，该网络包含文本条件去噪 (TCD) 模块和文本重建反馈 (TRF) 模块。TCD通过交叉注意力和结构化状态空间块动态识别并生成噪声掩码，以净化多模态视频表示。TRF进一步从净化后的视频表示中提炼出单一查询嵌入并与文本嵌入对齐，作为训练期间去噪的辅助监督。最后，利用文本嵌入在净化后的视频表示上执行条件检索。

Result: 在Charades-STA和QVHighlights数据集上的实验表明，所提出的方法在所有指标上均超越了现有最先进的方法。此外，“先去噪后检索”范式具有良好的适应性，可以无缝集成到现有高级VMR模型中以进一步提升性能。

Conclusion: 通过引入“先去噪后检索”的创新范式和DRNet模型，本研究有效解决了VMR中无关片段干扰的问题，显著提升了检索性能，并为未来VMR模型的设计提供了可扩展的增强策略。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [97] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 现有VLMs在逻辑理解方面存在“盲点”。本文提出LogicBench基准来系统诊断此问题，并引入LogicCLIP训练框架，通过逻辑感知数据生成和优化目标来提升VLMs的逻辑推理能力，实验证明其有效性且不牺牲通用性能。


<details>
  <summary>Details</summary>
Motivation: Vision-Language Models (VLMs)如CLIP在多模态智能方面表现突出，但其逻辑理解能力尚未充分探索，存在“逻辑盲点”，限制了其在实际应用中的可靠性。

Method: 1. **诊断**: 提出LogicBench，一个包含超过5万个视觉-语言对的综合基准，涵盖9个逻辑类别和4个不同场景（图像、视频、异常检测、医疗诊断）。2. **改进**: 提出LogicCLIP训练框架，旨在通过逻辑感知的数据生成和优化的目标函数来增强VLMs的逻辑敏感度。其对比学习策略结合了粗粒度对齐、细粒度多项选择目标和新颖的逻辑结构感知目标。

Result: 1. **诊断结果**: 现有VLMs（包括SOTA模型）在LogicBench上的表现比人类低40多个准确率百分点，尤其在因果关系和条件性等挑战性任务中表现更差，显示出它们对表面语义的依赖而非关键逻辑结构。2. **LogicCLIP效果**: LogicCLIP在LogicBench所有领域显著提升了逻辑理解能力，大幅优于基线模型。此外，LogicCLIP在通用视觉-语言基准测试中保持并经常超越了竞争性能，表明增强逻辑理解能力不会牺牲模型的通用对齐能力。

Conclusion: LogicBench和LogicCLIP将成为推动VLM逻辑能力发展的重要资源。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [98] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

TL;DR: 本文提出DSC-Track，一种新型3D多目标跟踪器，通过关注时序空间模式的“线索一致性”来克服现有方法在拥挤场景和检测不准确时的局限性，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 3D多目标跟踪是自动驾驶的关键挑战。传统方法（如卡尔曼滤波）在拥挤或检测不准确时因忽略几何关系而失效。现有几何感知方法易受无关对象干扰，导致特征模糊和关联错误。因此，需要一种更鲁棒的方法来利用空间线索，特别关注一致的稳定空间模式。

Method: 本文提出了动态场景线索一致性跟踪器（DSC-Track）。首先，设计了统一的时空编码器，利用点对特征（PPF）学习区分性轨迹嵌入并抑制干扰。其次，线索一致性Transformer模块明确对齐历史轨迹和当前检测之间的一致特征表示。最后，动态更新机制保留显著的时空信息，以实现稳定的在线跟踪。

Result: 在nuScenes和Waymo Open数据集上进行了广泛实验，验证了方法的有效性和鲁棒性。在nuScenes基准测试中，该方法在验证集和测试集上分别达到了73.2%和70.3%的AMOTA，实现了最先进的性能。

Conclusion: 通过引入线索一致性原则和相应的模块化设计（PPF时空编码器、线索一致性Transformer和动态更新机制），DSC-Track有效解决了3D多目标跟踪在复杂场景中的挑战，显著提升了跟踪性能，达到了行业领先水平，为自动驾驶提供了鲁棒的解决方案。

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [99] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 提出NoOp方法，通过优化特定噪声解决扩散分类器（DC）的噪声不稳定性问题，提高分类性能和速度。


<details>
  <summary>Details</summary>
Motivation: 现有扩散分类器（DC）虽然能实现泛化图像分类，但普遍存在噪声不稳定性问题，即不同随机噪声会导致显著的性能变化；现有解决方案通过集成大量噪声来提高稳定性，但显著降低了分类速度。

Method: 本文首先探索了噪声在DC中的作用，并指出存在能缓解不稳定性的“好噪声”，且这些噪声应满足“频率匹配”和“空间匹配”两个原则。基于此，提出了NoOp（Noise Optimization）方法：通过优化一个数据集特定的参数化噪声（实现频率匹配），并训练一个Meta-Network来输出图像特定的噪声偏移（实现空间匹配），将两者之和作为DC的输入噪声。

Result: 在各种数据集上的广泛消融实验证明了NoOp方法的有效性。

Conclusion: NoOp通过学习匹配（即“好”）噪声，成功解决了扩散分类器中的噪声不稳定性问题，从而提高了分类性能和速度。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [100] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

TL;DR: 本文提出GANDiff FR，一个结合GAN和扩散模型的合成框架，用于精确控制人口统计和环境因素，以可复现地测量、解释和减少人脸识别中的偏见。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以精确控制人口统计和环境因素来衡量和减少人脸识别中的偏见，缺乏可复现性。需要一个能实现精细化属性控制的合成数据生成框架，以支持公平性审计和法规遵循。

Method: GANDiff FR整合了基于StyleGAN3的身份保持生成与基于扩散模型的属性控制，实现了在“其他条件不变”下对姿态（约30度）、光照（四个方向）和表情（五个级别）的精细化操作。合成了10,000张人口统计学平衡的人脸，并通过自动化检测（98.2%）和人工评估（89%）验证了真实性。使用ArcFace、CosFace和AdaFace进行基准测试，并在RFW、BUPT和CASIA WebFace上进行了跨数据集评估。

Result: 合成人脸真实性高，自动化检测率为98.2%，人工评估为89%。基准测试显示，AdaFace将组间TPR差异降低了60%（从6.3%降至2.5%），其中光照因素占剩余偏见的42%。合成数据到真实数据的迁移效果强（r 0.85）。尽管计算开销增加约20%，但GANDiff FR生成了三倍多的属性条件变体。

Conclusion: GANDiff FR为公平性审计建立了一个可复现、符合法规（EU AI Act）的标准，为透明和可扩展的偏见评估提供了支持。研究结果强调了光照在人脸识别偏见中的重要作用。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [101] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

TL;DR: 针对基于Transformer的增量目标检测中灾难性遗忘问题，现有匈牙利匹配知识蒸馏方法存在缺陷。本文提出索引对齐查询蒸馏（IAQD），通过查询索引对齐和选择性蒸馏，有效缓解遗忘并达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 在基于Transformer的增量目标检测任务中，现有知识蒸馏方法依赖匈牙利匹配建立查询对应关系，但该匹配方式可能导致当前阶段模型查询在不同迭代中匹配上一阶段模型的不同查询，从而使查询中编码的旧类别知识被重塑和遗忘，加剧灾难性遗忘。

Method: 本文提出索引对齐查询蒸馏（IAQD）方法。该方法不依赖匈牙利匹配，而是建立上一阶段和当前阶段模型中具有相同索引的查询之间的对应关系。此外，IAQD仅对对先前类别检测至关重要的部分查询进行索引对齐蒸馏。

Result: 广泛的实验表明，IAQD方法有效地缓解了知识遗忘，并在代表性基准测试中取得了新的最先进性能。

Conclusion: IAQD通过独特的索引对齐和选择性蒸馏策略，成功解决了基于Transformer的增量目标检测中的灾难性遗忘问题，显著提升了模型在保留旧知识同时学习新知识的能力。

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [102] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

TL;DR: 提出一种主动标注方法，通过利用分类器不确定性选择最具信息量的图像进行标注，显著降低构建宫颈细胞分类训练数据集的人力成本，从而实现数据高效的宫颈癌诊断。


<details>
  <summary>Details</summary>
Motivation: 宫颈细胞数量和类别的诊断信息对宫颈癌诊断至关重要。然而，现有自动分类方法需要代表性训练数据集，导致高昂甚至难以承受的人力标注成本。

Method: 提出一种“主动标注”（active labeling）方法。该方法通过高效利用分类器对未标记宫颈细胞图像的不确定性，准确选择对模型训练最有益的图像进行标注，以更少的人力成本构建具有代表性的训练数据集。

Result: 该新算法能快速估计不确定性，并有效增强所构建训练数据集的代表性能力。广泛的实证结果再次证实了其在指导人力成本使用方面的功效。

Conclusion: 该方法为数据高效的宫颈细胞分类开辟了新途径，有效解决了高昂数据标注成本的挑战。

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [103] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

TL;DR: 论文提出一种语义引导的对抗性目标标签选择框架，利用预训练语言和视觉-语言模型进行跨模态知识迁移，结果表明该方法优于静态词典，并可构建更具可解释性、标准化和可扩展性的对抗性基准。


<details>
  <summary>Details</summary>
Motivation: 在针对视觉模型的对抗性攻击中，目标标签的选择至关重要但常被忽视。现有策略（如随机、模型预测或静态语义资源）存在解释性、可复现性或灵活性限制。

Method: 提出一个语义引导的对抗性目标选择框架，利用预训练的语言模型（BERT、TinyLLAMA）和视觉-语言模型（CLIP）进行跨模态知识迁移，作为相似度来源。通过选择与真实标签语义上最相关和最不相关的标签来构建对抗性场景。实验在三个视觉模型和五种攻击方法上进行评估。

Result: 预训练模型能够一致地生成有效的对抗性目标，并优于WordNet等静态词典，尤其是在处理远距离类别关系时。此外，目标标签的静态测试可以为相似度源的有效性提供初步评估。

Conclusion: 研究结果证实了预训练模型适用于构建跨架构和数据集的、可解释、标准化和可扩展的对抗性基准。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [104] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 提出首个基于奖励引导的MLLM受控解码方法，实现对视觉基础能力（如物体精确度与召回率）的动态控制，并在物体幻觉基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）应用日益广泛，但需要适应不同的用户需求，尤其是在视觉基础能力方面。

Method: 引入奖励引导的MLLM解码方法，通过构建两个独立的奖励模型来分别控制输出中物体的精确度和召回率。该方法允许在推理时动态调整奖励函数的重要性（实现精确度与召回率的权衡）以及解码搜索的广度（权衡计算量与视觉基础程度）。

Result: 在标准物体幻觉基准测试中，该方法显著提升了MLLM推理过程的可控性，并持续优于现有的幻觉缓解方法。

Conclusion: 通过奖励引导的受控解码，可以有效提升MLLM的视觉基础能力，并为用户提供灵活的推理控制，尤其在缓解物体幻觉方面表现出色。

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [105] [HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model](https://arxiv.org/abs/2508.11350)
*Zhenhao Zhang,Hanqing Wang,Xiangyu Zeng,Ziyu Cheng,Jiaxin Liu,Haoyu Yan,Zhirui Liu,Kaiyang Ji,Tianxiang Gui,Ke Hu,Kangyi Chen,Yahao Fan,Mokai Pan*

Main category: cs.CV

TL;DR: HOID-R1是一个创新的HOI检测框架，它在强化学习范式下，首次整合了思维链（CoT）引导的监督微调（SFT）和群组相对策略优化（GRPO），解决了现有方法忽视3D空间理解的问题，并在HOI检测和开放世界泛化方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 人类-物体交互（HOI）的理解和识别在AR/VR及机器人技术中具有关键应用。然而，现有的开放词汇HOI检测方法过度依赖大型语言模型获取文本提示，却忽视了模型固有的3D空间理解能力。

Method: 本文提出HOID-R1，一个在强化学习范式下整合了思维链（CoT）引导的监督微调（SFT）和群组相对策略优化（GRPO）的HOI检测框架。具体而言，首先应用SFT赋予模型必要的推理能力，使其能阐明思考过程；随后整合GRPO，利用多奖励信号进行策略优化，以增强跨模态对齐。为减轻CoT推理中的幻觉，引入“MLLM-as-a-judge”机制来监督CoT输出，进一步提升泛化能力。

Result: 广泛实验表明，HOID-R1在HOI检测基准上实现了最先进（SOTA）的性能，并在开放世界泛化到新颖场景方面优于现有方法。

Conclusion: HOID-R1成功地通过整合推理能力和多模态对齐解决了现有HOI检测方法在3D空间理解上的不足，显著提升了HOI检测的性能和开放世界泛化能力，为相关应用提供了更强大的解决方案。

Abstract: Understanding and recognizing human-object interaction (HOI) is a pivotal
application in AR/VR and robotics. Recent open-vocabulary HOI detection
approaches depend exclusively on large language models for richer textual
prompts, neglecting their inherent 3D spatial understanding capabilities. To
address this shortcoming, we introduce HOID-R1, the first HOI detection
framework that integrates chain-of-thought (CoT) guided supervised fine-tuning
(SFT) with group relative policy optimization (GRPO) within a reinforcement
learning (RL) paradigm. Specifically, we initially apply SFT to imbue the model
with essential reasoning capabilities, forcing the model to articulate its
thought process in the output. Subsequently, we integrate GRPO to leverage
multi-reward signals for policy optimization, thereby enhancing alignment
across diverse modalities. To mitigate hallucinations in the CoT reasoning, we
introduce an "MLLM-as-a-judge" mechanism that supervises the CoT outputs,
further improving generalization. Extensive experiments show that HOID-R1
achieves state-of-the-art performance on HOI detection benchmarks and
outperforms existing methods in open-world generalization to novel scenarios.

</details>


### [106] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

TL;DR: 首次将RETFound基础模型应用于视盘分割任务，仅用少量任务特定数据便超越了现有最先进的分割方法，证明了其多任务适应性和卓越性能。


<details>
  <summary>Details</summary>
Motivation: RETFound作为眼科图像诊断的基础模型表现出色，但尚未被探索用于其他任务。本研究旨在首次将其应用于视网膜图像分析中基础且普遍的视盘分割任务，以拓展其应用范围。

Method: 通过为RETFound基础模型训练一个“头部”网络，并使用少量任务特定示例，将其首次适应于视盘分割任务。该系统在四个公共数据集（IDRID, Drishti-GS, RIM-ONE-r3, REFUGE）和一个私有数据集（GoDARTS）上进行了性能评估。

Result: 该分割系统在所有数据集上均取得了约96%的Dice分数，表现出极高的一致性。它超越了现有最先进的、特定于分割的基线网络，并在内部验证、域泛化和域适应方面均表现出色。

Conclusion: 本研究证明了RETFound等基础模型能够被有效适应于其原始训练目的之外的任务，即便只使用有限的任务特定数据也能取得优异性能，从而支持了基础模型作为特定任务架构替代方案的潜力，并为视网膜图像分析提供了新的先进解决方案。

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [107] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

TL;DR: 本文对拓扑保持损失函数（如SRL）进行了理论分析和实证评估，发现其在细管结构分割任务上未能超越传统基线模型，揭示了此类方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 图像分割中，拓扑保持损失函数被提出并声称能有效分割细管结构，例如SRL被宣称在基准数据集上达到SOTA。本研究旨在通过理论和实证分析，批判性地评估此类方法的实际性能和局限性。

Method: 本文对SRL损失函数的梯度进行了理论分析。同时，还在原始及额外细管数据集上，将其分割模型的性能与传统基线模型进行了实证比较。

Result: 通过理论分析和实证比较发现，基于SRL的分割模型在细管结构分割任务上的性能并未超越传统的基线模型。

Conclusion: 结合理论解释和实证证据，本研究批判性地评估了拓扑保持损失函数的局限性，为未来开发更有效的复杂细管结构分割模型提供了宝贵见解。

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [108] [Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition](https://arxiv.org/abs/2508.11376)
*Durgesh Mishra,Rishabh Uikey*

Main category: cs.CV

TL;DR: 本文提出一种统一的知识蒸馏（KD）框架，结合实例级嵌入蒸馏和基于关系的成对相似度蒸馏，解决了传统KD在人脸识别中捕获细节和关系不足的问题，并在基准测试中超越现有SOTA，甚至能使学生模型性能超越教师模型。


<details>
  <summary>Details</summary>
Motivation: 在计算资源受限的环境中部署人脸识别模型时，知识蒸馏至关重要。然而，传统的知识蒸馏方法（如L2特征蒸馏或特征一致性损失）未能有效捕捉细粒度的实例级细节和复杂的结构关系，导致性能不佳。

Method: 提出一种统一的方法，整合了两种新的损失函数：实例级嵌入蒸馏（Instance-Level Embedding Distillation）通过动态硬样本挖掘对齐个体特征嵌入；基于关系的成对相似度蒸馏（Relation-Based Pairwise Similarity Distillation）利用记忆库机制和样本挖掘策略捕获成对相似度关系。该框架旨在同时确保有效的实例级对齐和样本间几何关系的保留。

Result: 通过广泛的实验评估，该统一框架在多个人脸识别基准数据集上超越了现有最先进的蒸馏方法。值得注意的是，当使用强大的教师网络时，该统一的知识蒸馏方法甚至能使学生模型的准确性超越教师模型。

Conclusion: 所提出的统一知识蒸馏框架通过综合考虑实例级对齐和关系结构保留，提供了一个更全面的蒸馏过程，显著提升了人脸识别模型的性能，并展现出学生模型超越教师模型潜力的强大能力。

Abstract: Knowledge Distillation is crucial for optimizing face recognition models for
deployment in computationally limited settings, such as edge devices.
Traditional KD methods, such as Raw L2 Feature Distillation or Feature
Consistency loss, often fail to capture both fine-grained instance-level
details and complex relational structures, leading to suboptimal performance.
We propose a unified approach that integrates two novel loss functions,
Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity
Distillation. Instance-Level Embedding Distillation focuses on aligning
individual feature embeddings by leveraging a dynamic hard mining strategy,
thereby enhancing learning from challenging examples. Relation-Based Pairwise
Similarity Distillation captures relational information through pairwise
similarity relationships, employing a memory bank mechanism and a sample mining
strategy. This unified framework ensures both effective instance-level
alignment and preservation of geometric relationships between samples, leading
to a more comprehensive distillation process. Our unified framework outperforms
state-of-the-art distillation methods across multiple benchmark face
recognition datasets, as demonstrated by extensive experimental evaluations.
Interestingly, when using strong teacher networks compared to the student, our
unified KD enables the student to even surpass the teacher's accuracy.

</details>


### [109] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: 提出G-CUT3R，一种通过集成辅助先验信息来增强CUT3R模型的3D场景重建前馈方法。


<details>
  <summary>Details</summary>
Motivation: 现有前馈3D重建方法仅依赖输入图像，而实际场景中常有深度、相机标定等辅助数据。研究旨在利用这些辅助信息提升重建性能，解决现有方法对图像单一依赖的局限性。

Method: 对CUT3R模型进行轻量级修改，为每种辅助模态（如深度、相机参数）集成专用编码器以提取特征。这些模态特征通过零卷积与RGB图像特征融合，形成一个灵活的设计，允许在推理时无缝整合任意组合的先验信息。

Result: 在3D重建及其他多视图任务的多个基准测试中，该方法展示出显著的性能提升。结果表明，它能有效利用可用先验信息，并保持对不同输入模态的兼容性。

Conclusion: G-CUT3R通过有效整合多模态先验信息，显著提升了3D场景重建的性能和灵活性，证明了利用辅助数据改进现有前馈方法的潜力。

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [110] [RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator](https://arxiv.org/abs/2508.11409)
*Zhiming Liu,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 本文提出RMFAT，一种轻量级循环网络，用于高效且时间一致地恢复受大气湍流影响的视频，显著提高了清晰度和推理速度，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 大气湍流严重降低视频质量，引入几何形变、模糊和时间闪烁。现有最先进方法（基于Transformer和3D架构）计算和内存开销大，难以在资源受限场景下实时部署。

Method: 提出RMFAT（Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator），采用轻量级循环框架，每次仅使用两个输入帧进行恢复，以降低计算负担。该方法在编解码器阶段集成多尺度特征编解码和时间扭曲模块，以增强空间细节和时间连贯性。

Result: 在合成和真实大气湍流数据集上的实验表明，RMFAT在清晰度恢复方面优于现有方法（SSIM提高近9%），并且推理速度显著提升（运行时减少四倍以上）。

Conclusion: RMFAT能够有效抑制大气湍流，提高视频质量，且因其高效率而特别适用于实时大气湍流抑制任务。

Abstract: Atmospheric turbulence severely degrades video quality by introducing
distortions such as geometric warping, blur, and temporal flickering, posing
significant challenges to both visual clarity and temporal consistency. Current
state-of-the-art methods are based on transformer and 3D architectures and
require multi-frame input, but their large computational cost and memory usage
limit real-time deployment, especially in resource-constrained scenarios. In
this work, we propose RMFAT: Recurrent Multi-scale Feature Atmospheric
Turbulence Mitigator, designed for efficient and temporally consistent video
restoration under AT conditions. RMFAT adopts a lightweight recurrent framework
that restores each frame using only two inputs at a time, significantly
reducing temporal window size and computational burden. It further integrates
multi-scale feature encoding and decoding with temporal warping modules at both
encoder and decoder stages to enhance spatial detail and temporal coherence.
Extensive experiments on synthetic and real-world atmospheric turbulence
datasets demonstrate that RMFAT not only outperforms existing methods in terms
of clarity restoration (with nearly a 9\% improvement in SSIM) but also
achieves significantly improved inference speed (more than a fourfold reduction
in runtime), making it particularly suitable for real-time atmospheric
turbulence suppression tasks.

</details>


### [111] [SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models](https://arxiv.org/abs/2508.11411)
*Fabian H. Reith,Jannik Franzen,Dinesh R. Palli,J. Lorenz Rumberger,Dagmar Kainmueller*

Main category: cs.CV

TL;DR: 本文提出了SelfAdapt，一种无需标签即可自适应预训练细胞分割模型的方法，通过引入L2-SP正则化和无标签停止准则，在多个数据集上显著提升了Cellpose的性能，并可进一步优化已进行监督微调的模型。


<details>
  <summary>Details</summary>
Motivation: 通用细胞分割模型（如Cellpose）在训练数据以外的领域性能会下降。尽管监督微调可以解决此问题，但其所需的标注数据通常难以获取。因此，需要一种无需标签的自适应方法。

Method: 本文提出SelfAdapt，基于学生-教师增强一致性训练框架，引入L2-SP正则化和无标签停止准则，以实现预训练细胞分割模型的无监督自适应。

Result: 在LiveCell和TissueNet数据集上的评估显示，与基线Cellpose相比，AP0.5相对提升高达29.64%。此外，该无监督自适应方法还能进一步提升先前已进行监督微调的模型性能。

Conclusion: SelfAdapt提供了一种有效的无监督方法，用于自适应细胞分割模型，显著改善其在不同领域的性能，且对已监督微调的模型也有增益。该方法作为Cellpose的扩展已开源。

Abstract: Deep neural networks have become the go-to method for biomedical instance
segmentation. Generalist models like Cellpose demonstrate state-of-the-art
performance across diverse cellular data, though their effectiveness often
degrades on domains that differ from their training data. While supervised
fine-tuning can address this limitation, it requires annotated data that may
not be readily available. We propose SelfAdapt, a method that enables the
adaptation of pre-trained cell segmentation models without the need for labels.
Our approach builds upon student-teacher augmentation consistency training,
introducing L2-SP regularization and label-free stopping criteria. We evaluate
our method on the LiveCell and TissueNet datasets, demonstrating relative
improvements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we
show that our unsupervised adaptation can further improve models that were
previously fine-tuned with supervision. We release SelfAdapt as an easy-to-use
extension of the Cellpose framework. The code for our method is publicly
available at https: //github.com/Kainmueller-Lab/self_adapt.

</details>


### [112] [Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems](https://arxiv.org/abs/2508.11419)
*Florian Bayer,Maximilian Russo,Christian Rathgeb*

Main category: cs.CV

TL;DR: 本研究探索了在生物识别模板保护中，通过多模态融合和降维，在同态加密下高效处理生物识别数据，同时保持高识别准确性。


<details>
  <summary>Details</summary>
Motivation: 生物识别模板的隐私和安全是关键问题。同态加密（HE）虽能提供保护，但计算成本高昂。深度神经网络提取的特征模板较大，进一步加剧了HE的计算负担。研究旨在解决HE在生物识别模板保护中的计算挑战，并利用多模态融合提升安全性。

Method: 研究通过融合深度神经网络（DNN）提取的面部、指纹和虹膜特征（来自FRGC、MCYT和CASIA数据库）构建的内部虚拟多生物识别数据库，探索了缩减多生物识别模板尺寸的方法。所评估的方法易于在加密下实现、无需训练且具备泛化能力，主要通过特征向量降维来减少同态加密操作。

Result: 研究结果表明，通过特征向量降维，可以显著减少同态加密域中的操作，从而提高加密处理效率。通过融合多模态特征向量，模板大小可以减少67%，且与最佳单一模态相比，等错误率（EER）没有损失，同时保持或超越了单一生物识别的准确性和安全性。

Conclusion: 通过多模态特征融合和降维，可以大幅缩减生物识别模板尺寸，从而在同态加密下实现更高效、安全的生物识别处理，且不牺牲识别性能，甚至优于单一模态识别。

Abstract: Biometric recognition is widely used, making the privacy and security of
extracted templates a critical concern. Biometric Template Protection schemes,
especially those utilizing Homomorphic Encryption, introduce significant
computational challenges due to increased workload. Recent advances in deep
neural networks have enabled state-of-the-art feature extraction for face,
fingerprint, and iris modalities. The ubiquity and affordability of biometric
sensors further facilitate multi-modal fusion, which can enhance security by
combining features from different modalities. This work investigates the
biometric performance of reduced multi-biometric template sizes. Experiments
are conducted on an in-house virtual multi-biometric database, derived from
DNN-extracted features for face, fingerprint, and iris, using the FRGC, MCYT,
and CASIA databases. The evaluated approaches are (i) explainable and
straightforward to implement under encryption, (ii) training-free, and (iii)
capable of generalization. Dimensionality reduction of feature vectors leads to
fewer operations in the Homomorphic Encryption (HE) domain, enabling more
efficient encrypted processing while maintaining biometric accuracy and
security at a level equivalent to or exceeding single-biometric recognition.
Our results demonstrate that, by fusing feature vectors from multiple
modalities, template size can be reduced by 67 % with no loss in Equal Error
Rate (EER) compared to the best-performing single modality.

</details>


### [113] [ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](https://arxiv.org/abs/2508.11428)
*Jingyu Li,Bozhou Zhang,Xin Jin,Jiankang Deng,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: ImagiDrive是一种端到端自动驾驶框架，通过整合VLM驱动智能体和DWM场景想象器，形成统一的想象与规划循环，显著提升了在复杂动态环境下的预测和规划能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要丰富的上下文理解和精确的预测推理。VLMs和DWMs分别在多模态理解和未来场景生成方面表现出色，但将二者整合以利用其互补优势仍是一个有前景但未被充分研究的策略。主要挑战在于连接动作级决策与像素级预测，并保持计算效率。

Method: 本文提出ImagiDrive框架，将基于VLM的驾驶智能体与基于DWM的场景想象器集成，形成统一的“想象-规划”循环。驾驶智能体根据多模态输入预测初始轨迹，引导场景想象器生成未来场景，这些想象的场景随后用于迭代优化驾驶智能体的规划决策。为解决效率和准确性问题，引入了早期停止机制和轨迹选择策略。

Result: 在nuScenes和NAVSIM数据集上的大量实验验证表明，ImagiDrive在开环和闭环条件下均展现出优于现有替代方案的鲁棒性和卓越性能。

Conclusion: ImagiDrive成功整合了VLM和DWM的优势，有效解决了自动驾驶中预测精度和规划鲁棒性的挑战，为未来自动驾驶系统的发展提供了新的方向。

Abstract: Autonomous driving requires rich contextual comprehension and precise
predictive reasoning to navigate dynamic and complex environments safely.
Vision-Language Models (VLMs) and Driving World Models (DWMs) have
independently emerged as powerful recipes addressing different aspects of this
challenge. VLMs provide interpretability and robust action prediction through
their ability to understand multi-modal context, while DWMs excel in generating
detailed and plausible future driving scenarios essential for proactive
planning. Integrating VLMs with DWMs is an intuitive, promising, yet
understudied strategy to exploit the complementary strengths of accurate
behavioral prediction and realistic scene generation. Nevertheless, this
integration presents notable challenges, particularly in effectively connecting
action-level decisions with high-fidelity pixel-level predictions and
maintaining computational efficiency. In this paper, we propose ImagiDrive, a
novel end-to-end autonomous driving framework that integrates a VLM-based
driving agent with a DWM-based scene imaginer to form a unified
imagination-and-planning loop. The driving agent predicts initial driving
trajectories based on multi-modal inputs, guiding the scene imaginer to
generate corresponding future scenarios. These imagined scenarios are
subsequently utilized to iteratively refine the driving agent's planning
decisions. To address efficiency and predictive accuracy challenges inherent in
this integration, we introduce an early stopping mechanism and a trajectory
selection strategy. Extensive experimental validation on the nuScenes and
NAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over
previous alternatives under both open-loop and closed-loop conditions.

</details>


### [114] [Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting](https://arxiv.org/abs/2508.11431)
*Simona Kocour,Assia Benbihi,Torsten Sattler*

Main category: cs.CV

TL;DR: 本研究引入一个新基准和评估框架，用于衡量3D高斯飞溅中对象移除后的语义信息残留，并发布了Remove360数据集，发现当前方法在移除对象后仍保留语义信息，揭示了现有技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 理解对象移除后哪些语义信息会持久存在，对于隐私保护的3D重建和可编辑场景表示至关重要。研究发现，在3D高斯飞溅中，即使移除了视觉几何体，语义痕迹（语义残余）仍可能被无意中留下。

Method: 引入了一个新颖的基准和评估框架来测量3D高斯飞溅中对象移除后的语义残余。发布了Remove360数据集，其中包含真实世界室内外场景的移除前后RGB图像和对象级掩码。通过实验评估在对象移除后，语义存在是否真正消除，以及下游模型是否仍能推断出被移除的内容。

Result: 实验结果表明，尽管视觉几何体已缺失，现有方法仍能保留语义信息。研究揭示了当前3D对象移除技术的关键局限性。

Conclusion: 需要开发更鲁棒的解决方案，以应对真实世界的复杂性，从而更好地消除3D场景中的对象及其语义存在。

Abstract: Understanding what semantic information persists after object removal is
critical for privacy-preserving 3D reconstruction and editable scene
representations. In this work, we introduce a novel benchmark and evaluation
framework to measure semantic residuals, the unintended semantic traces left
behind, after object removal in 3D Gaussian Splatting. We conduct experiments
across a diverse set of indoor and outdoor scenes, showing that current methods
can preserve semantic information despite the absence of visual geometry. We
also release Remove360, a dataset of pre/post-removal RGB images and
object-level masks captured in real-world environments. While prior datasets
have focused on isolated object instances, Remove360 covers a broader and more
complex range of indoor and outdoor scenes, enabling evaluation of object
removal in the context of full-scene representations. Given ground truth images
of a scene before and after object removal, we assess whether we can truly
eliminate semantic presence, and if downstream models can still infer what was
removed. Our findings reveal critical limitations in current 3D object removal
techniques and underscore the need for more robust solutions capable of
handling real-world complexity. The evaluation framework is available at
github.com/spatial-intelligence-ai/Remove360.git. Data are available at
huggingface.co/datasets/simkoc/Remove360.

</details>


### [115] [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](https://arxiv.org/abs/2508.11433)
*Qian Liang,Yujia Wu,Kuncheng Li,Jiwei Wei,Shiyuan He,Jinyu Guo,Ning Xie*

Main category: cs.CV

TL;DR: MM-R1利用跨模态思维链和分组奖励优化，使统一多模态大语言模型能零样本进行个性化图像生成，克服了现有方法的扩展性限制。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态大语言模型（MLLMs）在个性化图像生成上面临挑战，主要表现为现有方法通常是主体特定的，需要大量数据进行微调，限制了其可扩展性。

Method: 本文提出了MM-R1框架，该框架整合了跨模态思维链（X-CoT）推理策略，以释放统一MLLMs的个性化图像生成潜力。具体方法包括：1) 通过解释用户提供的图像和上下文线索来理解和定位主体概念；2) 基于提取出的主体表示和用户提示生成个性化图像。为进一步增强推理能力，该方法还采用了分组奖励近端策略优化（GRPO）来明确对齐生成过程。

Result: 实验证明，MM-R1在零样本条件下，成功释放了统一MLLMs的个性化能力，生成了具有高主体保真度和强文本对齐的图像。

Conclusion: MM-R1框架通过其创新的推理和优化策略，成功地使统一多模态大语言模型具备了高效、高质量的零样本个性化图像生成能力。

Abstract: Multimodal Large Language Models (MLLMs) with unified architectures excel
across a wide range of vision-language tasks, yet aligning them with
personalized image generation remains a significant challenge. Existing methods
for MLLMs are frequently subject-specific, demanding a data-intensive
fine-tuning process for every new subject, which limits their scalability. In
this paper, we introduce MM-R1, a framework that integrates a cross-modal
Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of
unified MLLMs for personalized image generation. Specifically, we structure
personalization as an integrated visual reasoning and generation process: (1)
grounding subject concepts by interpreting and understanding user-provided
images and contextual cues, and (2) generating personalized images conditioned
on both the extracted subject representations and user prompts. To further
enhance the reasoning capability, we adopt Grouped Reward Proximal Policy
Optimization (GRPO) to explicitly align the generation. Experiments demonstrate
that MM-R1 unleashes the personalization capability of unified MLLMs to
generate images with high subject fidelity and strong text alignment in a
zero-shot manner.

</details>


### [116] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出一种高效、实时、易于部署的深度学习方法，仅通过视觉输入即可进行室内导航，并发布了新的大型数据集和安卓应用。


<details>
  <summary>Details</summary>
Motivation: 室内导航由于GPS信号差而困难，现有解决方案复杂、部署性差，且依赖额外传感器、标记、地图或网络，限制了其实用性。

Method: 开发了一种基于纯视觉输入的深度学习方法，结合新颖的图基路径生成、可解释数据增强和课程学习，使数据收集、标注和训练自动化。同时创建了一个大型购物中心视觉数据集（帧级标注下一方向），并开发了安卓应用。

Result: 成功实现了一个高效、实时、易于部署的室内导航深度学习方案，该方案仅依赖视觉输入，无需特殊传感器、路径标记、场景地图或互联网。同时发布了用于训练的大型数据集和实用的安卓应用。

Conclusion: 该研究提供了一个实用、高效且易于部署的纯视觉室内导航解决方案，通过自动化数据处理和提供大规模数据集，显著推动了该领域的发展，并为实际应用奠定了基础。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [117] [Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2508.11464)
*Xiaoya Zhu,Yibing Nan,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文提出基于Swin Transformer V2-B的Deepfake图像检测方法，结合数据增强与样本生成技术，在比赛中获得优秀奖。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术发展，Deepfake技术带来数字安全挑战，因此需要有效识别AI生成内容，特别是Deepfake图像。

Method: 采用Swin Transformer V2-B分类网络，并利用在线数据增强和离线样本生成方法来丰富训练样本多样性，提高模型泛化能力。

Result: 在Deepfake图像检测比赛中荣获优秀奖。

Conclusion: 所提出的基于Swin Transformer V2-B并结合数据增强和样本生成的方法，在Deepfake图像检测任务中表现出色，成功应对了数字安全挑战。

Abstract: With the rapid development of technology in the field of AI, deepfake
technology has emerged as a double-edged sword. It has not only created a large
amount of AI-generated content but also posed unprecedented challenges to
digital security. The task of the competition is to determine whether a face
image is a Deepfake image and output its probability score of being a Deepfake
image. In the image track competition, our approach is based on the Swin
Transformer V2-B classification network. And online data augmentation and
offline sample generation methods are employed to enrich the diversity of
training samples and increase the generalization ability of the model. Finally,
we got the award of excellence in Deepfake image detection.

</details>


### [118] [CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation](https://arxiv.org/abs/2508.11469)
*Hongjin Fang,Daniel Reisenbüchler,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: CoFi是一种快速高效的粗到精少样本分割流水线，专为电镜图像中的肾小球基底膜（GBM）分割设计，解决了高标注负担问题，并实现了高精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 肾小球基底膜（GBM）的准确分割对肾病诊断至关重要。传统深度学习方法依赖大量像素级标注，不适合临床；现有少样本学习难以捕捉精细结构。因此，亟需一种高效、低标注负担且能捕捉精细结构的GBM分割方法。

Method: 本研究提出CoFi粗到精少样本分割流水线。首先，仅用三张标注图像训练轻量级神经网络生成初始粗分割掩膜；随后，自动处理该掩膜以生成高质量的形态学感知点提示，并引导SAM模型进行精细化分割。

Result: 所提出的CoFi方法在GBM分割上表现出色，Dice系数达到74.54%，推理速度为1.9 FPS。

Conclusion: CoFi不仅有效减轻了传统方法的标注和计算负担，还实现了准确可靠的分割结果。其速度和标注效率使其非常适用于研究，并具有强大的临床应用潜力。

Abstract: Accurate segmentation of the glomerular basement membrane (GBM) in electron
microscopy (EM) images is fundamental for quantifying membrane thickness and
supporting the diagnosis of various kidney diseases. While supervised deep
learning approaches achieve high segmentation accuracy, their reliance on
extensive pixel-level annotation renders them impractical for clinical
workflows. Few-shot learning can reduce this annotation burden but often
struggles to capture the fine structural details necessary for GBM analysis. In
this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot
segmentation pipeline designed for GBM delineation in EM images. CoFi first
trains a lightweight neural network using only three annotated images to
produce an initial coarse segmentation mask. This mask is then automatically
processed to generate high-quality point prompts with morphology-aware pruning,
which are subsequently used to guide SAM in refining the segmentation. The
proposed method achieved exceptional GBM segmentation performance, with a Dice
coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that
CoFi not only alleviates the annotation and computational burdens associated
with conventional methods, but also achieves accurate and reliable segmentation
results. The pipeline's speed and annotation efficiency make it well-suited for
research and hold strong potential for clinical applications in renal
pathology. The pipeline is publicly available at:
https://github.com/ddrrnn123/CoFi.

</details>


### [119] [TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations](https://arxiv.org/abs/2508.11478)
*Xinyi Yin,Wenbo Yuan,Xuecheng Wu,Liangyu Fu,Danlei Huang*

Main category: cs.CV

TL;DR: 针对特殊场景下异常人类行为检测中YOLO方法的挑战（小目标、任务冲突、多尺度融合），本文提出了TACR-YOLO框架，通过引入多个注意力模块和网络优化，并在新数据集PABD上实现了高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 异常人类行为检测（AHBD）在特殊场景中至关重要，但现有YOLO方法在处理小目标、分类-回归任务冲突以及多尺度融合方面存在局限性。

Method: 提出了TACR-YOLO实时框架，包含：坐标注意力模块（增强小目标检测）、任务感知注意力模块（处理任务冲突）、强化颈部网络（精炼多尺度融合）。此外，采用K-means聚类优化锚框尺寸，并引入DIoU-Loss改进边界框回归。同时，构建并发布了PABD数据集。

Result: TACR-YOLO在PABD数据集上取得了91.92%的mAP，并具备竞争力的速度和鲁棒性。消融研究也验证了各项改进的有效性。

Conclusion: 本工作为特殊场景下的异常行为检测提供了新的见解，并推动了该领域的发展。

Abstract: Abnormal Human Behavior Detection (AHBD) under special scenarios is becoming
increasingly crucial. While YOLO-based detection methods excel in real-time
tasks, they remain hindered by challenges including small objects, task
conflicts, and multi-scale fusion in AHBD. To tackle them, we propose
TACR-YOLO, a new real-time framework for AHBD. We introduce a Coordinate
Attention Module to enhance small object detection, a Task-Aware Attention
Module to deal with classification-regression conflicts, and a Strengthen Neck
Network for refined multi-scale fusion, respectively. In addition, we optimize
Anchor Box sizes using K-means clustering and deploy DIoU-Loss to improve
bounding box regression. The Personnel Anomalous Behavior Detection (PABD)
dataset, which includes 8,529 samples across four behavior categories, is also
presented. Extensive experimental results indicate that TACR-YOLO achieves
91.92% mAP on PABD, with competitive speed and robustness. Ablation studies
highlight the contribution of each improvement. This work provides new insights
for abnormal behavior detection under special scenarios, advancing its
progress.

</details>


### [120] [OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring](https://arxiv.org/abs/2508.11482)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary*

Main category: cs.CV

TL;DR: 本研究对建筑行业AI应用的视觉数据集进行了系统性审查，创建了OpenConstruction目录，并提出了未来数据基础设施的路线图。


<details>
  <summary>Details</summary>
Motivation: 建筑行业AI/ML应用日益依赖视觉数据，但现有数据集在规模、模态、标注质量和代表性方面差异大，且缺乏系统的审查，这限制了对数据集现状的理解、关键空白的识别以及未来AI应用方向的指导。

Method: 通过广泛搜索学术数据库和开放数据平台，收集了51个2005-2024年期间公开可用的建筑视觉数据集。采用结构化数据模式，根据数据基础、数据模态、标注框架和下游应用领域对这些数据集进行分类。

Result: 研究成果综合为一个开源目录“OpenConstruction”，旨在支持数据驱动的方法开发。同时，讨论了现有建筑数据集中存在的关键局限性，并提出了一个以FAIR（可查找、可访问、可互操作、可重用）原则为核心的未来数据基础设施路线图。

Conclusion: 通过审查当前数据集状况并提出战略优先事项，本研究支持建筑领域数据中心解决方案的进步与发展。

Abstract: The construction industry increasingly relies on visual data to support
Artificial Intelligence (AI) and Machine Learning (ML) applications for site
monitoring. High-quality, domain-specific datasets, comprising images, videos,
and point clouds, capture site geometry and spatiotemporal dynamics, including
the location and interaction of objects, workers, and materials. However,
despite growing interest in leveraging visual datasets, existing resources vary
widely in sizes, data modalities, annotation quality, and representativeness of
real-world construction conditions. A systematic review to categorize their
data characteristics and application contexts is still lacking, limiting the
community's ability to fully understand the dataset landscape, identify
critical gaps, and guide future directions toward more effective, reliable, and
scalable AI applications in construction. To address this gap, this study
conducts an extensive search of academic databases and open-data platforms,
yielding 51 publicly available visual datasets that span the 2005-2024 period.
These datasets are categorized using a structured data schema covering (i) data
fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and
point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv)
downstream application domains (e.g., progress tracking). This study
synthesizes these findings into an open-source catalog, OpenConstruction,
supporting data-driven method development. Furthermore, the study discusses
several critical limitations in the existing construction dataset landscape and
presents a roadmap for future data infrastructure anchored in the Findability,
Accessibility, Interoperability, and Reusability (FAIR) principles. By
reviewing the current landscape and outlining strategic priorities, this study
supports the advancement of data-centric solutions in the construction sector.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [121] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: 本文提出了一种针对一阶ASPIC+论证的智能实例化（grounding）方法，通过Datalog转换和ASPIC+特有简化来管理实例化规模，并经验性地证明了其可伸缩性。


<details>
  <summary>Details</summary>
Motivation: 尽管ASPIC+常用一阶规则，但现有论证推理方法大多只支持命题规则，需要进行实例化。然而，实例化可能导致输入理论规模呈指数级增长，且目前缺乏针对ASPIC+的专用智能解决方案。

Method: 提出了一种智能实例化过程，旨在控制实例化规模并保持推理正确性。具体方法包括：将一阶ASPIC+实例转换为Datalog程序并查询Datalog引擎以获取实例化代换；以及提出ASPIC+特有的简化措施，以避免实例化不影响推理的规则。最后，对原型实现进行了实证评估。

Result: 所提出的智能实例化过程能够有效地控制实例化后理论的规模，同时确保推理过程的正确性。通过实证评估，证明了该方法的良好可伸缩性。

Conclusion: 该研究成功地为一阶ASPIC+论证提供了一种有效的智能实例化解决方案，解决了处理一阶规则时面临的规模爆炸问题，确保了推理的正确性和可伸缩性。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [122] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 本文提出一个多智能体算法追索框架，通过建模为带容量的加权二分匹配问题并采用三层优化，实现系统级设计，旨在提高社会福利，解决传统个体追索忽略多智能体互动的问题。


<details>
  <summary>Details</summary>
Motivation: 现有算法追索研究主要关注个体（寻求者）对单一模型（提供者）的场景，忽略了现实世界中多智能体（多个寻求者和提供者）互动并竞争有限资源的问题，导致个体福利优化可能忽视集体可行性和社会福利。

Method: 将多对多互动建模为带容量的加权二分匹配问题，其中匹配由追索成本和提供者容量决定。通过三层优化框架实现：1) 基本带容量匹配，2) 优化容量再分配以最小化福利差距，3) 成本感知优化以平衡福利最大化与容量调整成本。

Result: 在合成和真实世界数据集上的实验验证表明，该框架能使多对多算法追索在系统设置中进行最小修改的情况下，实现接近最优的社会福利。

Conclusion: 这项工作将算法追索从个体推荐扩展到系统级设计，为在保持个体可操作性的同时实现更高社会福利提供了一条可行的路径。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [123] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: 本文提出一种结合PPO（近端策略优化）和基于Transformer的L2O（学习优化器）的自动化质子治疗计划框架，旨在显著提升治疗计划的效率和质量，并已在临床上验证其优于传统方法和人工计划。


<details>
  <summary>Details</summary>
Motivation: 质子笔形束扫描（PBS）治疗头颈部癌症的计划过程涉及多重冲突目标，需要人工耗费大量精力和经验进行参数调整和计算昂贵的逆向优化。尽管在自动调整目标参数方面已取得进展，但作为最耗时的核心环节——逆向优化，仍高度依赖理论驱动方法，存在效率瓶颈。

Method: 本研究提出了一种数据驱动的逆向优化器，并将其集成到基于PPO的自动治疗计划框架中。该逆向优化器是一种L2O方法，通过从特定任务数据分布中学习来预测更新步骤。作者首次将为大型语言模型（LLMs）设计的长上下文处理技术整合到Transformer-based L2O框架中，以解决现有L2O方法的可扩展性问题。PPO框架作为外层虚拟规划器，通过策略网络自主调整目标参数；内部循环的L2O逆向优化器则根据PPO细化的目标计算机器可交付的MU（机器单位）值。

Result: 研究收集了97名患者的数据进行验证。与传统的L-BFGSB方法相比，所提出的基于L2O的逆向优化器在有效性（Effectiveness）和效率（Efficiency）上分别提升了22.97%和36.41%。结合PPO虚拟规划器，该框架在平均2.55小时内生成的计划，对于不同处方剂量、靶区数量和光束角度的患者，其危及器官（OAR）的保护效果与人工计划相当或更优，且靶区覆盖更优。

Conclusion: 该框架能够以临床可接受的时间自动生成高质量的质子治疗计划，在显著提高效率的同时，确保了治疗效果优于或媲美人工计划，为质子治疗计划的自动化提供了有效且高效的解决方案。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [124] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: 该论文扩展了论元假设（ABA）中可采纳性概念的研究，引入并分析了通用（非扁平）ABA的强弱可采纳性及其语义，并探讨了它们的性质和局限性。


<details>
  <summary>Details</summary>
Motivation: 现有研究对强可采纳性在ABA中的探索不足，且弱可采纳性的研究仅限于扁平ABA。本研究旨在填补这些空白，将强弱可采纳性推广至更通用的非扁平ABA语境，并引入相应语义。

Method: 1. 在通用（非扁平）ABA中引入并研究了强可采纳性（strong admissibility）和弱可采纳性（weak admissibility）。2. 为这些新概念定义了偏好（preferred）、完备（complete）和基础（grounded）语义。3. 利用抽象双极集合论证框架（BSAFs）作为形式化工具来捕捉假设间的关系并表示非扁平ABA。

Result: 1. 成功为ABA引入了强可采纳性并分析了其理想性质。2. 将弱可采纳性的研究从扁平ABA扩展到非扁平ABA。3. 证明了核心的模块化性质在经典、强和弱可采纳性下均得以保持。4. 指出非扁平ABA中的强和弱可采纳性语义与标准可采纳性语义存在部分共同缺陷。

Conclusion: 本研究扩展了ABA中可采纳性概念的理论基础，特别是在非扁平语境下系统地分析了强弱可采纳性及其语义，明确了其优势（如模块化）和局限，为未来的研究提供了方向。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [125] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: 现有模型擅长解决定义清晰的问题，但缺乏在信息不足时主动提问的能力。本研究通过构建新数据集评估大型推理模型（LRM）的此项能力，发现LRM无法主动提问，并存在过度思考和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅评估LRM解决定义清晰问题的能力，但真正的智能体应能在信息不足时主动询问。这种评估空白是一个关键缺陷。

Method: 提出了一个包含两种类型、不同上下文的残缺问题新数据集，并基于此数据集对LRM进行了系统评估。

Result: 评估结果显示LRM无法主动询问信息，并暴露出过度思考和幻觉行为。研究还强调了监督微调在学习此能力时的潜力和挑战。

Conclusion: 本研究旨在为开发具有真正智能而非仅仅解决问题的LRM提供新见解。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [126] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: SAGE是一种用于持续知识图谱嵌入（CKGE）的框架，通过自适应嵌入维度和动态蒸馏机制，有效处理知识图谱的动态更新和不同规模的增长，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的知识图谱嵌入方法主要关注静态图，而现实世界的知识图谱是动态演化的。现有持续知识图谱嵌入（CKGE）方法未能充分考虑更新规模的差异，并且缺乏在整个更新过程中进行系统评估。

Method: 本文提出了SAGE框架，一种尺度感知渐进演化框架，用于持续知识图谱嵌入。具体方法包括：1) 根据更新规模确定并相应扩展嵌入维度；2) 采用动态蒸馏机制，以平衡保留现有知识和整合新事实。

Result: 在七个基准数据集上进行的广泛实验表明，SAGE始终优于现有基线方法，在MRR上提升1.38%，H@1上提升1.25%，H@10上提升1.6%。此外，与使用固定嵌入维度的方法相比，SAGE在每个快照上都实现了最佳性能，证明了自适应嵌入维度在CKGE中的重要性。

Conclusion: SAGE通过考虑更新规模并平衡知识保留与新信息整合，有效解决了动态知识图谱的演化问题，实现了持续知识图谱嵌入的最优性能。研究强调了自适应嵌入维度在CKGE中的关键作用。

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [127] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: 本研究提出CRAFT-GUI框架，通过结合课程学习（基于GRPO）和细粒度奖励函数，解决了现有强化学习方法在GUI自动化任务中忽略难度差异和奖励信号粗糙的问题，显著提升了代理性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在GUI任务中面临两大局限：1) 忽视不同GUI任务的难度差异，将训练数据视为均匀集合，阻碍学习过程适应性；2) 大多数方法将任务特定细微差别合并为单一粗糙奖励，导致策略更新效率低下。

Method: 提出CRAFT-GUI，一个基于组相对策略优化（GRPO）的课程学习框架，明确考虑轨迹间的难度差异。同时，设计了一种结合简单规则信号和模型评估的奖励函数，以提供更丰富和细致的训练反馈，实现更精细的策略优化。

Result: 实验结果表明，该方法在公共基准Android Control上比现有最先进方法提高了5.6%，在内部在线基准上提高了10.3%。

Conclusion: 这些发现实证验证了将强化学习与课程学习集成到GUI交互任务中的有效性。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [128] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLM）代理在不确定库存决策中的表现和偏见，发现其存在类似人类的决策偏见，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM代理已应用于业务运营，但其在不确定库存决策中的能力以及决策偏见（如框架效应）仍未被充分探索，这引发了对其在实际问题中有效性和潜在偏见影响的担忧。

Method: 引入了AIM-Bench，一个新型基准，通过一系列库存补货实验来评估LLM代理在不确定供应链管理场景中的决策行为。此外，还探索了认知反思和信息共享等策略来缓解“趋中效应”和“牛鞭效应”。

Result: 研究发现，不同的LLM通常表现出不同程度的决策偏见，这些偏见与人类观察到的偏见相似。同时，探索了认知反思和信息共享策略以减轻“趋中效应”和“牛鞭效应”。

Conclusion: 在库存决策场景中部署LLM时，需仔细考虑其潜在偏见。本研究的见解有望为缓解人类决策偏见和开发以人为中心的供应链决策支持系统提供方向。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [129] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: Inclusion Arena是一个基于AI应用中用户反馈的实时LLM/MLLM排行榜，通过创新方法提供可靠且贴近实际的性能评估，旨在弥补现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）和多模态大语言模型（MLLMs）评估基准（如静态数据集或通用众包提示）未能充分反映模型在真实世界应用中的实际表现，导致评估与实际使用场景脱节。

Method: 本文提出了Inclusion Arena，一个实时排行榜平台。它通过将模型两两比较集成到用户在AI应用中的自然交互中来收集人类反馈。排名采用增强型的Bradley-Terry模型，并引入了两项关键创新：(1) Placement Matches，用于新模型的快速冷启动评级；(2) Proximity Sampling，优先比较能力相近的模型以最大化信息增益和提高排名稳定性。

Result: 广泛的实证分析和模拟结果表明，Inclusion Arena生成的排名可靠且稳定，与通用众包数据集相比，展现出更高的数据传递性，并显著降低了恶意操纵的风险。

Conclusion: Inclusion Arena旨在通过促进基础模型与真实世界应用之间的开放联盟，加速LLMs和MLLMs的开发，使其能够真正为实际、以用户为中心的部署而优化。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [130] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: 本研究将经典规划中的地标概念扩展到随机领域，并调整UCT算法利用其作为子目标来分解MDPs，显著提升了在线概率规划的性能。


<details>
  <summary>Details</summary>
Motivation: 地标（Landmarks）在经典规划中贡献巨大，但在随机领域中却鲜有应用。本研究旨在弥补这一空白，探索地标在随机域中的有效性。

Method: 研究者形式化了概率地标，并调整UCT算法以利用这些地标作为子目标来分解马尔可夫决策过程（MDPs）。关键在于平衡贪婪地达成地标与最终目标达成之间的关系。

Result: 在基准领域的实验结果表明，选择得当的地标能够显著提高UCT在在线概率规划中的性能。然而，贪婪地标达成与长期目标达成之间的最佳平衡点因问题而异。

Conclusion: 研究结果表明，地标能够为解决MDPs的实时算法（anytime algorithms）提供有益的指导，有助于提升其性能。

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [131] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: 本文提出一种结合问题分解的新型LLM辅助规划器，旨在解决大规模规划问题中的状态空间爆炸。该规划器利用LLM4Inspire（通用知识）和LLM4Predict（领域特定知识）两种范式。实验证明LLMs能有效剪枝搜索空间并找到可行解，其中LLM4Predict表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 大规模规划问题因状态空间爆炸而成为挑战。现有利用大语言模型（LLMs）剪枝搜索空间的方法，普遍忽视了结合领域特定知识来确保规划的有效性，这导致了无效计划的风险。

Method: 本文提出了一种新颖的LLM辅助规划器，其核心思想是问题分解，即将大型规划问题分解为多个简化的子任务。在此基础上，研究探索了两种LLM利用范式来辅助问题分解：LLM4Inspire，其利用通用知识提供启发式指导；LLM4Predict，其通过领域特定知识推断中间条件。

Result: 实验结果表明，所提出的规划器在解决大规模规划问题时，能够有效地划分搜索空间。LLMs在剪枝搜索空间的同时，能够有效地定位可行解。具体而言，与提供通用知识的LLM4Inspire相比，注入了领域特定知识的LLM4Predict展现出更大的潜力。

Conclusion: 该研究表明，结合问题分解和LLM辅助（特别是融入领域特定知识的LLM4Predict）的规划器，是解决大规模规划问题的有效途径。通过剪枝搜索空间和发现可行解，该方法突显了领域特定知识在提升LLM在规划领域性能方面的重要性。

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [132] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

TL;DR: 本文提出一种基于合作博弈的多准则决策方法，用于解决投票集成学习中权重分配单一的问题，并在实验中证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 第四次工业革命以来，人工智能技术广泛应用但存在过拟合、欠拟合、类别不平衡及模型表征局限性等问题。集成学习，特别是投票集成，被广泛用于解决这些问题。然而，现有投票集成权重方法仅考虑单一评估准则，未能充分反映模型中需考虑的多种现实信息。

Method: 提出一种在多准则情境下，通过合作博弈进行决策的方法。该方法能同时考虑并反映分类器中已知的各种先验信息，以实现恰当的权重分配。

Result: 将机器学习算法应用于Open-ML-CC18数据集，并与现有集成权重方法进行比较。实验结果表明，所提方法比其他权重方法表现出更优越的性能。

Conclusion: 基于合作博弈的多准则决策方法，通过全面考虑分类器的多种先验信息，能有效优化权重分配，显著提升投票集成学习的性能。

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [133] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

TL;DR: 研究提出一个150亿参数的Apriel-Nemotron-15B-Thinker模型，该模型在企业任务中，以一半的内存占用实现了与320亿参数的先进大型语言模型相当或更优的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽具有卓越的推理能力，但其高昂的内存和计算成本限制了它们在实际企业环境中的广泛应用。

Method: Apriel-Nemotron-15B-Thinker模型采用四阶段训练流程：1) 基础模型升级，2) 持续预训练，3) 监督微调（SFT），以及 4) 使用GRPO进行强化学习。

Result: 通过在多种基准测试上的综合评估，Apriel-Nemotron-15B-Thinker模型（150亿参数）在内存占用仅为同类最先进中型模型一半的情况下，性能与320亿参数的对应模型相当或更优。

Conclusion: Apriel-Nemotron-15B-Thinker模型成功证明，可以在显著减小模型规模和内存需求的同时，实现与更大、更先进模型相当甚至超越的性能，从而解决了LLMs在企业部署中的成本障碍。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [134] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

TL;DR: 提出一种基于提示的持续学习（PCL）方法，通过统一提示池和最小扩展策略，解决了医疗领域数据共享受限导致的灾难性遗忘和数据分布偏移问题，显著提升了糖尿病视网膜病变诊断准确率并降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 医疗领域数据共享受伦理、社会和制度限制，导致集中式学习困难，各机构需增量更新模型。传统训练存在过拟合和灾难性遗忘，且医疗数据分布多样。现有持续学习方法多针对自然图像，医疗专用持续学习研究不足。

Method: 提出一种基于提示的持续学习（PCL）方法，该方法包含一个统一的提示池和最小扩展策略，通过扩展和冻结部分提示来降低计算开销，并引入一个新颖的正则化项以平衡知识保留与适应性。

Result: 在三个糖尿病视网膜病变数据集上的实验表明，该模型在最终分类准确率上比现有最佳方法至少提高10%，F1分数提高9个点，同时降低了推理成本。

Conclusion: 该研究有望推动可持续的医疗AI发展，在分布式医疗场景中实现实时诊断、患者监测和远程医疗应用。

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [135] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

TL;DR: Retro-Expert是一个可解释的逆合成预测框架，它结合了大型语言模型和专业模型的优势，实现了高性能并提供专家级的化学逻辑解释。


<details>
  <summary>Details</summary>
Motivation: 现有的逆合成预测模型依赖静态模式匹配，缺乏有效的逻辑决策能力且是黑箱，这限制了它们的应用并导致难以理解的决策过程。

Method: 该研究提出了Retro-Expert框架，通过强化学习结合大型语言模型（LLM）和专业模型进行协作推理。它包含三个核心组件：1) 专业模型构建高质量的化学决策空间；2) LLM进行批判性推理以生成预测和相应的可解释推理路径；3) 强化学习优化可解释的决策策略，从而输出基于化学逻辑的自然语言解释。

Result: 实验表明，Retro-Expert在各项指标上均超越了单独基于LLM和专业模型的方法。此外，它提供了与专家判断一致的解释，有效弥合了AI预测与实际可操作的化学见解之间的鸿沟。

Conclusion: Retro-Expert成功提升了逆合成预测的性能和可解释性，使其预测结果更具化学逻辑，并能提供专家级的洞察，有助于将AI预测转化为实际的化学见解。

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [136] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 本研究引入了BeyondWeb框架，用于生成高质量的预训练合成数据，显著超越现有技术，能使小型模型表现优于大型模型，并揭示了优化合成数据质量的关键因素。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练面临“数据墙”效应，即简单增加真实数据量回报递减；而合成数据虽有潜力，但其质量影响因素尚不明确。因此，需要开发能生成高质量合成数据的框架以突破性能瓶颈。

Method: 引入了BeyondWeb合成数据生成框架，该框架旨在扩展传统网络规模数据集的能力，并专注于优化多方面因素以生成高质量的预训练数据，而非依赖单一解决方案。研究还提供了关于如何重组数据、模型大小与家族对数据质量影响的见解。

Result: BeyondWeb在14项基准测试中，平均表现优于Cosmopedia达5.1个百分点，优于Nemotron-Synth达2.6个百分点。其训练速度比开放网络数据快7.7倍，比Nemotron-Synth快2.7倍。值得注意的是，使用BeyondWeb训练的3B模型在180B tokens预算下，性能超越了使用Cosmopedia训练的8B模型。研究还提供了关于合成数据益处驱动因素、如何及何时重组数据，以及模型大小和家族对数据质量影响的见解。

Conclusion: 生成高质量的预训练合成数据没有“灵丹妙药”，最佳结果需要共同优化诸多因素，这是一项需要严谨科学和实践经验的挑战性任务。简单方法可能收效甚微且成本高昂，而如BeyondWeb所示的精心执行方法则能带来变革性改进。

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [137] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 提出首个针对预训练文本到图像（T2I）模型的选择框架M&C，旨在高效识别最适合目标领域微调的模型。


<details>
  <summary>Details</summary>
Motivation: 现有扩散和Transformer架构的T2I模型虽快速发展并广泛共享，用户在微调时面临新挑战：如何从众多预训练模型中高效选择最适合特定目标数据域的模型，而无需对所有模型进行穷举式微调。传统分类任务的模型选择方法不适用于T2I模型。

Method: 本文提出M&C框架，其核心是一个匹配图。该图的节点包括可用模型和已分析的数据集；边则连接模型-数据对（表示微调性能）和数据-数据对（表示数据相似性）。通过结合模型/数据特征以及从匹配图中提取的图嵌入特征，构建一个预测模型，以选择在目标领域微调后能达到最佳质量的模型。

Result: 在10个T2I模型和32个数据集上对M&C进行了评估，并与三个基线方法进行了比较。结果显示，M&C在61.3%的案例中成功预测了最佳微调模型，在其余案例中也能预测出性能相近的模型。

Conclusion: M&C框架有效且高效地解决了预训练T2I模型的选择难题，使用户无需穷举微调即可为目标领域选择性能最优的模型，显著提高了模型应用的效率。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [138] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

TL;DR: 提出CURE框架，通过两阶段平衡探索与利用，解决大型语言模型（LLMs）中RLVR（带有验证奖励的强化学习）训练的熵崩溃问题，显著提升数学推理能力并实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR管线中，静态初始状态采样导致模型行为确定性过高、多样性低，进而引发快速熵崩溃，阻碍LLM在长期训练中持续提升性能。

Method: 引入CURE，一个两阶段框架。第一阶段，在高熵关键词处重新生成并联合优化原始与分支轨迹，以引导模型探索新颖上下文。第二阶段，继续使用静态初始状态采样（DAPO）进行训练，以逐步加强利用。

Result: 在Qwen-2.5-Math-7B上，CURE比其他RLVR方法在六个数学基准测试中性能提升5%，在熵和准确性方面均达到最新水平。第一阶段的重生成过程相较于DAPO已展现出更好的数学推理性能并维持高熵。

Conclusion: CURE框架有效解决了RLVR训练中的熵崩溃问题，显著提升了大型语言模型在数学推理任务上的表现，并实现了熵和准确性的SOTA结果。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [139] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

TL;DR: 本文将强彩票假设（SLTH）扩展到量化网络，证明了目标离散神经网络可以被精确表示，并给出了最优的过参数化界限。


<details>
  <summary>Details</summary>
Motivation: 神经网络量化的理论理解有限。现有的强彩票假设（SLTH）主要针对连续设置，无法直接应用于量化网络，因此需要将其理论扩展到量化领域。

Method: 本研究基于Borgs等人关于数划分问题的基础性成果，推导出量化设置下随机子集和问题的新理论结果。利用这些结果，将强彩票假设（SLTH）框架扩展到有限精度（量化）网络。

Result: 在量化设置中，目标离散神经网络的对应类别可以通过剪枝被精确表示，这与之前连续SLTH工作中实现的近似不同。此外，研究还证明了初始网络所需过参数化的最优界限，该界限是目标网络精度的函数。

Conclusion: 本工作通过将强彩票假设扩展到量化领域，显著提升了对量化技术的理论理解，实现了离散网络的精确表示，并提供了关键的过参数化界限。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [140] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

TL;DR: 本文提出了一种名为zono-conformal预测的新方法，旨在解决传统共形预测计算昂贵、数据密集且难以处理多维输出的局限性。该方法利用带形集合（zonotopes）构建预测集，通过一个数据高效的线性规划即可识别，并在回归和分类任务中表现出更低的保守性，同时保持相似的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有的共形预测方法存在以下缺点：1) 计算成本高昂且数据密集，因为在校准前需要构建不确定性模型；2) 通常使用区间来表示预测集，这限制了其捕捉多维输出依赖性的能力。

Method: 引入了zono-conformal预测，该方法受区间预测模型和可达集一致性识别的启发，构建具有保证覆盖范围的预测带形（prediction zonotopes）。通过将带形不确定性集直接置于基础预测器模型中，zono-conformal预测器可以通过单一且数据高效的线性规划进行识别。该方法可应用于任意非线性基础预测器（本文侧重前馈神经网络），并适用于回归和分类任务。此外，提供了概率覆盖保证和识别数据中离群点的方法。

Result: 在大量的数值实验中，zono-conformal预测器被证明比区间预测模型和标准共形预测方法更为不保守，同时在测试数据上实现了相似的覆盖率。

Conclusion: Zono-conformal预测成功克服了现有共形预测方法的计算和数据效率问题，并提升了处理多维输出的能力。它在保持统计有效覆盖率的同时，提供了更高效和不保守的预测集，是未来不确定性量化研究的有前景方向。

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [141] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

TL;DR: 该论文定义并形式化了学习或信念更新中的“置信度”概念，将其与概率区分开，并提供了公理化定义及多种数学表示，包括将贝叶斯法则视为优化学习器的特例。


<details>
  <summary>Details</summary>
Motivation: 在学习或更新信念过程中，存在一种对输入信息的“置信度”概念，它影响信念状态，且常被误解为概率。由于该概念能统一学习率、证据权重等多个现有框架，因此有必要对其进行形式化刻画，以提升对学习机制的理解。

Method: 1. 形式化地公理化了“有置信度学习”的含义。2. 提出了两种在连续统上衡量置信度的规范方法，并证明了置信度总能以这些方式表示。3. 在特定假设下，推导了基于置信度学习的更紧凑表示，如向量场和损失函数。

Result: 1. 明确了置信度是一个不同于概率或似然的独立概念，但能涵盖学习率、证据权重等。2. 证明了置信度总能通过两种规范方法在连续统上被度量和表示。3. 导出了置信度学习的紧凑表示（向量场和损失函数），这些表示引入了复合“并行”观察的扩展语言。4. 将贝叶斯法则刻画为一种优化学习器，其损失表示为线性期望的特殊情况。

Conclusion: 该研究成功地形式化并量化了学习和信念更新中的“置信度”概念，明确了其独立性，并提供了统一的数学框架。通过将贝叶斯法则视为优化特例，该工作加深了对学习过程的理解，并为处理信息信任度提供了新视角。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [142] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

TL;DR: 本文提出了一种方法，能够在广义非正态分布（一类特殊的非高斯分布）中，通过精度矩阵推断变量的条件独立结构，并提供了一种计算高效的算法。


<details>
  <summary>Details</summary>
Motivation: 对于一般非高斯分布，协方差和精度矩阵无法像多元高斯分布那样编码变量的独立性结构，这限制了它们在独立性结构推断中的应用。

Method: 研究表明，对于一类由高斯分布经对角变换得到的非高斯分布（称为广义非正态分布），在满足特定条件下，其条件独立结构仍可从精度矩阵中推断。基于此理论，本文提出了一种简单且计算高效的算法来恢复广义非正态数据的条件独立结构。

Result: 通过合成实验和真实世界数据的应用，验证了所提出算法在恢复条件独立结构方面的有效性。

Conclusion: 本文成功将通过精度矩阵推断条件独立结构的方法扩展到了一类重要的非高斯分布，为处理非高斯数据中的独立性推理问题提供了新的理论基础和实用的算法。

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [143] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

TL;DR: 事后解释方法（LIME和SHAP）易受对抗操纵以隐藏偏见。本研究评估了增强和集成策略以提高其检测鲁棒性，发现某些配置能显著改善偏见检测。


<details>
  <summary>Details</summary>
Motivation: 尽管事后解释方法（如LIME和SHAP）有助于理解黑箱分类器，但它们易受对抗性操纵，可能掩盖模型中的有害偏见，这影响了模型偏差和泛化能力的评估。

Method: 首先，复制COMPAS实验以验证现有发现并建立基线。其次，引入一个模块化测试框架，用于系统评估不同性能分类器上的增强型和集成解释方法。最后，利用该框架评估LIME/SHAP集成配置在分布外模型上抵抗偏见隐藏的能力。

Result: 研究结果识别出能够显著改善偏见检测的LIME/SHAP集成配置。

Conclusion: 发现的有效配置具有增强高风险机器学习系统部署透明度的潜力。

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [144] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

TL;DR: 本文提出一种丰度感知的Set Transformer变体，用于微生物组样本表示，通过整合物种丰度信息，显著提高了下游分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的微生物组样本嵌入方法常忽略分类群的丰度信息，导致无法充分利用其生物学重要性，影响表型预测和环境分类等下游任务的准确性。

Method: 提出一种丰度感知的Set Transformer方法。该方法通过按序列的相对丰度复制嵌入向量，并利用自注意力机制进行聚合，在不改变模型架构的情况下构建固定大小的样本级嵌入。

Result: 该方法在真实世界的微生物组分类任务中，表现优于平均池化和未加权的Set Transformer，并在某些情况下达到了完美性能。

Conclusion: 研究结果表明，丰度感知的聚合对于构建稳健且富含生物学信息的微生物组表示至关重要。这是首次将序列级丰度整合到基于Transformer的样本嵌入中的方法之一。

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [145] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

TL;DR: 本文提出一种针对即时消息的预测编码解决方案，通过数据管理、特征选择、逻辑回归及定量特征降维，实现经济可行且性能提升的文档分类，并证明其成本效益。


<details>
  <summary>Details</summary>
Motivation: 即时消息的非正式性和小尺寸特性给法律行业的预测编码（文档分类）带来额外挑战。

Method: 采用数据管理工作流将消息分组为“日会话”，结合特征选择和逻辑回归分类器，并通过定量特征降维提升模型性能。方法在Instant Bloomberg数据集上进行测试。

Result: 研究提供了一个经济可行的预测编码解决方案，通过降维提高了基线模型性能，并展示了该方法的成本节约效果。

Conclusion: 该方法为即时消息的预测编码提供了一个经济高效的解决方案，有效应对了即时消息数据挑战，并带来了显著的成本优势。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [146] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

TL;DR: 提出一种相对优势去偏框架，通过与参照分布比较来校正观看时长，从而提高视频推荐的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 原始观看时长作为用户满意度指标，受视频时长、流行度和用户行为等混杂因素影响，导致偏见的推荐模型。

Method: 提出新颖的相对优势去偏框架，通过将观看时长与基于用户和物品组的经验参考分布进行比较来校正，生成基于分位数的偏好信号；采用两阶段架构分离分布估计与偏好学习；引入分布嵌入高效参数化观看时长分位数。

Result: 离线和在线实验均表明，该框架相较于现有基线方法，显著提升了推荐准确性和鲁棒性。

Conclusion: 该框架有效解决了原始观看时长的偏见问题，显著提升了视频推荐系统的性能。

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [147] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: 本文提出一种基于神经网络的压缩元学习框架，通过元学习编码和解码阶段，解决现有压缩学习未能充分利用数据结构、效率和准确性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 随着新数据集规模的快速增长，需要快速高效的参数学习技术。然而，现有压缩学习的编码和解码技术通常是随机且与数据无关的，未能利用数据的底层结构。

Method: 本研究提出一个“压缩元学习”（Compressive Meta-Learning）框架。该框架利用神经网络对压缩学习的编码和解码阶段进行元学习。其潜力通过多种应用进行探索，包括基于神经网络的压缩PCA、压缩岭回归、压缩k-means和自编码器。

Result: 所提出的系统比当前最先进的方法更快、更准确。

Conclusion: 压缩元学习框架通过元学习编码和解码阶段，克服了传统压缩学习的局限性，为大规模数据处理提供了更高效、更准确的参数学习方法，并具有广泛的应用前景。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [148] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

TL;DR: 提出一种多模态系统，融合临床笔记和表格数据，用于患者入院早期ICD代码预测，性能超越现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有ICD代码分配研究多集中于出院后。对患者入院早期信息进行预测，可用于识别健康风险、提供有效治疗建议及优化资源配置，尽管此时信息有限。

Method: 提出一种多模态系统，融合电子健康记录中的临床笔记和表格事件。该模型整合了预训练编码器、特征池化和跨模态注意力机制以学习跨模态最优表示；并引入了一种加权时间损失函数。

Result: 实验证明，所提出的多模态融合及损失函数策略显著增强了早期预测模型，并超越了当前最先进的系统。

Conclusion: 本研究通过多模态数据融合和创新的模型设计（包括加权时间损失），有效提升了ICD代码的早期预测能力，为医疗决策提供了更及时准确的支持。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [149] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

TL;DR: 针对时尚推荐中搭配兼容性与个性化推荐的挑战，本文提出FGAT框架，通过分层图神经网络和注意力机制融合多模态特征，同时建模用户偏好与搭配兼容性，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 时尚产业快速发展和商品种类增多，用户难以在电商平台找到兼容商品。现有时尚推荐系统常独立处理搭配兼容性和个性化推荐，忽略了商品间及用户偏好间的复杂交互，导致推荐效果不佳。

Method: 本文提出FGAT框架，受HFGN模型启发，利用图神经网络和图注意力机制。该框架构建用户、搭配、商品三层分层图，集成视觉和文本特征，同时建模搭配兼容性和用户偏好。图注意力机制动态加权节点重要性，捕捉关键交互。

Result: 在POG数据集上评估，FGAT优于HFGN等基线模型，在精确率、HR、召回率、NDCG和准确率方面均取得了改进。

Conclusion: 结合多模态（视觉-文本）特征、分层图结构和注意力机制，能显著提高个性化时尚推荐系统的准确性和效率。

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [150] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

TL;DR: 本文从优化和统计角度深入研究了分段仿射正则化（PAR）在监督学习中实现量化的理论基础，包括临界点特性、计算方法和统计保证。


<details>
  <summary>Details</summary>
Motivation: 离散或量化变量的优化问题由于其组合性质而极具挑战性。分段仿射正则化（PAR）提供了一个灵活的基于连续优化的量化建模和计算框架，但其理论基础有待深入探讨。

Method: 1. 理论分析了在过参数化状态下，PAR正则化损失函数的临界点行为。2. 推导了多种（凸、拟凸和非凸）PAR的闭式近端映射，并展示了如何利用近端梯度法（及其加速变体）和交替方向乘子法求解PAR正则化问题。3. 研究了PAR正则化线性回归问题的统计保证，并将其与经典正则化（如L1、平方L2、非凸）进行比较。

Result: 1. 在过参数化状态下，PAR正则化损失函数的每个临界点都表现出高度量化。2. 成功推导了PAR的闭式近端映射，从而能够使用多种梯度下降和ADMM方法高效求解相关问题。3. 证明了PAR能够近似经典正则化（如L1、L2平方、非凸），并获得具有量化解的相似统计保证。

Conclusion: 分段仿射正则化（PAR）是解决离散/量化变量优化问题的有效框架。它在过参数化状态下能自发地产生高度量化解，提供了高效的计算方法，并且在统计上能够实现与传统正则化方法相当甚至更好的性能，同时获得量化解。

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [151] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

TL;DR: 本文提出CTRL元学习方法，解决多源异构数据中机器学习预测需同时兼顾总体准确性与源级别差异的挑战，并在多个大型数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 机器学习任务常处理来自多个不同来源的大规模数据，不仅需要高整体准确性，还需确保预测在各来源内的可靠性并保留来源间差异。然而，数据源众多、分布偏移和样本量差异大等特点为实现此目标带来了挑战，尤其是在难民安置等需为众多小型来源提供差异化预测的实际应用中。

Method: 本文提出了一种元学习方法——聚类迁移残差学习（Clustered Transfer Residual Learning, CTRL）。该方法结合了跨域残差学习和自适应池化/聚类的优势，旨在同时提高总体准确性并保留源级别异构性。研究还提供了理论结果，阐明了其目标如何平衡数据数量和数据质量。

Result: CTRL在5个大型数据集（包括一个来自瑞士国家庇护项目的数据集）上与其他最先进的基准方法进行了评估。结果表明，CTRL在使用不同基础学习器时，在多个关键指标上始终优于这些基准方法。

Conclusion: CTRL是一种有效且性能卓越的元学习方法，成功解决了多源异构数据预测中兼顾整体准确性和源级别差异的复杂问题，并在实际应用场景中得到了验证。

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [152] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

TL;DR: 本文提出一种名为NeuralKDB的新型贝叶斯网络分类器，通过学习特征值的分布表示来建模高阶特征依赖，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯网络分类器虽高效且可解释性强，但因参数爆炸和数据稀疏，难以建模高阶特征依赖，导致在复杂真实世界数据上的概率外推能力不足。

Method: 提出一种通过学习特征值分布表示（借鉴词嵌入和图表示学习）来设计高阶贝叶斯网络分类器的新范式。具体实现是，将K-依赖贝叶斯分类器（KDB）扩展为神经版本NeuralKDB，设计新的神经网络架构学习特征值分布表示并参数化条件概率，并采用随机梯度下降算法高效训练模型。

Result: 在60个UCI数据集上的大量分类实验表明，所提出的NeuralKDB分类器在捕获高阶特征依赖方面表现出色，并显著优于传统的贝叶斯网络分类器以及其他有竞争力的分类器（包括未进行分布表示学习的神经网络分类器）。

Conclusion: 通过引入分布表示学习，NeuralKDB成功解决了传统贝叶斯网络分类器在处理高阶特征依赖方面的局限性，为复杂表格数据分类提供了更优的解决方案。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [153] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

TL;DR: 本研究深入探讨了物联网多模态在线联邦学习（MMO-FL）中模态数量和质量不平衡（QQI）对学习性能的影响，并提出了一种基于原型学习的QQR算法以有效解决此问题，实验证明其在不平衡条件下优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 物联网生态系统产生海量多模态数据，随着边缘智能的发展，IoT设备需支持分布式和在线学习（MMO-FL）。然而，IoT设备固有的不稳定性导致数据收集中存在模态数量和质量不平衡（QQI），这对MMO-FL带来了新的挑战。

Method: 本研究首先系统性地调查了QQI在MMO-FL框架中的影响，并进行了全面的理论分析以量化两种不平衡如何降低学习性能。为解决这些挑战，提出了一种名为“模态数量和质量再平衡”（QQR）的算法，该算法是基于原型学习的方法，与训练过程并行运行。

Result: 在两个真实世界的多模态数据集上进行的广泛实验表明，所提出的QQR算法在模态不平衡条件下始终优于基准方法，并展现出良好的学习性能。

Conclusion: QQR算法能有效应对MMO-FL中由IoT设备不稳定性导致的模态数量和质量不平衡问题，显著提升了该框架下的学习表现。

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [154] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

TL;DR: 提出一种半监督生成模型，整合有标签数据的信息瓶颈原理和无标签数据似然最大化，并增强跨视图互信息，以有效处理多视图数据中视图缺失和标签有限的问题，提升预测与插补性能。


<details>
  <summary>Details</summary>
Motivation: 多视图学习在实际应用中常遭遇视图缺失和标签缺失问题。现有基于信息瓶颈（IB）的方法虽能处理视图缺失，但本质上是全监督的，无法利用大量无标签数据。因此，亟需一个能同时利用有标签和无标签样本的统一框架。

Method: 本研究提出一个半监督生成模型。该方法通过最大化无标签样本的似然来学习一个与有标签数据上基于信息瓶颈（IB）原理共享的潜在空间。同时，在潜在空间中执行跨视图互信息最大化，以增强视图间共享信息的提取。

Result: 与现有方法相比，该模型在图像和多组学数据上，于视图缺失和标签样本有限的情境下，取得了更好的预测和插补性能。

Conclusion: 所提出的半监督生成模型通过在统一框架下有效利用有标签和无标签数据，成功应对了多视图学习中视图缺失和标签有限的挑战，显著提升了模型的预测和插补能力。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [155] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

TL;DR: 提出QBM-VAE混合量子-经典架构，利用量子处理器实现玻尔兹曼分布先验，在复杂生物数据（如单细胞组学）分析中显著优于传统高斯模型，展现了深度学习中的实际量子优势。


<details>
  <summary>Details</summary>
Motivation: 现有概率深度学习模型过度依赖高斯先验，难以捕获复杂非高斯自然数据（特别是生物数据），限制了科学发现。玻尔兹曼分布虽更具表达力但经典计算不可行，而现有量子方法受限于量子比特规模和稳定性。

Method: 开发了量子玻尔兹曼机-变分自编码器（QBM-VAE），一种大规模、长时间稳定的混合量子-经典架构，利用量子处理器高效采样玻尔兹曼分布，并将其作为深度生成模型的强大先验。

Result: QBM-VAE在百万级单细胞数据集上应用时，生成的潜在空间能更好地保留复杂的生物结构，并在组学数据整合、细胞类型分类和轨迹推断等关键任务中持续超越传统高斯模型（VAE和SCVI）。此外，它还展示了将物理先验引入深度学习以突破数据限制、驱动科学发现能力的潜力。

Conclusion: 本工作在大规模科学问题上首次展示了深度学习中的实用量子优势，并为混合量子AI模型的开发提供了可借鉴的蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [156] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

TL;DR: 本文提出一种基于调制的元学习框架，使结构保持动力学模型能有效泛化到未知参数系统，无需显式参数知识或重复训练，同时保持物理约束。


<details>
  <summary>Details</summary>
Motivation: 现有结构保持动力学模型通常针对固定系统配置训练，需要明确的系统参数知识和在新参数下的昂贵再训练，这在多查询或参数可变场景中是主要限制。现有元学习方法（如基于优化的方法）常面临训练不稳定或泛化能力有限的问题。

Method: 引入一种基于调制的元学习框架，该框架通过将结构保持模型直接条件化于潜在的系统参数紧凑表示上，避免了灰箱系统知识和适应阶段的显式优化。通过对参数化能量守恒和耗散系统应用新颖的调制策略，实现了跨参数族动力学系统的可扩展和可泛化学习。

Result: 在标准基准问题上的实验表明，该方法在少样本学习设置中实现了准确预测，且未损害动力学稳定性所需的关键物理约束，展现了在参数空间中有效的泛化性能。

Conclusion: 本方法提供了一种在参数化动力学系统上进行可扩展和可泛化学习的有效途径，成功克服了现有结构保持模型在参数变化场景中的局限性，同时确保了物理约束的保持。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [157] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

TL;DR: 本研究旨在提升儿童早期风险评估的准确性，提出了名为BFF的对比多模态框架，通过利用后期数据隐式监督早期学习，显著改善了早期预测性能。


<details>
  <summary>Details</summary>
Motivation: 儿童风险评估通常分多阶段进行，后期评估虽更精确，但临床上迫切需要尽早获得可靠的风险评估。因此，本研究旨在提高早期风险评估的预测性能。

Method: 提出“Borrowing From the Future (BFF)”对比多模态框架。该框架将每个时间窗口视为独立的模态，在训练时利用所有可用阶段的数据，但评估时仅使用最新信息。其对比机制允许模型从后期阶段“借用”信息信号，以隐式监督早期阶段的学习。

Result: 在两项真实的儿童疾病结果预测任务中验证了BFF，结果显示它持续改善了早期风险评估的性能。

Conclusion: BFF框架通过有效利用多阶段数据，显著提升了儿童早期风险评估的准确性，证明了从未来阶段“借用”信息来指导早期学习的有效性。

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [158] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

TL;DR: 论文运用因果抽象理论，探讨系统如何通过表征实现计算，并结合深度学习讨论其在泛化和预测中的作用。


<details>
  <summary>Details</summary>
Motivation: 认知行为的解释常涉及对表征的计算。本研究旨在探讨一个系统如何在其内部合适的表征载体上实现特定计算，并重新审视计算实现和表征之间的关系。

Method: 论文提出使用因果语言，特别是因果抽象理论，来理解计算实现。通过分析深度学习中人工神经网络的当前讨论，并结合计算哲学和认知科学的经典主题进行论证。

Result: 论文提供了一个基于因果抽象的计算实现解释框架，并在此框架下阐明了表征的作用。研究指出，这些问题与系统的泛化和预测能力密切相关，并应在此背景下进行探讨。

Conclusion: 因果抽象理论为理解系统如何通过表征实现计算提供了富有成效的视角。将这些概念与深度学习和经典哲学主题联系起来，强调了泛化和预测在探索计算实现和表征问题中的关键作用。

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [159] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

TL;DR: 该研究提出一种混合CNN-LSTM模型，用于北京地区多变量时间序列数据的PM2.5浓度预测，该模型在预测6小时平均PM2.5浓度上表现出高准确性（RMSE 5.236），优于传统模型，但计算资源需求较高。


<details>
  <summary>Details</summary>
Motivation: 随着全球气候变化的加剧，准确预测PM2.5浓度等空气质量指标对于环境保护、公共健康和城市管理日益重要。

Method: 提出一种基于混合CNN-LSTM架构的PM2.5指数预测模型。该模型结合了CNN的空间特征提取能力和LSTM的时间序列依赖建模能力。模型使用2010年至2015年北京某工业区多变量（PM2.5、温度、露点、压力、风向、风速、降水）小时数据集，预测6小时平均PM2.5浓度。

Result: 实验结果显示，该模型预测PM2.5的均方根误差（RMSE）为5.236，在准确性和泛化能力上均优于传统时间序列模型，展现了在空气污染预警系统等实际应用中的巨大潜力。

Conclusion: 该混合CNN-LSTM模型在PM2.5预测方面表现出色，具有实际应用价值。然而，由于多变量输入的复杂性，模型对计算资源要求较高，且处理多样大气因素的能力仍需优化。未来的工作将侧重于增强模型的可扩展性，并拓展其在更复杂多变量气象预测任务中的应用。

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [160] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

TL;DR: 一种增强的交互式投票地图匹配算法，能高效处理不同采样率轨迹并高精度重建GPS轨迹。


<details>
  <summary>Details</summary>
Motivation: 旨在无论输入数据质量如何，都能高精度地重建GPS轨迹，并扩展现有地图匹配算法的适用性。

Method: 在原交互式投票地图匹配算法基础上，集成轨迹插补，引入距离限制的交互式投票策略以降低计算复杂度，修改以处理路网中缺失数据，并整合OpenStreetMap数据以支持更广泛的地理区域。

Result: 该增强算法能高效处理不同采样率的轨迹，高精度重建GPS轨迹，且在保持原算法核心优势的同时，显著拓宽了其在多样化真实世界场景中的适用性。

Conclusion: 这些改进在保留原算法优点的同时，极大地扩展了其在不同实际应用场景中的适用性。

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [161] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 本文提出GODNF，一种基于广义意见动力学的图神经网络框架，旨在克服现有扩散式GNN在适应性、深度和理论理解方面的局限性，并在多项任务中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式图神经网络存在三大局限：1) 依赖同质静态扩散，适应性差；2) 深度受计算开销和可解释性限制；3) 收敛行为缺乏足够的理论理解。

Method: 提出GODNF（广义意见动力学神经框架），它将多种意见动力学模型统一为可训练的扩散机制。该框架通过节点特定行为建模和动态邻域影响，捕捉异构扩散模式和时间动态，并确保深层消息传播的效率和可解释性。此外，提供了关于GODNF建模多样收敛配置能力的严格理论分析。

Result: 在节点分类和影响估计任务上的广泛实证评估证实，GODNF优于现有最先进的图神经网络。

Conclusion: GODNF成功解决了现有扩散式GNN的关键挑战，提供了一种能够处理异构扩散模式、支持深层传播且具有坚实理论基础的通用框架，并在实践中表现出色。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [162] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

TL;DR: 针对无法微调的闭源大语言模型，提出一种基于提示（prompting）的框架，通过将LLM作为特征提取器，实现公平分类。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLMs）日益广泛应用于高风险场景时，确保其公平性至关重要。然而，现有用于LLM分类器的公平性方法（如模型微调或头调）不适用于在上下文学习设置下的闭源LLMs（如GPT-4、Gemini、Claude），这些模型通常权重不可修改。

Method: 本文提出一个基于提示的框架，用于从闭源LLM中推导公平分类器。该方法将LLM视为特征提取器，通过为特定公平标准策略性设计的提示，从LLM的概率预测（例如，token对数概率）中提取特征。随后，将公平算法应用于这些提取出的特征，以事后方式训练一个轻量级公平分类器。

Result: 在五个数据集（包括三个表格数据集）上的实验表明，该框架从开源和闭源LLM中推导出的分类器在准确性和公平性之间取得了良好的权衡。该框架尤其数据高效，并且性能优于在LLM嵌入上训练的公平分类器（即head-tuning）或从原始表格特征从头训练的公平分类器。

Conclusion: 该框架为闭源LLM在上下文学习设置下的公平分类问题提供了一种有效且数据高效的解决方案，填补了现有方法无法应用的空白，并展现出优越的性能和数据效率。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [163] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

TL;DR: 脉冲神经网络（SNNs）的对抗鲁棒性未被充分理解。本文提出RTE框架，通过时序自集成提升SNNs的鲁棒性，有效应对其时序子网络的脆弱性及对抗漏洞的时间迁移性，并在实验中展现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNNs）在能效和类脑计算方面潜力巨大，但其对抗扰动的脆弱性尚未被深入理解。研究发现，SNNs存在个体时序子网络的脆弱性以及对抗漏洞在时间维度上的可迁移性这两个未被充分探索的挑战。

Method: 提出“鲁棒时序自集成（Robust Temporal self-Ensemble, RTE）”训练框架。该框架将网络视为跨离散时间步演化的子网络集合，旨在提高每个子网络的鲁棒性，同时减少对抗扰动在时间上的可迁移性。RTE将这两个目标整合到统一的损失函数中，并采用随机采样策略进行高效优化。

Result: 广泛的实验表明，RTE在多个基准测试中，其鲁棒性-准确性权衡始终优于现有训练方法。额外分析揭示，RTE重塑了SNNs的内部鲁棒性格局，形成了更具弹性且时序多样化的决策边界。

Conclusion: 本研究强调了时序结构在对抗性学习中的重要性，并为构建鲁棒的脉冲模型提供了原理性基础。

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [164] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: 现有图预训练和提示微调方法难以处理异质图谱分布。本文提出HS-GPPT模型，通过确保预训练和提示微调过程中的谱对齐，有效提升了在不同同配性图上的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图预训练和提示微调方法依赖基于同配性的低频知识，无法处理真实世界图中多样的谱分布。理论分析揭示，最佳知识迁移要求预训练谱滤波器与下游图的内在谱对齐，而有限监督下预训练与下游任务间的巨大谱间隙会阻碍有效适应。

Method: 提出HS-GPPT模型，一个在预训练和提示微调全程确保谱对齐的新颖框架。该方法采用混合谱滤波器骨干和局部-全局对比学习来获取丰富的谱知识，并设计提示图来将谱分布与预训练目标对齐，以促进跨同配性和异配性的谱知识迁移。

Result: 广泛的实验验证了所提方法在转导式和归纳式学习设置下的有效性。

Conclusion: HS-GPPT模型通过实现预训练与提示微调中的谱对齐，有效解决了现有方法在处理多样谱分布图上的局限性，显著提升了知识迁移性能。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [165] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

TL;DR: 本文提出RegimeNAS，一种新型可微分架构搜索框架，通过显式整合市场机制感知能力，显著提升了加密货币交易性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在高度动态的金融环境中（如加密货币交易）存在局限性，难以适应不断变化的市场条件。研究旨在开发一种能感知并适应不同市场机制的鲁棒模型。

Method: RegimeNAS是一个可微分的架构搜索框架，包含三项核心创新：1) 具有可证明收敛性的贝叶斯搜索空间；2) 专为不同市场条件设计的动态激活神经模块（波动、趋势、区间块）；3) 结合市场特定惩罚（如波动匹配、平滑过渡）和数学强制Lipschitz稳定性约束的多目标损失函数。市场机制识别通过多头注意力机制跨多时间框架实现。

Result: 在大量真实加密货币数据上的严格实证评估表明，RegimeNAS显著优于现有基准，与最佳传统循环基线相比，平均绝对误差降低了80.3%，并显着加快了收敛速度（9个vs. 50+个epochs）。消融研究证实了各组件，特别是机制感知适应机制的关键贡献。

Conclusion: 本研究强调了将市场机制等领域特定知识直接嵌入到NAS过程中对于开发鲁棒、自适应金融应用模型的必要性。

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [166] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

TL;DR: 现有CP方法在长尾分布中存在覆盖不平衡问题，少数类常被欠覆盖。本文提出TACP和sTACP方法来缩小头尾类覆盖差距，提升平衡性。


<details>
  <summary>Details</summary>
Motivation: 现有保形预测(CP)方法在长尾标签分布下，尽管能保证边际覆盖率，但常导致类间覆盖率不平衡，头部类被过度覆盖，尾部（少数）类则被欠覆盖，严重影响了对少数类预测集的可靠性。

Method: 提出尾部感知保形预测(TACP)方法，利用长尾结构减轻尾部类别的欠覆盖问题并缩小头尾覆盖差距。为进一步提升所有类别的覆盖平衡性，通过重加权机制引入了TACP的扩展——软TACP (sTACP)。

Result: 理论分析表明TACP能比标准方法持续实现更小的头尾覆盖差距。在多个长尾基准数据集上的实验证明了所提方法的有效性。

Conclusion: 本文提出的TACP和sTACP方法能有效缓解长尾标签分布下现有保形预测方法类间覆盖不平衡的问题，显著缩小头尾覆盖差距，从而提升了预测集对少数类别的可靠性。

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [167] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

TL;DR: 本文提出NeMo，一种可扩展且通用的深度神经网络（DNN）模块化训练（MwT）方法，通过在神经元级别应用对比学习，有效解决了现有MwT方法在大型和多样化模型（如Transformer）上的局限性，显著提高了模块分类精度并减少了模块尺寸。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络模型在现代软件系统中的广泛应用，其高昂的构建成本成为巨大挑战。模型重用虽能降低训练成本，但整体重用可能导致显著的推理开销。DNN模块化通过分解模型实现模块重用。然而，现有的训练时模块化（MwT）方法主要针对小型CNN模型且在卷积核级别操作，难以适用于多样化和大规模模型，特别是基于Transformer的模型。

Method: 我们提出了NeMo，一种可扩展且通用的MwT方法。NeMo在神经元级别（所有DNN共享的基础组件）进行操作，确保其适用于Transformer及各种架构。我们设计了一种基于对比学习的模块化训练方法，并结合了有效的复合损失函数，以实现对大规模模型的可扩展性。

Result: 通过在两个基于Transformer的模型和四个CNN模型上，跨两个分类数据集进行的综合实验表明，NeMo优于现有最先进的MwT方法。结果显示，模块分类准确率平均提升1.72%，模块尺寸平均减小58.10%，证明了其在CNN和大规模Transformer模型上的有效性。对开源项目的案例研究也展示了NeMo在实际场景中的潜在益处。

Conclusion: NeMo提供了一种有前景的方法，实现了可扩展和通用的DNN模块化，有效克服了现有MwT方法在处理多样化和大型模型时的局限性。

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [168] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

TL;DR: 本研究通过整合卫星图像和项目元数据，构建了一个全球造林与再造林数据集，并揭示了现有碳汇项目地理位置数据的普遍可靠性问题，提出了LDIS指标以增强问责制并提供训练数据。


<details>
  <summary>Details</summary>
Motivation: 目前的造林和再造林项目在碳固存效益报告上存在自我报告、外部验证不足的问题，导致数据可靠性和项目完整性受到质疑。为应对自愿碳市场日益增加的审查，急需提高数据透明度和准确性。

Method: 本研究编译了一个包含1,289,068个种植点和45,628个项目的全球造林与再造林数据集，涵盖33年。该数据集整合了原始元信息、时间序列卫星图像（如Sentinel-2和Planetscope）及其他辅助数据。研究引入了“位置数据完整性得分”（LDIS），对所提供的场地级位置信息进行标准化评估。

Result: 结果显示，约79%的已地理参考种植点在LDIS的至少一项指标上存在缺陷，而15%的受监测项目最初就缺乏机器可读的地理参考数据。

Conclusion: 所建立的数据集不仅有助于提高自愿碳市场的问责制，而且其关联的数百万张卫星图像也为计算机视觉等任务提供了宝贵的训练数据。

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [169] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

TL;DR: 针对不平衡数据流问题，本文提出了一种名为和谐梯度下降（HGD）的新算法。HGD通过均衡不同类别梯度范数来缓解少数类欠拟合，实现平衡在线学习，且无需额外参数或数据缓冲，适用于任何基于梯度下降的模型。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的数据流常呈现类别不平衡，导致少数类易出现欠拟合问题。尽管现有方法（如重采样和重加权）已有所探索，但仍存在改进空间。

Method: 本文通过训练修改，特别是聚焦于梯度下降技术来解决不平衡问题。具体引入了和谐梯度下降（HGD）算法，其目标是均衡不同类别梯度的范数。HGD无需数据缓冲区、额外参数或先验知识，可应用于任何使用梯度下降进行优化的学习模型。

Result: 理论分析表明HGD能实现满意的次线性后悔界限。与常用在线不平衡学习方法在多种场景下的广泛实验评估表明，HGD在学习不平衡数据流方面表现出高效性和有效性。

Conclusion: HGD算法成功地通过均衡梯度范数解决了不平衡数据流学习中的少数类欠拟合问题，实现了平衡的在线学习。其简化的实现过程和广泛的适用性使其成为处理不平衡数据流的有效方法。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [170] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

TL;DR: 本文提出了一种基于熵的机制（ETMR和EAR）来改进测试时强化学习（TTRL），以平衡大型语言模型（LLM）在无监督推理任务中的探索与利用，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂推理任务中仍依赖标注数据，在无监督场景下适应性有限。TTRL虽能自优化，但存在推理成本高昂、早期估计偏差导致过自信、输出多样性不足及性能平台期等挑战。

Method: 引入基于熵的机制，通过两种策略增强测试时强化学习的探索-利用平衡：熵分叉树多数回滚（Entropy-fork Tree Majority Rollout, ETMR）和基于熵的优势重塑（Entropy-based Advantage Reshaping, EAR）。

Result: 在AIME 2024基准测试中，使用Llama3.1-8B模型，Pass@1指标相对提升68%，同时仅消耗60%的回滚token预算。这表明该方法有效平衡了推理效率、多样性和估计鲁棒性。

Conclusion: 该方法通过优化推断效率、多样性和估计鲁棒性之间的权衡，有效推动了开放域推理任务中的无监督强化学习发展。

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [171] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

TL;DR: 本文提出PTSM框架，通过解耦个性化和共享神经模式，实现无需校准的鲁棒跨受试者EEG解码。


<details>
  <summary>Details</summary>
Motivation: 跨受试者脑电图（EEG）解码是脑机接口（BCI）研究中的一大挑战，主要源于个体间显著的差异性和受试者不变表示的稀缺性。

Method: 该研究提出PTSM（生理学感知和任务不变时空建模）框架。它采用双分支掩蔽机制独立学习个性化和共享时空模式，并对掩码进行时空因子分解。为解决表示纠缠问题，PTSM通过信息论约束将潜在嵌入分解为正交的任务相关和受试者相关子空间。模型通过结合分类、对比和解耦目标的端到端多目标损失进行训练。

Result: 在跨受试者运动想象数据集上的大量实验表明，PTSM实现了强大的零样本泛化能力，且无需受试者特异性校准，性能优于现有最先进的基线方法。

Conclusion: 研究结果强调了解耦神经表征在非平稳神经生理环境下实现个性化和可迁移解码的有效性。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [172] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

TL;DR: Dual-Feedback Actor (DFA)是一种新型强化学习算法，能将个体奖励和成对偏好融合到单一更新规则中，通过直接利用策略的对数概率进行偏好建模，避免了独立的奖励建模。理论上证明DFA可恢复SAC策略，并在模拟环境中展示出超越或媲美SAC及RLHF基线的性能和更稳定的训练过程。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习算法通常依赖于精确的个体奖励，但在许多实际场景中，获取高质量的奖励信号可能很困难，而偏好信息（如人类反馈）则相对易于收集。本研究旨在开发一种能有效融合这两种反馈形式的强化学习算法，以提高训练效率和性能，尤其是在奖励稀疏或需要利用人类偏好的情况下。

Method: 1. 提出了Dual-Feedback Actor (DFA) 强化学习算法，该算法将个体奖励和成对偏好（如果可用）融合到单一更新规则中。 2. DFA直接使用策略的对数概率来建模偏好概率，从而避免了单独的奖励建模步骤。 3. 偏好数据可以由人工标注提供（状态级或轨迹级），也可以从离策略重放缓冲区中存储的Q值在线合成。 4. 在Bradley-Terry模型下，理论证明最小化DFA的偏好损失可以恢复熵正则化的Soft Actor-Critic (SAC) 策略。

Result: 1. 在六个控制环境中，DFA在生成偏好上进行训练，其性能与SAC相当或优于SAC，并表现出更稳定的训练过程。 2. 在随机GridWorld中，仅使用Bradley-Terry模型下的半合成偏好数据集，DFA算法优于奖励建模的强化学习人类反馈 (RLHF) 基线。 3. DFA的性能接近使用真实奖励的“预言家”性能。

Conclusion: DFA是一种有效且稳定的强化学习算法，能够成功融合个体奖励和成对偏好。通过直接建模偏好概率，它简化了训练流程，并在理论上与SAC建立了联系。实验结果表明，DFA在多种环境下均能达到或超越现有基线，尤其在处理偏好数据方面展现出显著优势，为利用多样化反馈信息进行强化学习提供了一条有前景的路径。

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [173] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

TL;DR: 决策聚焦学习（DFL）在处理线性规划（LP）时常遇梯度为零问题。本文指出平滑LP仍无法解决此问题，并提出即使使用可微优化层，也应最小化代理损失。实验表明，此方法能使可微层取得良好性能，结合DYS-Net可显著缩短训练时间并保持先进的决策质量。


<details>
  <summary>Details</summary>
Motivation: 决策聚焦学习（DFL）旨在直接优化决策质量，但对于线性规划（LP）等问题，其关键的梯度在参数空间中几乎处处为零，导致梯度下降法失效。现有平滑LP的方法被发现无法有效解决这一梯度消失问题。

Method: 本文首先指出并证明了现有通过添加二次正则项平滑LP以实现可微性的方法，仍会因遗憾在参数空间大片区域内保持不变而导致梯度为零。为解决此问题，作者提出并实验验证了即使在使用可微优化层且可以直接最小化遗憾的情况下，也应最小化代理损失（surrogate losses）。该方法进一步应用于DYS-Net，一个高效的LP可微优化技术。

Result: 研究结果表明，最小化代理损失的方法使得可微优化层能够实现与传统基于代理损失的DFL方法相当或更优的决策遗憾。此外，将此策略应用于DYS-Net，不仅能达到与最先进技术相当的遗憾（决策质量），还能显著减少模型训练时间。

Conclusion: 即使在可微优化层可用时，通过最小化代理损失，可以有效解决DFL中线性规划的梯度消失问题，从而提升决策质量。当与DYS-Net等高效可微优化技术结合时，该方法还能在保持高性能的同时，大幅提高训练效率，为DFL的实际应用提供了新的有效途径。

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [174] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

TL;DR: 针对图神经网络在处理高阶交互和长距离信息传递中的“过挤压”问题，本文提出一种基于Forman-Ricci曲率的结构提升策略，以改善信息传递效率。


<details>
  <summary>Details</summary>
Motivation: 图神经网络虽擅长处理关系数据，但在面对真实世界中复杂的、高阶的拓扑结构时，以及长距离信息传递可能导致的信息失真和“过挤压”问题，仍面临挑战。几何和拓扑深度学习中的“提升”概念为此提供了解决方案的潜力。

Method: 本文提出一种结构提升策略，利用基于黎曼几何的Forman-Ricci曲率来定义基于边的网络特性。该曲率揭示了图的局部和全局属性，特别是网络的骨干结构，这些骨干被表示为超边，以更好地建模社群间跨距离的信息流。

Result: 该方法有效缓解了图学习中在长距离信息传递和图瓶颈处出现的信息失真和“过挤压”问题。

Conclusion: 通过使用Forman-Ricci曲率进行结构提升，本研究为改善图神经网络在复杂高阶网络中处理长距离信息传递时的效率和准确性提供了有效方案，成功缓解了过挤压现象。

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [175] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: 本文提出CHORD框架，通过将SFT作为RL中的动态加权辅助目标，并利用双重控制机制，有效融合离线专家数据与在线策略探索，解决了现有SFT与RL结合中模式破坏和过拟合问题，实现了LLM的稳定高效学习与性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有整合监督微调（SFT）和强化学习（RL）的方法，在改进大型语言模型（LLMs）能力和对齐行为时，面临破坏既有模型模式和对专家数据过拟合的风险。

Method: 提出了CHORD框架，将SFT重构为在线策略RL过程中的一个动态加权辅助目标。CHORD引入了双重控制机制：首先，一个全局系数用于整体引导从离线策略模仿到在线策略探索的过渡；其次，一个逐词元加权函数实现从专家词元的细粒度学习，同时保持在线策略探索并减轻离线数据的影响。

Result: 在广泛使用的基准测试中，CHORD展示了稳定高效的学习过程。通过有效协调离线专家数据与在线策略探索，CHORD取得了比基线方法显著的性能提升。

Conclusion: CHORD框架通过有效调和离线专家数据与在线策略探索，为大型语言模型提供了一个稳定、高效的学习过程，并显著提升了模型的性能。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [176] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

TL;DR: 提出LEAD框架，在共享潜在空间中协同优化抗体序列和结构，显著提高了CDR优化效率和性能，尤其适用于不可微分评估器。


<details>
  <summary>Details</summary>
Motivation: 现有抗体互补决定区（CDR）优化方法在原始数据空间操作，导致评估成本高昂且搜索过程效率低下。

Method: 提出LatEnt blAck-box Design (LEAD)框架，在序列和结构共有的潜在空间中进行协同优化。设计了黑盒指导策略，以适应属性评估器不可微分的现实场景。

Result: LEAD在单属性和多属性目标优化上均表现出卓越性能。相比基线方法，LEAD在超越其优化性能的同时，将查询消耗减少了一半。

Conclusion: LEAD通过在共享潜在空间进行协同优化，有效解决了现有抗体CDR优化方法的局限性，显著提升了优化效率和性能。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [177] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

TL;DR: 本文利用收缩理论并引入相应的正则化项，以提高卷积神经常微分方程（NODEs）对输入噪声和对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络容易受到输入噪声和对抗攻击的影响，表现出脆弱性。

Method: 1. 提出将收缩理论应用于卷积神经常微分方程（NODEs）来增强其鲁棒性。2. 通过在训练中使用涉及系统动力学雅可比矩阵的正则化项来诱导收缩性。3. 为减少计算负担，对于具有斜率受限激活函数的一类NODEs，还提出使用精选的权重正则化项来促进收缩性。

Result: 所提出的正则化方法在MNIST和FashionMNIST数据集上的基准图像分类任务中得到了验证，尤其是在图像受到不同类型噪声和攻击破坏的情况下，展示了其有效性。

Conclusion: 将收缩理论应用于卷积神经常微分方程并结合适当的正则化策略，能够有效提升神经网络在噪声和对抗攻击下的鲁棒性。

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [178] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: mCOCO是一个基于储层计算（RC）的新颖框架，用于从BOLD信号中学习具有认知能力的连接脑模板（CBT），解决了现有方法的解释性差、计算成本高和忽视认知能力的问题。


<details>
  <summary>Details</summary>
Motivation: 生成连接脑模板（CBT）对于识别个体共享的连接模式至关重要，但现有方法（如传统机器学习和图神经网络GNN）存在局限性：(i) 黑箱性质导致解释性差，(ii) 计算成本高，(iii) 仅关注结构和拓扑，忽视了所生成CBT的认知能力。

Method: 引入mCOCO（多感官认知计算）框架，利用储层计算（RC）从BOLD信号中学习群体水平的功能CBT。mCOCO分为两阶段：1) 将BOLD信号映射到储层以推导个体功能连接组，并聚合成群体级CBT；2) 通过认知储层整合多感官输入（如文本、音频、视觉数据），使CBT具备认知特性，同时保持计算效率。

Result: 广泛评估表明，基于mCOCO的模板在中心性、区分性、拓扑健全性和多感官记忆保留方面显著优于基于GNN的CBT。

Conclusion: mCOCO框架成功地解决了现有CBT学习方法的局限性，通过整合储层计算和多感官输入，生成了更具解释性、计算效率更高且具备认知能力的连接脑模板，为功能连接研究提供了新范式。

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [179] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

TL;DR: 研究表明，许多流行的机器学习事后解释算法对复杂模型并非信息丰富，并提出了一个基于学习理论的框架来定义“信息丰富”的解释，揭示了算法成为信息丰富所需的严格条件。


<details>
  <summary>Details</summary>
Motivation: 尽管研究人员认为事后解释算法能提供复杂机器学习模型的行为洞察，但其理论保证仅限于简单决策函数。目前尚不清楚这些算法在何种假设下对复杂模型依然有效，因此需要一个严格的框架来评估解释的有效性。

Method: 引入了一个通用的、基于学习理论的框架，用以定义解释如何为决策函数提供信息。该框架将“信息丰富”的解释定义为能够减少合理决策函数空间复杂度的解释。

Result: 通过该方法，研究发现许多流行的解释算法在应用于复杂决策函数时并非信息丰富，从而从数学上驳斥了任何模型都能被解释的观点。论文还推导出了不同解释算法变得信息丰富的条件，这些条件往往比预期更为严格（例如，梯度解释和反事实解释对可微函数空间而言是非信息丰富的，SHAP和锚点解释对决策树空间而言是非信息丰富的）。

Conclusion: 尽管分析是数学性的，但它对解释算法的实际适用性具有重大影响，特别是在人工智能的审计、监管和高风险应用中。研究结果为如何修改解释算法以使其更具信息性提供了方向，强调了在实践中应用这些算法时需要更为谨慎。

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [180] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

TL;DR: 本研究评估了六种概率机器学习算法在合成分类数据集上进行不确定性量化的表现，发现所有算法均校准良好，但深度学习算法在离分布数据上的不确定性表现不一致。


<details>
  <summary>Details</summary>
Motivation: 科学发现的有效性依赖于严格的统计方法和不确定性量化。然而，随着深度学习等复杂数据模型的出现，不确定性量化变得极其困难，尽管有多种技术被提出，但其定性性质尚不明确。

Method: 本案例研究采用近似贝叶斯推断的统一框架，结合对精心创建的合成分类数据集的经验测试，调查了六种不同概率机器学习算法的定性特性，包括：神经网络集成、带冲突损失的神经网络集成、证据深度学习、带Monte Carlo Dropout的单一神经网络、高斯过程分类以及狄利克雷过程混合模型。评估标准是检查算法产生的不确定性估计是否满足常用特性，例如良好校准以及对离分布数据点的不确定性增加。

Result: 所有算法都表现出良好的校准性。然而，基于深度学习的算法在处理离分布数据点时，未能始终如一地反映出缺乏实验证据所带来的不确定性增加。

Conclusion: 本研究希望可以为开发科学数据驱动建模中不确定性估计新方法的研究人员提供一个澄清性的示例。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [181] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

TL;DR: 本研究利用AutoML和可解释AI（SHAP）构建了一个透明且可复现的框架，用于预测和解释俄亥俄州机动车事故的严重程度，实现了高精度预测并识别出关键的环境和情境预测因子。


<details>
  <summary>Details</summary>
Motivation: 机动车事故是全球受伤和死亡的主要原因，因此需要数据驱动的方法来理解和减轻事故的严重性。

Method: 研究基于俄亥俄州2017-2022年间超过230万条车辆级事故记录，采用Automated Machine Learning (AutoML)（使用JADBio平台）与可解释人工智能 (explainable AI) 技术相结合的方法。通过对分层训练子集进行严格的特征选择，并使用SHapley Additive exPlanations (SHAP) 解释模型输出，构建了预测模型来区分严重和非严重碰撞结果。最终模型为岭逻辑回归（Ridge Logistic Regression）。

Result: 最终的岭逻辑回归模型在训练集上取得了85.6%的AUC-ROC，在测试集上取得了84.9%的AUC-ROC。模型识别出17个最具影响力的预测因子，涵盖人口统计学、环境、车辆、人员和操作类别，例如地点类型、限速、最低乘员年龄和碰撞前行为。与传统上强调的酒精或药物损害等因素相比，环境和情境变量在最终模型中影响更大。

Conclusion: 本研究提供了一个可扩展的框架，通过强调方法论的严谨性和可解释性，为“零愿景”计划提供支持，助力制定有针对性的干预措施和先进的数据驱动型交通安全政策。

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [182] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

TL;DR: 本文提出GraphOracle，一个新型自解释GNN框架，旨在生成和评估GNN的类级别解释。通过联合学习分类器和鉴别性子图，GraphOracle克服了现有方法的局限性，实现了更高的忠实性、可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有自解释图神经网络（GNNs）虽引入类特定原型，但其评估仅限于实例级别，未能有效验证这些原型能否泛化到同类实例以提供可靠的类级别解释，这阻碍了GNNs的安全和公平部署。

Method: GraphOracle框架通过联合学习GNN分类器和一组针对各类别具有鉴别性的结构化稀疏子图。模型采用一种新颖的集成训练方法，高效且忠实地捕获图-子图-预测依赖关系。同时，提出一种基于掩码的评估策略，用于验证GraphOracle并反向评估现有方法的类级别解释能力。此外，通过熵正则化子图选择和轻量级随机游走提取，避免了计算瓶颈。

Result: 研究发现，现有方法（如ProtGNN和PGIB）无法提供有效的类级别解释。相比之下，GraphOracle在多种图分类任务中表现出卓越的忠实性、可解释性和可扩展性。它还成功避免了先前方法（如蒙特卡洛树搜索）的计算瓶颈，实现了更快、更具扩展性的训练。

Conclusion: GraphOracle为GNNs中忠实的类级别自解释性提供了一个实用且有原则的解决方案。

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [183] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

TL;DR: 针对动态环境中决策代理的安全验证，本文提出一种双空间引导测试框架，通过协调场景参数与代理行为空间，有效生成兼具多样性和关键性的测试场景，实验验证其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着决策代理在动态环境中的日益部署，对其进行安全验证的需求增加。现有关键测试场景生成方法难以有效平衡多样性和关键性，在高维场景空间中易陷入局部最优。

Method: 提出一种双空间引导测试框架，协调场景参数空间和代理行为空间。在场景参数空间，采用分层表示结合降维与多维子空间评估，定位多样且关键的子空间，并动态协调局部扰动与全局探索两种生成模式。在代理行为空间，利用交互数据量化行为关键性/多样性，自适应支持模式切换，形成闭环反馈。

Result: 实验证明，该框架在五种决策代理上，将关键场景生成能力平均提升56.23%，并在新的参数-行为协同驱动度量下展现出更优的多样性，性能超越了现有基线。

Conclusion: 本文提出的双空间引导测试框架通过创新的参数-行为空间协同机制，有效解决了高维场景中关键测试场景生成中多样性与关键性平衡的难题，显著提升了决策代理的安全验证效率。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [184] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

TL;DR: 本文引入费曼图来计算神经正切核 (NTK) 统计量的有限宽度校正，简化了代数运算，并实现了层级递归关系，从而能预测深度网络在有限宽度下的训练动态。


<details>
  <summary>Details</summary>
Motivation: 无限宽度NTK虽然强大，但无法捕捉到NTK演化或特征学习等重要的训练特性。为了更真实地分析深度网络训练，需要将有限宽度效应纳入NTK分析中，这通常涉及复杂的代数修正。

Method: 引入费曼图以大幅简化计算NTK统计量有限宽度校正所需的代数操作。利用费曼图，可以计算涉及预激活、NTK及更高阶导数张量（dNTK、ddNTK）的层级递归关系，从而在领先阶次上预测训练动态。

Result: 该框架的可行性得到了证明。研究将深度网络的稳定性结果从预激活扩展到NTK。此外，证明了对于ReLU等尺度不变非线性函数，NTK格拉姆矩阵对角线上不存在有限宽度校正。所有结果均通过数值实验验证。

Conclusion: 费曼图提供了一种有效且简化的方法，可以将有限宽度效应整合到神经正切核分析中，从而能够更准确地预测深度神经网络的训练动态，并揭示了特定非线性函数在有限宽度下的一些特性。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [185] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

TL;DR: 提出一种基于物理信息扩散模型的无监督多元时间序列异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在时间序列领域已显示出有效性，但通过融入物理信息以更准确地学习数据分布，可进一步提升无监督异常检测性能。

Method: 开发了一种基于物理信息扩散模型的无监督异常检测方法，用于多元时间序列数据。该方法在扩散模型训练过程中，利用加权物理信息损失（采用静态权重调度）来学习数据中依赖物理的瞬时分布，从而更准确地逼近底层数据分布。

Result: 在合成和真实世界数据集上的实验表明，物理信息训练显著提高了异常检测的F1分数，并生成了更好的数据多样性和对数似然。该模型优于基线方法，在某些数据集上超越了先前的物理信息工作和纯数据驱动的扩散模型，并在其他数据集上保持了竞争力。

Conclusion: 将物理信息训练融入扩散模型中，通过改善数据分布的近似，显著提升了多元时间序列的无监督异常检测性能，表现优于现有方法。

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [186] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: 本文提出了HXAI（全息可解释人工智能）框架，旨在将解释性融入AI数据分析的全流程，为不同用户定制解释，以解决AI模型“黑箱”问题并提升其可信度。


<details>
  <summary>Details</summary>
Motivation: 现有可解释人工智能(XAI)方法仅关注单个预测的解释，忽视了影响模型可信度的上游决策和下游质量检查，导致AI模型仍被视为不透明的“黑箱”。

Method: 本研究提出用户中心的HXAI框架，将解释嵌入数据分析工作流的每个阶段，并为领域专家、数据分析师和数据科学家定制解释。它统一了数据、分析设置、学习过程、模型输出、模型质量和沟通渠道六个核心组件，并基于人类解释理论、人机交互原则和用户研究构建了112项问题库及综合分类法。此外，还展示了结合大语言模型的AI智能体如何协调解释技术，将技术产物转化为特定利益相关者可理解的叙述。

Result: HXAI框架提供了一个端到端、用户中心的解释性AI方法，通过统一的分类法和定制化解释，弥补了现有工具的覆盖空白。研究证明AI智能体能够有效转化技术信息为面向特定受众的叙述，促进AI开发者与领域专家之间的沟通。

Conclusion: HXAI为AI的透明度、可信度和负责任部署提供了一个新颖、全面的视角，通过整合多学科知识和实践经验，有效解决了AI模型的不透明性问题，推动了更具信任度的人工智能应用。

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [187] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

TL;DR: 本文提出DFed-SST，一个去中心化联邦图学习框架，通过利用局部子图拓扑信息实现自适应通信和高效模型聚合。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化联邦学习（DFL）策略未能有效处理局部子图的拓扑信息，而联邦图学习（FGL）虽适用于图数据但多为中心化模式，无法利用去中心化的优势。因此，研究旨在弥补DFL在图数据处理中对拓扑信息的不足以及FGL中心化的问题。

Method: 我们提出了DFed-SST框架，其核心是双拓扑自适应通信机制。该机制利用每个客户端本地子图的独特拓扑特征，动态构建并优化客户端间的通信拓扑，以高效指导异构环境下的模型聚合。

Result: 在八个真实世界数据集上进行的广泛实验表明，DFed-SST的性能优于基线方法，平均精度提升了3.26%。

Conclusion: DFed-SST成功结合了去中心化和图学习的优势，有效利用局部拓扑信息克服了现有挑战，显著提升了去中心化联邦图学习的性能。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [188] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

TL;DR: 本文提出了一种嵌套算子推断（OpInf）方法，用于从高维动力系统数据中学习降阶模型，显著提升了模型精度并大幅提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 提高从高维动力系统快照数据中学习物理信息降阶模型（ROMs）的精度和效率，并克服标准算子推断（OpInf）在模型重建误差方面的局限性。

Method: 提出了一种数据驱动的嵌套算子推断（OpInf）方法。该方法利用降维空间固有的层级结构，迭代构建初始猜测以优先处理主导模式的相互作用，并可从已学习模型进行热启动，以适应动态基和模型形式更新的场景。

Result: 在立方热传导问题中，嵌套OpInf比标准OpInf的误差小四倍，且离线时间相当。应用于格陵兰冰盖的大规模参数化模型时，即使存在模型形式近似误差，该方法学习的ROM平均误差也仅为3%，计算加速因子超过19,000倍。

Conclusion: 所提出的嵌套OpInf方法在降低降阶模型重建误差方面优于标准OpInf，并具有可证明的更高精度和显著的计算效率提升，尤其适用于大规模、复杂的高维动力系统。

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [189] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

TL;DR: SeamlessFlow是一个服务器端强化学习框架，通过数据平面解耦训练与执行，并利用标签驱动调度和时空复用管道优化资源利用，解决了工业级RL训练中解耦和GPU利用率两大挑战，实现了高稳定性与高性能，适用于复杂RL任务。


<details>
  <summary>Details</summary>
Motivation: 工业级强化学习面临两大核心挑战：1) 将RL训练与复杂的智能体执行流程解耦；2) 在大规模部署中，在保证稳定性和可扩展性的前提下，最大化GPU利用率并最小化空闲时间。

Method: 1. 数据平面：引入数据平面解耦RL训练器与多样智能体实现，并提供高吞吐量。中央轨迹管理器维护交互历史，支持部分rollout，允许在权重更新时暂停并无缝恢复rollout。
2. 标签驱动调度与时空复用：提出标签驱动调度范式，将硬件抽象为能力标签资源，统一并置和分离架构。引入时空复用管道，在训练-rollout分离设置中，动态将空闲训练节点分配给rollout，消除管道气泡，充分利用异构集群资源。

Result: 通过结合上述创新，SeamlessFlow实现了高稳定性与高性能。

Conclusion: SeamlessFlow非常适合多智能体、长时程及其他复杂的强化学习任务。

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [190] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

TL;DR: 提出一种基于马尔可夫博弈的多智能体强化学习框架，用于在考虑安全约束和地质连通性的情况下，优化多方参与的二氧化碳捕集与封存（CCS）项目的管理策略。


<details>
  <summary>Details</summary>
Motivation: CCS项目涉及多方利益相关者，目标各异，且项目复杂、规模大、周期长。在地质连通区域，共享地质特征导致竞争行为，利用现有基础设施进一步增加了独立优化的难度。因此，亟需研究在复杂多方环境下，如何有效规划和管理CCS项目，以及确定是独立优化还是需要协同合作。

Method: 采用基于马尔可夫博弈的范式，将该多利益相关者、多站点问题构建为带安全约束的多智能体强化学习问题。该方法使智能体能学习符合安全规定的最优策略。为降低高保真模型模拟的计算成本，引入了基于Embed-to-Control (E2C) 框架的代理模型。

Result: 通过案例演示，研究结果表明所提出的框架能够有效解决多个具有不同目标和利益的利益相关者参与的二氧化碳封存项目的优化管理问题。

Conclusion: 该研究提出的基于马尔可夫博弈和多智能体强化学习的框架为复杂的、多利益相关者和多站点CCS项目中的二氧化碳封存优化管理提供了有效的解决方案，尤其在考虑安全性和竞争动态方面具有优势。

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [191] [CrossTrace: Efficient Cross-Thread and Cross-Service Span Correlation in Distributed Tracing for Microservices](https://arxiv.org/abs/2508.11342)
*Linh-An Phan,MingXue Wang,Guangyu Wu,Wang Dawei,Chen Liqun,Li Jin*

Main category: cs.NI

TL;DR: CrossTrace是一个高效的零代码分布式追踪解决方案，通过创新的算法处理服务内span关联，并利用eBPF在TCP包头嵌入实现服务间关联，解决了现有方案中span关联的挑战，实现高精度和高性能。


<details>
  <summary>Details</summary>
Motivation: 分布式追踪对微服务应用至关重要，但广泛的插桩带来了巨大负担。虽然eBPF等零代码方案出现，但span关联仍是其主要挑战，现有方法常依赖线程亲和性、牺牲系统安全或计算开销大。

Method: 本文提出CrossTrace。对于服务内（intra-service）关联，它采用贪婪算法从延迟模式推断span关系，避免依赖线程标识符。对于服务间（inter-service）关联，CrossTrace通过eBPF将span标识符嵌入到TCP数据包头中，从而实现安全且高效的关联。

Result: 评估结果表明，CrossTrace能在数秒内关联数千个span，且准确率超过90%。

Conclusion: CrossTrace是一个实用且高效的分布式追踪解决方案，适用于微服务应用的调试，无需修改源代码，并对生产部署中的可观察性和诊断具有显著价值。

Abstract: Distributed tracing has become an essential technique for debugging and
troubleshooting modern microservice-based applications, enabling software
engineers to detect performance bottlenecks, identify failures, and gain
insights into system behavior. However, implementing distributed tracing in
large-scale applications remains challenging due to the need for extensive
instrumentation. To reduce this burden, zero-code instrumentation solutions,
such as those based on eBPF, have emerged, allowing span data to be collected
without modifying application code. Despite this promise, span correlation, the
process of establishing causal relationships between spans, remains a critical
challenge in zero-code approaches. Existing solutions often rely on thread
affinity, compromise system security by requiring the kernel integrity mode to
be disabled, or incur significant computational overhead due to complex
inference algorithms. This paper presents CrossTrace, a practical and efficient
distributed tracing solution designed to support the debugging of microservice
applications without requiring source code modifications. CrossTrace employs a
greedy algorithm to infer intra-service span relationships from delay patterns,
eliminating reliance on thread identifiers. For inter-service correlation,
CrossTrace embeds span identifiers into TCP packet headers via eBPF, enabling
secure and efficient correlation compromising system security policies.
Evaluation results show that CrossTrace can correlate thousands of spans within
seconds with over 90% accuracy, making it suitable for production deployment
and valuable for microservice observability and diagnosis.

</details>


### [192] [Optimizing ROS 2 Communication for Wireless Robotic Systems](https://arxiv.org/abs/2508.11366)
*Sanghoon Lee,Taehun Kim,Jiyeong Chae,Kyung-Joon Park*

Main category: cs.NI

TL;DR: ROS 2在无线传输大负载时面临性能瓶颈，DDS在有损无线链路表现不佳。本文首次深入分析ROS 2 DDS堆栈，识别出IP分片过多、重传时机低效和缓冲拥塞等问题。为此，提出一个轻量级DDS优化框架，通过调整通信参数提升大负载无线传输性能，同时保持低延迟，且无需修改协议，易于集成。


<details>
  <summary>Details</summary>
Motivation: ROS 2在无线传输高分辨率图像、激光雷达点云等大负载时存在显著瓶颈。默认的DDS通信堆栈在有损无线链路上性能显著下降。尽管ROS 2应用广泛，但其无线通信挑战的根本原因尚未被深入探究。

Method: 本文对ROS 2的DDS堆栈在无线条件下（传输大负载）进行了首次深入的网络层分析。在此基础上，提出一个轻量级且完全兼容的DDS优化框架，该框架通过基于链路和负载特性调整通信参数来实现优化。解决方案可通过ROS 2标准应用接口，以简单的XML-based QoS配置方式无缝应用，无需修改协议或额外组件。

Result: 分析识别出三个关键问题：过多的IP分片、低效的重传时机和拥塞缓冲突发。实验证明，在现有DDS模式失效的各种无线场景下，所提出的框架能成功传输大负载，同时保持较低的端到端延迟。

Conclusion: ROS 2在无线传输大负载时存在显著性能问题，主要源于DDS在有损链路上的表现。本文通过深入分析确定了具体的技术原因。提出的DDS优化框架能够有效解决这些问题，在无需协议修改和易于集成的前提下，显著提升ROS 2在大负载无线传输场景下的性能和延迟表现。

Abstract: Wireless transmission of large payloads, such as high-resolution images and
LiDAR point clouds, is a major bottleneck in ROS 2, the leading open-source
robotics middleware. The default Data Distribution Service (DDS) communication
stack in ROS 2 exhibits significant performance degradation over lossy wireless
links. Despite the widespread use of ROS 2, the underlying causes of these
wireless communication challenges remain unexplored. In this paper, we present
the first in-depth network-layer analysis of ROS 2's DDS stack under wireless
conditions with large payloads. We identify the following three key issues:
excessive IP fragmentation, inefficient retransmission timing, and congestive
buffer bursts. To address these issues, we propose a lightweight and fully
compatible DDS optimization framework that tunes communication parameters based
on link and payload characteristics. Our solution can be seamlessly applied
through the standard ROS 2 application interface via simple XML-based QoS
configuration, requiring no protocol modifications, no additional components,
and virtually no integration efforts. Extensive experiments across various
wireless scenarios demonstrate that our framework successfully delivers large
payloads in conditions where existing DDS modes fail, while maintaining low
end-to-end latency.

</details>


### [193] [D2Q Synchronizer: Distributed SDN Synchronization for Time Sensitive Applications](https://arxiv.org/abs/2508.11475)
*Ioannis Panitsas,Akrit Mudvari,Leandros Tassiulas*

Main category: cs.NI

TL;DR: 本文提出D2Q Synchronizer，一个基于强化学习的算法，用于分布式SDN中优化同步策略，通过智能卸载时间敏感任务至边缘服务器，以最小化长期网络成本并满足用户延迟要求。


<details>
  <summary>Details</summary>
Motivation: 分布式SDN控制器需要同步以维护全局网络状态，但现有同步策略未能联合优化网络和用户性能。

Method: 提出基于强化学习的D2Q Synchronizer算法，通过策略性地将时间敏感任务卸载到经济高效的边缘服务器，以最小化长期网络成本，同时满足所有任务的延迟要求。

Result: 评估结果显示，与启发式和其他学习策略相比，D2Q Synchronizer分别将网络成本降低至少45%和10%，同时在动态和多域SDN网络中确保所有用户任务的QoS要求。

Conclusion: D2Q Synchronizer是一个在分布式SDN中，能够有效平衡网络成本和用户性能的优越同步策略，解决了现有策略的不足。

Abstract: In distributed Software-Defined Networking (SDN), distributed SDN controllers
require synchronization to maintain a global network state. Despite the
availability of synchronization policies for distributed SDN architectures,
most policies do not consider joint optimization of network and user
performance. In this work, we propose a reinforcement learning-based algorithm
called D2Q Synchronizer, to minimize long-term network costs by strategically
offloading time-sensitive tasks to cost-effective edge servers while satisfying
the latency requirements for all tasks. Evaluation results demonstrate the
superiority of our synchronizer compared to heuristic and other learning
policies in literature, by reducing network costs by at least 45% and 10%,
respectively, while ensuring the QoS requirements for all user tasks across
dynamic and multi-domain SDN networks.

</details>


### [194] [Intelligent Edge Resource Provisioning for Scalable Digital Twins of Autonomous Vehicles](https://arxiv.org/abs/2508.11574)
*Mohammad Sajid Shahriar,Suresh Subramaniam,Motoharu Matsuura,Hiroshi Hasegawa,Shih-Chun Lin*

Main category: cs.NI

TL;DR: 针对智能交通系统中数字孪生(DTs)的计算资源管理挑战，本文提出了一种将DTs与移动边缘计算(MEC)集成的分布式架构和协作任务分配算法，显著提升了DTs的鲁棒性和边缘资源利用率。


<details>
  <summary>Details</summary>
Motivation: 下一代网络结合数字孪生(DTs)有望推动智能交通系统(ITS)发展，但如何高效管理计算资源以确保DTs不间断运行仍是一个开放性挑战。

Method: 本文提出了一种分布式计算架构，将DTs和移动边缘计算(MEC)集成到软件定义车载网络框架中。并开发了一种网络感知可伸缩协作任务分配算法来训练自主代理，通过真实的互联自动驾驶车辆(CAV)交通模拟进行评估。

Result: 所提出的框架显著增强了DT操作的鲁棒性和可伸缩性，成功将同步误差降低至5%，并实现了高达99.5%的边缘计算资源利用率。

Conclusion: 该分布式计算架构和任务分配算法有效解决了智能交通系统中DTs的资源管理难题，显著提升了系统性能，为实现智能、低延迟的交通服务提供了可靠支持。

Abstract: The next generation networks offers significant potential to advance
Intelligent Transportation Systems (ITS), particularly through the integration
of Digital Twins (DTs). However, ensuring the uninterrupted operation of DTs
through efficient computing resource management remains an open challenge. This
paper introduces a distributed computing archi tecture that integrates DTs and
Mobile Edge Computing (MEC) within a software-defined vehicular networking
framework to enable intelligent, low-latency transportation services. A network
aware scalable collaborative task provisioning algorithm is de veloped to train
an autonomous agent, which is evaluated using a realistic connected autonomous
vehicle (CAV) traffic simulation. The proposed framework significantly enhances
the robustness and scalability of DT operations by reducing synchronization
errors to as low as 5% while achieving up to 99.5% utilization of edge
computing resources.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [195] [Trees Assembling Mann Whitney Approach for Detecting Genome-wide Joint Association among Low Marginal Effect loci](https://arxiv.org/abs/1505.01206)
*Changshuai Wei,Daniel J. Schaid,Qing Lu*

Main category: q-bio.QM

TL;DR: 提出TAMW方法，有效分析复杂疾病中低边缘效应遗传变异的联合关联，优于现有方法并发现克罗恩病新基因。


<details>
  <summary>Details</summary>
Motivation: 复杂疾病受大量遗传变异的相互作用影响，尤其是低边缘效应（LME）遗传变异。然而，在高维数据（如全基因组关联研究）中发现LME变异并评估其联合关联仍是巨大挑战。

Method: 提出了一种计算高效且强大的方法，称为Trees Assembling Mann whitney (TAMW)，用于促进大量LME遗传变异的联合关联分析。

Result: 通过模拟研究和实证数据应用发现，当复杂疾病涉及多个LME位点及其相互作用时，TAMW表现优于多因子降维（MDR）和基于似然比的Mann whitney方法（LRMW）。例如，在20个相互作用LME位点的模拟中，TAMW的功效（0.931）高于MDR（0.599）和LRMW（0.704）。在克罗恩病（CD）的实证研究中，TAMW也识别出比MDR和LRMW更强的CD联合关联。此外，TAMW应用于Wellcome Trust CD GWAS，在40小时内完成459K单核苷酸多态性分析，揭示了与CD相关的联合关联（p值=2.763e-19），并提示13个基因（如ATG16L1和LACC1）可能在CD的病理生理和病因学过程中发挥重要作用。

Conclusion: TAMW是一种有效且高效的工具，能够发现复杂疾病中低边缘效应遗传变异的联合关联，在现有方法基础上实现了性能提升，并为克罗恩病等复杂疾病的致病机制提供了新的遗传学见解。

Abstract: Common complex diseases are likely influenced by the interplay of hundreds,
or even thousands, of genetic variants. Converging evidence shows that genetic
variants with low marginal effects (LME) play an important role in disease
development. Despite their potential significance, discovering LME genetic
variants and assessing their joint association on high dimensional data (e.g.,
genome wide association studies) remain a great challenge. To facilitate joint
association analysis among a large ensemble of LME genetic variants, we
proposed a computationally efficient and powerful approach, which we call Trees
Assembling Mann whitney (TAMW). Through simulation studies and an empirical
data application, we found that TAMW outperformed multifactor dimensionality
reduction (MDR) and the likelihood ratio based Mann whitney approach (LRMW)
when the underlying complex disease involves multiple LME loci and their
interactions. For instance, in a simulation with 20 interacting LME loci, TAMW
attained a higher power (power=0.931) than both MDR (power=0.599) and LRMW
(power=0.704). In an empirical study of 29 known Crohn's disease (CD) loci,
TAMW also identified a stronger joint association with CD than those detected
by MDR and LRMW. Finally, we applied TAMW to Wellcome Trust CD GWAS to conduct
a genome wide analysis. The analysis of 459K single nucleotide polymorphisms
was completed in 40 hours using parallel computing, and revealed a joint
association predisposing to CD (p-value=2.763e-19). Further analysis of the
newly discovered association suggested that 13 genes, such as ATG16L1 and
LACC1, may play an important role in CD pathophysiological and etiological
processes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [196] [LD-LAudio-V1: Video-to-Long-Form-Audio Generation Extension with Dual Lightweight Adapters](https://arxiv.org/abs/2508.11074)
*Haomin Zhang,Kristin Qi,Shuxin Yang,Zihao Chen,Chaofan Ding,Xinhan Di*

Main category: cs.SD

TL;DR: 本研究引入了LD-LAudio-V1模型，通过双轻量级适配器和高质量数据集，显著提升了长视频的音频生成质量，减少了拼接伪影和时间不一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成方法主要关注短视频（10秒以下）或依赖带噪声的长视频数据集，导致生成音频质量差、存在拼接伪影和时间不一致性。高质量、时间同步的视频音频生成对视频编辑和后期制作至关重要。

Method: 引入LD-LAudio-V1模型，作为现有先进视频到音频模型的扩展，并集成了双轻量级适配器以实现长音频生成。同时，发布了一个干净、人工标注的视频到音频数据集，仅包含纯净的音效，无噪声或伪影。

Result: LD-LAudio-V1显著减少了拼接伪影和时间不一致性，同时保持计算效率。与直接短视频微调相比，LD-LAudio-V1在多个评估指标上均有显著改进，例如$FD_{	ext{passt}}$提升27.27%，$FD_{	ext{panns}}$提升34.98%，$FD_{	ext{vgg}}$提升65.87%，语义相关性提升20.15%。

Conclusion: LD-LAudio-V1及其伴随的干净数据集成功解决了长视频音频生成中的关键问题，显著提升了生成音频的质量和一致性，并为未来长视频到音频生成的研究奠定了基础。

Abstract: Generating high-quality and temporally synchronized audio from video content
is essential for video editing and post-production tasks, enabling the creation
of semantically aligned audio for silent videos. However, most existing
approaches focus on short-form audio generation for video segments under 10
seconds or rely on noisy datasets for long-form video-to-audio zsynthesis. To
address these limitations, we introduce LD-LAudio-V1, an extension of
state-of-the-art video-to-audio models and it incorporates dual lightweight
adapters to enable long-form audio generation. In addition, we release a clean
and human-annotated video-to-audio dataset that contains pure sound effects
without noise or artifacts. Our method significantly reduces splicing artifacts
and temporal inconsistencies while maintaining computational efficiency.
Compared to direct fine-tuning with short training videos, LD-LAudio-V1
achieves significant improvements across multiple metrics: $FD_{\text{passt}}$
450.00 $\rightarrow$ 327.29 (+27.27%), $FD_{\text{panns}}$ 34.88 $\rightarrow$
22.68 (+34.98%), $FD_{\text{vgg}}$ 3.75 $\rightarrow$ 1.28 (+65.87%),
$KL_{\text{panns}}$ 2.49 $\rightarrow$ 2.07 (+16.87%), $KL_{\text{passt}}$ 1.78
$\rightarrow$ 1.53 (+14.04%), $IS_{\text{panns}}$ 4.17 $\rightarrow$ 4.30
(+3.12%), $IB_{\text{score}}$ 0.25 $\rightarrow$ 0.28 (+12.00%),
$Energy\Delta10\text{ms}$ 0.3013 $\rightarrow$ 0.1349 (+55.23%),
$Energy\Delta10\text{ms(vs.GT)}$ 0.0531 $\rightarrow$ 0.0288 (+45.76%), and
$Sem.\,Rel.$ 2.73 $\rightarrow$ 3.28 (+20.15%). Our dataset aims to facilitate
further research in long-form video-to-audio generation and is available at
https://github.com/deepreasonings/long-form-video2audio.

</details>


### [197] [Benchmarking Prosody Encoding in Discrete Speech Tokens](https://arxiv.org/abs/2508.11224)
*Kentaro Onda,Satoru Fukayama,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.SD

TL;DR: 本研究分析了自监督学习模型生成的离散token在捕获语音韵律信息方面的能力，旨在为设计此类token提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 目前，通过自监督学习模型和k-means聚类获得的离散token在语音语言模型中作为伪文本和中间表示被广泛使用。然而，这些token通常预先学习，且其离散化参数（如SSL模型、聚类数）需凭经验选择。更重要的是，尽管语音语言模型需理解和生成韵律特征，但关于离散token捕获韵律信息能力的研究有限。

Method: 本研究通过对离散token进行全面的韵律编码分析，重点评估它们对人工修改的韵律的敏感度。

Result: 抽象内容未详细说明具体的实验结果，但表明研究旨在为离散token的设计提供实用指南。

Conclusion: 本研究旨在通过分析离散token捕获韵律信息的能力，填补现有研究空白，并为设计能够有效编码韵律特征的离散token提供实用指导。

Abstract: Recently, discrete tokens derived from self-supervised learning (SSL) models
via k-means clustering have been actively studied as pseudo-text in speech
language models and as efficient intermediate representations for various
tasks. However, these discrete tokens are typically learned in advance,
separately from the training of language models or downstream tasks. As a
result, choices related to discretization, such as the SSL model used or the
number of clusters, must be made heuristically. In particular, speech language
models are expected to understand and generate responses that reflect not only
the semantic content but also prosodic features. Yet, there has been limited
research on the ability of discrete tokens to capture prosodic information. To
address this gap, this study conducts a comprehensive analysis focusing on
prosodic encoding based on their sensitivity to the artificially modified
prosody, aiming to provide practical guidelines for designing discrete tokens.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [198] [MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](https://arxiv.org/abs/2508.10991)
*Wenpeng Xing,Zhonghao Qi,Yupeng Qin,Yilin Li,Caini Chang,Jiahui Yu,Changting Lin,Zhenzhen Xie,Meng Han*

Main category: cs.CR

TL;DR: 针对大型语言模型（LLM）与工具集成中的安全漏洞，本文提出了分层防御架构MCP-Guard及其配套的评估基准MCP-AttackBench。


<details>
  <summary>Details</summary>
Motivation: LLM与外部工具（如通过MCP协议）的集成引入了严重的安全性漏洞，包括提示注入和数据泄露等威胁，亟需有效的防御机制。

Method: 本文提出MCP-Guard，一个三阶段的防御架构：首先是轻量级静态扫描，然后是基于深度神经网络（特别是微调的E5模型）的语义攻击检测，最后由一个轻量级LLM仲裁器综合判断。为支持训练和评估，还构建了包含7万余样本的综合基准MCP-AttackBench，模拟真实世界攻击。

Result: MCP-Guard中微调的E5模型在识别对抗性提示方面的准确率达到96.01%。

Conclusion: MCP-Guard为LLM-工具交互提供了一个鲁棒的防御方案，而MCP-AttackBench则为未来LLM-工具生态系统的安全研究奠定了坚实基础。

Abstract: The integration of Large Language Models (LLMs) with external tools via
protocols such as the Model Context Protocol (MCP) introduces critical security
vulnerabilities, including prompt injection, data exfiltration, and other
threats. To counter these challenges, we propose MCP-Guard, a robust, layered
defense architecture designed for LLM--tool interactions. MCP-Guard employs a
three-stage detection pipeline that balances efficiency with accuracy: it
progresses from lightweight static scanning for overt threats and a deep neural
detector for semantic attacks, to our fine-tuned E5-based model achieves
(96.01) accuracy in identifying adversarial prompts. Finally, a lightweight LLM
arbitrator synthesizes these signals to deliver the final decision while
minimizing false positives. To facilitate rigorous training and evaluation, we
also introduce MCP-AttackBench, a comprehensive benchmark of over 70,000
samples. Sourced from public datasets and augmented by GPT-4, MCP-AttackBench
simulates diverse, real-world attack vectors in the MCP format, providing a
foundation for future research into securing LLM-tool ecosystems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [199] [Expressive Speech Retrieval using Natural Language Descriptions of Speaking Style](https://arxiv.org/abs/2508.11187)
*Wonjune Kang,Deb Roy*

Main category: eess.AS

TL;DR: 本文引入了表达性语音检索任务，旨在根据自然语言风格描述而非内容来检索语音片段，通过训练语音和文本编码器实现跨模态检索。


<details>
  <summary>Details</summary>
Motivation: 现有语音检索主要关注“说什么”，而本研究的动机是填补空白，实现基于“怎么说”（即说话风格）的语音检索，允许用户使用自然语言描述来查询特定风格的语音。

Method: 该研究训练了语音和文本编码器，将语音和文本风格描述映射到共享的潜在空间中。这使得自由形式的文本提示（描述情感或风格）能够作为查询来检索匹配的表达性语音片段。研究还详细分析了编码器架构、有效的跨模态对齐训练准则以及用于提高泛化能力的提示增强方法。

Result: 在包含22种说话风格的多个数据集上进行的实验表明，所提出的方法在Recall@k指标上实现了强大的检索性能。

Conclusion: 本研究成功地引入并验证了一种基于自然语言描述的表达性语音检索方法，为依据语音风格进行检索提供了有效途径。

Abstract: We introduce the task of expressive speech retrieval, where the goal is to
retrieve speech utterances spoken in a given style based on a natural language
description of that style. While prior work has primarily focused on performing
speech retrieval based on what was said in an utterance, we aim to do so based
on how something was said. We train speech and text encoders to embed speech
and text descriptions of speaking styles into a joint latent space, which
enables using free-form text prompts describing emotions or styles as queries
to retrieve matching expressive speech segments. We perform detailed analyses
of various aspects of our proposed framework, including encoder architectures,
training criteria for effective cross-modal alignment, and prompt augmentation
for improved generalization to arbitrary text queries. Experiments on multiple
datasets encompassing 22 speaking styles demonstrate that our approach achieves
strong retrieval performance as measured by Recall@k.

</details>


### [200] [Emphasis Sensitivity in Speech Representations](https://arxiv.org/abs/2508.11566)
*Shaun Cassini,Thomas Hain,Anton Ragni*

Main category: eess.AS

TL;DR: 现代语音模型能以结构化、关系化的方式编码语调重音，且该编码随任务学习愈加精细。


<details>
  <summary>Details</summary>
Motivation: 旨在探究现代语音模型是否能区分重读词与中性词，以及它们如何编码语调重音。现有研究方法侧重孤立声学特征或标签预测，未能捕捉重音的关系结构。

Method: 提出一种基于残差的框架，将重音定义为配对的中性词和重读词表征之间的差异。

Result: 1. 在自监督语音模型中，重音残差与时长变化强相关，但单词识别性能差，表明重音以结构化、关系化的方式编码。 2. 在ASR微调模型中，残差占据的子空间比预训练模型紧凑多达50%，表明重音被编码为一致的、低维度的转换，并随任务特定学习变得更结构化。

Conclusion: 现代语音模型能够以结构化、关系化的方式编码语调重音，并且这种编码会随着任务特异性学习而变得更加一致和紧凑。

Abstract: This work investigates whether modern speech models are sensitive to prosodic
emphasis - whether they encode emphasized and neutral words in systematically
different ways. Prior work typically relies on isolated acoustic correlates
(e.g., pitch, duration) or label prediction, both of which miss the relational
structure of emphasis. This paper proposes a residual-based framework, defining
emphasis as the difference between paired neutral and emphasized word
representations. Analysis on self-supervised speech models shows that these
residuals correlate strongly with duration changes and perform poorly at word
identity prediction, indicating a structured, relational encoding of prosodic
emphasis. In ASR fine-tuned models, residuals occupy a subspace up to 50% more
compact than in pre-trained models, further suggesting that emphasis is encoded
as a consistent, low-dimensional transformation that becomes more structured
with task-specific learning.

</details>


### [201] [CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction in Cardiotocography](https://arxiv.org/abs/2508.10928)
*Sheng Wong,Beth Albert,Gabriel Davis Jones*

Main category: eess.AS

TL;DR: CTG伪影影响胎儿监测，本文提出CleanCTG，一个双阶段模型用于自动识别和重建伪影，显著提高了CTG解读的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 心脏胎儿监护（CTG）在胎儿监测中至关重要，但常受多种伪影干扰，掩盖真实胎儿心率（FHR）模式，导致误诊或延迟干预。现有深度学习方法和传统方法在全面处理复杂噪声方面存在不足。

Method: 本文提出CleanCTG，一个端到端双阶段模型。第一阶段通过多尺度卷积和上下文感知交叉注意力识别多种伪影类型；第二阶段通过伪影特异性校正分支重建受损片段。模型使用超过80万分钟的生理真实、合成损坏的CTG数据进行训练。

Result: 在合成数据上，CleanCTG实现了完美伪影检测（AU-ROC = 1.00），并显著降低了受损片段的均方误差（MSE）。在10,190分钟临床医生标注的外部验证数据上，AU-ROC达到0.95，优于六种对比分类器。与Dawes-Redman系统集成后，去噪轨迹将特异性提高（从80.70%到82.70%），并将中位决策时间缩短了33%。

Conclusion: 明确的伪影去除和信号重建方法能够保持诊断准确性并缩短监测时间，为更可靠的CTG解读提供了一条实用途径。

Abstract: Cardiotocography (CTG) is essential for fetal monitoring but is frequently
compromised by diverse artefacts which obscure true fetal heart rate (FHR)
patterns and can lead to misdiagnosis or delayed intervention. Current
deep-learning approaches typically bypass comprehensive noise handling,
applying minimal preprocessing or focusing solely on downstream classification,
while traditional methods rely on simple interpolation or rule-based filtering
that addresses only missing samples and fail to correct complex artefact types.
We present CleanCTG, an end-to-end dual-stage model that first identifies
multiple artefact types via multi-scale convolution and context-aware
cross-attention, then reconstructs corrupted segments through artefact-specific
correction branches. Training utilised over 800,000 minutes of physiologically
realistic, synthetically corrupted CTGs derived from expert-verified "clean"
recordings. On synthetic data, CleanCTG achieved perfect artefact detection
(AU-ROC = 1.00) and reduced mean squared error (MSE) on corrupted segments to
2.74 x 10^-4 (clean-segment MSE = 2.40 x 10^-6), outperforming the next best
method by more than 60%. External validation on 10,190 minutes of
clinician-annotated segments yielded AU-ROC = 0.95 (sensitivity = 83.44%,
specificity 94.22%), surpassing six comparator classifiers. Finally, when
integrated with the Dawes-Redman system on 933 clinical CTG recordings,
denoised traces increased specificity (from 80.70% to 82.70%) and shortened
median time to decision by 33%. These findings suggest that explicit artefact
removal and signal reconstruction can both maintain diagnostic accuracy and
enable shorter monitoring sessions, offering a practical route to more reliable
CTG interpretation.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [202] [Tabularis Formatus: Predictive Formatting for Tables](https://arxiv.org/abs/2508.11121)
*Mukul Singh,José Cambronero,Sumit Gulwani,Vu Le,Gust Verbruggen*

Main category: cs.DB

TL;DR: TaFo是一种神经符号方法，通过自动化学习规则和可视化属性，为电子表格生成条件格式化建议，解决了现有方法的复杂性与局限性，并表现出更高的准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 电子表格中的条件格式化规则创建复杂，需要专业知识和经验，且现有方法主要关注结构化格式化，依赖用户输入，无法有效解决用户无感知、规则创建困难和界面不足等问题。

Method: 本文提出了TaFo，一种神经符号方法，用于生成表格的条件格式化建议。它受基于组件的合成系统启发，并结合了语言模型的语义知识和保持多样性的规则排名。TaFo独特地融入了基于值（value-based）的格式化，能自动学习规则触发条件和相关的视觉格式化属性，从而实现完全预测和自动化的格式化，无需用户指定。

Result: 通过使用包含180万份公共工作簿的语料库进行评估，并将TaFo与多种符号和神经网络系统进行比较，结果显示TaFo生成的格式化建议比现有系统更准确、更多样、更完整，在匹配用户添加的真实规则方面，性能优于现有系统15.6%至26.5%。

Conclusion: TaFo成功地解决了条件格式化规则创建的痛点，提供了一种无需用户输入的自动化、预测性解决方案，其在准确性和多样性方面显著优于当前系统，为电子表格数据分析带来了更高的效率和便利性。

Abstract: Spreadsheet manipulation software are widely used for data management and
analysis of tabular data, yet the creation of conditional formatting (CF) rules
remains a complex task requiring technical knowledge and experience with
specific platforms. In this paper we present TaFo, a neuro-symbolic approach to
generating CF suggestions for tables, addressing common challenges such as user
unawareness, difficulty in rule creation, and inadequate user interfaces. TaFo
takes inspiration from component based synthesis systems and extends them with
semantic knowledge of language models and a diversity preserving rule
ranking.Unlike previous methods focused on structural formatting, TaFo uniquely
incorporates value-based formatting, automatically learning both the rule
trigger and the associated visual formatting properties for CF rules. By
removing the dependency on user specification used by existing techniques in
the form of formatted examples or natural language instruction, TaFo makes
formatting completely predictive and automated for the user. To evaluate TaFo,
we use a corpus of 1.8 Million public workbooks with CF and manual formatting.
We compare TaFo against a diverse set of symbolic and neural systems designed
for or adapted for the task of table formatting. Our results show that TaFo
generates more accurate, diverse and complete formatting suggestions than
current systems and outperforms these by 15.6\%--26.5\% on matching user added
ground truth rules in tables.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [203] [A weighted U statistic for association analysis considering genetic heterogeneity](https://arxiv.org/abs/1504.08319)
*Changshuai Wei,Robert C. Elston,Qing Lu*

Main category: stat.ME

TL;DR: 提出了一种名为HWU的新方法，用于考虑遗传异质性的关联分析，并在模拟和实际数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了复杂疾病中遗传异质性的影响，大多数统计方法假设疾病具有同质的遗传效应，导致在存在异质性时分析效力低下。

Method: 提出了一种异质性加权U (Heterogeneity Weighted U, HWU) 方法，用于考虑遗传异质性的关联分析。该方法适用于多种表型类型，且对高维遗传数据计算高效。

Result: 模拟结果显示，HWU在疾病遗传病因具有异质性时表现出优势，并对不同模型假设具有鲁棒性。应用于尼古丁依赖性全基因组分析，识别出CYP3A5和IKBKB两个新基因的异质性效应。

Conclusion: HWU方法有效解决了复杂疾病遗传研究中的异质性问题，提高了关联分析的效力，并能够发现具有异质性效应的新基因。

Abstract: Converging evidence suggests that common complex diseases with the same or
similar clinical manifestations could have different underlying genetic
etiologies. While current research interests have shifted toward uncovering
rare variants and structural variations predisposing to human diseases, the
impact of heterogeneity in genetic studies of complex diseases has been largely
overlooked. Most of the existing statistical methods assume the disease under
investigation has a homogeneous genetic effect and could, therefore, have low
power if the disease undergoes heterogeneous pathophysiological and etiological
processes. In this paper, we propose a heterogeneity weighted U (HWU) method
for association analyses considering genetic heterogeneity. HWU can be applied
to various types of phenotypes (e.g., binary and continuous) and is
computationally effcient for high- dimensional genetic data. Through
simulations, we showed the advantage of HWU when the underlying genetic
etiology of a disease was heterogeneous, as well as the robustness of HWU
against different model assumptions (e.g., phenotype distributions). Using HWU,
we conducted a genome-wide analysis of nicotine dependence from the Study of
Addiction: Genetics and Environments (SAGE) dataset. The genome-wide analysis
of nearly one million genetic markers took 7 hours, identifying heterogeneous
effects of two new genes (i.e., CYP3A5 and IKBKB) on nicotine dependence.

</details>


### [204] [A Generalized Similarity U Test for Multivariate Analysis of Sequencing Data](https://arxiv.org/abs/1505.01179)
*Changshuai Wei,Qing Lu*

Main category: stat.ME

TL;DR: 本文提出广义相似性U检验（GSU），这是一种基于相似性的新方法，旨在应对高维基因型和多种表型在复杂疾病遗传关联研究中的挑战，并在模拟和真实数据中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 基于测序的遗传关联研究面临数据高维、遗传变异低频的挑战，传统统计方法（如单基因座回归分析）难以应对。此外，识别与多种疾病表型（这些表型可能遵循不同分布，违反多数现有方法假设）相关的遗传风险因素是生物学和流行病学领域的一大兴趣点。

Method: 本文提出了一种广义相似性U检验（GSU）。GSU是一种基于相似性的检验方法，能够处理高维基因型和表型数据。研究中探讨了GSU的理论性质，并提供了高效的关联检验p值计算方法，以及用于研究设计的样本量和功效计算。

Result: 通过模拟研究，发现GSU在功效和对表型分布的鲁棒性方面优于现有方法。此外，将GSU应用于达拉斯心脏研究的测序数据进行多变量分析，成功识别出4个基因与5个代谢相关表型的联合关联。

Conclusion: GSU是处理高维基因型和多表型数据的有效工具，能够克服传统统计方法在复杂疾病遗传关联研究中的局限性，并在实际应用中成功发现有意义的遗传关联。

Abstract: Sequencing-based studies are emerging as a major tool for genetic association
studies of complex diseases. These studies pose great challenges to the
traditional statistical methods (e.g., single-locus analyses based on
regression methods) because of the high-dimensionality of data and the low
frequency of genetic variants. In addition, there is a great interest in
biology and epidemiology to identify genetic risk factors contributed to
multiple disease phenotypes. The multiple phenotypes can often follow different
distributions, which violates the assumptions of most current methods. In this
paper, we propose a generalized similarity U test, referred to as GSU. GSU is a
similarity-based test and can handle high-dimensional genotypes and phenotypes.
We studied the theoretical properties of GSU, and provided the efficient
p-value calculation for association test as well as the sample size and power
calculation for the study design. Through simulation, we found that GSU had
advantages over existing methods in terms of power and robustness to phenotype
distributions. Finally, we used GSU to perform a multivariate analysis of
sequencing data in the Dallas Heart Study and identified a joint association of
4 genes with 5 metabolic related phenotypes.

</details>


### [205] [A Weighted U Statistic for Genetic Association Analyses of Sequencing Data](https://arxiv.org/abs/1505.01204)
*Changshuai Wei,Ming Li,Zihuai He,Olga Vsevolozhskaya,Daniel J. Schaid,Qing Lu*

Main category: stat.ME

TL;DR: 开发了一种新的非参数加权U统计量（WU-seq），用于高维测序数据关联分析，在传统方法假设不成立时表现优异，且无需对疾病模型和表型分布做假设。


<details>
  <summary>Details</summary>
Motivation: 下一代测序技术产生了大量数据，为研究罕见变异的遗传病因提供了机会。然而，高维测序数据的统计分析极具挑战，传统关联分析方法因变异低频和数据高维性而导致功效显著下降。

Method: 开发了一种名为WU-seq的加权U统计量，用于高维测序数据关联分析。WU-seq基于非参数U统计量，无需对潜在疾病模型和表型分布做任何假设，可应用于多种表型。

Result: 通过模拟研究和实证研究表明，当底层假设被违反（例如，表型呈重尾分布）时，WU-seq的表现优于常用的SKAT方法；即使在假设满足的情况下，WU-seq仍能达到与SKAT相当的性能。将WU-seq应用于达拉斯心脏研究（DHS）的测序数据，成功检测到ANGPTL 4与极低密度脂蛋白胆固醇之间的关联。

Conclusion: WU-seq是一种针对高维测序数据关联分析的稳健且有效的非参数统计方法，尤其在传统方法假设不成立的情况下展现出优越性，并能够发现实际的生物学关联。

Abstract: With advancements in next generation sequencing technology, a massive amount
of sequencing data are generated, offering a great opportunity to
comprehensively investigate the role of rare variants in the genetic etiology
of complex diseases. Nevertheless, this poses a great challenge for the
statistical analysis of high-dimensional sequencing data. The association
analyses based on traditional statistical methods suffer substantial power loss
because of the low frequency of genetic variants and the extremely high
dimensionality of the data. We developed a weighted U statistic, referred to as
WU-seq, for the high-dimensional association analysis of sequencing data. Based
on a non-parametric U statistic, WU-SEQ makes no assumption of the underlying
disease model and phenotype distribution, and can be applied to a variety of
phenotypes. Through simulation studies and an empirical study, we showed that
WU-SEQ outperformed a commonly used SKAT method when the underlying assumptions
were violated (e.g., the phenotype followed a heavy-tailed distribution). Even
when the assumptions were satisfied, WU-SEQ still attained comparable
performance to SKAT. Finally, we applied WU-seq to sequencing data from the
Dallas Heart Study (DHS), and detected an association between ANGPTL 4 and very
low density lipoprotein cholesterol.

</details>


### [206] [Generalized Similarity U: A Non-parametric Test of Association Based on Similarity](https://arxiv.org/abs/1801.01220)
*Changshuai Wei,Qing Lu*

Main category: stat.ME

TL;DR: 本文提出一种广义相似性U (GSU) 检验，用于检测复杂基因型与复杂表型之间的关联，通过理论分析、模拟和实际数据（ADNI）验证了其在功效和鲁棒性方面的优势，并识别出与AD相关的基因，同时开发了C++软件包。


<details>
  <summary>Details</summary>
Motivation: 随着第二代测序技术在基因关联研究中的广泛应用，识别与多种表型（包括单变量、多变量甚至高维结果）相关的遗传变异成为核心研究兴趣。将基因型和表型视为复杂对象时，如何检验它们之间的关联构成了一个普遍的统计学难题。

Method: 本文提出了一种基于相似性的广义相似性U (GSU) 检验，用于检测复杂对象之间的关联。该方法首先进行了理论性质研究，并专注于其在测序关联研究中的应用。基于理论分析，建议GSU使用拉普拉斯核(Laplacian kernel)相似性来提升检验功效和鲁棒性。

Result: 通过模拟研究发现，GSU在功效和鲁棒性方面优于现有方法。将GSU应用于阿尔茨海默病神经影像学倡议(ADNI) 的全基因组测序数据扫描，成功识别出APOE、APOC1和TOMM40三个与影像学表型相关的基因。此外，开发了一个用于分析全基因组测序数据的C++软件包。

Conclusion: GSU是一种有效且鲁棒的统计检验方法，能够处理复杂基因型与复杂表型之间的关联分析。其在模拟和真实数据（如ADNI）中的表现证明了其在基因关联研究中的实用性和优越性。

Abstract: Second generation sequencing technologies are being increasingly used for
genetic association studies, where the main research interest is to identify
sets of genetic variants that contribute to various phenotype. The phenotype
can be univariate disease status, multivariate responses and even
high-dimensional outcomes. Considering the genotype and phenotype as two
complex objects, this also poses a general statistical problem of testing
association between complex objects. We here proposed a similarity-based test,
generalized similarity U (GSU), that can test the association between complex
objects. We first studied the theoretical properties of the test in a general
setting and then focused on the application of the test to sequencing
association studies. Based on theoretical analysis, we proposed to use
Laplacian kernel based similarity for GSU to boost power and enhance
robustness. Through simulation, we found that GSU did have advantages over
existing methods in terms of power and robustness. We further performed a whole
genome sequencing (WGS) scan for Alzherimer Disease Neuroimaging Initiative
(ADNI) data, identifying three genes, APOE, APOC1 and TOMM40, associated with
imaging phenotype. We developed a C++ package for analysis of whole genome
sequencing data using GSU. The source codes can be downloaded at
https://github.com/changshuaiwei/gsu.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [207] [The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers](https://arxiv.org/abs/2506.20844)
*Xingyu Deng,Xi Wang,Mark Stevenson*

Main category: cs.IR

TL;DR: 科学事实核查比一般事实核查更复杂，现有系统因只关注摘要而存在局限性。本文分析了当前系统的不足，指出了证据检索中的五大关键挑战，并旨在通过专业的信息检索系统推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 科学事实核查本质上比一般事实核查更复杂，因为它需要适应科学知识的演变、学术文献的结构复杂性以及长篇多模态科学表达带来的挑战。然而，现有方法过于简化，仅基于小规模摘要数据集，未能解决处理完整科学文档的相关挑战。

Method: 本文通过审查现有科学事实核查系统的局限性，揭示了可用于提高其性能的潜在特征和资源。同时，通过进行初步实验来证实这些挑战并识别潜在的解决方案。

Result: 研究结果识别出证据检索中的五大关键研究挑战：1) 解决语义限制和主题不平衡的证据驱动检索；2) 利用引文跟踪缓解过时信息的时间感知证据检索；3) 利用结构化文档解析利用长程上下文；4) 处理复杂的科学表达，包括表格、图表和特定领域术语；5) 评估科学文献的可信度。

Conclusion: 本透视论文旨在通过一个专门针对实际应用的信息检索（IR）系统，推进科学事实核查领域的发展。

Abstract: Scientific fact-checking aims to determine the veracity of scientific claims
by retrieving and analysing evidence from research literature. The problem is
inherently more complex than general fact-checking since it must accommodate
the evolving nature of scientific knowledge, the structural complexity of
academic literature and the challenges posed by long-form, multimodal
scientific expression. However, existing approaches focus on simplified
versions of the problem based on small-scale datasets consisting of abstracts
rather than full papers, thereby avoiding the distinct challenges associated
with processing complete documents. This paper examines the limitations of
current scientific fact-checking systems and reveals the many potential
features and resources that could be exploited to advance their performance. It
identifies key research challenges within evidence retrieval, including (1)
evidence-driven retrieval that addresses semantic limitations and topic
imbalance (2) time-aware evidence retrieval with citation tracking to mitigate
outdated information, (3) structured document parsing to leverage long-range
context, (4) handling complex scientific expressions, including tables,
figures, and domain-specific terminology and (5) assessing the credibility of
scientific literature. Preliminary experiments were conducted to substantiate
these challenges and identify potential solutions. This perspective paper aims
to advance scientific fact-checking with a specialised IR system tailored for
real-world applications.

</details>


### [208] [PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing](https://arxiv.org/abs/2508.11116)
*Zhuoqun Li,Xuanang Chen,Hongyu Lin,Yaojie Lu,Xianpei Han,Le Sun*

Main category: cs.IR

TL;DR: 本文提出PaperRegister系统，通过分层索引和自适应检索，解决了现有论文搜索系统无法支持灵活粒度查询的问题，尤其在细粒度搜索中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着研究深入，论文搜索需求变得更加灵活，有时需要搜索特定细节而非粗粒度主题。然而，现有论文搜索系统主要基于摘要构建索引，缺乏足够细节来支持细粒度查询，无法满足这些灵活粒度的需求。

Method: 本文提出PaperRegister系统，它由离线分层索引和在线自适应检索组成。该系统将传统的基于摘要的索引转换为分层索引树，从而支持灵活粒度的论文搜索。

Result: 在涵盖不同粒度的论文搜索任务中进行的实验表明，PaperRegister取得了最先进的性能，尤其在细粒度场景下表现突出。

Conclusion: PaperRegister作为一种有效的解决方案，在实际应用中展现出良好潜力，能够有效支持灵活粒度的论文搜索。

Abstract: Paper search is an important activity for researchers, typically involving
using a query with description of a topic to find relevant papers. As research
deepens, paper search requirements may become more flexible, sometimes
involving specific details such as module configuration rather than being
limited to coarse-grained topics. However, previous paper search systems are
unable to meet these flexible-grained requirements, as these systems mainly
collect paper abstracts to construct index of corpus, which lack detailed
information to support retrieval by finer-grained queries. In this work, we
propose PaperRegister, consisted of offline hierarchical indexing and online
adaptive retrieval, transforming traditional abstract-based index into
hierarchical index tree for paper search, thereby supporting queries at
flexible granularity. Experiments on paper search tasks across a range of
granularity demonstrate that PaperRegister achieves the state-of-the-art
performance, and particularly excels in fine-grained scenarios, highlighting
the good potential as an effective solution for flexible-grained paper search
in real-world applications. Code for this work is in
https://github.com/Li-Z-Q/PaperRegister.

</details>


### [209] [+VeriRel: Verification Feedback to Enhance Document Retrieval for Scientific Fact Checking](https://arxiv.org/abs/2508.11122)
*Xingyu Deng,Xi Wang,Mark Stevenson*

Main category: cs.IR

TL;DR: 本文提出+VeriRel模型，通过将验证成功纳入文档排名，显著提升了科学事实核查中的证据检索和验证效果。


<details>
  <summary>Details</summary>
Motivation: 现有科学事实核查方法依赖通用信息检索算法，仅基于相关性而非证据有效性对文档进行排名，导致支持证据识别效率低下。

Method: 提出+VeriRel方法，将验证成功的反馈信息整合到文档排名过程中，以更有效地检索支持或反驳声明的证据。

Result: 在SciFact、SciFact-Open和Check-Covid三个科学事实核查数据集上的实验结果表明，+VeriRel在文档证据检索方面表现持续领先，并对后续验证流程产生了积极影响。

Conclusion: 该研究强调了将验证反馈整合到文档相关性评估中，对于构建高效科学事实核查系统的潜力，并指出未来可进一步研究复杂文档的细粒度相关性评估。

Abstract: Identification of appropriate supporting evidence is critical to the success
of scientific fact checking. However, existing approaches rely on off-the-shelf
Information Retrieval algorithms that rank documents based on relevance rather
than the evidence they provide to support or refute the claim being checked.
This paper proposes +VeriRel which includes verification success in the
document ranking. Experimental results on three scientific fact checking
datasets (SciFact, SciFact-Open and Check-Covid) demonstrate consistently
leading performance by +VeriRel for document evidence retrieval and a positive
impact on downstream verification. This study highlights the potential of
integrating verification feedback to document relevance assessment for
effective scientific fact checking systems. It shows promising future work to
evaluate fine-grained relevance when examining complex documents for advanced
scientific fact checking.

</details>


### [210] [Role-Augmented Intent-Driven Generative Search Engine Optimization](https://arxiv.org/abs/2508.11158)
*Xiaolu Chen,Haojie Wu,Jie Bao,Zhen Chen,Yong Liao,Hu Huang*

Main category: cs.IR

TL;DR: 本文提出一种面向生成式搜索引擎（GSEs）的“角色增强意图驱动生成式搜索引擎优化（G-SEO）”方法，以应对传统SEO在GSEs中失效的问题，并通过实验验证了其在提升内容可见性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式搜索引擎（GSEs）正在改变信息检索方式，但其“黑盒”特性削弱了传统搜索引擎优化（SEO）实践，导致内容创作者的可见性降低。现有基准测试也存在局限性。

Method: 提出“角色增强意图驱动G-SEO”方法，通过跨多样化信息角色进行反思性细化来建模搜索意图，从而实现内容优化。为改善评估，扩展了GEO数据集并引入了多级别的LLM增强评估标准G-Eval 2.0。

Result: 实验结果表明，搜索意图作为内容优化的有效信号，相比单一维度基线方法，在主观印象和GSE响应中的客观内容可见性方面均取得了显著提升。

Conclusion: 所提出的G-SEO方法，以搜索意图为指导，能有效优化内容以适应生成式搜索引擎场景，显著提高内容的可见性。

Abstract: Generative Search Engines (GSEs), powered by Large Language Models (LLMs) and
Retrieval-Augmented Generation (RAG), are reshaping information retrieval.
While commercial systems (e.g., BingChat, Perplexity.ai) demonstrate impressive
semantic synthesis capabilities, their black-box nature fundamentally
undermines established Search Engine Optimization (SEO) practices. Content
creators face a critical challenge: their optimization strategies, effective in
traditional search engines, are misaligned with generative retrieval contexts,
resulting in diminished visibility. To bridge this gap, we propose a
Role-Augmented Intent-Driven Generative Search Engine Optimization (G-SEO)
method, providing a structured optimization pathway tailored for GSE scenarios.
Our method models search intent through reflective refinement across diverse
informational roles, enabling targeted content enhancement. To better evaluate
the method under realistic settings, we address the benchmarking limitations of
prior work by: (1) extending the GEO dataset with diversified query variations
reflecting real-world search scenarios and (2) introducing G-Eval 2.0, a
6-level LLM-augmented evaluation rubric for fine-grained human-aligned
assessment. Experimental results demonstrate that search intent serves as an
effective signal for guiding content optimization, yielding significant
improvements over single-aspect baseline approaches in both subjective
impressions and objective content visibility within GSE responses.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [211] [AlphaAgents: Large Language Model based Multi-Agents for Equity Portfolio Constructions](https://arxiv.org/abs/2508.11152)
*Tianjiao Zhao,Jingrao Lyu,Stokes Jones,Harrison Garber,Stefano Pasquali,Dhagash Mehta*

Main category: q-fin.ST

TL;DR: 本研究探讨了基于大型语言模型（LLM）的角色型多智能体系统在股票选择中的应用，评估其选股表现并分析了该框架在股票分析中的优缺点及实施挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的AI代理和多智能体协作的快速发展，其在解决复杂问题上的潜力日益显现。本研究旨在探索将角色型多智能体系统应用于股票研究和投资组合管理中的股票选择，以提升效率和准确性。

Method: 构建一个由专业智能体组成的角色型多智能体系统，进行股票选择的全面分析。研究评估了该系统的选股表现，并将其与既定基准在不同风险承受水平下进行比较。此外，还分析了在股票分析中采用多智能体框架的优势和局限性。

Result: 研究展示了专业智能体团队执行的综合分析结果及其选股表现，并与既定基准进行了对比评估。此外，研究还揭示了多智能体框架在股票分析中的优势和局限性。

Conclusion: 本研究为在股票分析中部署多智能体框架的实际效用和潜在实施挑战提供了关键见解。

Abstract: The field of artificial intelligence (AI) agents is evolving rapidly, driven
by the capabilities of Large Language Models (LLMs) to autonomously perform and
refine tasks with human-like efficiency and adaptability. In this context,
multi-agent collaboration has emerged as a promising approach, enabling
multiple AI agents to work together to solve complex challenges. This study
investigates the application of role-based multi-agent systems to support stock
selection in equity research and portfolio management. We present a
comprehensive analysis performed by a team of specialized agents and evaluate
their stock-picking performance against established benchmarks under varying
levels of risk tolerance. Furthermore, we examine the advantages and
limitations of employing multi-agent frameworks in equity analysis, offering
critical insights into their practical efficacy and implementation challenges.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [212] [Deep Learning-Based Automated Segmentation of Uterine Myomas](https://arxiv.org/abs/2508.11010)
*Tausifa Jan Saleem,Mohammad Yaqub*

Main category: eess.IV

TL;DR: 子宫肌瘤MRI图像手动分割面临效率和一致性挑战，本研究利用公开数据集（UMD）建立自动化分割基线，以促进标准化评估和未来研究。


<details>
  <summary>Details</summary>
Motivation: 子宫肌瘤是常见的女性良性肿瘤，其MRI图像的精确分割对于治疗决策至关重要。然而，手动分割耗时、劳动密集且易受操作者差异影响，亟需一种准确、自动化的分割方法。现有深度学习研究多使用私有数据集，难以进行验证和比较。

Method: 本研究利用公开可用的子宫肌瘤MRI数据集（UMD），旨在建立子宫肌瘤自动化分割的基线。

Result: （抽象中未直接给出实验结果）本研究的成果是建立了一个基于UMD公共数据集的子宫肌瘤自动化分割基线，旨在实现标准化评估。

Conclusion: 建立在公共数据集上的自动化分割基线，将有助于实现子宫肌瘤分割研究的标准化评估，并为未来的深入研究提供便利。

Abstract: Uterine fibroids (myomas) are the most common benign tumors of the female
reproductive system, particularly among women of childbearing age. With a
prevalence exceeding 70%, they pose a significant burden on female reproductive
health. Clinical symptoms such as abnormal uterine bleeding, infertility,
pelvic pain, and pressure-related discomfort play a crucial role in guiding
treatment decisions, which are largely influenced by the size, number, and
anatomical location of the fibroids. Magnetic Resonance Imaging (MRI) is a
non-invasive and highly accurate imaging modality commonly used by clinicians
for the diagnosis of uterine fibroids. Segmenting uterine fibroids requires a
precise assessment of both the uterus and fibroids on MRI scans, including
measurements of volume, shape, and spatial location. However, this process is
labor intensive and time consuming and subjected to variability due to intra-
and inter-expert differences at both pre- and post-treatment stages. As a
result, there is a critical need for an accurate and automated segmentation
method for uterine fibroids. In recent years, deep learning algorithms have
shown re-markable improvements in medical image segmentation, outperforming
traditional methods. These approaches offer the potential for fully automated
segmentation. Several studies have explored the use of deep learning models to
achieve automated segmentation of uterine fibroids. However, most of the
previous work has been conducted using private datasets, which poses challenges
for validation and comparison between studies. In this study, we leverage the
publicly available Uterine Myoma MRI Dataset (UMD) to establish a baseline for
automated segmentation of uterine fibroids, enabling standardized evaluation
and facilitating future research in this domain.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [213] [SDSNN: A Single-Timestep Spiking Neural Network with Self-Dropping Neuron and Bayesian Optimization](https://arxiv.org/abs/2508.10913)
*Changqing Xu,Buxuan Song,Yi Liu,Xinfang Liao,Wenbin Zheng,Yintang Yang*

Main category: cs.NE

TL;DR: 本文提出一种单时间步脉冲神经网络（SNN），通过优化脉冲生成和时间参数（如自丢弃神经元和贝叶斯优化），解决了传统多时间步SNN在边缘计算中存在的延迟和能耗问题，在保持甚至提升精度的同时显著降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 传统的脉冲神经网络（SNNs）尽管具有事件驱动和稀疏编码带来的能效优势，但其多时间步的计算模型显著增加了推理延迟和能耗，从而限制了SNNs在边缘计算场景中的广泛应用。

Method: 研究者提出一种单时间步SNN模型。具体方法包括：1) 设计“自丢弃神经元”机制，通过动态阈值调整和选择性脉冲抑制来提升信息承载能力；2) 采用贝叶斯优化全局搜索时间参数，以实现高效的单时间步推理模式。

Result: 在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上的实验结果表明，与传统的多时间步SNN（采用LIF模型）相比，该单时间步方法分别达到了93.72%、92.20%和69.45%的分类精度，保持了相当或更优的精度。同时，能耗分别降低了56%、21%和22%。

Conclusion: 所提出的单时间步SNN有效解决了传统多时间步SNN的推理延迟和高能耗问题，通过在单个时间步内实现高精度和显著的能耗降低，极大地提升了SNN在边缘计算场景的实用性和适用性。

Abstract: Spiking Neural Networks (SNNs), as an emerging biologically inspired
computational model, demonstrate significant energy efficiency advantages due
to their event-driven information processing mechanism. Compared to traditional
Artificial Neural Networks (ANNs), SNNs transmit information through discrete
spike signals, which substantially reduces computational energy consumption
through their sparse encoding approach. However, the multi-timestep computation
model significantly increases inference latency and energy, limiting the
applicability of SNNs in edge computing scenarios. We propose a single-timestep
SNN, which enhances accuracy and reduces computational energy consumption in a
single timestep by optimizing spike generation and temporal parameters. We
design a Self-Dropping Neuron mechanism, which enhances information-carrying
capacity through dynamic threshold adjustment and selective spike suppression.
Furthermore, we employ Bayesian optimization to globally search for time
parameters and obtain an efficient inference mode with a single time step.
Experimental results on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets
demonstrate that, compared to traditional multi-timestep SNNs employing the
Leaky Integrate-and-Fire (LIF) model, our method achieves classification
accuracies of 93.72%, 92.20%, and 69.45%, respectively, using only
single-timestep spikes, while maintaining comparable or even superior accuracy.
Additionally, it reduces energy consumption by 56%, 21%, and 22%, respectively.

</details>


### [214] [Insect-Wing Structured Microfluidic System for Reservoir Computing](https://arxiv.org/abs/2508.10915)
*Jacob Clouse,Thomas Ramsey,Samitha Somathilaka,Nicholas Kleinsasser,Sangjin Ryu,Sasitharan Balasubramaniam*

Main category: cs.NE

TL;DR: 该研究探索了一种基于蜻蜓翅膀微流控芯片的储层计算系统，用于模式分类，即使在有限数据下也能达到91%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统电子设备难以满足对更高效和自适应计算的需求。微流控平台作为受自然启发的架构，为低功耗、高弹性的计算提供了有前景的替代方案，尤其适用于电子设备不适用的环境。

Method: 本研究开发了一种混合储层计算系统，其核心是一个受蜻蜓翅膀启发的微流控芯片。系统通过三个染料基入口通道将时间输入模式编码为流体相互作用，并通过摄像头监控区域将离散空间模式转换为动态颜色输出。这些输出经修改后输入到一个可训练的读出层进行模式分类。研究通过结合原始和合成储层输出来评估系统性能、清晰度和数据效率。

Result: 该系统在模式分类任务中表现出高达91%的稳定分类准确率，即使在粗糙分辨率和有限训练数据的情况下也能实现。

Conclusion: 研究结果突出了微流控储层计算的可行性，证明了其在未来计算领域的潜力。

Abstract: As the demand for more efficient and adaptive computing grows,
nature-inspired architectures offer promising alternatives to conventional
electronic designs. Microfluidic platforms, drawing on biological forms and
fluid dynamics, present a compelling foundation for low-power, high-resilience
computing in environments where electronics are unsuitable. This study explores
a hybrid reservoir computing system based on a dragonfly-wing inspired
microfluidic chip, which encodes temporal input patterns as fluid interactions
within the micro channel network.
  The system operates with three dye-based inlet channels and three
camera-monitored detection areas, transforming discrete spatial patterns into
dynamic color output signals. These reservoir output signals are then modified
and passed to a simple and trainable readout layer for pattern classification.
Using a combination of raw reservoir outputs and synthetically generated
outputs, we evaluated system performance, system clarity, and data efficiency.
The results demonstrate consistent classification accuracies up to $91\%$, even
with coarse resolution and limited training data, highlighting the viability of
the microfluidic reservoir computing.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [215] [CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems](https://arxiv.org/abs/2508.11287)
*Xuran Liu,Nan Xue,Rui Bao,Yaping Sun,Zhiyong Chen,Meixia Tao,Xiaodong Xu,Shuguang Cui*

Main category: cs.IT

TL;DR: 针对边缘设备上大语言模型部署的冷启动延迟问题，本文提出了一种延迟感知的调度框架，通过重叠模型加载与计算通信，显著降低了总推理延迟。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署大语言模型面临资源限制和按需模型加载导致的冷启动延迟，现有管道并行方法未能有效解决此问题，影响了低延迟和隐私保护AI服务的实现。

Method: 本文提出一个延迟感知的调度框架，旨在通过重叠模型加载与计算通信来最小化总推理延迟。该框架基于设备和模型参数动态调整层分区和分配，以隐藏加载时间。问题被公式化为混合整数非线性规划（MINLP），并设计了高效的动态规划算法来优化模型分区和设备分配。

Result: 实验结果表明，与基线策略相比，所提出的方法显著降低了冷启动延迟。

Conclusion: 该延迟感知调度框架通过优化模型加载与计算的重叠，成功解决了边缘设备上大语言模型的冷启动延迟问题，显著提升了分布式推理的效率。

Abstract: While deploying large language models on edge devices promises low-latency
and privacy-preserving AI services, it is hindered by limited device resources.
Although pipeline parallelism facilitates distributed inference, existing
approaches often ignore the cold-start latency caused by on-demand model
loading. In this paper, we propose a latency-aware scheduling framework that
overlaps model loading with computation and communication to minimize total
inference latency. Based on device and model parameters, the framework
dynamically adjusts layer partitioning and allocation to effectively hide
loading time, thereby eliminating as many idle periods as possible. We
formulate the problem as a Mixed-Integer Non-Linear Program and design an
efficient dynamic programming algorithm to optimize model partitioning and
device assignment. Experimental results show that the proposed method
significantly reduces cold-start latency compared to baseline strategies.

</details>


### [216] [Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks](https://arxiv.org/abs/2508.11291)
*Rui Bao,Nan Xue,Yaping Sun,Zhiyong Chen*

Main category: cs.IT

TL;DR: 本文提出一个动态路由框架，在无线边缘设备协作环境中，通过智能调度移动设备和边缘服务器上的模型，在保持LLM推理质量的同时，显著降低响应延迟和大型模型调用次数。


<details>
  <summary>Details</summary>
Motivation: 在无线边缘设备协作环境中部署LLM面临推理质量与端到端延迟之间的关键权衡。任务复杂性与资源分配之间存在根本性不匹配：简单查询卸载会引入过高延迟，而设备端模型又缺乏处理复杂计算的能力。

Method: 本文提出了一个动态、质量-延迟感知的路由框架，用于在移动设备上的轻量级模型和边缘服务器上的强大模型之间协调推理。该框架采用两种不同的成本模型：对于单轮查询，它将BERT预测的语义分数与通信和计算开销融合；对于多轮对话，它进一步量化了模型切换和KV缓存管理产生的上下文感知成本。

Result: 在保持完整推理质量的同时，大量实验表明，与MMLU、GSM8K和MT-Bench-101基准上的竞争基线相比，该框架将平均响应延迟缩短了5-15%，并将大型模型调用减少了10-20%。

Conclusion: 该动态路由框架有效解决了无线边缘环境中LLM部署的质量与延迟权衡问题，显著提升了LLM服务的效率和用户体验，而无需牺牲推理质量。

Abstract: The integration of wireless communications and Large Language Models (LLMs)
is poised to unlock ubiquitous intelligent services, yet deploying them in
wireless edge-device collaborative environments presents a critical trade-off
between inference quality and end-to-end latency. A fundamental mismatch exists
between task complexity and resource allocation: offloading simple queries
invites prohibitive latency, while on-device models lack the capacity for
demanding computations. To address this challenge, we propose a dynamic,
quality-latency aware routing framework that orchestrates inference between a
lightweight model on the mobile device and a powerful model on the edge server.
Our framework employs two distinct cost models: for single-turn queries, it
fuses a BERT-predicted semantic score with communication and computation
overheads; for multi-turn dialogues, it further quantifies context-aware costs
arising from model switching and KV-cache management. While maintaining full
inference quality, extensive experiments demonstrate that our framework cuts
average response latency by 5-15% and reduces large model invocations by 10-20%
against competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [217] [Non-asymptotic convergence bound of conditional diffusion models](https://arxiv.org/abs/2508.10944)
*Mengze Li*

Main category: stat.ML

TL;DR: 针对条件扩散模型缺乏非渐近理论性质的问题，本文提出了CARD模型，该模型创新性地整合了预训练模型f_{\phi}(x)，并从理论上推导了其随机微分方程和Fokker-Planck方程的广义形式，最终在Lipschitz等假设下，利用Wasserstein距离证明了生成分布与真实分布之间的误差上界以及分数函数估计的收敛上界。


<details>
  <summary>Details</summary>
Motivation: 尽管条件扩散模型在生成质量和加速算法方面取得了显著进展，但其非渐近性质的缺失阻碍了进一步的理论研究。

Method: 1. 提出了CARD（Conditional Diffusion model within the domains of Classification and Regression）模型，旨在学习给定输入x的原始分布Y|X。
2. 创新性地将预训练模型f_{\phi}(x)集成到原始扩散模型框架中，以精确捕获条件分布Y|f_{\phi}(x)。
3. 理论上，推导了CARD的随机微分方程（SDEs），并基于Fokker-Planck方程建立了其广义形式。
4. 主要在Lipschitz假设下，利用二阶Wasserstein距离证明了原始与生成条件分布间的误差上界。
5. 通过附加轻尾性等假设，推导了分数函数真实值与网络估计值之间的收敛上界。

Result: 1. 当预训练模型f_{\phi}(x)表现良好时，Y|f_{\phi}(x)能很好地近似Y|X。
2. 为CARD模型建立了坚实的理论基础，包括其SDEs和基于Fokker-Planck方程的广义形式。
3. 在Lipschitz假设下，通过二阶Wasserstein距离，量化了原始与生成条件分布间的误差上界。
4. 在特定假设（如轻尾性）下，得到了分数函数真实值与对应网络估计值之间的收敛上界。

Conclusion: 1. CARD模型通过整合预训练模型，为条件扩散模型的理论分析提供了新视角。
2. 本文为条件扩散模型（CARD）提供了严格的理论基础，填补了非渐近性质研究的空白。
3. 研究结果通过理论证明量化了生成质量和估计精度，为条件扩散模型的可靠性提供了理论支撑。

Abstract: Learning and generating various types of data based on conditional diffusion
models has been a research hotspot in recent years. Although conditional
diffusion models have made considerable progress in improving acceleration
algorithms and enhancing generation quality, the lack of non-asymptotic
properties has hindered theoretical research. To address this gap, we focus on
a conditional diffusion model within the domains of classification and
regression (CARD), which aims to learn the original distribution with given
input x (denoted as Y|X). It innovatively integrates a pre-trained model
f_{\phi}(x) into the original diffusion model framework, allowing it to
precisely capture the original conditional distribution given f (expressed as
Y|f_{\phi}(x)). Remarkably, when f_{\phi}(x) performs satisfactorily,
Y|f_{\phi}(x) closely approximates Y|X. Theoretically, we deduce the stochastic
differential equations of CARD and establish its generalized form predicated on
the Fokker-Planck equation, thereby erecting a firm theoretical foundation for
analysis. Mainly under the Lipschitz assumptions, we utilize the second-order
Wasserstein distance to demonstrate the upper error bound between the original
and the generated conditional distributions. Additionally, by appending
assumptions such as light-tailedness to the original distribution, we derive
the convergence upper bound between the true value analogous to the score
function and the corresponding network-estimated value.

</details>


### [218] [Counterfactual Survival Q Learning for Longitudinal Randomized Trials via Buckley James Boosting](https://arxiv.org/abs/2508.11060)
*Jeongjin Lee,Jong-Min Kim*

Main category: stat.ML

TL;DR: 提出一种基于Buckley James (BJ) Boost Q学习框架，用于在右删失生存数据下估计最优动态治疗方案，在多阶段临床试验中展现出更高的决策准确性。


<details>
  <summary>Details</summary>
Motivation: 在纵向随机临床试验中，需要为右删失生存数据估计最优动态治疗方案。现有基于Cox模型的Q学习方法依赖限制性的比例风险假设，且在模型设定错误时易产生偏差，亟需一种能直接建模条件生存时间、避免比例风险假设的无偏估计方法。

Method: 提出Buckley James (BJ) Boost Q学习框架。该方法在反事实Q学习范式中，整合加速失效时间（AFT）模型与迭代Boosting技术（包括分量最小二乘和回归树）。通过直接建模条件生存时间来避免比例风险假设，并在潜在结果框架下确保最优治疗方案的可识别性。

Result: 该方法提供了鲁棒且灵活的估计，并实现了阶段性Q函数的无偏估计。模拟研究和对ACTG175 HIV试验的分析表明，BJ Boost Q学习在治疗决策制定中具有更高的准确性，尤其是在偏差易累积的多阶段环境中表现优异。

Conclusion: BJ Boost Q学习框架为右删失生存数据下的最优动态治疗方案估计提供了一种优越且准确的方法。它通过避免比例风险假设和提供无偏估计，成功克服了传统基于Cox模型Q学习的局限性，在临床试验背景下具有重要应用价值。

Abstract: We propose a Buckley James (BJ) Boost Q learning framework for estimating
optimal dynamic treatment regimes under right censored survival data, tailored
for longitudinal randomized clinical trial settings. The method integrates
accelerated failure time models with iterative boosting techniques, including
componentwise least squares and regression trees, within a counterfactual Q
learning framework. By directly modeling conditional survival time, BJ Boost Q
learning avoids the restrictive proportional hazards assumption and enables
unbiased estimation of stage specific Q functions. Grounded in potential
outcomes, this framework ensures identifiability of the optimal treatment
regime under standard causal assumptions. Compared to Cox based Q learning,
which relies on hazard modeling and may suffer from bias under
misspecification, our approach provides robust and flexible estimation.
Simulation studies and analysis of the ACTG175 HIV trial demonstrate that BJ
Boost Q learning yields higher accuracy in treatment decision making,
especially in multistage settings where bias can accumulate.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [219] [Note on Selection Bias in Observational Estimates of Algorithmic Progress](https://arxiv.org/abs/2508.11033)
*Parker Whitfill*

Main category: econ.GN

TL;DR: 本文指出Ho et al. (2024) 估算语言模型算法进步的方法存在潜在偏差，认为其未考虑潜在算法质量和内生性计算选择。


<details>
  <summary>Details</summary>
Motivation: 对Ho et al. (2024) 估算语言模型算法进步的方法论问题提出质疑，指出其可能导致估计偏差。

Method: 通过理论分析Ho et al. 的估算策略，假设算法质量部分是潜在的且计算选择与算法质量内生相关，以此来论证潜在偏差。

Result: 研究结果是，如果算法质量是潜在的且计算选择是内生的，Ho et al. 估算的算法质量将存在偏差。

Conclusion: Ho et al. 估算的语言模型算法进步程度可能因方法学上的缺陷（即未考虑潜在变量和内生性）而存在偏差。

Abstract: Ho et. al (2024) is an interesting paper that attempts to estimate the degree
of algorithmic progress from language models. They collect observational data
on language models' loss and compute over time, and argue that as time has
passed, language models' algorithmic efficiency has been rising. That is, the
loss achieved for fixed compute has been dropping over time. In this note, I
want to raise one potential methodological problem with the estimation
strategy. Intuitively, if part of algorithmic quality is latent, and compute
choices are endogenous to algorithmic quality, then resulting estimates of
algorithmic quality will be biased.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [220] [Multimodal Quantitative Measures for Multiparty Behaviour Evaluation](https://arxiv.org/abs/2508.10916)
*Ojas Shirekar,Wim Pouw,Chenxu Hao,Vrushank Phadnis,Thabo Beeler,Chirag Raman*

Main category: cs.HC

TL;DR: 本文提出一个统一的、干预驱动的框架，用于客观评估多方交互中数字人的社交行为，通过引入同步性、时间对齐和结构相似性等指标，形成了一个评估和完善社交智能体的强大工具包。


<details>
  <summary>Details</summary>
Motivation: 现有评估数字人在多方交互中社交行为的指标，未能充分考虑情境协调动态，导致评估不足。

Method: 引入一个统一的、干预驱动的框架，通过骨骼运动数据客观评估多方社交行为。该框架包含三个互补维度：使用交叉递归量化分析（CRQA）评估同步性、基于多尺度经验模态分解的节拍一致性评估时间对齐、使用软动态时间规整（Soft DTW）评估结构相似性。通过对DnD数据集应用三种理论驱动的扰动（手势运动学阻尼、统一语音-手势延迟、韵律音高变化减少）验证了度量敏感性，并进行了一项感知研究。

Result: 混合效应分析揭示了可预测的、独立于关节的变化：阻尼增加了CRQA确定性并降低了节拍一致性，延迟削弱了参与者间的耦合，音高平坦化提高了F0 Soft-DTW成本。补充性感知研究量化了表征效应。

Conclusion: 所提出的三项度量提供了对空间结构、时间对齐和行为变异性的正交洞察，形成了一个评估和完善社交智能体的强大工具包。

Abstract: Digital humans are emerging as autonomous agents in multiparty interactions,
yet existing evaluation metrics largely ignore contextual coordination
dynamics. We introduce a unified, intervention-driven framework for objective
assessment of multiparty social behaviour in skeletal motion data, spanning
three complementary dimensions: (1) synchrony via Cross-Recurrence
Quantification Analysis, (2) temporal alignment via Multiscale Empirical Mode
Decompositionbased Beat Consistency, and (3) structural similarity via Soft
Dynamic Time Warping. We validate metric sensitivity through three
theory-driven perturbations -- gesture kinematic dampening, uniform
speech-gesture delays, and prosodic pitch-variance reduction-applied to
$\approx 145$ 30-second thin slices of group interactions from the DnD dataset.
Mixed-effects analyses reveal predictable, joint-independent shifts: dampening
increases CRQA determinism and reduces beat consistency, delays weaken
cross-participant coupling, and pitch flattening elevates F0 Soft-DTW costs. A
complementary perception study ($N=27$) compares judgments of full-video and
skeleton-only renderings to quantify representation effects. Our three measures
deliver orthogonal insights into spatial structure, timing alignment, and
behavioural variability. Thereby forming a robust toolkit for evaluating and
refining socially intelligent agents. Code available on
\href{https://github.com/tapri-lab/gig-interveners}{GitHub}.

</details>


### [221] [Managing the unexpected: Operator behavioural data and its value in predicting correct alarm responses](https://arxiv.org/abs/2508.10917)
*Chidera W. Amazu,Joseph Mietkiewicz,Ammar N. Abbas,Gabriele Baldissone,Davide Fissore,Micaela Demichela,Anders L. Madsen,Maria Chiara Leva*

Main category: cs.HC

TL;DR: 本研究探讨使用分布式控制系统(DCS)中的实时过程和操作员系统交互数据，来分析操作员行为并预测其在异常情况下的响应结果，作为侵入式生理测量方法的替代方案。


<details>
  <summary>Details</summary>
Motivation: 心理生理测量虽能提供洞察，但可穿戴工具具侵入性，不适合日常操作。因此，需要一种非侵入式方法，利用现有系统数据来理解操作员行为和预测响应，尤其是在应对关键警报场景时。

Method: 研究使用甲醛生产装置模拟器，通过实验设计和四种人机回路实验配置获取数据。采用逐步逻辑回归和贝叶斯网络模型进行分析，以比较不同配置下的行为和性能。

Result: 研究识别出一些可预测的操作员行为指标，并讨论了它们作为警报响应场景中整体系统性能前兆或预测指标的价值。

Conclusion: 实时可获取且具有预测性的行为指标，能更好地帮助决策者预测结果并及时为操作员提供支持措施，从而提升系统在警报响应场景下的整体性能。

Abstract: Data from psychophysiological measures can offer new insight into control
room operators' behaviour, cognition, and mental workload status. This can be
particularly helpful when combined with appraisal of capacity to respond to
possible critical plant conditions (i.e. critical alarms response scenarios).
However, wearable physiological measurement tools such as eye tracking and EEG
caps can be perceived as intrusive and not suitable for usage in daily
operations. Therefore, this article examines the potential of using real-time
data from process and operator-system interactions during abnormal scenarios
that can be recorded and retrieved from the distributed control system's
historian or process log, and their capacity to provide insight into operator
behavior and predict their response outcomes, without intruding on daily tasks.
Data for this study were obtained from a design of experiment using a
formaldehyde production plant simulator and four human-in-the-loop experimental
support configurations. A comparison between the different configurations in
terms of both behaviour and performance is presented in this paper. A step-wise
logistic regression and a Bayesian network models were used to achieve this
objective. The results identified some predictive metrics and the paper discuss
their value as precursor or predictor of overall system performance in alarm
response scenarios. Knowledge of relevant and predictive behavioural metrics
accessible in real time can better equip decision-makers to predict outcomes
and provide timely support measures for operators.

</details>


### [222] [Human-AI collaboration or obedient and often clueless AI in instruct, serve, repeat dynamics?](https://arxiv.org/abs/2508.10919)
*Mohammed Saqr,Kamila Misiejuk,Sonsoles López-Pernas*

Main category: cs.HC

TL;DR: 研究发现，在复杂认知任务中，当前大语言模型（LLMs）主要以指令遵循模式与人类交互，而非真正的协同合作，导致缺乏协同效应。这表明LLMs作为认知伙伴的能力有限，提示未来AI设计需更注重认知对齐和协作。


<details>
  <summary>Details</summary>
Motivation: 现有的人机协作研究多集中在语言学习领域，且多采用传统计数方法，较少关注在认知要求高的任务中协作的演变和动态性。本研究旨在填补此空白，深入探讨人类与AI在解决复杂问题时的交互行为。

Method: 本研究对学生与AI的交互进行了定性编码，并运用多种定量分析方法，包括转换网络分析、序列分析、偏相关网络、卡方检验以及Person残差阴影马赛克图，以映射交互模式、其演变过程及其与问题复杂度和学生表现的关系。

Result: 研究揭示了一种主导的“指令式”交互模式，其特点是迭代式命令而非协作性协商。学生与AI的交互中常出现提示与AI输出错位的情况，表现出协同不足，这挑战了LLMs作为协作伙伴的普遍假设。此外，作业复杂性、提示长度与学生成绩之间无显著相关性，暗示缺乏认知深度或问题难度影响。

Conclusion: 研究表明，当前的LLMs主要针对指令遵循而非认知伙伴关系进行优化，这限制了它们作为认知刺激或对齐的协作者的能力。因此，未来设计AI系统时，应优先考虑促进认知对齐和真正的协作。

Abstract: While research on human-AI collaboration exists, it mainly examined language
learning and used traditional counting methods with little attention to
evolution and dynamics of collaboration on cognitively demanding tasks. This
study examines human-AI interactions while solving a complex problem.
Student-AI interactions were qualitatively coded and analyzed with transition
network analysis, sequence analysis and partial correlation networks as well as
comparison of frequencies using chi-square and Person-residual shaded Mosaic
plots to map interaction patterns, their evolution, and their relationship to
problem complexity and student performance. Findings reveal a dominant
Instructive pattern with interactions characterized by iterative ordering
rather than collaborative negotiation. Oftentimes, students engaged in long
threads that showed misalignment between their prompts and AI output that
exemplified a lack of synergy that challenges the prevailing assumptions about
LLMs as collaborative partners. We also found no significant correlations
between assignment complexity, prompt length, and student grades suggesting a
lack of cognitive depth, or effect of problem difficulty. Our study indicates
that the current LLMs, optimized for instruction-following rather than
cognitive partnership, compound their capability to act as cognitively
stimulating or aligned collaborators. Implications for designing AI systems
that prioritize cognitive alignment and collaboration are discussed.

</details>


### [223] [AI That Helps Us Help Each Other: A Proactive System for Scaffolding Mentor-Novice Collaboration in Entrepreneurship Coaching](https://arxiv.org/abs/2508.11052)
*Evey Jiaxin Huang,Matthew Easterday,Elizabeth Gerber*

Main category: cs.HC

TL;DR: 本文提出一个结合领域认知模型和大语言模型的人工智能教练系统，旨在支持新手创业者的元认知和导师的指导，并通过实地部署验证了其在提升会议质量和双方思维方面的有效性，并探讨了AI信任等关键问题。


<details>
  <summary>Details</summary>
Motivation: 创业者面临开放、定义不清的问题，需在不确定性下识别风险、挑战假设并做决策；新手常难以应对这些元认知需求，而导师因时间有限和缺乏可见性难以提供定制化支持。

Method: 开发了一个人机协作的AI教练系统，该系统结合了创业风险的领域特定认知模型和大型语言模型（LLM），主动提出诊断性问题挑战新手思维，并帮助新手和导师规划更专注、情感协调的会议。导师可检查并修改底层认知模型，以适应其不断变化的需求。

Result: 通过探索性实地部署发现，该系统支持了新手的元认知，帮助导师规划了情感协调的策略，提升了会议的深度、目的性和专注度；同时也揭示了围绕信任、误诊和对AI期望的关键问题。

Conclusion: 研究为在复杂、定义不清领域（如医疗、教育、知识工作）中促进元认知和人际协作的主动式AI系统提供了设计原则和启示。

Abstract: Entrepreneurship requires navigating open-ended, ill-defined problems:
identifying risks, challenging assumptions, and making strategic decisions
under deep uncertainty. Novice founders often struggle with these metacognitive
demands, while mentors face limited time and visibility to provide tailored
support. We present a human-AI coaching system that combines a domain-specific
cognitive model of entrepreneurial risk with a large language model (LLM) to
proactively scaffold both novice and mentor thinking. The system proactively
poses diagnostic questions that challenge novices' thinking and helps both
novices and mentors plan for more focused and emotionally attuned meetings.
Critically, mentors can inspect and modify the underlying cognitive model,
shaping the logic of the system to reflect their evolving needs. Through an
exploratory field deployment, we found that using the system supported novice
metacognition, helped mentors plan emotionally attuned strategies, and improved
meeting depth, intentionality, and focus--while also surfaced key tensions
around trust, misdiagnosis, and expectations of AI. We contribute design
principles for proactive AI systems that scaffold metacognition and human-human
collaboration in complex, ill-defined domains, offering implications for
similar domains like healthcare, education, and knowledge work.

</details>


### [224] [Uncovering Latent Connections in Indigenous Heritage: Semantic Pipelines for Cultural Preservation in Brazil](https://arxiv.org/abs/2508.10911)
*Luis Vitor Zerkowski,Nina S. T. Hirata*

Main category: cs.HC

TL;DR: 本研究利用AI增强巴西原住民文化数字藏品的可访问性、解释性和探索性。


<details>
  <summary>Details</summary>
Motivation: 原住民社区在系统性边缘化和城市化进程中面临文化遗产保护挑战；旨在提升巴西国家原住民博物馆在线藏品的可访问性与利用效率。

Method: 基于博物馆公开数据，开发了数据驱动的AI解决方案，包括：一个建模图像相似性的视觉语义管道和一个捕捉描述语义关系的文本语义管道。这些嵌入空间被投射到二维，并整合到一个交互式可视化工具中，支持相似性、时间、地理等多维度探索。

Result: 开发的系统提供了基于相似性的导航，允许用户通过时间、地理维度探索藏品，实现了语义和语境化的视角。该系统支持策展任务、促进公众参与，并揭示了藏品中潜在的联系。

Conclusion: 本研究展示了人工智能如何能以符合伦理的方式，有效促进文化遗产保护实践。

Abstract: Indigenous communities face ongoing challenges in preserving their cultural
heritage, particularly in the face of systemic marginalization and urban
development. In Brazil, the Museu Nacional dos Povos Indigenas through the
Tainacan platform hosts the country's largest online collection of Indigenous
objects and iconographies, providing a critical resource for cultural
engagement. Using publicly available data from this repository, we present a
data-driven initiative that applies artificial intelligence to enhance
accessibility, interpretation, and exploration. We develop two semantic
pipelines: a visual pipeline that models image-based similarity and a textual
pipeline that captures semantic relationships from item descriptions. These
embedding spaces are projected into two dimensions and integrated into an
interactive visualization tool we also developed. In addition to
similarity-based navigation, users can explore the collection through temporal
and geographic lenses, enabling both semantic and contextualized perspectives.
The system supports curatorial tasks, aids public engagement, and reveals
latent connections within the collection. This work demonstrates how AI can
ethically contribute to cultural preservation practices.

</details>


### [225] [Is General-Purpose AI Reasoning Sensitive to Data-Induced Cognitive Biases? Dynamic Benchmarking on Typical Software Engineering Dilemmas](https://arxiv.org/abs/2508.11278)
*Francesco Sovrano,Gabriele Dominici,Rita Sevastjanova,Alessandra Stramiglio,Alberto Bacchelli*

Main category: cs.HC

TL;DR: 研究发现通用AI系统（GPAI）在软件工程任务中表现出显著的认知偏差，且偏差敏感性随任务复杂度增加而加剧，对实际部署构成风险。


<details>
  <summary>Details</summary>
Motivation: 人类认知偏差是软件工程中错误的重要来源，而通用AI系统（GPAI）可能有助于缓解这些偏差。然而，由于GPAI系统是在人类生成的数据上训练的，其自身是否也存在认知偏差是一个关键问题，本研究旨在探究这一点。

Method: 开发了首个动态基准测试框架，用于评估GPAI在软件工程工作流中的数据诱导认知偏差。框架包含16个手工设计的任务，涵盖8种认知偏差。同时，构建了一个按需任务增强管道，利用GPAI生成大量任务变体，以确保真实性、多样性和推理复杂度的可控性。该方法还验证了嵌入式偏差的有害性及其对基于逻辑的无偏差推理器的不可检测性。最终，使用该框架评估了主流GPAI系统（如GPT、LLaMA、DeepSeek）。

Result: 评估发现所有被测试的GPAI系统都表现出认知偏差（偏差范围从5.9%到35%），它们倾向于依赖浅层语言启发而非深度推理。此外，偏差敏感性随着任务复杂度的增加而急剧上升（最高达49%）。

Conclusion: GPAI系统在软件工程领域表现出的认知偏差，尤其是在面对复杂任务时偏差敏感性的增加，揭示了在实际软件工程部署中存在的关键风险。

Abstract: Human cognitive biases in software engineering can lead to costly errors.
While general-purpose AI (GPAI) systems may help mitigate these biases due to
their non-human nature, their training on human-generated data raises a
critical question: Do GPAI systems themselves exhibit cognitive biases?
  To investigate this, we present the first dynamic benchmarking framework to
evaluate data-induced cognitive biases in GPAI within software engineering
workflows. Starting with a seed set of 16 hand-crafted realistic tasks, each
featuring one of 8 cognitive biases (e.g., anchoring, framing) and
corresponding unbiased variants, we test whether bias-inducing linguistic cues
unrelated to task logic can lead GPAI systems from correct to incorrect
conclusions.
  To scale the benchmark and ensure realism, we develop an on-demand
augmentation pipeline relying on GPAI systems to generate task variants that
preserve bias-inducing cues while varying surface details. This pipeline
ensures correctness (88--99% on average, according to human evaluation),
promotes diversity, and controls reasoning complexity by leveraging
Prolog-based reasoning and LLM-as-a-judge validation. It also verifies that the
embedded biases are both harmful and undetectable by logic-based, unbiased
reasoners.
  We evaluate leading GPAI systems (GPT, LLaMA, DeepSeek) and find a consistent
tendency to rely on shallow linguistic heuristics over deep reasoning. All
systems exhibit cognitive biases (ranging from 5.9% to 35% across types), with
bias sensitivity increasing sharply with task complexity (up to 49%),
highlighting critical risks in real-world software engineering deployments.

</details>


### [226] [Human-in-the-Loop Systems for Adaptive Learning Using Generative AI](https://arxiv.org/abs/2508.11062)
*Bhavishya Tarun,Haoze Du,Dinesh Kannan,Edward F. Gehringer*

Main category: cs.HC

TL;DR: 一种人机协作（HITL）方法，通过整合学生反馈，利用生成式AI提升个性化学习。


<details>
  <summary>Details</summary>
Motivation: 旨在通过整合学生反馈，增强个性化学习效果，促进学生深度参与和理解，并提高学习留存率和参与度，尤其是在STEM教育领域。

Method: 采用人机协作（HITL）方法，学生使用预定义反馈标签批评和修改AI响应。系统利用标签技术、提示工程和检索增强生成（RAG）系统，实时个性化内容并调整解释。

Result: 初步研究表明，与传统AI工具相比，STEM学生的学习成果和自信心有所提高。

Conclusion: 本研究突出了AI通过迭代优化创建动态、反馈驱动和个性化学习环境的潜力。

Abstract: A Human-in-the-Loop (HITL) approach leverages generative AI to enhance
personalized learning by directly integrating student feedback into
AI-generated solutions. Students critique and modify AI responses using
predefined feedback tags, fostering deeper engagement and understanding. This
empowers students to actively shape their learning, with AI serving as an
adaptive partner. The system uses a tagging technique and prompt engineering to
personalize content, informing a Retrieval-Augmented Generation (RAG) system to
retrieve relevant educational material and adjust explanations in real time.
This builds on existing research in adaptive learning, demonstrating how
student-driven feedback loops can modify AI-generated responses for improved
student retention and engagement, particularly in STEM education. Preliminary
findings from a study with STEM students indicate improved learning outcomes
and confidence compared to traditional AI tools. This work highlights AI's
potential to create dynamic, feedback-driven, and personalized learning
environments through iterative refinement.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [227] [FLUID: Flow-Latent Unified Integration via Token Distillation for Expert Specialization in Multimodal Learning](https://arxiv.org/abs/2508.07264)
*Van Duc Cuong,Ta Dinh Tam,Tran Duc Chinh,Nguyen Thi Hanh*

Main category: cs.SI

TL;DR: 本文提出FLUID，一个基于token的流水线，用于增强多模态分类的鲁棒性和可扩展性。它通过Q-transforms、两阶段融合方案和专家混合模型实现，在GLAMI-1M基准上表现卓越，并对噪声和不平衡数据具有强大的抵抗力。


<details>
  <summary>Details</summary>
Motivation: 多模态分类需要鲁棒地整合视觉和文本信号，但现有的融合策略脆弱且容易受到模态特定噪声的影响。

Method: FLUID（Flow-Latent Unified Integration via Token Distillation for Expert Specialization）包含三个核心要素：1. Q-transforms：可学习的查询token，用于从模态特定骨干网络中提炼和保留显著的token级特征。2. 两阶段融合方案：通过对比对齐强制执行跨模态一致性，然后通过门控机制和Q-bottleneck执行自适应、任务感知的融合。3. 轻量级、负载均衡的专家混合（Mixture-of-Experts）：在预测时实现对不同语义模式的有效特化。

Result: FLUID在GLAMI-1M基准上达到了91%的准确率，显著优于现有基线，并表现出对标签噪声、长尾类别不平衡和语义异质性的强大弹性。消融研究证实了所提出组件的独立和协同效益。

Conclusion: FLUID是一种可扩展、抗噪声的多模态产品分类解决方案，其提出的组件展现出显著的独立和协同优势。

Abstract: Multimodal classification requires robust integration of visual and textual
signals, yet common fusion strategies are brittle and vulnerable to
modality-specific noise. In this paper, we present \textsc{FLUID}-Flow-Latent
Unified Integration via Token Distillation for Expert Specialization, a
principled token-level pipeline that improves cross-modal robustness and
scalability. \textsc{FLUID} contributes three core elements: (1)
\emph{Q-transforms}, learnable query tokens that distill and retain salient
token-level features from modality-specific backbones; (2) a two-stage fusion
scheme that enforces cross-modal consistency via contrastive alignment and then
performs adaptive, task-aware fusion through a gating mechanism and a
\emph{Q-bottleneck} that selectively compresses information for downstream
reasoning; and (3) a lightweight, load-balanced Mixture-of-Experts at
prediction time that enables efficient specialization to diverse semantic
patterns. Extensive experiments demonstrate that \textsc{FLUID} attains
\(91\%\) accuracy on the GLAMI-1M benchmark, significantly outperforming prior
baselines and exhibiting strong resilience to label noise, long-tail class
imbalance, and semantic heterogeneity. Targeted ablation studies corroborate
both the individual and synergistic benefits of the proposed components,
positioning \textsc{FLUID} as a scalable, noise-resilient solution for
multimodal product classification.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [228] [Diffusion is a code repair operator and generator](https://arxiv.org/abs/2508.11110)
*Mukul Singh,Gust Verbruggen,Vu Le,Sumit Gulwani*

Main category: cs.SE

TL;DR: 本文探讨如何利用代码扩散模型进行“最后一英里修复”及生成相关训练数据，利用其后期去噪过程与代码修复的相似性。


<details>
  <summary>Details</summary>
Motivation: 发现代码扩散模型在后期去噪时，其离散表示的变化类似于对损坏或不完整代码进行的“最后一英里修复”，故旨在评估这种相似性在实际代码修复问题中的利用潜力。

Method: 1. 通过对损坏代码片段添加噪声并恢复扩散过程，直接利用扩散模型进行“最后一英里修复”。2. 通过从扩散过程中采样中间程序（输入）和最终程序（输出），利用扩散模型为“最后一英里修复”任务生成训练数据。

Result: 在Python、Excel和PowerShell三个领域进行了实验，以评估上述应用的有效性并分析相关属性。

Conclusion: 研究表明，代码扩散模型能够被有效利用于代码的“最后一英里修复”任务，并能作为高效生成修复任务训练数据的工具，具有重要的应用潜力。

Abstract: Code diffusion models generate code by iteratively removing noise from the
latent representation of a code snippet. During later steps of the diffusion
process, when the code snippet has almost converged, differences between
discrete representations of these snippets look like last-mile repairs applied
to broken or incomplete code. We evaluate the extent to which this resemblance
can be exploited to leverage pre-trained code diffusion models for the problem
of last-mile repair by considering two applications with significant potential.
First, we can leverage the diffusion model for last-mile repair by adding noise
to a broken code snippet and resuming the diffusion process. Second, we can
leverage the diffusion model to generate arbitrary amount of training data for
last-mile repair tasks (that are computationally more efficient) by sampling an
intermediate program (input) and the final program (output) from the diffusion
process. We perform experiments on 3 domains (Python, Excel and PowerShell) to
evaluate applications, as well as analyze properties.

</details>


### [229] [ORFuzz: Fuzzing the "Other Side" of LLM Safety -- Testing Over-Refusal](https://arxiv.org/abs/2508.11222)
*Haonan Zhang,Dongxia Wang,Yi Liu,Kexin Chen,Jiashui Wang,Xinlei Ying,Long Liu,Wenhai Wang*

Main category: cs.SE

TL;DR: 大型语言模型（LLMs）存在过度拒绝良性查询的问题。本文提出首个进化测试框架ORFuzz及其生成的基准数据集ORFuzzSet，有效检测并量化LLM的过度拒绝行为，旨在提升模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）日益表现出“过度拒绝”这一关键性功能缺陷，即错误地拒绝良性查询，这严重损害了其可靠性和可用性。现有测试方法因基准缺陷和测试生成能力有限而无法有效检测此行为。

Method: 本文提出ORFuzz，一个用于系统检测和分析LLM过度拒绝的首个进化测试框架。ORFuzz独特地整合了三个核心组件：1) 安全类别感知的种子选择，以实现全面的测试覆盖；2) 利用推理型LLMs进行自适应变异器优化，以生成有效的测试用例；3) OR-Judge，一个经验证能准确反映用户对内容毒性和拒绝感知的类人判断模型。

Result: 广泛评估表明，ORFuzz生成的多种过度拒绝实例的平均检出率（6.98%）是领先基线的两倍多，有效揭示了漏洞。此外，ORFuzz的输出形成了ORFuzzSet，一个包含1,855个高度可迁移测试用例的新基准，在10个不同LLMs上实现了63.56%的平均过度拒绝率，显著优于现有数据集。

Conclusion: ORFuzz和ORFuzzSet提供了一个强大的自动化测试框架和宝贵的社区资源，为开发更可靠、更值得信赖的基于LLM的软件系统铺平了道路。

Abstract: Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously
rejecting benign queries due to overly conservative safety measures - a
critical functional flaw that undermines their reliability and usability.
Current methods for testing this behavior are demonstrably inadequate,
suffering from flawed benchmarks and limited test generation capabilities, as
highlighted by our empirical user study. To the best of our knowledge, this
paper introduces the first evolutionary testing framework, ORFuzz, for the
systematic detection and analysis of LLM over-refusals. ORFuzz uniquely
integrates three core components: (1) safety category-aware seed selection for
comprehensive test coverage, (2) adaptive mutator optimization using reasoning
LLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge
model validated to accurately reflect user perception of toxicity and refusal.
Our extensive evaluations demonstrate that ORFuzz generates diverse, validated
over-refusal instances at a rate (6.98% average) more than double that of
leading baselines, effectively uncovering vulnerabilities. Furthermore,
ORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly
transferable test cases that achieves a superior 63.56% average over-refusal
rate across 10 diverse LLMs, significantly outperforming existing datasets.
ORFuzz and ORFuzzSet provide a robust automated testing framework and a
valuable community resource, paving the way for developing more reliable and
trustworthy LLM-based software systems.

</details>


### [230] [Hallucination in LLM-Based Code Generation: An Automotive Case Study](https://arxiv.org/abs/2508.11257)
*Marc Pavel,Nenad Petrovic,Lukasz Mazur,Vahid Zolfaghari,Fengjunjie Pan,Alois Knoll*

Main category: cs.SE

TL;DR: 本研究调查了大型语言模型（LLMs）在汽车领域代码生成中的幻觉现象，发现即使是先进模型也存在高频错误，仅在提供丰富上下文时才能生成正确代码，强调了缓解技术的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在自动化代码生成方面潜力巨大，但其幻觉（生成看似合理但错误或无意义的输出）限制了其实际应用。本研究旨在深入探讨LLMs在汽车领域代码生成中的幻觉问题。

Method: 采用案例研究方法，评估了多个代码LLMs在三种不同提示复杂度下的表现：从极简提示，到增加Covesa车辆信号规范（VSS）作为上下文，再到进一步增加代码骨架。评估模型包括GPT-4.1、Codex和GPT-4o。

Result: 评估发现，最先进的模型（如GPT-4.1、Codex和GPT-4o）存在高频的语法违规、无效引用错误和API知识冲突。仅当提供最丰富的上下文时，GPT-4.1和GPT-4o才能够生成正确的解决方案。简单的提示策略即使经过多次迭代也未能产生可用结果。

Conclusion: 研究结果强调，为确保LLM生成的代码在安全关键领域（如汽车软件系统）中安全可靠地使用，急需开发有效的幻觉缓解技术。

Abstract: Large Language Models (LLMs) have shown significant potential in automating
code generation tasks offering new opportunities across software engineering
domains. However, their practical application remains limited due to
hallucinations - outputs that appear plausible but are factually incorrect,
unverifiable or nonsensical. This paper investigates hallucination phenomena in
the context of code generation with a specific focus on the automotive domain.
A case study is presented that evaluates multiple code LLMs for three different
prompting complexities ranging from a minimal one-liner prompt to a prompt with
Covesa Vehicle Signal Specifications (VSS) as additional context and finally to
a prompt with an additional code skeleton. The evaluation reveals a high
frequency of syntax violations, invalid reference errors and API knowledge
conflicts in state-of-the-art models GPT-4.1, Codex and GPT-4o. Among the
evaluated models, only GPT-4.1 and GPT-4o were able to produce a correct
solution when given the most context-rich prompt. Simpler prompting strategies
failed to yield a working result, even after multiple refinement iterations.
These findings highlight the need for effective mitigation techniques to ensure
the safe and reliable use of LLM generated code, especially in safety-critical
domains such as automotive software systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [231] [Risk-Based Prognostics and Health Management](https://arxiv.org/abs/2508.11031)
*John W. Sheppard*

Main category: eess.SY

TL;DR: 提出一种基于风险的预诊方法，利用连续时间贝叶斯网络紧密结合风险评估与故障预测，并探讨其在决策支持和性能物流中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统的风险评估和故障预测常被视为独立任务，本研究旨在实现两者更紧密的耦合。

Method: 采用基于风险的预诊方法，以连续时间贝叶斯网络（CTBN）作为底层建模框架，并概述了从数据中推导模型的技术。

Result: 展示了如何利用CTBN实现风险评估与故障预测的紧密耦合，并说明该方法可应用于决策支持和基于性能的物流等实际任务。

Conclusion: 本工作旨在概述基于风险的预诊领域的最新发展，并作为教程协助他人采用这些技术。

Abstract: It is often the case that risk assessment and prognostics are viewed as
related but separate tasks. This chapter describes a risk-based approach to
prognostics that seeks to provide a tighter coupling between risk assessment
and fault prediction. We show how this can be achieved using the
continuous-time Bayesian network as the underlying modeling framework.
Furthermore, we provide an overview of the techniques that are available to
derive these models from data and show how they might be used in practice to
achieve tasks like decision support and performance-based logistics. This work
is intended to provide an overview of the recent developments related to
risk-based prognostics, and we hope that it will serve as a tutorial of sorts
that will assist others in adopting these techniques.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [232] [StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation](https://arxiv.org/abs/2508.11203)
*Seungmi Lee,Kwan Yun,Junyong Noh*

Main category: cs.GR

TL;DR: 新框架StyleMM，能依据用户文本描述构建风格化3DMM。


<details>
  <summary>Details</summary>
Motivation: 旨在解决通过文本描述生成风格化3DMM时，现有方法难以保持面部属性（如身份、表情）一致性的问题。

Method: 基于预训练的网格变形和纹理生成网络，利用扩散模型通过文本引导图像到图像（i2i）生成风格化图像作为训练目标。引入一种显式保留面部属性的风格化方法，对模型进行微调，以确保在3DMM参数空间内实现一致的3D风格迁移。

Result: 训练后的模型可前向生成具有形状、表情和纹理参数显式控制的风格化人脸网格，保持顶点连接性和可动画性。定量和定性评估显示，该方法在身份层面的人脸多样性和风格化能力方面优于现有最先进的方法。

Conclusion: StyleMM成功实现了通过文本描述构建高质量、可控且保持面部属性一致性的风格化3DMM，并在性能上超越了现有技术。

Abstract: We introduce StyleMM, a novel framework that can construct a stylized 3D
Morphable Model (3DMM) based on user-defined text descriptions specifying a
target style. Building upon a pre-trained mesh deformation network and a
texture generator for original 3DMM-based realistic human faces, our approach
fine-tunes these models using stylized facial images generated via text-guided
image-to-image (i2i) translation with a diffusion model, which serve as
stylization targets for the rendered mesh. To prevent undesired changes in
identity, facial alignment, or expressions during i2i translation, we introduce
a stylization method that explicitly preserves the facial attributes of the
source image. By maintaining these critical attributes during image
stylization, the proposed approach ensures consistent 3D style transfer across
the 3DMM parameter space through image-based training. Once trained, StyleMM
enables feed-forward generation of stylized face meshes with explicit control
over shape, expression, and texture parameters, producing meshes with
consistent vertex connectivity and animatability. Quantitative and qualitative
evaluations demonstrate that our approach outperforms state-of-the-art methods
in terms of identity-level facial diversity and stylization capability. The
code and videos are available at
[kwanyun.github.io/stylemm_page](kwanyun.github.io/stylemm_page).

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [233] [Data-driven global ocean model resolving ocean-atmosphere coupling dynamics](https://arxiv.org/abs/2508.10908)
*Jeong-Hwan Kim,Daehyun Kang,Young-Min Yang,Jae-Heung Park,Yoo-Geun Ham*

Main category: physics.ao-ph

TL;DR: 本研究开发了KIST-Ocean，一个基于深度学习的全球三维海洋环流模型，有效模拟了海洋响应和海气耦合机制，为提升长期气候预测能力奠定基础。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在短期天气预报中表现出色，但要将预测扩展到超季节时间尺度，亟需开发能真实模拟海洋对大气强迫复杂响应的深度学习（DL）海洋-大气耦合模型。

Method: 本研究提出了KIST-Ocean，一个基于深度学习的全球三维海洋环流模型。该模型采用U型视觉注意力对抗网络架构，并整合了部分卷积、对抗训练和迁移学习，以解决沿海复杂性和自回归模型中的预测分布漂移问题。

Result: KIST-Ocean模型在综合评估中展现出强大的海洋预测能力和高效率。它能准确捕捉真实的海洋响应，如热带太平洋的开尔文波和罗斯贝波传播，以及风应力引起的垂直运动，并能代表包括厄尔尼诺-南方涛动在内的关键海气耦合机制。

Conclusion: 研究结果增强了对基于深度学习的全球天气和气候模型的信心，并支持将深度学习方法推广应用于更广泛的地球系统建模，为提高气候预测能力提供了巨大潜力。

Abstract: Artificial intelligence has advanced global weather forecasting,
outperforming traditional numerical models in both accuracy and computational
efficiency. Nevertheless, extending predictions beyond subseasonal timescales
requires the development of deep learning (DL)-based ocean-atmosphere coupled
models that can realistically simulate complex oceanic responses to atmospheric
forcing. This study presents KIST-Ocean, a DL-based global three-dimensional
ocean general circulation model using a U-shaped visual attention adversarial
network architecture. KIST-Ocean integrates partial convolution, adversarial
training, and transfer learning to address coastal complexity and predictive
distribution drift in auto-regressive models. Comprehensive evaluations
confirmed the model's robust ocean predictive skill and efficiency. Moreover,
it accurately captures realistic ocean response, such as Kelvin and Rossby wave
propagation in the tropical Pacific, and vertical motions induced by cyclonic
and anticyclonic wind stress, demonstrating its ability to represent key
ocean-atmosphere coupling mechanisms underlying climate phenomena, including
the El Nino-Southern Oscillation. These findings reinforce confidence in
DL-based global weather and climate models and their extending DL-based
approaches to broader Earth system modeling, offering potential for enhancing
climate prediction capabilities.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [234] [Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance](https://arxiv.org/abs/2508.11093)
*Cesar Alan Contreras,Manolis Chiou,Alireza Rastegarpanah,Michal Szulik,Rustam Stolkin*

Main category: cs.RO

TL;DR: 本文提出将视觉语言模型（VLM）和大型语言模型（LLM）集成到GUIDER框架中，形成语义先验，以提升机器人根据任务提示推断用户意图、筛选目标物体和位置的能力，从而改进人机协作中的导航与操作。


<details>
  <summary>Details</summary>
Motivation: 人机协作要求机器人能快速推断用户意图、提供透明推理并协助用户达成目标。虽然GUIDER框架已能推断导航和操作意图，但仍需增强其语义理解能力，以便更有效地根据任务提示过滤物体和位置。

Method: 该研究通过整合VLM和LLM来增强GUIDER，形成一个语义先验。视觉管道（使用YOLO进行目标检测和Segment Anything Model进行实例分割）将候选对象裁剪图输入VLM，由VLM根据操作员提示评估其相关性；同时，LLM对检测到的对象标签列表进行排名。这些分数用于加权GUIDER现有的导航和操作层，以选择上下文相关目标并抑制无关对象。当组合置信度超过阈值时，机器人将自主导航至目标区域并取回所需对象，同时适应操作员意图的变化。

Result: 通过集成VLM和LLM，机器人能够基于语义理解有效过滤目标物体和位置，选择与上下文相关的目标并抑制无关对象。系统实现了机器人自主导航至期望区域并取回目标对象的能力，并能适应操作员意图的变化。

Conclusion: 该研究通过引入语义先验，显著增强了机器人理解和执行用户意图的能力，提升了人机协作的效率和适应性。未来的工作将侧重于在Isaac Sim仿真环境中，使用特定的机器人平台（Franka Emika机械臂和Ridgeback基座）对系统进行实时辅助能力的评估。

Abstract: Human-robot collaboration requires robots to quickly infer user intent,
provide transparent reasoning, and assist users in achieving their goals. Our
recent work introduced GUIDER, our framework for inferring navigation and
manipulation intents. We propose augmenting GUIDER with a vision-language model
(VLM) and a text-only language model (LLM) to form a semantic prior that
filters objects and locations based on the mission prompt. A vision pipeline
(YOLO for object detection and the Segment Anything Model for instance
segmentation) feeds candidate object crops into the VLM, which scores their
relevance given an operator prompt; in addition, the list of detected object
labels is ranked by a text-only LLM. These scores weight the existing
navigation and manipulation layers of GUIDER, selecting context-relevant
targets while suppressing unrelated objects. Once the combined belief exceeds a
threshold, autonomy changes occur, enabling the robot to navigate to the
desired area and retrieve the desired object, while adapting to any changes in
the operator's intent. Future work will evaluate the system on Isaac Sim using
a Franka Emika arm on a Ridgeback base, with a focus on real-time assistance.

</details>


### [235] [Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward](https://arxiv.org/abs/2508.11143)
*Jiarui Yang,Bin Zhu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: AC3是一个新颖的强化学习框架，通过为Actor和Critic引入特定稳定机制，实现了对高维连续动作序列的稳定、数据高效学习，有效解决了长周期、稀疏奖励机器人操作任务中的挑战，并在多项任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在处理长周期、稀疏奖励的机器人操作任务时面临困难，尤其是在稳定且数据高效地学习连续动作块方面仍是关键挑战。

Method: 本文提出了AC3（Actor-Critic for Continuous Chunks）框架，一个用于学习生成高维、连续动作序列的强化学习方法。为确保学习过程的稳定性和数据效率，AC3为Actor和Critic引入了针对性稳定机制：Actor采用非对称更新规则，仅从成功轨迹中学习；Critic的更新通过块内n步回报稳定，并通过自监督模块在动作块的锚点提供内在奖励进行丰富。

Result: 在BiGym和RLBench基准测试的25项任务中进行了广泛实验。结果表明，AC3仅使用少量演示和简单的模型架构，便在大多数任务上取得了卓越的成功率。

Conclusion: AC3的有效设计得到了验证，能够成功应对长周期、稀疏奖励机器人操作任务中的挑战。

Abstract: Existing reinforcement learning (RL) methods struggle with long-horizon
robotic manipulation tasks, particularly those involving sparse rewards. While
action chunking is a promising paradigm for robotic manipulation, using RL to
directly learn continuous action chunks in a stable and data-efficient manner
remains a critical challenge. This paper introduces AC3 (Actor-Critic for
Continuous Chunks), a novel RL framework that learns to generate
high-dimensional, continuous action sequences. To make this learning process
stable and data-efficient, AC3 incorporates targeted stabilization mechanisms
for both the actor and the critic. First, to ensure reliable policy
improvement, the actor is trained with an asymmetric update rule, learning
exclusively from successful trajectories. Second, to enable effective value
learning despite sparse rewards, the critic's update is stabilized using
intra-chunk $n$-step returns and further enriched by a self-supervised module
providing intrinsic rewards at anchor points aligned with each action chunk. We
conducted extensive experiments on 25 tasks from the BiGym and RLBench
benchmarks. Results show that by using only a few demonstrations and a simple
model architecture, AC3 achieves superior success rates on most tasks,
validating its effective design.

</details>


### [236] [Visuomotor Grasping with World Models for Surgical Robots](https://arxiv.org/abs/2508.11200)
*Hongbin Lin,Bin Li,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 本文提出GASv2，一个针对机器人辅助手术的视觉运动学习抓取框架，通过模拟到真实迁移和单目立体相机，实现了对未知手术物品的通用、鲁棒抓取，成功率达65%。


<details>
  <summary>Details</summary>
Motivation: 在机器人辅助手术中实现自动化抓取能减轻外科医生负担并提高效率和安全性。现有方法依赖显式物体姿态跟踪或手工视觉特征，限制了泛化性和鲁棒性，且难以处理可变形物体。视觉运动学习虽有潜力，但在手术环境中面临低信噪比、高安全性和毫米级精度要求等挑战。

Method: 引入了名为Grasp Anything for Surgery V2 (GASv2) 的视觉运动学习框架。该框架采用基于世界模型（world-model-based）的架构、用于视觉观察的手术感知管线以及混合控制系统以确保安全执行。策略在模拟环境中通过域随机化进行训练以实现模拟到真实迁移，并仅使用单对内窥镜相机在真实机器人上进行部署。

Result: 在基于模型和离体手术设置中均达到了65%的成功率。实验证明其策略可泛化到未见过的物体和夹持器，并能适应各种干扰，展现出强大的性能、通用性和鲁棒性。

Conclusion: GASv2 提供了一个在机器人辅助手术中具有强大性能、通用性和鲁棒性的视觉运动抓取策略，有效解决了模拟到真实迁移、单目立体相机学习以及物体无关抓取等关键挑战。

Abstract: Grasping is a fundamental task in robot-assisted surgery (RAS), and
automating it can reduce surgeon workload while enhancing efficiency, safety,
and consistency beyond teleoperated systems. Most prior approaches rely on
explicit object pose tracking or handcrafted visual features, limiting their
generalization to novel objects, robustness to visual disturbances, and the
ability to handle deformable objects. Visuomotor learning offers a promising
alternative, but deploying it in RAS presents unique challenges, such as low
signal-to-noise ratio in visual observations, demands for high safety and
millimeter-level precision, as well as the complex surgical environment. This
paper addresses three key challenges: (i) sim-to-real transfer of visuomotor
policies to ex vivo surgical scenes, (ii) visuomotor learning using only a
single stereo camera pair -- the standard RAS setup, and (iii) object-agnostic
grasping with a single policy that generalizes to diverse, unseen surgical
objects without retraining or task-specific models. We introduce Grasp Anything
for Surgery V2 (GASv2), a visuomotor learning framework for surgical grasping.
GASv2 leverages a world-model-based architecture and a surgical perception
pipeline for visual observations, combined with a hybrid control system for
safe execution. We train the policy in simulation using domain randomization
for sim-to-real transfer and deploy it on a real robot in both phantom-based
and ex vivo surgical settings, using only a single pair of endoscopic cameras.
Extensive experiments show our policy achieves a 65% success rate in both
settings, generalizes to unseen objects and grippers, and adapts to diverse
disturbances, demonstrating strong performance, generality, and robustness.

</details>


### [237] [Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation](https://arxiv.org/abs/2508.11204)
*Hongbin Lin,Juan Rojas,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 针对机器人视觉运动学习的采样效率问题，本文通过探索非等距对称性，提出新的POMDP公式和多群等变增强（MEA）数据增强方法，并结合离线强化学习和体素视觉表示，有效提升了采样效率，并在仿真和真实机器人实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人操作中，视觉运动学习的采样效率是关键挑战。现有方法虽利用任务对称性提高效率，但多局限于等距对称性（即所有对象在所有时间步应用相同变换），这限制了其应用范围。

Method: 探索非等距对称性，即在空间和时间维度上应用多个独立的群变换。提出一种融入非等距对称结构的新型偏观测马尔可夫决策过程（POMDP）公式。引入一种简单有效的多群等变增强（MEA）数据增强方法。将MEA与离线强化学习相结合，以提高采样效率，并采用一种保留平移等变性的体素视觉表示。

Result: 在两个操作领域的广泛模拟和真实机器人实验中，该方法均表现出显著的有效性。

Conclusion: 通过引入非等距对称性、创新的POMDP和MEA方法，以及结合离线强化学习和体素视觉表示，本研究成功提高了视觉运动学习的采样效率，并在实际机器人操作中展现了其潜力。

Abstract: Sampling efficiency is critical for deploying visuomotor learning in
real-world robotic manipulation. While task symmetry has emerged as a promising
inductive bias to improve efficiency, most prior work is limited to isometric
symmetries -- applying the same group transformation to all task objects across
all timesteps. In this work, we explore non-isometric symmetries, applying
multiple independent group transformations across spatial and temporal
dimensions to relax these constraints. We introduce a novel formulation of the
partially observable Markov decision process (POMDP) that incorporates the
non-isometric symmetry structures, and propose a simple yet effective data
augmentation method, Multi-Group Equivariance Augmentation (MEA). We integrate
MEA with offline reinforcement learning to enhance sampling efficiency, and
introduce a voxel-based visual representation that preserves translational
equivariance. Extensive simulation and real-robot experiments across two
manipulation domains demonstrate the effectiveness of our approach.

</details>


### [238] [Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent](https://arxiv.org/abs/2508.11286)
*Che Rin Yu,Daewon Chae,Dabin Seo,Sangwon Lee,Hyeongwoo Im,Jinkyu Kim*

Main category: cs.RO

TL;DR: 提出一种主动重规划框架，通过比较实时场景图与参考图，在机器人执行任务前检测并纠正环境不匹配，显著提高任务成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自主机器人缺乏环境适应性，易因忽略场景变化而失败；多数重规划方案反应滞后。主动重规划虽有潜力，但常依赖手动规则和大量监督。

Method: 构建主动重规划框架。在子任务边界，将当前RGB-D观察构建的场景图与成功演示中的参考图进行比对。若不匹配，激活轻量级推理模块诊断并调整计划。

Result: 在AI2-THOR模拟器中验证，该方法能提前检测语义和空间不匹配，显著提升任务成功率和鲁棒性。

Conclusion: 该框架通过预防性地识别并修正环境差异，有效解决了机器人适应性差和任务失败问题，提高了自主任务的可靠性。

Abstract: When humans perform everyday tasks, we naturally adjust our actions based on
the current state of the environment. For instance, if we intend to put
something into a drawer but notice it is closed, we open it first. However,
many autonomous robots lack this adaptive awareness. They often follow
pre-planned actions that may overlook subtle yet critical changes in the scene,
which can result in actions being executed under outdated assumptions and
eventual failure. While replanning is critical for robust autonomy, most
existing methods respond only after failures occur, when recovery may be
inefficient or infeasible. While proactive replanning holds promise for
preventing failures in advance, current solutions often rely on manually
designed rules and extensive supervision. In this work, we present a proactive
replanning framework that detects and corrects failures at subtask boundaries
by comparing scene graphs constructed from current RGB-D observations against
reference graphs extracted from successful demonstrations. When the current
scene fails to align with reference trajectories, a lightweight reasoning
module is activated to diagnose the mismatch and adjust the plan. Experiments
in the AI2-THOR simulator demonstrate that our approach detects semantic and
spatial mismatches before execution failures occur, significantly improving
task success and robustness.

</details>
