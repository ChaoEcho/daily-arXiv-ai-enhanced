{"id": "2508.20201", "pdf": "https://arxiv.org/pdf/2508.20201", "abs": "https://arxiv.org/abs/2508.20201", "authors": ["Lance Calvin Lim Gamboa", "Yue Feng", "Mark Lee"], "title": "Social Bias in Multilingual Language Models: A Survey", "categories": ["cs.CL"], "comment": "Accepted into EMNLP 2025 Main Conference", "summary": "Pretrained multilingual models exhibit the same social bias as models\nprocessing English texts. This systematic review analyzes emerging research\nthat extends bias evaluation and mitigation approaches into multilingual and\nnon-English contexts. We examine these studies with respect to linguistic\ndiversity, cultural awareness, and their choice of evaluation metrics and\nmitigation techniques. Our survey illuminates gaps in the field's dominant\nmethodological design choices (e.g., preference for certain languages, scarcity\nof multilingual mitigation experiments) while cataloging common issues\nencountered and solutions implemented in adapting bias benchmarks across\nlanguages and cultures. Drawing from the implications of our findings, we chart\ndirections for future research that can reinforce the multilingual bias\nliterature's inclusivity, cross-cultural appropriateness, and alignment with\nstate-of-the-art NLP advancements.", "AI": {"tldr": "\u8be5\u7cfb\u7edf\u7efc\u8ff0\u5206\u6790\u4e86\u591a\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u8bc4\u4f30\u4e0e\u7f13\u89e3\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u7814\u7a76\u7684\u4e0d\u8db3\uff08\u5982\u8bed\u8a00\u504f\u597d\u3001\u591a\u8bed\u8a00\u7f13\u89e3\u5b9e\u9a8c\u7a00\u7f3a\uff09\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u9884\u8bad\u7ec3\u591a\u8bed\u8a00\u6a21\u578b\u4e0e\u82f1\u8bed\u5904\u7406\u6a21\u578b\u4e00\u6837\u5b58\u5728\u793e\u4f1a\u504f\u89c1\uff0c\u9700\u8981\u5bf9\u975e\u82f1\u8bed\u548c\u591a\u8bed\u8a00\u8bed\u5883\u4e0b\u7684\u504f\u89c1\u8bc4\u4f30\u4e0e\u7f13\u89e3\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u7684\u65b9\u5f0f\uff0c\u5206\u6790\u4e86\u6269\u5c55\u504f\u89c1\u8bc4\u4f30\u548c\u7f13\u89e3\u65b9\u6cd5\u5230\u591a\u8bed\u8a00\u53ca\u975e\u82f1\u8bed\u8bed\u5883\u7684\u65b0\u5174\u7814\u7a76\uff0c\u91cd\u70b9\u8003\u5bdf\u4e86\u8bed\u8a00\u591a\u6837\u6027\u3001\u6587\u5316\u610f\u8bc6\u3001\u8bc4\u4f30\u6307\u6807\u548c\u7f13\u89e3\u6280\u672f\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u9886\u57df\u65b9\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u7a7a\u767d\uff08\u4f8b\u5982\uff0c\u5bf9\u67d0\u4e9b\u8bed\u8a00\u7684\u504f\u597d\uff0c\u591a\u8bed\u8a00\u504f\u89c1\u7f13\u89e3\u5b9e\u9a8c\u7684\u7a00\u7f3a\u6027\uff09\uff0c\u5e76\u68b3\u7406\u4e86\u5728\u8de8\u8bed\u8a00\u548c\u6587\u5316\u9002\u5e94\u504f\u89c1\u57fa\u51c6\u65f6\u9047\u5230\u7684\u5e38\u89c1\u95ee\u9898\u548c\u5df2\u5b9e\u65bd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u8bba\u6587\u4e3a\u672a\u6765\u7684\u591a\u8bed\u8a00\u504f\u89c1\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\uff0c\u65e8\u5728\u589e\u5f3a\u5176\u5305\u5bb9\u6027\u3001\u8de8\u6587\u5316\u9002\u7528\u6027\u4ee5\u53ca\u4e0e\u6700\u65b0NLP\u8fdb\u5c55\u7684\u5951\u5408\u5ea6\u3002"}}
{"id": "2508.20217", "pdf": "https://arxiv.org/pdf/2508.20217", "abs": "https://arxiv.org/abs/2508.20217", "authors": ["Mohammad Amini", "Babak Ahmadi", "Xiaomeng Xiong", "Yilin Zhang", "Christopher Qiao"], "title": "Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This study explores automatic generation (AIG) using language models to\ncreate multiple choice questions (MCQs) for morphological assessment, aiming to\nreduce the cost and inconsistency of manual test development. The study used a\ntwo-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)\nwith a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven\nstructured prompting strategies, including zero-shot, few-shot,\nchain-of-thought, role-based, sequential, and combinations. Generated items\nwere assessed using automated metrics and expert scoring across five\ndimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate\nhuman scoring at scale. Results show that structured prompting, especially\nstrategies combining chain-of-thought and sequential design, significantly\nimproved Gemma's outputs. Gemma generally produced more construct-aligned and\ninstructionally appropriate items than GPT-3.5's zero-shot responses, with\nprompt design playing a key role in mid-size model performance. This study\ndemonstrates that structured prompting and efficient fine-tuning can enhance\nmidsized models for AIG under limited data conditions. We highlight the value\nof combining automated metrics, expert judgment, and large-model simulation to\nensure alignment with assessment goals. The proposed workflow offers a\npractical and scalable way to develop and validate language assessment items\nfor K-12.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u8bed\u8a00\u6a21\u578b\uff08Gemma\u548cGPT-3.5\uff09\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u548c\u5fae\u8c03\uff0c\u81ea\u52a8\u751f\u6210\u5f62\u6001\u5b66\u8bc4\u4f30\u7684\u591a\u9009\u9898\uff0c\u65e8\u5728\u964d\u4f4e\u4eba\u5de5\u5f00\u53d1\u6210\u672c\u5e76\u63d0\u9ad8\u4e00\u81f4\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u6784\u5316\u63d0\u793a\u548c\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u5347\u4e2d\u578b\u6a21\u578b\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u52a8\u3001\u4e13\u5bb6\u548c\u5927\u578b\u6a21\u578b\u6a21\u62df\u8bc4\u4f30\u7684\u5b9e\u7528\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u4eba\u5de5\u5f00\u53d1\u5f62\u6001\u5b66\u8bc4\u4f30\u591a\u9009\u9898\uff08MCQs\uff09\u7684\u6210\u672c\u5e76\u89e3\u51b3\u5176\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5229\u7528\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u751f\u6210\uff08AIG\uff09\u7684\u65b9\u6cd5\u3002", "method": "1. **\u6a21\u578b\u5bf9\u6bd4**\uff1a\u6bd4\u8f83\u4e86\u5fae\u8c03\u8fc7\u7684\u4e2d\u578b\u6a21\u578bGemma (2B) \u4e0e\u672a\u5fae\u8c03\u7684\u5927\u578b\u6a21\u578bGPT-3.5 (175B)\u30022. **\u63d0\u793a\u7b56\u7565\u8bc4\u4f30**\uff1a\u8bc4\u4f30\u4e86\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u601d\u7ef4\u94fe\u3001\u89d2\u8272\u626e\u6f14\u3001\u5e8f\u5217\u5316\u53ca\u5176\u7ec4\u5408\u7b49\u4e03\u79cd\u7ed3\u6784\u5316\u63d0\u793a\u7b56\u7565\u30023. **\u9898\u76ee\u8bc4\u4f30**\uff1a\u4f7f\u7528\u81ea\u52a8\u5316\u6307\u6807\u548c\u4e13\u5bb6\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u8bc4\u5206\u30024. **\u5927\u89c4\u6a21\u8bc4\u4f30\u6a21\u62df**\uff1a\u5229\u7528\u7ecf\u8fc7\u4e13\u5bb6\u8bc4\u5206\u6837\u672c\u8bad\u7ec3\u7684GPT-4.1\u6765\u6a21\u62df\u4eba\u7c7b\u8bc4\u5206\u3002", "result": "1. \u7ed3\u6784\u5316\u63d0\u793a\uff0c\u7279\u522b\u662f\u7ed3\u5408\u4e86\u601d\u7ef4\u94fe\u548c\u5e8f\u5217\u5316\u8bbe\u8ba1\u7684\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86Gemma\u6a21\u578b\u7684\u8f93\u51fa\u8d28\u91cf\u30022. \u4e0eGPT-3.5\u7684\u96f6\u6837\u672c\u54cd\u5e94\u76f8\u6bd4\uff0cGemma\u751f\u6210\u7684\u9898\u76ee\u5728\u6784\u5ff5\u5bf9\u9f50\u548c\u6559\u5b66\u9002\u5b9c\u6027\u65b9\u9762\u901a\u5e38\u8868\u73b0\u66f4\u4f18\uff0c\u5176\u4e2d\u63d0\u793a\u8bbe\u8ba1\u5bf9\u4e2d\u578b\u6a21\u578b\u6027\u80fd\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "1. \u5728\u6570\u636e\u6709\u9650\u7684\u6761\u4ef6\u4e0b\uff0c\u7ed3\u6784\u5316\u63d0\u793a\u548c\u9ad8\u6548\u5fae\u8c03\u80fd\u591f\u6709\u6548\u589e\u5f3a\u4e2d\u578b\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u751f\u6210\uff08AIG\uff09\u7684\u80fd\u529b\u30022. \u7ed3\u5408\u81ea\u52a8\u5316\u6307\u6807\u3001\u4e13\u5bb6\u5224\u65ad\u548c\u5927\u578b\u6a21\u578b\u6a21\u62df\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u786e\u4fdd\u4e0e\u8bc4\u4f30\u76ee\u6807\u4e00\u81f4\u6027\u5177\u6709\u91cd\u8981\u4ef7\u503c\u30023. \u672c\u7814\u7a76\u63d0\u51fa\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e3aK-12\u8bed\u8a00\u8bc4\u4f30\u9879\u76ee\u7684\u5f00\u53d1\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.20223", "pdf": "https://arxiv.org/pdf/2508.20223", "abs": "https://arxiv.org/abs/2508.20223", "authors": ["Andrei Mihai Albu", "Giovanni Pollo", "Alessio Burrello", "Daniele Jahier Pagliari", "Cristian Tesconi", "Alessandra Neri", "Dario Soldi", "Fabio Autieri", "Sara Vinco"], "title": "Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach", "categories": ["cs.CL"], "comment": null, "summary": "The growing complexity of cyber-physical systems, particularly in automotive\napplications, has increased the demand for efficient modeling and cross-domain\nco-simulation techniques. While SystemC Transaction-Level Modeling (TLM)\nenables effective hardware/software co-design, its limited interoperability\nwith models from other engineering domains poses integration challenges. This\npaper presents a fully open-source methodology for integrating SystemC TLM\nmodels into Functional Mock-up Interface (FMI)-based co-simulation workflows.\nBy encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional\nMock-up Units (FMUs), the proposed approach facilitates seamless, standardized\nintegration across heterogeneous simulation environments. We introduce a\nlightweight open-source toolchain, address key technical challenges such as\ntime synchronization and data exchange, and demonstrate the feasibility and\neffectiveness of the integration through representative case studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5f00\u6e90\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06SystemC TLM\u6a21\u578b\u5c01\u88c5\u4e3aFMI 3.0 FMU\uff0c\u5b9e\u73b0SystemC TLM\u4e0eFMI\u534f\u540c\u4eff\u771f\u5de5\u4f5c\u6d41\u7684\u96c6\u6210\uff0c\u4ee5\u89e3\u51b3\u8de8\u57df\u4e92\u64cd\u4f5c\u6027\u6311\u6218\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff08\u5c24\u5176\u5728\u6c7d\u8f66\u5e94\u7528\u4e2d\uff09\u7684\u65e5\u76ca\u590d\u6742\uff0c\u5bf9\u9ad8\u6548\u5efa\u6a21\u548c\u8de8\u57df\u534f\u540c\u4eff\u771f\u6280\u672f\u7684\u9700\u6c42\u589e\u52a0\u3002SystemC TLM\u867d\u80fd\u6709\u6548\u8fdb\u884c\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u4f46\u5176\u4e0e\u5176\u4ed6\u5de5\u7a0b\u9886\u57df\u6a21\u578b\u7684\u6709\u9650\u4e92\u64cd\u4f5c\u6027\u5e26\u6765\u4e86\u96c6\u6210\u96be\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5b8c\u5168\u5f00\u6e90\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06SystemC TLM\u7ec4\u4ef6\u5c01\u88c5\u4e3aFMI 3.0\u534f\u540c\u4eff\u771f\u529f\u80fd\u6a21\u578b\u5355\u5143\uff08FMU\uff09\uff0c\u5b9e\u73b0SystemC TLM\u6a21\u578b\u5230FMI\u534f\u540c\u4eff\u771f\u5de5\u4f5c\u6d41\u7684\u96c6\u6210\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90\u5de5\u5177\u94fe\uff0c\u5e76\u89e3\u51b3\u4e86\u65f6\u95f4\u540c\u6b65\u548c\u6570\u636e\u4ea4\u6362\u7b49\u5173\u952e\u6280\u672f\u6311\u6218\u3002", "result": "\u901a\u8fc7\u4ee3\u8868\u6027\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u96c6\u6210\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6807\u51c6\u5316\u4e14\u65e0\u7f1d\u7684\u96c6\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86SystemC TLM\u6a21\u578b\u5728\u5f02\u6784\u4eff\u771f\u73af\u5883\u4e2d\u7684\u4e92\u64cd\u4f5c\u6027\u95ee\u9898\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u8de8\u57df\u534f\u540c\u4eff\u771f\u3002"}}
{"id": "2508.20324", "pdf": "https://arxiv.org/pdf/2508.20324", "abs": "https://arxiv.org/abs/2508.20324", "authors": ["Rikuto Kotoge", "Mai Nishimura", "Jiaxin Ma"], "title": "Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning has emerged as a post-training approach to elicit\nagentic RAG behaviors such as search and planning from language models.\nHowever, compact language models (e.g., 0.5B parameters) struggle due to poor\nreasoning ability, resulting in sparse rewards and unstable training. To\novercome these difficulties, we propose Distillation-Guided Policy Optimization\n(DGPO), which addresses the challenges through cold-start initialization from\nteacher demonstrations and continuous teacher guidance during policy\noptimization. To systematically evaluate our approach, we introduce Agentic RAG\nCapabilities (ARC), a fine-grained metric analyzing reasoning, search\ncoordination, and response synthesis. Comprehensive experiments demonstrate\nthat DGPO enables compact models to achieve sophisticated agentic search\nbehaviors, even outperforming the larger teacher model in some cases. DGPO\nmakes agentic RAG feasible in computing resource-constrained environments.", "AI": {"tldr": "\u9488\u5bf9\u7d27\u51d1\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0Agentic RAG\u884c\u4e3a\u65f6\u9047\u5230\u7684\u96be\u9898\uff0c\u672c\u6587\u63d0\u51faDistillation-Guided Policy Optimization (DGPO) \u65b9\u6cd5\uff0c\u901a\u8fc7\u6559\u5e08\u5f15\u5bfc\u4f7f\u5176\u80fd\u5b9e\u73b0\u590d\u6742\u7684Agentic\u641c\u7d22\u884c\u4e3a\uff0c\u751a\u81f3\u8d85\u8d8a\u5927\u578b\u6559\u5e08\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002", "motivation": "\u7d27\u51d1\u578b\u8bed\u8a00\u6a21\u578b\uff08\u59820.5B\u53c2\u6570\uff09\u5728\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5b9e\u73b0Agentic RAG\u884c\u4e3a\u65f6\uff0c\u56e0\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\uff0c\u9762\u4e34\u7a00\u758f\u5956\u52b1\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51faDistillation-Guided Policy Optimization (DGPO) \u65b9\u6cd5\uff0c\u901a\u8fc7\u6559\u5e08\u6f14\u793a\u8fdb\u884c\u51b7\u542f\u52a8\u521d\u59cb\u5316\uff0c\u5e76\u5728\u7b56\u7565\u4f18\u5316\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u6301\u7eed\u7684\u6559\u5e08\u6307\u5bfc\u3002\u6b64\u5916\uff0c\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f15\u5165\u4e86Agentic RAG Capabilities (ARC) \u7ec6\u7c92\u5ea6\u6307\u6807\uff0c\u7528\u4e8e\u5206\u6790\u63a8\u7406\u3001\u641c\u7d22\u534f\u8c03\u548c\u54cd\u5e94\u5408\u6210\u80fd\u529b\u3002", "result": "\u5168\u9762\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cDGPO\u4f7f\u7d27\u51d1\u578b\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u590d\u6742\u7684Agentic\u641c\u7d22\u884c\u4e3a\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u8d85\u8d8a\u4e86\u5927\u578b\u6559\u5e08\u6a21\u578b\u3002", "conclusion": "DGPO\u4f7f\u5f97\u5728\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u5b9e\u73b0Agentic RAG\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2508.20205", "pdf": "https://arxiv.org/pdf/2508.20205", "abs": "https://arxiv.org/abs/2508.20205", "authors": ["Md. Emadul Haque", "Faisal Tariq", "Muhammad R A Khandaker", "Md. Sakir Hossain", "Muhammad Ali Imran", "Kai-Kit Wong"], "title": "A Comprehensive Survey of 5G URLLC and Challenges in the 6G Era", "categories": ["cs.NI"], "comment": "41 pages, 9 figures", "summary": "As the wireless communication paradigm is being transformed from human\ncentered communication services towards machine centered communication\nservices, the requirements of rate, latency and reliability for these services\nhave also been transformed drastically. Thus the concept of Ultra Reliable and\nLow Latency Communication (URLLC) has emerged as a dominant theme for 5G and 6G\nsystems. Though the latency and reliability requirement varies from one use\ncase to another, URLLC services generally aim to achieve very high reliability\nin the range of 99.999\\% while ensuring the latency of up to 1 ms. These two\ntargets are however inherently opposed to one another. Significant amounts of\nwork have been carried out to meet these ambitious but conflicting targets. In\nthis article a comprehensive survey of the URLLC approaches in 5G systems are\nanalysed in detail. Effort has been made to trace the history and evolution of\nlatency and reliability issues in wireless communication. A layered approach is\ntaken where physical layer, Medium Access Control (MAC) layer as well as cross\nlayer techniques are discussed in detail. It also covers the design\nconsideration for various 5G and beyond verticals. Finally the article\nconcludes by providing a detailed discussion on challenges and future outlook\nwith particular focus on the emerging 6G paradigm.", "AI": {"tldr": "\u672c\u6587\u5bf95G\u7cfb\u7edf\u4e2d\u7684\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\uff08URLLC\uff09\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u5176\u53d1\u5c55\u5386\u53f2\u3001\u5206\u5c42\u6280\u672f\u3001\u8bbe\u8ba1\u8003\u91cf\u4ee5\u53ca\u9762\u54116G\u7684\u672a\u6765\u6311\u6218\u548c\u5c55\u671b\u3002", "motivation": "\u968f\u7740\u65e0\u7ebf\u901a\u4fe1\u4ece\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u8f6c\u5411\u4ee5\u673a\u5668\u4e3a\u4e2d\u5fc3\uff0c\u5bf9\u901f\u7387\u3001\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002URLLC\u4f5c\u4e3a5G\u548c6G\u7684\u5173\u952e\u6280\u672f\u5e94\u8fd0\u800c\u751f\uff0c\u4f46\u5176\u9ad8\u53ef\u9760\u6027\u4e0e\u4f4e\u5ef6\u8fdf\u76ee\u6807\u672c\u8d28\u4e0a\u76f8\u4e92\u51b2\u7a81\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u548c\u89e3\u51b3\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u5408\u8c03\u67e5\u65b9\u6cd5\uff0c\u8be6\u7ec6\u5206\u6790\u4e865G\u7cfb\u7edf\u4e2d\u7684URLLC\u65b9\u6848\u3002\u7814\u7a76\u8ffd\u6eaf\u4e86\u65e0\u7ebf\u901a\u4fe1\u4e2d\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\u95ee\u9898\u7684\u5386\u53f2\u53ca\u6f14\u53d8\uff0c\u5e76\u91c7\u7528\u5206\u5c42\u65b9\u6cd5\uff08\u7269\u7406\u5c42\u3001MAC\u5c42\u548c\u8de8\u5c42\u6280\u672f\uff09\u8fdb\u884c\u8ba8\u8bba\u3002\u540c\u65f6\uff0c\u8fd8\u6db5\u76d6\u4e86\u5404\u79cd5G\u53ca\u672a\u6765\u5782\u76f4\u9886\u57df\u7684URLLC\u8bbe\u8ba1\u8003\u91cf\u3002", "result": "\u6587\u7ae0\u8be6\u7ec6\u5206\u6790\u4e865G\u7cfb\u7edf\u4e2dURLLC\u7684\u5404\u79cd\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5305\u62ec\u7269\u7406\u5c42\u3001MAC\u5c42\u53ca\u8de8\u5c42\u6280\u672f\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c5G\u5782\u76f4\u9886\u57df\u7684\u8bbe\u8ba1\u8003\u8651\u3002\u7ed3\u679c\u5448\u73b0\u4e86URLLC\u5728\u6ee1\u8db3\u9ad8\u53ef\u9760\u6027\u548c\u4f4e\u5ef6\u8fdf\u53cc\u91cd\u6311\u6218\u65b9\u9762\u7684\u5f53\u524d\u8fdb\u5c55\u3002", "conclusion": "URLLC\u662f5G\u548c6G\u7684\u5173\u952e\uff0c\u4f46\u5b9e\u73b0\u5176\u51b2\u7a81\u76ee\u6807\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u6587\u7ae0\u6700\u540e\u8ba8\u8bba\u4e86\u73b0\u6709\u6311\u6218\uff0c\u5e76\u5bf9\u672a\u6765\u53d1\u5c55\u8fdb\u884c\u4e86\u5c55\u671b\uff0c\u7279\u522b\u5173\u6ce8\u65b0\u5174\u76846G\u8303\u5f0f\u3002"}}
{"id": "2508.20143", "pdf": "https://arxiv.org/pdf/2508.20143", "abs": "https://arxiv.org/abs/2508.20143", "authors": ["Ruobing Wang", "Qiaoyu Tan", "Yili Wang", "Ying Wang", "Xin Wang"], "title": "CrystalICL: Enabling In-Context Learning for Crystal Generation", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "Designing crystal materials with desired physicochemical properties remains a\nfundamental challenge in materials science. While large language models (LLMs)\nhave demonstrated strong in-context learning (ICL) capabilities, existing\nLLM-based crystal generation approaches are limited to zero-shot scenarios and\nare unable to benefit from few-shot scenarios. In contrast, human experts\ntypically design new materials by modifying relevant known structures which\naligns closely with the few-shot ICL paradigm. Motivated by this, we propose\nCrystalICL, a novel model designed for few-shot crystal generation.\nSpecifically, we introduce a space-group based crystal tokenization method,\nwhich effectively reduces the complexity of modeling crystal symmetry in LLMs.\nWe further introduce a condition-structure aware hybrid instruction tuning\nframework and a multi-task instruction tuning strategy, enabling the model to\nbetter exploit ICL by capturing structure-property relationships from limited\ndata. Extensive experiments on four crystal generation benchmarks demonstrate\nthe superiority of CrystalICL over the leading baseline methods on conditional\nand unconditional generation tasks.", "AI": {"tldr": "\u9488\u5bf9\u73b0\u6709LLM\u6676\u4f53\u751f\u6210\u65e0\u6cd5\u5229\u7528\u5c11\u6837\u672c\u5b66\u4e60\u7684\u6311\u6218\uff0c\u672c\u6587\u63d0\u51faCrystalICL\u6a21\u578b\u3002\u901a\u8fc7\u7a7a\u95f4\u7fa4\u6807\u8bb0\u5316\u548c\u6307\u4ee4\u5fae\u8c03\uff0cCrystalICL\u5b9e\u73b0\u4e86\u5c11\u6837\u672c\u6676\u4f53\u751f\u6210\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8bbe\u8ba1\u5177\u6709\u6240\u9700\u7406\u5316\u6027\u8d28\u7684\u6676\u4f53\u6750\u6599\u662f\u6750\u6599\u79d1\u5b66\u7684\u57fa\u672c\u6311\u6218\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6676\u4f53\u751f\u6210\u65b9\u6cd5\u53d7\u9650\u4e8e\u96f6\u6837\u672c\uff08zero-shot\uff09\u573a\u666f\uff0c\u65e0\u6cd5\u53d7\u76ca\u4e8e\u5c11\u6837\u672c\uff08few-shot\uff09\u5b66\u4e60\u3002\u4eba\u7c7b\u4e13\u5bb6\u901a\u8fc7\u4fee\u6539\u5df2\u77e5\u7ed3\u6784\u8fdb\u884c\u6750\u6599\u8bbe\u8ba1\uff0c\u8fd9\u4e0e\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u8303\u5f0f\u9ad8\u5ea6\u5951\u5408\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5229\u7528\u5c11\u6837\u672cICL\u8fdb\u884c\u6676\u4f53\u751f\u6210\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faCrystalICL\u6a21\u578b\uff0c\u4e13\u4e3a\u5c11\u6837\u672c\u6676\u4f53\u751f\u6210\u8bbe\u8ba1\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1) \u5f15\u5165\u57fa\u4e8e\u7a7a\u95f4\u7fa4\u7684\u6676\u4f53\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u4ee5\u6709\u6548\u964d\u4f4eLLM\u5efa\u6a21\u6676\u4f53\u5bf9\u79f0\u6027\u7684\u590d\u6742\u6027\uff1b2) \u5f15\u5165\u6761\u4ef6\u7ed3\u6784\u611f\u77e5\u7684\u6df7\u5408\u6307\u4ee4\u5fae\u8c03\u6846\u67b6\uff1b3) \u91c7\u7528\u591a\u4efb\u52a1\u6307\u4ee4\u5fae\u8c03\u7b56\u7565\uff0c\u4f7f\u6a21\u578b\u80fd\u4ece\u6709\u9650\u6570\u636e\u4e2d\u6355\u83b7\u7ed3\u6784-\u6027\u8d28\u5173\u7cfb\uff0c\u4ece\u800c\u66f4\u597d\u5730\u5229\u7528ICL\u3002", "result": "\u5728\u56db\u4e2a\u6676\u4f53\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eCrystalICL\u5728\u6709\u6761\u4ef6\u548c\u65e0\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u4e8e\u9886\u5148\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "CrystalICL\u6210\u529f\u5730\u5c06\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\u5e94\u7528\u4e8e\u6676\u4f53\u751f\u6210\uff0c\u514b\u670d\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u7a7a\u95f4\u7fa4\u6807\u8bb0\u5316\u548c\u6df7\u5408\u6307\u4ee4\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u6676\u4f53\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.20181", "pdf": "https://arxiv.org/pdf/2508.20181", "abs": "https://arxiv.org/abs/2508.20181", "authors": ["Alberto Compagnoni", "Davide Caffagni", "Nicholas Moratelli", "Lorenzo Baraldi", "Marcella Cornia", "Rita Cucchiara"], "title": "Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": "BMVC 2025", "summary": "Multimodal Large Language Models (MLLMs) emerge as a unified interface to\naddress a multitude of tasks, ranging from NLP to computer vision. Despite\nshowcasing state-of-the-art results in many benchmarks, a long-standing issue\nis the tendency of MLLMs to hallucinate, that is to generate answers to the\nuser's query that are not reflected in the visual input. In this paper, we\naddress the problem of hallucinations as an alignment problem, seeking to steer\nthe MLLM so that it prefers generating content without hallucinations. In\ncontrast to recent approaches that require complicated pipelines to build\nsynthetic preference data for alignment training, often relying on proprietary\nmodels, we capitalize on the well-known CHAIR metric, originally proposed to\ngauge the degree of hallucinations in image captioning. Given a pair of\ngenerated answers, we leverage CHAIR to distinguish winner and loser options\n(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf\nMLLMs via Direct Preference Optimization (DPO). The resulting method, which we\nrefer to as CHAIR-DPO, effectively diminishes the amount of hallucinated\nanswers on several hallucination benchmarks, demonstrating the effectiveness of\nfine-tuning the MLLM with a CHAIR-based reward. Source code and trained models\nare publicly available at https://github.com/aimagelab/CHAIR-DPO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCHAIR-DPO\u65b9\u6cd5\uff0c\u5229\u7528CHAIR\u6307\u6807\u6784\u5efa\u504f\u597d\u6570\u636e\uff0c\u5e76\u901a\u8fc7DPO\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u6709\u6548\u51cf\u5c11\u5176\u5e7b\u89c9\u751f\u6210\u95ee\u9898\uff0c\u4e14\u65e0\u9700\u590d\u6742\u7684\u5408\u6210\u6570\u636e\u7ba1\u9053\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5c3d\u7ba1\u6027\u80fd\u5353\u8d8a\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5373\u751f\u6210\u4e0e\u89c6\u89c9\u8f93\u5165\u4e0d\u7b26\u7684\u5185\u5bb9\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u9700\u8981\u590d\u6742\u7684\u5408\u6210\u504f\u597d\u6570\u636e\u751f\u6210\u6d41\u7a0b\u548c\u4e13\u6709\u6a21\u578b\u3002", "method": "\u5c06\u5e7b\u89c9\u95ee\u9898\u89c6\u4e3a\u5bf9\u9f50\u95ee\u9898\u3002\u5229\u7528\u73b0\u6709\u7684CHAIR\u6307\u6807\uff0c\u6839\u636e\u751f\u6210\u7684\u7b54\u6848\u5bf9\uff08\u4e00\u4e2a\u65e0\u5e7b\u89c9\uff0c\u4e00\u4e2a\u6709\u5e7b\u89c9\uff09\u6765\u533a\u5206\u201c\u4f18\u80dc\u201d\u548c\u201c\u52a3\u52bf\u201d\u9009\u9879\u3002\u7136\u540e\uff0c\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u5bf9\u73b0\u6709MLLMs\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u7528\u57fa\u4e8eCHAIR\u7684\u5956\u52b1\u6765\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u65e0\u5e7b\u89c9\u5185\u5bb9\uff0c\u8be5\u65b9\u6cd5\u547d\u540d\u4e3aCHAIR-DPO\u3002", "result": "CHAIR-DPO\u65b9\u6cd5\u5728\u591a\u4e2a\u5e7b\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u51cf\u5c11\u4e86\u5e7b\u89c9\u7b54\u6848\u7684\u6570\u91cf\uff0c\u8bc1\u660e\u4e86\u4f7f\u7528\u57fa\u4e8eCHAIR\u7684\u5956\u52b1\u6765\u5fae\u8c03MLLM\u7684\u6709\u6548\u6027\u3002", "conclusion": "CHAIR-DPO\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528CHAIR\u6307\u6807\u548cDPO\u5fae\u8c03MLLM\uff0c\u663e\u8457\u7f13\u89e3\u4e86MLLM\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u3002"}}
{"id": "2508.20131", "pdf": "https://arxiv.org/pdf/2508.20131", "abs": "https://arxiv.org/abs/2508.20131", "authors": ["Yuqicheng Zhu", "Nico Potyka", "Daniel Hern\u00e1ndez", "Yuan He", "Zifeng Ding", "Bo Xiong", "Dongzhuoran Zhou", "Evgeny Kharlamov", "Steffen Staab"], "title": "ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models by\nincorporating external knowledge, yet suffers from critical limitations in\nhigh-stakes domains -- namely, sensitivity to noisy or contradictory evidence\nand opaque, stochastic decision-making. We propose ArgRAG, an explainable, and\ncontestable alternative that replaces black-box reasoning with structured\ninference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG\nconstructs a QBAF from retrieved documents and performs deterministic reasoning\nunder gradual semantics. This allows faithfully explaining and contesting\ndecisions. Evaluated on two fact verification benchmarks, PubHealth and\nRAGuard, ArgRAG achieves strong accuracy while significantly improving\ntransparency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faArgRAG\uff0c\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u53ef\u4e89\u8bae\u7684RAG\u66ff\u4ee3\u65b9\u6848\uff0c\u5b83\u5229\u7528\u5b9a\u91cf\u4e24\u6781\u8bba\u8bc1\u6846\u67b6\uff08QBAF\uff09\u8fdb\u884c\u7ed3\u6784\u5316\u3001\u786e\u5b9a\u6027\u63a8\u7406\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edfRAG\u5728\u566a\u58f0\u654f\u611f\u6027\u548c\u4e0d\u900f\u660e\u51b3\u7b56\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u663e\u8457\u7684\u900f\u660e\u5ea6\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5b58\u5728\u5173\u952e\u9650\u5236\uff0c\u5373\u5bf9\u566a\u58f0\u6216\u77db\u76fe\u8bc1\u636e\u7684\u654f\u611f\u6027\u4ee5\u53ca\u4e0d\u900f\u660e\u3001\u968f\u673a\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86ArgRAG\uff0c\u901a\u8fc7\u4f7f\u7528\u5b9a\u91cf\u4e24\u6781\u8bba\u8bc1\u6846\u67b6\uff08QBAF\uff09\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u53d6\u4ee3\u4e86\u4f20\u7edf\u7684\u9ed1\u76d2\u63a8\u7406\u3002ArgRAG\u4ece\u68c0\u7d22\u5230\u7684\u6587\u6863\u4e2d\u6784\u5efaQBAF\uff0c\u5e76\u5728\u6e10\u8fdb\u8bed\u4e49\u4e0b\u6267\u884c\u786e\u5b9a\u6027\u63a8\u7406\uff0c\u4ece\u800c\u5b9e\u73b0\u51b3\u7b56\u7684\u5fe0\u5b9e\u89e3\u91ca\u548c\u4e89\u8bae\u3002", "result": "\u5728PubHealth\u548cRAGuard\u8fd9\u4e24\u4e2a\u4e8b\u5b9e\u6838\u67e5\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cArgRAG\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u3002", "conclusion": "ArgRAG\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u4e14\u53ef\u4e89\u8bae\u7684RAG\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u89e3\u51b3\u4e86RAG\u7684\u9ed1\u76d2\u51b3\u7b56\u548c\u566a\u58f0\u654f\u611f\u6027\u95ee\u9898\uff0c\u5e76\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u51b3\u7b56\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2508.20325", "pdf": "https://arxiv.org/pdf/2508.20325", "abs": "https://arxiv.org/abs/2508.20325", "authors": ["Haibo Jin", "Ruoxi Chen", "Peiyan Zhang", "Andy Zhou", "Yang Zhang", "Haohan Wang"], "title": "GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "54 pages", "summary": "As Large Language Models become increasingly integral to various domains,\ntheir potential to generate harmful responses has prompted significant societal\nand regulatory concerns. In response, governments have issued ethics guidelines\nto promote the development of trustworthy AI. However, these guidelines are\ntypically high-level demands for developers and testers, leaving a gap in\ntranslating them into actionable testing questions to verify LLM compliance.\n  To address this challenge, we introduce GUARD (\\textbf{G}uideline\n\\textbf{U}pholding Test through \\textbf{A}daptive \\textbf{R}ole-play and\nJailbreak \\textbf{D}iagnostics), a testing method designed to operationalize\nguidelines into specific guideline-violating questions that assess LLM\nadherence. To implement this, GUARD uses automated generation of\nguideline-violating questions based on government-issued guidelines, thereby\ntesting whether responses comply with these guidelines. When responses directly\nviolate guidelines, GUARD reports inconsistencies. Furthermore, for responses\nthat do not directly violate guidelines, GUARD integrates the concept of\n``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that\nprovoke unethical or guideline-violating responses, effectively identifying\npotential scenarios that could bypass built-in safety mechanisms. Our method\nfinally culminates in a compliance report, delineating the extent of adherence\nand highlighting any violations.\n  We have empirically validated the effectiveness of GUARD on seven LLMs,\nincluding Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,\nGPT-4o, and Claude-3.7, by testing compliance under three government-issued\nguidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can\ntransfer jailbreak diagnostics to vision-language models, demonstrating its\nusage in promoting reliable LLM-based applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGUARD\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u751f\u6210\u8fdd\u89c4\u95ee\u9898\u5e76\u7ed3\u5408\u8d8a\u72f1\u8bca\u65ad\uff08GUARD-JD\uff09\uff0c\u5c06\u9ad8\u5c42\u7ea7\u4f26\u7406\u6307\u5357\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5408\u89c4\u6027\u5e76\u8bc6\u522b\u6f5c\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u6700\u7ec8\u751f\u6210\u5408\u89c4\u62a5\u544a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u6f5c\u529b\u5f15\u53d1\u4e86\u793e\u4f1a\u548c\u76d1\u7ba1\u62c5\u5fe7\u3002\u653f\u5e9c\u53d1\u5e03\u4e86\u4f26\u7406\u6307\u5357\uff0c\u4f46\u8fd9\u4e9b\u6307\u5357\u901a\u5e38\u662f\u9ad8\u5c42\u7ea7\u8981\u6c42\uff0c\u7f3a\u4e4f\u5c06\u5176\u8f6c\u5316\u4e3a\u5177\u4f53\u53ef\u64cd\u4f5c\u7684\u6d4b\u8bd5\u95ee\u9898\u6765\u9a8c\u8bc1LLM\u5408\u89c4\u6027\u7684\u65b9\u6cd5\u3002", "method": "GUARD\u65b9\u6cd5\u901a\u8fc7\u81ea\u52a8\u5316\u751f\u6210\u57fa\u4e8e\u653f\u5e9c\u6307\u5357\u7684\u8fdd\u89c4\u95ee\u9898\u6765\u6d4b\u8bd5LLMs\u7684\u5408\u89c4\u6027\u3002\u5bf9\u4e8e\u76f4\u63a5\u8fdd\u89c4\u7684\u54cd\u5e94\uff0cGUARD\u4f1a\u62a5\u544a\u4e0d\u4e00\u81f4\u6027\u3002\u5bf9\u4e8e\u672a\u76f4\u63a5\u8fdd\u89c4\u7684\u54cd\u5e94\uff0cGUARD-JD\u5f15\u5165\u201c\u8d8a\u72f1\u201d\u6982\u5ff5\uff0c\u521b\u5efa\u573a\u666f\u4ee5\u8bf1\u53d1\u4e0d\u9053\u5fb7\u6216\u8fdd\u89c4\u54cd\u5e94\uff0c\u4ece\u800c\u8bc6\u522b\u7ed5\u8fc7\u5185\u7f6e\u5b89\u5168\u673a\u5236\u7684\u6f5c\u5728\u6f0f\u6d1e\u3002\u6700\u7ec8\u751f\u6210\u8be6\u7ec6\u7684\u5408\u89c4\u62a5\u544a\u3002", "result": "GUARD\u5728\u4e03\u4e2aLLMs\uff08\u5305\u62ecVicuna-13B\u3001LongChat-7B\u3001Llama2-7B\u3001Llama-3-8B\u3001GPT-3.5\u3001GPT-4\u3001GPT-4o\u548cClaude-3.7\uff09\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u6d4b\u8bd5\u4e86\u5728\u4e09\u9879\u653f\u5e9c\u6307\u5357\u4e0b\u7684\u5408\u89c4\u6027\u5e76\u8fdb\u884c\u4e86\u8d8a\u72f1\u8bca\u65ad\u3002GUARD-JD\u8fd8\u80fd\u5c06\u8d8a\u72f1\u8bca\u65ad\u8f6c\u79fb\u5230\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e0a\u3002", "conclusion": "GUARD\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5c06\u4f26\u7406\u6307\u5357\u8f6c\u5316\u4e3aLLM\u5408\u89c4\u6027\u6d4b\u8bd5\u7684\u6311\u6218\uff0c\u80fd\u591f\u8bc6\u522bLLM\u7684\u8fdd\u89c4\u884c\u4e3a\u548c\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u6709\u52a9\u4e8e\u63a8\u5e7f\u53ef\u9760\u7684LLM\u5e94\u7528\u3002"}}
{"id": "2508.20272", "pdf": "https://arxiv.org/pdf/2508.20272", "abs": "https://arxiv.org/abs/2508.20272", "authors": ["Fatemeh Roshanzadeh", "Hamid Barati", "Ali Barati"], "title": "DRR-MDPF: A Queue Management Strategy Based on Dynamic Resource Allocation and Markov Decision Process in Named Data Networking (NDN)", "categories": ["cs.NI"], "comment": null, "summary": "Named Data Networking (NDN) represents a transformative shift in network\narchitecture, prioritizing content names over host addresses to enhance data\ndissemination. Efficient queue and resource management are critical to NDN\nperformance, especially under dynamic and high-traffic conditions. This paper\nintroduces DRR-MDPF, a novel hybrid strategy that integrates the Markov\nDecision Process Forwarding (MDPF) model with the Deficit Round Robin (DRR)\nalgorithm. MDPF enables routers to intelligently predict optimal forwarding\ndecisions based on key metrics such as bandwidth, delay, and the number of\nunsatisfied Interests, while DRR ensures fair and adaptive bandwidth allocation\namong competing data flows. The proposed method models each router as a\nlearning agent capable of adjusting its strategies through continuous feedback\nand probabilistic updates. Simulation results using ndnSIM demonstrate that\nDRR-MDPF significantly outperforms state-of-the-art strategies including SAF,\nRFA, SMDPF, and LA-MDPF across various metrics such as throughput, Interest\nSatisfaction Rate (ISR), packet drop rate, content retrieval time, and load\nbalancing. Notably, DRR-MDPF maintains robustness under limited cache sizes and\nheavy traffic, offering enhanced adaptability and lower computational\ncomplexity due to its single-path routing design. Furthermore, its multi-metric\ndecision-making capability enables more accurate interface selection, leading\nto optimized network performance. Overall, DRR-MDPF serves as an intelligent,\nadaptive, and scalable queue management solution for NDN, effectively\naddressing core challenges such as resource allocation, congestion control, and\nroute optimization in dynamic networking environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDRR-MDPF\uff0c\u4e00\u79cd\u7ed3\u5408MDPF\u548cDRR\u7684\u6df7\u5408\u7b56\u7565\uff0c\u7528\u4e8e\u547d\u540d\u6570\u636e\u7f51\u7edc\uff08NDN\uff09\u7684\u961f\u5217\u548c\u8d44\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u591a\u6307\u6807\u51b3\u7b56\u5b9e\u73b0\u9ad8\u6548\u548c\u81ea\u9002\u5e94\u7684\u6570\u636e\u8f6c\u53d1\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5728\u52a8\u6001\u548c\u9ad8\u6d41\u91cf\u6761\u4ef6\u4e0b\uff0cNDN\u7684\u6548\u7387\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6709\u6548\u7684\u961f\u5217\u548c\u8d44\u6e90\u7ba1\u7406\uff0c\u4ee5\u4f18\u5316\u6570\u636e\u4f20\u64ad\u3002", "method": "\u5f15\u5165DRR-MDPF\uff0c\u4e00\u79cd\u6df7\u5408\u7b56\u7565\uff0c\u5c06\u57fa\u4e8e\u5e26\u5bbd\u3001\u5ef6\u8fdf\u548c\u672a\u6ee1\u8db3\u5174\u8da3\u6570\u91cf\u9884\u6d4b\u6700\u4f18\u8f6c\u53d1\u51b3\u7b56\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u8f6c\u53d1\uff08MDPF\uff09\u6a21\u578b\uff0c\u4e0e\u786e\u4fdd\u516c\u5e73\u5e26\u5bbd\u5206\u914d\u7684\u4e8f\u7a7a\u8f6e\u8be2\uff08DRR\uff09\u7b97\u6cd5\u76f8\u7ed3\u5408\u3002\u8def\u7531\u5668\u88ab\u5efa\u6a21\u4e3a\u901a\u8fc7\u8fde\u7eed\u53cd\u9988\u548c\u6982\u7387\u66f4\u65b0\u8c03\u6574\u7b56\u7565\u7684\u5b66\u4e60\u4ee3\u7406\uff0c\u5e76\u5728ndnSIM\u4e2d\u8fdb\u884c\u4eff\u771f\u3002", "result": "DRR-MDPF\u5728\u541e\u5410\u91cf\u3001\u5174\u8da3\u6ee1\u8db3\u7387\uff08ISR\uff09\u3001\u4e22\u5305\u7387\u3001\u5185\u5bb9\u68c0\u7d22\u65f6\u95f4\u548c\u8d1f\u8f7d\u5747\u8861\u7b49\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7b56\u7565\uff08SAF, RFA, SMDPF, LA-MDPF\uff09\u3002\u5b83\u5728\u6709\u9650\u7f13\u5b58\u548c\u9ad8\u6d41\u91cf\u4e0b\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5177\u6709\u589e\u5f3a\u7684\u9002\u5e94\u6027\u548c\u8f83\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u4e14\u591a\u6307\u6807\u51b3\u7b56\u80fd\u529b\u80fd\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u63a5\u53e3\u9009\u62e9\u3002", "conclusion": "DRR-MDPF\u662fNDN\u7684\u4e00\u79cd\u667a\u80fd\u3001\u81ea\u9002\u5e94\u4e14\u53ef\u6269\u5c55\u7684\u961f\u5217\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u3001\u62e5\u585e\u63a7\u5236\u548c\u8def\u7531\u4f18\u5316\u7b49\u6838\u5fc3\u6311\u6218\u3002"}}
{"id": "2508.20206", "pdf": "https://arxiv.org/pdf/2508.20206", "abs": "https://arxiv.org/abs/2508.20206", "authors": ["Elisha Dayag", "Nhat Thanh Van Tran", "Jack Xin"], "title": "Filter then Attend: Improving attention-based Time Series Forecasting with Spectral Filtering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer-based models are at the forefront in long time-series forecasting\n(LTSF). While in many cases, these models are able to achieve state of the art\nresults, they suffer from a bias toward low-frequencies in the data and high\ncomputational and memory requirements. Recent work has established that\nlearnable frequency filters can be an integral part of a deep forecasting model\nby enhancing the model's spectral utilization. These works choose to use a\nmultilayer perceptron to process their filtered signals and thus do not solve\nthe issues found with transformer-based models. In this paper, we establish\nthat adding a filter to the beginning of transformer-based models enhances\ntheir performance in long time-series forecasting. We add learnable filters,\nwhich only add an additional $\\approx 1000$ parameters to several\ntransformer-based models and observe in multiple instances 5-10 \\% relative\nimprovement in forecasting performance. Additionally, we find that with filters\nadded, we are able to decrease the embedding dimension of our models, resulting\nin transformer-based architectures that are both smaller and more effective\nthan their non-filtering base models. We also conduct synthetic experiments to\nanalyze how the filters enable Transformer-based models to better utilize the\nfull spectrum for forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728Transformer\u6a21\u578b\u4e2d\u52a0\u5165\u53ef\u5b66\u4e60\u9891\u7387\u6ee4\u6ce2\u5668\uff0c\u4ee5\u6539\u5584\u957f\u5e8f\u5217\u65f6\u95f4\u9884\u6d4b\uff08LTSF\uff09\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u5176\u4f4e\u9891\u504f\u5dee\u53ca\u9ad8\u8d44\u6e90\u6d88\u8017\u95ee\u9898\uff0c\u5e76\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6a21\u578b\u6548\u7387\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u957f\u5e8f\u5217\u65f6\u95f4\u9884\u6d4b\u4e2d\u9762\u4e34\u4f4e\u9891\u504f\u5dee\u4ee5\u53ca\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u95ee\u9898\u3002\u73b0\u6709\u5229\u7528\u53ef\u5b66\u4e60\u9891\u7387\u6ee4\u6ce2\u5668\u7684\u5de5\u4f5c\u867d\u80fd\u589e\u5f3a\u5149\u8c31\u5229\u7528\uff0c\u4f46\u672a\u80fd\u89e3\u51b3Transformer\u6a21\u578b\u7684\u56fa\u6709\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8005\u5728\u591a\u4e2aTransformer\u6a21\u578b\u7684\u524d\u7aef\u6dfb\u52a0\u4e86\u53ef\u5b66\u4e60\u7684\u9891\u7387\u6ee4\u6ce2\u5668\uff0c\u8fd9\u4e9b\u6ee4\u6ce2\u5668\u4ec5\u589e\u52a0\u4e86\u5927\u7ea61000\u4e2a\u53c2\u6570\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u5c1d\u8bd5\u964d\u4f4e\u6a21\u578b\u7684\u5d4c\u5165\u7ef4\u5ea6\uff0c\u5e76\u8fdb\u884c\u4e86\u5408\u6210\u5b9e\u9a8c\u6765\u5206\u6790\u6ee4\u6ce2\u5668\u5982\u4f55\u5e2e\u52a9\u6a21\u578b\u66f4\u597d\u5730\u5229\u7528\u5168\u9891\u8c31\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u901a\u8fc7\u6dfb\u52a0\u6ee4\u6ce2\u5668\uff0c\u6a21\u578b\u5728\u591a\u4e2a\u5b9e\u4f8b\u4e2d\u5b9e\u73b0\u4e865-10%\u7684\u76f8\u5bf9\u9884\u6d4b\u6027\u80fd\u63d0\u5347\u3002\u540c\u65f6\uff0c\u7814\u7a76\u53d1\u73b0\u6dfb\u52a0\u6ee4\u6ce2\u5668\u540e\u53ef\u4ee5\u51cf\u5c0f\u6a21\u578b\u7684\u5d4c\u5165\u7ef4\u5ea6\uff0c\u4f7f\u5f97Transformer\u67b6\u6784\u66f4\u5c0f\u4e14\u6bd4\u65e0\u6ee4\u6ce2\u5668\u7684\u57fa\u7840\u6a21\u578b\u66f4\u6709\u6548\u3002\u5408\u6210\u5b9e\u9a8c\u8868\u660e\u6ee4\u6ce2\u5668\u4f7fTransformer\u6a21\u578b\u80fd\u66f4\u597d\u5730\u5229\u7528\u5168\u9891\u8c31\u8fdb\u884c\u9884\u6d4b\u3002", "conclusion": "\u4e3aTransformer\u6a21\u578b\u6dfb\u52a0\u53ef\u5b66\u4e60\u9891\u7387\u6ee4\u6ce2\u5668\u80fd\u6709\u6548\u63d0\u5347\u5176\u5728\u957f\u5e8f\u5217\u65f6\u95f4\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u4f7f\u5f97\u6a21\u578b\u66f4\u7d27\u51d1\u9ad8\u6548\uff0c\u5e76\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u6570\u636e\u5168\u9891\u8c31\u7684\u5229\u7528\u80fd\u529b\u3002"}}
