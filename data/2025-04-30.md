<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 4]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [It's the same but not the same: Do LLMs distinguish Spanish varieties?](https://arxiv.org/abs/2504.20049)
*Marina Mayor-Rocher,Cristina Pozo,Nina Melero,Gonzalo Martínez,María Grandury,Pedro Reviriego*

Main category: cs.CL

TL;DR: 评估大型语言模型识别不同西班牙语地域变体的能力，发现 GPT-4o 表现最佳。


<details>
  <summary>Details</summary>
Motivation: 西班牙语拥有五亿母语使用者，并非单一语言，而是存在丰富的地域变体。现有大型语言模型虽已展现出良好的西班牙语处理能力，但其识别和区分这些具体变体的能力需要评估。

Method: 通过一个包含七种西班牙语变体（安第斯、安的列斯、加勒比大陆、智利、半岛、墨西哥与中美洲、拉普拉塔）的形态句法和词汇特征的多项选择测试，评估了九个大型语言模型。

Result: 研究结果显示，所有模型对半岛西班牙语的识别效果最好。在所有被评估的模型中，GPT-4o 是唯一能够识别西班牙语多样性的模型。

Conclusion: 虽然大型语言模型普遍能较好地识别半岛西班牙语，但目前只有 GPT-4o 表现出识别西班牙语丰富地域变体的能力。

Abstract: In recent years, large language models (LLMs) have demonstrated a high
capacity for understanding and generating text in Spanish. However, with five
hundred million native speakers, Spanish is not a homogeneous language but
rather one rich in diatopic variations spanning both sides of the Atlantic. For
this reason, in this study, we evaluate the ability of nine language models to
identify and distinguish the morphosyntactic and lexical peculiarities of seven
varieties of Spanish (Andean, Antillean, Continental Caribbean, Chilean,
Peninsular, Mexican and Central American and Rioplatense) through a
multiple-choice test. The results indicate that the Peninsular Spanish variety
is the best identified by all models and that, among them, GPT-4o is the only
model capable of recognizing the variability of the Spanish language.
  --
  En los \'ultimos a\~nos, los grandes modelos de lenguaje (LLMs, por sus
siglas en ingl\'es) han demostrado una alta capacidad para comprender y generar
texto en espa\~nol. Sin embargo, con quinientos millones de hablantes nativos,
la espa\~nola no es una lengua homog\'enea, sino rica en variedades
diat\'opicas que se extienden a ambos lados del Atl\'antico. Por todo ello,
evaluamos en este trabajo la capacidad de nueve modelos de lenguaje de
identificar y discernir las peculiaridades morfosint\'acticas y l\'exicas de
siete variedades de espa\~nol (andino, antillano, caribe\~no continental,
chileno, espa\~nol peninsular, mexicano y centroamericano y rioplatense)
mediante un test de respuesta m\'ultiple. Los resultados obtenidos indican que
la variedad de espa\~nol peninsular es la mejor identificada por todos los
modelos y que, de entre todos, GPT-4o es el \'unico modelo capaz de identificar
la variabilidad de la lengua espa\~nola.

</details>


### [2] [Evaluating Large Language Models on Multiword Expressions in Multilingual and Code-Switched Contexts](https://arxiv.org/abs/2504.20051)
*Frances Laureano De Leon,Harish Tayyar Madabushi,Mark G. Lee*

Main category: cs.CL

TL;DR: 大型语言模型（包括GPT-4）在理解多词表达（尤其是具有歧义的习语）方面表现不佳，特别是在低频语境和新任务中，甚至不如基线模型。


<details>
  <summary>Details</summary>
Motivation: 多词表达具有非组合性意义和句法不规则性，其含义可能在字面和习语之间变化。尽管大型语言模型在许多任务上表现强大，但它们处理这种语言细微之处的能力，尤其是在难以依赖记忆的低频语境中，仍不确定。

Method: 研究评估了最新的语言模型（包括GPT-4）处理潜在习语性多词表达歧义的能力。评估在英语、葡萄牙语和加利西亚语上进行，使用了新颖的语码转换数据集和新任务，并与xlm-roBERTa-base基线进行比较。

Result: 大型语言模型，包括GPT-4，在处理细微语言方面存在困难。在多词表达的检测和语义任务中，它们的表现未能超越xlm-roBERTa-base基线，并且在新引入的任务上表现尤其差。

Conclusion: 多词表达，特别是那些具有歧义的表达，对当前的模型来说仍然是一个挑战。

Abstract: Multiword expressions, characterised by non-compositional meanings and
syntactic irregularities, are an example of nuanced language. These expressions
can be used literally or idiomatically, leading to significant changes in
meaning. While large language models have demonstrated strong performance
across many tasks, their ability to handle such linguistic subtleties remains
uncertain. Therefore, this study evaluates how state-of-the-art language models
process the ambiguity of potentially idiomatic multiword expressions,
particularly in contexts that are less frequent, where models are less likely
to rely on memorisation. By evaluating models across in Portuguese and
Galician, in addition to English, and using a novel code-switched dataset and a
novel task, we find that large language models, despite their strengths,
struggle with nuanced language. In particular, we find that the latest models,
including GPT-4, fail to outperform the xlm-roBERTa-base baselines in both
detection and semantic tasks, with especially poor performance on the novel
tasks we introduce, despite its similarity to existing tasks. Overall, our
results demonstrate that multiword expressions, especially those which are
ambiguous, continue to be a challenge to models.

</details>


### [3] [Understanding and Mitigating Risks of Generative AI in Financial Services](https://arxiv.org/abs/2504.20086)
*Sebastian Gehrmann,Claire Huang,Xian Teng,Sergei Yurovski,Iyanuoluwa Shode,Chirag S. Patel,Arjun Bhorkar,Naveen Thomas,John Doucette,David Rosenberg,Mark Dredze,David Rabinowitz*

Main category: cs.CL

TL;DR: 本文关注金融服务领域的生成式AI内容安全，提出特定风险分类法，并发现现有安全护栏不足以覆盖这些风险。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全研究多关注通用模型和风险（如有害性、偏见），忽视了金融等具有特定法律法规要求的专业领域，现有安全措施可能无法应对金融领域的特定内容风险。

Method: 识别金融服务领域的特定AI内容安全考量；构建相应的AI内容风险分类法；与现有工作比较；讨论风险违规对利益相关者的影响；通过红队测试收集的数据评估现有开源技术护栏对该分类法的覆盖程度。

Result: 现有的开源技术护栏未能检测出本文所讨论的大部分金融服务特定内容风险。

Conclusion: 为金融服务负责任地开发生成式AI，需要特定领域的内容安全考量和风险分类法，因为当前的通用安全护栏不足以应对这些特定风险。

Abstract: To responsibly develop Generative AI (GenAI) products, it is critical to
define the scope of acceptable inputs and outputs. What constitutes a "safe"
response is an actively debated question. Academic work puts an outsized focus
on evaluating models by themselves for general purpose aspects such as
toxicity, bias, and fairness, especially in conversational applications being
used by a broad audience. In contrast, less focus is put on considering
sociotechnical systems in specialized domains. Yet, those specialized systems
can be subject to extensive and well-understood legal and regulatory scrutiny.
These product-specific considerations need to be set in industry-specific laws,
regulations, and corporate governance requirements. In this paper, we aim to
highlight AI content safety considerations specific to the financial services
domain and outline an associated AI content risk taxonomy. We compare this
taxonomy to existing work in this space and discuss implications of risk
category violations on various stakeholders. We evaluate how existing
open-source technical guardrail solutions cover this taxonomy by assessing them
on data collected via red-teaming activities. Our results demonstrate that
these guardrails fail to detect most of the content risks we discuss.

</details>


### [4] [Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models](https://arxiv.org/abs/2504.20157)
*Zae Myung Kim,Chanwoo Park,Vipul Raheja,Dongyeop Kang*

Main category: cs.CL

TL;DR: 提出元策略优化（MPO）框架，通过元奖励模型动态调整奖励模型的提示，以解决现有基于奖励的大模型对齐方法中的奖励 hacking 和繁琐提示工程问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于奖励的大语言模型（LLM）对齐方法存在两大局限：容易受到奖励 hacking（模型利用奖励信号缺陷）的影响；以及当LLM用作奖励模型时，依赖于脆弱且耗费人力的提示工程。

Method: 引入元策略优化（MPO）框架。该框架集成了一个元奖励模型，在训练过程中动态优化奖励模型的提示。元奖励模型监控训练环境的变化，持续调整奖励模型提示以维持高对齐度，提供一个能抵抗策略利用的自适应奖励信号。

Result: MPO 实现了与经过大量手动设计奖励提示的模型相当或更好的性能。它减少了手动设计奖励提示的需求，提高了策略优化的稳定性，并在问答、数学推理等不同任务上保持有效性，无需专门的奖励设计。

Conclusion: MPO 解决了基于奖励的强化学习对齐 LLM 中的理论和实践挑战，提供了一种更鲁棒、适应性更强的对齐策略，为未来的对齐方法铺平了道路。

Abstract: Reward-based alignment methods for large language models (LLMs) face two key
limitations: vulnerability to reward hacking, where models exploit flaws in the
reward signal; and reliance on brittle, labor-intensive prompt engineering when
LLMs are used as reward models. We introduce Meta Policy Optimization (MPO), a
framework that addresses these challenges by integrating a meta-reward model
that dynamically refines the reward model's prompt throughout training. In MPO,
the meta-reward model monitors the evolving training context and continuously
adjusts the reward model's prompt to maintain high alignment, providing an
adaptive reward signal that resists exploitation by the policy. This
meta-learning approach promotes a more stable policy optimization, and greatly
reduces the need for manual reward prompt design. It yields performance on par
with or better than models guided by extensively hand-crafted reward prompts.
Furthermore, we show that MPO maintains its effectiveness across diverse tasks,
such as question answering and mathematical reasoning, without requiring
specialized reward designs. Beyond standard RLAIF, MPO's meta-learning
formulation is readily extensible to higher-level alignment frameworks.
Overall, this method addresses theoretical and practical challenges in
reward-based RL alignment for LLMs, paving the way for more robust and
adaptable alignment strategies. The code and models will be publicly shared.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [Can Geometry Save Central Views for Sports Field Registration?](https://arxiv.org/abs/2504.20052)
*Floriane Magera,Thomas Hoyoux,Martin Castin,Olivier Barnich,Anthony Cioppa,Marc Van Droogenbroeck*

Main category: cs.CV

TL;DR: 提出一种利用圆形标记进行单帧体育场配准的新方法，特别适用于缺乏特征点的特写视图。


<details>
  <summary>Details</summary>
Motivation: 现有体育场配准方法在处理仅含线条和圆形标记的场地中心区域特写视图时遇到困难，因为它们主要依赖线条交点，难以有效利用圆形信息。

Method: 提出一种新颖的几何方法，从圆形对应关系中推导出点和线集合，从而将圆形信息整合进配准过程。

Result: 实验表明，该方法优于现有顶尖检测器，并能有效补充它们，在仅有线条和圆形的困难场景下成功实现体育场配准。

Conclusion: 该方法通过有效利用圆形标记，提升了体育场配准在挑战性视图（如特写镜头）下的性能和鲁棒性。

Abstract: Single-frame sports field registration often serves as the foundation for
extracting 3D information from broadcast videos, enabling applications related
to sports analytics, refereeing, or fan engagement. As sports fields have
rigorous specifications in terms of shape and dimensions of their line, circle
and point components, sports field markings are commonly used as calibration
targets for this task. However, because of the sparse and uneven distribution
of field markings, close-up camera views around central areas of the field
often depict only line and circle markings. On these views, sports field
registration is challenging for the vast majority of existing methods, as they
focus on leveraging line field markings and their intersections. It is indeed a
challenge to include circle correspondences in a set of linear equations. In
this work, we propose a novel method to derive a set of points and lines from
circle correspondences, enabling the exploitation of circle correspondences for
both sports field registration and image annotation. In our experiments, we
illustrate the benefits of our bottom-up geometric method against
top-performing detectors and show that our method successfully complements
them, enabling sports field registration in difficult scenarios.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [6] [Tree embedding based mapping system for low-latency mobile applications in multi-access networks](https://arxiv.org/abs/2504.20246)
*Yu Mi,Randeep Bhatia,Fang Hao,An Wang,Steve Benno,Tv Lakshman*

Main category: cs.NI

TL;DR: 提出了一种基于定位符/ID分离和树嵌入覆盖网络的新型端到端系统，用于低延迟、高动态应用中的多连接移动设备跟踪和性能优化。


<details>
  <summary>Details</summary>
Motivation: 低延迟应用（如AR/VR、在线游戏）和新兴技术（V2X、LEO卫星、6G）对快速、稳定的移动连接提出了更高要求，而传统移动性管理方案在路由效率、通用性和多接入支持方面存在不足，难以满足快速移动性需求。

Method: 设计了一个基于定位符/ID分离原则的端到端系统。该系统采用了一种新颖的基于树嵌入的覆盖网络，支持多接入网络，无需专用路由器或缓存，实现了快速会话建立，并允许端点之间直接处理移动性。

Result: 与LISP相比（其因缓存未命中导致359%的延迟膨胀），该方案将连接延迟膨胀降低至最短路径的7.42%。同时，它显著减少了位置更新的开销和移动过程中的中断时间。

Conclusion: 该系统能够有效地大规模跟踪多连接移动设备，并为对延迟敏感、高度动态的应用优化性能，在降低延迟、开销和中断方面表现优越。

Abstract: Low-latency applications like AR/VR and online gaming need fast, stable
connections. New technologies such as V2X, LEO satellites, and 6G bring unique
challenges in mobility management. Traditional solutions based on centralized
or distributed anchors often fall short in supporting rapid mobility due to
inefficient routing, low versatility, and insufficient multi-access support. In
this paper, we design a new end-to-end system for tracking multi-connected
mobile devices at scale and optimizing performance for latency-sensitive,
highly dynamic applications. Our system, based on the locator/ID separation
principle, extends to multi-access networks without requiring specialized
routers or caching. Using a novel tree embedding-based overlay, we enable fast
session setup while allowing endpoints to directly handle mobility between
them. Evaluation with real network data shows our solution cuts connection
latency to 7.42% inflation over the shortest path, compared to LISP's 359\% due
to cache misses. It also significantly reduces location update overhead and
disruption time during mobility.

</details>
