<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 72]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.LG](#cs.LG) [Total: 55]
- [cs.NI](#cs.NI) [Total: 9]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [q-fin.PR](#q-fin.PR) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 7]
- [cs.SE](#cs.SE) [Total: 6]
- [math.OC](#math.OC) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CY](#cs.CY) [Total: 11]
- [eess.SP](#eess.SP) [Total: 4]
- [eess.AS](#eess.AS) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文首次系统评估了大型语言模型（LLM）在意大利语性别中立重写（GNR）任务中的表现，发现开源LLM优于现有专用模型，且微调模型能在更小规模下达到或超越最佳开源LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 性别中立重写在意大利语等语法性别语言中是一项艰巨的任务，需要消除不必要的性别指定同时保留文本含义。

Method: 引入了一个衡量中立性和语义忠实度的二维框架；比较了多种LLM的few-shot提示性能；微调了部分选定模型；并对训练数据进行了有针对性的清洗。

Result: 开源LLM超越了现有唯一的意大利语GNR专用模型；作者的微调模型在远小于最佳开源LLM的规模下，性能却能与之持平或更优。

Conclusion: 研究讨论了在优化训练数据时，平衡中立性和意义保留之间权衡的重要性。

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [2] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: 发布了Op-Fed数据集，用于分析FOMC会议记录中的观点和立场，并评估了LLM在该任务上的零样本性能，发现其在立场分类上远低于人类基线。


<details>
  <summary>Details</summary>
Motivation: 美国联邦公开市场委员会(FOMC)的货币政策讨论影响广泛，但分析其会议记录面临两大挑战：类别不平衡（非中性立场的句子极少）和句子间依赖性（多数实例需超出句子层面的上下文）。

Method: 创建了Op-Fed数据集，包含1044个带人工标注的FOMC会议记录句子及其上下文。为解决挑战，开发了五阶段分层标注方案，并使用主动学习方法选择实例进行标注，使积极实例数量翻倍。

Result: 一个顶级的闭源大型语言模型在观点分类上的零样本准确率为0.80。但在对货币政策立场的分类上，零样本准确率仅为0.61，远低于人类基线（0.89）。

Conclusion: Op-Fed数据集对未来的模型训练、置信度校准和作为后续标注工作的种子数据集具有重要价值。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [3] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: DSTC12 Track 1专注于LLM对话系统评估，包含多维度自动评估和多语言多文化安全检测两个子任务。结果显示多维度评估基线表现不佳，文化感知安全检测面临挑战，凸显了这两个领域的改进空间。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的快速发展，对话系统亟需鲁棒的评估方法。现有传统指标和安全考量往往不足、定义狭隘或存在文化偏见，难以实现全面评估。

Method: DSTC12 Track 1设置了两个子任务：(1) 对话级多维度自动评估指标，涵盖10个对话维度；(2) 多语言和多文化安全检测。研究提供了数据集和基线模型（Llama-3-8B用于任务一，Llama-Guard-3-1B用于任务二）供参与者评估。

Result: 任务一中，Llama-3-8B基线在对话维度上的平均Spearman相关性仅为0.1681，表明有显著改进空间。任务二中，参与团队在多语言安全子集上表现显著优于Llama-Guard-3-1B基线（最高ROC-AUC 0.9648），但在文化安全子集上基线表现更优（0.5126 ROC-AUC），突显了文化感知安全评估的挑战。

Conclusion: 本论文描述了DSTC12 Track 1的数据集、基线及评估结果，强调了对话系统多维度自动评估指标和文化感知安全检测领域仍存在巨大挑战和改进需求。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [4] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: 针对LLMs在未知任务上的泛化需求，本文提出了一个分析框架来解剖跨任务迁移学习。研究发现，源数据集的隐藏统计特征和语言特性比表面相似性更能影响迁移学习性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在部署时常遇到训练中未见的任务，且无法为所有任务获取高质量训练数据。因此，需要依赖迁移学习处理分布外请求。本研究旨在深入理解跨任务迁移学习的复杂机制。

Method: 提出了一种分析框架，通过构建迁移学习矩阵和降维来解剖跨任务交互。训练并分析了10个模型，以识别潜在能力（如推理、情感分类、NLU、算术）并发现迁移学习的副作用。

Result: 迁移学习的性能提升往往无法用数据集的表面相似性或源数据质量来解释。相反，源数据集的隐藏统计因素（如类别分布、生成长度倾向）以及特定的语言特征被发现更具影响力。

Conclusion: 本研究揭示了迁移学习的复杂动态，为LLMs更可预测和有效的适应性提供了新思路。

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [5] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）将问题歧义线性编码在其内部表示中，可通过神经元级别进行检测和控制。


<details>
  <summary>Details</summary>
Motivation: 现实世界问题普遍存在歧义，但LLMs通常自信地给出答案，而非寻求澄清，这限制了其应用。

Method: 在LLM预填充阶段识别编码歧义的少量神经元（AENs）。训练探针检测AENs中的歧义信息。进行分层分析以确定AENs的出现层级。通过操纵AENs来控制LLM的行为。

Result: 问题歧义被线性编码在LLM内部表示中。仅少数（甚至一个）神经元编码歧义信息。基于AENs训练的探针在歧义检测上表现出色，泛化性强，且优于基线方法。AENs从浅层出现，表明歧义信号在模型处理早期就被编码。通过操纵AENs，可以控制LLM的行为，使其从直接回答转向回避。

Conclusion: LLMs形成了紧凑的问题歧义内部表示，这使得它们的行为具有可解释性和可控性。

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [6] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 本文提出了CL$^2$GEC，首个针对多学科中文语法纠错的持续学习基准，并评估了多种持续学习方法，发现基于正则化的方法能更有效地缓解遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错（CGEC）研究缺乏针对多学科领域学术写作的专用基准，且忽视了持续学习（CL）在处理领域语言变异和防止灾难性遗忘方面的潜力。

Method: 引入了CL$^2$GEC，一个包含10个学科共10,000条人工标注句子的持续学习基准，旨在模拟真实世界的编辑动态，评估适应性CGEC。研究评估了大型语言模型在顺序微调、参数高效适应和四种代表性持续学习算法下的表现，并采用标准GEC指标和适应任务级变化的持续学习指标进行评估。

Result: 实验结果显示，基于正则化的方法在缓解遗忘方面比基于回放或朴素顺序的方法更有效。

Conclusion: 所提出的CL$^2$GEC基准为未来在不同学术领域进行适应性语法纠错研究奠定了坚实基础。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [7] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG通过模拟多智能体工作流，实现对文本生成的精细和复杂控制，并在多个任务和实际应用中取得了最先进（SOTA）效果。


<details>
  <summary>Details</summary>
Motivation: 受控文本生成（CTG）在细粒度条件控制方面面临挑战，且实际场景对成本、可扩展性、领域知识学习和精确控制有更高要求。

Method: 提出新型可扩展框架AgentCTG，通过模拟多智能体工作流的控制和调节机制，增强文本生成的精确和复杂控制。探索多种智能体协作方法，并引入自动提示模块以提升生成效果。

Result: 在多个公开数据集上取得SOTA结果。提出新的字符驱动重写任务验证实际有效性。应用于在线导航和角色扮演时，显著提升了驾驶体验和内容交付，促进了在线社区中更具沉浸感的交互、个性化和用户参与度。

Conclusion: AgentCTG为受控文本生成提供了一个新颖且可扩展的解决方案，通过多智能体协作实现了高精度和复杂控制，并在理论和实际应用中均表现出色。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [8] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: 提出CARE框架，通过模型自身检索将语境证据融入推理，显著提升LLMs在知识密集型任务中的准确性、可靠性和效率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在基于提供信息回答问题时，常面临语境忠实度问题，导致答案不一致。现有方法或依赖昂贵的有监督微调生成证据，或训练模型进行网络搜索，但未能有效提升对给定语境的利用率。

Method: 提出CARE，一个新颖的原生检索增强推理框架。它教授LLMs利用自身检索能力，在推理过程中明确整合语境中的证据。该方法仅需有限的标注证据数据，并通过在推理链中战略性地检索语境中的token来增强性能。

Result: 在多个真实世界和反事实问答基准上的大量实验表明，CARE方法显著优于有监督微调、传统检索增强生成方法以及外部检索解决方案，同时显著提升了检索准确性和答案生成性能。

Conclusion: 这项工作在使LLMs在知识密集型任务中更准确、更可靠、更高效方面取得了基础性进展。

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [9] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在日语比较级自然语言推理任务中表现不佳，其性能受提示格式和少样本示例影响，但逻辑语义提示有助于提升解决能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言推理（NLI）中表现良好，但在涉及数值和逻辑表达（如比较级）的NLI中仍面临挑战，尤其是在日语等非主流训练数据语言中，其鲁棒性未被充分探索。

Method: 构建了一个专注于比较级的日语NLI数据集，并在零样本和少样本设置下评估了多种大型语言模型。

Result: 模型性能对零样本设置中的提示格式敏感，并受少样本示例中黄金标签的影响。大型语言模型也难以处理日语特有的语言现象。此外，包含逻辑语义表示的提示有助于模型解决即使少样本也难以解决的推理问题。

Conclusion: 大型语言模型在处理日语比较级NLI时仍存在显著挑战，其性能受提示格式和样本选择影响。然而，引入逻辑语义表示的提示能够有效提升模型解决复杂推理问题的能力。

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [10] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: 研究展示了通过DSPy优化指令调优的LLMs，能有效处理结合结构化和非结构化数据的临床分类任务，性能与专业多模态系统相当，且更简单灵活。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在文本生成方面表现出色，但其处理涉及时间序列等结构化数据的临床分类任务的能力尚未得到充分探索。

Method: 利用基于DSPy的提示优化技术，对指令调优的LLMs进行调整，使其能够联合处理临床笔记和结构化电子健康记录（EHR）输入。

Result: 该方法在性能上与专业的专用多模态系统相当，同时所需复杂性更低，并能提供更强的跨任务适应性。

Conclusion: 通过DSPy优化指令调优的LLMs能够有效处理临床分类任务中的结构化和非结构化数据，实现与复杂多模态系统媲美的性能，且具有更高的效率和灵活性。

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [11] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: DSCC-HS是一个受双过程认知理论启发的框架，通过FAP和HDP代理模型在自回归解码期间动态引导LLM，实时注入校准向量，以主动抑制幻觉，无需修改目标模型，并在TruthfulQA和BioGEN上达到SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的幻觉问题严重阻碍了其可靠部署；现有方法（如RAG）往往是被动的。

Method: 引入了动态自强化校准幻觉抑制（DSCC-HS）框架，该框架在自回归解码期间进行干预。受双过程认知理论启发，DSCC-HS使用一个紧凑的代理模型，训练为事实对齐代理（FAP）和幻觉检测代理（HDP）。在推理过程中，这些代理通过注入FAP和HDP logits之间的差值作为实时引导向量，在每个解码步骤动态引导大型目标模型，且无需修改目标模型。

Result: 实验结果显示DSCC-HS取得了最先进的性能。在TruthfulQA上，其事实一致性率（FCR）达到99.2%。在长篇BioGEN基准测试中，其FActScore达到46.50，为最高分。

Conclusion: DSCC-HS被验证为一种原则性且高效的解决方案，能够显著增强LLM的事实性。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [12] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 开发了一种跨机构NLP工具，用于筛选放射肿瘤学中的高严重性事件报告，在人工整理数据集上的表现与人类相似。


<details>
  <summary>Details</summary>
Motivation: 医疗保健中的事件报告是改进安全和质量的重要工具，但人工审查耗时且需要专业知识，因此需要自动化工具来检测高严重性事件报告。

Method: 使用两个文本数据集（来自本机构的7,094份报告和来自IAEA SAFRON的571份报告）训练和评估NLP模型，所有报告均由临床专家标注了严重性分数。训练并评估了SVM和BlueBERT两种模型。通过跨机构测试和使用在两个数据集上微调的BlueBERT_TRANSFER模型来评估模型的泛化能力。此外，还分析了在人工整理的59份报告子集上的模型表现。

Result: 在本机构测试集上，SVM和BlueBERT的AUROC分别为0.82和0.81。未经跨机构迁移学习，在SAFRON测试集上的表现有限（SVM AUROC 0.42，BlueBERT AUROC 0.56）。经两个数据集微调的BlueBERT_TRANSFER模型将SAFRON测试集上的AUROC提高到0.78。在人工整理的本机构报告上，SVM和BlueBERT_TRANSFER模型的表现（AUROC 0.85和0.74）与人类表现（AUROC 0.81）相似。

Conclusion: 成功开发了用于放射肿瘤学事件报告文本的跨机构NLP模型。这些模型在人工整理数据集上，检测高严重性报告的能力与人类相似。

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [13] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 提出了一种名为DSPC的两阶段、无需训练的提示压缩方法，通过TF-IDF进行句级过滤和基于注意力、损失差异及位置重要性进行词级修剪，有效降低了计算成本并提高了大语言模型在有限token预算下的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型为提高准确性需要更长的提示，这导致更高的计算成本（提示膨胀问题）。现有的提示压缩方法大多需要训练一个辅助模型，这又引入了额外的计算负担。

Method: 本文提出DSPC（Dual-Stage Progressive Compression）方法，一个无需训练的两阶段方法：
1. **粗粒度阶段**：使用TF-IDF进行语义相关句子过滤，移除语义价值低的句子。
2. **细粒度阶段**：通过评估注意力贡献、跨模型损失差异和位置重要性来衡量token重要性，从而剪枝低效用token，同时保留语义。

Result: DSPC在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上，在受限token预算下，展现出持续的性能提升。例如，在Longbench数据集的FewShot任务中，DSPC仅使用1/3的token就达到了49.17的性能，超越了现有最佳基线LongLLMLingua 7.76个百分点。

Conclusion: DSPC成功地解决了提示膨胀问题，它提供了一种高效、无需训练的提示压缩方案，能够在显著减少token数量的同时保持甚至提升大语言模型的性能，优于现有先进方法。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [14] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 针对日语比较句的自然语言推理（NLI）挑战，本文提出了一个基于组合语义的逻辑推理系统ccg-jcomp，并在日语NLI数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: NLI中的比较句理解困难。现有基于组合语义的逻辑推理系统主要针对英语比较句，但由于日语和英语比较句在形态和语义上的差异，无法直接应用于日语。本研究旨在解决这一应用空白。

Method: 提出一个名为ccg-jcomp的、基于组合语义的日语比较句逻辑推理系统。该系统在一个包含比较表达的日语NLI数据集上进行评估，并通过与现有LLMs的准确性比较来验证其性能。

Result: 实验证明了所提出的ccg-jcomp系统在处理日语比较句NLI任务上的有效性。

Conclusion: ccg-jcomp系统成功为日语比较句NLI提供了一个有效的逻辑推理解决方案，克服了英语系统无法直接应用于日语的难题。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [15] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探讨了阿拉伯语方言识别（ADI）的数据高效和参数高效方法，比较了大型语言模型（LLM）的硬提示、各种软提示策略和LoRA，发现LoRA表现最佳，甚至超越了完全微调。


<details>
  <summary>Details</summary>
Motivation: 旨在探索不同数据高效和参数高效的方法来提升阿拉伯语方言识别（ADI）的性能，并评估LLM在不同提示设置下的方言识别能力。

Method: 研究了多种软提示策略（如prefix-tuning, prompt-tuning, P-tuning, P-tuning V2）和LoRA重参数化。对LLM使用硬提示进行零样本和少样本推理以分析其方言识别能力。参数高效的PEFT实验基于阿拉伯语专用编码器模型在多个主要数据集上进行。还在开源解码器模型（Phi-3.5, SILMA）上分析了n-shot推理。

Result: LLM在零样本或少样本设置下识别方言细微差别时普遍表现不佳。软提示编码器变体表现更好。基于LoRA的微调模型表现最佳，甚至超越了完全微调。

Conclusion: LLMs在有限样本下对阿拉伯语方言识别能力不足。LoRA是一种极其有效的参数高效微调方法，在ADI任务中展现出卓越的性能，能够超越其他参数高效策略乃至完全微调。

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [16] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出CAMPUS框架，通过动态、能力感知和多维度课程调度，克服了现有课程学习指令微调的僵化问题，显著提升了LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有课程学习指令微调方法依赖静态启发式难度指标，导致课程僵化，无法适应模型能力演变，可能导致次优学习路径。

Method: 提出CAMPUS（Competence-Aware Multi-Perspective cUrriculum inStruction tuning）框架，其特点包括：动态选择子课程、能力感知调整课程时间表以及多难度维度调度。

Result: 广泛的实验证明CAMPUS在高效指令微调方面，相较于现有最先进的基线方法，展现出卓越的性能。

Conclusion: CAMPUS框架有效解决了现有课程学习指令微调的僵化问题，通过其动态、能力感知和多维度调度机制，显著提升了大型语言模型的指令微调效果。

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [17] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 本研究探讨了职业名称中显式语法性别对自动职位排序系统的影响，提出了一种控制性别的排名比较指标（RBO）和多语言测试集，并发现现有模型普遍存在不同程度的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 研究职业名称中显式语法性别分配如何影响自动职位排序系统的结果，并评估这些系统中的性别偏见。

Method: 1. 提出控制性别的排名比较指标（如RBO）来评估职位标题排序系统中的性别偏见。2. 创建并共享了四种具有语法性别的语言的职位标题匹配任务测试集，包含阳性/阴性形式的职业名称，并进行了性别和匹配相关性标注。3. 使用新测试集和所提方法评估了多个开箱即用的多语言模型的性别偏见，作为基线。

Result: 所有被评估的多语言基线模型都表现出不同程度的性别偏见。

Conclusion: 职业名称中的显式语法性别会对自动职位排序系统产生影响，且现有模型普遍存在性别偏见。本研究为未来评估和减轻这种偏见奠定了基础。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [18] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLMs）的幻觉问题，本文提出一种基于原型分析的几何框架，在黑盒访问下同时量化全局（Geometric Volume）和局部（Geometric Suspicion）不确定性，并在问答和医疗数据集中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）会产生幻觉，生成看似合理但不正确的内容。现有不确定性量化方法在黑盒模型访问下无法同时提供全局（批次）和局部（个体）不确定性估计，且局部方法通常需要白盒访问。

Method: 本文引入一个几何框架，通过对黑盒模型采样的响应批次进行原型分析（archetypal analysis）。
*   **全局不确定性**：提出“Geometric Volume”，测量响应嵌入原型凸包的体积。
*   **局部不确定性**：提出“Geometric Suspicion”，根据可靠性对单个响应进行排序，以减少幻觉。
该方法能提供语义边界点，用于归因单个响应的可靠性。

Result: *   在短形式问答数据集上，该框架的性能与现有方法相当或更优。
*   在幻觉风险尤其关键的医疗数据集上，取得了卓越结果。
*   提供了理论依据，证明了凸包体积与熵之间的关联。

Conclusion: 本文提出的几何框架为黑盒大语言模型提供了有效的全局和局部不确定性量化方法，能够更好地检测和减少幻觉，尤其在医疗等关键领域展现出显著优势。

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [19] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: 本文介绍了2025年第三届AutoMin共享任务，涵盖自动会议纪要生成和基于会议文本的问答，支持多语言和多领域，并因参与团队有限而引入了多个LLM基线系统进行评估。


<details>
  <summary>Details</summary>
Motivation: 本文旨在呈现2025年AutoMin共享任务的第三版，该任务旨在推动自动会议纪要生成及基于会议文本的问答技术的发展。

Method: 共享任务包含两部分：1. 会议纪要生成任务，支持英语和捷克语，涉及项目会议和欧洲议会会议两个领域。2. 基于会议文本的问答任务，专注于项目会议，提供英语单语和捷克语-英语跨语言问答。由于参与团队有限，组织者还纳入了多个大型语言模型作为基线系统进行综合评估。

Result: 2025年的参与度低于往年，会议纪要任务仅有一个团队参与，问答任务有两个团队。然而，组织者通过引入多个大型语言模型（LLMs）作为基线系统，确保了对当前技术的全面评估。

Conclusion: AutoMin 2025成功举办了会议纪要生成和问答两项共享任务，尽管参与团队数量有限，但通过引入LLM基线系统，为评估和推动自动会议处理技术提供了有价值的平台和全面的基准。

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [20] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）对德国方言使用者的刻板印象。结果显示，LLMs在联想和决策任务中均表现出显著的负面偏见，且明确提及方言使用者会放大这种偏见。


<details>
  <summary>Details</summary>
Motivation: 方言是人类文化的重要组成部分，但方言使用者常面临负面社会刻板印象。研究旨在探究大型语言模型（LLMs）是否也反映了这些刻板印象。

Method: 借鉴社会语言学文献，分析与方言使用者相关的常见特质。通过联想任务和决策任务，评估LLMs的方言命名偏见和方言使用偏见。为评估方言使用偏见，构建了一个包含七种德国地方方言（如阿勒曼尼语、巴伐利亚语）句子及其标准德语对应版本的新型评估语料库。

Result: 1. 在联想任务中，所有LLMs都表现出针对德国方言使用者的显著方言命名和方言使用偏见，体现在负面形容词联想上。 2. 所有模型在决策制定中也重现了这些偏见。 3. 与先前研究相反，明确标注语言人口统计信息（德国方言使用者）比隐式线索（如方言使用）更能放大偏见。

Conclusion: 大型语言模型反映并可能加剧了针对德国方言使用者的负面社会刻板印象，尤其是在明确提及方言群体时，偏见会显著增强。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [21] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLMs）在不同类型偏见情境下与人类社会偏见价值观（HVSB）的对齐情况。发现模型规模与对齐率无必然关系，LLMs对特定情境有偏好，同系列模型判断一致性高。LLMs对HVSB理解无显著差异，更倾向于自身解释；微调小型模型能生成可读性更高的解释，但模型认同度较低。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）若与人类价值观不符，尤其在涉及复杂敏感社会偏见时，可能导致不良后果。现有研究多使用专家设计或基于代理模拟的偏见情境，但LLMs与人类价值观的对齐是否在不同类型情境（如含负面或非负面问题的情境）中存在差异尚不明确。因此，本研究旨在探究LLMs在不同类型偏见情境下与人类社会偏见价值观的对齐情况。

Method: 本研究调查了12个来自四个模型家族的LLMs，并使用了四个数据集，分析它们在不同类型偏见情境下与人类社会偏见价值观（HVSB）的对齐情况。此外，通过LLMs对HVSB的解释来研究它们的理解能力。还通过微调方式，赋予小型语言模型（LMs）解释HVSB的能力。

Result: 研究发现，参数规模大的LLMs不一定具有更低的对齐错误率和攻击成功率。LLMs对特定类型的情境表现出一定的对齐偏好，且同一模型家族的LLMs倾向于具有更高判断一致性。在HVSB理解能力方面，LLMs之间没有显著差异，并且它们更偏爱自己生成的解释。微调后的小型LMs生成的解释可读性更高，但模型认同度相对较低。

Conclusion: 本研究深入揭示了LLMs在不同偏见情境下与人类社会偏见价值观对齐的复杂性，包括模型规模、家族一致性以及解释能力与质量的权衡。研究结果强调了在评估和改进LLMs对齐性时，考虑情境类型和解释生成的重要性。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [22] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 本文提出了CER（Combining Evidence and Reasoning）框架，通过结合科学证据检索、大型语言模型推理和监督式真实性预测，旨在解决生物医学事实核查中的挑战，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域的错误信息（如疫苗犹豫、未经证实的疗法）对公众健康和医疗系统信任构成风险。尽管现有机器学习和自然语言处理技术在自动化事实核查方面有所进展，但生物医学声明的复杂性、专业领域知识需求以及对科学证据的严格依赖使其验证面临独特挑战。

Method: 我们引入了CER（Combining Evidence and Reasoning）框架，用于生物医学事实核查。该框架整合了科学证据检索、通过大型语言模型（LLM）进行的推理，以及监督式真实性预测。CER通过结合LLM的文本生成能力和先进的检索技术来获取高质量的生物医学科学证据，有效降低了幻觉风险，确保生成结果以可验证、基于证据的来源为基础。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估表明，CER展现出最先进的性能（state-of-the-art performance）和有前景的跨数据集泛化能力。

Conclusion: CER框架通过创新性地整合证据检索和LLM推理，成功应对了生物医学事实核查的独特挑战，减轻了幻觉风险，并显著提升了该领域的自动化水平和可靠性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [23] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 本文提出CER框架，通过结合科学证据检索、大语言模型推理和监督预测，解决了生物医学事实核查的挑战，有效减少幻觉并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医疗健康领域的错误信息对公众健康和医疗系统信任构成严重威胁。尽管自动化事实核查技术有所发展，但生物医学声明的验证因其复杂术语、对领域专业知识的需求以及必须基于科学证据的特性而面临独特挑战。

Method: 引入CER（Combining Evidence and Reasoning）框架，该框架整合了科学证据检索、通过大型语言模型进行的推理以及监督式真实性预测。通过将大语言模型的文本生成能力与先进的生物医学科学证据检索技术相结合，CER旨在确保生成结果基于可验证的证据，从而有效减轻幻觉风险。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估表明，CER框架实现了最先进的性能，并展现出良好的跨数据集泛化能力。

Conclusion: CER框架通过创新性地整合证据检索和LLM推理，成功应对了生物医学事实核查的独特挑战，提供了高性能且可靠的解决方案，为打击医疗健康错误信息做出了重要贡献。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [24] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）的词义理解能力，发现它们在词义消歧任务上可与专业系统媲美，并在生成任务中表现出高达98%的准确率。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在上下文理解方面进行了大量评估，但它们真正掌握词义的程度仍未被充分探索。

Method: 本研究通过以下两点来解决这一问题：1) 评估指令调优LLMs的词义消歧（WSD）能力，并与现有最先进的WSD系统进行比较；2) 评估两款顶级LLMs在定义生成、自由解释和示例生成这三种生成设置中理解词义的能力。

Result: 在WSD任务中，GPT-4o和DeepSeek-V3等领先模型表现与专业WSD系统持平，并在不同领域和难度级别上展现出更强的鲁棒性。在生成任务中，LLMs能在上下文中解释词义，准确率高达98%，其中自由解释任务表现最佳，这与其生成能力最为契合。

Conclusion: LLMs在词义理解方面表现出强大的能力，在词义消歧任务中能与专业系统竞争，并在生成解释任务中展现出高准确性和鲁棒性。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [25] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 研究发现多语言RAG模型在引用时存在对英语来源的偏好，这种偏好有时会牺牲文档相关性。


<details>
  <summary>Details</summary>
Motivation: 探究多语言文档混合是否对多语言检索增强生成（mRAG）系统的生成和引用行为产生意想不到的影响。

Method: 引入受控方法，利用模型内部机制衡量语言偏好，同时保持文档相关性等因素不变。实验涵盖八种语言和六个开源模型。

Result: 模型在英语查询时倾向于引用英语来源，这种偏见在低资源语言和位于文本中间的文档中更为显著。模型有时会为了语言偏好而牺牲文档相关性，表明引用选择并非总是由信息性驱动。

Conclusion: 研究结果揭示了语言模型如何利用多语言上下文并影响引用行为。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [26] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: 本文为WMT25机器翻译质量评估任务提交，构建了基于COMET框架的系统，利用增强型长上下文数据训练预测ESA分数，并通过整合多个人工判断数据集，证明长上下文信息能显著提高模型与人工判断的相关性。


<details>
  <summary>Details</summary>
Motivation: 参与WMT25机器翻译质量自动评估共享任务，旨在开发出更准确且与人类判断高度相关的机器翻译质量评估系统。

Method: 1. 基于COMET框架构建评估系统。2. 模型训练目标是预测段落级错误跨度标注（ESA）分数。3. 采用增强型长上下文数据进行训练。4. 长上下文训练数据通过拼接领域内人工标注句子并计算其分数的加权平均值构建。5. 整合多个异构人工判断数据集（MQM、SQM、DA），并通过归一化其尺度来处理数据。6. 训练多语言回归模型，输入为源语言、假设翻译和参考翻译，输出为质量分数。

Result: 实验结果表明，与仅在短片段上训练的模型相比，结合长上下文信息显著提高了模型与人工判断的相关性。

Conclusion: 结合长上下文信息是提高机器翻译质量自动评估模型准确性及其与人工判断相关性的有效策略。

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [27] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: 本文提出Slim-SC，一种基于链间相似性剪枝的自洽性（SC）加速方法，能显著降低LLM推理的计算开销（延迟和KVC使用），同时保持或提升准确性。


<details>
  <summary>Details</summary>
Motivation: 自洽性（Self-Consistency, SC）是提高LLM推理性能的有效测试时扩展（TTS）技术，但其巨大的计算开销限制了广泛部署。现有加速方法多依赖模型置信度或启发式规则，缺乏充分经验支持。

Method: 研究人员首先理论和经验分析了SC的低效性，并基于这些见解提出了Slim-SC。Slim-SC是一种分步剪枝策略，通过在“思想”层面利用链间相似性来识别并移除冗余推理链。

Result: 在三个STEM推理数据集和两种LLM架构上的实验表明，Slim-SC（配合R1-Distill）能将推理延迟降低高达45%，KVC使用降低高达26%，同时保持或提高了模型的准确性。

Conclusion: Slim-SC为自洽性（SC）提供了一种简单而高效的测试时扩展（TTS）替代方案，有效解决了SC的计算开销问题。

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [28] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

TL;DR: ES-CoT是一种推理时方法，通过检测LLM CoT生成中的答案收敛并提前停止，平均减少41%的推理tokens，同时保持与标准CoT相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通过生成冗长的思维链（CoT）在解决复杂问题上表现出色，但这种CoT带来了高昂的推理成本。

Method: 引入ES-CoT。在每个推理步骤结束时，提示LLM输出当前最终答案（步答案），并追踪连续相同步答案的游程长度。当游程长度急剧增加并超过最小阈值时，终止CoT生成。该方法有经验和理论支持，表明步答案稳定收敛且游程长度跳变能可靠地标志收敛。

Result: 实验结果显示，ES-CoT在五个推理数据集和三个LLM上平均减少了约41%的推理tokens，同时保持了与标准CoT相当的准确性。此外，ES-CoT能与自洽提示无缝集成，并对超参数选择表现出鲁棒性。

Conclusion: ES-CoT是一种实用且有效的推理效率提升方法，通过智能的早期停止机制，显著降低CoT推理成本而性能损失极小。

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [29] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

TL;DR: 提出Hala模型家族，通过“翻译-微调”流程构建阿拉伯语指令与翻译模型，在阿拉伯语基准测试中取得SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 旨在构建高性能、阿拉伯语中心的指令遵循和翻译模型。

Method: 首先，将强大的AR↔EN教师模型压缩至FP8以生成高保真双语监督数据；然后，利用该数据微调轻量级模型LFM2-1.2B，生成百万级阿拉伯语指令语料；最后，训练不同参数规模的Hala模型（350M、700M、1.2B、9B），并应用slerp合并技术以平衡阿拉伯语专业化与基础模型优势。

Result: Hala模型在阿拉伯语中心基准测试中，于“纳米”（≤2B）和“小型”（7-9B）类别中均达到最先进水平，并超越了其基础模型。

Conclusion: 成功开发并发布了一系列性能卓越的阿拉伯语中心指令和翻译模型Hala，以及相关数据、评估和方案，旨在加速阿拉伯语NLP领域的研究。

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [30] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

TL;DR: 本研究比较了机器翻译的文本和音频评估方法，发现音频评估与文本评估结果基本一致，但在某些情况下能发现显著差异，建议将其纳入未来的评估框架。


<details>
  <summary>Details</summary>
Motivation: 尽管机器翻译技术不断进步，但其质量评估仍主要以文本为中心。鉴于许多实际应用涉及语音翻译而非文本阅读，通过语音进行评估将更为自然，能更好地反映真实使用场景。

Method: 研究选取了WMT通用机器翻译共享任务中的10个机器翻译系统，通过Amazon Mechanical Turk收集众包判断，比较了纯文本和基于音频的评估结果。同时，进行了统计显著性测试和自我复制实验以验证音频方法的可靠性和一致性。

Result: 基于音频的众包评估得出的系统排名与纯文本评估结果大体一致。然而，在某些情况下，音频评估能够识别出不同翻译系统之间存在的显著差异。研究将此归因于语音作为一种更丰富、更自然的模态。

Conclusion: 语音评估是一种有效且有时能揭示文本评估无法发现差异的方法。因此，研究提议将基于语音的评估纳入未来的机器翻译评估框架中。

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [31] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文验证了训练数据稀疏性是机器翻译上下文利用困难的关键瓶颈，并提出两种训练策略，在单语和多语环境中将准确率分别提升了高达6%和8%。


<details>
  <summary>Details</summary>
Motivation: 实现人类水平翻译需要利用上下文来确保连贯性并处理代词消歧等复杂现象。研究假设标准训练数据中上下文丰富示例的稀疏性是上下文利用困难的原因。

Method: 通过构建具有受控比例上下文相关示例的训练数据集，在单语和多语环境中系统验证了训练数据稀疏性对模型性能的影响。此外，提出并经验性评估了两种旨在充分利用现有数据的训练策略。

Result: 研究发现训练数据稀疏性与模型性能之间存在强关联，证实其为关键瓶颈。一个上下文现象的改进不能泛化到其他现象。观察到一些跨语言迁移，但同语系语言之间无显著更高。提出的训练策略提高了上下文利用率，在ctxPro评估中，单语和多语设置下分别获得了高达6和8个百分点的准确率提升。

Conclusion: 训练数据中上下文丰富示例的稀疏性是机器翻译模型难以有效利用上下文的关键原因。通过设计特定的训练策略，可以显著提高模型利用上下文的能力，从而提升翻译准确性。

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [32] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

TL;DR: 多智能体辩论（MAD）系统中的大型语言模型（LLM）因缺乏置信度表达而导致辩论效果不佳。本文提出将置信度表达整合到MAD系统中，并开发了ConfMAD框架，实验证明其有效性，并为设计置信度感知的MAD系统提供了见解。


<details>
  <summary>Details</summary>
Motivation: 现有MAD系统中，LLM难以清晰表达其优越的知识或推理能力，部分原因是缺乏置信度表达。不恰当的置信度表达会导致智能体固执己见或过早收敛到次优解，从而降低辩论效率和系统性能。

Method: 提出将置信度表达纳入MAD系统，使LLM能明确沟通其置信水平。开发了ConfMAD框架，该框架将置信度表达整合到整个辩论过程中以验证此方法。

Result: 实验结果证明了该方法的有效性。进一步分析了置信度如何影响辩论动态。

Conclusion: 提出的置信度表达方法有效提升了MAD系统性能，并为设计置信度感知的MAD系统提供了宝贵见解。

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [33] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

TL;DR: 本文提出问题辅助手语翻译（QB-SLT），利用问题文本作为上下文线索，提出SSL-SSAW多模态融合方法，在新建数据集上实现了SOTA性能，并证明易得的问题辅助比传统手语转录更有效。


<details>
  <summary>Details</summary>
Motivation: 手语翻译（SLT）中对话能提供关键上下文，但传统的手语转录（gloss）标注困难且不自然。相比之下，对话（特别是问题）在交流中自然发生且更易标注，因此研究如何高效集成对话以弥补沟通鸿沟。

Method: 提出了跨模态自监督学习与Sigmoid自注意力加权（SSL-SSAW）融合方法。该方法采用对比学习来对齐QB-SLT中的多模态特征，并引入Sigmoid自注意力加权（SSAW）模块，从问题和手语序列中自适应提取特征。此外，通过自监督学习利用问题文本来增强表示和翻译能力。

Result: 在新建的CSL-Daily-QA和PHOENIX-2014T-QA数据集上，SSL-SSAW方法取得了SOTA性能。值得注意的是，易于获取的问题辅助能够达到甚至超越手语转录（gloss）辅助的性能。可视化结果也进一步证明了整合对话在提升翻译质量方面的有效性。

Conclusion: 通过引入问题辅助手语翻译（QB-SLT）及提出的SSL-SSAW方法，证明了高效整合易于获取的对话（问题）上下文可以显著提升手语翻译的质量，并提供了一种比传统手语转录更实用和高效的翻译增强手段。

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [34] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

TL;DR: Canary-1B-v2是一个快速、鲁棒的多语言ASR和AST模型，采用FastConformer编码器和Transformer解码器，支持25种语言。它在英文ASR上超越Whisper-large-v3并快10倍，同时在多语言任务上与大型模型表现相当。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个快速、鲁棒的多语言ASR和AST模型，以有效减少语音幻觉、提供准确时间戳，并在多语言场景下超越现有主流模型。

Method: 模型采用FastConformer编码器和Transformer解码器，支持25种语言。通过1.7M小时的混合数据（包含非语音音频）进行两阶段预训练和微调，并采用动态数据平衡。时间戳利用NeMo Forced Aligner (NFA) 结合辅助CTC模型生成。

Result: Canary-1B-v2在英文ASR上比Whisper-large-v3快10倍且性能更优，并在多语言ASR和AST上与Seamless-M4T-v2-large等大型模型表现出竞争力。实验表明FastConformer在微调后表现出色。同时发布了更小的多语言ASR模型Parakeet-TDT-0.6B-v3。

Conclusion: Canary-1B-v2成功提供了一个在速度、鲁棒性和多语言性能上均表现出色的ASR和AST解决方案，特别是在英文ASR上实现了显著的速度提升和性能超越，并在多语言复杂场景下展现了强大竞争力。

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [35] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

TL;DR: 介绍CS-FLEURS，一个用于开发和评估非高资源语言混码语音识别与翻译系统的新数据集。


<details>
  <summary>Details</summary>
Motivation: 开发和评估超越高资源语言的混码语音识别与翻译系统，并拓宽未来混码语音研究的范围。

Method: 发布CS-FLEURS数据集，包含4个测试集（覆盖52种语言的113个混码语言对）和一个128小时的训练集。测试集结合了真实人声、生成式文本到语音和拼接式文本到语音技术。

Result: 成功创建并提供了一个包含多样化混码语言对（包括低资源语言）的综合性测试和训练数据集CS-FLEURS。

Conclusion: CS-FLEURS数据集有望促进未来混码语音研究的发展和范围拓展。

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


### [36] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

TL;DR: 现有MLLM联想能力评估存在歧义，导致结果不可靠。本文提出AssoCiAm基准，通过分解歧义并采用混合计算方法，实现了更准确可靠的联想能力评估，并揭示了认知与联想的正相关。


<details>
  <summary>Details</summary>
Motivation: 联想能力是多模态大语言模型（MLLMs）迈向通用人工智能（AGI）的关键创造性特征。然而，现有联想能力评估框架常忽视任务固有的歧义性，这会削弱评估的可靠性。

Method: 将歧义分解为内部歧义和外部歧义两类。引入AssoCiAm基准，该基准采用混合计算方法来规避歧义，以评估联想能力。

Result: 实验发现认知与联想之间存在显著正相关；评估过程中歧义的存在会导致MLLMs的行为更趋随机。

Conclusion: 所提出的AssoCiAm方法能有效确保联想能力评估的准确性和可靠性。

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [37] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

TL;DR: 该研究提出了一个将行为金融学融入个性化金融建议的框架，并用此创建数据集微调8B模型，使其在性能上媲美更大的模型，同时显著降低了80%的成本。


<details>
  <summary>Details</summary>
Motivation: 个性化金融建议需要考虑用户多方面因素，现有LLM工作主要集中于投资者支持系统。同时，当前处理更广泛个人财务任务（如预算、债务管理）的代理式流水线成本高昂且效果不佳，投资回报率低于25%。

Method: 引入了一个新颖且可复现的框架，该框架整合了相关金融背景和行为金融学研究，以构建用于端到端顾问的监督数据。利用此框架创建了一个包含19k样本的推理数据集，并基于该数据集对Qwen-3-8B模型进行了全面的微调。

Result: 通过精心的数据整理和行为整合，该8B模型在事实准确性、流畅性和个性化指标上达到了与显著更大的基线模型（14-32B参数）相当的性能，同时运行成本比后者降低了80%。

Conclusion: 通过仔细的数据整理和行为整合，即使是较小的LLM（如8B模型）也能在个性化金融建议任务中展现出与大型模型相当的性能，并大幅降低成本，为开发高效且经济的金融顾问提供了可行方案。

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [38] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

TL;DR: 该研究对英美议会75年来的移民相关话语进行了大规模计算分析，发现美国话语日益两极化，而英国话语虽党派立场有别但总体一致，且叙事转向安全化，同时论及国际法和人权的比重增加。


<details>
  <summary>Details</summary>
Motivation: 旨在通过大规模计算分析，理解英美两国议会中移民话语的演变趋势、党派立场差异及细粒度叙事框架的变化，并验证大语言模型在政治和历史背景下进行细粒度话语分析的潜力。

Method: 使用开源大语言模型（LLMs）对每条声明进行高级别移民立场标注，追踪不同时期和党派对移民的整体态度。针对英国，进一步采用半自动化框架提取细粒度叙事框架，以捕捉话语的细微差别。

Result: 美国话语日益两极分化；英国议会态度在党派间相对一致，但工党与保守党之间存在持续的意识形态鸿沟，并预计在2025年达到最负面水平。英国叙事框架转向安全化（如边境控制、非法移民），而整合导向的框架（如社会融合）则有所下降。此外，关于移民的国家法律讨论逐渐被国际法和人权讨论所取代。

Conclusion: 大语言模型（LLMs）能够有效支持在政治和历史语境下进行可扩展、细粒度的话语分析。

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [39] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

TL;DR: Apertus是一个完全开放的大语言模型套件，旨在解决现有开放模型生态中数据合规性和多语言表示的不足。


<details>
  <summary>Details</summary>
Motivation: 解决当前开放模型数据合规性问题（如缺乏可复现数据管道，不尊重内容版权），并提升模型的多语言覆盖能力及降低记忆化风险。

Method: 仅使用公开数据进行预训练，并遵守robots.txt及过滤有害内容；采用Goldfish目标抑制记忆化；训练数据涵盖1800多种语言的15T tokens，其中约40%为非英语内容；发布8B和70B规模模型及所有开发工件（脚本、检查点、代码）。

Result: 在多语言基准测试中，Apertus模型在完全开放模型中接近最先进水平，性能可与甚至超越一些开放权重模型。

Conclusion: Apertus通过其在数据合规性、多语言能力和开发透明度方面的创新，为开放LLM生态系统做出了重要贡献，推动了该领域的进步。

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 本工作提出一种用于不确定性感知决策的证据检索机制，通过Dempster-Shafer理论融合检索到的近邻样本，形成实例自适应阈值，相比固定预测熵阈值，实现了更可靠、可解释的不确定性感知性能。


<details>
  <summary>Details</summary>
Motivation: 针对不确定性感知决策，旨在用证据条件化、实例自适应的准则取代单一全局阈值，以提高决策的透明度和可靠性。

Method: 对每个测试实例，在嵌入空间中检索近邻样本（证据）；使用Dempster-Shafer理论融合这些样本的预测分布，形成融合信念，作为实例自适应的决策阈值。

Result: 在CIFAR-10/100数据集上，使用BiT和ViT骨干网络进行实验，结果显示该机制与预测熵阈值相比，具有更高或相当的不确定性感知性能，显著减少了自信错误的判断，并保持了可持续的审查负担。实现这些改进仅需少量证据。

Conclusion: 证据条件化标记为操作性不确定性感知决策提供了一种比固定预测熵阈值更可靠、更可解释的替代方案。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [41] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [42] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 本研究提出了一个集成技术框架，通过优化YOLOv11-DIoU和改进DeepSort提升车辆感知精度，并构建GRU-Attention模型实现高速公路交通拥堵的准确预警。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通拥堵严重降低出行效率并阻碍区域互联互通。现有“检测-预测”系统存在缺陷，包括遮挡下车辆感知精度低和拥堵预测中长序列依赖关系缺失。

Method: 1. **交通流感知：** 将YOLOv11升级为YOLOv11-DIoU（用DIoU Loss替换GIoU Loss）；改进DeepSort，融合马氏距离（运动）和余弦距离（外观）。2. **拥堵预警：** 建立了GRU-Attention模型来捕获拥堵前兆；使用Greenberg模型分析高密度场景下的速度-密度关系。模型在长深高速公路视频数据上训练，包含流量、密度和速度数据。

Result: 1. **YOLOv11-DIoU：** mAP达到95.7%（比基线高6.5个百分点），遮挡漏检率为5.3%。2. **DeepSort：** MOTA达到93.8%（比SORT高11.3个百分点），仅发生4次ID切换。3. **Greenberg模型：** 速度和密度呈强负相关（r=-0.97）。4. **GRU-Attention：** 测试准确率达99.7%（比传统GRU高7-9个百分点），在10分钟提前预警30分钟拥堵时，时间误差 $\leq$ 1分钟。独立视频验证显示预警准确率95%，拥堵点空间重叠度超过90%。

Conclusion: 该集成框架为高速公路拥堵控制提供了量化支持，具有良好的智能交通应用前景。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [43] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 该研究利用卷积神经网络（CNNs）自动化了众包停车服务的地面实况测试过程，将人工时间减少了高达99.58%。


<details>
  <summary>Details</summary>
Motivation: 优化实时云端路边停车服务的质量，通过分析并自动化其现有地面实况测试过程，以替代分析过程中的人工工程工作。

Method: 应用机器学习方法，特别是图像模式识别，使用卷积神经网络（CNNs）来自动化分析过程，丰富数据库，并替代人工工程工作。

Result: 实现了高水平的自动化，使人力资源时间减少了高达99.58%。

Conclusion: 通过引入自动化分析工具，显著提升了停车服务质量测试的效率，大幅节省了人力资源，并为未来的发展和应用提供了展望。

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [44] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了视觉语言模型（VLMs）在零样本OOD检测中的工作机制、优势及鲁棒性。研究发现VLM的优越性源于其利用语义新颖性，且对图像噪声有弹性但对提示措辞高度敏感。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）在零样本OOD检测方面表现出色，但对其工作原理、相对于单模态方法的优势以及行为鲁棒性缺乏全面理解。

Method: 本研究采用系统性的实证分析方法，利用内部分布（ID）和外部分布（OOD）提示来研究基于VLM的OOD检测。具体包括：系统表征VLM嵌入空间中的关键操作属性；实证量化VLM相对于单模态方法的优越性；揭示其鲁棒性概况中的不对称性。

Result: 1. 阐明了VLM嵌入空间中促进零样本OOD检测的关键操作属性和机制。2. 证实并量化了VLM优于传统单模态方法的优势，并将其归因于VLM利用丰富语义新颖性的能力。3. 发现VLM-based方法对常见图像噪声具有弹性，但对提示措辞表现出高度敏感性。

Conclusion: 本研究增进了对VLM-based OOD检测的优势和关键脆弱性的理解，为未来开发更鲁棒、可靠的系统提供了重要的、基于经验的指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [45] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 利用截面曲率概念，为离散度量空间构建几何剖面，并用此量化评估数据表示效果及估计数据内在维度。


<details>
  <summary>Details</summary>
Motivation: 为离散度量空间构建几何剖面，并引入一种量化度量来评估数据表示（如降维技术）的有效性，同时估算数据集的内在维度。

Method: 基于新开发的截面曲率抽象概念，构建离散度量空间的曲率几何剖面。此曲率捕捉了三点之间及其与其它点的度量关系。

Result: 基于曲率剖面，提出量化度量以评估数据表示的有效性。实验表明，该曲率分析可估计数据集的内在维度，并可用于探索经验网络的宏观几何结构及评估降维技术。

Conclusion: 该研究提供了一种新的基于曲率的分析框架，能够量化评估数据表示质量和估计内在维度，为理解离散数据空间的几何特性提供有效工具。

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [46] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 本研究利用机器学习和遥感框架，分析斐济纳迪2013年至2024年土地利用和土地覆盖变化，旨在为城市化监测提供技术支持。


<details>
  <summary>Details</summary>
Motivation: 斐济作为发展中国家面临快速城市化和大规模开发项目，本研究的最终目标是为土地覆盖/土地利用建模和变化检测提供技术支持。

Method: 使用Landsat-8卫星图像；创建有标签的监督学习训练数据集；通过Google Earth Engine和k-means聚类生成土地覆盖图；利用卷积神经网络对选定区域的土地覆盖类型进行分类。

Result: 展示了变化检测的可视化结果，重点突出了城市区域随时间的变化，以监测地图上的变化。

Conclusion: 本研究提供了一套机器学习和遥感框架，成功可视化了斐济城市化进程中的土地变化，为土地覆盖/土地利用建模和变化检测提供了技术支持。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [47] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 提出一个新颖的三阶段框架，用于电力传输系统中的实时异物入侵（FOI）检测与跟踪，并针对边缘设备进行了优化部署。


<details>
  <summary>Details</summary>
Motivation: 解决电力传输系统在实际场景中，对异物入侵进行高效、鲁棒的实时检测与跟踪的需求。

Method: 该框架集成三部分：1. YOLOv7分割模型实现快速目标定位；2. 基于ConvNeXt和三重损失训练的特征提取器生成判别性嵌入；3. 特征辅助IoU跟踪器确保多目标在遮挡和运动下的弹性跟踪。为实现可扩展的现场部署，通过混合精度推理优化了在低成本边缘硬件上的部署，并支持无需重训练的模型增量更新。

Result: 在真实世界监控和无人机视频数据集上的广泛实验表明，该框架在各种异物入侵场景下均表现出高精度和鲁棒性。此外，在NVIDIA Jetson设备上的硬件基准测试证实了其在实际边缘应用中的实用性和可扩展性。

Conclusion: 该三阶段框架为电力传输系统中的实时异物入侵检测与跟踪提供了一个高效、鲁棒且实用的解决方案，特别适合在边缘计算环境中进行部署和应用。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [48] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: 该论文提出了EdiVal-Agent，一个自动化、可扩展、细粒度的多轮指令图像编辑评估框架，采用以对象为中心的方法，并结合VLM与对象检测器等工具进行评估。同时构建了EdiVal-Bench基准测试集。


<details>
  <summary>Details</summary>
Motivation: 指令式图像编辑进展迅速，但可靠、可解释的评估仍是瓶颈。现有协议要么依赖配对参考图像（覆盖范围有限，存在偏差），要么仅依赖零样本视觉-语言模型（VLM），其评估（指令遵循、内容一致性、视觉质量）往往不精确。

Method: 引入EdiVal-Agent框架，从以对象为中心的视角进行多轮指令编辑评估。它首先将图像分解为语义对象，然后合成多样的情境感知编辑指令。评估时，框架整合VLM与开放词汇对象检测器评估指令遵循，使用语义级特征提取器评估内容一致性，并利用人类偏好模型评估视觉质量。基于此构建了EdiVal-Bench，一个涵盖9种指令类型和11种SOTA编辑模型的多轮编辑基准。

Result: 研究表明，将VLM与对象检测器结合，在指令遵循评估中与人类判断的吻合度高于单独使用VLM和基于CLIP的指标。该管道的模块化设计允许未来工具的无缝集成，可随时间提高评估准确性。EdiVal-Agent能够识别现有模型的失效模式，从而为下一代编辑模型的开发提供信息。

Conclusion: EdiVal-Agent提供了一个全面、可扩展、可解释的评估解决方案，用于指令式图像编辑，有效解决了现有评估方法的局限性。它通过细粒度、以对象为中心的评估，揭示了模型性能的深层问题，并能指导未来编辑模型的改进与发展。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [49] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一种统一的基于Transformer的前馈模型，它能从图像和可选几何输入中直接回归度量3D场景几何和相机，从而在单个模型中解决多种3D视觉任务。


<details>
  <summary>Details</summary>
Motivation: 目前的3D视觉任务通常需要专业模型，而研究动机是开发一个能够统一处理广泛3D重建任务的通用3D重建骨干，提高效率并简化训练。

Method: MapAnything是一个基于Transformer的前馈模型，输入为一张或多张图像以及可选的几何输入（如相机内参、姿态、深度、部分重建）。它通过回归深度图、局部射线图、相机姿态和度量尺度因子等因子化多视图场景几何表示，将局部重建升级为全局一致的度量框架。模型通过标准化不同数据集的监督和训练，以及灵活的输入增强来实现这一点。

Result: MapAnything在广泛的实验分析和模型消融研究中，表现优于或与专业前馈模型持平。它提供了更高效的联合训练行为，并在单次前馈中处理了包括未校准SfM、校准多视图立体、单目深度估计、相机定位、深度补全等多种3D视觉任务。

Conclusion: MapAnything通过其卓越或匹配的性能以及高效的联合训练行为，为开发一个通用的3D重建骨干铺平了道路。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [50] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 本文提出SCM-PR框架，通过结合RGB图像的高层语义与LiDAR地图，实现鲁棒的跨模态地点识别，以克服现有方法对环境变化敏感及在复杂场景下表现不佳的问题，并在KITTI数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在无GPS环境下，机器人精确本地化是难题。现有RGB-based VPR方法对光照、天气等环境变化敏感。当前跨模态定位方法在复杂场景、精细匹配及视角变化时表现不足。

Method: 引入语义增强跨模态地点识别（SCM-PR）框架。该方法结合RGB图像高层语义与LiDAR地图。具体包括：使用VMamba作为RGB图像特征提取骨干；引入语义感知特征融合（SAFF）模块；设计融合语义与几何的LiDAR描述符；在NetVLAD中加入跨模态语义注意力机制；并利用语义信息在对比学习框架中设计多视图语义-几何匹配和语义一致性损失。

Result: 在KITTI和KITTI-360数据集上的实验表明，SCM-PR相较于其他跨模态地点识别方法取得了最先进的性能。

Conclusion: SCM-PR通过有效整合语义信息，显著提升了跨模态地点识别的鲁棒性与精度，成功解决了现有方法在复杂环境和各种变化下的挑战。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [51] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 本文提出用场景自适应格点矢量量化 (SALVQ) 替代3DGS数据压缩中现有方法的均匀标量量化 (USQ)，以提高R-D效率，并支持单一模型适应多码率目标。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS) 渲染效果好但数据量巨大，亟需高效压缩。现有锚点式神经压缩方法主要依赖简单的均匀标量量化 (USQ)，研究动机在于探索是否能以极小的额外开销，通过更复杂的量化器提升现有3DGS压缩方法的性能。

Method: 提出使用格点矢量量化 (LVQ) 替代USQ，并进一步开发了场景自适应格点矢量量化 (SALVQ)。SALVQ为每个场景优化格点基以捕捉场景特性，平衡了矢量量化的R-D效率与USQ的低复杂度。此外，SALVQ通过缩放格点基向量动态调整格点密度，使单一模型能适应多个比特率目标。

Result: SALVQ能无缝集成到现有3DGS压缩架构中，以最小的修改和计算开销提升其R-D性能。通过动态调整格点密度，一个模型即可适应多个比特率目标，显著减少了训练时间和内存消耗，无需为不同压缩级别训练多个模型。

Conclusion: SALVQ通过引入场景自适应格点矢量量化，有效提升了3DGS数据压缩的R-D效率和灵活性，在保持低复杂度的同时，实现了现有压缩方法的性能增强和多码率适配能力。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [52] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 为解决公共空间社交群体检测难题，本文提出了MINGLE三阶段管道（结合人体检测、VLM推理和空间聚合），并构建了一个100K图像的新数据集，用于识别和定位抽象人际关系定义的社交群体区域。


<details>
  <summary>Details</summary>
Motivation: 理解公共空间中的群体社交互动对城市规划至关重要。从图像中检测此类互动具有挑战性，因为它涉及解释超越传统目标检测的复杂视觉线索（如关系、距离、共同运动）。

Method: 引入“社交群体区域检测”任务，旨在推断和定位由抽象人际关系定义的视觉区域。提出MINGLE（建模人际群体级别参与）三阶段模块化管道，集成：1) 现成的人体检测和深度估计；2) 基于VLM的推理来分类成对的社交关系；3) 轻量级空间聚合算法来定位社交连接的群体。同时，构建了一个包含10万张城市街景图像的新数据集，标注了个人和社交互动群体，结合了人工标注和MINGLE管道输出。

Result: 成功定义并提出“社交群体区域检测”这一新任务；开发了MINGLE模块化管道以解决该任务；创建了包含10万张图像的全新大规模数据集，支持该任务并鼓励未来研究。

Conclusion: MINGLE方法和新数据集为理解和检测公共空间中的群体社交互动提供了有效工具，有助于城市规划和社会环境设计，并为未来研究奠定了基础。

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [53] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: 本文提出了BiasMap框架，利用注意力图发现并缓解文生图模型中潜在的概念级偏见（人口统计学-语义纠缠），通过能量引导的采样实现偏见缓解，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有偏见发现方法主要关注生成模型输出层面的统计分布偏见，但无法保证在缓解后概念表征的解耦。研究者需要深入探究图像生成过程中潜在的概念级（如人口统计学与职业）纠缠偏见。

Method: 提出模型无关的BiasMap框架，利用交叉注意力归因图揭示人口统计学（如性别、种族）与语义（如职业）之间在生成过程中的结构性纠缠。通过交并比（IoU）量化这种空间概念纠缠。进一步，通过能量引导的扩散采样，直接修改潜在噪声空间并在去噪过程中最小化预期的SoftIoU，以缓解偏见。

Result: 研究发现，现有公平性干预措施虽能减少输出分布差距，但常无法解耦概念级纠缠。而BiasMap的缓解方法能够有效降低图像生成中的概念纠缠，并与分布偏见缓解相辅相成。

Conclusion: BiasMap提供了一种新颖且有效的手段，能够揭示并缓解文生图模型中隐藏的潜在概念级表征偏见（人口统计学-语义纠缠），弥补了现有仅关注输出分布的偏见发现和缓解方法的不足。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [54] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePixel是一个Python实现的图形用户界面，旨在为实时图像采集系统提供灵活、实时的图像标注，以加速AI模型在实验工作流中的开发。


<details>
  <summary>Details</summary>
Motivation: 现有的图像标注工具缺乏灵活性，多需要预先收集的数据集，限制了按需管道的支持，并在实验室等需要实时数据采集的环境中阻碍了AI模型的部署。

Method: 引入LivePixel，一个基于Python的GUI，能够与摄像头、显微镜等成像系统集成，实现实时图像标注。它提供常见的图形编辑工具（如贝塞尔曲线、二进制掩码、非破坏性图层），并结合OpenCV和Numpy进行对象检测操作优化。

Result: LivePixel促进了数据的无缝收集和标注，显著加速了AI模型在实验工作流中的开发。

Conclusion: LivePixel通过提供集成实时成像系统的灵活标注工具，解决了现有工具的局限性，从而加快了AI模型在科学领域中的部署和发展。

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [55] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 提出DEFT-VTON方法，结合Doob's h-transform高效微调与自适应一致性损失，以极低的参数量和推理步数实现高质量虚拟试穿，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的虚拟试穿（VTO）方法需要大量训练和推理资源，不适用于资源和预算有限的实际应用场景。

Method: 1. 应用Doob's h-transform高效微调（DEFT）技术，将大型预训练无条件模型适配到VTO任务，通过冻结模型参数并训练一个小型h-变换网络，仅训练1.42%的参数。2. 引入自适应一致性损失，并以数据自适应方式将其与去噪分数匹配损失结合，以进一步提升DEFT的性能并减少推理时间。

Result: 所提出的DEFT-VTON方法在VTO任务上取得了最先进的性能。推理过程仅需15个去噪步，同时保持了极具竞争力的结果。

Conclusion: DEFT-VTON方法为虚拟试穿提供了一种资源高效且性能卓越的解决方案，通过显著减少训练参数和推理步数，成功克服了实际应用中的资源限制，并实现了SOTA表现。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [56] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 为解决自动驾驶中合成数据与真实数据间的域鸿沟问题，本文提出一种结合数据增强和新型生成网络的流水线，通过在Cityscapes数据集上添加虚拟行人，以提高行人识别能力，并评估其在语义和实例分割任务上的效果。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域中，合成数据对于覆盖特定交通场景至关重要，但其与真实数据存在显著的域鸿沟。本研究旨在通过提升数据增强的真实感来改善行人识别性能。

Method: 开发了一个数据增强流水线，用于在Cityscapes数据集中添加虚拟行人，以生成自定义交通场景。为提高增强数据的真实感，引入了一种新颖的生成网络架构，用于通过对抗学习来优化数据集的光照条件。该方法在语义分割和实例分割任务上进行了评估。

Result: 抽象中未提供具体的量化结果，但指出所提出的方法在语义分割和实例分割任务上进行了评估，旨在验证其在提高行人识别性能方面的有效性。

Conclusion: 该研究通过结合数据增强和新型生成网络，能够生成更具真实感的虚拟行人场景，有助于弥补合成数据与真实数据之间的域鸿沟，从而有望提升自动驾驶系统中的行人识别性能。

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [57] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出FunKAN和U-FunKAN，将Kolmogorov-Arnold网络推广到函数空间，用于医疗图像增强和分割，提供可解释且性能优越的解决方案。


<details>
  <summary>Details</summary>
Motivation: 医学图像增强与分割面临伪影和复杂解剖变异挑战。传统深度学习方法架构复杂且可解释性差。现有Kolmogorov-Arnold网络（KANs）虽可解释，但其扁平化特征表示破坏了图像的空间结构。

Method: 我们提出了功能性Kolmogorov-Arnold网络（FunKAN），这是一个专为图像处理设计的可解释神经网络框架。FunKAN将Kolmogorov-Arnold表示定理推广到函数空间，并利用基于Hermite函数基的傅里叶分解学习内部函数。同时，提出了U-FunKAN作为先进的二值医学分割模型。

Result: FunKAN在磁共振图像的Gibbs振铃抑制任务（IXI数据集）中表现出色。U-FunKAN在BUSI（乳腺癌）、GlaS（腺体）和CVC-ClinicDB（息肉）三个医学数据集上的分割任务中，其性能（IoU, F1）和图像增强性能（PSNR, TV）均优于其他基于KAN的骨干网络。

Conclusion: 本研究工作弥合了理论函数逼近与医学图像分析之间的差距，为临床应用提供了一种鲁棒且可解释的解决方案。

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [58] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 针对仇恨视频检测，本文提出一种多模态双流图神经网络模型（MultiHateGNN），通过实例图提取实例级特征并利用权重图突出仇恨实例，以提高检测效果和可解释性，达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨视频多模态检测方法通常忽略即使少量仇恨内容也能定义视频类别的问题，未能重点强调仇恨成分，且无法系统捕捉视频中的结构化信息，限制了多模态融合的有效性。

Method: 本文提出一种新颖的多模态双流图神经网络模型。该模型首先将视频分解为多个实例以构建实例图，提取实例级特征；然后，通过互补权重图为这些特征分配重要性权重，以突出仇恨实例。最终，结合权重和实例特征生成视频标签。模型采用图框架系统建模模态内和模态间的结构化关系。

Result: 在公开数据集上进行的广泛实验表明，所提出的模型在仇恨视频分类方面达到了最先进的水平，并具有强大的可解释性。

Conclusion: 本文提出的多模态双流图神经网络模型有效解决了现有仇恨视频检测方法中忽视关键仇恨内容和缺乏结构化信息建模的问题，实现了最先进的分类性能和良好的可解释性。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [59] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个基于扩散模型的结肠镜单目深度估计方法，通过合成数据和风格迁移实现时间一致性，达到SOTA零样本性能，并支持临床应用。


<details>
  <summary>Details</summary>
Motivation: 结肠镜3D场景理解需要精确的深度估计，但现有模型在视频序列中缺乏时间一致性，限制了其在3D重建中的应用。

Method: 提出ColonCrafter，一个基于扩散的深度估计模型，用于从单目结肠镜视频生成时间一致的深度图。该方法通过从合成结肠镜序列学习鲁棒的几何先验。同时引入风格迁移技术，在保留几何结构的同时，使真实临床视频适应合成训练领域。

Result: ColonCrafter在C3VD数据集上实现了最先进的零样本性能，优于通用和内窥镜专用方法。研究展示了其在3D点云生成和表面覆盖评估等临床相关应用。

Conclusion: ColonCrafter成功解决了单目结肠镜深度估计中的时间一致性挑战，取得了SOTA性能，并展示了实际的临床应用潜力，尽管完整的轨迹3D重建仍是一个挑战。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [60] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 该研究通过在体素空间合并冗余高斯原语以减少GPU内存占用，并通过Patch-Grid点采样初始化高斯原语以提高渲染质量，从而改进了3D Gaussian Splatting，适用于微型空中飞行器（MAVs）等嵌入式平台。


<details>
  <summary>Details</summary>
Motivation: 当前3D Gaussian Splatting（3DGS）研究主要关注桌面级GPU，忽视了计算和内存资源有限的嵌入式平台（如MAVs）。这些平台常面临系统性能与重建质量的权衡，需要改进现有方法以减少GPU内存使用并提升渲染质量。

Method: 为减少GPU内存占用，提出基于几何相似性在体素空间中合并SLAM中冗余的3D高斯原语。为提高渲染质量，通过Patch-Grid（PG）点采样初始化3D高斯原语，以更准确地建模整个场景。

Result: 所提方法在不影响系统运行时性能的前提下，有效减少了GPU内存使用。通过Patch-Grid点采样，渲染质量得到了提升。在公开数据集上的定量和定性评估证实了改进的有效性。

Conclusion: 本研究提出的方法成功地为3DGS在嵌入式平台上解决了GPU内存占用过高和渲染质量不足的问题，通过高斯合并和PG点采样显著优化了性能和质量。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [61] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 针对自动驾驶轨迹预测中的OOD问题，本文提出一种自适应框架，通过建模随时间变化的预测误差模式，实现了鲁棒的OOD检测，并在准确性和效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶轨迹预测模型在实际部署中面临训练数据与现实世界条件间的分布偏移，导致出现分布外（OOD）场景。现有OOD检测研究多集中于计算机视觉任务，轨迹级别的OOD检测仍未被充分探索。

Method: 在最快变化检测（QCD）问题表述的基础上，本文提出一个引入自适应机制的新框架。该方法通过显式建模预测误差（即使在分布内样本上）所表现出的随时间动态演变的模式依赖分布。

Result: 经验分析发现预测误差存在模式依赖且随时间动态演变。通过建模这些误差模式，本方法在检测延迟和误报率上均实现显著提升。在轨迹预测基准测试中，该框架在准确性和计算效率上显著优于先前的UQ和基于视觉的OOD方法。

Conclusion: 本文提出的框架为实现可靠、驾驶感知的自动驾驶提供了一条实用途径。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [62] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 利用深度学习和卫星图像对亚马逊森林砍伐进行检测并自动语义标注。


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林对地球气候和生物多样性至关重要，但森林砍伐对其造成严重影响，急需有效工具来监测和研究。

Method: 使用地球观测卫星的图像对，通过深度学习技术比较不同日期的图像以识别森林覆盖变化。提出视觉语义模型，利用从亚马逊相关科学文档中提取的关键词自动标注检测到的变化。

Result: 在亚马逊图像对数据集上评估了该方法，结果表明其在检测森林砍伐和生成相关注释方面有效。

Conclusion: 该方法为监测和研究亚马逊森林砍伐的影响提供了一个有用的工具，且具有通用性，可应用于其他领域。

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [63] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 该工作提出了一个智能多模态框架，利用视觉-语言模型（VLMs），特别是Google Gemini 2.5 Flash，实现多模态医学影像（如CT, MRI, X-ray, Ultrasound）的自动化肿瘤检测和临床报告生成，展示了高性能和零样本学习能力。


<details>
  <summary>Details</summary>
Motivation: 人工智能在医疗影像诊断中取得了快速进展，但仍需要更智能的多模态框架来进一步提升诊断医学和临床决策过程的效率与准确性。

Method: 该框架整合Google Gemini 2.5 Flash，结合视觉特征提取与自然语言处理，实现对CT、MRI、X光和超声等多种成像模态的自动化肿瘤检测和临床报告生成。方法包括上下文图像解释、坐标验证机制、异常分布的概率高斯建模、多层可视化技术（生成详细医疗插图、叠加比较和统计表示），以及利用精确提示工程和文本分析提取结构化临床信息。系统提供用户友好的Gradio界面，并支持零样本学习。

Result: 实验评估表明，该系统在多模态异常检测中表现出高性能。位置测量的平均偏差为80像素。系统还展示了零样本学习能力，有效减少了对大型数据集的依赖。

Conclusion: 该框架在自动化诊断支持和放射学工作流程效率方面取得了显著进展，但其广泛应用前仍需要进行临床验证和多中心评估。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [64] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: 本文将RoboCup 2024冠军赛中使用的2D定位算法CLAP（以其对异常值的鲁棒性著称）泛化至3D定位和图像拼接领域，并探讨其与RANSAC、Hough变换的关系。


<details>
  <summary>Details</summary>
Motivation: 扩展CLAP算法的应用范围，使其能够处理2D定位之外的更广泛任务（如3D定位和图像拼接），并提供一种替代传统异常值抑制方案（如RANSAC）的聚类策略。

Method: 将现有基于聚类的2D定位算法CLAP泛化为一个更通用的框架，并具体应用于3D定位和图像拼接。同时，分析CLAP、RANSAC和Hough变换之间的内在联系。

Result: 成功将CLAP泛化到3D定位和图像拼接等领域，并阐明了CLAP、RANSAC和Hough变换之间的关系。泛化后的CLAP有望在更多领域有效处理噪声和不确定性。

Conclusion: CLAP的泛化使其在处理噪声和不确定性方面具有广泛的适用性，可成为多领域的重要工具。

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [65] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR是一种高效医学图像配准框架，利用Segment Anything Model (SAM) 增强特征提取，通过任务特定适应、轻量级3D头部和分层特征一致性损失，在无需弱监督标签的情况下，显著优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督医学图像配准方法依赖稀缺的解剖学先验（如分割掩模或地标），限制了其实用性。本文受视觉基础模型强大表示学习能力的启发，旨在无需此类弱标签的情况下提高配准精度。

Method: 本文提出了SAMIR框架：1. 使用SAM的图像编码器设计任务特定适应管道，提取结构感知特征嵌入，而非直接使用原始图像。2. 设计一个轻量级3D头部，用于在嵌入空间中细化特征，以适应医学图像的局部形变。3. 引入分层特征一致性损失（Hierarchical Feature Consistency Loss），以指导从粗到细的特征匹配和改进解剖对齐。

Result: 广泛实验表明，SAMIR在受试者内心脏图像配准（ACDC数据集）上实现2.68%的性能提升，在受试者间腹部CT图像配准（腹部数据集）上实现6.44%的性能提升，显著优于现有最先进方法。

Conclusion: SAMIR成功利用视觉基础模型SAM的强大能力，在无需外部弱标签的情况下，实现了高效且高精度的医学图像配准，并在不同医学配准任务中均表现出卓越的性能。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [66] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 本文提出一种基于联邦学习的分布式方法，用于在保护数据隐私的前提下，从卫星图像中识别和定位森林砍伐。


<details>
  <summary>Details</summary>
Motivation: 准确识别卫星图像中的森林砍伐对于理解区域地理状况至关重要。传统集中式训练方法需要汇集数据，可能损害客户端的数据隐私和安全，因此需要一种分布式且注重隐私的解决方案。

Method: 该研究引入了一种新的分布式联邦学习（FL）框架，将客户端定义为负责本地数据处理的边缘卫星中心。框架利用FLOWER和RAY进行分布式学习工作负载执行和高效客户端生成。模型方面，使用了YOLOS-small、带有ResNet50骨干的Faster R-CNN以及带有MobileNetV3骨干的Faster R-CNN，并在公开数据集上进行了训练和测试。

Result: 该方法为卫星图像上的图像分割任务提供了一种新的视角。

Conclusion: 该联邦学习方法为卫星图像中的森林砍伐识别提供了一种创新的分布式解决方案，通过平衡协作训练与数据隐私，有望改进基于图像分割的卫星图像分析任务。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [67] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一个免训练框架，通过对齐独立重建的3D高斯混合模型来估计度量相对相机姿态，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统双视角姿态估计算法无法提供度量尺度，且在大基线、无纹理或反光表面下表现不佳。

Method: GARPS利用度量单目深度估计器和高斯场景重建器为每张图像构建度量3D高斯混合模型(GMM)，然后通过优化一个可微分的GMM对齐目标（综合考虑几何结构、颜色、协方差和语义特征）来精炼初始姿态。

Result: 在Real-Estate10K数据集上的实验表明，GARPS优于经典和最先进的基于学习的方法，包括MASt3R。

Conclusion: 结合单目感知和多视角几何在实现鲁棒且度量的相对姿态估计方面具有巨大潜力。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [68] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 本文提出一种基于查找表（lookup table）的通用高效操作，替代卷积神经网络中计算量大的乘法，从而提升模型在资源受限设备上的效率（能耗和推理速度），并保持或超越现有性能。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络（CNN）计算强度高，特别是乘法操作，其计算复杂度和能耗较高，推理时间长，阻碍了CNN在移动设备和资源受限边缘设备上的部署。

Method: 引入一种通用且高效的查找操作作为神经网络的基本操作，替代权重与激活值之间的乘法。为实现端到端优化，查找表被构建为可微分形式，并提出了多种训练策略以促进其收敛。通过将乘法替换为查找操作，开发了适用于图像分类、图像超分辨率和点云分类等任务的“查找网络”。

Result: 所提出的查找网络在能耗和推理速度方面表现出更高的效率，同时保持了与传统卷积网络相当的性能。在图像分类、图像超分辨率和点云分类等不同任务（分类和回归）及不同数据类型（图像和点云）上，查找网络均取得了最先进的性能。

Conclusion: 通过将计算昂贵的乘法替换为高效的查找操作，本文提出的查找网络在保持或提升性能的同时，显著提高了卷积神经网络在能耗和推理速度方面的效率，使其更适用于资源受限的边缘设备，并在多项任务上展现出卓越的性能。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [69] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 针对MLLM+SAM在Referring Image Segmentation (RIS)中视觉token冗余导致计算密集的问题，本文提出一种语义视觉投影器，利用SAM生成的语义超像素作为“视觉词”，将视觉token数量减少93%且不影响性能，显著加速MLLM的训练和推理，并超越现有压缩方法。


<details>
  <summary>Details</summary>
Motivation: RIS框架（MLLM+SAM）在适应分割任务时计算密集，主要原因在于视觉token冗余。传统的基于patch的视觉投影器难以在减少视觉token数量和保持语义清晰度之间取得平衡，通常保留过长的token序列以避免性能下降。

Method: 受文本tokenizer启发，提出了一种新颖的语义视觉投影器。该方法利用SAM生成的语义超像素作为图像中的“视觉词”，通过压缩和投影这些超像素来作为视觉token，从而根据场景复杂性自适应地缩短token序列，并最小化压缩中的语义损失。为进一步缓解信息丢失，还提出了语义超像素位置嵌入，以增强MLLM对超像素几何和位置的感知，并设计了语义超像素聚合器，以同时保留超像素内部的细粒度细节和外部的全局上下文。

Result: 实验表明，本文方法在不损害性能的前提下，将视觉token数量减少了93%。这显著加快了MLLM的训练和推理速度，并且在RIS任务上表现优于现有的压缩视觉投影器。

Conclusion: 本研究通过提出的语义视觉投影器有效解决了MLLM在RIS中视觉token冗余带来的计算效率低下问题。该方法不仅大幅减少了视觉token数量并加速了模型运行，还保持了卓越的性能，证明了其在提升视觉语言模型效率方面的有效性。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [70] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: 本文提出了FishBEV，一个专门为鱼眼相机设计的BEV分割框架，通过引入畸变鲁棒特征提取、不确定性感知空间对齐和距离感知时间自注意力机制，有效解决了鱼眼相机带来的挑战，并在基准测试中超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的BEV分割技术在针孔相机上取得了显著进展，但难以扩展到鱼眼相机。鱼眼相机存在严重的几何畸变、模糊的多视角对应和不稳定的时间动态，这些问题显著降低了BEV分割性能。

Method: 本文提出了FishBEV框架，包含三项创新：1) 畸变鲁棒多尺度提取（DRME）骨干网络，用于在畸变下学习鲁棒特征并保持尺度一致性；2) 不确定性感知空间交叉注意力（U-SCA）机制，利用不确定性估计实现可靠的跨视角对齐；3) 距离感知时间自注意力（D-TSA）模块，自适应平衡近场细节和远场上下文以确保时间连贯性。

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环视鱼眼BEV分割任务的性能评估上，持续优于现有SOTA基线方法。

Conclusion: FishBEV是一个针对鱼眼相机BEV分割的有效框架，通过其创新机制成功克服了鱼眼相机固有的挑战，并取得了卓越的性能，超越了现有最先进的方法。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [71] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 本研究提出基于样条的Kolmogorov-Arnold Networks (KANs) 模型（如SBTAYLOR-KAN）用于医疗图像分类。该模型在有限、多样化的数据集上表现出高精度、强大的泛化能力和稳定性，且仅需极少的参数，同时保持可解释性，非常适合资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 在计算机辅助诊断中，尤其是在资源有限的临床环境中，对医学图像进行有效且可解释的分类是一个重大挑战。

Method: 引入了基于样条的Kolmogorov-Arnold Networks (KANs) 模型，包括SBTAYLOR-KAN（结合B样条和泰勒级数）、SBRBF-KAN（结合B样条和径向基函数）以及SBWAVELET-KAN（B样条嵌入Morlet小波变换）。这些方法利用样条函数逼近来捕获局部和全局非线性。模型直接在脑部MRI、胸部X光、肺结核X光和皮肤病变图像等原始数据上进行评估，无需预处理。使用Grad-CAM进行可解释性分析。

Result: SBTAYLOR-KAN在广泛实验中，包括跨数据集验证和数据缩减分析，表现出强大的泛化性和稳定性。其最高准确率达98.93%，且在使用30%训练数据时，在三个数据集中仍能保持86%以上的准确率。在类不平衡的皮肤癌数据集中，SBTAYLOR-KAN也优于其他模型，达到68.22%的准确率。与传统的CNN（如ResNet50的24.18M参数）相比，SBTAYLOR-KAN仅需2,872个可训练参数即可达到可比性能。Grad-CAM验证了模型的区域相关性识别能力。

Conclusion: 该框架为医疗图像分类提供了一种轻量级、可解释且泛化性强的解决方案，成功应对了临床AI应用中数据集有限和数据稀缺的挑战。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [72] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 针对扩散模型滥用复制艺术风格的问题，本文提出StyleProtect策略。该方法通过更新扩散模型中选定的交叉注意力层，有效防御微调模型对艺术风格的模仿，并保持良好隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型等生成模型的发展，恶意使用者能够廉价复制艺术家的独特风格，尤其通过模型微调可实现高保真度模仿，这催生了保护艺术作品免受风格模仿的需求。

Method: 假设某些交叉注意力层对艺术风格高度敏感，通过测量注意力层对风格和内容表示的激活强度及其与外部模型特征的相关性来评估敏感性。基于此，提出轻量级保护策略StyleProtect，通过仅更新扩散模型中选定的交叉注意力层来实现对风格的防御。实验使用WikiArt和Anita数据集。

Result: 所提出的方法在保护艺术品和动漫的独特风格免受恶意扩散模型定制方面展现出良好性能，同时保持了有竞争力的不可察觉性。

Conclusion: StyleProtect提供了一种高效且轻量级的方案，能够有效防御微调扩散模型对艺术风格的模仿，成功保护作品的独有风格，并具备良好的隐蔽性。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [73] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth通过运动与不确定性感知精炼，改善了自监督单目深度估计在低纹理及动态区域的精度，并在KITTI上取得SOTA，且无推理时开销。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督单目深度估计算法在低纹理或动态区域等输入数据不确定性高的场景中，深度估计精度会降低。

Method: 提出了UM-Depth框架，结合运动感知和不确定性感知的精炼策略。通过师生训练机制，将不确定性估计嵌入训练流程和网络架构，加强光度信号弱区域的监督。该方法仅在训练期间的教师网络中使用光流，避免了推理开销和额外标签需求。

Result: 在KITTI和Cityscapes数据集上的广泛实验证明了不确定性感知精炼的有效性。UM-Depth在KITTI数据集上的自监督深度和位姿估计方面均达到了最先进的（SOTA）结果。

Conclusion: UM-Depth通过创新的运动与不确定性感知精炼策略以及独特的师生训练机制，有效解决了自监督单目深度估计在挑战区域的精度问题，并在KITTI数据集上取得了SOTA性能，且无额外推理成本。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [74] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 本文提出Triple Query Former (TQF)，通过将查询分解为动态、专业化的组件并结合运动感知聚合模块，解决了Referring Video Object Segmentation (RVOS) 中静态查询易受干扰导致的“查询选择偏差”问题。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS查询方法使用静态文本对象查询进行跨模态对齐，但易受外观或运动相似的干扰物误导，导致“查询选择偏差”问题。

Method: 提出TQF模型，将指代查询分解为外观查询（静态属性）、帧内交互查询（空间关系）和帧间运动查询（时间关联）三个专业组件。这些查询通过整合语言线索和视觉指导动态构建。此外，引入两个运动感知聚合模块：帧内交互聚合（增强帧内对象交互）和帧间运动聚合（利用轨迹引导对齐确保时间一致性）。

Result: 在多个RVOS基准测试中，TQF及其结构化查询设计和运动感知聚合模块展现出显著优势和有效性。

Conclusion: TQF通过其创新的动态、结构化查询设计和运动感知聚合模块，有效解决了RVOS中的查询选择偏差问题，提升了模型的性能和鲁棒性。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [75] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG是一个多任务通用视觉定位框架，首次将实例感知能力融入广义指代表达理解（GREC）和分割（GRES）任务，通过联合训练和实例查询实现了多粒度预测一致性，并达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理GREC和GRES，忽略了联合训练带来的多粒度预测一致性及流程简化优势。此外，现有GRES方法常将其视为语义分割，忽视了实例感知能力及其在实例级框和掩码间保持一致性的重要性。

Method: 提出InstanceVG框架，一个具备实例感知能力的多任务通用视觉定位框架。它利用实例查询来统一实例级框和掩码的联合与一致性预测。通过为每个实例查询分配一个先验参考点，该设计确保了同一实例的点、框和掩码预测的一致性，并辅助目标匹配。

Result: InstanceVG在十个数据集的四项任务上进行了广泛实验，结果显示其实现了最先进的性能，在各项评估指标上显著超越了现有方法。

Conclusion: InstanceVG是首个同时处理GREC和GRES并融入实例感知能力的通用视觉定位框架，有效解决了现有方法独立处理任务及缺乏实例感知能力的局限性，实现了多粒度预测的一致性。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [76] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: 针对图文人物检索任务，本文提出FMFA框架，通过A-SDM模块修正不匹配正样本，并引入EFA模块进行显式细粒度对齐，有效增强了跨模态匹配，取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前图文人物检索方法在跨模态对齐上面临挑战，主要表现为缺乏对局部特征对齐的验证能力，以及在模型更新时忽视了不匹配的正样本对。

Method: 提出FMFA（Full-Mode Fine-grained Alignment）框架，包含两个核心模块：1. 自适应相似度分布匹配（A-SDM）模块：通过在联合嵌入空间中自适应地拉近不匹配的正样本对，纠正不匹配的正样本，实现更精确的全局对齐。2. 显式细粒度对齐（EFA）模块：通过稀疏化相似度矩阵并采用硬编码方法进行局部对齐，加强显式跨模态细粒度交互，弥补隐式关系推理缺乏验证能力的问题。

Result: 在三个公共数据集上进行了评估，所提出的FMFA方法在所有全局匹配方法中取得了最先进的性能。

Conclusion: FMFA框架通过引入A-SDM和EFA模块，有效解决了现有方法中正样本对未匹配和局部对齐缺乏验证的问题，显著提升了图文人物检索的跨模态对齐精度和整体性能。

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [77] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 为解决文本驱动图像编辑中颜色控制精度与连续性不足问题，本文提出一个颜色映射模块，显式关联文本嵌入与RGB值，实现精细、连续且可控的颜色编辑。


<details>
  <summary>Details</summary>
Motivation: 文本驱动图像编辑在颜色控制上存在精度不足和难以连续控制的挑战，这源于自然语言的模糊性和离散性。现有线性插值文本嵌入的方法也无法精确控制颜色变化范围，且插值系数与颜色关系不明确。

Method: 引入一个颜色映射模块，该模块显式建模文本嵌入空间与图像RGB值之间的对应关系。它能根据给定RGB值预测相应的嵌入向量，从而在保持语义一致性的前提下，实现对生成图像颜色的精确控制。

Result: 实验结果表明，该方法在颜色连续性和可控性方面表现出色。

Conclusion: 通过构建文本嵌入与RGB值的显式映射，本研究有效提升了文本驱动图像颜色编辑的精度、连续性与可控性。

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [78] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 本文提出一种迭代提示词优化算法，利用视觉语言模型（VLM）结合视觉反馈，提升文本到图像（T2I）模型的安全性，并引入一个新数据集以支持监督微调。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像（T2I）模型输出的质量和安全性高度依赖提示词。传统安全方法仅通过大型语言模型（LLM）优化提示词，却忽视了生成的图像，可能导致不安全输出或对安全提示词进行不必要的修改。

Method: 本文提出一种迭代提示词优化算法，利用视觉语言模型（VLM）同时分析输入提示词和生成的图像。通过整合视觉反馈，该方法能更有效地优化提示词。此外，还引入了一个新的数据集，该数据集使用现成的多模态LLM进行文本和视觉安全信号的标注，以支持监督微调。

Result: 实验结果表明，该方法在提升安全性的同时，能有效保持用户意图，其可靠性与现有基于LLM的方法相当。通过实验验证，该方法能在不损害用户意图一致性的前提下，生成更安全的输出。

Conclusion: 本研究提供了一个生成更安全T2I内容的实用解决方案，通过整合视觉反馈机制，有效提升了T2I模型的安全性，并有望在实际应用中发挥作用。

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [79] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: TA-ISP是一个紧凑的RAW-to-RGB框架，通过多尺度调制算子生成任务导向表示，解决了现有方法计算开销大和表示能力受限的问题，显著提高视觉任务精度并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有RAW数据处理方法面临两大挑战：大型ISP网络计算成本高昂，而传统ISP管线调整方法表示能力不足，难以充分利用RAW数据提升视觉感知任务性能。

Method: 提出任务感知图像信号处理（TA-ISP），一个紧凑的RAW-to-RGB框架。它通过预测一组轻量级、多尺度的调制算子，在全局、区域和像素层面重塑图像统计信息，从而为预训练视觉模型生成任务导向的表示。这种分解控制方式在严格限制内存、计算和延迟的同时，显著扩展了空间变化变换的表示能力。

Result: 在白天和夜间RAW域检测与分割基准测试中，TA-ISP持续提升了下游任务的准确性，并显著减少了参数数量和推理时间。

Conclusion: TA-ISP因其在提升精度的同时大幅降低资源消耗，非常适合部署在资源受限设备上。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [80] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 针对夜间低光环境下去雨的挑战，本文提出一种新型夜间去雨位置增强感知网络（NDLPNet），通过位置感知模块有效处理雨条纹的空间信息，并构建了新的夜间雨景数据集（NSR），在夜间去雨任务上显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 夜间低光条件下的雨条纹严重影响夜间监控和自动导航性能。现有去雨技术主要针对白天，在夜间因雨分布异质性和光照依赖性而表现不佳。

Method: 提出夜间去雨位置增强感知网络（NDLPNet），旨在有效捕获低光环境下雨条纹的空间位置和密度分布信息。其中引入位置感知模块（PPM）来捕获并利用空间上下文信息。此外，构建了一个包含900对真实夜间场景图像的夜间雨景（NSR）数据集。

Result: NDLPNet能够有效去除雨条纹并保留关键背景信息。在现有数据集和新构建的NSR数据集上进行的广泛定性定量实验表明，所提方法在夜间去雨任务中持续优于现有最先进（SOTA）方法。

Conclusion: 本研究提出的NDLPNet有效解决了夜间低光环境下去雨的难题，通过创新网络结构和新建数据集为该领域的研究树立了新基准，显著提升了夜间视觉系统的性能。

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [81] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: 提出VocSegMRI多模态框架，融合视频、音频和音位信号，通过交叉注意力与对比学习，实现实时rtMRI发音结构的高精度分割，即使推理时音频不可用。


<details>
  <summary>Details</summary>
Motivation: 实时磁共振成像（rtMRI）中的发音结构分割主要依赖视觉线索，精度面临挑战；同步的声学和音位信号能提供互补上下文信息，有望提高精度。

Method: 引入VocSegMRI多模态框架，通过交叉注意力融合视频、音频和音位输入，实现动态特征对齐。此外，结合对比学习目标，以增强跨模态表示，即使推理时音频不可用也能提高分割性能。

Result: 在USC-75 rtMRI数据集子集上，实现了最先进的性能，Dice分数为0.95，95th百分位Hausdorff距离（HD_95）为4.20 mm，优于单模态和多模态基线。消融研究证实了交叉注意力和对比学习对分割精度和鲁棒性的贡献。

Conclusion: 集成多模态建模对于准确分析声道具有重要价值。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [82] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 提出一种基于扩散先验的生成式编码框架，用于在低比特率下显著提升视觉内容的压缩性能和感知质量，尤其适用于自然与AI生成混合内容。


<details>
  <summary>Details</summary>
Motivation: 随着生成技术发展，视觉内容日益复杂（自然与AI生成混合），需要更高效且优先考虑感知质量的编码技术。传统和现有学习方法在低比特率下难以保持主观质量，而现有生成方法则面临视觉保真度和泛化性挑战。

Method: 本研究提出一种利用扩散先验的生成式编码框架。该方法使用预优化编码器生成广义压缩域表示，并通过轻量级适配器和注意力融合模块与预训练扩散模型的内部特征集成。此外，还引入了分布重归一化方法以增强重建保真度。

Result: 实验表明，该方法在低比特率下视觉保真度优于现有方法，压缩性能比H.266/VVC提升高达79%，为AI生成内容提供了高效解决方案，并能适应更广泛的内容类型。

Conclusion: 本研究提供了一个新颖、高效且可适应的生成式编码框架，通过利用扩散先验，在低比特率下实现了卓越的压缩性能和视觉保真度，有效解决了混合视觉内容编码的挑战。

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [83] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive是一个受快慢思维启发的VLA框架，通过自适应推理机制，在自动驾驶中平衡了CoT决策质量和计算效率，提升了性能并减少了推理时间。


<details>
  <summary>Details</summary>
Motivation: 链式思维（CoT）虽在VLA模型中广泛应用并在自动驾驶中展现潜力，但在简单场景下引入不必要的计算开销，未能有效提升决策质量。

Method: ['提出AdaThinkDrive，一个基于快慢思维的双模推理VLA框架。', '框架通过QA和轨迹数据集在大规模自动驾驶场景上进行预训练，以获取世界知识和驾驶常识。', '在监督微调（SFT）阶段，引入包含无CoT的快速回答和有CoT的慢速思考的双模数据集，使模型能区分需要推理的场景。', '结合Group Relative Policy Optimization (GRPO)，提出自适应思考奖励策略，通过比较不同推理模式下的轨迹质量，奖励模型选择性地应用CoT。']

Result: ['在Navsim基准测试中，AdaThinkDrive的PDMS达到90.3，超过最佳纯视觉基线1.7点。', '消融实验表明，AdaThinkDrive分别比“从不思考”和“总是思考”基线提升PDMS 2.0和1.4。', '推理时间比“总是思考”基线减少14%。']

Conclusion: AdaThinkDrive通过其自适应推理能力，成功在自动驾驶场景中平衡了决策的准确性与计算效率。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [84] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 为解决Deepfake伪造区域定位中现有方法忽视局部-全局互补性及融合策略缺陷问题，本文提出一种新方法，独立预测局部和全局操纵区域，并使用形态学操作进行融合，有效抑制噪声，提高定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测领域日益需要精确的操纵区域定位，但现有方法在此方面仍面临挑战。主要痛点是：1) 它们常忽略局部细节与全局语义上下文的互补性；2) 局部和全局预测的简单融合策略会放大噪声和错误，影响定位效果。

Method: 本文提出一种新颖方法，该方法独立地从局部和全局视角预测被操纵区域。为有效融合这些预测结果，采用形态学操作来抑制噪声并增强空间连贯性。

Result: 广泛的实验证明，该方法中的每个模块都能有效提高伪造区域定位的准确性和鲁棒性。

Conclusion: 通过独立地从局部和全局视角预测操纵区域，并结合形态学操作进行智能融合，本文提出的方法能够有效克服现有技术在Deepfake伪造区域定位中的不足，显著提升定位的准确性和鲁棒性。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [85] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 提出了一种名为Variable-Rate Spatial Event Mamba (VSEM)的新架构，它直接处理原始事件流，通过轻量级空间编码器和基于Mamba的状态空间模型，以线性复杂度实现可伸缩的时间建模，并能自适应调整处理速度，有效解决现有事件相机方法的延迟和计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机方法常将事件流转换为中间表示（如帧、体素网格、点云），引入预定义时间窗导致窗口延迟；点式检测方法因计算成本高昂而难以实现实时效率。

Method: 提出Variable-Rate Spatial Event Mamba (VSEM)架构，直接处理原始事件流。该方法引入轻量级因果空间邻域编码器捕获局部几何关系，并结合基于Mamba的状态空间模型进行可伸缩的时间建模，具有线性复杂度。推理时，控制器根据事件速率自适应调整处理速度。

Result: 通过直接处理原始事件流，避免了中间表示及其导致的窗口延迟。利用Mamba模型实现了线性复杂度的可伸缩时间建模。自适应控制器能在窗口延迟和推理延迟之间取得最佳平衡。

Conclusion: VSEM架构成功克服了现有事件相机方法在延迟和计算效率上的限制，通过直接处理原始事件流和自适应处理速度，为高速视觉任务提供了更高效、低延迟的解决方案。

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [86] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: 为解决扩散Transformer（DiTs）视频生成的高延迟问题，本文提出无训练的BWCache方法，通过动态缓存和复用DiT块的特征，实现了高达2.24倍的加速，并保持了视觉质量。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer（DiTs）是视频生成的最新SOTA方法，但其固有的顺序去噪过程导致高延迟，限制了实际应用。现有加速方法或牺牲视觉质量，或未能有效复用中间特征。分析发现DiT块是推理延迟的主要贡献者，且其特征在中间时间步具有高相似性，存在大量计算冗余。

Method: 提出无训练的块级缓存（BWCache）方法，以加速基于DiT的视频生成。BWCache动态缓存并复用DiT块在不同扩散时间步的特征。同时，引入一个相似性指标，仅当相邻时间步的块特征差异低于特定阈值时才触发特征复用，从而最小化冗余计算并维持视觉保真度。

Result: 在多个视频扩散模型上的广泛实验表明，BWCache方法在保持可比视觉质量的前提下，实现了高达2.24倍的加速。

Conclusion: BWCache通过创新的块级特征缓存与复用策略，有效解决了DiT视频生成中的高延迟问题，在显著提升速度的同时，成功维持了输出的视觉质量。

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [87] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 本文提出一个新基准VHBench-10以系统分析大型视觉语言模型中视觉编码器导致的细粒度幻觉问题，并提出了VisionWeaver，一个上下文感知路由网络，显著减少了幻觉并提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）中的物体幻觉严重阻碍了其在现实世界的应用。作者假设不同的视觉编码器因其训练范式不同而具有独特的归纳偏置，导致其幻觉表现各异，而现有基准未能捕获这些细粒度的幻觉。

Method: 研究者引入了VHBench-10，一个包含约10,000个样本的综合基准，用于评估LVLM在十个细粒度幻觉类别上的表现。在此基础上，他们提出了VisionWeaver，一个新颖的上下文感知路由网络，利用全局视觉特征生成路由信号，动态聚合来自多个专业视觉专家的特征。

Result: 评估证实了不同的编码器确实表现出独特的幻觉特性。通过全面的实验，VisionWeaver被证实能显著减少幻觉并提高模型的整体性能。

Conclusion: 研究证实了视觉编码器在LVLM幻觉中的关键作用及其多样性。VHBench-10提供了一个系统分析幻觉的工具，而所提出的VisionWeaver通过动态特征聚合，有效解决了物体幻觉问题并提升了模型表现。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [88] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 针对航天器位姿估计，本文提出首个监督域适应 (SDA) 框架，利用少量真实标注数据有效克服合成-真实域差距，实现高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 航天器位姿估计是自主空间操作的核心能力。现有混合管线在合成数据上表现出色，但在真实数据上由于合成-真实域差距性能急剧下降。当有少量真实标注数据时，现有无监督域适应方法表现不佳，因此需要一种新的监督域适应方法来解决此问题。

Method: 本文提出了首个专为航天器位姿估计关键点回归设计的监督域适应 (SDA) 框架。该方法基于学习不变表示和风险 (LIRR) 范式，通过同时利用合成标注数据和有限的真实标注数据，联合优化域不变表示和任务特定风险。

Result: 在 SPEED+ 基准测试中，该方法持续优于仅源模型、微调和基线模型。值得注意的是，仅用5%的真实标注数据，其性能即可匹敌甚至超越使用更多标注数据训练的基线模型。该框架轻量、与骨干网络无关且计算高效。

Conclusion: 该框架为在实际空间环境中实现鲁棒和可部署的航天器位姿估计提供了一条实用途径，有效缓解了合成-真实域差距问题。

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [89] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 为解决GNSS受限环境下无人机定位问题，本文提出大规模多高度飞行数据集MAFS和一种新型语义加权自适应粒子滤波（SWA-PF）方法，显著提升了计算效率和定位精度，实现快速姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的无人机定位方法在GNSS受限环境中面临数据集不足、实时性能差、环境敏感性高以及泛化能力有限（尤其在动态或时变环境）等挑战。

Method: 本文构建了一个大规模多高度飞行数据集MAFS，并提出一种语义加权自适应粒子滤波（SWA-PF）方法。该方法通过语义加权机制和优化的粒子滤波架构，有效整合无人机图像与卫星图像的语义特征。

Result: 所提方法在计算效率上比传统特征提取方法提高了10倍，全球定位误差保持在10米以内，并能利用低分辨率卫星地图在数秒内实现快速的4自由度（4-DoF）姿态估计。

Conclusion: SWA-PF方法在GNSS受限环境中为无人机提供了高效、精准且鲁棒的定位和姿态估计解决方案，有效克服了现有方法的局限性，尤其适用于动态和多变环境。

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [90] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 本文提出Masked Feature Modeling (MFM)，一种新的辅助任务，通过特征掩码和重建，在特征空间中直接操作，有效提升无监督域适应语义分割的性能，且与主流架构兼容。


<details>
  <summary>Details</summary>
Motivation: 无监督域适应（UDA）语义分割中，对比学习已提升特征判别性，但掩码建模（masked modeling）方法因架构不兼容和优化目标不一致而未被充分探索。

Method: 引入Masked Feature Modeling (MFM)，它在特征空间进行特征掩码和重建，并将学习目标与主分割任务对齐。MFM与DeepLab、DAFormer等标准架构兼容，无需修改推理流程。使用轻量级辅助模块Rebuilder协助重建（推理时丢弃），并利用分割解码器分类重建特征，紧密耦合辅助与主任务。

Result: 在多种架构和UDA基准测试中，MFM持续提升了分割性能。

Conclusion: MFM为无监督域适应语义分割提供了一个简单、高效且泛化性强的策略，显著增强了性能。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [91] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 高光谱图像光谱分类中，现有最佳模型在数据有限时性能下降。本文提出MiniROCKET，在数据受限场景下超越现有最佳模型，并在一般情况下保持同等水平。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像的光谱分类应用广泛，但当前最先进模型1D-Justo-LiuNet在训练数据有限时性能下降。急需找到一种对有限数据更鲁棒的光谱分类方法。

Method: 引入并研究MiniROCKET和HDC-MiniROCKET模型进行光谱分类。MiniROCKET的特征提取部分不含可训练参数，使其不易受限于有限训练数据。

Result: 在有限训练数据场景下，MiniROCKET的性能优于1D-Justo-LiuNet；在普遍情况下，MiniROCKET的性能与1D-Justo-LiuNet基本持平。

Conclusion: MiniROCKET为高光谱图像光谱分类提供了一种更稳健的方法，尤其在训练数据有限时表现更优，能有效解决现有模型在该场景下的性能瓶色。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [92] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: 本文提出Semi-MOE，一个多任务混合专家框架，通过利用专业专家网络和鲁棒的伪标签机制，解决了半监督组织病理学图像分割中伪标签噪声问题，并在低标签设置下超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有半监督组织病理学图像分割方法面临伪标签噪声问题，根源在于腺体边界模糊和形态学误分类，亟需更有效的伪标签生成与管理机制。

Method: 引入Semi-MOE框架，它包含三个专业专家网络（主分割、符号距离场回归、边界预测），旨在捕捉不同形态特征。采用Multi-Gating伪标签模块动态聚合专家特征，实现鲁棒的伪标签融合与细化。此外，提出自适应多目标损失以动态平衡学习目标并避免手动调优。

Result: 在GlaS和CRAG基准测试中，该方法在低标签设置下表现优于现有最先进方法，证明了其有效性。

Conclusion: Semi-MOE框架成功克服了半监督组织病理学图像分割中的伪标签噪声挑战，并凸显了基于MoE的架构在推动半监督分割领域中的巨大潜力。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [93] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 本文挑战现有表征学习中视图无关性假设，提出“一致视图对齐”自监督学习方法，通过显式诱导潜在空间结构来提升下游任务性能，并在MICCAI 2025 SSL3D挑战中获得佳绩。


<details>
  <summary>Details</summary>
Motivation: 现有表征学习方法普遍假设数据点不相关的视图足以学习有意义的表征，但本文指出潜在空间中有意义的结构不会自然生成，而需要被显式诱导。

Method: 提出了一种名为“一致视图对齐”（Consistent View Alignment）的自监督学习方法。该方法通过对齐数据不同视图的表征，以整合互补信息，同时避免引入假阳性。

Result: 实验证明，所提出的“一致视图对齐”方法显著提升了下游任务的性能。在MICCAI 2025 SSL3D挑战赛中，该方法分别使用Primus vision transformer和ResEnc卷积神经网络获得了第一名和第二名。

Conclusion: 研究表明，结构化的视图对齐对于学习有效的表征至关重要。本文提出的方法成功地通过显式诱导潜在空间结构，提升了表征学习的效果和下游任务的性能。

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [94] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecDiff是一种新的扩散模型加速方法，通过自我推测引入未来信息并结合历史信息进行特征缓存，显著提高了推理速度（最高3.17倍），同时保持了可忽略的质量损失，有效解决了加速与精度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型特征缓存方法仅依赖历史信息，导致其在精度和速度性能上受到限制。

Method: 提出了一种名为SpecDiff的无训练多级特征缓存策略。该策略通过基于同一时间步长在不同迭代次数间的信息相似性进行自我推测，引入了未来信息。SpecDiff包含：1. 基于自我推测信息的特征选择算法，结合自我推测和历史信息为token确定动态重要性分数，并据此选择缓存特征。2. 基于特征重要性分数的多级特征分类算法，利用重要性分数的差异对token进行分类，并引入多级特征计算策略。

Result: 在NVIDIA A800-80GB GPU上，与RFlow相比，SpecDiff在Stable Diffusion 3、3.5和FLUX上分别实现了平均2.80倍、2.74倍和3.17倍的加速，且质量损失可忽略不计。

Conclusion: 通过融合推测性信息和历史信息，SpecDiff克服了扩散模型高效推理中的加速-精度权衡瓶颈，推动了加速和精度方面的帕累托前沿。

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [95] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 本文提出Gated Residual Tokenization (GRT) 方法和DIVE基准，以解决现有VLLM在处理高帧率视频时缺乏密集时间信息的问题，实现了高效、可扩展的高帧率视频理解。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型(VLLM)和基准主要采用低帧率采样，丢弃了密集的时序信息，导致无法捕捉视频的精细细节，且难以应对需要精确时间对齐的密集信息任务。此外，对每一帧进行Token化成本高昂，而现有基准也缺乏针对密集时序推理的能力。

Method: 引入了密集视频理解(DVU)框架，旨在通过减少Token化时间和开销实现高帧率视频理解。提出了DIVE (Dense Information Video Evaluation) 基准，用于密集的时序推理。核心方法是Gated Residual Tokenization (GRT)，一个两阶段框架：1) 运动补偿帧间门控Token化，利用像素级运动估计跳过静态区域，实现Token数量和计算的亚线性增长；2) 语义场景帧内Token化融合，在场景内融合静态区域的Token，进一步减少冗余并保留动态语义。

Result: 在DIVE基准测试中，GRT方法表现优于更大规模的VLLM基线模型，并且其性能能够随着帧率(FPS)的提高而正向扩展。

Conclusion: 研究结果突显了密集时间信息的重要性，并证明GRT能够实现高效、可扩展的高帧率视频理解。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [96] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: 本文提出EDITS框架，通过利用图像的隐式文本语义，结合VLM和LLM生成文本与图像原型，并通过扩散模型生成最终合成数据集，以增强数据集蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏技术主要捕捉低级视觉特征，忽略了图像中固有的高级语义和结构信息，导致蒸馏效果受限。

Method: EDITS框架首先利用VLM生成的外部文本与图像特征通过全局语义查询模块融合，形成聚类缓冲区。随后，局部语义感知从缓冲区中选择代表性样本构建图像和文本原型（后者由精心设计的提示引导LLM生成）。最终，双原型指导策略通过扩散模型生成最终的合成数据集。

Result: 大量实验证实了我们方法的有效性。

Conclusion: EDITS框架通过利用隐式文本语义显著增强了数据集蒸馏的效果，实现了更高效且性能优越的学习。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [97] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: LamiGauss是一种新的层析成像重建算法，它结合了高斯辐射栅格化和专门的转换模型，即使在极度稀疏视角下也能高效、准确地重建板状结构，并且性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: X射线计算层析成像(CL)对于微芯片和复合电池材料等板状结构的无损检测至关重要，但从层析投影中重建高质量体积仍然面临挑战，尤其是在极度稀疏视角采集条件下。

Method: 提出LamiGauss算法，该算法结合了高斯辐射栅格化(Gaussian Splatting radiative rasterization)和一个包含层析倾斜角的专用探测器到世界坐标系转换模型。LamiGauss还采用了一种初始化策略，可明确过滤初步重建中的常见层析伪影，从而将模型容量集中于表示真实物体。

Result: LamiGauss能直接从稀疏投影中有效优化，实现有限数据下的准确高效重建。在合成和真实数据集上的广泛实验证明了该方法相较于现有技术的有效性和优越性。LamiGauss仅使用3%的完整视图就能比在完整数据集上优化的迭代方法取得更优异的性能。

Conclusion: LamiGauss通过创新的算法设计，成功解决了稀疏视角下层析成像重建的难题，显著提升了重建质量和效率，其性能优于现有技术。

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [98] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: 本文提出一种干扰物感知的记忆模块及管理方法（DAM4SAM），显著提升了视觉目标跟踪在面对干扰物和遮挡时的性能，并在多个基准上达到SOTA，同时构建了DiDi数据集。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆的视频分割方法（如SAM2）在视觉目标跟踪任务中，面对干扰物时易产生跟踪漂移，且遮挡后重识别能力弱，未能充分适应跟踪需求。

Method: 本文提出一个针对SAM2的干扰物感知（distractor-aware）插入式记忆模块和内省式管理方法，命名为DAM4SAM。此外，构建了一个用于分析干扰物存在下跟踪性能的DiDi（Distractor-Distilled）数据集。

Result: DAM4SAM有效减少了对干扰物的跟踪漂移，并改进了目标遮挡后的重识别能力。在13个基准测试中，DAM4SAM优于SAM2.1，并在其中10个上取得了新的最先进结果。将其集成到实时跟踪器EfficientTAM中，性能提升11%，且达到非实时SAM2.1-L的跟踪质量；集成到边缘跟踪器EdgeTAM中，性能提升4%，显示出良好的架构泛化性。

Conclusion: 所提出的干扰物感知记忆模块和管理方法显著提升了视觉目标跟踪在处理干扰物和遮挡时的性能，并在不同架构上展现出良好的泛化能力。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [99] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一个双流注意力网络，通过融合原始X射线和分割骨骼图像，显著提高了骨盆骨折（包括隐匿性骨折）的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 标准X射线诊断骨盆骨折面临挑战，尤其当骨折迹象不明显或不可见时，诊断难度大。

Method: 引入PelFANet，一个双流注意力网络，融合原始骨盆X射线图像和分割后的骨骼图像，以改善骨折分类。该网络使用融合注意力块（FABlocks）迭代交换和细化来自两种输入的特征，捕捉全局背景和局部解剖细节。采用两阶段分割引导的训练流程。

Result: 在AMERI数据集上，对可见骨折实现了88.68%的准确率和0.9334的AUC。对未经训练的隐匿性骨折病例，泛化能力良好，达到82.29%的准确率和0.8688的AUC。性能优于传统方法。

Conclusion: 解剖学感知的双输入架构在鲁棒性骨折检测中具有重要的临床应用潜力，特别适用于射线表现不明显的病例。

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [100] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: 本文提出了EvHand-FPV，一个用于单事件相机的轻量级自我中心第一人称视角（FPV）3D手部跟踪框架，实现了高精度、低延迟和高能效，适用于XR设备。


<details>
  <summary>Details</summary>
Motivation: 传统的帧基手部跟踪方法在资源受限的XR设备中难以满足精度、低延迟和能效要求。事件相机通过异步感知亮度变化，能提供微秒级时间分辨率和毫瓦级功耗，为解决此问题提供了潜力。

Method: EvHand-FPV框架通过以下方式实现：1) 构建了一个结合合成训练数据（带3D标签）和真实事件数据（带2D标签）的事件基FPV数据集；2) 引入了基于手腕的兴趣区域（ROI），通过几何线索定位手部；3) 采用端到端映射策略，将ROI偏移量嵌入网络以减少计算量，避免显式重建；4) 利用多任务学习策略，通过辅助几何特征头提高表示能力，且不增加测试时的开销。

Result: 在真实FPV测试集上，EvHand-FPV将2D-AUCp从0.77提升至0.85，同时将参数量减少了89%（从11.2M降至1.2M），并将每次推理的FLOPs减少了89%（从1.648G降至0.185G）。在合成数据上，它保持了0.84的竞争力3D-AUCp。

Conclusion: 这些结果表明EvHand-FPV能够实现准确且高效的自我中心事件基手部跟踪，非常适合在XR设备上进行应用。

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [101] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 针对少样本3D点云分割（FS-PCS）中现有原型生成方法的随机性问题，本文提出白化聚合与恢复模块（WARM），通过在交叉注意力机制中嵌入白化和着色变换，有效解决支持特征与原型标记间的分布不匹配，从而生成更具代表性的原型，并显著提升FS-PCS性能达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有FS-PCS原型生成方法（如最远点采样）的初始随机性严重影响性能，且原型生成过程未被充分探索。作者旨在探索基于注意力机制的先进原型生成方法，以克服现有方法的局限性，并解决朴素注意力模块中存在的学习原型标记与支持特征间的分布差距。

Method: 提出白化聚合与恢复模块（WARM）。该模块通过在交叉注意力机制前后分别嵌入白化（whitening）和着色（coloring）变换来解决原型标记和支持特征之间的分布不匹配。具体而言，白化在注意力处理前将支持特征对齐到原型标记，着色随后恢复处理后标记的原始分布，从而实现鲁棒的注意力机制，捕获支持特征间的语义关系以生成有代表性的原型。

Result: 所提出的方法在多个FS-PCS基准测试中取得了显著优于现有SOTA性能的结果。

Conclusion: WARM模块通过其创新的白化和着色机制，有效解决了FS-PCS中原型生成的核心挑战，实现了鲁棒且有代表性的原型构建，并通过广泛实验证明了其卓越的有效性和性能。

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [102] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 本文提出Self-Rationale Calibration (SRC) 框架，通过迭代校准大型视觉-语言模型（LVLMs）的原理与答案对齐，显著提升其视觉问答能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LVLMs在视觉问答中表现强大，但它们在原理和生成答案的对齐上仍存在不足，导致推理不一致和回答错误。

Method: 引入SRC框架，迭代校准原理与答案的对齐。具体包括：1) 轻量级“原理微调”，使模型在无显式提示下先生成原理后回答；2) 为每个样本生成多样化候选响应，并使用定制的R-Scorer模型通过成对评分策略评估原理质量和事实一致性；3) 基于置信度加权的偏好策展过程，将对齐校准转化为偏好微调。

Result: SRC框架显著提升了LVLMs在多个基准测试中的感知、推理和泛化能力。

Conclusion: 研究结果强调了面向原理的对齐在挖掘LVLMs潜力方面的重要性。

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [103] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 针对扩散模型生成内容滥用，现有保护性扰动易被净化移除的问题，本文提出了AntiPure方法。它通过逐块频率引导和错误时间步引导两种机制，嵌入持久且不可察觉的扰动，有效抵御净化，在定制后对图像造成显著失真，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视觉合成中具有强大定制能力，但也带来了深度伪造和版权侵犯等严重安全风险。现有保护性扰动方法可通过注入对抗性噪声来缓解图像滥用，但净化技术能够移除这些扰动，使图像再次面临恶意伪造的风险。因此，迫切需要开发能够抵御净化的保护性扰动。

Method: 本文形式化了抗净化任务，并提出了一种诊断性保护性扰动AntiPure。该方法通过两种引导机制暴露“净化-定制”工作流中净化的脆弱性：1) 逐块频率引导，降低模型对净化图像高频成分的影响；2) 错误时间步引导，扰乱模型在不同时间步的去噪策略。通过这些引导，AntiPure能嵌入在代表性净化设置下依然持久且不可察觉的扰动。

Result: 实验结果表明，作为净化方法的压力测试，AntiPure实现了最小的感知差异和最大的定制后失真。在“净化-定制”工作流中，AntiPure的表现优于其他保护性扰动方法。

Conclusion: AntiPure成功开发了一种能够有效抵御净化的保护性扰动，通过独特的引导机制，确保嵌入的扰动在图像定制后依然保持，从而有效防止恶意滥用，并展现出优越的性能。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [104] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 本文提出噪声水平引导（NLG），一种简单高效的噪声优化方法，无需额外训练，通过优化初始噪声提高扩散模型的图像生成质量和条件依从性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型中初始的随机高斯噪声会影响最终输出的图像质量和提示依从性。现有噪声优化方法依赖额外数据集、网络或反向传播，实用性受限。

Method: 提出噪声水平引导（NLG），这是一种简单、高效且通用的噪声水平优化方法。它通过增加初始噪声与通用指导对齐的可能性来优化噪声，无需额外训练数据、辅助网络或反向传播。NLG提供了一个统一框架，适用于条件和无条件扩散模型。

Result: 在五个标准基准上进行的大量实验表明，NLG方法显著提高了生成输出的质量和输入条件的依从性。

Conclusion: NLG通过与现有指导方法无缝集成并保持计算效率，成为扩散模型实用且可扩展的增强方案。

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [105] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: 论文提出了PairTally数据集，用于评估细粒度视觉计数任务，并发现现有先进模型在该任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 视觉计数，尤其是在复杂场景中进行细粒度、意图驱动的计数任务，仍然具有挑战性。现有模型（如类别无关计数模型和大型视觉语言模型）在此类任务中的能力尚不明确。

Method: 提出了PairTally基准数据集，包含681张高分辨率图像，每张图像包含两个目标类别，要求模型根据形状、大小、颜色或语义的细微差异进行区分和计数。数据集包含类别间和类别内设置。对多种最先进模型（包括基于范例的方法、语言提示模型和大型VLM）进行了基准测试。

Result: 尽管最近取得了进展，但现有模型在可靠地计数用户意图的目标方面仍然存在困难，特别是在细粒度和视觉模糊的情况下。

Conclusion: PairTally为细粒度视觉计数系统的诊断和改进提供了新基础。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [106] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，能将大型多模态教师模型（如LLaVa）的区域级语义高效迁移到轻量级视觉目标检测器（如YOLO），通过对象级对齐，在少样本检测任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 旨在克服传统方法侧重于密集或全局对齐的局限性，实现对象级别的语义高效迁移，且无需修改教师模型或在推理时提供文本输入，从而使轻量级视觉检测器能利用大型多模态模型的知识，并适用于实际部署。

Method: 引入MOCHA（Multi-modal Objects-aware Cross-arcHitecture Alignment），这是一种知识蒸馏方法。它使用一个翻译模块将学生（如YOLO）的特征映射到一个联合空间，并通过双目标损失函数（强制执行局部对齐和全局关系一致性）指导学生和翻译模块的训练。该方法在对象级别操作，而不是密集或全局对齐。

Result: 在四个少样本个性化检测基准测试中，MOCHA持续优于基线方法，平均分数提高了10.1。尽管架构紧凑，其性能与更大型的多模态模型相当。

Conclusion: MOCHA能够将大型多模态模型的知识有效迁移到轻量级视觉检测器中，其紧凑的架构和与大型模型相当的性能证明了它在实际部署中的适用性。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [107] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 本研究提出YOLO-FEDER FusionNet的增强版，通过优化训练数据、特征融合策略和骨干网络设计，显著提升了在复杂视觉环境下对无人机的检测性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂视觉环境中，无人机检测因背景杂乱、目标尺度小及伪装效应而充满挑战。通用目标检测器（如YOLO）在低纹理场景表现良好，但在目标与背景分离度低的杂乱环境中性能会下降。

Method: 本工作提出了YOLO-FEDER FusionNet的增强迭代，该框架结合了通用目标检测与伪装目标检测技术。具体改进包括：1) 利用大规模逼真合成数据辅以少量真实样本来优化训练数据组成；2) 系统评估中间多尺度FEDER特征的贡献；3) 在多种基于YOLO的骨干网络配置上全面测试检测性能。

Result: 实验结果表明，集成中间FEDER特征并结合骨干网络升级能显著提升性能。在最优化配置（YOLO-FEDER FusionNet搭载YOLOv8l骨干网络并结合DWD模块提取的FEDER特征）下，相较于初始基线，假阴性率（FNR）降低高达39.1个百分点，平均精度（mAP）在IoU阈值0.5时提升高达62.8个百分点。

Conclusion: 通过整合中间FEDER特征和升级骨干网络，YOLO-FEDER FusionNet在复杂视觉环境下的无人机检测性能得到了显著提升，有效解决了现有方法的局限性。

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [108] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一个开源多模态LVM，通过数据、训练和MoE架构创新，在2B/8B参数规模下，于图像和视频基准测试（尤其复杂推理任务）上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 旨在构建一个全面的多模态理解和推理能力的基础模型，超越现有技术（如SAIL-VL），并在广泛的图像和视频基准测试中达到最先进水平。

Method: 1. **大规模数据整理流水线**：采用评分和过滤策略，优化多模态数据的质量和分布。 2. **渐进式训练框架**：包含强大的预训练视觉编码器（SAIL-ViT）、多模态预训练，以及“思考融合”SFT-RL混合范式。 3. **架构创新**：引入高效的稀疏专家混合（MoE）设计。

Result: 1. 在2B和8B参数规模下，SAIL-VL2在多样化的图像和视频基准测试中达到最先进性能，展现从细粒度感知到复杂推理的强大能力。 2. 在106个数据集上表现有竞争力，并在MMMU和MathVista等挑战性推理基准测试中取得SOTA结果。 3. SAIL-VL2-2B在OpenCompass排行榜上，在4B参数规模以下的官方发布开源模型中排名第一。

Conclusion: SAIL-VL2通过其创新的数据、训练和架构方法，在多模态理解和推理任务上取得了行业领先的SOTA性能，并为开源多模态社区提供了一个高效且可扩展的基础模型。

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [109] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [110] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个统一的角色动画和替换框架，能将角色图像根据参考视频的动作和表情生成高保真动画，或将动画角色无缝集成到视频中，同时复制环境光照和色调。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的框架，能够将静止的角色图像根据参考视频的动作和表情进行高质量动画，并能将动画后的角色无缝地替换视频中的原有角色，同时保持环境光照和色彩的一致性，以实现高保真和可控性。

Method: 该框架基于Wan模型，采用修改后的输入范式来统一多项任务。通过空间对齐的骨架信号复制身体动作，并从源图像中提取隐式面部特征来重现表情。为增强角色替换时的环境融合，开发了一个辅助的Relighting LoRA模块，以保持角色外观一致性并应用适当的环境光照和色调。

Result: 实验结果表明，Wan-Animate在角色动画和替换任务中实现了最先进的性能，能够生成高保真、高表现力且与环境无缝融合的角色视频。

Conclusion: Wan-Animate是一个最先进的统一框架，成功解决了角色动画和替换的挑战，提供了高可控性和表现力，并实现了无缝的环境融合。该模型权重和源代码将开源。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [111] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 本文提出VSE-MOT框架，通过视觉语义增强解决低质量视频中的多目标跟踪问题，显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有多目标跟踪（MOT）算法忽视低质量视频固有的问题，导致在真实图像劣化场景下性能严重下降，因此，提升MOT算法在真实低质量视频场景中的应用是一个关键且有意义的课题。

Method: 本文提出VSE-MOT框架，灵感来源于视觉-语言模型。具体而言，设计了一个三分支架构，利用视觉-语言模型提取全局视觉语义信息并与查询向量融合。随后，引入多目标跟踪适配器（MOT-Adapter）来适配视觉语义信息，并引入视觉语义融合模块（VSFM）来提高特征融合的效率。

Result: 通过大量实验验证，所提方法在真实低质量视频场景中的跟踪性能指标优于现有方法约8%到20%，同时在常规场景下也保持了鲁棒性能。

Conclusion: VSE-MOT框架有效解决了低质量视频中的多目标跟踪挑战，通过视觉语义增强显著提升了性能，并在不同场景下展现出优越性和鲁棒性。

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [112] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 研究表明，思维型大语言模型在作为评判者时，其准确性、效率和鲁棒性均显著优于非思维型模型，即使对小型非思维模型进行增强也无法弥补差距。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）被广泛用作基准测试和奖励建模中的自动评判者，确保其可靠性、效率和鲁棒性变得至关重要。

Method: 本研究使用小尺寸的开源Qwen 3模型（0.6B, 1.7B, 4B），系统比较了“思维型”和“非思维型”LLM在“LLM即评判者”范式下的表现。评估指标包括RewardBench任务上的准确性和计算效率（FLOPs）。同时，探索了针对非思维模型的增强策略，如上下文学习、规则指导、基于参考的评估和N-best聚合。此外，还进行了偏见和鲁棒性分析，并扩展到多语言环境。

Result: 结果显示，尽管有增强，非思维模型普遍不如思维型模型。思维型模型在准确性上高出约10个百分点，而额外开销很小（低于2倍），相比之下，增强策略（如少样本学习）增益有限但成本更高（>8倍）。思维型模型在多种偏见条件下（位置、从众、身份、多样性、随机偏见）表现出显著更高的一致性（平均高6%）。实验还证实显式推理的益处在多语言环境中同样存在。

Conclusion: 总体而言，研究结果提供了系统性证据，表明显式推理（思维）在“LLM即评判者”范式中具有明显优势，这不仅体现在准确性和效率上，也体现在鲁棒性方面。

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [113] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 研究发现，大语言模型（LLMs）的“评估意识”（即在评估和部署环境中行为不同的能力）随模型规模的增大而可预测地增强，呈现出清晰的幂律缩放关系。


<details>
  <summary>Details</summary>
Motivation: LLMs的“评估意识”行为（能够在测试中隐藏危险能力）对AI安全评估构成威胁。现有研究仅在一个70B模型中证实了这种现象，但其在不同模型规模下的缩放关系尚不清楚。

Method: 本文选取了来自四个家族、规模从0.27B到70B参数的15个模型，通过对转向向量激活（steering vector activations）进行线性探测（linear probing），研究了它们的评估意识。

Result: 研究结果揭示了一个清晰的幂律缩放：LLMs的评估意识随模型规模的增大而可预测地增强。

Conclusion: 这一缩放定律使我们能够预测未来更大模型中的欺骗行为，并为AI安全评估设计规模感知的策略提供了指导。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [114] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: 本文提出FRIT，一种可扩展的无监督对齐方法，通过系统地干预Chain-of-thought推理步骤并利用偏好优化，训练大型语言模型产生更具因果一致性和可信赖性的推理。


<details>
  <summary>Details</summary>
Motivation: Chain-of-thought (CoT) 推理虽能提升LLM在复杂任务上的表现，但其推理步骤常与最终答案缺乏因果关联，导致输出不可靠。现有方法多侧重衡量忠实性，而非系统性地提升。

Method: 引入忠实推理干预训练 (FRIT) 方法。该方法通过干预模型生成的CoT中的单个推理步骤，系统地创建合成的“忠实/不忠实”训练数据对。然后，利用直接偏好优化 (DPO) 训练模型偏好因果一致的推理路径。

Result: 在Qwen3-8B和Mistral-7B-v0.1模型以及事实和符号推理任务上进行评估，FRIT使Mistral在GSM8K任务上的忠实推理提高了3.4个百分点，同时准确率提升了7.6个百分点。

Conclusion: FRIT提供了首个可扩展、无需监督的方法，用于训练语言模型生成更可靠和可解释的推理，有效弥合了推理性能与可信赖性之间的关键鸿沟。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [115] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 本立场文件主张AI安全应采纳反脆弱视角，使系统处理罕见和OOD事件的能力随时间增强，以超越静态测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法（如静态基准测试）未能适应环境演变，导致模型出现不适应性（如奖励作弊、过度优化）。为了实现开放式ML系统的长期可靠性，特别是在面对稀有或分布外事件时，需要一种能持续适应和改进的策略。

Method: 论文首先识别了静态测试的关键局限性（包括场景多样性、奖励作弊和过度对齐）。然后，探索了反脆弱解决方案在管理罕见事件方面的潜力。核心方法是倡导对AI安全的测量、基准测试和长期持续改进方法进行根本性重新校准，并提供伦理和实践指南，以促进反脆弱AI安全社区的建设。

Result: 通过提出反脆弱的AI安全视角，论文旨在补充现有鲁棒性方法，并为实现长期、持续改进的AI安全提供了理论框架和实践方向。其结果是呼吁和倡导一种全新的社区共识和方法论转型。

Conclusion: AI安全必须从根本上转向反脆弱方法，使系统能够随着时间推移增强应对不确定性（特别是罕见和OOD事件）的能力。这需要重新校准现有的衡量、基准和持续改进方法，并构建一个支持这种范式转变的AI安全社区。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [116] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 通过世界模型生成虚拟环境，并利用IMAC（想象自动课程）方法自动设计训练课程，即使世界模型数据有限，也能培养出泛化能力强的鲁棒代理。


<details>
  <summary>Details</summary>
Motivation: 现有具身代理训练方法需要大量数据或精确仿真，但这些条件在现实世界中往往不具备。世界模型作为替代方案，能利用离线数据生成多样化仿真环境。本文旨在利用世界模型训练能泛化至新任务的鲁棒代理，并解决如何确保代理在有用数据上训练的挑战。

Method: 提出了一种新方法IMAC (Imagined Autocurricula)，它利用无监督环境设计（UED）在生成的世界中引入自动课程，从而引导代理在有用的生成数据上进行训练。

Result: 在具有挑战性的程序生成环境中，即使世界模型仅从较窄的数据集学习，且代理仅在世界模型生成的想象环境中训练，也能在未见环境中展现出强大的迁移性能。

Conclusion: 这项工作证明了利用世界模型训练通用代理的潜力，并为未来利用更大规模的基础世界模型铺平了道路。

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [117] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 本文提出动作链（CoA）框架，通过将高级规划与低级控制统一在一个VLA模型中，解决通用智能体动作空间选择的挑战。CoA将抽象动作视为推理步骤，使智能体学习到更鲁棒和可泛化的策略，并在Minecraft任务中达到新的SOTA，同时发布OpenHA基准。


<details>
  <summary>Details</summary>
Motivation: 开发端到端可训练的通用智能体时，动作空间的选择是关键但未解决的挑战。现有研究表明，没有单一动作空间是普遍最优的，有效抽象高度依赖任务，这给构建通用智能体带来了困境。

Method: 首先，对Minecraft中VLA或分层智能体的抽象动作空间进行大规模系统比较。其次，提出“动作链”（Chain of Action, CoA）框架，该框架将高级规划和低级控制统一在一个单一的VLA模型中。CoA将抽象动作视为类似“思维链”的中间推理步骤，指导最终可执行动作的生成。在此基础上，训练了一个All-in-One智能体，它在多种动作空间上使用了CoA范式。

Result: 比较分析表明，没有单一动作空间是普遍最优的，最有效的抽象高度依赖任务。使用CoA范式训练的All-in-One智能体学习到了更鲁棒和可泛化的策略，并在整体任务成功率上超越了强大的专业化基线，实现了新的SOTA。此外，发布了OpenHA基准套件以促进可复现研究。

Conclusion: 动作链（CoA）框架通过将高级规划与低级控制统一在一个VLA模型中，有效解决了通用智能体动作空间选择的困境，通过将抽象动作作为推理步骤，显著提高了智能体的鲁棒性和泛化能力，并达到了SOTA性能。所发布的OpenHA基准将有助于未来的研究。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [118] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: 本文提出PDDL-Instruct指令微调框架，通过逻辑思维链推理增强大型语言模型（LLMs）的符号规划能力，使其在规划准确率上最高达到94%，相比基线模型有66%的绝对提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种任务中表现出色，但在结构化符号规划方面能力有限，尤其是在需要像规划领域定义语言（PDDL）这类形式化表示的领域。

Method: 提出了一个新颖的PDDL-Instruct指令微调框架，旨在通过逻辑思维链推理增强LLMs的符号规划能力。该方法侧重于通过显式逻辑推理步骤，教会模型严格推理动作适用性、状态转换和规划有效性。通过设计指导模型进行精确逻辑推理的指令提示，使LLMs能够通过结构化反思自我纠正规划过程。框架通过将规划过程分解为关于前置条件满足、效果应用和不变性保持的显式推理链，系统地构建验证技能。

Result: 在多个规划领域的实验结果表明，基于思维链推理的指令微调模型在规划方面表现显著更优，在标准基准测试中规划准确率高达94%，比基线模型有66%的绝对提升。

Conclusion: 这项工作弥合了LLMs通用推理能力与自动化规划所需逻辑精度之间的差距，为开发更好的AI规划系统提供了一个有前景的方向。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [119] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 本文提出Agentic UAVs框架，利用LLM驱动的推理与工具调用，克服现有UAVs自主性局限，实现更高水平的上下文感知、自主决策和系统集成，并在模拟搜救中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前UAVs自主性普遍停留在SAE Level 2-3，依赖规则和窄AI，缺乏动态不确定任务中的适应性、情境感知推理、自主决策和生态系统集成，尤其未能利用带工具调用的LLM代理进行实时知识访问。

Method: 引入Agentic UAVs框架，一个包含感知、推理、行动、集成、学习的五层架构，通过LLM驱动的推理、数据库查询和第三方系统交互增强UAVs。构建了基于ROS2和Gazebo的原型，结合YOLOv11目标检测、GPT-4推理和本地Gemma-3部署。

Result: 在模拟搜救场景中，Agentic UAVs实现了更高的检测置信度（0.79 vs 0.72）、更高的人员检测率（91% vs 75%），并显著提高了行动建议能力（92% vs 4.5%）。

Conclusion: 研究结果证实，适度的计算开销即可使UAVs获得质变级的新自主性和生态系统集成能力。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [120] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 本文提出“语义融合”方案，通过并行的模糊成员特征通道增强Transformer语言模型，编码词元级语义。它在保持模型简洁和低开销的同时，提高了困惑度，实现了可控的极性和标点生成，并提供了可解释的条件生成路径。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer语言模型在捕获细粒度词元级语义和实现用户可控生成方面存在局限性，需要一种轻量级且可解释的方法来增强其语义理解能力并提升生成的可控性。

Method: 该方法引入“语义融合”机制，为Transformer语言模型增加一个并行的模糊成员特征通道。每个词元通过可微分成员函数被表示为包含词性、浅层角色、边界标志、情感极性等可解释特征的向量。这些词元向量组成句子级语义矩阵，通过门控适配器融入语言模型。训练结合标准下一词元预测、辅助损失（从隐藏状态重建语义特征）以及轻量级均匀器（正则化形容词类别分布）。

Result: 在一个合成的双子句语料库（包含分布外形容词控制）上，语义融合显著改善了困惑度，实现了对文本极性和标点的精确、用户可控生成。该方法仅增加少量开销，保持了模型简洁性，与绑定输入-输出嵌入完全兼容，并为条件自然语言生成提供了一条可解释的路径。

Conclusion: 语义融合是一种高效、轻量且可解释的Transformer语言模型增强方案，它通过融入丰富的词元级语义，显著提升了模型的生成质量和用户可控性，而无需牺牲模型简洁性或引入高额计算开销。

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [121] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [122] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: 本文提出了$Agent^2$，一个由LLM驱动的“智能体生成智能体”框架，能实现全自动强化学习智能体设计，通过自然语言和环境代码自主生成高性能RL解决方案，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习智能体开发需要大量专业知识、耗时且失败率高，可及性有限。

Method: $Agent^2$采用双智能体架构：生成器智能体（AI设计者）分析任务并生成可执行的强化学习智能体，目标智能体是被自动生成的RL智能体。框架将RL开发分解为MDP建模和算法优化两个阶段，基于模型上下文协议，实现跨环境和算法的标准化智能体创建，并整合自适应训练管理和智能反馈分析，以实现持续改进。核心驱动技术是LLM。

Result: 在MuJoCo、MetaDrive、MPE和SMAC等多个基准测试中，$Agent^2$始终优于手动设计的解决方案，性能提升高达55%，并取得了显著的平均增益。

Conclusion: 该工作实现了RL智能体设计的真正端到端、闭环自动化，开创了智能智能体设计和优化其他智能体的新范式，是自动化AI系统的一个根本性突破。

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [123] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 本文对16个最先进的视觉-语言模型（VLM）在6个多模态数据集上进行了全面的不确定性量化基准测试，发现大型模型的不确定性量化能力更优，且数学和推理任务中的不确定性表现普遍较差。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLM）在复杂视觉理解任务中取得了显著进展，且性能基准测试加深了对其能力的理解，但其关键的不确定性量化维度尚未得到充分关注。

Method: 本研究进行了一项全面的不确定性基准测试，评估了16个最先进的视觉-语言模型（包括开源和闭源），横跨6个多模态数据集，并使用了3种不同的评分函数。

Result: 研究发现，大型模型始终表现出更好的不确定性量化能力，即“知道得越多，也越清楚自己不知道什么”。更确信的模型能达到更高的准确性。与其它领域相比，数学和推理任务在所有模型中都引发了较差的不确定性性能。

Conclusion: 这项工作为多模态系统中的可靠不确定性评估奠定了基础。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [124] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 本文提出使用Transformer模型和梯度下降，仅从动作序列中学习命题STRIPS世界模型，并证明该架构能忠实地表示并从正负样本序列中学习这些模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是仅从动作轨迹中学习命命题STRIPS世界模型。

Method: 使用深度学习架构（Transformer）和梯度下降。将任务转化为监督式“下一个token预测”问题，其中token为动作。判断动作是否可跟随的逻辑是基于先前动作的隐藏效果不能使当前动作的前置条件变为假。

Result: 实验结果表明，合适的Transformer架构能够忠实地表示命题STRIPS世界模型。此外，这些模型可以仅从随机的有效（正例）和无效（反例）动作序列集中学习。

Conclusion: Transformer架构能够有效地从仅包含动作序列的数据中学习并表示命题STRIPS世界模型，且能够从正负样本中进行学习。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [125] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: 该研究引入了SteeringControl基准，系统评估表征引导方法在对齐目标（如偏见、有害生成、幻觉）及次级行为（如逢迎、道德）上的效果与权衡，发现引导性能和概念纠缠高度依赖于引导方法、模型和目标行为的特定组合。


<details>
  <summary>Details</summary>
Motivation: 现有对齐工作在理解表征引导的副作用时，未能系统性探索其中存在的诸多未被理解的权衡，导致对复杂行为纠缠的认知不足。

Method: 引入SteeringControl基准，构建了一个模块化引导框架。收集了一个包含安全相关初级和次级行为的数据集，用于评估引导效果和行为纠缠。在Qwen-2.5-7B和Llama-3.1-8B模型上，使用五种流行的引导方法进行了评估。

Result: 研究发现，强大的引导性能取决于引导方法、模型和目标行为的特定组合；不佳的组合会导致严重的次级行为和概念纠缠。

Conclusion: 表征引导方法的有效性及其对模型次级行为的影响是复杂的，需要综合考虑引导方法、模型架构和具体目标行为的匹配，以实现更好的对齐效果并避免意想不到的负面权衡和概念纠缠。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [126] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 为LLM代理配备类人协作工具（如社交媒体、日志）可显著提高其在困难编程问题上的表现，通过增强推理和自适应策略实现，且结构化表达而非单纯信息访问是主要改进驱动因素。


<details>
  <summary>Details</summary>
Motivation: 研究LLM代理在获得人类自然使用的协作工具和自主性后，其问题解决性能是否能得到提升。

Method: 为Claude Code代理配备基于MCP的社交媒体和日志工具，并允许它们自主使用这些工具，在34个Aider Polyglot Python编程挑战上进行评估。

Result: 在最困难的问题上，协作工具使成本降低15-40%，轮次减少12-27%，完成速度提高12-38%。在完整挑战集上效果参差不齐，表明工具在需要额外推理支撑时作用更大。不同模型（如Sonnet 3.7和Sonnet 4）无需明确指令就采取了不同的协作策略。行为分析显示代理更偏爱写作而非阅读（约2-9倍），表明结构化表达是主要的改进驱动因素。

Conclusion: AI代理在其能力边缘可以系统性地受益于人类启发式的协作工具，自适应的协作界面是推理增强器，而非通用的效率提升器。

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [127] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 本研究通过问卷和访谈，分析了在允许使用生成式AI的证明类数学课程中，学生对AI的使用情况、感知及其对教学的启示。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式AI在高等教育中的迅速发展及现有AI检测工具的不可靠性，制定促进学生学习和批判性思维的政策变得尤为重要。

Method: 在三门允许部分使用生成式AI的证明类本科数学课程（抽象代数、拓扑学）中，通过问卷调查和学生访谈，分析学生对AI工具的使用方式和看法。

Result: 分析了学生与AI工具的互动方式、他们对生成式AI有用性与局限性的看法，以及这些看法对证明类数学教学的影响。

Conclusion: 探讨了将生成式AI融入证明类数学教学的未来考量。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [128] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: CoBRA是一个新颖的工具包，用于在基于LLM的社会模拟中系统且精确地编程代理的认知偏差，通过经典社会科学实验解决传统自然语言描述方法行为不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 传统上通过隐式自然语言描述来指定LLM代理行为的方法，无法在不同模型间产生一致的行为，也无法捕捉描述的细微差别。

Method: 本文介绍了CoBRA工具包，其通过经典社会科学实验来明确地编程代理的认知偏差。CoBRA包含两个主要组件：1) 认知偏差指数（Cognitive Bias Index），通过量化代理在经典社会科学实验中的反应来衡量其认知偏差；2) 行为调节引擎（Behavioral Regulation Engine），用于调整代理行为以展示受控的认知偏差。研究通过演示和技术基准测试评估了CoBRA作为一个HCI工具包的有效性。

Result: 研究结果表明，CoBRA能够以模型无关的方式精确地编程社交代理所展示的认知偏差。

Conclusion: CoBRA成功地提供了一种精确、可控且模型无关的方法，用于在LLM社会模拟中编程代理的认知偏差，解决了传统方法在行为一致性和细微差别捕捉上的不足。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [129] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 多模态智能体在GUI切换控制中表现不可靠，本文提出StaR训练方法，通过状态感知推理，将切换指令执行准确率提升30%以上，并增强通用任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态智能体在图形用户界面（GUI）控制中，尤其是在执行“切换”（toggle）控制指令时，存在可靠性瓶颈，特别是在当前状态与期望状态一致时表现不佳。

Method: 研究者首先构建了一个包含二元切换指令的状态控制基准。为解决智能体在切换控制上的挑战，他们提出了“状态感知推理”（State-aware Reasoning, StaR）训练方法，旨在教会智能体感知当前切换状态、分析指令中的期望状态并据此行动。

Result: 对现有智能体的评估证实了其在切换指令执行上的不可靠性。StaR方法将三种多模态智能体的切换指令执行准确率提高了30%以上，同时在三个公共基准测试中也提升了通用任务性能，并在动态环境中展现了实际应用潜力。

Conclusion: StaR训练方法通过引入状态感知推理，显著解决了多模态智能体在GUI切换控制方面的可靠性问题，并提升了其通用任务性能，为实际应用提供了有效途径。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [130] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: 本文提出了InfraMind，一个专为工业管理系统设计的LLM驱动GUI代理框架，通过解决现有自动化方法的关键挑战，显著提升了任务成功率和操作效率。


<details>
  <summary>Details</summary>
Motivation: 关键工业基础设施的管理软件日益复杂，但其操作面临系统复杂性高、多厂商集成困难和专家短缺的挑战。现有RPA和通用LLM-GUI代理自动化存在灵活性差、维护成本高以及在工业管理中面临元素理解、精度效率、状态定位、部署限制和安全等核心问题。

Method: 本文提出了InfraMind，一个基于探索的GUI代理框架，专为工业管理系统设计。它集成了五个创新模块：1) 基于系统搜索的探索与虚拟机快照，用于自主理解复杂GUI；2) 记忆驱动的规划，确保高精度和高效任务执行；3) 高级状态识别，实现分层界面中的稳健定位；4) 结构化知识蒸馏，实现轻量化高效部署；5) 全面多层安全机制，保障敏感操作。

Result: 在开源和商业DCIM平台上进行的广泛实验表明，InfraMind在任务成功率和操作效率方面持续优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了一个严谨且可扩展的解决方案，有效解决了该领域面临的关键挑战。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [131] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在数学高精度任务中仍有不足。THOR提出通过多智能体数据生成、分层RL优化和自校正机制，显著提升LLMs集成工具的性能，并在数学和代码基准上实现SOTA。


<details>
  <summary>Details</summary>
Motivation: LLMs在数学推理方面取得显著进展，但在数值计算和形式符号操作等高精度任务上仍存在困难。尽管集成外部工具是一种有前景的解决方案，但现有方法在构建高质量的工具集成推理数据、执行精细优化以及增强推理能力方面面临关键挑战。

Method: 本文提出THOR（Tool-Integrated Hierarchical Optimization via RL）框架以解决上述挑战：
1.  **数据构建 (TIRGen)**：引入TIRGen，一个基于多智能体actor-critic的流水线，用于构建高质量的工具集成推理路径数据集，该数据集与策略对齐并具有良好的泛化能力。
2.  **分层优化**：提出一种强化学习（RL）策略，共同优化轨迹级的问题解决和步骤级的代码生成。其核心洞察是中间工具调用的成功率是最终答案正确性的强预测因子。
3.  **推理增强 (自校正)**：整合自校正机制，利用即时工具反馈在推理过程中动态修正错误的推理路径。

Result: 1.  在不同模型上表现出强大的泛化能力，对推理和非推理模型均有效。
2.  在多个数学基准上，对于同等规模的模型，THOR取得了最先进（SOTA）的性能。
3.  在代码基准上也带来了持续的性能提升。

Conclusion: THOR通过其创新的数据生成、分层强化学习优化和自校正推理机制，成功克服了LLMs在处理高精度数学和代码任务时集成工具的现有局限性，实现了卓越的泛化能力和领先的性能。

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [132] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA是一个智能手机AI任务指令推荐框架，通过长按图片/文本提供上下文相关建议，旨在简化用户与AI服务的互动，并显著提升了指令推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术推动AI服务集成到智能手机，用户与设备的交互方式正在改变。本研究旨在简化用户对预定义AI服务的访问，实现智能手机上直观的一触式AI任务处理。

Method: 本研究引入MIRA框架，包含三大创新：1) 基于多模态大语言模型（MLLM）的推荐管道，用于提取关键实体、推断用户意图和生成精确指令；2) 模板增强推理机制，通过集成高级推理模板提高任务推断准确性；3) 基于前缀树的受限解码策略，将输出限制在预定义指令候选中，确保建议的连贯性和意图对齐。

Result: 通过对真实世界标注数据集的评估和用户研究，MIRA在指令推荐的准确性方面展现出显著提升。

Conclusion: MIRA的积极成果表明其有潜力彻底改变用户在智能手机上使用AI服务的方式，提供更无缝、高效的体验。

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [133] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 本文提出一种基于DPLL和MIP简化技术的整数线性约束模型计数（MCILC）精确方法，在随机和应用基准测试中均显著优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 整数线性约束模型计数（MCILC）是计算机科学、运筹学和优化等领域的基础且重要问题，许多实际应用都归结为该任务。

Method: 设计了一种基于穷举DPLL架构的MCILC精确方法，并通过集成混合整数规划中的多种有效简化技术来提高效率。

Result: 在随机基准测试中，所提方法显著优于所有精确方法，解决了1718个实例，而最先进方法仅解决1470个。此外，该方法是唯一能够解决所有4131个应用实例的方法。

Conclusion: 所提出的MCILC精确方法在处理随机和应用基准测试方面表现出卓越的性能和鲁棒性，显著优于现有技术。

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [134] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 研究表明，人工神经网络中信息流（拓扑结构）的变化能导致认知性能的质的飞跃，支持认知进化中的“重大转变”假说。


<details>
  <summary>Details</summary>
Motivation: 进化理论强调少数关键变化能塑造可演化性，对后代产生重大影响。最近有理论提出，认知能力也可能通过操纵生物神经网络结构、改变信息流的重大转变而进化。本研究旨在通过理想化模型（人工神经网络）评估网络中信息流的变化是否能引发认知性能的过渡性变化。

Method: 使用人工神经网络（ANNs）作为信息流的理想化模型。比较具有前馈、循环和分层三种不同拓扑结构的网络性能。测试网络学习不同复杂程度人工语法的能力，并控制网络大小和资源。

Result: 相比前馈网络，循环网络在可处理的输入类型上实现了质的扩展，并且在学习最复杂语法时性能有质的提升。训练循环网络的难度也体现了类似进化过渡中的“过渡障碍”和“偶然不可逆性”。然而，并非所有拓扑变化都带来优势，分层网络在语法学习中并未超越非分层网络。

Conclusion: 研究结果表明，信息流中的某些变化（体现在网络拓扑结构上）确实可以导致认知性能发生过渡性转变。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [135] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: 引入CrowdAgent，一个多智能体系统，通过合理分配任务和管理质量-成本权衡，实现对LLMs、SLMs和人类专家等多种标注来源的端到端协作标注流程控制。


<details>
  <summary>Details</summary>
Motivation: 当前方法在利用LLMs、SLMs和人类专家等多种标注来源时，缺乏对这些来源进行动态管理、任务调度和质量-成本权衡的整体流程控制。

Method: 提出CrowdAgent，一个受众包公司启发的、整合任务分配、数据标注和质量/成本管理的多智能体系统。它采用新颖的任务理性分配方法，促进LLMs、SLMs和人类专家在协作标注工作流中协同工作，实现端到端流程控制。

Result: 通过在六个不同的多模态分类任务上进行大量实验，证明了CrowdAgent的有效性。

Conclusion: CrowdAgent系统通过协同利用多种标注来源，为协作标注提供了有效的端到端流程控制。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [136] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文通过一个分层GCN-MLP架构，实证验证了二阶学习能促进与环境同构的心理表征的出现，并在新颖迷宫任务中展示了显著的性能提升和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 心理表征对高级认知至关重要但难以实证研究。现有理论假设二阶学习能促进这种环境-认知同构的心理表征的形成。本文旨在实证验证这一假设。

Method: 提出了一个分层架构，其中包含作为一阶学习器的图卷积网络（GCN）和作为二阶学习器的多层感知机（MLP）控制器。GCN直接将节点特征映射到最优导航路径预测，MLP则在面对结构新颖的迷宫环境时动态调整GCN的参数。

Result: 当认知系统发展出与环境结构同构的内部心理地图时，二阶学习表现出尤其高的效率。该方法在未见过的迷宫任务中实现了显著的性能提升和强大的泛化能力。

Conclusion: 研究结果为结构化心理表征在最大化二阶学习有效性中的关键作用提供了实证支持，从而验证了二阶学习促进环境-认知同构的假设。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [137] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: USPIL是一个统一的时空物理信息深度学习框架，整合PINN和守恒定律，能高效且准确地建模跨维度生态系统动力学（ODE/PDE），提供机制性理解，并大幅提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以捕捉生态系统复杂的跨尺度动力学，包括时间振荡和涌现的时空模式，同时难以遵守物理守恒定律。

Method: 提出了统一时空物理信息学习（USPIL）框架，该深度学习架构结合了物理信息神经网络（PINNs）和守恒定律，通过自动微分强制物理约束，并利用自适应损失权重平衡数据保真度与物理一致性，能统一建模常微分方程（ODE）和偏微分方程（PDE）系统。

Result: 在Lotka-Volterra系统上，USPIL在1D时间动力学中达到98.9%的相关性（MAE: 0.0184），在2D系统中成功捕捉复杂螺旋波（模式相关性: 0.94）。验证表明守恒定律遵守度在0.5%以内，推理计算速度比传统数值求解器快10-50倍。此外，USPIL还能通过可解释的物理约束实现参数发现和敏感性分析，提供机制性理解。

Conclusion: USPIL作为一种变革性工具，能够应用于生态预测、保护规划和理解生态系统韧性，并开辟了多尺度生态建模的新途径，确立了物理信息深度学习作为强大且科学严谨的范式。

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [138] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 该研究实证分析了神经网络训练中优化器选择对能耗和碳排放的影响，旨在促进可持续AI。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型日益复杂且计算密集，理解训练决策对环境的影响对于可持续AI发展至关重要。

Method: 通过360次受控实验，在MNIST、CIFAR-10、CIFAR-100三个基准数据集上，使用八种流行优化器（如SGD, Adam, AdamW），每个优化器15个随机种子。使用CodeCarbon在Apple M1 Pro硬件上精确测量训练时长、峰值内存、碳排放和模型性能。

Result: 研究发现训练速度、准确性和环境影响之间存在显著权衡，且这些权衡因数据集和模型复杂性而异。AdamW和NAdam被确定为持续高效的选择，而SGD在复杂数据集上表现优异但排放较高。

Conclusion: 这些结果为实践者在平衡机器学习工作流的性能和可持续性方面提供了可操作的见解。

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [139] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 本文提出了一种混合DeepONet-Transolver框架，用于PET瓶屈曲分析，能在不同几何形状上泛化预测节点位移场和反作用力时间演变，替代计算昂贵的有限元分析。


<details>
  <summary>Details</summary>
Motivation: 现有神经代理和算子网络在解决偏微分方程问题时，难以泛化到非参数几何域。传统的PET瓶屈曲分析（包装设计问题）依赖计算昂贵的有限元分析（FEA）。

Method: 引入了混合DeepONet-Transolver框架，同时预测顶载压缩下的节点位移场和反作用力的时间演变。该方法在两类瓶几何形状（分别由两个和四个设计变量参数化）上进行评估，训练数据通过Abaqus中的非线性FEA模拟生成，每类包含254个独特设计。

Result: 对于四参数瓶家族，框架在位移场上的平均相对$L^2$误差为2.5-13%，时间相关反作用力误差约为2.4%。逐点误差分析显示绝对位移误差在$10^{-4}$-$10^{-3}$量级，最大差异局限于局部几何区域。模型准确捕捉了不同瓶几何形状的关键物理现象，例如屈曲行为。

Conclusion: 该框架具有作为可扩展且计算高效代理的潜力，特别适用于计算力学中的多任务预测和需要快速设计评估的应用。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [140] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: 本文提出了AERIS，一个1.3B-80B参数的Swin扩散transformer，并结合SWiPe并行技术，在Aurora超算上实现了ExaFLOPS级性能和高效扩展。AERIS超越现有模型并能稳定预测90天，展示了大型扩散模型在天气和气候预测中的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 生成式机器学习为理解地球系统动力学提供了新机会，扩散模型在天气预报中能改善偏差和校准。然而，现有扩散模型在高分辨率下难以稳定扩展。

Method: 引入AERIS，一个1.3B至80B参数的像素级Swin扩散transformer来解决扩展性问题。同时，提出SWiPe，一种通用技术，通过结合窗口并行、序列并行和流水线并行，实现基于窗口的transformer分片，且不增加通信开销或全局批次大小。

Result: 在Aurora超算（10,080节点）上，AERIS实现了10.21 ExaFLOPS的持续性能（混合精度），峰值达11.21 ExaFLOPS，弱扩展效率95.5%，强扩展效率81.6%。AERIS性能优于IFS ENS，并在季节尺度（90天）上保持稳定。

Conclusion: 十亿参数级扩散模型在天气和气候预测方面具有巨大潜力。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [141] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: 本文介绍了一种名为LAMeL的线性元学习算法，它通过识别相关任务间的共享参数，在提高化学性质预测准确性的同时保持模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 化学家在寻找结构-性质关系时面临高质量数据集有限的挑战，机器学习虽提升了预测能力，但也增加了数据需求。为满足对可解释AI (XAI)的需求，并弥合预测准确性和人类可理解性之间的差距，且鉴于大多数方法孤立地处理每个化学预测任务，作者开发了LAMeL。

Method: 引入了LAMeL（Linear Algorithm for Meta-Learning），该算法采用元学习框架，通过识别相关任务（即使不共享数据）之间的共享模型参数，学习一个共同的功能流形，作为新任务更明智的起始点，从而在提高预测精度的同时保持模型的可解释性。

Result: LAMeL相较于标准岭回归，实现了1.1倍至25倍的性能提升（具体取决于数据集领域）。尽管性能提升程度因任务而异，但LAMeL始终优于或与传统线性方法持平。

Conclusion: LAMeL是一种可靠的化学性质预测工具，特别适用于对准确性和可解释性都有严格要求的场景。

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [142] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: 研究发现OpenAI的GPT-4o mini在多模态仇恨言论检测中存在“单模态瓶颈”，其安全系统过度依赖上下文无关的单模态过滤，导致多模态推理受阻并产生误报。


<details>
  <summary>Details</summary>
Motivation: 随着大规模多模态模型（LMMs）日益融入日常生活，理解其安全架构对于AI对齐是一个关键问题。

Method: 对OpenAI的GPT-4o mini在多模态仇恨言论检测任务上进行了系统分析。使用Hateful Memes Challenge数据集的500个样本进行多阶段调查，并对144个内容政策拒绝进行了定量验证。

Result: 实验性地识别出“单模态瓶颈”，即模型的先进多模态推理被上下文无关的安全过滤器系统性地抢占。144个拒绝中，单模态视觉和文本内容各触发了50%。该安全系统脆弱，不仅阻止高风险图像，还阻止无害的常见表情包格式，导致可预测的误报。

Conclusion: 这些发现揭示了最先进LMMs在能力和安全之间的根本张力，强调需要更集成、更具上下文意识的对齐策略，以确保AI系统能够安全有效地部署。

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [143] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 为ALS（先进光源）开发了一套自动化故障分析框架，通过实时处理EPICS事件日志，利用语义嵌入和序列感知神经网络来检测异常并快速识别复杂系统故障前的关键事件。


<details>
  <summary>Details</summary>
Motivation: 旨在解决先进光源（ALS）复杂系统故障前关键事件序列的快速识别问题，帮助操作员及时发现系统异常。

Method: 将EPICS控制系统的实时日志条目视为自然语言，利用语义嵌入技术将其转换为上下文向量表示；然后，使用一个在正常运行数据上训练的序列感知神经网络，为每个事件分配实时异常分数。

Result: 该方法能够标记偏离基线行为的事件，并使操作员能够快速识别导致复杂系统故障的关键事件序列。

Conclusion: 该框架通过对实时日志的自动化分析，利用机器学习方法有效提高了ALS系统故障的预警和诊断能力。

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [144] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: 本文提出一种基于差分隐私（DP）的私有预测框架，无需微调即可生成具有隐私保证的高质量合成文本。通过聚合token分布并结合私有/公共推理，该方法在保持高实用性的同时，在ICL任务上超越了现有SOTA。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言理解和生成方面表现出色，但存在隐私泄露风险，即对抗方可能从提示中提取敏感信息。

Method: 引入一种新颖的私有预测框架，利用差分隐私（DP）确保信息泄露的理论最坏情况边界，且无需对底层模型进行微调。该方法在私有记录上执行推理，并聚合由此产生的每token输出分布，以生成更长、更连贯的合成文本。此外，提出一种简单的混合操作，结合私有和公共推理以进一步提高实用性。

Result: 经验评估表明，该方法在上下文学习（ICL）任务上优于以前的最先进方法。

Conclusion: 该方法为隐私保护文本生成提供了一个有前景的方向，同时保持了高实用性。

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [145] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 本文提出DeepLogit模型，采用序贯约束方法，在提高深度学习模型预测准确性的同时，保持其在交通政策分析中的可解释性，弥补了传统深度学习模型黑箱性质的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习模型进步显著，但其“黑箱”性质使其在规划和政策相关领域（如交通政策分析）的应用面临挑战，难以提供可解释性。

Method: 开发了一套DeepLogit模型，采用新颖的序贯约束方法：首先，估计一个仅含线性项的CNN模型（等同于线性参数多项Logit模型）以获取可解释参数；然后，在此基础上约束这些可解释参数，并引入高阶项或Transformer等高级深度学习架构来估计其他深度学习模型。

Result: 该方法在保持选定参数可解释性的同时，显著提高了模型准确性，优于传统的离散选择模型。该方法已在新加坡真实公交智能卡数据的公交路线选择案例中得到验证。

Conclusion: 本研究展示了一种统一方法的潜力，能够结合理论驱动的离散选择模型（DCM）和数据驱动的AI模型的优势，在保持可解释性的前提下提升预测能力，为规划和政策领域提供更准确且适用的模型。

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [146] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 本文提出一个结合数字孪生（DT）和零知识联邦学习（zkFed）的创新框架，用于解决无人机辅助联邦学习系统中的能耗、通信效率和安全挑战。


<details>
  <summary>Details</summary>
Motivation: 现有无人机辅助联邦学习（FL）系统面临能耗过高、通信效率低下和安全漏洞等问题，影响其可靠运行。

Method: 提出一个整合数字孪生（DT）技术（用于实时监控和预测性维护）和零知识联邦学习（zkFed）的框架（利用零知识证明增强安全性）。此外，引入动态分配策略，通过块坐标下降和凸优化技术优化无人机飞行路径、传输功率和处理速率，以提高能源效率和资源管理。

Result: 相比传统FL方法，系统能耗显著降低高达29.6%。仿真结果表明，学习性能、安全性和可扩展性均得到改善。

Conclusion: 该框架为下一代基于无人机的智能网络提供了一个有前景的解决方案。

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [147] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 一种将PPG、GSR和ACC等多模态生理信号转换为2D图像矩阵的新方法，结合CNNs显著提升压力检测性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效捕捉多模态生理信号（如PPG、GSR、ACC）的时序和跨信号依赖，限制了压力检测的准确性。

Method: 将多模态生理信号转化为结构化的2D图像矩阵，使CNNs能更有效地捕捉时序和跨信号依赖。通过系统重组融合信号并采用多阶段训练流程，进一步增强模型的泛化性和鲁棒性。

Result: 该方法显著提升了分类性能。图像转换不仅提高了可解释性，还作为一种鲁棒的数据增强形式。

Conclusion: 该方法在压力检测中表现出色，并广泛适用于涉及多模态生理信号的领域，有望促进更准确、个性化、实时的可穿戴健康监测。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [148] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved (LLM-I) 框架将图文交错生成重构为工具使用问题，通过LLM/MLLM智能编排多样化视觉工具，显著超越现有模型，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型存在“单一工具”瓶颈，仅限于合成图像，难以处理需要事实依据或程序精确性的任务，亟需一个更灵活的框架来解决这些局限。

Method: 提出LLM-Interleaved (LLM-I) 框架，将图文交错生成视为工具使用问题。该框架赋能一个中央LLM或MLLM代理智能编排多样化的专业视觉工具（包括在线图像搜索、扩散生成、代码执行和图像编辑）。代理通过强化学习（RL）框架进行训练，该框架采用结合规则逻辑与LLM和MLLM评估器判断的混合奖励系统，以熟练选择和应用工具。模型在多样化的新数据集上使用四种不同的模型主干进行训练。

Result: LLM-I在四个基准测试中展示了最先进的性能，大幅超越现有方法。此外，引入了一种新颖的测试时缩放策略，进一步提升了性能。

Conclusion: LLM-I通过将图文交错生成重构为工具使用问题，并利用LLM/MLLM对多样化视觉工具的智能编排，成功克服了现有模型的“单一工具”瓶颈和局限性，在多项任务上实现了卓越的性能表现。

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [149] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 生成式推荐中数据增强的重要性被低估且缺乏系统理解。本文提出GenPAS框架，将数据增强建模为三步随机采样过程，实现对训练分布的灵活控制，并在实验中展现出优越的准确性、数据效率和参数效率。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型中数据增强对泛化能力和性能影响显著，但现有方法缺乏系统性、原则性的理解。经验发现不同增强策略会导致巨大性能差异，促使作者深入分析其对训练分布、未来目标对齐及泛化能力的影响，并系统化其设计空间。

Method: 提出GenPAS框架，将数据增强建模为输入-目标对上的随机采样过程。该框架包含序列采样、目标采样和输入采样三个偏置控制步骤，旨在系统化设计空间、统一现有策略并灵活控制训练分布。

Result: 在基准和工业数据集上的大量实验表明，GenPAS相较于现有策略，在准确性、数据效率和参数效率方面均表现出卓越性能。

Conclusion: GenPAS为生成式推荐中的训练数据构建提供了实用的、原则性的指导。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [150] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 本文提出CPT方法，通过稳定梯度更新和修剪梯度，实现了NLP任务中公平性-准确性之间可控且精确的用户偏好权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法专注于寻找单一“最优”解决方案，但无法满足用户多样化的公平性-准确性权衡需求。尽管多目标优化能探索帕累托前沿，但训练过程的随机性和高维梯度向量使其难以精确控制权衡。

Method: 提出可控帕累托权衡(CPT)方法。CPT通过1) 使用随机梯度的移动平均来稳定公平性更新方向，2) 仅保留关键参数的梯度来修剪梯度，从而有效训练模型以实现用户偏好。

Result: 在仇恨言论检测和职业分类任务上，CPT比基线方法获得了更高质量的帕累托前沿解集，并展现出更好的可控性，能精确遵循人工定义的参考向量。

Conclusion: CPT方法通过提供高质量、可控且能精确响应用户偏好的帕累托前沿解，有效解决了NLP任务中公平性-准确性权衡的挑战。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [151] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: 本文提出RF-LSCM框架，利用辐射场联合建模大规模信号衰减和多径分量，通过多域公式、频率相关衰减模型和点云辅助方法，克服了传统LSCM在多小区、多网格和多频率分析中的局限性，并采用低秩张量表示和HiTAM算法提高效率，在真实数据集上显著提高了覆盖预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统局部统计信道建模（LSCM）方法受限于单小区、单网格和单载波频率分析，无法捕获复杂的跨域交互，导致蜂窝网络优化中的性能预测不准确。

Method: RF-LSCM框架通过辐射场联合建模信号衰减和多径分量来表示信道APS。它引入了：1) 物理信息频率相关衰减模型（FDAM）以实现跨频率泛化；2) 点云辅助的环境增强方法以支持多小区和多网格信道建模。此外，为解决计算效率问题，RF-LSCM利用低秩张量表示和分层张量角度建模（HiTAM）算法，显著减少了GPU内存和训练时间。

Result: RF-LSCM在真实多小区数据集上显著优于现有SOTA方法，实现了：1) 覆盖预测平均绝对误差（MAE）降低高达30%；2) 通过有效融合多频率数据，MAE提升22%。

Conclusion: RF-LSCM成功克服了传统LSCM方法的局限性，提供了一种更准确、高效且能处理多域交互的无线信道建模新范式，显著提升了蜂窝网络优化中的性能预测能力。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [152] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 针对Physics-Informed Neural Networks (PINNs)中现有不确定性量化(UQ)方法缺乏严格统计保证的问题，本文引入了一个无分布共形预测(CP)框架。该框架通过构建非一致性分数和局部共形分位数估计，为PINNs提供了具有严格有限样本覆盖保证和空间自适应性的不确定性区间，并被证明优于启发式方法。


<details>
  <summary>Details</summary>
Motivation: Physics-Informed Neural Networks (PINNs)在解决偏微分方程(PDEs)方面展现出强大潜力，但其现有不确定性量化(UQ)方法普遍缺乏严格的统计保证。

Method: 引入了一种无分布共形预测(CP)框架用于PINNs的UQ。该框架通过在校准集上构建非一致性分数来校准预测区间，从而提供具有严格有限样本覆盖保证的无分布不确定性估计。为处理空间异方差性，进一步引入了局部共形分位数估计，以实现空间自适应的不确定性区间，同时保持理论保证。

Result: 通过对典型偏微分方程（如阻尼谐振子、泊松、Allen-Cahn和Helmholtz方程）的系统评估和多项不确定性指标的全面测试，结果表明所提出的框架实现了可靠的校准和局部自适应的不确定性区间，并且持续优于启发式UQ方法。

Conclusion: 本工作通过将PINNs与无分布UQ相结合，引入了一个通用框架，该框架不仅增强了校准和可靠性，还为复杂偏微分方程系统的不确定性感知建模开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [153] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 该研究开发了一种基于智能手表和机器学习的方法，用于实时预测社交焦虑症患者的瞬时（状态）焦虑，旨在支持实时自适应干预。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑导致学业、社交和职业功能障碍，但现有研究很少测量或预测其在一天内的波动。捕获这些日内动态对于设计实时、个性化干预措施（如JITAIs）至关重要。

Method: 研究招募了72名社交焦虑症大学生，使用定制的智能手表系统平均监测9.03天，每天进行7次生态瞬时评估（EMAs）报告状态焦虑。开发了一个基于超过10,000天外部心率数据的基础模型，通过迁移学习和微调生成概率预测，并将其与特质水平测量结合在元学习器中。

Result: 该方法在其数据集中实现了60.4%的平衡准确率来检测状态焦虑。为评估泛化能力，将训练方法应用于TILES-18数据集的独立保留集，在10,095次每日EMAs上实现了59.1%的平衡准确率，比现有工作高出至少7%。

Conclusion: 研究成功开发了一种有效且可泛化的方法，能够实时检测社交焦虑症患者的瞬时焦虑，为未来基于JITAIs的个性化干预奠定基础。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [154] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 本文提出DirGraphSSM，首次将状态空间模型（SSMs）扩展到有向图学习领域，通过DirEgo2Token方法将有向图序列化，实现了在有向图任务上最先进的性能，并显著提升了训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有针对有向图的GNN和图Transformer难以有效捕捉长程因果依赖，且在大规模数据集上难以平衡准确性和训练效率。此外，尽管SSMs在因果序列任务上表现出色且图SSMs效率高，但它们仅限于无向图，限制了其在有向图学习中的应用。

Method: 1. 提出DirEgo2Token方法，通过k跳ego图将有向图序列化。2. 基于此，开发了DirGraphSSM，这是一种新颖的有向图神经网络架构，通过消息传递机制在有向图上实现状态空间模型。

Result: DirGraphSSM在三个代表性的有向图学习任务上取得了最先进（state-of-the-art）的性能。在另外两个任务上也达到了有竞争力的性能，同时与现有最先进模型相比，训练速度提升了1.5倍至2倍。

Conclusion: DirGraphSSM成功地将状态空间模型扩展到有向图领域，有效解决了长程因果依赖捕捉、准确性与训练效率平衡的挑战，为有向图学习提供了高效且高性能的解决方案。

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [155] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: 本文提出ParaAegis，一个并行的联邦学习保护框架，通过模型分区（低范数部分用DP，其余用HE）实现隐私-效用-效率的灵活平衡。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习保护机制（如DP和HE）在模型效用和计算效率之间存在僵硬的权衡，缺乏灵活性，阻碍了实际应用。

Method: 引入ParaAegis框架，核心方法是战略性模型分区：对模型中不那么关键的低范数部分应用轻量级差分隐私（DP），而其余部分则用同态加密（HE）保护。通过分布式投票机制确保分区共识。

Result: 理论分析证实了在相同隐私水平下效率和效用的可调节性。实验结果表明，通过调整超参数，该方法能够灵活地平衡模型准确性和训练时间。

Conclusion: ParaAegis提供了一种灵活控制联邦学习中隐私、效用和效率平衡的解决方案，有助于解决现有保护机制的局限性。

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [156] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK是一个新颖的LLM框架，通过引入空间增强注意力（SE-Attention）和记忆检索前馈网络（MRFFN），解决了大型语言模型（LLMs）在交通预测中捕获时空依赖的局限性，并在基准数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 交通预测对智能交通系统至关重要。尽管LLMs在近期研究中表现出潜力，但其固有的序列处理设计使其在有效捕获空间依赖性方面面临挑战，特别是难以建模空间关系和兼容图结构空间数据。

Method: 提出ST-LINK框架以增强LLMs捕获时空依赖的能力。核心组件包括：
1. Spatially-Enhanced Attention (SE-Attention)：扩展旋转位置嵌入，将空间相关性作为直接旋转变换整合到注意力机制中，以最大限度地进行空间学习。
2. Memory Retrieval Feed-Forward Network (MRFFN)：动态检索并利用关键历史模式，以捕获复杂的时态依赖并提高长期预测的稳定性。

Result: 在基准数据集上的综合实验表明，ST-LINK超越了传统的深度学习和LLM方法，能够有效捕获常规交通模式和突变。

Conclusion: ST-LINK通过其创新的SE-Attention和MRFFN组件，成功增强了LLMs捕获交通数据中时空依赖的能力，并在交通预测任务中实现了卓越的性能。

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [157] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 针对多视图无监督特征选择（MUFS）中因混杂因素导致虚假关联，进而选择不相关特征的问题，本文提出了CAUSA方法。它通过引入因果正则化模块，有效识别并缓解虚假关联，实现因果信息特征选择。


<details>
  <summary>Details</summary>
Motivation: 现有MUFS方法依赖特征与聚类标签的关联，但这种关联可能不可靠，且忽视了混杂因素导致的虚假关联，从而选择了不相关特征。本文旨在从因果角度解决这一问题。

Method: 本文引入新颖的结构因果模型从因果角度分析MUFS，并提出CAUSA方法。CAUSA包含两部分：1. 广义无监督谱回归模型，捕捉特征与一致性聚类标签间的依赖。2. 因果正则化模块，自适应分离混杂因素，学习视图共享样本权重以平衡混杂分布，从而缓解虚假关联。两者整合于统一框架，选择因果信息特征。

Result: 综合实验表明，CAUSA优于现有的多个最先进方法。

Conclusion: 本文首次深入研究无监督设置下的因果多视图特征选择问题，通过引入因果视角有效解决了虚假关联问题，并提出了高性能方法CAUSA。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [158] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: 提出了一种名为FHNN的物理结构神经网络，用于解决流体-结构相互作用中的浮体耗散动力学建模难题，提供可解释的预测和更稳定的长程模拟，优于传统黑箱模型。


<details>
  <summary>Details</summary>
Motivation: 现有黑箱神经网络模型在建模耗散动力学时，解释性有限且长程预测不稳定，难以准确建模流固耦合系统中浮体运动的耗散动力学。

Method: 提出了浮体流体动力学神经网络（FHNN），一个物理结构化的框架。该框架预测可解释的流体动力学参数（如附加质量、阻力系数和基于流函数的流场），并将其与解析运动方程相结合。

Result: 在合成涡流数据集上，FHNN的误差比Neural ODEs低一个数量级，并能恢复物理上一致的流场。与哈密顿和拉格朗日神经网络相比，FHNN在处理耗散动力学方面更有效，同时保持了可解释性。

Conclusion: FHNN通过结合物理结构和神经网络，弥合了黑箱学习和透明系统识别之间的鸿沟，为流固耦合中的耗散动力学建模提供了一个可解释、稳定且准确的解决方案。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [159] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: 本文提出GPhyT，一种通用物理Transformer模型，通过上下文学习实现对多种物理现象（如流固耦合、激波、热对流等）的统一模拟，无需预设方程，并在性能、零样本泛化和长期预测方面超越专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有物理领域的机器学习方法局限于单一狭窄领域，且每个新系统都需要重新训练，无法达到像自然语言处理中基础模型那样的“一次训练，随处部署”的范式。研究者希望开发一个物理基础模型（PFM）以 democratize 高精度模拟、加速科学发现并消除专业求解器开发的需要。

Method: 研究者提出了通用物理Transformer (GPhyT)，它在1.8 TB的多元模拟数据上进行训练。其核心在于Transformer能够从上下文中学习并推断出控制动力学，从而使一个模型能够模拟多种物理现象，而无需被告知底层方程。

Result: GPhyT实现了三项关键突破：1) 在多个物理领域表现出卓越性能，超越专用架构高达29倍；2) 通过上下文学习实现对全新物理系统的零样本泛化；3) 能够进行稳定的50步长预测。

Conclusion: 本研究确立了一个单一模型能够仅从数据中学习可泛化的物理原理，为构建一个能彻底改变计算科学和工程的通用物理基础模型（PFM）开辟了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [160] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 本研究利用混合量子-经典方法解决小样本信用风险评估问题，在真实金融数据集上实现了超越经典模型的优异性能。


<details>
  <summary>Details</summary>
Motivation: 经典方法难以处理复杂的金融问题，尤其是在普惠金融领域，数据稀缺和不平衡严重限制了传统模型在小样本信用风险评估中的有效性。

Method: 设计并实现了一种新颖的混合量子-经典工作流。首先，使用经典机器学习模型（逻辑回归、随机森林、XGBoost）的集成进行智能特征工程和降维。随后，通过参数偏移规则训练的量子神经网络 (QNN) 作为核心分类器。该框架在数值模拟和Quafu量子云平台的ScQ-P21超导处理器上进行了评估。

Result: 在一个包含279个样本的真实信用数据集上，QNN在模拟中取得了0.852 +/- 0.027的平均AUC，在硬件实验中实现了0.88的AUC。其性能超越了一系列经典基准模型，特别是在召回率指标上表现突出。

Conclusion: 本研究为在NISQ时代将量子计算应用于数据受限的金融场景提供了实用蓝图，并为量子计算在普惠金融等高风险应用中的潜力提供了有价值的实证支持。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [161] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 本文提出一个将图神经网络(GNN)嵌入孔隙网络模型(PNM)的端到端可微分混合框架，通过以整体渗透率作为训练目标，学习孔隙尺度水力传导率，实现复杂多孔介质中渗透率的准确预测和良好泛化。


<details>
  <summary>Details</summary>
Motivation: 准确预测多孔介质渗透率对地下流动建模至关重要。纯数据驱动模型缺乏泛化性和物理约束；传统孔隙网络模型(PNM)虽基于物理但依赖理想几何假设，限制了复杂结构中的精度。

Method: 开发了一个将GNN嵌入PNM的端到端可微分混合框架。GNN取代PNM中用于传导率计算的分析公式，根据孔隙和喉道特征预测传导率。预测值随后输入PNM求解器计算渗透率。GNN无需标记传导率数据，通过使用单一标量渗透率作为训练目标进行学习，利用自动微分和离散伴随法实现GNN和PNM求解器的梯度反向传播，实现完全耦合的端到端训练。

Result: 该模型实现了高精度和跨尺度的良好泛化，优于纯数据驱动和传统PNM方法。基于梯度的敏感性分析揭示了物理一致的特征影响，提高了模型可解释性。

Conclusion: 该方法为复杂多孔介质中的渗透率预测提供了一个可扩展且物理信息丰富的框架，有效降低了模型不确定性并提高了准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [162] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 本文提出一种概率框架，用于联合插补心脏数据并个性化心血管力学模型，以解决脑研究中心脏数据不完整的问题，从而探索心-脑关系。


<details>
  <summary>Details</summary>
Motivation: 临床研究中缺乏多模态患者数据（例如神经影像数据集缺少足够的心脏特征），限制了力学模型在脑部疾病中心血管因素建模的应用。

Method: 引入一个概率框架，用于联合心脏数据插补和心血管力学模型个性化。该方法基于变分框架，联合推断心脏信息插补模型，并结合高斯过程模拟器以忠实地再现个性化心血管动态。

Result: 在UK Biobank数据集上的实验结果表明，即使在仅包含收缩压和舒张压等最少心脏信息的数据集中，该模型也能准确插补缺失的心脏特征，并联合估计集总模型的模拟参数。

Conclusion: 该方法通过模拟与不同脑解剖状况对应的真实心脏动态，实现了对心-脑联合关系的新颖探索。

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [163] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 在分布式异构小样本数据环境下，该研究提出一种图正则化高斯混合模型（GMM）学习方法，利用相似图指导参数共享，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 需要在分布式、局部数据异构且有限的环境中有效学习高斯混合模型，同时避免原始数据传输。

Method: 提出一种图正则化的GMM学习方法。该方法利用预设的相似图指导节点间参数共享，并允许灵活聚合邻居参数，避免了原始数据的传输。

Result: 在数据异构且样本量低的场景下，该方法优于集中式和本地独立训练的GMM。

Conclusion: 所提出的图正则化GMM学习方法在分布式异构、小样本环境下表现出卓越性能和有效性。

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [164] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 本研究提出了一个将Masked Diffusion Models (MDMs)解释为离散最优传输中能量最小化问题的理论框架，证明了三种能量形式的等价性，并基于此设计了高效的能量启发式采样调度，在低步长采样中表现优异。


<details>
  <summary>Details</summary>
Motivation: 澄清Masked Diffusion Models (MDMs)的理论基础，并通过理论的统一性启发并实现采样效率的实际提升。

Method: 构建了一个理论框架，将MDMs解释为离散最优传输中的能量最小化问题。证明了动能、条件动能和测地线能三种能量形式在MDMs结构下数学等价，且在掩码调度满足最优条件时MDMs能最小化这些能量。通过Beta分布参数化插值调度，将调度设计空间简化为2D搜索，实现高效训练后调优。

Result: 理论上统一了MDMs与离散最优传输中三种能量最小化问题。实验证明，所提出的能量启发式调度在合成和真实世界基准测试中优于手动设计的基线，尤其在低步长采样设置下性能更佳。

Conclusion: MDMs的理论基础通过离散最优传输中的能量最小化得到统一和澄清，这不仅加深了理解，还促成了实用且高效的能量启发式采样调度，显著提升了MDMs在低步长采样时的性能。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [165] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: FedSSG是一种联邦学习中的漂移对齐方法，它利用历史梯度草图和基于参与率的统计门控来解决非独立同分布数据和部分参与导致的客户端漂移问题，从而提高收敛稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，非独立同分布（Non-IID）数据和客户端部分参与会导致客户端漂移，进而引发不稳定的收敛和准确性下降。

Method: FedSSG维护一个客户端级别的漂移记忆，该记忆以轻量级草图形式累积本地模型差异（历史梯度）。关键在于，记忆更新和局部对齐项都通过一个平滑函数进行门控，该函数基于观察到的/预期的参与率（一个从服务器采样器导出的阶段信号）。这个统计学上可靠的门控在早期采样噪声占主导时保持弱和平滑，一旦参与统计数据稳定，它就会加强，从而在不增加额外通信的情况下缩小本地-全局差距。

Result: FedSSG在CIFAR-10/100数据集上，对100/500客户端和2-15%参与率的设置中，始终优于强大的基线方法，并加速了收敛。在基准测试中，它将测试准确率提高了几个百分点（例如，CIFAR-10上平均提高约+0.9，CIFAR-100上平均提高约+2.7），并且实现目标准确率的收敛速度平均快约4.5倍。该方法仅增加O(d)的客户端内存和一个常数时间的门控，且在接近独立同分布或均匀采样的情况下表现良好。

Conclusion: FedSSG表明，采样统计数据可以转化为一种有原则、历史感知的阶段控制，以稳定和加速联邦训练。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [166] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TFMAdapter是一种轻量级适配器，通过两阶段方法将协变量整合到时间序列基础模型（TSFMs）中，显著提高了预测准确性，且无需微调基础模型。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型（TSFMs）在单变量预测中表现出色，但缺乏利用协变量（对许多应用至关重要的未来可用外部变量）的能力，这限制了它们在实际应用中的准确性。

Method: 提出了TFMAdapter，一个轻量级、实例级的适配器，它不进行微调，而是通过两阶段方法增强TSFMs：1) 使用简单回归模型生成伪预测，以处理完整的历史上下文并限制对TSFM的调用；2) 训练高斯过程回归器，结合伪预测、TSFM预测和协变量来优化最终预测。

Result: 在真实世界数据集上的实验表明，TFMAdapter持续优于基础模型和监督基线，在数据和计算开销极小的情况下，比基础模型提高了24-27%。

Conclusion: 研究结果表明，轻量级适配器有潜力弥合通用基础模型与领域特定预测需求之间的鸿沟，使其能够有效利用关键协变量。

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [167] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 提出APFEx框架，首次将交叉公平性建模为敏感属性笛卡尔积上的联合优化问题。该框架通过自适应多目标优化器和可微分公平性指标，有效减少了公平性违规，并保持了竞争力准确性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习公平性方法主要关注单一属性，无法处理交叉保护属性（如种族、性别、年龄）导致的复合偏见，未能捕获交叉子群体面临的细微、乘性偏见，存在关键的研究空白。

Method: 引入自适应帕累托前沿探索器（APFEx），首次将交叉公平性建模为敏感属性笛卡尔积上的联合优化问题。APFEx结合了三项创新：1) 自适应多目标优化器，动态调整策略以平衡公平性与准确性；2) 可微分的交叉公平性指标，实现基于梯度的非平滑子群体差异优化；3) 收敛到帕累托最优解的理论保证。

Result: 在四个真实世界数据集上的实验表明，APFEx在减少公平性违规方面表现出优越性，同时保持了具有竞争力的模型准确性。

Conclusion: 本研究弥合了公平机器学习中的关键空白，为交叉公平性提供了一个可扩展、模型无关的解决方案。

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [168] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 通过简单的置信度加权平均集成现有最先进模型，无需重新训练即可在城市车辆轨迹预测任务中实现显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶领域 SOTA 预测模型不断涌现，如何结合这些大型模型的优势且无需高成本重新训练是一个重要挑战。

Method: 采用集成建模方法，将现有的 SOTA 深度学习模型直接（无需重新训练或微调）通过简单的置信度加权平均法进行组合。

Result: 该简单方法使整体预测性能比最佳单一模型提升10%，尤其在长尾指标上表现突出。该性能提升在 NuScenes 和 Argoverse 数据集上均得到验证，且覆盖数据集分布。

Conclusion: 无需重新训练或微调，通过简单的置信度加权平均集成现有最先进模型，可有效增强城市环境中车辆轨迹预测的整体性能。

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [169] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: 本文提出WILF-Q，一种基于Q-learning和Whittle指数的客户端选择方法，解决了无线联邦学习中因客户端动态状态未知导致的效率低下问题，能有效缩短达到目标精度所需时间。


<details>
  <summary>Details</summary>
Motivation: 在无线联邦学习中，服务器无法观察客户端的动态状态（如计算和通信效率），导致难以有效选择客户端以减少达到特定学习精度所需的总时间。

Method: 将客户端选择问题建模为无休止多臂老虎机问题。提出WILF-Q方法，该方法利用Q-learning自适应学习和更新与每个客户端相关的近似Whittle指数，并选择指数最高的客户端。此方法的一大优点是无需客户端状态转换或数据分布的显式知识。

Result: 实验结果表明，WILF-Q在学习效率方面显著优于现有的基线策略。

Conclusion: WILF-Q为无线联邦学习中的客户端选择提供了一种鲁棒且高效的方法。

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [170] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: 本文提出eXtended Physics-Informed Neural Network (X-PINN) 框架，结合XFEM思想、能量损失函数和域分解，通过多个神经网络有效解决多裂纹断裂力学问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理断裂介质中多裂纹问题时，难以有效捕捉裂纹体不连续性和裂纹尖端奇异性，需要一个更鲁棒、灵活且可扩展的模拟框架。

Method: 引入X-PINN框架，采用基于能量的损失函数、定制积分方案和域分解。借鉴XFEM，通过专用函数丰富神经网络解空间以捕获裂纹不连续性和奇异性。使用不同神经网络建模标准和富集解分量，形成结构化框架。

Result: 数值实验验证了所提方法在1D和2D多裂纹问题上的有效性和鲁棒性，并展现了其向3D问题扩展的潜力。

Conclusion: X-PINN为解决复杂的断裂力学问题提供了一个新颖、鲁棒且灵活的框架，能够有效模拟多裂纹行为，具有良好的性能和可扩展性。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [171] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: 本文提出EpiSMART，一个持续学习框架，通过选择性地保留高熵和预测发作样本，实现个性化癫痫发作自动检测，F1分数提高21%，适用于实时可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作检测目前依赖耗时且需要专业知识的脑电图专家分析。现有深度学习模型难以适应患者信号随时间演变，且存在灾难性遗忘问题。研究动机在于开发一种能个性化适应患者脑电信号特征的自动化持续学习模型。

Method: 提出EpiSMART持续学习框架，用于癫痫发作检测。该框架采用大小受限的回放缓冲区和知情的样本选择策略，通过选择性地保留高熵和预测发作样本，逐步适应患者特异性脑电信号，避免灾难性遗忘，同时最小化内存和计算需求。

Result: 在CHB-MIT数据集上验证，EpiSMART相较于未更新的基线模型，F1分数提高了21%。平均每天仅需6.46分钟标记数据和6.28次更新，表明其适用于可穿戴系统的实时部署。

Conclusion: EpiSMART通过有效整合新数据而不损害旧知识，在现实和资源受限条件下实现了鲁棒且个性化的癫痫发作检测，为可穿戴医疗系统中的患者特定适应和实际部署提供了持续学习方法。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [172] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 本文提出一种接收机中心的深度时态图网络，通过将干扰缓解重构为动态图回归，实时预测并校正GNSS接收机在干扰下的水平偏差，实现卓越的定位精度和数据效率。


<details>
  <summary>Details</summary>
Motivation: 全球导航卫星系统（GNSS）日益受到有意干扰的影响，导致在定位和授时至关重要时，可用性下降。

Method: 将干扰缓解重构为动态图回归问题。引入一个接收机中心的深度时态图网络，以1 Hz的频率将卫星接收机环境表示为异构星形图（接收机为中心，跟踪卫星为叶子），并包含时变属性（如信噪比、方位角、仰角、经纬度）。使用单层异构图卷积长短期记忆网络（HeteroGCLSTM）聚合短历史中的空间上下文和时间动态，输出2D偏差矢量进行实时校正。

Result: 在两个不同接收机、三种干扰模式（连续波、三音、宽带FM）和六种功率水平（-45至-70 dBm）的数据集上进行评估。与多变量时间序列基线（MLP、统一CNN和Seq2Point CNN）相比，模型持续获得最低的平均绝对误差（MAE）。在-45 dBm时，MAE达到3.64 cm至7.74 cm之间；在-60至-70 dBm时，改善至1.65-2.08 cm。在混合模式数据集上，MAE为3.78 cm (GP01) 和 4.25 cm (ublox10)，优于基线。在数据效率研究中，仅使用10%的训练数据，其性能（20 cm）仍显著优于基线（36-42 cm）。

Conclusion: 所提出的深度时态图网络能有效缓解GNSS干扰，通过实时预测和校正接收机偏差，在准确性和数据效率方面均优于现有基线方法。

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [173] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: 本文提出一种基于联邦学习（FL）和客户端级别差分隐私（DP）的本地化疫情预测方法，以在保障隐私的前提下，利用有限的本地数据为德国县级区域提供有用的COVID-19病例预测。


<details>
  <summary>Details</summary>
Motivation: 疫情期间需要快速响应的本地化干预措施，但这面临两大挑战：一是本地数据不足以训练独立的机器学习模型；二是集中敏感的健康数据存在严重的隐私和安全问题。因此，研究的动机是开发一种既能协助公共卫生专家决策，又能保护患者隐私的疫情预测方法。

Method: 研究提出了一种基于联邦学习（FL）的隐私保护预测方法。将德国的县、社区或地方卫生机构（LHA）视为客户端。该方法采用客户端级别的差分隐私（DP），训练一个共享的多层感知机（MLP）模型，利用近期病例数的滑动窗口来预测病例数。在训练过程中，客户端只交换经过范数裁剪的更新，服务器在聚合这些更新时会添加DP噪声，以确保隐私。该方法在县级的COVID-19数据上进行了两个阶段的评估。

Result: 评估结果显示，过于严格的隐私设置会导致预测不稳定和不可用。但在中等强度的隐私水平下，DP模型的性能非常接近非DP模型：2020年11月，R²为0.94（非DP为0.95），平均绝对百分比误差（MAPE）为26%；2022年3月，R²为0.88（非DP为0.93），MAPE为21%。这表明在保持良好预测效果的同时，隐私得到了有效保护。

Conclusion: 研究得出结论，客户端级别的差分隐私联邦学习（DP-FL）方法能够提供有用的县级疫情预测，并附带强大的隐私保障。同时，可行的隐私预算取决于具体的疫情阶段，这种方法能够促进卫生部门之间在本地疫情预测方面的隐私合规协作。

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [174] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 本研究通过小波变换将纳米孔电流信号转换为尺度图图像，并结合机器学习实现了对肽的实时高精度分类，为即时诊断提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 临床环境中需要廉价、快速的实时蛋白质分类技术以实现疾病诊断。纳米孔设备是潜在候选，但其复杂信号限制了分类准确性。

Method: 将纳米孔电流信号通过小波变换转换为尺度图图像，该图像捕获了幅度、频率和时间信息，适合机器学习算法。在此基础上进行分类，并展示了模型迁移技术。

Result: 在42种肽的测试中，分类准确率达到约81%，创下了该领域的新SOTA（State-of-the-Art）。同时，展示了对实际硬件部署至关重要的模型迁移技术。

Conclusion: 该方法在实现即时肽/蛋白质诊断方面迈出了重要一步，并为实时疾病诊断提供了新的途径。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [175] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 本文提出一种基于环境传感器（温、湿度、压差）融合的轻量级蜂王检测系统，采用量化决策树在STM32微控制器上实现，无需音频输入即可达到99%以上的检测准确率，为大规模养蜂提供可扩展的低功耗解决方案。


<details>
  <summary>Details</summary>
Motivation: 蜂王对蜂群健康和稳定至关重要，但现有手动监测方法费时、扰民且不适合大规模养蜂。现有的音频监测方案存在功耗高、预处理复杂、易受环境噪声影响等问题。

Method: 提出一种轻量级、多模态的蜂王检测系统，通过融合蜂箱内外环境传感器数据（温度、湿度和压力差）进行蜂王检测。该方法在商用STM32微控制器上采用量化决策树推理，实现实时、低功耗的边缘计算。

Result: 该系统仅使用环境输入即可实现超过99%的蜂王检测准确率，且音频特征未能带来显著的性能提升。

Conclusion: 该工作提供了一个可扩展、可持续的非侵入式蜂箱监测解决方案，为使用现成、节能硬件实现自主精准养蜂铺平了道路。

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [176] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 本文研究强化学习中的贝叶斯风险规避，利用BRMDP处理认知不确定性，发现其价值函数存在悲观低估。提出基于后验采样的在线RL和CMAB算法，并建立了次线性遗憾界，通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在强化学习（RL）中，由于数据不足导致的认知不确定性（即未知基础模型的参数不确定性）是一个关键挑战，需要一种能有效考虑并规避这种不确定性的方法。

Method: 1. 采用贝叶斯风险马尔可夫决策过程（BRMDP）来处理模型参数不确定性。2. 推导了贝叶斯风险价值函数与真实价值函数差异的渐近正态性。3. 提出了两种基于后验采样（Posterior Sampling）的算法，分别应用于一般的在线强化学习和在线上下文多臂老虎机（CMAB）问题。4. 进行了数值实验以验证算法的有效性及理论性质。

Result: 1. 贝叶斯风险规避方法倾向于悲观地低估原始价值函数，且这种偏差随风险规避程度的增强而增大，随数据量的增加而减小。2. 为RL和CMAB（基于常规遗憾定义）建立了次线性遗憾界。3. 为CMAB（基于贝叶斯风险遗憾定义）建立了次线性遗憾界。

Conclusion: 提出的算法能够有效解决强化学习中的认知不确定性问题，并且其理论性质得到了验证。贝叶斯风险规避方法为在不确定环境下做出稳健决策提供了一种有效途径。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [177] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 本研究分析了EEG数据分类中，不同优化器和神经网络架构在各频率带上的性能，并强调了优化器、模型和频率带选择对分类器性能和特征重要性的影响。


<details>
  <summary>Details</summary>
Motivation: 旨在通过探索不同的EEG频率带、优化器和模型架构对分类器性能的影响，从而提高神经影像分类任务中分类器的性能，并理解特征的重要性。

Method: 实现了三种神经网络架构：深度全连接网络、浅层三层网络和卷积神经网络（CNN），并使用TensorFlow和PyTorch框架进行比较。此外，采用SHAP (Shapley Additive Explanations) 图来识别有效的类别预测。

Result: {'优化器表现': 'Adagrad和RMSprop优化器在不同频率带上持续表现良好，Adadelta在跨模型评估中表现稳健。具体来说，Adagrad在beta带中表现最佳，RMSprop在gamma带中表现优异。SGD和FTRL的表现则不一致。', '模型架构表现': 'CNN的准确率排名第二，尤其擅长捕获EEG数据的空间特征。深度全连接网络在学习复杂模式方面具有竞争力。浅层三层网络虽然有时准确率较低，但提供了计算效率。', '特征分析': 'SHAP图揭示了EEG频率带对模型准确性的细微贡献。'}

Conclusion: 优化器选择、模型架构和EEG频率带分析对于提高分类器性能以及理解神经影像分类任务中的特征重要性至关重要。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [178] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 本文提出一种可解释的分位数神经基模型（QNBM），它将分位数广义加性模型的可解释性与神经网络的预测能力结合，用于多步概率预测。


<details>
  <summary>Details</summary>
Motivation: 神经网络在多步概率预测中精度高，但其特征条件输出的底层机制难以理解，缺乏可解释性。

Method: 引入分位数神经基模型（QNBM），通过整合分位数广义加性模型（QGAM）的可解释性原则到端到端神经网络训练框架中。该模型利用共享基分解和权重分解，避免了参数分布假设。

Result: 在日前电力价格预测任务中，QNBM取得了与现有分布和分位数回归神经网络相当的预测性能。

Conclusion: 该模型通过学习输入特征到输出预测的非线性映射，为模型行为提供了有价值的洞察力，从而提升了多步概率预测模型的可解释性。

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [179] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 本研究通过与堪萨斯州约翰逊县合作，利用预测模型识别高风险个体，并通过有针对性的心理健康外展干预，有效降低了最高风险被监禁者的再入狱率，并改善了其心理健康服务利用和刑事司法介入状况。


<details>
  <summary>Details</summary>
Motivation: 许多被监禁者面临精神疾病、药物依赖和无家可归等复杂问题，而现有刑事司法系统难以满足这些需求，导致未治疗的需求恶化、再犯罪循环，对个人和公共安全造成不良后果，并加剧种族不平等。为打破这一循环，利益相关者正探索创新方法，如社区驱动和替代性警务、指导、社区建设、恢复性司法、审前分流、整体辩护和社会服务连接。本研究旨在通过有针对性的、积极主动的心理健康外展来降低再入狱率。

Method: 本研究是堪萨斯州约翰逊县与卡内基梅隆大学的合作项目。方法包括：描述所用数据；开发并报告预测建模方法和结果；设计并分析一项现场试验，以验证模型的预测能力，评估目标外展的影响，并确定在何种再入狱风险水平下外展可能最有效。

Result: 研究发现，开发的模型对新的入狱记录具有高度预测性，试验中最高风险组的个体有一半以上在次年再次入狱。外展干预在这些最高风险个体中最为有效，对心理健康服务利用、紧急医疗服务（EMS）调度和刑事司法介入产生了积极影响。

Conclusion: 通过预测模型识别高风险个体并进行有针对性的心理健康外展，是减少再入狱率的有效策略，尤其对最高风险人群效果显著，并能改善其心理健康及与刑事司法系统的互动。

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [180] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [181] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 本文提出一个端到端AI框架，通过结合多阶段AI架构、新颖的数据生成策略PCDS和贝叶斯引擎，从稀疏的常规数据中非侵入性地估计诸如青光眼相关房水流出网络渗透率等不可测量变量，解决了临床诊断和计算建模中的挑战。


<details>
  <summary>Details</summary>
Motivation: 关键医疗决策（如青光眼诊断）受到无法测量核心参数（如小梁网渗透率）的挑战，导致临床依赖间接替代指标。同时，为这类病态逆问题开发预测模型面临缺乏真实数据和高昂模拟成本的计算难题。

Method: 开发了一个端到端框架，包含：1) 多阶段人工智能架构以功能性分离问题；2) 称为PCDS的新型数据生成策略，显著减少了计算时间；3) 贝叶斯引擎以量化预测不确定性。该框架通过常规输入将单一眼压测量分解为其基本组成部分。

Result: 非侵入性估计的房水流出易度与最先进的眼压描记术表现出极好的一致性，精度媲美直接物理仪器。此外，新推导的渗透率生物标志物在按疾病风险分层临床队列方面显示出高准确性。

Conclusion: 该框架成功从常规输入中估算不可测量的组织渗透率和患者房水流出易度，展示了其诊断潜力。更广泛地，它为解决其他数据稀缺、计算密集领域的类似逆问题提供了一个可推广的通用蓝图。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [182] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: 提出TopoSizing框架，通过图算法和LLM对原始网表进行电路理解，并将其整合到贝叶斯优化中，以提高模拟和混合信号电路设计的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 模拟和混合信号电路设计面临缺乏高质量数据、难以将领域知识嵌入自动化流程的挑战。传统黑盒优化缺乏电路理解；基于学习的方法案例特定且再训练成本高；近期LLM尝试依赖人工干预，限制了通用性和透明度。

Method: 提出TopoSizing端到端框架。首先，使用图算法将电路组织为分层的器件-模块-阶段表示。其次，LLM代理通过迭代的假设-验证-细化循环（内置一致性检查）生成显式注释。最后，将这些验证后的洞察通过LLM引导的初始采样和停滞触发的信任域更新，整合到贝叶斯优化中。

Result: 将深层电路理解转化为优化增益，提高了设计效率，同时保持了可行性。

Conclusion: TopoSizing通过结合鲁棒的电路理解与优化的集成，克服了传统模拟电路设计自动化方法的局限性，实现了更高效、更可靠的设计流程。

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [183] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: 本文提出Tree-Guided Preference Optimization (TGPO) 框架，通过树形轨迹表示和自动奖励模型，解决大模型作为Web Agent进行强化学习时遇到的信用分配、标注成本高和奖励稀疏等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉-语言模型的快速发展，使用大模型作为Web Agent实现自动化网页交互变得至关重要。然而，通过强化学习训练Web Agent面临信用分配错误、高昂的标注成本和奖励稀疏等关键挑战。

Method: 提出TGPO离线强化学习框架：1. 使用树形结构轨迹表示，合并语义相同的状态以消除标签冲突。2. 引入Process Reward Model，通过子目标进度、冗余检测和动作验证自动生成细粒度奖励。3. 采用动态加权机制，在训练过程中优先处理高影响决策点。

Result: 在Online-Mind2Web和自建的C-WebShop数据集上的实验表明，TGPO显著优于现有方法，实现了更高的成功率和更少的冗余步骤。

Conclusion: TGPO框架有效解决了强化学习训练Web Agent的难题，提升了性能和效率。

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [184] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: TimeAlign是一个轻量级、即插即用的框架，通过重建任务学习辅助特征，成功纠正了时间序列预测中输入历史与未来目标间的频率不匹配，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 尽管表示学习技术在时间序列预测中已被探索，但它们在性能上未显示出显著优势，导致当前最先进的预测器很少采用。本文旨在挑战这一观点，并证明显式表示对齐能提供关键信息，以弥补输入历史和未来目标之间的分布差距。

Method: 提出TimeAlign框架，该框架通过一个简单的重建任务学习辅助特征，并将这些特征反馈给任何基础预测器。TimeAlign被设计为轻量级且即插即用的。

Result: 在八个基准测试中，TimeAlign展现出卓越的性能。研究表明，性能提升主要源于纠正了历史输入与未来输出之间的频率不匹配。该方法在理论上增加了学习表示与预测目标之间的互信息。

Conclusion: TimeAlign作为一个与架构无关且开销可忽略不计的通用对齐模块，能够显著提升现代深度学习时间序列预测系统的性能，证明了表示对齐在时间序列预测中的有效性。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [185] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 本文提出了一个统一的变分框架，用于理论化基于残差的自适应策略，并证明其在系统设计、降低误差和提升学习动态方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习中广泛使用的基于残差的自适应策略仍 largely heuristic（主要基于启发式），缺乏统一的理论基础。

Method: 引入了一个统一的变分框架，通过整合残差的凸变换来形式化基于残差的自适应策略。该框架将自适应加权解释为选择优化原始目标的采样分布，从而将离散化选择与误差度量直接关联。

Result: 该方法带来了三方面益处：1) 能够系统设计跨范数的自适应方案；2) 通过减少损失估计器的方差来降低离散化误差；3) 通过提高梯度信噪比来增强学习动态。在算子学习中，该框架在不同优化器和架构上都展示了显著的性能提升。

Conclusion: 该研究为基于残差的自适应性提供了理论依据，并为原则性的离散化和训练策略奠定了基础。

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [186] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种开创性的Banach-Bregman随机优化框架，将现有理论从希尔伯特空间扩展到更一般的Banach空间，统一了多种优化方法，并通过Bregman几何实现了显著的收敛加速和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现代AI（如机器学习、深度学习、强化学习和大型语言模型训练）中的随机优化理论主要局限于希尔伯特空间，无法有效处理非欧几里得设置（如单纯形上的镜像下降、信息几何中的自然梯度、KL正则化语言模型训练），因此需要一个更普适的优化框架。

Method: 该工作引入了基于Bregman几何的Banach-Bregman框架，在一般Banach空间中进行随机迭代。它利用Bregman投影和Bregman-Fejer单调性提供了一个统一的优化模板，涵盖了随机近似、镜像下降、自然梯度和自适应方法。此外，它在非希尔伯特设置中引入了超松弛（λ > 2）机制，并建立了从几乎必然有界性到几何速率的收敛定理。

Result: 该框架（i）为随机优化提供了统一模板；（ii）在非希尔伯特设置中引入超松弛（λ > 2），实现加速；（iii）给出了收敛定理。在机器学习、深度学习（如Transformer）、强化学习和大型语言模型任务上的实证研究表明，相比传统基线，收敛速度提升高达20%，方差降低，准确性提高。

Conclusion: Banach-Bregman几何有望成为统一AI核心范式中优化理论与实践的基石，通过在一般Banach空间中建立Bregman几何，突破了现有希尔伯特空间理论的局限性。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [187] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: 提出RKTV-INR去噪框架，利用隐式神经网络、Runge-Kutta和全变分，从噪声数据中重建动力系统轨迹和导数，进而实现精确的系统识别。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的非线性动力系统建模常因测量噪声而受阻。

Method: RKTV-INR框架使用隐式神经网络（INR）表示状态轨迹，直接拟合噪声观测数据，并施加Runge-Kutta积分和全变分作为约束。训练后的INR生成去噪、连续的轨迹和精确的导数，随后将这些数据输入到SINDy方法中以恢复控制方程。

Result: 实验表明，RKTV-INR能有效抑制噪声、精确估计导数并实现可靠的系统识别。

Conclusion: RKTV-INR框架为从噪声数据中进行准确的动力系统建模和识别提供了一个有效且可靠的解决方案。

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [188] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 研究表明，语言模型的激活值能够线性编码信息在训练期间学习的时间顺序。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型是否能够根据信息的习得时间进行区分，及其对模型处理冲突数据和知识修改的影响。

Method: 通过在六个不相交的命名实体数据集上顺序微调Llama-3.2-1B模型，构建具有已知训练顺序的模型，并分析测试样本的平均激活值，同时使用线性探针来区分不同学习阶段的实体。

Result: 发现六个训练数据集的测试样本平均激活值能够编码训练顺序，在2D子空间中呈线性排列；线性探针能以约90%的准确率区分“早期”与“后期”实体，并泛化到未见实体；模型可被微调以约80%的准确率报告未见实体的训练阶段；此时间信号与激活幅度、损失或模型置信度无关。

Conclusion: 模型能够根据信息的习得时间进行区分，这对于它们管理冲突数据和响应知识修改具有重要的启示。

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [189] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 本文提出一种基于临界阻尼高阶Langevin动力学的防御机制，通过引入辅助变量在扩散过程早期破坏敏感数据，以抵御生成式AI中扩散模型的成员推断攻击。


<details>
  <summary>Details</summary>
Motivation: 生成式AI应用带来了新的数据安全担忧，特别是扩散模型面临成员推断攻击的威胁。尽管扩散模型本身具有一定抵抗力，但仍易受攻击，因此需要提出有效的防御机制。

Method: 提出一种基于“临界阻尼高阶Langevin动力学”的防御机制。该方法引入多个辅助变量，并沿这些变量设计一个联合扩散过程，通过在扩散过程早期混合外部随机性来破坏敏感输入数据。

Result: 该防御概念在理论上进行了探讨，并通过在玩具数据集和语音数据集上的实验验证了其有效性。评估使用了AUROC曲线和FID指标。

Conclusion: 提出的基于临界阻尼高阶Langevin动力学的防御机制，通过早期引入外部随机性保护敏感数据，能有效抵御扩散模型上的成员推断攻击，并在理论和实践中均显示出潜力。

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [190] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: 本文提出NIRVANA，一种基于Adam优化下的神经正切核（NTK）一阶显著性准则的LLM结构化剪枝方法。它通过自适应稀疏性分配和KL散度校准数据选择，有效平衡零样本准确性与微调能力，在Llama3、Qwen和T5模型上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）的结构化剪枝方法常导致显著的性能下降，尤其在零样本设置下，且需要昂贵的监督微调（SFT）或适配器插入等恢复技术。研究动机是开发一种能够平衡零样本准确性与鲁棒微调能力，同时避免高昂恢复成本的剪枝方法。

Method: 引入NIRVANA方法，具体包括：1) 利用在Adam优化动态下从神经正切核（NTK）导出的一阶显著性准则，提供理论基础的剪枝策略；2) 整合自适应稀疏性分配机制，在全球范围内平衡地调整跨层和模块（注意力与MLP）的剪枝强度；3) 提出一种基于KL散度的简单有效校准数据选择策略，以减轻剪枝决策对校准数据质量的敏感性，确保更可靠和与任务无关的剪枝结果。

Result: 在Llama3、Qwen和T5模型上进行的全面实验表明，在等效稀疏性约束下，NIRVANA优于现有的结构化剪枝方法。这证明了它为LLM压缩提供了一种理论上合理且实用的方法。

Conclusion: NIRVANA是一种新颖的、理论上合理且实用的LLM结构化剪枝方法。它成功解决了现有方法在零样本性能下降和高昂恢复成本方面的不足，通过平衡零样本准确性保持与鲁棒微调能力，实现了卓越的LLM压缩效果。

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [191] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: CaT提出在无真实标签的后训练阶段，通过模型推理时的探索生成自监督信号，将并行推断合成单一参考，显著提升大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决模型在后训练阶段缺乏真实标签时，如何获取学习信号以进行持续改进的问题。

Method: 提出"Compute as Teacher (CaT)"方法。该方法在推理时，通过模型并行生成多组推断(rollouts)，并利用一个冻结的初始策略(anchor)来综合这些推断，生成一个单一的“教师”参考信号。该信号被转化为奖励，用于可验证任务（编程等价）和不可验证任务（LLM法官评分的自提标准）。CaT的合成方法优于传统选择方法，即使所有推断都错误，合成结果也可能正确，且性能随推断数量扩展。可与强化学习结合（CaT-RL）。

Result: 作为测试时过程，CaT使Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B模型在MATH-500上性能提升高达27%，在HealthBench上提升高达12%。结合强化学习（CaT-RL）后，性能进一步提升，分别达到33%和30%，且训练后的策略超越了初始教师信号。

Conclusion: CaT提供了一种在无真实标签场景下生成自监督信号的有效机制，通过利用推理时的计算和探索显著提升了大型语言模型的性能，并为进一步的强化学习优化奠定了基础，使其能够超越自我监督的初始水平。

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [192] [GRU-Based Learning for the Identification of Congestion Protocols in TCP Traffic](https://arxiv.org/abs/2509.13490)
*Paul Bergeron,Sandhya Aneja*

Main category: cs.NI

TL;DR: 本文使用基于GRU的学习模型，在马里斯特大学校园网络中以97.04%的准确率识别了TCP Reno、TCP Cubic、TCP Vegas和BBR拥塞控制协议。


<details>
  <summary>Details</summary>
Motivation: 旨在复杂且竞争激烈的网络环境中，利用更快的神经网络架构实现对现有TCP拥塞控制协议的高精度识别。

Method: 采用基于GRU（门控循环单元）的学习模型，并使用了更快的神经网络架构进行协议识别。

Result: 在马里斯特大学校园网络中，实现了97.04%的识别准确率，与现有工作相比，在更复杂的网络环境下取得了相当高的准确率。

Conclusion: 基于GRU的学习模型能够以高精度识别复杂网络环境下的多种TCP拥塞控制协议，表现出良好的鲁棒性和有效性。

Abstract: This paper presents the identification of congestion control protocols TCP
Reno, TCP Cubic, TCP Vegas, and BBR on the Marist University campus, with an
accuracy of 97.04% using a GRU-based learning model. We used a faster neural
network architecture on a more complex and competitive network in comparison to
existing work and achieved comparably high accuracy.

</details>


### [193] [Odin: Effective End-to-End SLA Decomposition for 5G/6G Network Slicing via Online Learning](https://arxiv.org/abs/2509.13511)
*Duo Cheng,Ramanujan K Sheshadri,Ahan Kak,Nakjung Choi,Xingyu Zhou,Bo Ji*

Main category: cs.NI

TL;DR: 为解决5G/6G网络切片中端到端SLA分解的挑战，本文提出基于贝叶斯优化的Odin方案，通过利用在线反馈，显著提升SLA满足度并降低资源成本。


<details>
  <summary>Details</summary>
Motivation: 5G/6G网络切片要求将端到端SLA高效分解为域级目标，但由于域异构性、动态网络条件及SLA编排器对域资源优化缺乏感知，SLA分解面临巨大挑战。

Method: 提出Odin方案，该方案基于贝叶斯优化，利用各域的在线反馈实现可证明高效的SLA分解。

Result: 相较于基线方案，Odin的端到端编排器在SLA满足度上实现了高达45%的性能提升，并降低了整体资源成本，即使在存在域噪声反馈的情况下也表现良好。

Conclusion: Odin提供了一种高效的SLA分解方法，显著提升了网络切片的SLA满足度，并有效降低了资源消耗。

Abstract: Network slicing plays a crucial role in realizing 5G/6G advances, enabling
diverse Service Level Agreement (SLA) requirements related to latency,
throughput, and reliability. Since network slices are deployed end-to-end
(E2E), across multiple domains including access, transport, and core networks,
it is essential to efficiently decompose an E2E SLA into domain-level targets,
so that each domain can provision adequate resources for the slice. However,
decomposing SLAs is highly challenging due to the heterogeneity of domains,
dynamic network conditions, and the fact that the SLA orchestrator is oblivious
to the domain's resource optimization. In this work, we propose Odin, a
Bayesian Optimization-based solution that leverages each domain's online
feedback for provably-efficient SLA decomposition. Through theoretical analyses
and rigorous evaluations, we demonstrate that Odin's E2E orchestrator can
achieve up to 45% performance improvement in SLA satisfaction when compared
with baseline solutions whilst reducing overall resource costs even in the
presence of noisy feedback from the individual domains.

</details>


### [194] [A Framework for Multi-source Prefetching Through Adaptive Weight](https://arxiv.org/abs/2509.13604)
*Yoseph Berhanu Alebachew,Mulugeta Libsie*

Main category: cs.NI

TL;DR: 本文提出一个新颖的预取框架，能集成不同类型的预取方案（基于历史和基于语义），通过自适应权重管理降低网络延迟，尤其适用于资源受限的移动设备。


<details>
  <summary>Details</summary>
Motivation: 尽管万维网已成为日常生活重要部分，用户观察到的延迟仍是问题。现有缓存效果有限，而预取技术在补充缓存方面有所发展。然而，现有预取方法（多为基于访问历史）难以利用应用层级的Web文档关系或语义信息，且将不同方案集成时可扩展性受限。

Method: 本文提出了一个新颖的框架，能够整合基于用户访问历史和基于语义信息的预取方案，而无需对现有算法进行重大修改。该框架将每个参与的方案视为生成未来可能访问对象列表的算法。它还采用自适应权重管理技术，根据各算法的实际表现调整其在整体预测中的影响。

Result: 研究发现，该框架比现有同类方案的“攻击性”更低，这对于资源受限的移动设备（当前Web用户的主要访问方式）来说至关重要。它实现了不同预取方案的无缝集成和自适应调整。

Conclusion: 该框架提供了一个可扩展且自适应的解决方案，用于集成各种Web预取方案以解决网络延迟问题。其“攻击性”较低的特性使其特别适用于资源受限的移动设备，为未来的Web预取研究和实践提供了新的方向。

Abstract: The World Wide Web has come to be a great part of our daily life, yet user
observed latency is still a problem that needs a proper means of handling. Even
though earlier attempts focused on caching as the chief solution to tackling
this issue, its success was extremely limited. Prefetching has come to be the
primary technique in supplementing caching towards soothing the latency problem
associated with the contemporary Internet. However, existing approaches in
prefetching are extremely limited in their ability to employ application level
web document relationship which is often visible only to the content developer.
This is because most approaches are access history based schemes that make
future users' access prediction only based on past user access. Attempts to
incorporate prefetching schemes that utilize semantic information with those
that use users past access history are extremely limited in their
extensibility. In this work we present a novel framework that enables
integration of schemes from both worlds of prefetching without the need for a
major modification to the algorithms. When there is a need/possibility to
capture new application level context, a new algorithm could be developed to do
so and then it can be integrated into the framework. Since each participating
scheme is merely viewed as an algorithm that produces a list of candidate
objects that are likely to be accessed in the near future, the framework can
entertain any one of the existing prefetching schemes. With its adaptive weight
management technique the framework adjusts the effect of each algorithm in the
overall prediction to parallel with its observed performance so far. We have
found this formwork to be less aggressive than its contemporary counterparts
which is extremely important for resource constrained mobile devices that have
come to be the major means of access by users of the current web.

</details>


### [195] [LINC: An In-Network Coding Approach to Tame Packet Loss in Hybrid Wireless-Fiber Backbones](https://arxiv.org/abs/2509.13714)
*Benoit Pit-Claudel,Muriel Médard,Manya Ghobadi*

Main category: cs.NI

TL;DR: 混合骨干网面临环境性丢包，现有协议误判为拥塞。LINC提出一种无需终端主机配合的网络内部编码系统，通过消除不必要的重传，可将端到端延迟降低18%。


<details>
  <summary>Details</summary>
Motivation: 超低延迟应用促使混合骨干网发展，但其易受环境因素导致偶发性丢包。现有传输协议错误地将此类丢包视为网络拥塞，导致不必要的重传。此外，现有网络编码方案需要终端主机栈的完全访问和配合，限制了其应用。

Method: 论文提出LINC系统，通过在网络内部提供网络编码（NC）能力来缓解环境性丢包，无需终端主机配合。LINC采用基于链路的系统块编码方法，在网络内部对数据包进行编码和解码。研究还建模了端到端重传与LINC引入的冗余数据包之间的有效吞吐量权衡，并提出了优化公式以确定最佳编码参数。

Result: 在真实骨干网络拓扑上的仿真结果表明，LINC通过消除不必要的重传，将端到端延迟降低了高达18%。

Conclusion: LINC通过提供无需终端主机配合的网络内部网络编码，有效地解决了混合骨干网络中的环境性丢包问题，显著降低了超低延迟应用的端到端延迟。

Abstract: The emergence of ultra-low latency applications, such as financial
transactions, has driven the development of hybrid backbone networks that rely
on fiber, satellite, and microwave links. Despite providing low latencies,
these hybrid networks suffer from occasional environmental packet loss caused
by poor weather, construction, and line of sight blockage. Paradoxically,
today's hybrid backbones rely on conventional transport protocols that take
packet loss to signal network congestion, as opposed to transient environmental
obstacles. A common approach to address this challenge is to use network coding
(NC) between the end hosts to recover from these occasional packet loss events.
However, current NC proposals assume full access to the end-hosts' stack to
perform end-to-end encoding/decoding operations. In this paper, we introduce
LINC, a novel system that provides in-network NC capabilities to mitigate
environmental packet loss events without requiring cooperation from the end
hosts. LINC uses a systematic block coding approach on a link-by-link basis,
encoding and decoding packets inside the network. We model the tradeoff in
goodput between end-to-end retransmissions and redundant packets introduced by
LINC, and propose an optimization formulation to determine the optimal choice
of coding parameters. Our simulations on real-world backbone topologies
demonstrate that LINC reduces the end-to-end latency by up to 18% by
eliminating unnecessary retransmissions.

</details>


### [196] [Conducting Mission-Critical Voice Experiments with Automated Speech Recognition and Crowdsourcing](https://arxiv.org/abs/2509.13724)
*Jan Janak,Kahlil Dozier,Lauren Berny,Liang Hu,Dan Rubenstein,Charles Jennings,Henning Schulzrinne*

Main category: cs.NI

TL;DR: 本研究开发了评估任务关键型语音（MCV）系统QoE的人机实验方法和工具，发现人类在准确性相关的MCV任务中通常优于ASR，且编解码器显著影响最终用户QoE和ASR性能。


<details>
  <summary>Details</summary>
Motivation: 任务关键型语音（MCV）通信系统对公共安全至关重要，但现有研究在模拟真实世界环境和准确衡量用户体验质量（QoE）方面存在局限性。美国国家标准与技术研究院（NIST）的公共安全通信研究（PSCR）部门旨在关联MCV系统中的损伤与用户的QoE。

Method: 开发了用于MCV人机实验的方法和工具，包括一个模拟真实世界MCV系统的测试平台，以及一个在转录任务中近似人类受试者的自动语音识别（ASR）机器人。通过基于Levenshtein距离的指标评估QoE，并认为其适合衡量理解度。与Amazon MTurk志愿者进行了人类受试者研究，以理解系统参数和损伤对人类表现及最终用户QoE的影响，并比较了多种ASR系统配置与人类受试者的表现。

Result: 研究发现，人类在准确性相关的MCV任务中通常优于ASR。此外，编解码器（codec）显著影响最终用户的QoE和ASR性能。

Conclusion: 本研究成功开发了在模拟真实环境中进行MCV人机实验的方法和工具，并发现人类在准确性任务中表现优于ASR，同时强调了编解码器对用户体验质量和ASR性能的关键影响。

Abstract: Mission-critical voice (MCV) communications systems have been a critical tool
for the public safety community for over eight decades. Public safety users
expect MCV systems to operate reliably and consistently, particularly in
challenging conditions. Because of these expectations, the Public Safety
Communications Research (PSCR) Division of the National Institute of Standards
and Technology (NIST) has been interested in correlating impairments in MCV
communication systems and public safety user quality of experience (QoE).
Previous research has studied MCV voice quality and intelligibility in a
controlled environment. However, such research has been limited by the
challenges inherent in emulating real-world environmental conditions.
Additionally, there is the question of the best metric to use to reflect QoE
accurately.
  This paper describes our efforts to develop the methodology and tools for
human-subject experiments with MCV. We illustrate their use in human-subject
experiments in emulated real-world environments. The tools include a testbed
for emulating real-world MCV systems and an automated speech recognition (ASR)
robot approximating human subjects in transcription tasks. We evaluate QoE
through a Levenshtein Distance-based metric, arguing it is a suitable proxy for
measuring comprehension and the QoE. We conducted human-subject studies with
Amazon MTurk volunteers to understand the influence of selected system
parameters and impairments on human subject performance and end-user QoE. We
also compare the performance of several ASR system configurations with
human-subject performance. We find that humans generally perform better than
ASR in accuracy-related MCV tasks and that the codec significantly influences
the end-user QoE and ASR performance.

</details>


### [197] [Performance Evaluation of Intent-Based Networking Scenarios: A GitOps and Nephio Approach](https://arxiv.org/abs/2509.13901)
*Saptarshi Ghosh,Ioannis Mavromatis,Konstantinos Antonakoglou,Konstantinos Katsaros*

Main category: cs.NI

TL;DR: 本文对Argo CD、Flux CD和ConfigSync等GitOps工具在意图驱动网络（IBN）场景下的性能和资源开销进行了基准测试，评估了它们的延迟、资源消耗及权衡。


<details>
  <summary>Details</summary>
Motivation: 尽管GitOps范式已被广泛采用，但其工具在意图驱动网络（IBN）场景中的性能和可扩展性尚未得到充分评估。

Method: 通过可复现的、度量驱动的基准测试，评估了Argo CD、Flux CD和ConfigSync三种主流GitOps操作符的延迟和资源开销。在单意图和多意图场景下进行了受控实验，并使用Nephio作为编排器，调查了现实的端到端部署管道中的处理延迟和开销。

Result: 研究结果揭示了这些工具在确定性、资源效率和响应性方面的权衡。同时，量化了声明式端到端部署管道中的处理延迟和开销。

Conclusion: 研究发现为未来自主网络编排系统中的GitOps工具选择和优化提供了有价值的见解。

Abstract: GitOps has emerged as a foundational paradigm for managing cloud-native
infrastructures by enabling declarative configuration, version-controlled
state, and automated reconciliation between intents and runtime deployments.
Despite its widespread adoption, the performance and scalability of GitOps
tools in Intent-Based Networking (IBN) scenarios are insufficiently evaluated.
This paper presents a reproducible, metric-driven benchmarking, assessing the
latency and resource overheads of three widely used GitOps operators: Argo CD,
Flux CD, and ConfigSync. We conduct controlled experiments under both single-
and multi-intent scenarios, capturing key performance indicators such as
latency and resource consumption. Our results highlight trade-offs between the
tools in terms of determinism, resource efficiency, and responsiveness. We
further investigate a realistic orchestration scenario, using Nephio as our
orchestrator, to quantify the processing latency and overhead in declarative
end-to-end deployment pipelines. Our findings can offer valuable insights for
tool selection and optimisation in future autonomous network orchestration
systems.

</details>


### [198] [Low-cost Highly-interoperable Multiplatform Campus Network: Experience of YARSI University](https://arxiv.org/abs/2509.13954)
*Surya Agustian,Sandra Permana,Salman Teguh Pratista,Syarifu Adam,Iswandi*

Main category: cs.NI

TL;DR: 雅尔西大学通过结合开源系统、自组装PC和Cisco交换机，设计并实施了一个低成本校园网络及互联网接入方案，显著降低了成本。


<details>
  <summary>Details</summary>
Motivation: 建设校园网络成本高昂，且缺乏IT知识或工程师会导致外包成本失控，使得项目难以实施。

Method: 雅尔西大学成立CMIS，利用在自组装PC上运行的开源操作系统作为网关和路由器，结合Cisco交换技术，设计了基于UTP的低成本校园网络。同时，通过多个宽带连接和专用无线接入，并使用强制门户系统，为超过100名同时在线用户共享互联网。

Result: 通过该策略，显著降低了网络基础设施和互联网接入的采购、维护和运营成本。

Conclusion: 该低成本校园网络和互联网连接设计模型可供预算有限的农村社区或组织采纳。

Abstract: To some organizations, building campus network is sometimes considered to be
very expensive; and this has made the project uneasy to perform. Moreover, if
the organization without sufficient IT knowledge does not have capable IT
engineers, leaving this project to third parties without supervision would lead
to unexpected larger expenses. For this reason, in the year of 2003, YARSI
University formed CMIS (Center for Management Infor-mation System) to perform
tasks in designing, operations and maintenance of campus network and its
services. By combining Open Source operating system run on a local assembled
personal computer as gateway and router, and switching technology from Cisco,
we designed a low-cost UTP-based campus network which covering rooms and
buildings in YARSI environment. Meanwhile the internet access through several
broadband connections and dedicated wireless was shared to more than 100
simultaneous users by a captive portal system. With this strategy, we can
significantly reduce cost for purchasing, maintenance and operations of network
infrastructure and internet access. Our model in designing low-cost campus
network and internet connections could be adopted by rural community or
organizations that have limited budget to have internet access.

</details>


### [199] [Path-Oblivious Entanglement Swapping for the Quantum Internet](https://arxiv.org/abs/2509.13993)
*Vincent Mutolo,Rhea Parekh,Dan Rubenstein*

Main category: cs.NI

TL;DR: 针对量子互联网中Bell对交换的现有路径预留方案，本文提出并初步探索了一种路径无关的方法，认为其更适用于未来更稳定、廉价的量子态，并通过一个线性规划和一个朴素基线协议进行了初步验证。


<details>
  <summary>Details</summary>
Motivation: 现有量子互联网中的Bell对交换协议采用预设路径，这基于量子态昂贵且不稳定的假设。然而，经典网络经验表明，在资源充足时，灵活、非预留方法往往优于限制性方法。因此，本文旨在探索一种路径无关的交换方法，以适应未来更廉价、更稳定的量子态。

Method: 将Bell对交换过程公式化为一个线性规划问题。提出并评估了一个相对朴素的基线交换协议，该协议旨在平衡网络中的Bell对。

Result: 初步结果表明，虽然朴素的平衡方法仍有改进空间，但研究路径无关的Bell对交换是一个有前景的方向。

Conclusion: 路径无关的Bell对交换方法具有潜力，是未来量子互联网中值得深入研究的方向。

Abstract: Proposed Bell pair swapping protocols, an essential component of the Quantum
Internet, are planned-path: specific, structured, routing paths are reserved
prior to the execution of the swapping process. This makes sense when one
assumes the state used in the swapping process is expensive, fragile, and
unstable. However, lessons from classical networking have shown that while
reservations seem promising in concept, flexible, reservation-light or free
approaches often outperform their more restrictive counterparts in
well-provisioned networks. In this paper, we propose that a path-oblivious
approach is more amenable to supporting swapping as quantum state evolves into
a cheaper, more robust form. We formulate the swapping process as a linear
program and present and evaluate a fairly naive baseline swapping protocol that
tries to balance Bell pairs throughout the network. Preliminary results show
that while naive balancing leaves room for improvement, investigating
path-oblivious swapping is a promising direction.

</details>


### [200] [RepCaM++: Exploring Transparent Visual Prompt With Inference-Time Re-Parameterization for Neural Video Delivery](https://arxiv.org/abs/2509.14002)
*Rongyu Zhang,Xize Duan,Jiaming Liu,Li Du,Yuan Du,Dan Wang,Shanghang Zhang,Fangxin Wang*

Main category: cs.NI

TL;DR: 本文提出RepCaM++框架，包含RepCaM模块和TVP，旨在解决现有内容感知视频超分辨率方法中参数累积和性能下降问题，实现了视频恢复质量和带宽压缩的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有内容感知视频超分辨率方法通过额外参数定制模型以适应每个视频块，导致参数积累，随着视频长度增加，交付成本和性能都会受到负面影响。

Method: 引入RepCaM++框架，其核心是可重参数化内容感知调制（RepCaM）模块，该模块在训练期间集成并行级联参数以处理多个视频块，并在推理时通过重参数化消除这些参数。此外，提出透明视觉提示（TVP），使用少量零初始化的图像级参数来捕获视频块的精细细节，以进一步提升性能。

Result: 在包含六个不同视频场景的VSD4K数据集上进行广泛实验，结果表明该方法在视频恢复质量和交付带宽压缩方面均达到最先进水平。

Conclusion: RepCaM++框架及其RepCaM模块和TVP组件有效解决了现有内容感知方法的局局限性，显著提升了视频恢复质量并降低了带宽需求，达到了领先的性能。

Abstract: Recently, content-aware methods have been employed to reduce bandwidth and
enhance the quality of Internet video delivery. These methods involve training
distinct content-aware super-resolution (SR) models for each video chunk on the
server, subsequently streaming the low-resolution (LR) video chunks with the SR
models to the client. Prior research has incorporated additional partial
parameters to customize the models for individual video chunks. However, this
leads to parameter accumulation and can fail to adapt appropriately as video
lengths increase, resulting in increased delivery costs and reduced
performance. In this paper, we introduce RepCaM++, an innovative framework
based on a novel Re-parameterization Content-aware Modulation (RepCaM) module
that uniformly modulates video chunks. The RepCaM framework integrates extra
parallel-cascade parameters during training to accommodate multiple chunks,
subsequently eliminating these additional parameters through
re-parameterization during inference. Furthermore, to enhance RepCaM's
performance, we propose the Transparent Visual Prompt (TVP), which includes a
minimal set of zero-initialized image-level parameters (e.g., less than 0.1%)
to capture fine details within video chunks. We conduct extensive experiments
on the VSD4K dataset, encompassing six different video scenes, and achieve
state-of-the-art results in video restoration quality and delivery bandwidth
compression.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [201] [Enhancing Time Awareness in Generative Recommendation](https://arxiv.org/abs/2509.13957)
*Sunkyung Lee,Seongmin Park,Jonghyo Kim,Mincheol Yoon,Jongwuk Lee*

Main category: cs.IR

TL;DR: 现有生成式推荐模型忽略时间动态。本文提出GRUT模型，通过时间感知提示和趋势感知推理捕捉用户偏好的演化，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐研究主要关注物品的序列顺序，而忽略了物品间的时间动态，这可能蕴含用户不断演变的偏好。

Method: 本文提出了GRUT模型。它引入了“时间感知提示”（Time-aware Prompting），包含建模个性化时间模式的用户级时间上下文和提供跨用户转换模式的物品级转换上下文。此外，还设计了“趋势感知推理”（Trend-aware Inference），一个结合物品趋势信息和生成似然来增强排名的无训练方法。

Result: GRUT在四个基准数据集上，相较于最先进模型，Recall@5和NDCG@5的性能分别提升高达15.4%和14.3%。

Conclusion: GRUT通过有效捕捉各种时间信号来解决生成式推荐中时间动态被忽视的问题，并显著提升了推荐效果。

Abstract: Generative recommendation has emerged as a promising paradigm that formulates
the recommendations into a text-to-text generation task, harnessing the vast
knowledge of large language models. However, existing studies focus on
considering the sequential order of items and neglect to handle the temporal
dynamics across items, which can imply evolving user preferences. To address
this limitation, we propose a novel model, Generative Recommender Using Time
awareness (GRUT), effectively capturing hidden user preferences via various
temporal signals. We first introduce Time-aware Prompting, consisting of two
key contexts. The user-level temporal context models personalized temporal
patterns across timestamps and time intervals, while the item-level transition
context provides transition patterns across users. We also devise Trend-aware
Inference, a training-free method that enhances rankings by incorporating trend
information about items with generation likelihood. Extensive experiments
demonstrate that GRUT outperforms state-of-the-art models, with gains of up to
15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The
source code is available at https://github.com/skleee/GRUT.

</details>


### [202] [GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing](https://arxiv.org/abs/2509.14221)
*Silan Hu,Shiqi Zhang,Yimin Shi,Xiaokui Xiao*

Main category: cs.IR

TL;DR: 本文提出了GEM-Bench，首个针对生成式引擎营销（GEM）中广告注入响应生成的综合基准。该基准包含数据集、度量本体和基线解决方案，初步结果揭示了广告参与度与用户满意度之间的权衡，并强调了未来研究的需求。


<details>
  <summary>Details</summary>
Motivation: 生成式引擎营销（GEM）中的广告注入响应生成和评估缺乏专门设计的现有基准，这限制了该新兴领域的研究进展。

Method: 本文提出了GEM-Bench，一个全面的广告注入响应生成基准。GEM-Bench包括：1. 三个精选数据集，涵盖聊天机器人和搜索场景；2. 一个捕捉用户满意度和参与度多维度指标的度量本体；3. 在可扩展多智能体框架下实现的多个基线解决方案。

Result: 初步结果显示：1. 简单的基于提示的方法能实现合理的广告参与度（如点击率），但常会降低用户满意度；2. 基于预生成无广告响应的广告插入方法有助于缓解满意度问题，但会引入额外开销。

Conclusion: 研究结果表明，未来需要设计更有效和高效的解决方案，以在GEM中生成广告注入响应，从而解决当前方法在用户满意度、参与度和效率之间存在的权衡问题。

Abstract: Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing
generative engines, such as LLM-based chatbots, by seamlessly integrating
relevant advertisements into their responses. At the core of GEM lies the
generation and evaluation of ad-injected responses. However, existing
benchmarks are not specifically designed for this purpose, which limits future
research. To address this gap, we propose GEM-Bench, the first comprehensive
benchmark for ad-injected response generation in GEM. GEM-Bench includes three
curated datasets covering both chatbot and search scenarios, a metric ontology
that captures multiple dimensions of user satisfaction and engagement, and
several baseline solutions implemented within an extensible multi-agent
framework. Our preliminary results indicate that, while simple prompt-based
methods achieve reasonable engagement such as click-through rate, they often
reduce user satisfaction. In contrast, approaches that insert ads based on
pre-generated ad-free responses help mitigate this issue but introduce
additional overhead. These findings highlight the need for future research on
designing more effective and efficient solutions for generating ad-injected
responses in GEM.

</details>


### [203] [Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation](https://arxiv.org/abs/2509.13603)
*Yongye Su,Zeya Zhang,Jane Kou,Cheng Ju,Shubhojeet Sarkar,Yamin Wang,Ji Liu,Shengbo Guo*

Main category: cs.IR

TL;DR: 本文提出一个结合关键词和嵌入式检索的Facebook群组搜索框架，以提高搜索结果的相关性和多样性，并通过线上指标和基于LLM的评估方法验证了其显著的用户参与度和搜索质量提升。


<details>
  <summary>Details</summary>
Motivation: 在社交网络搜索中，为用户提供相关信息和潜在连接至关重要。传统的关键词检索在Facebook群组搜索中可能不足以提供足够的相关性和多样性，需要改进。

Method: 引入了一个现代化的Facebook群组范围搜索框架，融合了传统的关键词检索和基于嵌入的检索（EBR）。将语义检索整合到现有关键词搜索管道中。为评估该混合方法的影响，开发了一个利用大型语言模型（LLMs）进行离线相关性评估的新型评估框架。

Result: 混合检索系统显著提高了用户参与度和搜索质量。这一结果通过在线指标和基于LLM的评估都得到了验证。

Conclusion: 这项工作为在大型、真实的社交平台中部署和评估高级检索系统提供了实用的见解。

Abstract: Beyond general web-scale search, social network search uniquely enables users
to retrieve information and discover potential connections within their social
context. We introduce a framework of modernized Facebook Group Scoped Search by
blending traditional keyword-based retrieval with embedding-based retrieval
(EBR) to improve the search relevance and diversity of search results. Our
system integrates semantic retrieval into the existing keyword search pipeline,
enabling users to discover more contextually relevant group posts. To
rigorously assess the impact of this blended approach, we introduce a novel
evaluation framework that leverages large language models (LLMs) to perform
offline relevance assessments, providing scalable and consistent quality
benchmarks. Our results demonstrate that the blended retrieval system
significantly enhances user engagement and search quality, as validated by both
online metrics and LLM-based evaluation. This work offers practical insights
for deploying and evaluating advanced retrieval systems in large-scale,
real-world social platforms.

</details>


### [204] [Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval](https://arxiv.org/abs/2509.13626)
*Amanda Chan,James Jiayu Liu,He Kai,Onno P. Kampman*

Main category: cs.IR

TL;DR: 通过智能识别知识缺口并进行有针对性的语料库扩充，可以高效构建高质量、可信赖的心理健康信息系统。


<details>
  <summary>Details</summary>
Motivation: 获取可靠的心理健康信息对于早期求助至关重要，但现有知识库扩展耗费资源且常与用户需求不符，导致信息检索系统在面对非正式或情境化表达时表现不佳。

Method: 提出了一种基于AI的缺口感知框架，该框架通过叠加如论坛帖子等自然用户数据来识别未充分代表的主题（缺口），从而优先进行语料库扩充。通过案例研究，比较了“定向扩充”（缺口感知）与“非定向扩充”（随机添加）在四种检索增强生成（RAG）管道中的信息检索相关性和有用性。

Result: 定向扩充以适度的数据增长（42%至318%）达到了近乎最优的性能（接近详尽参考语料库性能的95%）。相比之下，非定向扩充需要大幅且不切实际的扩展（232%至763%）才能达到可比的性能。

Conclusion: 策略性地定向语料库增长可以减少内容创建需求，同时维持高质量的检索和信息提供，为构建可信赖的健康信息库和支持高风险领域的生成式AI应用提供了可扩展的方法。

Abstract: Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [205] [A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching](https://arxiv.org/abs/2509.14041)
*Henry Kao,Nikhil Sreekumar,Prabhdeep Singh Soni,Ali Sedaghati,Fang Su,Bryan Chan,Maziar Goudarzi,Reza Azimi*

Main category: cs.AR

TL;DR: TRRIP是一种软硬件协同设计，利用代码“温度”信息优化移动CPU指令缓存替换策略，以减少缓存未命中并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代移动CPU软件行为复杂，导致指令重用距离高，传统指令缓存替换策略失效。移动代码常面临CPU前端停顿和资源饥饿。应用复杂性和代码足迹增长快于片上内存，使传统硬件方法不足。

Method: 提出TRRIP（Temperature-based Re-Reference Interval Prediction）软硬件协同设计。编译器分析、分类并转换代码（热/冷），通过OS接口将代码温度信息提供给硬件。轻量级硬件扩展利用代码温度属性优化指令缓存替换策略，减少热代码逐出。

Result: TRRIP可将指令的L2 MPKI降低26.5%，在PGO优化的RRIP缓存替换移动代码基础上，平均速度提升3.9%。

Conclusion: TRRIP是一种实用且易于采纳的移动系统软硬件协同设计，通过代码温度信息有效优化指令缓存替换，显著提升性能。

Abstract: Modern mobile CPU software pose challenges for conventional instruction cache
replacement policies due to their complex runtime behavior causing high reuse
distance between executions of the same instruction. Mobile code commonly
suffers from large amounts of stalls in the CPU frontend and thus starvation of
the rest of the CPU resources. Complexity of these applications and their code
footprint are projected to grow at a rate faster than available on-chip memory
due to power and area constraints, making conventional hardware-centric methods
for managing instruction caches to be inadequate. We present a novel
software-hardware co-design approach called TRRIP (Temperature-based
Re-Reference Interval Prediction) that enables the compiler to analyze,
classify, and transform code based on "temperature" (hot/cold), and to provide
the hardware with a summary of code temperature information through a
well-defined OS interface based on using code page attributes. TRRIP's
lightweight hardware extension employs code temperature attributes to optimize
the instruction cache replacement policy resulting in the eviction rate
reduction of hot code. TRRIP is designed to be practical and adoptable in real
mobile systems that have strict feature requirements on both the software and
hardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%
resulting in geomean speedup of 3.9%, on top of RRIP cache replacement running
mobile code already optimized using PGO.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [206] [When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training](https://arxiv.org/abs/2509.14132)
*Julia S. Dollis,Iago A. Brito,Fernanda B. Färber,Pedro S. F. B. Ribeiro,Rafael T. Sousa,Arlindo R. Galvão Filho*

Main category: cs.HC

TL;DR: 本文提出一个将大语言模型（LLMs）集成到VR中的框架，用于创建具有心理学真实性的虚拟患者，以提升医疗沟通技能培训，并揭示了关键设计原则。


<details>
  <summary>Details</summary>
Motivation: 现有VR在模拟物理环境方面表现出色，但在培训复杂人际技能时，因缺乏心理学上可信的虚拟人物而效果有限，尤其在医疗教育等高风险领域，这是一个关键的空白。

Method: 引入一个框架，将LLMs集成到沉浸式VR中，以创建具有独特、一致个性的医学虚拟患者。该框架采用模块化架构，将个性特征与临床数据解耦。研究通过一项混合方法、受试者内研究评估了该系统，让执业医师参与模拟会诊。

Result: 该方法不仅可行，还被医师认为是极具价值和有效的培训增强。研究还揭示了关键设计原则，包括“真实性-冗余悖论”（即较少言语的智能体可能显得更不真实），以及挑战需被感知为真实才能具有指导意义。

Conclusion: 本工作提供了一个经验证的框架和关键见解，用于开发下一代社交智能VR培训环境。

Abstract: While virtual reality (VR) excels at simulating physical environments, its
effectiveness for training complex interpersonal skills is limited by a lack of
psychologically plausible virtual humans. This is a critical gap in high-stakes
domains like medical education, where communication is a core competency. This
paper introduces a framework that integrates large language models (LLMs) into
immersive VR to create medically coherent virtual patients with distinct,
consistent personalities, built on a modular architecture that decouples
personality from clinical data. We evaluated our system in a mixed-method,
within-subjects study with licensed physicians who engaged in simulated
consultations. Results demonstrate that the approach is not only feasible but
is also perceived by physicians as a highly rewarding and effective training
enhancement. Furthermore, our analysis uncovers critical design principles,
including a ``realism-verbosity paradox" where less communicative agents can
seem more artificial, and the need for challenges to be perceived as authentic
to be instructive. This work provides a validated framework and key insights
for developing the next generation of socially intelligent VR training
environments.

</details>


### [207] [LLM Chatbot-Creation Approaches](https://arxiv.org/abs/2509.13326)
*Hemil Mehta,Tanvi Raut,Kohav Yadav,Edward F. Gehringer*

Main category: cs.HC

TL;DR: 该研究比较了低代码平台和自定义代码解决方案在教育领域开发课程聊天机器人方面的优缺点，并提出了一个选择开发策略的框架。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在教学中日益普及，如何选择最佳的聊天机器人开发策略（兼顾易用性、定制性、数据隐私和可扩展性）成为挑战。

Method: 研究对比了使用AnythingLLM和Botpress等低代码平台，与使用LangChain、FAISS和FastAPI等自定义代码解决方案。评估通过Prompt工程、RAG和个性化技术，衡量了聊天机器人在技术性能、可扩展性和用户体验方面的表现。

Result: 低代码平台实现快速原型开发，但在定制和扩展性上受限；自定义代码系统提供更多控制，但需要较高的技术专长。两种方法都能成功实现自适应反馈循环和会话连贯性。

Conclusion: 本研究提供了一个基于机构目标和资源的开发策略选择框架。未来工作将探索结合低代码易用性和模块化定制的混合方案，并整合多模态输入。

Abstract: This full research-to-practice paper explores approaches for developing
course chatbots by comparing low-code platforms and custom-coded solutions in
educational contexts. With the rise of Large Language Models (LLMs) like GPT-4
and LLaMA, LLM-based chatbots are being integrated into teaching workflows to
automate tasks, provide assistance, and offer scalable support. However,
selecting the optimal development strategy requires balancing ease of use,
customization, data privacy, and scalability. This study compares two
development approaches: low-code platforms like AnythingLLM and Botpress, with
custom-coded solutions using LangChain, FAISS, and FastAPI. The research uses
Prompt engineering, Retrieval-augmented generation (RAG), and personalization
to evaluate chatbot prototypes across technical performance, scalability, and
user experience. Findings indicate that while low-code platforms enable rapid
prototyping, they face limitations in customization and scaling, while
custom-coded systems offer more control but require significant technical
expertise. Both approaches successfully implement key research principles such
as adaptive feedback loops and conversational continuity. The study provides a
framework for selecting the appropriate development strategy based on
institutional goals and resources. Future work will focus on hybrid solutions
that combine low-code accessibility with modular customization and incorporate
multimodal input for intelligent tutoring systems.

</details>


<div id='q-fin.PR'></div>

# q-fin.PR [[Back]](#toc)

### [208] [Valuation of Exotic Options and Counterparty Games Based on Conditional Diffusion](https://arxiv.org/abs/2509.13374)
*Helin Zhao,Junchi Shen*

Main category: q-fin.PR

TL;DR: 本文提出了一种扩散-条件概率模型（DDPM）以改进奇异期权定价，该模型对部分期权显示出更高的盈利能力，但在处理极端事件敏感产品时因低估尾部风险而存在局限性。


<details>
  <summary>Details</summary>
Motivation: 传统模型因无法捕捉现实市场现象（如肥尾分布和波动性聚类），在奇异期权和结构性产品定价方面面临挑战。

Method: 引入了扩散-条件概率模型（DDPM）以生成更真实的股价路径；结合了包含金融特定特征的复合损失函数；并提出了P-Q动态博弈框架进行对抗性回测以评估模型经济价值。

Result: 静态验证显示P模型能有效匹配市场均值和波动率。在动态博弈中，对于欧式和亚式期权，该模型比传统蒙特卡洛模型表现出显著更高的盈利能力。然而，在定价对极端事件高度敏感的产品（如雪球、累积器）时，由于低估了尾部风险，模型显示出局限性。

Conclusion: 扩散模型在提高定价准确性方面具有巨大潜力，但需要进一步研究以改善其对极端市场风险的建模能力。

Abstract: This paper addresses the challenges of pricing exotic options and structured
products, which traditional models often fail to handle due to their inability
to capture real-world market phenomena like fat-tailed distributions and
volatility clustering. We introduce a Diffusion-Conditional Probability Model
(DDPM) to generate more realistic price paths. Our method incorporates a
composite loss function with financial-specific features, and we propose a P-Q
dynamic game framework for evaluating the model's economic value through
adversarial backtesting. Static validation shows our P-model effectively
matches market mean and volatility. In dynamic games, it demonstrates
significantly higher profitability than a traditional Monte Carlo-based model
for European and Asian options. However, the model shows limitations in pricing
products highly sensitive to extreme events, such as snowballs and
accumulators, because it tends to underestimate tail risks. The study concludes
that diffusion models hold significant potential for enhancing pricing
accuracy, though further research is needed to improve their ability to model
extreme market risks.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [209] [Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis](https://arxiv.org/abs/2408.00208)
*SaeedReza Motamedian,Sadra Mohaghegh,Elham Babadi Oregani,Mahrsa Amjadi,Parnian Shobeiri,Negin Cheraghi,Niusha Solouki,Nikoo Ahmadi,Hossein Mohammad-Rahimi,Yassine Bouchareb,Arman Rahmim*

Main category: physics.med-ph

TL;DR: 该研究系统回顾了AI在COVID-19预后预测中的应用，发现AI模型基于影像学特征能有效辅助临床管理，结合多模态数据可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 识别、评估并综合现有关于人工智能（AI）在COVID-19预后预测中应用的研究。

Method: 通过Medline、Google Scholar、Scopus、Embase、Cochrane和ProQuest等电子数据库进行文献检索。纳入使用机器学习或深度学习方法，基于CT或胸部X光图像预测COVID-19预后的研究。计算汇总的敏感性、特异性、曲线下面积和诊断优势比。

Result: 共纳入36篇文章，涉及疾病严重程度、机械通气、ICU入院和死亡率等预后问题。研究采用了多种AI模型，如Siamense模型、支持向量机、随机森林和卷积神经网络。模型在死亡率预测上的敏感性、特异性分别为71%和69%；在严重程度评估上为88%和89%；在通气需求预测上为67%和89%。

Conclusion: 基于CT或CXR图像放射组学特征的机器学习和深度学习方法能有效帮助临床医生管理COVID-19患者和更有效地分配资源。结合患者人口统计学、临床数据、实验室检查和放射组学特征可进一步提升模型性能。

Abstract: Purpose: Artificial intelligence (AI) techniques have been extensively
utilized for diagnosing and prognosis of several diseases in recent years. This
study identifies, appraises and synthesizes published studies on the use of AI
for the prognosis of COVID-19. Method: Electronic search was performed using
Medline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that
examined machine learning or deep learning methods to determine the prognosis
of COVID-19 using CT or chest X-ray images were included. Polled sensitivity,
specificity area under the curve and diagnostic odds ratio were calculated.
Result: A total of 36 articles were included; various prognosis-related issues,
including disease severity, mechanical ventilation or admission to the
intensive care unit and mortality, were investigated. Several AI models and
architectures were employed, such as the Siamense model, support vector
machine, Random Forest , eXtreme Gradient Boosting, and convolutional neural
networks. The models achieved 71%, 88% and 67% sensitivity for mortality,
severity assessment and need for ventilation, respectively. The specificity of
69%, 89% and 89% were reported for the aforementioned variables. Conclusion:
Based on the included articles, machine learning and deep learning methods used
for the prognosis of COVID-19 patients using radiomic features from CT or CXR
images can help clinicians manage patients and allocate resources more
effectively. These studies also demonstrate that combining patient demographic,
clinical data, laboratory tests and radiomic features improves model
performances.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [210] [A Survey and Evaluation Framework for Secure DNS Resolution](https://arxiv.org/abs/2509.13797)
*Ali Sadeghi Jahromi,AbdelRahman Abdou,Paul C. van Oorschot*

Main category: cs.CR

TL;DR: 评估了12种安全DNS方案，发现无单一方案能提供全面保护，但结合兼容方案可实现端到端安全。


<details>
  <summary>Details</summary>
Motivation: 传统DNS缺乏安全性，现有安全DNS方案未能全面取代或提供完全保护，因此需要研究如何有效增强DNS解析过程的安全和隐私。

Method: 调查了DNS解析过程的攻击和威胁，开发了全面的威胁模型和攻击分类法，并据此提出了14个理想的安全、隐私和可用性属性。接着，利用这些属性开发了一个客观评估框架，并用其比较分析了12种现有的安全DNS方案。

Result: 评估显示，没有单一方案能在整个DNS解析路径上提供理想的全面保护。相反，这些方案通常只解决特定阶段的某个子集属性。

Conclusion: 由于针对DNS解析不同阶段的方案是互补的且可协同工作，因此结合兼容方案是实现DNS解析过程全面安全的实用有效途径。

Abstract: Since security was not among the original design goals of the Domain Name
System (herein called Vanilla DNS), many secure DNS schemes have been proposed
to enhance the security and privacy of the DNS resolution process. Some
proposed schemes aim to replace the existing DNS infrastructure entirely, but
none have succeeded in doing so. In parallel, numerous schemes focus on
improving DNS security without modifying its fundamental two-stage structure.
These efforts highlight the feasibility of addressing DNS security as two
distinct but compatible stages. We survey DNS resolution process attacks and
threats and develop a comprehensive threat model and attack taxonomy for their
systematic categorization. This analysis results in the formulation of 14
desirable security, privacy, and availability properties to mitigate the
identified threats. Using these properties, we develop an objective evaluation
framework and apply it to comparatively analyze 12 secure DNS schemes surveyed
in this work that aim to augment the properties of the DNS resolution process.
Our evaluation reveals that no single scheme provides ideal protection across
the entire resolution path. Instead, the schemes tend to address a subset of
properties specific to individual stages. Since these schemes targeting
different stages of DNS resolution are complementary and can operate together,
combining compatible schemes offers a practical and effective approach to
achieving comprehensive security in the DNS resolution process.

</details>


### [211] [Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents](https://arxiv.org/abs/2509.13597)
*Abhishek Goswami*

Main category: cs.CR

TL;DR: 鉴于自主LLM智能体在无监督下可能导致权限升级，本文引入A-JWT（Agentic JWT）意图令牌，通过绑定智能体行为与用户意图及智能体身份，有效防范提示注入、重放和冒充等攻击，实现智能体应用的安全。


<details>
  <summary>Details</summary>
Motivation: 自主大型语言模型（LLM）智能体在无人类监督下可执行大量API调用。现有的OAuth 2.0协议假设客户端是确定性的，但在智能体环境中，随机推理、提示注入或多智能体编排可能悄无声息地扩大权限，带来严重的安全风险。

Method: 引入Agentic JWT (A-JWT) 这一双面意图令牌，它将每个智能体的行为绑定到可验证的用户意图，并可选择绑定到特定工作流步骤。A-JWT包含：基于提示、工具和配置生成的智能体身份（单向校验和哈希）、证明下游智能体执行任务的链式委托声明，以及防止重放和进程内冒充的每智能体持有证明密钥。同时，还定义了一种新的授权机制，并增加了一个轻量级客户端垫片库，用于运行时代码自验证、意图令牌铸造、工作流跟踪和密钥派生，以实现安全的智能体身份和分离。

Result: 论文阐述了智能体应用的全面威胁模型，并实现了一个Python概念验证（PoC）。结果显示，该方案能有效阻止违反范围的请求、重放攻击、冒充行为和提示注入途径，且在普通硬件上仅产生亚毫秒级的开销。

Conclusion: A-JWT的设计与当前的OAuth智能体讨论一致，为智能体应用实现零信任安全保障提供了一条可行的即插即用路径。

Abstract: Autonomous LLM agents can issue thousands of API calls per hour without human
oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings
stochastic reasoning, prompt injection, or multi-agent orchestration can
silently expand privileges.
  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each
agent's action to verifiable user intent and, optionally, to a specific
workflow step. A-JWT carries an agent's identity as a one-way checksum hash
derived from its prompt, tools and configuration, and a chained delegation
assertion to prove which downstream agent may execute a given task, and
per-agent proof-of-possession keys to prevent replay and in-process
impersonation. We define a new authorization mechanism and add a lightweight
client shim library that self-verifies code at run time, mints intent tokens,
tracks workflow steps and derives keys, thus enabling secure agent identity and
separation even within a single process.
  We illustrate a comprehensive threat model for agentic applications,
implement a Python proof-of-concept and show functional blocking of
scope-violating requests, replay, impersonation, and prompt-injection pathways
with sub-millisecond overhead on commodity hardware. The design aligns with
ongoing OAuth agent discussions and offers a drop-in path toward zero-trust
guarantees for agentic applications. A comprehensive performance and security
evaluation with experimental results will appear in our forthcoming journal
publication

</details>


### [212] [Secure, Scalable and Privacy Aware Data Strategy in Cloud](https://arxiv.org/abs/2509.13627)
*Vijay Kumar Butte,Sujata Butte*

Main category: cs.CR

TL;DR: 本文提出并讨论了一种有效的云端企业数据策略，以应对大数据处理、存储和决策支持的挑战，并提供了关注安全、可扩展性和隐私的架构。


<details>
  <summary>Details</summary>
Motivation: 企业在安全、可扩展地处理和存储海量数据以及支持快速、知情的数据驱动决策方面面临严峻挑战。

Method: 开发并讨论了有效的云端企业数据策略的各个组件，并提供了解决安全、可扩展性和隐私问题的架构。

Result: 提出了一套有效的云端企业数据策略，并提供了解决大数据处理中安全、可扩展性和隐私问题的具体架构。

Conclusion: 所提出的云端企业数据策略及其架构能够有效帮助企业应对大数据处理、存储和决策支持的挑战。

Abstract: The enterprises today are faced with the tough challenge of processing,
storing large amounts of data in a secure, scalable manner and enabling
decision makers to make quick, informed data driven decisions. This paper
addresses this challenge and develops an effective enterprise data strategy in
the cloud. Various components of an effective data strategy are discussed and
architectures addressing security, scalability and privacy aspects are
provided.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [213] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

TL;DR: 本文改进了一种基于深度神经网络的机器人位姿估计方法，通过修改损失函数提高了定位精度，并提供了一个完整的室内场景鲁棒导航算法构建流程。


<details>
  <summary>Details</summary>
Motivation: 提高现有基于视觉信息的深度神经网络机器人位姿估计方法的定位性能，增加对感知混淆的鲁棒性，并构建一个适用于任意室内场景的鲁棒导航算法。

Method: 修改了现有深度神经网络的损失函数，以直观结合位置和旋转误差来增强鲁棒性。利用摄影测量数据生成带位姿标签的数据集，用于在本地环境训练模型。将训练后的模型作为导航算法在TurtleBot上进行实时测试。

Result: 室内场景定位精度提高，中位位置误差降低高达9.64%，中位旋转误差降低高达2.99%。在本地环境训练后，定位精度达到0.11米和0.89度。在TurtleBot上实时测试成功。

Conclusion: 开发了一种改进的深度学习方法，显著提高了机器人位姿估计的鲁棒性。提出了一个完整的管道，仅需场景图像即可为任何室内场景创建鲁棒的导航算法。

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


### [214] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

TL;DR: Point-JEPA自监督预训练在低标签条件下显著提高了3D抓取关节角度预测的数据效率，性能甚至能媲美全监督方法。


<details>
  <summary>Details</summary>
Motivation: 研究3D自监督预训练（Point-JEPA）能否实现标签高效的抓取关节角度预测。

Method: 利用来自网格的点云和经ShapeNet预训练的Point-JEPA编码器，训练一个轻量级多假设头部网络，并采用“赢者通吃”策略和最高logit选择进行评估。

Result: 在DLR-Hand II数据集的低标签情境下，Point-JEPA将RMSE降低了高达26%，并能与全监督方法的性能持平。

Conclusion: JEPA风格的预训练是实现数据高效抓取学习的实用方法。

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [215] [ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy](https://arxiv.org/abs/2509.13380)
*Alejandro D. Mousist*

Main category: cs.RO

TL;DR: 本文介绍了ASTREA，首个部署在飞行合格硬件（TRL 9）上的自主航天器智能体系统，将受限LLM与强化学习控制器结合应用于热控制。地面试验证实其可行性，但轨验证发现LLM推理延迟与LEO快速热循环不匹配导致性能下降，揭示了LLM智能体系统在真实飞行环境中的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 探索并实现自主航天器操作，尤其是在空间合格硬件上部署智能体系统（如大语言模型），以解决如热控制等复杂任务，并评估其在真实空间环境中的表现。

Method: 本文提出了ASTREA系统，将一个资源受限的大语言模型（LLM）智能体与一个强化学习（RL）控制器集成在异步架构中。该系统专为空间合格平台（TRL 9）设计，并以热控制作为代表性用例进行部署和测试。

Result: 地面试验表明，LLM引导的监督能提高热稳定性并减少违规，证实了在硬件约束下结合语义推理与自适应控制的可行性。然而，国际空间站（ISS）上的在轨验证显示，由于LLM推理延迟与低地球轨道（LEO）卫星快速热循环不匹配，导致系统性能下降。

Conclusion: 代理式LLM系统在真实飞行环境中既带来了机遇，也暴露了其当前的局限性。研究结果为未来空间自主系统的设计提供了实用的指导方针。

Abstract: This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.

</details>


### [216] [Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation](https://arxiv.org/abs/2509.13574)
*Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian*

Main category: cs.RO

TL;DR: 流匹配在机器人策略学习中存在泛化性早饱和及推理步数增加反常降低性能的问题。本文提出非均匀时间调度训练和密集跳跃推理集成策略，有效提升性能达23.7%。


<details>
  <summary>Details</summary>
Motivation: 流匹配在机器人领域有竞争力，但存在两个问题：1) 泛化性在流轨迹早期饱和。2) 增加欧拉积分步数反常地降低策略性能。原因在于过采样后期区域限制泛化性和学习到的速度场在积分时间接近1时变得非Lipschitz导致不稳定。

Method: 为解决上述问题，提出一种新颖策略：1) 训练时采用非均匀时间调度（如U形），强调早期和晚期时间阶段以正则化策略训练。2) 推理时采用密集跳跃积分调度，在跳跃点之后使用单步积分替代多步积分，以避免接近1的不稳定区域。本质上是一种高效的单步学习器，通过多步积分推进性能。

Result: 该策略在多种机器人任务中，比现有最先进基线提升高达23.7%的性能。

Conclusion: 通过引入非均匀时间调度训练和密集跳跃推理集成，可以有效解决流匹配在机器人策略学习中的泛化和稳定性问题，显著提升性能。

Abstract: Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.

</details>


### [217] [TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning](https://arxiv.org/abs/2509.13579)
*Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu*

Main category: cs.RO

TL;DR: 提出TreeIRL，一种结合蒙特卡洛树搜索（MCTS）和逆向强化学习（IRL）的自动驾驶规划器，在模拟和实际驾驶中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶规划面临性能瓶颈，需要一种能在安全性、效率、舒适度和拟人化之间取得平衡的先进规划方法。

Method: TreeIRL结合MCTS生成安全候选轨迹，并使用深度IRL评分函数选择最拟人化的轨迹。在大型模拟和拉斯维加斯都会区超过500英里的实际驾驶中进行评估，测试场景包括密集城市交通、自适应巡航、切入和红绿灯，并与经典及最先进的规划器进行比较。

Result: TreeIRL取得了最佳的总体性能，在安全性、进程、舒适度和拟人化之间达到了平衡。这是首次在公共道路上展示基于MCTS的自动驾驶规划。

Conclusion: 本研究首次在公共道路上成功展示了基于MCTS的规划器，强调了在真实世界环境中采用多样化指标评估规划器的重要性。TreeIRL具有高度可扩展性，可通过强化学习和模仿学习进一步改进，为解决自动驾驶规划瓶颈提供了经典与学习方法结合的框架。

Abstract: We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.

</details>


### [218] [Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning](https://arxiv.org/abs/2509.13336)
*Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（RL）的无人机路径规划方法，用于优化超视距（BVLoS）蜂窝连接无人机的行程距离并最大化蜂窝链路连接质量。


<details>
  <summary>Details</summary>
Motivation: 在无人机超视距（BVLoS）操作中，需要解决无人机蜂窝通信的限制，同时最小化飞行距离并最大化蜂窝链路连接质量，并考虑真实的空中覆盖约束。

Method: 该方法采用强化学习技术，将无人机与基站（BS）之间的通信链路质量作为奖励函数来训练代理，并使用经验性空中信道模型。

Result: 仿真结果表明，该方法能有效训练代理并生成可行的无人机路径规划，高效识别最佳路径以确保与地面基站的最大连接。该方案可作为离线路径规划模块部署。

Conclusion: 该强化学习方法解决了无人机蜂窝通信的挑战，实现了安全可靠的超视距飞行，并为复杂的长距离无人机应用提供了潜力。

Abstract: This paper presents a reinforcement learning (RL) based approach for path
planning of cellular connected unmanned aerial vehicles (UAVs) operating beyond
visual line of sight (BVLoS). The objective is to minimize travel distance
while maximizing the quality of cellular link connectivity by considering real
world aerial coverage constraints and employing an empirical aerial channel
model. The proposed solution employs RL techniques to train an agent, using the
quality of communication links between the UAV and base stations (BSs) as the
reward function. Simulation results demonstrate the effectiveness of the
proposed method in training the agent and generating feasible UAV path plans.
The proposed approach addresses the challenges due to limitations in UAV
cellular communications, highlighting the need for investigations and
considerations in this area. The RL algorithm efficiently identifies optimal
paths, ensuring maximum connectivity with ground BSs to ensure safe and
reliable BVLoS flight operation. Moreover, the solution can be deployed as an
offline path planning module that can be integrated into future ground control
systems (GCS) for UAV operations, enhancing their capabilities and safety. The
method holds potential for complex long range UAV applications, advancing the
technology in the field of cellular connected UAV path planning.

</details>


### [219] [DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](https://arxiv.org/abs/2509.13666)
*Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin*

Main category: cs.RO

TL;DR: 本文提出了DREAM，一个由视觉语言模型（VLM）引导的水下自主框架，用于长期水下探索和栖息地监测，在效率、覆盖率和路径优化方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 海洋变暖和酸化增加了牡蛎等敏感贝类大规模死亡的风险，因此需要长期监测系统。然而，人工水下作业成本高昂且危险，促使人们寻求更安全、高效的机器人解决方案。为使水下机器人无需人工干预即可做出实时、环境感知的决策，需要为其配备智能“大脑”，以实现持久、大范围、低成本的底栖生物监测。

Method: 本文提出了DREAM框架，这是一个由视觉语言模型（VLM）引导的自主系统，专为水下机器人的长期探索和栖息地监测而设计。

Result: DREAM框架在没有先验位置信息的情况下，能高效发现和探索目标物体（如牡蛎、沉船）。在牡蛎监测任务中，与现有基线相比，完成相同数量牡蛎的监测时间减少了31.5%；与普通VLM相比，步骤减少23%，牡蛎覆盖率增加了8.88%。在沉船场景中，该框架成功实现无碰撞探索和绘制沉船地图，所需步骤比普通模型减少27.5%，并达到了100%的覆盖率，而普通模型平均覆盖率为60.23%。

Conclusion: DREAM框架能够有效、高效地赋能水下机器人进行目标物体的自主探索和环境监测，显著提升了任务效率、探索覆盖率和路径优化，优于现有基线和普通VLM模型。

Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [220] [An Empirical Study on Failures in Automated Issue Solving](https://arxiv.org/abs/2509.13941)
*Simiao Liu,Fang Liu,Liehao Li,Xin Tan,Yinghao Zhu,Xiaoli Lian,Li Zhang*

Main category: cs.SE

TL;DR: 本文分析了SWE-Bench上自动化问题解决工具的性能和故障模式，发现代理（agentic）工具主要因推理缺陷和认知僵局失败。为此，作者提出了一个专家-执行者（Expert-Executor）协作框架，显著提高了解决率。


<details>
  <summary>Details</summary>
Motivation: 自动化问题解决工具（特别是基于LLM的代理工具）在SWE-Bench上仍有大量任务失败。现有评估仅报告总体解决率，无法诊断模型弱点。需要深入理解失败的根本原因，尤其代理工具常受推理缺陷和认知僵局困扰，以指导针对性改进。

Method: 首先，分析了三种SOTA工具（包括基于管道和代理架构）在SWE-Bench-Verified上的性能和效率。其次，对150个失败案例进行了系统性手动分析，开发了一个包含3个阶段、9个主要类别和25个细粒度子类别的故障模式分类法。然后，分析了识别出的故障模式分布，揭示了不同架构范式之间的独特故障特征。最后，提出了一个协作式的专家-执行者框架，由一个监督性专家代理为主要执行者代理提供战略性监督和纠错。

Result: 研究揭示了不同架构范式之间独特的故障特征，其中大多数代理故障源于推理缺陷和认知僵局。实验表明，所提出的专家-执行者框架能解决领先单一代理此前无法解决的22.2%的问题。

Conclusion: 这些发现通过诊断性评估和协作式设计，为构建更鲁棒的代理铺平了道路，特别是通过专家-执行者框架有效纠正了推理缺陷和打破了认知僵局。

Abstract: Automated issue solving seeks to autonomously identify and repair defective
code snippets across an entire codebase. SWE-Bench has emerged as the most
widely adopted benchmark for evaluating progress in this area. While LLM-based
agentic tools show great promise, they still fail on a substantial portion of
tasks. Moreover, current evaluations primarily report aggregate issue-solving
rates, which obscure the underlying causes of success and failure, making it
challenging to diagnose model weaknesses or guide targeted improvements. To
bridge this gap, we first analyze the performance and efficiency of three SOTA
tools, spanning both pipeline-based and agentic architectures, in automated
issue solving tasks of SWE-Bench-Verified under varying task characteristics.
Furthermore, to move from high-level performance metrics to underlying cause
analysis, we conducted a systematic manual analysis of 150 failed instances.
From this analysis, we developed a comprehensive taxonomy of failure modes
comprising 3 primary phases, 9 main categories, and 25 fine-grained
subcategories. Then we systematically analyze the distribution of the
identified failure modes, the results reveal distinct failure fingerprints
between the two architectural paradigms, with the majority of agentic failures
stemming from flawed reasoning and cognitive deadlocks. Motivated by these
insights, we propose a collaborative Expert-Executor framework. It introduces a
supervisory Expert agent tasked with providing strategic oversight and
course-correction for a primary Executor agent. This architecture is designed
to correct flawed reasoning and break the cognitive deadlocks that frequently
lead to failure. Experiments show that our framework solves 22.2% of previously
intractable issues for a leading single agent. These findings pave the way for
building more robust agents through diagnostic evaluation and collaborative
design.

</details>


### [221] [An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software](https://arxiv.org/abs/2509.13471)
*Sina Gogani-Khiabani,Ashutosh Trivedi,Diptikalyan Saha,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 本文提出一种基于LLM驱动的多智能体变异测试方法，旨在提高自然语言法规转化为可执行法律关键软件的可靠性。在税务代码案例中，发现小模型(GPT-4o-mini)性能优于大型前沿模型，证明了该方法构建可信赖法律软件的潜力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)在将自然语言法规转化为可执行逻辑方面前景广阔，但由于歧义和幻觉，在法律关键场景中其可靠性仍面临挑战。主要的挑战在于预言者问题下的测试用例生成，因为正确输出需要准确地解释法律。

Method: 提出一种用于开发法律关键软件的智能体（agentic）方法，并以美国联邦税收准备为例。该方法基于变异测试，引入了高阶变异关系来比较相似个体结构化转变下的系统输出。为自动化测试生成和代码合成，采用了一个LLM驱动、基于角色的框架。实现了一个多智能体系统，负责将税法转换为可执行软件，并整合了一个搜索反例的变异测试智能体。

Result: 实验结果显示，使用较小模型（GPT-4o-mini）的框架在复杂税法任务上的最差通过率为45%，显著优于前沿模型（GPT-4o和Claude 3.5，通过率为9-15%）。

Conclusion: 研究结果支持智能体LLM方法学作为从自然语言规范构建稳健、可信赖的法律关键软件的可行途径。

Abstract: Large language models (LLMs) show promise for translating natural-language
statutes into executable logic, but reliability in legally critical settings
remains challenging due to ambiguity and hallucinations. We present an agentic
approach for developing legal-critical software, using U.S. federal tax
preparation as a case study. The key challenge is test-case generation under
the oracle problem, where correct outputs require interpreting law. Building on
metamorphic testing, we introduce higher-order metamorphic relations that
compare system outputs across structured shifts among similar individuals.
Because authoring such relations is tedious and error-prone, we use an
LLM-driven, role-based framework to automate test generation and code
synthesis. We implement a multi-agent system that translates tax code into
executable software and incorporates a metamorphic-testing agent that searches
for counterexamples. In experiments, our framework using a smaller model
(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier
models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results
support agentic LLM methodologies as a path to robust, trustworthy
legal-critical software from natural-language specifications.

</details>


### [222] [Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation](https://arxiv.org/abs/2509.13487)
*Abubakari Alidu,Michele Ciavotta,Flavio DePaoli*

Main category: cs.SE

TL;DR: Prompt2DAG是一种将自然语言描述转换为Apache Airflow DAG的方法。通过对四种生成方法的广泛评估，发现混合方法在可靠性、代码质量和可执行性方面表现最佳，并显著优于LLM-only和Direct方法。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的数据丰富管道需要大量的工程专业知识，这促使研究如何自动化该过程。

Method: 研究提出了Prompt2DAG方法，旨在将自然语言描述转化为可执行的Apache Airflow DAG。评估了四种生成方法（Direct、LLM-only、Hybrid、Template-based），通过260次实验，使用了十三种LLM和五个案例研究。性能通过结合可靠性、代码质量（SAT）、结构完整性（DST）和可执行性（PCT）的惩罚评分框架进行衡量。

Result: 混合(Hybrid)方法表现最佳，成功率达78.5%，并具有稳健的质量得分（SAT: 6.79, DST: 7.67, PCT: 7.76），显著优于LLM-only（66.2%成功率）和Direct（29.2%成功率）方法。研究发现可靠性而非内在代码质量是主要区分因素。成本效益分析显示，混合方法在生成成功DAG方面的效率是直接提示的两倍以上。

Conclusion: 结构化的混合方法对于平衡自动化工作流生成中的灵活性和可靠性至关重要，为数据管道开发的民主化提供了一条可行途径。

Abstract: Developing reliable data enrichment pipelines demands significant engineering
expertise. We present Prompt2DAG, a methodology that transforms natural
language descriptions into executable Apache Airflow DAGs. We evaluate four
generation approaches -- Direct, LLM-only, Hybrid, and Template-based -- across
260 experiments using thirteen LLMs and five case studies to identify optimal
strategies for production-grade automation. Performance is measured using a
penalized scoring framework that combines reliability with code quality (SAT),
structural integrity (DST), and executability (PCT). The Hybrid approach
emerges as the optimal generative method, achieving a 78.5% success rate with
robust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly
outperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.
Our findings show that reliability, not intrinsic code quality, is the primary
differentiator. Cost-effectiveness analysis reveals the Hybrid method is over
twice as efficient as Direct prompting per successful DAG. We conclude that a
structured, hybrid approach is essential for balancing flexibility and
reliability in automated workflow generation, offering a viable path to
democratize data pipeline development.

</details>


### [223] [Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework](https://arxiv.org/abs/2509.14093)
*Kerui Huang,Shuhan Liu,Xing Hu,Tongtong Xu,Lingfeng Bao,Xin Xia*

Main category: cs.SE

TL;DR: 链式思考（CoT）虽能增强大型语言模型（LLMs），但会带来高昂的计算成本。本研究发现过长的CoT并非总有益，甚至会导致截断、准确性下降和延迟增加。为此，提出SEER框架，通过自适应压缩CoT，平均缩短42.1%，提高准确性并消除大部分死循环，使LLM在资源受限下更高效、更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 链式思考（CoT）虽能提升LLM性能，但其高计算成本（延迟、内存、KV-cache）在软件工程等领域尤为关键。经验研究表明，过长的CoT常导致截断、准确率下降和高延迟，这挑战了“推理越长越好”的假设，凸显了自适应CoT控制的必要性。

Method: 进行了一项基于代码生成基准的实证研究以分析CoT的权衡。提出并评估了SEER（Self-Enhancing Efficient Reasoning）自适应框架。SEER结合了Best-of-N采样和任务感知的自适应过滤，根据预推理输出动态调整阈值，以减少冗余和计算开销。

Result: 实证研究显示，过长的CoT会造成截断、准确性下降，延迟最高增加五倍，且失败输出通常更长。SEER在三个软件工程任务和一个数学任务上，平均将CoT缩短42.1%，通过减少截断提高了准确性，并消除了大部分无限循环。

Conclusion: SEER是一个实用的方法，能使链式思考增强的LLMs在资源受限下变得更加高效和鲁棒。

Abstract: Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by
prompting intermediate steps, improving accuracy and robustness in arithmetic,
logic, and commonsense tasks. However, this benefit comes with high
computational costs: longer outputs increase latency, memory usage, and
KV-cache demands. These issues are especially critical in software engineering
tasks where concise and deterministic outputs are required. To investigate
these trade-offs, we conduct an empirical study based on code generation
benchmarks. The results reveal that longer CoT does not always help. Excessive
reasoning often causes truncation, accuracy drops, and latency up to five times
higher, with failed outputs consistently longer than successful ones. These
findings challenge the assumption that longer reasoning is inherently better
and highlight the need for adaptive CoT control. Motivated by this, we propose
SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that
compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with
task-aware adaptive filtering, dynamically adjusting thresholds based on
pre-inference outputs to reduce verbosity and computational overhead. We then
evaluate SEER on three software engineering tasks and one math task. On
average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,
and eliminates most infinite loops. These results demonstrate SEER as a
practical method to make CoT-enhanced LLMs more efficient and robust, even
under resource constraints.

</details>


### [224] [GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?](https://arxiv.org/abs/2509.13650)
*Amena Amro,Manar H. Alalfi*

Main category: cs.SE

TL;DR: 本研究评估了GitHub Copilot代码审查功能在检测安全漏洞方面的有效性，发现它在识别SQL注入、XSS等关键漏洞方面表现不佳，反而主要处理低严重性问题，表明AI辅助代码审查在支持安全开发方面存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动工具在软件开发中日益普及，确保这些工具能支持安全编码至关重要。本研究旨在评估GitHub Copilot新推出的代码审查功能在检测安全漏洞方面的效果。

Method: 研究使用了一组精心策划的、带有标签的易受攻击代码样本，这些样本来源于不同开源项目，涵盖多种编程语言和应用领域。通过系统性评估Copilot识别常见安全缺陷并提供反馈的能力来完成研究。

Result: 研究结果出乎意料：Copilot的代码审查功能频繁未能检测到SQL注入、跨站脚本（XSS）和不安全反序列化等关键漏洞。相反，其反馈主要集中在编码风格和拼写错误等低严重性问题上。

Conclusion: 研究揭示了AI辅助代码审查的感知能力与实际支持安全开发实践的有效性之间存在显著差距。结果强调了专用安全工具和人工代码审计对于确保软件稳健安全性的持续必要性。

Abstract: As software development practices increasingly adopt AI-powered tools,
ensuring that such tools can support secure coding has become critical. This
study evaluates the effectiveness of GitHub Copilot's recently introduced code
review feature in detecting security vulnerabilities. Using a curated set of
labeled vulnerable code samples drawn from diverse open-source projects
spanning multiple programming languages and application domains, we
systematically assessed Copilot's ability to identify and provide feedback on
common security flaws. Contrary to expectations, our results reveal that
Copilot's code review frequently fails to detect critical vulnerabilities such
as SQL injection, cross-site scripting (XSS), and insecure deserialization.
Instead, its feedback primarily addresses low-severity issues, such as coding
style and typographical errors. These findings expose a significant gap between
the perceived capabilities of AI-assisted code review and its actual
effectiveness in supporting secure development practices. Our results highlight
the continued necessity of dedicated security tools and manual code audits to
ensure robust software security.

</details>


### [225] [Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations](https://arxiv.org/abs/2509.13680)
*Wei Ma,Yixiao Yang,Jingquan Ge,Xiaofei Xie,Lingxiao Jiang*

Main category: cs.SE

TL;DR: 本研究评估了代码生成模型对提示词措辞的敏感性，提出了PromptSE框架来衡量稳定性，并发现模型性能与稳定性是相对独立的优化目标。


<details>
  <summary>Details</summary>
Motivation: 代码生成模型广泛使用，但其对提示词措辞敏感性（不同情感/风格导致输出差异）研究不足，现有基准多侧重于峰值性能而非稳定性。

Method: 提出PromptSE框架，通过情感和个性模板创建语义等效的提示词变体，并使用概率感知连续评分或二元通过率评估模型稳定性。结果通过AUC-E指标进行聚合和跨模型比较。

Result: 在Llama、Qwen和DeepSeek三个家族的14个模型上发现，模型性能与稳定性是 largely 解耦的优化目标，并揭示了挑战模型鲁棒性常见假设的架构和规模相关模式。

Conclusion: PromptSE框架支持闭源模型筛选和详细稳定性分析，帮助实践者量化部署和模型选择中的性能-稳定性权衡，将提示词稳定性定位为与性能、公平性并列的评估维度，从而提升AI辅助软件开发工具的可信度。

Abstract: Code generation models are widely used in software development, yet their
sensitivity to prompt phrasing remains under-examined. Identical requirements
expressed with different emotions or communication styles can yield divergent
outputs, while most benchmarks emphasize only peak performance. We present
PromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically
equivalent prompt variants with emotion and personality templates, and that
evaluates stability using probability aware continuous scoring or using binary
pass rates when logits are unavailable. The results are aggregated into a
proposed area under curve metric (AUC-E) for cross model comparison. Across 14
models from three families (Llama, Qwen, and DeepSeek), our study shows that
performance and stability behave as largely decoupled optimization objectives,
and it reveals architectural and scale related patterns that challenge common
assumptions about model robustness. The framework supports rapid screening for
closed-source models as well as detailed stability analysis in research
settings. PromptSE enables practitioners to quantify performance stability
trade offs for deployment and model selection, positioning prompt stability as
a complementary evaluation dimension alongside performance and fairness, and
contributing to more trustworthy AI-assisted software development tools.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [226] [Complexity Bounds for Smooth Convex Multiobjective Optimization](https://arxiv.org/abs/2509.13550)
*Phillipe R. Sampaio*

Main category: math.OC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the oracle complexity of finding $\varepsilon$-Pareto stationary
points in smooth multiobjective optimization with $m$ objectives. The progress
metric is the Pareto stationarity gap $\mathcal{G}(x)$ (the norm of an optimal
convex combination of gradients). Our contributions are fourfold. (i) For
strongly convex objectives, any span first-order method (iterates lie in the
span of past gradients) exhibits linear convergence no faster than
$\exp(-\Theta(T/\sqrt{\kappa}))$ after $T$ oracle calls, where $\kappa$ is the
condition number, implying $\Theta(\sqrt{\kappa}\log(1/\varepsilon))$
iterations; this matches classical accelerated upper bounds. (ii) For convex
problems and oblivious one-step methods (a fixed scalarization with
pre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best
gradient norm among the first $T$ iterates. (iii) Although accelerated gradient
descent is outside this restricted class, it is an oblivious span method and
attains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex
problems and general span methods with adaptive scalarizations, we establish a
universal lower bound of order $1/T^{2}$ on the gradient norm of the final
iterate after $T$ steps, highlighting a gap between known upper bounds and
worst-case guarantees. All bounds hold on non-degenerate instances with
distinct objectives and non-singleton Pareto fronts; rates are stated up to
universal constants and natural problem scaling.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [227] [Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation](https://arxiv.org/abs/2509.13331)
*Reza Pirayeshshirazinezhad*

Main category: astro-ph.IM

TL;DR: 本文提出结合AI和自适应控制系统，优化高精度航天器编队任务（如VTXO），实现能源消耗降低和任务精度提高。


<details>
  <summary>Details</summary>
Motivation: VTXO任务需要两个航天器组成一公里焦距的虚拟望远镜，以55毫角秒的精度观测X射线高能天体，对航天器编队的精度和效率有极高要求。

Method: 使用AI和监督自适应控制系统进行任务规划和优化。具体方法包括：利用机器学习和鲁棒控制提高编队效率；采用时间自动机进行监督控制；通过蒙特卡洛模拟评估稳定性和鲁棒性；集成深度神经网络进行任务参数优化估计；将深度神经网络与受约束的非凸动态优化流程结合，预测最佳任务参数并提供解释性。

Result: 研究结果显示，该系统显著降低了能源消耗，提高了任务精度。AI框架通过预测能耗和任务误差，增强了系统的可解释性，并能实现透明、合理且实时的权衡，这是传统自适应控制器所不具备的能力。系统能有效应对动态不确定性和干扰。

Conclusion: 结合AI和监督自适应控制的系统能够成功优化高精度航天器编队任务，提高能源效率和任务准确性，并提供传统方法缺乏的解释性和实时权衡能力，有效应对复杂的动态环境。

Abstract: We use artificial intelligence (AI) and supervisory adaptive control systems
to plan and optimize the mission of precise spacecraft formation. Machine
learning and robust control enhance the efficiency of spacecraft precision
formation of the Virtual Telescope for X-ray Observation (VTXO) space mission.
VTXO is a precise formation of two separate spacecraft making a virtual
telescope with a one-kilometer focal length. One spacecraft carries the lens
and the other spacecraft holds the camera to observe high-energy space objects
in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed
automata for supervisory control, Monte Carlo simulations for stability and
robustness evaluation, and integration of deep neural networks for optimal
estimation of mission parameters, satisfy the high precision mission criteria.
We integrate deep neural networks with a constrained, non-convex dynamic
optimization pipeline to predict optimal mission parameters, ensuring precision
mission criteria are met. AI framework provides explainability by predicting
the resulting energy consumption and mission error for a given set of mission
parameters. It allows for transparent, justifiable, and real-time trade-offs, a
capability not present in traditional adaptive controllers. The results show
reductions in energy consumption and improved mission accuracy, demonstrating
the capability of the system to address dynamic uncertainties and disturbances.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [228] [Benchmarking Dimensionality Reduction Techniques for Spatial Transcriptomics](https://arxiv.org/abs/2509.13344)
*Md Ishtyaq Mahmud,Veena Kochat,Suresh Satpati,Jagan Mohan Reddy Dwarampudi,Kunal Rai,Tania Banerjee*

Main category: q-bio.GN

TL;DR: 引入统一框架评估空间转录组降维技术，对比多种方法，并展示其在提升生物学准确性方面的效果。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组降维技术（超越PCA）缺乏统一的评估框架，难以有效选择适合特定分析的方法。

Method: 在胆管癌Xenium数据集上，基准测试了PCA、NMF、自编码器、VAE及两种混合嵌入共六种降维方法。系统性改变潜在维度和聚类分辨率，并使用重建误差、解释方差、聚类内聚性、聚类标记物一致性（CMC）和标记物排除率（MER）等指标进行评估。采用帕累托最优分析进行超参数选择，并应用MER引导重分配策略。

Result: 各方法表现出独特性能：PCA提供快速基线，NMF最大化标记物富集，VAE平衡重建与可解释性，自编码器居中。MER引导重分配显著提高了所有方法的生物学忠实度，CMC分数平均提高达12%。

Conclusion: 所提出的框架能够为空间转录组分析中降维方法的原理性选择提供指导。

Abstract: We introduce a unified framework for evaluating dimensionality reduction
techniques in spatial transcriptomics beyond standard PCA approaches. We
benchmark six methods PCA, NMF, autoencoder, VAE, and two hybrid embeddings on
a cholangiocarcinoma Xenium dataset, systematically varying latent dimensions
($k$=5-40) and clustering resolutions ($\rho$=0.1-1.2). Each configuration is
evaluated using complementary metrics including reconstruction error, explained
variance, cluster cohesion, and two novel biologically-motivated measures:
Cluster Marker Coherence (CMC) and Marker Exclusion Rate (MER). Our results
demonstrate distinct performance profiles: PCA provides a fast baseline, NMF
maximizes marker enrichment, VAE balances reconstruction and interpretability,
while autoencoders occupy a middle ground. We provide systematic hyperparameter
selection using Pareto optimal analysis and demonstrate how MER-guided
reassignment improves biological fidelity across all methods, with CMC scores
improving by up to 12\% on average. This framework enables principled selection
of dimensionality reduction methods tailored to specific spatial
transcriptomics analyses.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [229] [A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings](https://arxiv.org/abs/2509.13371)
*Xuyuan Kang,Xiao Wang,Jingjing An,Da Yan*

Main category: eess.SY

TL;DR: 提出了一种用于冰蓄冷系统的集成负荷预测与优化控制方法，通过预测模型和基于分时电价的规则型控制策略，实现了显著的能耗成本节约和系统效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有蓄热蓄冷（TES）系统多采用固定运行计划，无法充分发挥其负荷转移能力，亟需优化控制策略以提升冷却系统性能和管理水平。

Method: 开发了带有日中修正机制的冷负荷预测模型以提高准确性。基于预测结果，结合分时电价，提出了规则型控制策略，并引入日中控制调整机制以适应预测修正。

Result: 应用于北京某商业综合体冰蓄冷系统，冷负荷预测模型的平均绝对误差（MAE）为389 kW，MAE变异系数为12.5%。集成的预测控制策略实现了9.9%的能源成本节约率。

Conclusion: 所提出的集成预测与优化控制模型已成功部署在实际楼宇自动化系统中，显著提升了冷却系统的效率和自动化水平。

Abstract: Thermal energy storage (TES) is an effective method for load shifting and
demand response in buildings. Optimal TES control and management are essential
to improve the performance of the cooling system. Most existing TES systems
operate on a fixed schedule, which cannot take full advantage of its load
shifting capability, and requires extensive investigation and optimization.
This study proposed a novel integrated load prediction and optimized control
approach for ice-based TES in commercial buildings. A cooling load prediction
model was developed and a mid-day modification mechanism was introduced into
the prediction model to improve the accuracy. Based on the predictions, a
rule-based control strategy was proposed according to the time-of-use tariff;
the mid-day control adjustment mechanism was introduced in accordance with the
mid-day prediction modifications. The proposed approach was applied in the
ice-based TES system of a commercial complex in Beijing, and achieved a mean
absolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The
integrated prediction-based control strategy achieved an energy cost saving
rate of 9.9%. The proposed model was deployed in the realistic building
automation system of the case building and significantly improved the
efficiency and automation of the cooling system.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [230] [A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds](https://arxiv.org/abs/2509.13390)
*Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias*

Main category: cs.SD

TL;DR: 针对汽车座舱声音的无监督异常检测，本文提出一种基于领域知识的“代理异常”模型选择方法，通过扰动正常样本生成代理异常进行验证，显著优于传统策略。


<details>
  <summary>Details</summary>
Motivation: 汽车座舱声音的异常检测对车辆质量和乘客舒适度至关重要。由于缺乏带标签的故障数据，该任务常被视为无监督学习问题。然而，在无监督设置下，缺少故障样本进行验证以及常用指标的局限性，使得有效的模型选择成为重大挑战。

Method: 提出了一种领域知识驱动的模型选择方法。通过对正常频谱图进行结构化扰动来工程化“代理异常”（proxy-anomalies），并将其用于验证集以支持模型选择。该方法在一个高保真电动汽车座舱声音数据集上进行评估，该数据集包含五种故障类型。

Result: 实验评估表明，使用代理异常进行模型选择，在五种故障情况下均能选择出最优模型，并且显著优于传统的模型选择策略。

Conclusion: 所提出的代理异常模型选择方法有效解决了无监督异常检测中模型选择的难题，实现了更优的性能。同时，公开的高保真数据集有助于进一步研究。

Abstract: The detection of anomalies in automotive cabin sounds is critical for
ensuring vehicle quality and maintaining passenger comfort. In many real-world
settings, this task is more appropriately framed as an unsupervised learning
problem rather than the supervised case due to the scarcity or complete absence
of labeled faulty data. In such an unsupervised setting, the model is trained
exclusively on healthy samples and detects anomalies as deviations from normal
behavior. However, in the absence of labeled faulty samples for validation and
the limited reliability of commonly used metrics, such as validation
reconstruction error, effective model selection remains a significant
challenge. To overcome these limitations, a domain-knowledge-informed approach
for model selection is proposed, in which proxy-anomalies engineered through
structured perturbations of healthy spectrograms are used in the validation set
to support model selection. The proposed methodology is evaluated on a
high-fidelity electric vehicle dataset comprising healthy and faulty cabin
sounds across five representative fault types viz., Imbalance, Modulation,
Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced
sound synthesis techniques, and validated via expert jury assessments, has been
made publicly available to facilitate further research. Experimental
evaluations on the five fault cases demonstrate the selection of optimal models
using proxy-anomalies, significantly outperform conventional model selection
strategies.

</details>


### [231] [Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection](https://arxiv.org/abs/2509.13853)
*Shun Huang,Zhihua Fang,Liang He*

Main category: cs.SD

TL;DR: 本文提出OS-SCL训练技术和TFgram特征，有效解决了多机器同类型异常声音检测中误报率高的问题，并在DCASE 2020挑战赛中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 无监督异常声音检测在处理来自不同机器的同类型样本时，自监督方法仍存在频繁误报的问题。

Method: 1. 引入one-stage supervised contrastive learning (OS-SCL) 训练技术，通过扰动嵌入空间中的特征和使用单阶段噪声监督对比学习来降低误报。
2. 提出一种名为TFgram的时间-频率特征，从原始音频中提取，以有效捕捉异常声音检测的关键信息。

Result: 1. OS-SCL结合Log-Mel特征在DCASE 2020 Challenge Task 2上达到94.64% AUC, 88.42% pAUC, 和89.24% mAUC。
2. 结合TFgram特征后，性能进一步提升至95.71% AUC, 90.23% pAUC, 和91.23% mAUC。

Conclusion: 通过OS-SCL训练技术和TFgram特征的引入，本研究显著提高了无监督异常声音检测在不同机器同类型场景下的准确性，有效降低了误报率。

Abstract: Unsupervised anomalous sound detection aims to detect unknown anomalous
sounds by training a model using only normal audio data. Despite advancements
in self-supervised methods, the issue of frequent false alarms when handling
samples of the same type from different machines remains unresolved. This paper
introduces a novel training technique called one-stage supervised contrastive
learning (OS-SCL), which significantly addresses this problem by perturbing
features in the embedding space and employing a one-stage noisy supervised
contrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved
94.64\% AUC, 88.42\% pAUC, and 89.24\% mAUC using only Log-Mel features.
Additionally, a time-frequency feature named TFgram is proposed, which is
extracted from raw audio. This feature effectively captures critical
information for anomalous sound detection, ultimately achieving 95.71\% AUC,
90.23\% pAUC, and 91.23\% mAUC. The source code is available at:
\underline{www.github.com/huangswt/OS-SCL}.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [232] [Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI](https://arxiv.org/abs/2509.13345)
*Zihao Li,Weiwei Yi,Jiahong Chen*

Main category: cs.CY

TL;DR: 本文认为大语言模型（LLMs）的“幻觉”问题不能仅靠追求准确性来解决，过度依赖准确性会导致“准确性悖论”，反而加剧了LLMs的认识论和社会风险。文章从输出、个体和社会三个维度分析了这一悖论，并指出现有法规不足。呼吁转向多元、情境感知和抗操纵的AI治理方法。


<details>
  <summary>Details</summary>
Motivation: LLMs日益渗透日常决策，其认识论和社会风险（特别是幻觉）亟需审查。传统观点和现有法规普遍将“准确性”视为缓解幻觉危害的主要基准。然而，本文旨在挑战这一观点，认为过度依赖准确性误诊了问题，并产生了适得其反的效果，即“准确性悖论”。

Method: 本文借鉴跨学科文献，发展了一套幻觉类型学，并从输出、个体和社会三个相互关联的维度来阐释“准确性悖论”。此外，文章还分析了欧盟AI法案、GDPR和DSA等现有法规，以评估其应对这些风险的能力。

Result: 研究揭示了“准确性悖论”的三个维度：1) 准确性仅作为可靠性的表面代理，导致模型优先优化修辞流畅性而非认识论可信度，鼓励用户对看似准确实则站不住脚的输出产生被动信任。2) 准确性作为单一指标无法检测非事实性错误但具误导性、价值偏向或社会扭曲的危害，如共识幻觉。3) 对准确性的监管过度强调掩盖了幻觉更广泛的社会后果，包括社会分化、隐私侵犯、公平损害和多元性减少。文章指出，现有法规未能从结构上有效解决这些由过度依赖准确性加剧的认识论、关系和系统性危害。

Conclusion: 过度依赖准确性导致了概念和实践上的挑战，加剧了LLMs的认识论、关系和系统性危害。因此，AI信任治理需要进行根本性转变，采纳多元化、情境感知和抗操纵的方法。

Abstract: As Large Language Models (LLMs) permeate everyday decision-making, their
epistemic and societal risks demand urgent scrutiny. Hallucinations, the
generation of fabricated, misleading, oversimplified or untrustworthy outputs,
has emerged as imperative challenges. While regulatory, academic, and technical
discourse position accuracy as the principal benchmark for mitigating such
harms, this article contends that overreliance on accuracy misdiagnoses the
problem and has counterproductive effect: the accuracy paradox. Drawing on
interdisciplinary literatures, this article develops a taxonomy of
hallucination types and shows the paradox along three intertwining dimensions:
outputs, individuals and society. First, accuracy functions as a superficial
proxy for reliability, incentivising the optimisation of rhetorical fluency and
surface-level correctness over epistemic trustworthiness. This encourages
passive user trust in outputs that appear accurate but epistemically untenable.
Second, accuracy as a singular metric fails to detect harms that are not
factually false but are nonetheless misleading, value-laden, or socially
distorting, including consensus illusions, sycophantic alignment, and subtle
manipulation. Third, regulatory overemphasis on accuracy obscures the wider
societal consequences of hallucination, including social sorting, privacy
violations, equity harms, epistemic convergence that marginalises dissent,
reduces pluralism, and causes social deskilling. By examining the EU AI Act,
GDPR, and DSA, the article argues that current regulations are not yet
structurally equipped to address these epistemic, relational, and systemic
harms and exacerbated by the overreliance on accuracy. By exposing such
conceptual and practical challenges, this article calls for a fundamental shift
towards pluralistic, context-aware, and manipulation-resilient approaches to AI
trustworthy governance.

</details>


### [233] [Synthetic Data and the Shifting Ground of Truth](https://arxiv.org/abs/2509.13355)
*Dietmar Offenhuber*

Main category: cs.CY

TL;DR: 本文探讨了合成数据兴起后，机器学习中“事实真相”（ground truth）概念如何变得复杂和自指，挑战了传统数据保真度观念，并分析了这种从表征性到模仿性数据概念转变的更广泛影响。


<details>
  <summary>Details</summary>
Motivation: 合成数据因其便利性和隐私保护优势被广泛使用，但其不指向外部特征的特性，使“事实真相”的概念复杂化。尽管缺乏现实世界参照，合成数据仍被用作训练数据，甚至被声称能带来优于真实数据的模型性能。这挑战了“输入垃圾，输出垃圾”的传统数据保真度假设。因此，研究人员需要理解在此悖论下，机器学习从业者如何建立“事实真相”，以及这种数据概念转变的深远影响。

Method: 本文通过概念分析和反思的方式进行研究。它“审视”机器学习研究人员和实践者如何在缺乏现实世界参考的情况下建立“事实真相”，并“反思”数据从表征性（representational）转向模仿性（mimetic）或图像性（iconic）概念的更广泛含义。

Result: 研究指出，合成数据的使用使“事实真相”变得自指，其标签本身是生成模型的产物，与现实世界观察脱节。这种数据缺乏现实性不仅可以接受，甚至有时能带来更好的模型性能，例如补偿已知偏差、防止过拟合、支持泛化并增强模型鲁棒性。这极大地复杂化了基于表征准确性来判断数据保真度的传统假设。

Conclusion: 结论是，机器学习领域正经历从基于表征的“事实真相”到基于模仿或图像概念的“事实真相”的范式转变。理解这种转变如何影响“事实真相”的建立过程及其更广泛的哲学和社会影响至关重要，因为这挑战了我们对数据、现实和人工智能系统可靠性的基本假设。

Abstract: The emergence of synthetic data for privacy protection, training data
generation, or simply convenient access to quasi-realistic data in any shape or
volume complicates the concept of ground truth. Synthetic data mimic real-world
observations, but do not refer to external features. This lack of a
representational relationship, however, not prevent researchers from using
synthetic data as training data for AI models and ground truth repositories. It
is claimed that the lack of data realism is not merely an acceptable tradeoff,
but often leads to better model performance than realistic data: compensate for
known biases, prevent overfitting and support generalization, and make the
models more robust in dealing with unexpected outliers. Indeed, injecting noisy
and outright implausible data into training sets can be beneficial for the
model. This greatly complicates usual assumptions based on which
representational accuracy determines data fidelity (garbage in - garbage out).
Furthermore, ground truth becomes a self-referential affair, in which the
labels used as a ground truth repository are themselves synthetic products of a
generative model and as such not connected to real-world observations. My paper
examines how ML researchers and practitioners bootstrap ground truth under such
paradoxical circumstances without relying on the stable ground of
representation and real-world reference. It will also reflect on the broader
implications of a shift from a representational to what could be described as a
mimetic or iconic concept of data.

</details>


### [234] [Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study](https://arxiv.org/abs/2509.13359)
*Benjamin J. Walker,Beatriz Navarro Lameda,Ruth A. Reynolds*

Main category: cs.CY

TL;DR: 本研究探讨了在无监考、开放书籍且可访问生成式AI（GenAI）的环境下，传统数学考试的教学有效性。结果显示GenAI的成绩可达一级荣誉学位水平，且表现高度一致，这表明现有评估标准在GenAI时代可能失去教学价值，亟需重新设计数学评估方式。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具正在改变教育格局，促使人们重新思考传统评估方式。同时，大学探索无监考考试，引发了对学术诚信和教学一致性的担忧。因此，本研究旨在探究在假设的无监考、开放书籍且可访问GenAI的环境下，传统闭卷数学考试是否仍具有教学相关性。

Method: 采用实证方法，研究人员生成、转录并盲批了GenAI对一所罗素集团大学八门本科数学考试（涵盖大一全部课程）的答卷。通过整合GenAI对单个问题的独立回答，对GenAI在模块层面和整个大一课程中的表现进行了有意义的评估。

Result: 研究发现，GenAI的成绩达到了获得一级荣誉学位的水平，尽管其在不同模块间的表现可能有所差异。此外，GenAI在整个课程中的表现 remarkably consistent，显著高于有监考考试中学生的表现。

Conclusion: 研究结果证明，在无人监督的环境下，数学评估需要重新设计。这突出表明，在生成式AI时代，当前评估标准的教学价值可能降低。

Abstract: Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are
transforming the educational landscape, prompting reconsideration of
traditional assessment practices. In parallel, universities are exploring
alternatives to in-person, closed-book examinations, raising concerns about
academic integrity and pedagogical alignment in uninvigilated settings. This
study investigates whether traditional closed-book mathematics examinations
retain their pedagogical relevance when hypothetically administered in
uninvigilated, open-book settings with GenAI access. Adopting an empirical
approach, we generate, transcribe, and blind-mark GenAI submissions to eight
undergraduate mathematics examinations at a Russel Group university, spanning
the entirety of the first-year curriculum. By combining independent GenAI
responses to individual questions, we enable a meaningful evaluation of GenAI
performance, both at the level of modules and across the first-year curriculum.
We find that GenAI attainment is at the level of a first-class degree, though
current performance can vary between modules. Further, we find that GenAI
performance is remarkably consistent when viewed across the entire curriculum,
significantly more so than that of students in invigilated examinations. Our
findings evidence the need for redesigning assessments in mathematics for
unsupervised settings, and highlight the potential reduction in pedagogical
value of current standards in the era of generative artificial intelligence.

</details>


### [235] [An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies](https://arxiv.org/abs/2509.12577)
*Elinor Poole-Dayan,Deb Roy,Jad Kabbara*

Main category: cs.CY

TL;DR: 本研究利用大语言模型（LLMs）分析审议大会的会议记录，以实证追踪思想的演变、精炼以及代表观点的变化，揭示传统方法难以捕捉的细致动态。


<details>
  <summary>Details</summary>
Motivation: 在社会碎片化和信任缺失的背景下，审议大会作为政策制定论坛日益重要。然而，现有实证研究不足以系统追踪思想在审议中如何发展、优先排序或被弃用，以及审议过程如何影响代表的观点和投票动态。

Method: 开发基于大语言模型（LLMs）的方法论，对技术增强型面对面审议大会的会议记录进行实证分析。该框架能够识别并可视化建议空间，并重建每位代表在会议期间不断演变的视角。

Result: 所提出的方法为审议过程提供了新颖的实证见解，并成功展示了大语言模型如何揭示传统会议输出中不可见的、高分辨率的动态。

Conclusion: 利用大语言模型能够对复杂的审议过程进行高分辨率的实证分析，从而提供传统方法无法捕捉的深入动态和见解。

Abstract: In an era of increasing societal fragmentation, political polarization, and
erosion of public trust in institutions, representative deliberative assemblies
are emerging as a promising democratic forum for developing effective policy
outcomes on complex global issues. Despite theoretical attention, there remains
limited empirical work that systematically traces how specific ideas evolve,
are prioritized, or are discarded during deliberation to form policy
recommendations. Addressing these gaps, this work poses two central questions:
(1) How might we trace the evolution and distillation of ideas into concrete
recommendations within deliberative assemblies? (2) How does the deliberative
process shape delegate perspectives and influence voting dynamics over the
course of the assembly? To address these questions, we develop LLM-based
methodologies for empirically analyzing transcripts from a tech-enhanced
in-person deliberative assembly. The framework identifies and visualizes the
space of expressed suggestions. We also empirically reconstruct each delegate's
evolving perspective throughout the assembly. Our methods contribute novel
empirical insights into deliberative processes and demonstrate how LLMs can
surface high-resolution dynamics otherwise invisible in traditional assembly
outputs.

</details>


### [236] [The Provenance Problem: LLMs and the Breakdown of Citation Norms](https://arxiv.org/abs/2509.13365)
*Brian D. Earp,Haotian Yuan,Julian Koplin,Sebastian Porsdam Mann*

Main category: cs.CY

TL;DR: 生成式AI在科学写作中引发了“出处问题”，即AI可能在未引用的情况下复制想法，造成一种新型归因损害，现有框架无法解决，威胁到科学声誉和认知公正。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在科学写作中的广泛应用，引发了关于知识归属和著作权归属的紧迫问题。AI系统可能在未引用的情况下复制来源想法，从而造成新型的归因损害，而当前的伦理和专业框架未能有效应对此类问题。

Method: 本文以“视角”文章的形式，分析了AI如何挑战既定的作者规范，引入了理解“出处问题”的概念工具，并提出了旨在维护学术交流完整性和公平性的策略。

Result: 研究识别并定义了“出处问题”——一种新型归因损害，它不同于传统剽窃（不涉及欺骗意图），但仍然利用了他人的未署名智力贡献。这种现象威胁到科学的声誉经济和认知公正。

Conclusion: 文章指出AI对既定作者规范的挑战，提供了理解“出处问题”的概念工具，并提出了旨在维护学术交流的完整性和公平性的策略，以应对生成式AI带来的挑战。

Abstract: The increasing use of generative AI in scientific writing raises urgent
questions about attribution and intellectual credit. When a researcher employs
ChatGPT to draft a manuscript, the resulting text may echo ideas from sources
the author has never encountered. If an AI system reproduces insights from, for
example, an obscure 1975 paper without citation, does this constitute
plagiarism? We argue that such cases exemplify the 'provenance problem': a
systematic breakdown in the chain of scholarly credit. Unlike conventional
plagiarism, this phenomenon does not involve intent to deceive (researchers may
disclose AI use and act in good faith) yet still benefit from the uncredited
intellectual contributions of others. This dynamic creates a novel category of
attributional harm that current ethical and professional frameworks fail to
address. As generative AI becomes embedded across disciplines, the risk that
significant ideas will circulate without recognition threatens both the
reputational economy of science and the demands of epistemic justice. This
Perspective analyzes how AI challenges established norms of authorship,
introduces conceptual tools for understanding the provenance problem, and
proposes strategies to preserve integrity and fairness in scholarly
communication.

</details>


### [237] [CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI](https://arxiv.org/abs/2509.13356)
*Hasin Jawad Ali,Ilhamul Azam,Ajwad Abrar,Md. Kamrul Hasan,Hasan Mahmud*

Main category: cs.CY

TL;DR: 本文提出了CogniAlign，一个基于自然istic道德实在论的多智能体框架，通过跨学科辩论提升AI的道德推理能力，在道德问题上显著优于GPT-4o，为安全透明的AI对齐提供了新途径。


<details>
  <summary>Details</summary>
Motivation: AI与人类价值观对齐面临挑战，主要源于道德原则的抽象性、冲突性以及现有方法的缺乏透明度。

Method: 引入CogniAlign，一个多智能体审议框架，其道德推理根植于个体和集体维度的“生存能力”。通过神经科学、心理学、社会学和进化生物学等领域科学家智能体之间的结构化辩论，由仲裁者综合形成透明且基于经验的判断。使用五部分伦理审计框架，将CogniAlign的输出与GPT-4o进行比较评估。

Result: CogniAlign在超过60个道德问题上持续优于GPT-4o，分析质量平均提升16.2点，广度提升14.3点，解释深度提升28.4点。在海因茨困境中，CogniAlign得分89.2，而GPT-4o得分69.2，显示出处理道德推理的决定性优势。

Conclusion: CogniAlign通过减少黑箱推理并避免欺骗性对齐，突出了跨学科审议作为安全透明AI对齐的可扩展途径的潜力。

Abstract: The challenge of aligning artificial intelligence (AI) with human values
persists due to the abstract and often conflicting nature of moral principles
and the opacity of existing approaches. This paper introduces CogniAlign, a
multi-agent deliberation framework based on naturalistic moral realism, that
grounds moral reasoning in survivability, defined across individual and
collective dimensions, and operationalizes it through structured deliberations
among discipline-specific scientist agents. Each agent, representing
neuroscience, psychology, sociology, and evolutionary biology, provides
arguments and rebuttals that are synthesized by an arbiter into transparent and
empirically anchored judgments. We evaluate CogniAlign on classic and novel
moral questions and compare its outputs against GPT-4o using a five-part
ethical audit framework. Results show that CogniAlign consistently outperforms
the baseline across more than sixty moral questions, with average performance
gains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4
points in depth of explanation. In the Heinz dilemma, for example, CogniAlign
achieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a
decisive advantage in handling moral reasoning. By reducing black-box reasoning
and avoiding deceptive alignment, CogniAlign highlights the potential of
interdisciplinary deliberation as a scalable pathway for safe and transparent
AI alignment.

</details>


### [238] [Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis](https://arxiv.org/abs/2509.13387)
*Delaram Golpayegani,Marta Lasek-Markey,Arjumand Younus,Aphra Kerr,Dave Lewis*

Main category: cs.CY

TL;DR: 本文通过定性主题分析和定量BERTopic模型，分析欧盟AI治理文件（包括AI法案、HLEG指南及2018年后政策文件），以理解并追踪欧盟AI治理方法的演变。


<details>
  <summary>Details</summary>
Motivation: 尽管欧盟是AI治理政策的重要制定者，其现有政策和指南（如HLEG指南和AI法案）在范围、侧重点、规范性和优先级上可能存在差异，导致AI治理格局碎片化，因此需要对欧盟的AI治理方法进行全面理解。

Method: 1. 采用定性主题分析方法，识别欧盟关键文件（包括AI法案和HLEG伦理指南）中的普遍主题。2. 进一步采用定量主题建模方法（BERTopic模型），扩大文档样本至2018年后发布的欧盟AI政策文件，以增强分析结果。

Result: 研究提供了一个关于欧盟AI政策的全新视角，成功追踪了其应对AI治理方法的演变。

Conclusion: 本研究通过系统分析欧盟的AI治理政策文件，为理解欧盟AI治理方法的演进提供了一个新颖且全面的视角。

Abstract: The upsurge of policies and guidelines that aim to ensure Artificial
Intelligence (AI) systems are safe and trustworthy has led to a fragmented
landscape of AI governance. The European Union (EU) is a key actor in the
development of such policies and guidelines. Its High-Level Expert Group (HLEG)
issued an influential set of guidelines for trustworthy AI, followed in 2024 by
the adoption of the EU AI Act. While the EU policies and guidelines are
expected to be aligned, they may differ in their scope, areas of emphasis,
degrees of normativity, and priorities in relation to AI. To gain a broad
understanding of AI governance from the EU perspective, we leverage qualitative
thematic analysis approaches to uncover prevalent themes in key EU documents,
including the AI Act and the HLEG Ethics Guidelines. We further employ
quantitative topic modelling approaches, specifically through the use of the
BERTopic model, to enhance the results and increase the document sample to
include EU AI policy documents published post-2018. We present a novel
perspective on EU policies, tracking the evolution of its approach to
addressing AI governance.

</details>


### [239] [The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self](https://arxiv.org/abs/2509.13391)
*Sandrine R. Schiller,Camilo Miguel Signorelli,Filippos Stamatiou*

Main category: cs.CY

TL;DR: 生成式AI正从响应式转向预测式，深刻影响人机和自我关系，本文探讨其对任务执行、情境互动及自我认知的影响。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式AI日益预测化和自主化，改变人与技术、他人及自我的互动方式，有必要重新思考人机关系及其对“关系性自我”的影响，从而进行更深层次的生存论探讨。

Method: 本文基于“关系性自我”概念，通过概念分析，探讨生成式AI对“外部化输出领域”、“情境领域”和“自我关系领域”的潜在影响，并阐述AI如何履行任务并日益预判和截断人类主动性。

Result: 研究阐明了生成式AI不仅能完成任务，还能在“外部化输出领域”、“情境领域”和“自我关系领域”日益预判并截断人类的主动性。

Conclusion: 生成式AI从被动响应向预测和主动干预的转变，要求我们对人机关系及其对个体自我关系产生的存在论影响进行深刻反思。

Abstract: Generative AI is changing our way of interacting with technology, others, and
ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple
intelligence still awaits our prompt for action. Yet, it is likely that AI
assistant systems will only become better at predicting our behaviour and
acting on our behalf. Imagine new generations of generative and predictive AI
deciding what you might like best at a new restaurant, picking an outfit that
increases your chances on your date with a partner also chosen by the same or a
similar system. Far from a science fiction scenario, the goal of several
research programs is to build systems capable of assisting us in exactly this
manner. The prospect urges us to rethink human-technology relations, but it
also invites us to question how such systems might change the way we relate to
ourselves. Building on our conception of the relational self, we question the
possible effects of generative AI with respect to what we call the sphere of
externalised output, the contextual sphere and the sphere of self-relating. In
this paper, we attempt to deepen the existential considerations accompanying
the AI revolution by outlining how generative AI enables the fulfilment of
tasks and also increasingly anticipates, i.e. intercepts, our initiatives in
these different spheres.

</details>


### [240] [The threat of analytic flexibility in using large language models to simulate human data: A call to attention](https://arxiv.org/abs/2509.13397)
*Jamie Cummins*

Main category: cs.CY

TL;DR: LLMs生成的“硅样本”的分析选择会严重影响其质量，且没有普适的最佳配置，需要警惕分析灵活性带来的风险。


<details>
  <summary>Details</summary>
Motivation: 社会科学家正利用大语言模型创建“硅样本”以革新人类受试者研究，但生成这些样本时所需的分析选择对样本质量的影响尚不明确。

Method: 作者梳理了制作“硅样本”的分析选择，并通过测试252种不同配置，评估了这些配置在估计参与者排名、响应分布和量表间相关性方面的能力，以展示不同决策对样本质量的影响。

Result: 极少数分析决策就能显著改变“硅样本”与人类数据之间的一致性。不同配置在估计参与者排名、响应分布和量表间相关性方面的表现差异很大，且质量不一致——在一个维度上表现良好的配置在另一个维度上可能表现不佳，表明不存在“一刀切”的最佳配置。

Conclusion: 在使用“硅样本”时，必须更加关注分析灵活性所带来的潜在风险。

Abstract: Social scientists are now using large language models to create "silicon
samples" - synthetic datasets intended to stand in for human respondents, aimed
at revolutionising human subjects research. However, there are many analytic
choices which must be made to produce these samples. Though many of these
choices are defensible, their impact on sample quality is poorly understood. I
map out these analytic choices and demonstrate how a very small number of
decisions can dramatically change the correspondence between silicon samples
and human data. Configurations (N = 252) varied substantially in their capacity
to estimate (i) rank ordering of participants, (ii) response distributions, and
(iii) between-scale correlations. Most critically, configurations were not
consistent in quality: those that performed well on one dimension often
performed poorly on another, implying that there is no "one-size-fits-all"
configuration that optimises the accuracy of these samples. I call for greater
attention to the threat of analytic flexibility in using silicon samples.

</details>


### [241] [Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews](https://arxiv.org/abs/2509.13400)
*Sai Suresh Marchala Vasu,Ivaxi Sheth,Hui-Po Wang,Ruta Binkyte,Mario Fritz*

Main category: cs.CY

TL;DR: 研究发现，大语言模型（LLMs）生成的同行评审存在机构和性别偏见，偏向高排名机构，且存在细微的性别偏好。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）正在变革同行评审过程，带来机遇的同时也引发了对公平性和可靠性的担忧。

Method: 通过对作者单位和性别等敏感元数据进行对照实验，调查LLM生成的同行评审中的偏见。

Result: 分析一致显示，LLMs存在机构偏见，偏向在学术排名中靠前的机构。此外，还发现了一些性别偏好，尽管程度细微但有随时间累积的潜力。通过基于token的软评分，揭示了更明显的隐含偏见。

Conclusion: LLMs生成的同行评审中存在机构和性别的偏见，这些偏见，尤其是在高排名机构和潜在的性别方面，可能影响评审的公平性和可靠性，并且隐含偏见可通过特定方法显现。

Abstract: The adoption of large language models (LLMs) is transforming the peer review
process, from assisting reviewers in writing more detailed evaluations to
generating entire reviews automatically. While these capabilities offer
exciting opportunities, they also raise critical concerns about fairness and
reliability. In this paper, we investigate bias in LLM-generated peer reviews
by conducting controlled experiments on sensitive metadata, including author
affiliation and gender. Our analysis consistently shows affiliation bias
favoring institutions highly ranked on common academic rankings. Additionally,
we find some gender preferences, which, even though subtle in magnitude, have
the potential to compound over time. Notably, we uncover implicit biases that
become more evident with token-based soft ratings.

</details>


### [242] [Reproducible workflow for online AI in digital health](https://arxiv.org/abs/2509.13499)
*Susobhan Ghosh,Bhanu T. Gulapalli,Daiqi Gao,Asim Gazi,Anna Trella,Ziping Xu,Kelly Zhang,Susan A. Murphy*

Main category: cs.CY

TL;DR: 本文提出一个可复现的科学工作流程，用于开发、部署和分析数字健康干预中的在线AI算法，旨在解决其适应性与可复现性之间的平衡挑战。


<details>
  <summary>Details</summary>
Motivation: 在线AI算法是数字健康干预的重要组成部分，需持续学习并改进。然而，部署在线AI面临一个关键挑战：如何在保持其适应性的同时确保可复现性。鉴于该领域的快速发展和迭代部署特性，确保数据存储准确、算法行为可审计、结果可比较，对科学效用和可信赖的优化至关重要。

Method: 论文提出一种可复现的科学工作流程，用于开发、部署和分析数字健康干预中的在线AI决策算法。该流程以多次真实世界部署的实践经验为基础。

Result: 所提出的工作流程旨在解决在线AI算法开发生命周期各个阶段的可复现性关键挑战。

Conclusion: 该工作流程为数字健康干预中在线AI算法的开发、部署和分析提供了解决方案，以增强可复现性，从而促进科学发现和可信赖的系统改进。

Abstract: Online artificial intelligence (AI) algorithms are an important component of
digital health interventions. These online algorithms are designed to
continually learn and improve their performance as streaming data is collected
on individuals. Deploying online AI presents a key challenge: balancing
adaptability of online AI with reproducibility. Online AI in digital
interventions is a rapidly evolving area, driven by advances in algorithms,
sensors, software, and devices. Digital health intervention development and
deployment is a continuous process, where implementation - including the AI
decision-making algorithm - is interspersed with cycles of re-development and
optimization. Each deployment informs the next, making iterative deployment a
defining characteristic of this field. This iterative nature underscores the
importance of reproducibility: data collected across deployments must be
accurately stored to have scientific utility, algorithm behavior must be
auditable, and results must be comparable over time to facilitate scientific
discovery and trustworthy refinement. This paper proposes a reproducible
scientific workflow for developing, deploying, and analyzing online AI
decision-making algorithms in digital health interventions. Grounded in
practical experience from multiple real-world deployments, this workflow
addresses key challenges to reproducibility across all phases of the online AI
algorithm development life-cycle.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [243] [Dual Actor DDPG for Airborne STAR-RIS Assisted Communications](https://arxiv.org/abs/2509.13328)
*Danish Rizvi,David Boyle*

Main category: eess.SP

TL;DR: 本研究提出一种基于无人机搭载耦合TRC模型STAR-RIS（Aerial-STAR）的多用户通信系统，通过联合优化无人机轨迹、基站波束成形和RIS TRC，设计DA-DDPG算法和HFI奖励函数，显著提升了通信效率和公平性。


<details>
  <summary>Details</summary>
Motivation: 当前STAR-RIS研究普遍假设传输和反射系数（TRC）独立，本研究旨在探索采用耦合TRC相移模型的无人机搭载STAR-RIS（Aerial-STAR）系统，以应对现有模型的局限性，并优化多用户下行通信的效率。

Method: 本研究联合优化了无人机轨迹、基站主动波束成形向量和RIS被动TRC（设计为离散与连续混合动作），同时考虑无人机能量约束。提出了一种新型双Actor深度确定性策略梯度（DA-DDPG）算法，该算法使用两个独立的Actor网络处理高维混合动作空间。此外，还提出了一种基于调和平均指数（HFI）的奖励函数以确保通信公平性。

Result: 仿真结果表明，所提出的DA-DDPG算法在累积奖励方面比传统DDPG和DQN算法分别高出24%和97%。三维无人机轨迹优化比二维和高度优化方案提升通信效率28%。HFI奖励函数使服务质量（QoS）拒绝率降低41%。移动Aerial-STAR系统性能优于固定部署系统，且耦合相STAR-RIS优于双传输/反射RIS和传统RIS。同时发现RIS尺寸增大将增加无人机阻力及能耗。

Conclusion: 研究结果突显了Aerial-STAR系统的巨大潜力，以及所提出的DA-DDPG方法在优化其性能方面的有效性。这些发现证实了考虑耦合相STAR-RIS和先进优化策略对于提升未来无线通信系统性能的关键作用。

Abstract: This study departs from the prevailing assumption of independent Transmission
and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect
Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a
novel multi-user downlink communication system that leverages a UAV-mounted
STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key
contributions include the joint optimization of UAV trajectory, active
beamforming vectors at the base station, and passive RIS TRCs to enhance
communication efficiency, while considering UAV energy constraints. We design
the TRC as a combination of discrete and continuous actions, and propose a
novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The
algorithm relies on two separate actor networks for high-dimensional hybrid
action space. We also propose a novel harmonic mean index (HFI)-based reward
function to ensure communication fairness amongst users. For comprehensive
analysis, we study the impact of RIS size on UAV aerodynamics showing that it
increases drag and energy demand. Simulation results demonstrate that the
proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based
solutions by 24% and 97%, respectively, in accumulated reward.
Three-dimensional UAV trajectory optimization achieves 28% higher communication
efficiency compared to two-dimensional and altitude optimization. The HFI based
reward function provides 41% lower QoS denial rates as compared to other
benchmarks. The mobile Aerial-STAR system shows superior performance over fixed
deployed counterparts, with the coupled phase STAR-RIS outperforming dual
Transmit/Reflect RIS and conventional RIS setups. These findings highlight the
potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG
approach in optimizing their performance.

</details>


### [244] [Domino: Dominant Path-based Compensation for Hardware Impairments in Modern WiFi Sensing](https://arxiv.org/abs/2509.13807)
*Ruiqi Kong,He Chen*

Main category: eess.SP

TL;DR: Domino框架通过将信道状态信息（CSI）转换为信道冲激响应（CIR）并利用主导静态路径作为参考，有效补偿了现代WiFi硬件引起的射频失真，将WiFi传感精度提高了至少2倍。


<details>
  <summary>Details</summary>
Motivation: 现代WiFi（802.11ac/ax）硬件引入的复杂动态射频失真，严重影响了WiFi传感的可靠性，并使现有补偿方法失效。

Method: 引入Domino框架，将CSI转换为CIR，并利用硬件失真对所有信号路径的均匀影响，通过延迟域处理，以主导静态路径作为可靠参考进行精确失真补偿。

Result: 在呼吸监测实验中，Domino比现有方法平均精度高至少2倍，即使在单天线、直视和遮挡场景下，仍能保持稳健性能，中位误差低于0.24 bpm。

Conclusion: Domino框架有效解决了WiFi传感中硬件引起的射频失真问题，显著提升了传感精度和可靠性，尤其适用于呼吸监测等应用。

Abstract: WiFi sensing faces a critical reliability challenge due to hardware-induced
RF distortions, especially with modern, market-dominant WiFi cards supporting
802.11ac/ax protocols. These cards employ sensitive automatic gain control and
separate RF chains, introducing complex and dynamic distortions that render
existing compensation methods ineffective. In this paper, we introduce Domino,
a new framework that transforms channel state information (CSI) into channel
impulse response (CIR) and leverages it for precise distortion compensation.
Domino is built on the key insight that hardware-induced distortions impact all
signal paths uniformly, allowing the dominant static path to serve as a
reliable reference for effective compensation through delay-domain processing.
Real-world respiration monitoring experiments show that Domino achieves at
least 2x higher mean accuracy over existing methods, maintaining robust
performance with a median error below 0.24 bpm, even using a single antenna in
both direct line-of-sight and obstructed scenarios.

</details>


### [245] [Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems](https://arxiv.org/abs/2509.14201)
*Guangjin Pan,Liping Bai,Zhuojun Tian,Hui Chen,Mehdi Bennis,Henk Wymeersch*

Main category: eess.SP

TL;DR: 本文将主动推断框架（AIF）引入SCC赋能的无人机系统，实现联合状态估计、控制和传感资源分配，通过最小化自由能，有效降低了控制和传感成本。


<details>
  <summary>Details</summary>
Motivation: 现有的闭环感知、通信和控制（SCC）解决方案通常将感知与控制独立处理，导致性能不佳且资源利用率低下。

Method: 将主动推断框架（AIF）应用于SCC赋能的无人机（UAV）系统，用于联合状态估计、控制和传感资源分配。通过构建统一的生成模型，将问题转化为最小化用于推断的变分自由能和用于行动规划的期望自由能。

Result: 仿真结果表明，与基线方案相比，所提出的方法显著降低了控制成本和传感成本。

Conclusion: 主动推断框架能够有效地优化SCC-UAV系统的联合状态估计、控制和传感资源分配，从而降低总体运行成本。

Abstract: Integrated sensing and communication (ISAC) is a core technology for 6G, and
its application to closed-loop sensing, communication, and control (SCC)
enables various services. Existing SCC solutions often treat sensing and
control separately, leading to suboptimal performance and resource usage. In
this work, we introduce the active inference framework (AIF) into SCC-enabled
unmanned aerial vehicle (UAV) systems for joint state estimation, control, and
sensing resource allocation. By formulating a unified generative model, the
problem reduces to minimizing variational free energy for inference and
expected free energy for action planning. Simulation results show that both
control cost and sensing cost are reduced relative to baselines.

</details>


### [246] [Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device](https://arxiv.org/abs/2509.12510)
*Wei Shao,Ruoyu Zhang,Zequan Liang,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 本文提出一种创新的无监督PPG信号质量评估(SQA)方法，结合自监督学习(SSL)和拓扑数据分析(TDA)，生成对光学发射器和运动不变的信号嵌入，并通过聚类提供一个稳健的跨设备质量门控。


<details>
  <summary>Details</summary>
Motivation: 可穿戴光电容积描记(PPG)信号易受运动、灌注不足和环境光等因素干扰，严重影响下游心血管分析。现有信号质量评估方法要么依赖脆弱的启发式规则，要么需要大量标注数据，效率不高且难以泛化。

Method: 本研究引入了首个针对腕部PPG的全无监督SQA流程。第一阶段，使用对比学习的1-D ResNet-18模型，在276小时原始无标签异构数据上进行训练，学习生成对光学发射器和运动均不变的信号嵌入。第二阶段，通过持久同调(PH)将512维编码器嵌入转换为4维拓扑签名，并使用HDBSCAN对这些签名进行聚类。最密集的聚类被定义为可接受的PPG信号，其余则被认为是低质量信号，从而生成二元信号质量指数(SQI)。整个框架是一个混合自监督学习-拓扑数据分析(SSL-TDA)方案。

Result: 在不进行重新调优的情况下，该SQI在10,000个窗口的分层样本上，分别取得了0.72的Silhouette分数、0.34的Davies-Bouldin分数和6173的Calinski-Harabasz分数。

Conclusion: 本研究提出了一种混合自监督学习-拓扑数据分析(SSL-TDA)框架，为PPG信号提供了一个可即插即用、可扩展且跨设备的质量门控。

Abstract: Wearable photoplethysmography (PPG) is embedded in billions of devices, yet
its optical waveform is easily corrupted by motion, perfusion loss, and ambient
light, jeopardizing downstream cardiometric analytics. Existing signal-quality
assessment (SQA) methods rely either on brittle heuristics or on data-hungry
supervised models. We introduce the first fully unsupervised SQA pipeline for
wrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,
unlabeled data from heterogeneous sources (varying in device and sampling
frequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,
the learned representation is stable across differences in LED wavelength,
drive intensity, and device optics, as well as wrist motion). Stage 2 converts
each 512-D encoder embedding into a 4-D topological signature via persistent
homology (PH) and clusters these signatures with HDBSCAN. To produce a binary
signal-quality index (SQI), the acceptable PPG signals are represented by the
densest cluster while the remaining clusters are assumed to mainly contain
poor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,
Davies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,
respectively, on a stratified sample of 10,000 windows. In this study, we
propose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)
framework that offers a drop-in, scalable, cross-device quality gate for PPG
signals.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [247] [TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models](https://arxiv.org/abs/2509.13395)
*Haolong Zheng,Yekaterina Yegorova,Mark Hasegawa-Johnson*

Main category: eess.AS

TL;DR: 本文提出TICL方法，通过文本嵌入KNN提升语音上下文学习中上下文示例选择效率，无需微调即可显著增强多模态大模型在多种挑战性ASR任务上的语音识别能力，相对WER降低高达84.7%。


<details>
  <summary>Details</summary>
Motivation: 语音上下文学习（SICL）中，有效上下文示例的选择对性能至关重要，但目前相关选择方法尚缺乏深入探索。

Method: 提出Text-Embedding KNN for SICL (TICL)，一种利用语义上下文的简单管道。该方法通过KNN选择上下文示例，以增强现有多模态大模型的语音识别能力，且无需进行模型微调。

Result: 在口音英语、多语言语音和儿童语音等挑战性自动语音识别任务上，TICL方法使模型性能超越零样本表现，实现了高达84.7%的相对词错误率（WER）降低。通过消融研究证明了方法的鲁棒性和效率。

Conclusion: TICL方法能够有效且无需微调地提升多模态大模型的语音上下文学习能力，在多种挑战性ASR任务上表现出显著的性能提升和鲁棒性。

Abstract: Speech foundation models have recently demonstrated the ability to perform
Speech In-Context Learning (SICL). Selecting effective in-context examples is
crucial for SICL performance, yet selection methodologies remain underexplored.
In this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline
that uses semantic context to enhance off-the-shelf large multimodal models'
speech recognition ability without fine-tuning. Across challenging automatic
speech recognition tasks, including accented English, multilingual speech, and
children's speech, our method enables models to surpass zero-shot performance
with up to 84.7% relative WER reduction. We conduct ablation studies to show
the robustness and efficiency of our method.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [248] [Unleashing the power of computational insights in revealing the complexity of biological systems in the new era of spatial multi-omics](https://arxiv.org/abs/2509.13376)
*Zhiwei Fan,Tiangang Wang,Kexin Huang,Binwu Ying,Xiaobo Zhou*

Main category: q-bio.QM

TL;DR: 空间组学技术革新了生物研究。本综述系统回顾了空间多组学技术与计算算法的进展，展示了其在解析复杂生物过程中的应用，并展望了其在精准医疗中的未来。


<details>
  <summary>Details</summary>
Motivation: 旨在系统概述空间多组学技术和计算算法的持续进展，以期更深入、系统地理解哺乳动物组织和器官的结构与机制。

Method: 本综述通过系统概述空间多组学技术与计算算法的最新进展，并探讨先进机器学习算法和多组学整合建模的应用。

Result: 揭示了通过空间多组学、机器学习和整合建模，可以解码复杂的生物过程，如器官发育中的细胞空间组织和拓扑关系，以及肿瘤发生和转移中的关键分子特征和调控网络。

Conclusion: 展望了空间组学技术创新和建模洞察在精准医疗领域的未来发展方向。

Abstract: Recent advances in spatial omics technologies have revolutionized our ability
to study biological systems with unprecedented resolution. By preserving the
spatial context of molecular measurements, these methods enable comprehensive
mapping of cellular heterogeneity, tissue architecture, and dynamic biological
processes in developmental biology, neuroscience, oncology, and evolutionary
studies. This review highlights a systematic overview of the continuous
advancements in both technology and computational algorithms that are paving
the way for a deeper, more systematic comprehension of the structure and
mechanisms of mammalian tissues and organs by using spatial multi-omics. Our
viewpoint demonstrates how advanced machine learning algorithms and multi-omics
integrative modeling can decode complex biological processes, including the
spatial organization and topological relationships of cells during organ
development, as well as key molecular signatures and regulatory networks
underlying tumorigenesis and metastasis. Finally, we outline future directions
for technological innovation and modeling insights of spatial omics in
precision medicine.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [249] [A reduced-order derivative-informed neural operator for subsurface fluid-flow](https://arxiv.org/abs/2509.13620)
*Jeongjin,Park,Grant Bruer,Huseyin Tuna Erdinc,Abhinav Prakash Gahlot,Felix J. Herrmann*

Main category: physics.comp-ph

TL;DR: DeFINO是一种基于Fisher信息矩阵的导数感知神经算子训练框架，通过将Jacobian投影到主要特征方向，显著降低了计算成本，同时提高了梯度精度，适用于流体模拟和反演问题。


<details>
  <summary>Details</summary>
Motivation: 神经算子在流体模拟中作为替代模型很有前景，但下游任务（如优化和贝叶斯推断）对模型梯度的精度要求很高。现有物理信息方法虽然能利用导数信息提升精度，但显式Jacobian的计算成本随输入参数呈二次方增长，计算量巨大，因此需要一种既能保持梯度精度又能降低计算成本的方法。

Method: 本文提出了DeFINO（Derivative-based Fisher-score Informed Neural Operator），这是一个降阶的、导数感知的训练框架。它将傅里叶神经算子（FNOs）与一种由Fisher信息矩阵（FIM）指导的新型导数训练策略相结合，通过将Jacobian投影到FIM识别出的主特征方向上，捕获关键的敏感性信息，从而显著降低了计算开销。

Result: 通过地下多相流体模拟的合成实验验证，DeFINO在保持鲁棒的前向预测能力的同时，显著提高了梯度精度，并大幅降低了计算成本。

Conclusion: DeFINO为复杂现实世界中的反演问题提供了一种实用、可扩展且计算成本显著降低的解决方案。

Abstract: Neural operators have emerged as cost-effective surrogates for expensive
fluid-flow simulators, particularly in computationally intensive tasks such as
permeability inversion from time-lapse seismic data, and uncertainty
quantification. In these applications, the fidelity of the surrogate's
gradients with respect to system parameters is crucial, as the accuracy of
downstream tasks, such as optimization and Bayesian inference, relies directly
on the quality of the derivative information. Recent advances in
physics-informed methods have leveraged derivative information to improve
surrogate accuracy. However, incorporating explicit Jacobians can become
computationally prohibitive, as the complexity typically scales quadratically
with the number of input parameters. To address this limitation, we propose
DeFINO (Derivative-based Fisher-score Informed Neural Operator), a
reduced-order, derivative-informed training framework. DeFINO integrates
Fourier neural operators (FNOs) with a novel derivative-based training strategy
guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto
dominant eigen-directions identified by the FIM, DeFINO captures critical
sensitivity information directly informed by observational data, significantly
reducing computational expense. We validate DeFINO through synthetic
experiments in the context of subsurface multi-phase fluid-flow, demonstrating
improvements in gradient accuracy while maintaining robust forward predictions
of underlying fluid dynamics. These results highlight DeFINO's potential to
offer practical, scalable solutions for inversion problems in complex
real-world scenarios, all at substantially reduced computational cost.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [250] [Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging](https://arxiv.org/abs/2509.13372)
*Prahlad G Menon*

Main category: eess.IV

TL;DR: 一个AI流程能够从常规血管造影数据快速生成Fontan心脏病患者的3D几何结构和虚拟血流可视化，以辅助CFD分析和手术规划。


<details>
  <summary>Details</summary>
Motivation: Fontan术后患者的血流动力学失败与复杂血流模式难以通过传统2D成像精确表征。现有血管造影提供的3D几何信息有限，阻碍了计算流体动力学（CFD）分析和手术规划。

Method: 开发了一个多步骤AI流程，利用Google Gemini 2.5 Flash进行荧光血管造影图像的系统迭代处理。该流程包含医学图像预处理、血管分割、对比度增强、伪影去除和2D投影内的虚拟血流可视化。最终视图通过Tencent Hunyuan3D-2mini生成立体光刻（STL）文件。

Result: 该流程成功地从单视图血管造影图生成了几何优化的2D投影，经迭代细化后实现了准确的解剖学表示。最终投影准确保留了复杂的Fontan几何结构并增强了对比度，适用于3D转换。AI生成的虚拟血流可视化识别出中央连接处的停滞区和分支动脉中的血流模式。整个处理过程耗时不到15分钟。

Conclusion: 该方法证明了从常规血管造影数据生成CFD适用几何的临床可行性，实现了3D生成和快速虚拟血流可视化，为全面的CFD模拟提供了初步见解，并为普及高级几何和血流动力学分析奠定了基础。

Abstract: Fontan palliation for univentricular congenital heart disease progresses to
hemodynamic failure with complex flow patterns poorly characterized by
conventional 2D imaging. Current assessment relies on fluoroscopic angiography,
providing limited 3D geometric information essential for computational fluid
dynamics (CFD) analysis and surgical planning.
  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash
(2.5B parameters) for systematic, iterative processing of fluoroscopic
angiograms through transformer-based neural architecture. The pipeline
encompasses medical image preprocessing, vascular segmentation, contrast
enhancement, artifact removal, and virtual hemodynamic flow visualization
within 2D projections. Final views were processed through Tencent's
Hunyuan3D-2mini (384M parameters) for stereolithography file generation.
  The pipeline successfully generated geometrically optimized 2D projections
from single-view angiograms after 16 processing steps using a custom web
interface. Initial iterations contained hallucinated vascular features
requiring iterative refinement to achieve anatomically faithful
representations. Final projections demonstrated accurate preservation of
complex Fontan geometry with enhanced contrast suitable for 3D conversion.
AI-generated virtual flow visualization identified stagnation zones in central
connections and flow patterns in branch arteries. Complete processing required
under 15 minutes with second-level API response times.
  This approach demonstrates clinical feasibility of generating CFD-suitable
geometries from routine angiographic data, enabling 3D generation and rapid
virtual flow visualization for cursory insights prior to full CFD simulation.
While requiring refinement cycles for accuracy, this establishes foundation for
democratizing advanced geometric and hemodynamic analysis using readily
available imaging data.

</details>


### [251] [PREDICT-GBM: Platform for Robust Evaluation and Development of Individualized Computational Tumor Models in Glioblastoma](https://arxiv.org/abs/2509.13360)
*L. Zimmer,J. Weidner,M. Balcerak,F. Kofler,I. Ezhov,B. Menze,B. Wiestler*

Main category: eess.IV

TL;DR: 本文介绍了PREDICT-GBM平台，用于系统评估胶质母细胞瘤生长模型。研究表明，个性化放疗方案在复发覆盖率上优于传统方案，旨在加速模型临床转化。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤高度侵袭且复发率高，传统放疗未考虑患者特异性因素。尽管计算模型能预测肿瘤扩散，但临床应用受限，急需弥合转化鸿沟，加速模型开发与验证。

Method: 引入PREDICT-GBM，一个集成的建模与评估平台及数据集。该平台用于系统基准测试最先进的肿瘤生长模型，使用了包含255名受试者的专家精选临床数据集。研究将基于肿瘤生长预测的个性化放疗方案与传统统一边缘方法进行比较。

Result: 分析表明，对于所评估的模型中的两个，源自肿瘤生长预测的个性化放疗方案在复发覆盖率方面优于传统的统一边缘方法。

Conclusion: PREDICT-GBM为推进和系统评估尖端肿瘤生长建模方法提供了强大平台，最终目标是促进临床转化并改善患者预后。

Abstract: Glioblastoma is the most prevalent primary brain malignancy, distinguished by
its highly invasive behavior and exceptionally high rates of recurrence.
Conventional radiation therapy, which employs uniform treatment margins, fails
to account for patient-specific anatomical and biological factors that
critically influence tumor cell migration. To address this limitation, numerous
computational models of glioblastoma growth have been developed, enabling
generation of tumor cell distribution maps extending beyond radiographically
visible regions and thus informing more precise treatment strategies. However,
despite encouraging preliminary findings, the clinical adoption of these growth
models remains limited. To bridge this translational gap and accelerate both
model development and clinical validation, we introduce PREDICT-GBM, a
comprehensive integrated pipeline and dataset for modeling and evaluation. This
platform enables systematic benchmarking of state-of-the-art tumor growth
models using an expert-curated clinical dataset comprising 255 subjects with
complete tumor segmentations and tissue characterization maps. Our analysis
demonstrates that personalized radiation treatment plans derived from tumor
growth predictions achieved superior recurrence coverage compared to
conventional uniform margin approaches for two of the evaluated models. This
work establishes a robust platform for advancing and systematically evaluating
cutting-edge tumor growth modeling approaches, with the ultimate goal of
facilitating clinical translation and improving patient outcomes.

</details>
