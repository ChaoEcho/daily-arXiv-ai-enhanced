<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: 该研究提出一种新颖框架，利用大型语言模型（LLMs）的内部权重激活，通过剪枝算法构建语言的度量空间，揭示了106种语言的内在特征和相互联系。


<details>
  <summary>Details</summary>
Motivation: 传统的语言分析方法依赖手工设计的语言特征。本研究旨在突破这一局限，自动从LLMs中提取高维向量表示，以捕捉语言的内在特性，并构建一个反映语言学现象的度量空间。

Method: 引入一个新颖的框架，利用现代LLMs的内部权重激活来构建语言的度量空间。具体方法是通过一个适应性的剪枝算法计算权重重要性分数，从而自动推导出高维向量表示。

Result: 该方法在涵盖106种语言的多种数据集和多语言LLMs上进行了验证。结果显示，它与已建立的语言家族高度吻合，并且揭示了可能指示历史接触或语言演变的意外语言间联系。

Conclusion: 本研究成功地利用LLM内部权重构建了语言的度量空间，有效捕捉了语言的内在特性，并为语言分类和演变研究提供了新的视角和发现。

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [2] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: 研究LLM生成的合成QA数据能否作为人工基准的有效替代品来评估RAG系统。


<details>
  <summary>Details</summary>
Motivation: 当缺乏人工标注基准数据时，探究由大型语言模型（LLMs）生成的合成问答（QA）数据是否能作为评估检索增强生成（RAG）系统的可靠替代品。

Method: 通过两项实验评估合成基准的可靠性：一项实验固定生成器并改变检索器参数，另一项实验固定检索器并改变生成器架构。实验在四个数据集（两个开放域，两个专有）上进行。

Result: 研究发现，合成基准在评估不同检索器配置的RAG系统时能可靠地排名，且与人工标注基准表现一致。然而，在比较不同生成器架构时，合成基准未能产生一致的RAG排名。

Conclusion: 合成QA数据可有效用于评估RAG系统中的检索器配置，但由于可能存在的任务不匹配和对特定生成器的风格偏见，不适用于评估生成器架构。

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [3] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 本研究将模仿学习应用于对话生成，成功训练出对话策略和判别器。判别器揭示了对话模型的局限性，并提出该技术可用于识别对话数据模型的异常行为。


<details>
  <summary>Details</summary>
Motivation: 在缺乏奖励信号的情况下，利用专家演示通过模仿学习创建对话策略，以实现与用户进行对话。

Method: 将模仿学习应用于对话任务，训练了一个能根据提示与用户对话的策略模型，以及一个能区分专家对话和合成对话的判别器。

Result: 所训练的对话策略是有效的。然而，判别器的分析结果揭示了现有对话模型的局限性。

Conclusion: 该研究表明，所采用的技术（特别是判别器）可用于识别和揭示面向对话任务的任意数据模型的不足或异常行为。

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [4] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: 研究了低资源Faetar ASR基准测试中的转录不一致性，发现其并非主要挑战；词级别二元语言模型无益，但有限词典解码有益；该任务仍极具挑战性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探究在具有挑战性的低资源自动语音识别（ASR）基准测试Faetar中，转录不一致性所扮演的角色，并评估不同语言模型和解码策略的影响。

Method: 研究通过构建一个小型手工词典来分析转录不一致性。此外，还评估了词级别二元语言模型（bigram word-based language modelling）和有限词典解码约束（constraining decoding to a finite lexicon）对Faetar ASR任务性能的影响。

Result: 研究发现Faetar转录中确实存在不一致性，但其并非该任务的主要挑战。词级别二元语言模型并未带来额外收益，但将解码限制在有限词典内可能有所裨益。

Conclusion: 尽管尝试了不同的方法，Faetar ASR任务仍然极其困难，转录不一致性并非主要症结所在。

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [5] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: 研究评估大型语言模型（LLMs）在学术同行评审中的文本处理能力，发现其表现不佳，不建议在同行评审中未经检查地使用LLMs。


<details>
  <summary>Details</summary>
Motivation: 围绕大型语言模型（LLMs）能否辅助科学发现，尤其是在学术同行评审中的应用，存在激烈争论。本研究旨在评估LLMs在学术文本处理方面的实际应用潜力。

Method: 研究设计了一个结构化工作流程来评估LLMs处理学术文本的能力，包括四个任务：内容复现/比较/评分/反思。每个任务都要求LLM扮演特定角色。输入文本选用信息系统领域顶级期刊的一流文章。采用多种文本度量标准进行内部、外部（与真值比较）和人工评估，测试了Google的Gemini模型，并考察了提示词变化的影响。

Result: 领先的LLM（Google Gemini）表现不佳：其学术文本总结和转述可接受；通过成对文本比较进行排名扩展性差；用于学术文本评分时鉴别力差；对文本的定性反思虽然自洽但缺乏洞察力，难以激发有意义的研究。这些证据表明不应过度认可LLMs的文本处理能力，且结果在不同评估方法和提示词变化下均保持一致。

Conclusion: 总体而言，研究不建议在构建同行评审时未经检查地使用大型语言模型。

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 为满足消防通道的关键安全需求，提出并评估了一种基于深度学习的实时吸烟检测系统，该系统在复杂监控环境下表现优异，并能在边缘设备上高效运行。


<details>
  <summary>Details</summary>
Motivation: 由于消防通道区域存在关键安全要求，需要开发一个实时吸烟检测系统，以监控公共安全并实现自动法规遵从。

Method: 构建了一个包含8124张图片（包括2708张低光照样本）的数据集。评估了YOLOv8、YOLOv11和YOLOv12三种先进目标检测模型，并开发了一个基于YOLOv8并为复杂监控环境优化的定制模型。

Result: 所提出的定制模型性能最佳，召回率达78.90%，mAP@50达83.70%。在多线程操作下，Jetson Xavier NX边缘设备上的推理时间为52至97毫秒，证实其适用于时间敏感操作。

Conclusion: 该系统提供了一个强大且适应性强的平台，可用于监控公共安全并实现自动法规遵从。

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [7] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 研究人员仅使用程序化数据训练表示模型，并结合视觉记忆应用于多种视觉任务，实现了与真实数据模型相当的性能，尤其在细粒度分类和零样本分割上表现出色，同时保持了对真实世界的完全隔离。


<details>
  <summary>Details</summary>
Motivation: 旨在探索仅使用程序化数据训练的模型能否在不依赖真实世界图像的情况下，在各种视觉任务上实现强大的性能，并达到对真实数据的完全隔离，以解决隐私或数据获取限制等问题。

Method: 通过仅使用程序化数据训练表示模型，并利用一个显式的参考图像嵌入数据库（即视觉记忆）来执行视觉相似性、分类和语义分割任务，无需在真实数据上进行额外训练。

Result: 与在Places数据集上训练的模型相比，该程序化模型在NIGHTS视觉相似性任务上性能差距在1%以内，在CUB200和Flowers102细粒度分类上分别优于8%和15%，在ImageNet-1K分类上性能差距在10%以内。此外，在COCO零样本分割任务上，其R^2值与真实数据训练的模型仅相差10%。研究还发现，程序化模型中同一对象的不同部分可能具有不相似的表示，这解释了性能差距的原因。

Conclusion: 仅用程序化数据训练的模型结合视觉记忆，可以有效应对多种视觉任务，并展现出与真实数据训练模型相当的强大性能，尤其在细粒度分类和零样本分割方面有优势。其独特之处在于实现了对真实数据的完全隔离。未来可通过解决同对象部分表示不一致的问题来进一步提升性能。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 该论文提出了一种名为有限自动机提取（FAE）的新方法，通过使用新颖的领域特定语言（Retro Coder）从游戏视频中学习神经符号世界模型，解决了传统世界模型在可迁移性和可解释性方面的挑战，并实现了更精确和通用的模型。


<details>
  <summary>Details</summary>
Motivation: 传统的基于神经网络的世界模型在学习到的环境动态的可迁移性和可解释性方面面临挑战。

Method: 提出有限自动机提取（FAE）方法，该方法从以新型领域特定语言（DSL）Retro Coder表示的游戏视频中，学习神经符号世界模型。

Result: 与现有世界模型方法相比，FAE能够学习到更精确的环境模型；与现有基于DSL的方法相比，FAE能生成更通用的代码。

Conclusion: FAE提供了一种有效的方法来学习神经符号世界模型，克服了传统方法在模型精度和代码通用性上的局限，从而实现了更精确且通用的环境表示。

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: 为解决多上下文RAG场景下LLM长序列推理中KV缓存的效率问题，本文提出了SamKV，一种首次用于多上下文KV缓存的注意力稀疏化方法，能在不影响准确率的情况下显著压缩序列长度并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长序列推理中面临高昂成本。现有KV缓存复用和稀疏化方法仅限于单上下文场景，在RAG等多上下文场景中因上下文独立计算且缺乏交叉注意力而失效，导致无法有效降低内存开销和提升效率。

Method: 本文提出了SamKV，首次探索了多上下文KV缓存的注意力稀疏化。具体方法是在稀疏化某一上下文时，考虑其他上下文的互补信息，然后对稀疏化的信息进行局部重计算。

Result: 实验结果表明，与完全重计算基线相比，SamKV在不损失准确率的情况下将序列长度压缩至15%，显著提升了多上下文RAG场景下的吞吐量。

Conclusion: SamKV成功解决了多上下文RAG场景中KV缓存稀疏化的挑战，通过创新的注意力稀疏化和局部重计算机制，实现了显著的序列长度压缩和吞吐量提升，同时保持了模型准确性。

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [10] [OddEEC: A New Sketch Technique for Error Estimating Coding](https://arxiv.org/abs/2508.11842)
*Huayi Wang,Jingfan Meng,Jun Xu*

Main category: cs.NI

TL;DR: 提出了一种名为OddEEC的新型错误估计编码方案，它基于Odd Sketch技术，实现了与现有方案相当的估计精度，但解码复杂度大大降低。


<details>
  <summary>Details</summary>
Motivation: 错误估计编码(EEC)是无线网络中估计数据包传输期间比特错误数量的标准技术。本研究旨在提出一种新颖的EEC方案，以应对现有技术中的新挑战。

Method: 本研究提出OddEEC方案，它是数据素描技术Odd Sketch在EEC中的非平凡改编，通过其位采样技术和最大似然估计器来解决相关挑战。

Result: 实验结果表明，OddEEC的整体估计精度与gEEC和mEEC等竞争方案相当，但其解码复杂度显著降低。

Conclusion: OddEEC是一种具有竞争力的EEC方案，它在保持相似估计精度的同时，大大降低了解码复杂度，从而提供了更高效的错误估计方法。

Abstract: Error estimating coding (EEC) is a standard technique for estimating the
number of bit errors during packet transmission over wireless networks. In this
paper, we propose OddEEC, a novel EEC scheme. OddEEC is a nontrivial adaptation
of a data sketching technique named Odd Sketch to EEC, addressing new
challenges therein by its bit sampling technique and maximum likelihood
estimator. Our experiments show that OddEEC overall achieves comparable
estimation accuracy as competing schemes such as gEEC and mEEC, with much
smaller decoding complexity.

</details>


### [11] [Bandit-Based Charging with Beamforming for Mobile Wireless-Powered IoT Systems](https://arxiv.org/abs/2508.11971)
*Chenchen Fu,Zining Zhou,Xiaoxing Qiu,Sujunjie Sun,Weiwei Wu,Song Han*

Main category: cs.NI

TL;DR: 提出一种基于bandit算法的充电框架，解决移动充电器在动态信道和实时约束下的无线供电物联网（WP-IoT）系统充电问题。


<details>
  <summary>Details</summary>
Motivation: 现有的移动充电器无线供电物联网（WP-IoT）研究忽略了动态信道条件和充电调度中的实时约束（如充电器有限的能量预算和严格的充电截止日期）。

Method: 提出一个基于bandit算法的WP-IoT充电框架，考虑实际波束成形能力和实时充电约束。制定了联合决定充电位置、持续时间和波束成形配置的时空充电策略。通过区域离散化实现多项式时间枚举。提出了两种在线bandit算法，适用于静态和非静态未知信道状态场景，并具有有界后悔。

Result: 实验结果验证了所提出的算法能快速接近理论上限，并有效跟踪动态信道状态进行自适应调整。

Conclusion: 所提出的基于bandit算法的框架及其算法能有效解决移动充电器在动态信道和实时约束下为WP-IoT系统供电的挑战，并表现出良好的性能。

Abstract: Wireless power transfer (WPT) is increasingly used to sustain
Internet-of-Things (IoT) systems by wirelessly charging embedded devices.
Mobile chargers further enhance scalability in wireless-powered IoT (WP-IoT)
networks, but pose new challenges due to dynamic channel conditions and limited
energy budgets. Most existing works overlook such dynamics or ignore real-time
constraints on charging schedules. This paper presents a bandit-based charging
framework for WP-IoT systems using mobile chargers with practical beamforming
capabilities and real-time charging constraints. We explicitly consider
time-varying channel state information (CSI) and impose a strict charging
deadline in each round, which reflects the hard real-time constraint from the
charger's limited battery capacity. We formulate a temporal-spatial charging
policy that jointly determines the charging locations, durations, and
beamforming configurations. Area discretization enables polynomial-time
enumeration with constant approximation bounds. We then propose two online
bandit algorithms for both stationary and non-stationary unknown channel state
scenarios with bounded regrets. Our extensive experimental results validate
that the proposed algorithms can rapidly approach the theoretical upper bound
while effectively tracking the dynamic channel states for adaptive adjustment.

</details>
