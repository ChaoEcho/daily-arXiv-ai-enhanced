<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 4]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning](https://arxiv.org/abs/2505.00001)
*Shaun Baek,Shaun Esua-Mensah,Cyrus Tsui,Sejan Vigneswaralingam,Abdullah Alali,Michael Lu,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 提出Rosetta-PL基准评估大型语言模型在受控低资源环境下的逻辑推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）主要在高资源自然语言上训练，这限制了它们在低资源环境和需要深度逻辑推理任务中的有效性。

Method: 构建Rosetta-PL基准：将Lean语言的逻辑命题数据集翻译成自定义逻辑语言，并使用该数据集微调LLM（如GPT-4o）。通过实验分析数据集大小和翻译方法对模型性能的影响。

Result: 在翻译过程中保持逻辑关系能显著提高精确度。当训练样本量达到约20,000个之后，准确率趋于平稳。

Conclusion: 该研究为优化LLM在形式推理任务中的训练以及提升其在低资源语言应用中的性能提供了有价值的指导方针。

Abstract: Large Language Models (LLMs) are primarily trained on high-resource natural
languages, limiting their effectiveness in low-resource settings and in tasks
requiring deep logical reasoning. This research introduces Rosetta-PL, a
benchmark designed to evaluate LLMs' logical reasoning and generalization
capabilities in a controlled environment. We construct Rosetta-PL by
translating a dataset of logical propositions from Lean into a custom logical
language, which is then used to fine-tune an LLM (e.g., GPT-4o). Our
experiments analyze the impact of the size of the dataset and the translation
methodology on the performance of the model. Our results indicate that
preserving logical relationships in the translation process significantly
boosts precision, with accuracy plateauing beyond roughly 20,000 training
samples. These insights provide valuable guidelines for optimizing LLM training
in formal reasoning tasks and improving performance in various low-resource
language applications.

</details>


### [2] [Symbol grounding in computational systems: A paradox of intentions](https://arxiv.org/abs/2505.00002)
*Vincent C. Müller*

Main category: cs.CL

TL;DR: 该论文指出计算主义（心智即计算机）在解释符号接地时存在悖论：无论心智计算的是有意义还是无意义的符号，最终都指向语义先天论。


<details>
  <summary>Details</summary>
Motivation: 探讨计算主义理论是否能够解释符号接地（符号如何获得意义）的问题。

Method: 通过逻辑分析，考察计算主义下的两种情况：心智处理有意义的符号或无意义的符号，并推导这两种情况对符号接地的影响。

Result: 1. 若心智处理有意义符号，则其功能预设了意义的存在，意味着语义先天论。 2. 若心智处理无意义符号，则在符号接地之前不存在意向认知过程，而符号接地本身又需要意向认知过程，导致符号接地无法发生。

Conclusion: 无论在哪种情况下，计算主义都无法回避语义先天论（即某些意义是天生的），这揭示了计算主义在解释符号接地方面的一个核心困难。

Abstract: The paper presents a paradoxical feature of computational systems that
suggests that computationalism cannot explain symbol grounding. If the mind is
a digital computer, as computationalism claims, then it can be computing either
over meaningful symbols or over meaningless symbols. If it is computing over
meaningful symbols its functioning presupposes the existence of meaningful
symbols in the system, i.e. it implies semantic nativism. If the mind is
computing over meaningless symbols, no intentional cognitive processes are
available prior to symbol grounding. In this case, no symbol grounding could
take place since any grounding presupposes intentional cognitive processes. So,
whether computing in the mind is over meaningless or over meaningful symbols,
computationalism implies semantic nativism.

</details>


### [3] [The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs](https://arxiv.org/abs/2505.00003)
*Zizhou Liu,Ziwei Gong,Lin Ai,Zheng Hui,Run Chen,Colin Wayne Leach,Michelle R. Greene,Julia Hirschberg*

Main category: cs.CL

TL;DR: 这篇论文综述了心理学理论如何促进大型语言模型（LLM）的发展。


<details>
  <summary>Details</summary>
Motivation: 鉴于心理学曾推动NLP的关键突破，并且LLMs日益复杂，研究者认为心理学对于实现类人认知、行为和交互至关重要。

Method: 通过回顾和整合认知心理学、发展心理学、行为心理学、社会心理学、人格心理学和心理语言学的理论，分析它们如何应用于LLM开发的不同阶段（数据、预训练、后训练、评估与应用）。

Result: 分析突出了当前心理学理论在LLM应用中的趋势和不足，并指出了跨领域的联系与矛盾之处。

Conclusion: 旨在弥合心理学与NLP之间的学科鸿沟，推动未来研究中更深入、更审慎地整合心理学知识。

Abstract: Psychological insights have long shaped pivotal NLP breakthroughs, including
the cognitive underpinnings of attention mechanisms, formative reinforcement
learning, and Theory of Mind-inspired social modeling. As Large Language Models
(LLMs) continue to grow in scale and complexity, there is a rising consensus
that psychology is essential for capturing human-like cognition, behavior, and
interaction. This paper reviews how psychological theories can inform and
enhance stages of LLM development, including data, pre-training, post-training,
and evaluation\&application. Our survey integrates insights from cognitive,
developmental, behavioral, social, personality psychology, and
psycholinguistics. Our analysis highlights current trends and gaps in how
psychological theories are applied. By examining both cross-domain connections
and points of tension, we aim to bridge disciplinary divides and promote more
thoughtful integration of psychology into future NLP research.

</details>


### [4] [LangVAE and LangSpace: Building and Probing for Language Model VAEs](https://arxiv.org/abs/2505.00004)
*Danilo S. Carvalho,Yingji Zhang,Harriet Unsworth,André Freitas*

Main category: cs.CL

TL;DR: 提出 LangVAE 框架，利用预训练大语言模型构建变分自编码器（VAE）以生成紧凑、解耦的文本表示，并提供 LangSpace 框架用于分析这些表示。


<details>
  <summary>Details</summary>
Motivation: 需要一种方法将预训练大语言模型（LLMs）的知识编码成更紧凑且语义解耦的表示，并系统地分析这些表示的特性。

Method: 开发了 LangVAE 框架，模块化地在预训练 LLMs 基础上构建 VAE。同时开发了 LangSpace 框架，包含向量遍历、插值、解耦度量和聚类可视化等探测方法来分析 LangVAE 生成的表示。进行了不同编码器/解码器组合的实验。

Result: LangVAE 和 LangSpace 提供了一种灵活、高效且可扩展的方式来构建和分析文本表示，并能轻松集成 HuggingFace Hub 上的模型。实验揭示了不同模型架构和尺寸在泛化性和解耦性方面存在广泛的交互作用。

Conclusion: 该研究提出的框架为系统化实验和理解基于 LLMs 的文本表示提供了一个有前景的途径。

Abstract: We present LangVAE, a novel framework for modular construction of variational
autoencoders (VAEs) on top of pre-trained large language models (LLMs). Such
language model VAEs can encode the knowledge of their pre-trained components
into more compact and semantically disentangled representations. The
representations obtained in this way can be analysed with the LangVAE companion
framework: LangSpace, which implements a collection of probing methods, such as
vector traversal and interpolation, disentanglement measures, and cluster
visualisations. LangVAE and LangSpace offer a flexible, efficient and scalable
way of building and analysing textual representations, with simple integration
for models available on the HuggingFace Hub. Additionally, we conducted a set
of experiments with different encoder and decoder combinations, as well as
annotated inputs, revealing a wide range of interactions across architectural
families and sizes w.r.t. generalisation and disentanglement. Our findings
demonstrate a promising framework for systematising the experimentation and
understanding of textual representations.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [Learning to Borrow Features for Improved Detection of Small Objects in Single-Shot Detectors](https://arxiv.org/abs/2505.00044)
*Richard Schmit*

Main category: cs.CV

TL;DR: 提出一种新框架，通过让小目标特征“借用”同类大目标的判别性特征，提升单阶段检测器对小目标的检测性能。


<details>
  <summary>Details</summary>
Motivation: 单阶段目标检测器在检测小物体时面临挑战，因为卷积特征图在空间分辨率和语义丰富度之间存在固有的权衡。

Method: 在SSD框架基础上，引入三个新模块：特征匹配块（FMB）识别跨层相似描述符，特征表示块（FRB）加权聚合生成增强的浅层特征，特征融合块（FFB）融合原始、借用和上下文信息优化特征图。

Result: 实验结果表明，该方法显著提升了小目标检测的准确率，优于基线方法。

Conclusion: 该方法有效提升了浅层特征的描述能力，同时保持了实时性能，为小目标检测提供了有前景的方向。

Abstract: Detecting small objects remains a significant challenge in single-shot object
detectors due to the inherent trade-off between spatial resolution and semantic
richness in convolutional feature maps. To address this issue, we propose a
novel framework that enables small object representations to "borrow"
discriminative features from larger, semantically richer instances within the
same class. Our architecture introduces three key components: the Feature
Matching Block (FMB) to identify semantically similar descriptors across
layers, the Feature Representing Block (FRB) to generate enhanced shallow
features through weighted aggregation, and the Feature Fusion Block (FFB) to
refine feature maps by integrating original, borrowed, and context information.
Built upon the SSD framework, our method improves the descriptive capacity of
shallow layers while maintaining real-time detection performance. Experimental
results demonstrate that our approach significantly boosts small object
detection accuracy over baseline methods, offering a promising direction for
robust object detection in complex visual environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Position Paper: Towards Open Complex Human-AI Agents Collaboration System for Problem-Solving and Knowledge Management](https://arxiv.org/abs/2505.00018)
*Ju Wu,Calvin K. L. Or*

Main category: cs.AI

TL;DR: 该立场文件回顾了近期人机协作的实证研究，指出了缺乏统一理论框架的问题，并提出了一种新的概念架构（分层探索-利用网络）来整合不同研究并指导未来。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能与人类协作研究在技术上取得进展，但缺乏一个统一的理论框架来整合各种方法，特别是在处理开放式、复杂任务时。

Method: 提出一个新的概念架构（分层探索-利用网络），系统地连接多智能体协调、知识管理、控制反馈和高层控制，并将现有技术（符号AI、LLM智能体、混合实践）映射到该框架上。

Result: 该框架有助于修订现有方法，启发结合定性和定量范式的新工作，并为设计人机共生系统提供参考。

Conclusion: 提出的框架和见解为实现人类认知与人工智能能力的更深层次共同进化提供了基础。

Abstract: This position paper critically surveys a broad spectrum of recent empirical
developments on human-AI agents collaboration, highlighting both their
technical achievements and persistent gaps. We observe a lack of a unifying
theoretical framework that can coherently integrate these varied studies,
especially when tackling open-ended, complex tasks. To address this, we propose
a novel conceptual architecture: one that systematically interlinks the
technical details of multi-agent coordination, knowledge management, cybernetic
feedback loops, and higher-level control mechanisms. By mapping existing
contributions, from symbolic AI techniques and connectionist LLM-based agents
to hybrid organizational practices, onto this proposed framework (Hierarchical
Exploration-Exploitation Net), our approach facilitates revision of legacy
methods and inspires new work that fuses qualitative and quantitative
paradigms. The paper's structure allows it to be read from any section, serving
equally as a critical review of technical implementations and as a
forward-looking reference for designing or extending human-AI symbioses.
Together, these insights offer a stepping stone toward deeper co-evolution of
human cognition and AI capability.

</details>
