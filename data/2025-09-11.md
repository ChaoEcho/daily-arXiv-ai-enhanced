<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 19]
- [cs.CV](#cs.CV) [Total: 19]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.LG](#cs.LG) [Total: 18]
- [cs.NI](#cs.NI) [Total: 7]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Bilingual Word Level Language Identification for Omotic Languages](https://arxiv.org/abs/2509.07998)
*Mesay Gemeda Yigezu,Girma Yohannis Bade,Atnafu Lambebo Tonja,Olga Kolesnikova,Grigori Sidorov,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 本文针对埃塞俄比亚南部Wolaita和Gofa两种语言的双语识别（BLID）问题，提出并评估了多种方法。结合BERT预训练模型和LSTM的方法表现最佳，在测试集上F1分数为0.72。


<details>
  <summary>Details</summary>
Motivation: 在多语言社区中，文本常包含多种语言。由于Wolaita和Gofa这两种语言之间词汇存在相似性和差异性，使得其双语识别（BLID）任务极具挑战性，因此需要开发有效方法来克服这一挑战。

Method: 采用了多种方法进行实验。其中，结合了基于BERT的预训练语言模型和LSTM的方法被采用并评估。

Result: 结合BERT预训练语言模型和LSTM的方法表现最佳，在测试集上取得了0.72的F1分数。

Conclusion: 本研究工作将有效解决社交媒体中不必要的语言问题，并为该领域的进一步研究奠定基础。

Abstract: Language identification is the task of determining the languages for a given
text. In many real world scenarios, text may contain more than one language,
particularly in multilingual communities. Bilingual Language Identification
(BLID) is the task of identifying and distinguishing between two languages in a
given text. This paper presents BLID for languages spoken in the southern part
of Ethiopia, namely Wolaita and Gofa. The presence of words similarities and
differences between the two languages makes the language identification task
challenging. To overcome this challenge, we employed various experiments on
various approaches. Then, the combination of the BERT based pretrained language
model and LSTM approach performed better, with an F1 score of 0.72 on the test
set. As a result, the work will be effective in tackling unwanted social media
issues and providing a foundation for further research in this area.

</details>


### [2] [AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs](https://arxiv.org/abs/2509.08000)
*Debdeep Sanyal,Manodeep Ray,Murari Mandal*

Main category: cs.CL

TL;DR: 本文提出AntiDote，一种双层优化方法，旨在使开源大语言模型（LLMs）抵抗恶意微调攻击，从而在保持通用能力的同时，有效防止安全防护被擦除。


<details>
  <summary>Details</summary>
Motivation: 开源LLMs在推动研究的同时，也带来了被恶意微调以生成有害内容的风险。现有安全措施难以在保留模型通用能力的前提下，有效抵抗拥有完全模型访问权限的对手通过参数微调擦除安全防护。

Method: 引入AntiDote，一个双层优化过程。该方法涉及一个辅助对抗性超网络，它根据防御模型的内部激活学习生成恶意的LoRA权重。防御型LLM随后被训练以抵消这些对抗性权重添加的影响，从而强制模型维持其安全对齐。

Result: AntiDote在52种红队攻击（包括越狱提示、潜在空间操纵和直接权重空间攻击）中被验证，其鲁棒性比防篡改和遗忘基线提高了高达27.4%。同时，它对模型效用影响极小，在MMLU、HellaSwag和GSM8K等能力基准测试中，性能下降不到0.5%。

Conclusion: 该工作提供了一种实用且计算高效的方法，用于构建安全性更强、更具韧性的开源模型，使其安全性成为一个更内在和更具弹性的特性。

Abstract: The release of open-weight large language models (LLMs) creates a tension
between advancing accessible research and preventing misuse, such as malicious
fine-tuning to elicit harmful content. Current safety measures struggle to
preserve the general capabilities of the LLM while resisting a determined
adversary with full access to the model's weights and architecture, who can use
full-parameter fine-tuning to erase existing safeguards. To address this, we
introduce AntiDote, a bi-level optimization procedure for training LLMs to be
resistant to such tampering. AntiDote involves an auxiliary adversary
hypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA)
weights conditioned on the defender model's internal activations. The defender
LLM is then trained with an objective to nullify the effect of these
adversarial weight additions, forcing it to maintain its safety alignment. We
validate this approach against a diverse suite of 52 red-teaming attacks,
including jailbreak prompting, latent space manipulation, and direct
weight-space attacks. AntiDote is upto 27.4\% more robust against adversarial
attacks compared to both tamper-resistance and unlearning baselines. Crucially,
this robustness is achieved with a minimal trade-off in utility, incurring a
performance degradation of upto less than 0.5\% across capability benchmarks
including MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute
efficient methodology for building open-weight models where safety is a more
integral and resilient property.

</details>


### [3] [MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values](https://arxiv.org/abs/2509.08022)
*Yao Liang,Dongcheng Zhao,Feifei Zhao,Guobin Shen,Yuwei Wang,Dongqi Liang,Yi Zeng*

Main category: cs.CL

TL;DR: 本研究引入MVPBench，一个评估大型语言模型（LLM）在75个国家多维度人类价值偏好对齐的新基准。发现现有LLM存在显著的地域和人口对齐差异，并证明轻量级微调方法可有效提升对齐性能。


<details>
  <summary>Details</summary>
Motivation: LLM与人类价值观的对齐对其安全有效部署至关重要，但现有对齐基准忽视文化和人口多样性，导致对LLM价值对齐的全球泛化能力理解不足。

Method: 引入了MVPBench，一个包含24,020个高质量实例的新基准，用于系统评估LLM在75个国家的多维度人类价值偏好对齐。该基准包含细粒度价值标签、个性化问题和丰富的人口统计元数据。使用MVPBench分析了SOTA LLM，并探索了LoRA和DPO等轻量级微调方法。

Result: 分析揭示了SOTA LLM在地域和人口层面存在显著的价值对齐性能差异。同时，轻量级微调方法（如LoRA和DPO）能够显著增强LLM在域内和域外设置中的价值对齐。

Conclusion: 研究强调了进行人口感知对齐评估的必要性，并为构建文化适应性强、价值敏感的LLM提供了实用见解。MVPBench为全球对齐、个性化价值建模和公平AI的未来研究奠定了基础。

Abstract: The alignment of large language models (LLMs) with human values is critical
for their safe and effective deployment across diverse user populations.
However, existing benchmarks often neglect cultural and demographic diversity,
leading to limited understanding of how value alignment generalizes globally.
In this work, we introduce MVPBench, a novel benchmark that systematically
evaluates LLMs' alignment with multi-dimensional human value preferences across
75 countries. MVPBench contains 24,020 high-quality instances annotated with
fine-grained value labels, personalized questions, and rich demographic
metadata, making it the most comprehensive resource of its kind to date. Using
MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,
revealing substantial disparities in alignment performance across geographic
and demographic lines. We further demonstrate that lightweight fine-tuning
methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization
(DPO), can significantly enhance value alignment in both in-domain and
out-of-domain settings. Our findings underscore the necessity for
population-aware alignment evaluation and provide actionable insights for
building culturally adaptive and value-sensitive LLMs. MVPBench serves as a
practical foundation for future research on global alignment, personalized
value modeling, and equitable AI development.

</details>


### [4] [NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment](https://arxiv.org/abs/2509.08025)
*Hoang-Trung Nguyen,Tan-Minh Nguyen,Xuan-Bach Le,Tuan-Kiet Le,Khanh-Huyen Nguyen,Ha-Thanh Nguyen,Thi-Hai-Yen Vuong,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: NOWJ团队在COLIEE 2025比赛中提交了所有五项任务的方法和结果，尤其在法律案例蕴含任务（Task 2）中通过混合模型获得了第一名。


<details>
  <summary>Details</summary>
Motivation: 参与COLIEE 2025比赛并展示法律信息处理方面的进步，特别是法律案例蕴含任务。

Method: 综合方法结合了预排序模型（BM25, BERT, monoT5）、基于嵌入的语义表示（BGE-m3, LLM2Vec）以及先进的大型语言模型（Qwen-2, QwQ-32B, DeepSeek-V3）进行摘要、相关性评分和上下文重排序。在Task 2中，采用了词汇语义过滤与上下文LLM分析相结合的两阶段检索系统。其他任务则通过精心设计的集成和基于提示的推理策略实现。

Result: 在法律案例蕴含任务（Task 2）中获得第一名，F1分数为0.3195。在法律案例检索、法规检索、法律文本蕴含和法律判决预测等其他任务中也表现出稳健的性能。

Conclusion: 研究结果强调了将传统信息检索技术与当代生成模型相结合的混合模型的潜力，为未来法律信息处理的进步提供了有价值的参考。

Abstract: This paper presents the methodologies and results of the NOWJ team's
participation across all five tasks at the COLIEE 2025 competition, emphasizing
advancements in the Legal Case Entailment task (Task 2). Our comprehensive
approach systematically integrates pre-ranking models (BM25, BERT, monoT5),
embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large
Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance
scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage
retrieval system combined lexical-semantic filtering with contextualized LLM
analysis, achieving first place with an F1 score of 0.3195. Additionally, in
other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal
Textual Entailment, and Legal Judgment Prediction--we demonstrated robust
performance through carefully engineered ensembles and effective prompt-based
reasoning strategies. Our findings highlight the potential of hybrid models
integrating traditional IR techniques with contemporary generative models,
providing a valuable reference for future advancements in legal information
processing.

</details>


### [5] [SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery](https://arxiv.org/abs/2509.08032)
*Fengyu She,Nan Wang,Hongfei Wu,Ziyi Wan,Jingmian Wang,Chang Wang*

Main category: cs.CL

TL;DR: 本文提出SciGPT，一个基于Qwen3架构的领域适应性基础模型，专为科学文献理解设计，并引入ScienceBench作为评估基准。SciGPT通过低成本领域蒸馏、稀疏MoE注意力机制和知识感知适应性创新，在核心科学任务上超越GPT-4o，并在未见任务上表现出强大的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 科学文献呈指数级增长，导致研究人员高效合成知识面临瓶颈。通用大型语言模型难以捕捉科学领域特定细微差别（如专业术语、方法严谨性）并处理复杂科学任务，限制了其在跨学科研究中的效用。

Method: 提出SciGPT，一个基于Qwen3架构的领域适应性基础模型，用于科学文献理解。核心创新包括：1) 通过两阶段流水线实现低成本领域蒸馏；2) 采用稀疏专家混合（SMoE）注意力机制，将32,000-token长文档推理的内存消耗降低55%；3) 整合领域本体的知识感知适应性。同时，还发布了ScienceBench，一个评估科学LLM的开源基准。

Result: 实验结果表明，在ScienceBench上，SciGPT在包括序列标注、生成和推理在内的核心科学任务中表现优于GPT-4o。此外，它在未见科学任务中也展现出强大的鲁棒性。

Conclusion: SciGPT验证了其促进AI增强型科学发现的潜力。

Abstract: Scientific literature is growing exponentially, creating a critical
bottleneck for researchers to efficiently synthesize knowledge. While
general-purpose Large Language Models (LLMs) show potential in text processing,
they often fail to capture scientific domain-specific nuances (e.g., technical
jargon, methodological rigor) and struggle with complex scientific tasks,
limiting their utility for interdisciplinary research. To address these gaps,
this paper presents SciGPT, a domain-adapted foundation model for scientific
literature understanding and ScienceBench, an open source benchmark tailored to
evaluate scientific LLMs.
  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:
(1) low-cost domain distillation via a two-stage pipeline to balance
performance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention
mechanism that cuts memory consumption by 55\% for 32,000-token long-document
reasoning; and (3) knowledge-aware adaptation integrating domain ontologies to
bridge interdisciplinary knowledge gaps.
  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in
core scientific tasks including sequence labeling, generation, and inference.
It also exhibits strong robustness in unseen scientific tasks, validating its
potential to facilitate AI-augmented scientific discovery.

</details>


### [6] [No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models](https://arxiv.org/abs/2509.08075)
*Flor Miriam Plaza-del-Arco,Paul Röttger,Nino Scherrer,Emanuele Borgonovo,Elmar Plischke,Dirk Hovy*

Main category: cs.CL

TL;DR: 本研究量化了社会人口学角色对大型语言模型（LLM）误拒用户请求的影响，发现模型能力、模型选择和任务类型是影响误拒率的关键因素，而角色效应可能被高估。


<details>
  <summary>Details</summary>
Motivation: LLM个性化可能增加意想不到的副作用，特别是角色提示可能导致模型误拒用户请求。此前的工作未能充分量化这一问题的程度。

Method: 研究测量了15种社会人口学角色（基于性别、种族、宗教和残疾）对误拒的影响。为控制其他因素，测试了16种不同模型、3种任务（自然语言推理、礼貌性、冒犯性分类）和9种提示词变体。提出了一种基于蒙特卡洛的方法以样本高效的方式进行量化。

Result: 结果显示，随着模型能力的提升，角色对拒绝率的影响越来越小。某些社会人口学角色在部分模型中确实增加了误拒，暗示对齐策略或安全机制存在潜在偏见。然而，模型选择和任务类型显著影响误拒，尤其是在敏感内容任务中。研究发现角色效应可能被高估，并可能归因于其他因素。

Conclusion: 角色对LLM误拒的影响可能被高估了，模型能力、模型选择和任务类型是更重要的影响因素，尽管仍存在一些与角色相关的潜在偏见。

Abstract: Large language models (LLMs) are increasingly integrated into our daily lives
and personalized. However, LLM personalization might also increase unintended
side effects. Recent work suggests that persona prompting can lead models to
falsely refuse user requests. However, no work has fully quantified the extent
of this issue. To address this gap, we measure the impact of 15
sociodemographic personas (based on gender, race, religion, and disability) on
false refusal. To control for other factors, we also test 16 different models,
3 tasks (Natural Language Inference, politeness, and offensiveness
classification), and nine prompt paraphrases. We propose a Monte Carlo-based
method to quantify this issue in a sample-efficient manner. Our results show
that as models become more capable, personas impact the refusal rate less and
less. Certain sociodemographic personas increase false refusal in some models,
which suggests underlying biases in the alignment strategies or safety
mechanisms. However, we find that the model choice and task significantly
influence false refusals, especially in sensitive content tasks. Our findings
suggest that persona effects have been overestimated, and might be due to other
factors.

</details>


### [7] [Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression](https://arxiv.org/abs/2509.08093)
*Nathaniel Imel,Noga Zaslavsky*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）能够像人类语言一样，通过信息瓶颈（IB）原理演化出高效、以感知为基础的人类语义系统。


<details>
  <summary>Details</summary>
Motivation: 人类语言的语义系统通过信息瓶颈原理实现近乎最优的压缩，但LLMs并未为此目标训练。因此，研究旨在探讨LLMs是否能演化出高效的、类似人类的语义系统。

Method: 研究以颜色领域为认知分类理论的关键测试平台，使用LLMs（Gemini 2.0-flash和Llama 3.3-70B-Instruct）复现了两项有影响力的人类行为研究。首先，进行了一项英语颜色命名研究。其次，通过迭代上下文语言学习模拟了LLMs中伪颜色命名系统的文化演化，以测试LLMs是否具备类似人类的IB效率归纳偏好。

Result: 在英语颜色命名研究中，Gemini与英语母语者的命名模式高度一致，并取得了显著高的IB效率得分；Llama则展示了一个高效但复杂度低于英语的系统。在模拟文化演化中，LLMs（与人类类似）迭代地将最初随机的系统重组，使其趋向更高的IB效率和与全球语言模式更一致的特点。

Conclusion: 这些发现表明，LLMs能够演化出以感知为基础的、类似人类的语义系统，且其演化受制于与人类语言语义效率相同的基本原理（信息瓶颈原理）。

Abstract: Converging evidence suggests that systems of semantic categories across human
languages achieve near-optimal compression via the Information Bottleneck (IB)
complexity-accuracy principle. Large language models (LLMs) are not trained for
this objective, which raises the question: are LLMs capable of evolving
efficient human-like semantic systems? To address this question, we focus on
the domain of color as a key testbed of cognitive theories of categorization
and replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two
influential human behavioral studies. First, we conduct an English color-naming
study, showing that Gemini aligns well with the naming patterns of native
English speakers and achieves a significantly high IB-efficiency score, while
Llama exhibits an efficient but lower complexity system compared to English.
Second, to test whether LLMs simply mimic patterns in their training data or
actually exhibit a human-like inductive bias toward IB-efficiency, we simulate
cultural evolution of pseudo color-naming systems in LLMs via iterated
in-context language learning. We find that akin to humans, LLMs iteratively
restructure initially random systems towards greater IB-efficiency and
increased alignment with patterns observed across the world's languages. These
findings demonstrate that LLMs are capable of evolving perceptually grounded,
human-like semantic systems, driven by the same fundamental principle that
governs semantic efficiency across human languages.

</details>


### [8] [MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion](https://arxiv.org/abs/2509.08105)
*Kosei Uemura,David Guzmán,Quang Phuoc Nguyen,Jesujoba Oluwadara Alabi,En-shiun Annie Lee,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: MERLIN是一个两阶段模型堆叠框架，通过课程学习策略和DoRA权重调整，显著提升了大型语言模型在低资源语言复杂推理任务上的准确性，并对高资源语言也有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在英语表现出色，但在许多低资源语言（LRLs）的复杂推理能力上仍有不足。现有方法在中高资源语言上有效，但在低资源语言上仍存在巨大差距。

Method: 提出了MERLIN，一个两阶段模型堆叠框架。该方法采用课程学习策略（从通用双语语料到特定任务数据），并且只调整一小部分DoRA权重。

Result: 在AfriMGSM基准测试中，MERLIN的精确匹配准确率比MindMerger提高了+12.9个百分点，并超越了GPT-4o-mini。同时，在MGSM和MSVAMP上也取得了持续提升（分别提高+0.9和+2.8个百分点）。

Conclusion: MERLIN在低资源和高资源语言环境中都展现了显著的有效性，尤其在低资源语言的复杂推理任务中表现出卓越的性能。

Abstract: Large language models excel in English but still struggle with complex
reasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder
methods such as LangBridge and MindMerger raise accuracy on mid and
high-resource languages, yet they leave a large gap on LRLs. We present MERLIN,
a two-stage model-stacking framework that applies a curriculum learning
strategy -- from general bilingual bitext to task-specific data -- and adapts
only a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves
exact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.
It also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),
demonstrating effectiveness across both low and high-resource settings.

</details>


### [9] [Bias after Prompting: Persistent Discrimination in Large Language Models](https://arxiv.org/abs/2509.08146)
*Nivedha Sivakumar,Natalie Mackraz,Samira Khorshidi,Krishna Patel,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: 本文挑战了LLM偏见不转移的假设，通过研究发现偏见会通过提示工程转移到适应模型，且现有去偏见方法效果不佳。


<details>
  <summary>Details</summary>
Motivation: 质疑先前关于预训练大语言模型（LLMs）的偏见不会转移到经提示工程适应的模型中的“危险假设”，因为提示工程在实际应用中是一种非常流行且易于使用的适应策略。

Method: 通过提示适应，在因果模型中研究偏见转移假设（BTH）。具体分析了内在偏见与提示适应后偏见在不同人口统计学和任务间的相关性，并探究了少样本组合参数变化（如样本量、刻板印象内容）的影响。同时，评估了几种基于提示的去偏见策略。

Result: 研究发现偏见会通过提示工程进行转移，且内在偏见与提示适应后的偏见在不同人口统计学和任务中保持中度到强烈的关联（如性别rho>=0.94，年龄rho>=0.98）。这种强关联性在改变少样本参数时依然存在。此外，流行的基于提示的偏见缓解方法无法持续有效地阻止偏见转移。

Conclusion: 研究结果表明，纠正内在模型（预训练模型）中的偏见，并可能提升其推理能力，或能更有效地阻止偏见传播到下游任务。

Abstract: A dangerous assumption that can be made from prior work on the bias transfer
hypothesis (BTH) is that biases do not transfer from pre-trained large language
models (LLMs) to adapted models. We invalidate this assumption by studying the
BTH in causal models under prompt adaptations, as prompting is an extremely
popular and accessible adaptation strategy used in real-world applications. In
contrast to prior work, we find that biases can transfer through prompting and
that popular prompt-based mitigation methods do not consistently prevent biases
from transferring. Specifically, the correlation between intrinsic biases and
those after prompt adaptation remain moderate to strong across demographics and
tasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age
(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we
find that biases remain strongly correlated when varying few-shot composition
parameters, such as sample size, stereotypical content, occupational
distribution and representational balance (rho >= 0.90). We evaluate several
prompt-based debiasing strategies and find that different approaches have
distinct strengths, but none consistently reduce bias transfer across models,
tasks or demographics. These results demonstrate that correcting bias, and
potentially improving reasoning ability, in intrinsic models may prevent
propagation of biases to downstream tasks.

</details>


### [10] [Verbalized Algorithms](https://arxiv.org/abs/2509.08150)
*Supriya Lall,Christian Farrell,Hari Pathanjaly,Marko Pavic,Sarvesh Chezhian,Masataro Asai*

Main category: cs.CL

TL;DR: 该研究提出“言语化算法”（Verbalized Algorithms, VAs）范式，将经典算法与LLM结合，让LLM处理简单的自然语言操作，以提高复杂推理任务的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）在推理任务中进行一次性查询（one-shot query）的可靠性不足。

Method: 提出“言语化算法”（VAs），该范式利用具有理论基础的经典算法，将复杂任务分解为LLM能够可靠回答的简单自然语言字符串操作，并限制LLM只执行这些简单操作。例如，在排序任务中，LLM作为二进制比较预言机嵌入到已知的排序算法（如比特onic排序网络）中。

Result: 该方法在排序和聚类任务上展示了有效性。

Conclusion: 结合经典算法并让LLM处理简单子任务的“言语化算法”范式，能够有效解决复杂的自然语言推理任务。

Abstract: Instead of querying LLMs in a one-shot manner and hoping to get the right
answer for a reasoning task, we propose a paradigm we call \emph{verbalized
algorithms} (VAs), which leverage classical algorithms with established
theoretical understanding. VAs decompose a task into simple elementary
operations on natural language strings that they should be able to answer
reliably, and limit the scope of LLMs to only those simple tasks. For example,
for sorting a series of natural language strings, \emph{verbalized sorting}
uses an LLM as a binary comparison oracle in a known and well-analyzed sorting
algorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of
this approach on sorting and clustering tasks.

</details>


### [11] [Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions](https://arxiv.org/abs/2509.08217)
*Eve Fleisig,Matthias Orlikowski,Philipp Cimiano,Dan Klein*

Main category: cs.CL

TL;DR: 现有机器学习数据集的垃圾标注过滤方法在处理主观任务时，倾向于移除合法的多样性而非垃圾标注，导致标签多样性损失。研究发现现有方法对垃圾标注者的随机性假设有误，因此需要开发能兼顾标签多样性的新过滤方法。


<details>
  <summary>Details</summary>
Motivation: 为使机器学习数据集能准确反映人群中的多样化观点，需在过滤垃圾或低质量响应的同时，保留数据标签中的固有变异。研究旨在解决如何平衡标注者可靠性（去除垃圾）与标签多样性（保留观点）之间的矛盾。

Method: 经验性评估了一系列用于标注者过滤的启发式方法，观察它们在主观任务中如何影响变异性的保留。此外，通过分析合成垃圾数据来检验这些方法的性能和其对垃圾标注者的假设。

Result: 1. 现有过滤方法（设计用于单一“真实”标签场景）常移除持异议的标注者而非垃圾标注者，导致准确性和标签多样性之间出现次优权衡。 2. 标注者移除的保守设置（<5%）效果最佳，超过此阈值后，所有测试方法都会增加与真实平均标签的平均绝对误差。 3. 现有方法常假设垃圾标注者不如真实标注者随机，但大多数垃圾标注者与真实标注者在分布上难以区分，少数可区分的倾向于给出固定而非随机的答案。 4. 需要保留变异性的任务与现有垃圾过滤方法的直觉相反：垃圾标注者往往不如非垃圾标注者随机，因此假设变异是垃圾的度量方法效果更差。

Conclusion: 研究结果强调，急需开发能够充分考虑并保留标签多样性的垃圾标注移除方法，以应对主观任务中现有过滤机制的不足。

Abstract: For machine learning datasets to accurately represent diverse opinions in a
population, they must preserve variation in data labels while filtering out
spam or low-quality responses. How can we balance annotator reliability and
representation? We empirically evaluate how a range of heuristics for annotator
filtering affect the preservation of variation on subjective tasks. We find
that these methods, designed for contexts in which variation from a single
ground-truth label is considered noise, often remove annotators who disagree
instead of spam annotators, introducing suboptimal tradeoffs between accuracy
and label diversity. We find that conservative settings for annotator removal
(<5%) are best, after which all tested methods increase the mean absolute error
from the true average label. We analyze performance on synthetic spam to
observe that these methods often assume spam annotators are less random than
real spammers tend to be: most spammers are distributionally indistinguishable
from real annotators, and the minority that are distinguishable tend to give
fixed answers, not random ones. Thus, tasks requiring the preservation of
variation reverse the intuition of existing spam filtering methods: spammers
tend to be less random than non-spammers, so metrics that assume variation is
spam fare worse. These results highlight the need for spam removal methods that
account for label diversity.

</details>


### [12] [Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage Relations via Answerability Detection](https://arxiv.org/abs/2509.08304)
*Yehudit Aperstein,Alon Gottlib,Gal Benita,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的语义覆盖关系（SCR）建模框架，定义了等价、包含和语义重叠三种关系，并采用基于问答（QA）的方法进行分类。通过构建合成数据集，发现判别式模型（如RoBERTa）在SCR预测上显著优于生成式模型。


<details>
  <summary>Details</summary>
Motivation: 理解文档间信息共享模式对信息检索、摘要和内容对齐等任务至关重要。本文旨在引入一个新颖框架，用于对文档对的信息内容对齐方式进行分类，即语义覆盖关系（SCR）。

Method: 定义了等价、包含和语义重叠三种核心语义覆盖关系。采用基于问答（QA）的方法，利用共享问题的可回答性作为语义覆盖的指标。构建了一个从SQuAD语料库派生的合成数据集，通过改写源文本和选择性省略信息来精确控制内容重叠。利用该数据集来基准测试生成式语言模型并训练基于Transformer的分类器进行SCR预测。

Result: 判别式模型在SCR预测上显著优于生成式方法。其中，RoBERTa-base模型达到了61.4%的最高准确率，而基于Random Forest的模型在宏F1分数上取得52.9%，表现出最佳平衡。

Conclusion: 研究结果表明，基于问答（QA）的方法能有效评估风格多样文本间的语义关系，并提供了关于当前模型超越表面相似性进行信息推理能力的见解。为支持研究的可重现性，本研究的数据集和代码已公开。

Abstract: Understanding how information is shared across documents, regardless of the
format in which it is expressed, is critical for tasks such as information
retrieval, summarization, and content alignment. In this work, we introduce a
novel framework for modelling Semantic Coverage Relations (SCR), which
classifies document pairs based on how their informational content aligns. We
define three core relation types: equivalence, where both texts convey the same
information using different textual forms or styles; inclusion, where one
document fully contains the information of another and adds more; and semantic
overlap, where each document presents partially overlapping content. To capture
these relations, we adopt a question answering (QA)-based approach, using the
answerability of shared questions across documents as an indicator of semantic
coverage. We construct a synthetic dataset derived from the SQuAD corpus by
paraphrasing source passages and selectively omitting information, enabling
precise control over content overlap. This dataset allows us to benchmark
generative language models and train transformer-based classifiers for SCR
prediction. Our findings demonstrate that discriminative models significantly
outperform generative approaches, with the RoBERTa-base model achieving the
highest accuracy of 61.4% and the Random Forest-based model showing the best
balance with a macro-F1 score of 52.9%. The results show that QA provides an
effective lens for assessing semantic relations across stylistically diverse
texts, offering insights into the capacity of current models to reason about
information beyond surface similarity. The dataset and code developed in this
study are publicly available to support reproducibility.

</details>


### [13] [Toward Subtrait-Level Model Explainability in Automated Writing Evaluation](https://arxiv.org/abs/2509.08345)
*Alejandro Andrade-Lotero,Lee Becker,Joshua Southerland,Scott Hellman*

Main category: cs.CL

TL;DR: 研究利用生成式语言模型进行子特质评估，以提高自动写作评分的透明度，并发现自动化与人工评分之间存在适度相关性。


<details>
  <summary>Details</summary>
Motivation: 增强自动写作分数的透明度，使评分过程更易于理解。

Method: 使用生成式语言模型进行可解释性和子特质评分的原型开发。

Result: 在人类子特质与特质分数之间，以及自动化与人类子特质分数之间，发现了适度的相关性。

Conclusion: 所提出的方法通过提供详细信息，有助于消除教育者和学生对自动写作分数的困惑，提升其可解释性。

Abstract: Subtrait (latent-trait components) assessment presents a promising path
toward enhancing transparency of automated writing scores. We prototype
explainability and subtrait scoring with generative language models and show
modest correlation between human subtrait and trait scores, and between
automated and human subtrait scores. Our approach provides details to demystify
scores for educators and students.

</details>


### [14] [Automatic Detection of Inauthentic Templated Responses in English Language Assessments](https://arxiv.org/abs/2509.08355)
*Yashad Samant,Lee Becker,Scott Hellman,Bradley Behan,Sarah Hughes,Joshua Southerland*

Main category: cs.CL

TL;DR: 本研究引入了自动化检测英语语言评估中模板化作弊答案的任务（AuDITR），提出了一种机器学习方法，并强调了模型定期更新的重要性。


<details>
  <summary>Details</summary>
Motivation: 在高风险英语语言评估中，低技能考生可能使用记忆模板来欺骗自动评分系统。

Method: 研究引入了自动化检测不真实、模板化答案（AuDITR）的任务，并描述了一种基于机器学习的方法来解决此任务。

Result: 研究结果强调了在实际生产环境中，定期更新这些检测模型对于其有效性至关重要。

Conclusion: 为了有效应对模板化作弊，开发和部署的机器学习检测模型需要持续的更新和维护。

Abstract: In high-stakes English Language Assessments, low-skill test takers may employ
memorized materials called ``templates'' on essay questions to ``game'' or fool
the automated scoring system. In this study, we introduce the automated
detection of inauthentic, templated responses (AuDITR) task, describe a machine
learning-based approach to this task and illustrate the importance of regularly
updating these models in production.

</details>


### [15] [<think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs](https://arxiv.org/abs/2509.08358)
*Sergey Pletenev,Daniil Moskovskiy,Alexander Panchenko*

Main category: cs.CL

TL;DR: 本文研究LLM生成合成毒性数据用于训练文本解毒模型的有效性。结果显示，基于合成数据训练的模型性能显著低于人类数据训练的模型，主要原因在于合成数据缺乏词汇多样性。


<details>
  <summary>Details</summary>
Motivation: LLM在生成合成数据方面表现出色，但在文本解毒等敏感领域，其生成合成数据的性能及应用潜力尚未得到充分关注。研究旨在探讨LLM生成的合成毒性数据是否能有效替代人类标注数据来训练文本解毒模型。

Method: 使用Llama 3和Qwen（激活补丁模型）从ParaDetox和SST-2数据集中性文本生成了合成的毒性对应文本。随后，将解毒模型在这些合成数据上进行微调，并与在人类标注数据上训练的模型进行性能比较。

Result: 实验发现，在合成数据上微调的模型性能始终不如在人类数据上训练的模型，在综合指标上性能下降高达30%。分析表明，根本原因在于合成毒性数据存在关键的词汇多样性鸿沟：LLM生成的毒性内容词汇量小且重复，未能捕捉人类毒性表达的细微差别和多样性。

Conclusion: 当前LLM在生成高质量合成毒性数据以用于训练文本解毒系统方面存在局限性。构建健壮的文本解毒系统仍需依赖多样化、人工标注的数据。

Abstract: Modern Large Language Models (LLMs) are excellent at generating synthetic
data. However, their performance in sensitive domains such as text
detoxification has not received proper attention from the scientific community.
This paper explores the possibility of using LLM-generated synthetic toxic data
as an alternative to human-generated data for training models for
detoxification. Using Llama 3 and Qwen activation-patched models, we generated
synthetic toxic counterparts for neutral texts from ParaDetox and SST-2
datasets. Our experiments show that models fine-tuned on synthetic data
consistently perform worse than those trained on human data, with a drop in
performance of up to 30% in joint metrics. The root cause is identified as a
critical lexical diversity gap: LLMs generate toxic content using a small,
repetitive vocabulary of insults that fails to capture the nuances and variety
of human toxicity. These findings highlight the limitations of current LLMs in
this domain and emphasize the continued importance of diverse, human-annotated
data for building robust detoxification systems.

</details>


### [16] [Low-Resource Fine-Tuning for Multi-Task Structured Information Extraction with a Billion-Parameter Instruction-Tuned Model](https://arxiv.org/abs/2509.08381)
*Yu Cheng Chih,Yong Hao Hou*

Main category: cs.CL

TL;DR: 针对资源受限环境，本研究提出ETLCH，一个十亿参数的LLaMA模型，通过LoRA微调少量样本，在结构化数据提取任务中超越大模型基线，证明小模型也能提供高效可靠的解决方案。


<details>
  <summary>Details</summary>
Motivation: 部署大型语言模型（LLMs）进行结构化数据提取对小型团队而言成本高昂且难以准备高质量数据集。此外，现有指令微调研究主要关注大型模型，缺乏关于小模型在低资源、多任务条件下可靠性的证据。

Method: 本研究提出了ETLCH，一个基于LLaMA的十亿参数模型，使用低秩适应（LoRA）技术进行微调。每个任务（如JSON提取、知识图谱提取和命名实体识别）仅使用了数百到一千个样本。

Result: 尽管ETLCH规模较小，但在大多数评估指标上均优于强大的基线模型，即使在最低数据量条件下也取得了显著的性能提升。

Conclusion: 研究结果表明，经过精心微调的小模型能够以极低的计算成本提供稳定且准确的结构化输出，为资源受限环境中的经济高效、可靠的信息提取管道提供了可能。

Abstract: Deploying large language models (LLMs) for structured data extraction in
domains such as financial compliance reporting, legal document analytics, and
multilingual knowledge base construction is often impractical for smaller teams
due to the high cost of running large architectures and the difficulty of
preparing large, high-quality datasets. Most recent instruction-tuning studies
focus on seven-billion-parameter or larger models, leaving limited evidence on
whether much smaller models can work reliably under low-resource, multi-task
conditions. This work presents ETLCH, a billion-parameter LLaMA-based model
fine-tuned with low-rank adaptation on only a few hundred to one thousand
samples per task for JSON extraction, knowledge graph extraction, and named
entity recognition. Despite its small scale, ETLCH outperforms strong baselines
across most evaluation metrics, with substantial gains observed even at the
lowest data scale. These findings demonstrate that well-tuned small models can
deliver stable and accurate structured outputs at a fraction of the
computational cost, enabling cost-effective and reliable information extraction
pipelines in resource-constrained environments.

</details>


### [17] [CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction with a New Dataset and Multi-Order Generative Framework](https://arxiv.org/abs/2509.08438)
*Jinzhong Ning,Paerhati Tulajiang,Yingying Le,Yijia Zhang,Yuanyuan Sun,Hongfei Lin,Haifeng Liu*

Main category: cs.CL

TL;DR: 本文提出了CommonVoice-SpeechRE，一个大型真实语音关系抽取数据集，并引入了RPG-MoGe框架，通过多序生成策略和关系提示引导实现了跨模态对齐和准确的三元组生成，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有语音关系抽取(SpeechRE)基准数据集过度依赖合成数据，缺乏真实人声的多样性和数量；现有模型存在僵硬的单序生成模板和语义对齐弱等问题，限制了性能。

Method: 1. 构建了CommonVoice-SpeechRE，一个包含近20,000个真实人声样本的大规模数据集。2. 提出了Relation Prompt-Guided Multi-Order Generative Ensemble (RPG-MoGe)框架，该框架包含：(1) 一种多序三元组生成集成策略，在训练和推理过程中利用不同元素顺序来增加数据多样性；(2) 基于CNN的潜在关系预测头，生成显式关系提示以指导跨模态对齐和准确的三元组生成。

Result: 实验结果表明，所提出的方法优于现有最先进的方法。

Conclusion: 本文为SpeechRE研究提供了一个新的基准数据集，并为实际应用中的SpeechRE提供了一个有效的解决方案。

Abstract: Speech Relation Extraction (SpeechRE) aims to extract relation triplets
directly from speech. However, existing benchmark datasets rely heavily on
synthetic data, lacking sufficient quantity and diversity of real human speech.
Moreover, existing models also suffer from rigid single-order generation
templates and weak semantic alignment, substantially limiting their
performance. To address these challenges, we introduce CommonVoice-SpeechRE, a
large-scale dataset comprising nearly 20,000 real-human speech samples from
diverse speakers, establishing a new benchmark for SpeechRE research.
Furthermore, we propose the Relation Prompt-Guided Multi-Order Generative
Ensemble (RPG-MoGe), a novel framework that features: (1) a multi-order triplet
generation ensemble strategy, leveraging data diversity through diverse element
orders during both training and inference, and (2) CNN-based latent relation
prediction heads that generate explicit relation prompts to guide cross-modal
alignment and accurate triplet generation. Experiments show our approach
outperforms state-of-the-art methods, providing both a benchmark dataset and an
effective solution for real-world SpeechRE. The source code and dataset are
publicly available at https://github.com/NingJinzhong/SpeechRE_RPG_MoGe.

</details>


### [18] [Adversarial Attacks Against Automated Fact-Checking: A Survey](https://arxiv.org/abs/2509.08463)
*Fanzhen Liu,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Jia Wu,Jian Yang,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 本文对针对自动化事实核查（AFC）系统的对抗性攻击进行了首次深入综述。它分类了攻击方法，评估了其影响，审查了对抗性防御进展，并指出了开放研究问题，强调了构建弹性AFC框架的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 自动化事实核查（AFC）系统在打击错误信息中扮演关键角色，但它们易受对抗性攻击影响，这些攻击会操纵信息并损害模型可靠性。尽管研究日益增多，但目前缺乏对这些攻击挑战的全面、整体概述，包括理解攻击策略、评估模型韧性及增强鲁棒性的方法。

Method: 本研究提供了一项深入的综述，对针对事实核查（FC）的对抗性攻击进行了首次全面审视。具体方法包括：对现有攻击方法进行分类、评估其对AFC系统的影响、审查对抗性防御的最新进展，并提出需要进一步探索的开放研究问题。

Result: 该综述揭示了针对AFC系统的各种对抗性攻击类型及其影响，并审视了对抗性防御的当前进展。研究结果突出了现有系统对攻击的脆弱性，并展示了当前研究在应对这些挑战方面的状况。

Conclusion: 研究强调，迫切需要开发具有韧性的事实核查框架，以有效抵御对抗性操纵，从而在保持高核查准确性方面发挥作用。

Abstract: In an era where misinformation spreads freely, fact-checking (FC) plays a
crucial role in verifying claims and promoting reliable information. While
automated fact-checking (AFC) has advanced significantly, existing systems
remain vulnerable to adversarial attacks that manipulate or generate claims,
evidence, or claim-evidence pairs. These attacks can distort the truth, mislead
decision-makers, and ultimately undermine the reliability of FC models. Despite
growing research interest in adversarial attacks against AFC systems, a
comprehensive, holistic overview of key challenges remains lacking. These
challenges include understanding attack strategies, assessing the resilience of
current models, and identifying ways to enhance robustness. This survey
provides the first in-depth review of adversarial attacks targeting FC,
categorizing existing attack methodologies and evaluating their impact on AFC
systems. Additionally, we examine recent advancements in adversary-aware
defenses and highlight open research questions that require further
exploration. Our findings underscore the urgent need for resilient FC
frameworks capable of withstanding adversarial manipulations in pursuit of
preserving high verification accuracy.

</details>


### [19] [Acquiescence Bias in Large Language Models](https://arxiv.org/abs/2509.08480)
*Daniel Braun*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）不显示人类的默许偏见，反而倾向于回答“否”。


<details>
  <summary>Details</summary>
Motivation: 默许偏见在人类调查中普遍存在。鉴于LLMs易受输入影响且基于人类数据训练，研究假设它们可能也存在类似偏见。

Method: 本研究调查了不同模型、任务和语言（英语、德语和波兰语）中LLMs的默许偏见。

Result: 结果表明，与人类相反，LLMs表现出一种偏向回答“否”的偏见，无论“否”是表示同意还是不同意。

Conclusion: LLMs并未显示出人类的默许偏见，反而呈现出一种独特的“否”倾向。

Abstract: Acquiescence bias, i.e. the tendency of humans to agree with statements in
surveys, independent of their actual beliefs, is well researched and
documented. Since Large Language Models (LLMs) have been shown to be very
influenceable by relatively small changes in input and are trained on
human-generated data, it is reasonable to assume that they could show a similar
tendency. We present a study investigating the presence of acquiescence bias in
LLMs across different models, tasks, and languages (English, German, and
Polish). Our results indicate that, contrary to humans, LLMs display a bias
towards answering no, regardless of whether it indicates agreement or
disagreement.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [20] [3D and 4D World Modeling: A Survey](https://arxiv.org/abs/2509.07996)
*Lingdong Kong,Wesley Yang,Jianbiao Mei,Youquan Liu,Ao Liang,Dekai Zhu,Dongyue Lu,Wei Yin,Xiaotao Hu,Mingkai Jia,Junyuan Deng,Kaiwen Zhang,Yang Wu,Tianyi Yan,Shenyuan Gao,Song Wang,Linfeng Li,Liang Pan,Yong Liu,Jianke Zhu,Wei Tsang Ooi,Steven C. H. Hoi,Ziwei Liu*

Main category: cs.CV

TL;DR: 本综述首次全面审查了3D和4D世界建模与生成，旨在弥补现有研究对2D方法侧重而忽视3D/4D的不足，并解决世界模型定义和分类碎片化的问题，为领域提供基础性参考。


<details>
  <summary>Details</summary>
Motivation: 现有世界建模研究主要关注2D图像和视频数据，忽视了快速增长的3D和4D表示方法；此外，缺乏对“世界模型”的标准化定义和分类，导致领域内主张碎片化且不一致。

Method: 本文通过对3D和4D世界建模与生成进行首次全面综述来解决上述问题。具体方法包括：建立精确定义，引入结构化分类法（涵盖基于视频、占用和LiDAR的方法），系统总结适用于3D/4D设置的数据集和评估指标，并讨论实际应用、开放挑战及有前景的研究方向。

Result: 建立了3D和4D世界模型的精确定义和结构化分类法（VideoGen, OccGen, LiDARGen）；系统总结了3D/4D数据集和评估指标；讨论了实际应用、开放挑战和未来研究方向。

Conclusion: 本综述旨在为推动3D和4D世界建模领域的发展提供一个连贯且基础性的参考依据。

Abstract: World modeling has become a cornerstone in AI research, enabling agents to
understand, represent, and predict the dynamic environments they inhabit. While
prior work largely emphasizes generative methods for 2D image and video data,
they overlook the rapidly growing body of work that leverages native 3D and 4D
representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds
for large-scale scene modeling. At the same time, the absence of a standardized
definition and taxonomy for ``world models'' has led to fragmented and
sometimes inconsistent claims in the literature. This survey addresses these
gaps by presenting the first comprehensive review explicitly dedicated to 3D
and 4D world modeling and generation. We establish precise definitions,
introduce a structured taxonomy spanning video-based (VideoGen),
occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and
systematically summarize datasets and evaluation metrics tailored to 3D/4D
settings. We further discuss practical applications, identify open challenges,
and highlight promising research directions, aiming to provide a coherent and
foundational reference for advancing the field. A systematic summary of
existing literature is available at https://github.com/worldbench/survey

</details>


### [21] [An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities](https://arxiv.org/abs/2509.08003)
*Shahid Shafi Dar,Bharat Kaurav,Arnav Jain,Chandravardhan Singh Raghaw,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

TL;DR: 本文提出了XFloodNet，一个利用先进深度学习技术应对城市洪涝分类挑战的框架。通过引入分层跨模态门控注意力、异构卷积自适应多尺度注意力及级联卷积Transformer特征细化技术，解决了传统方法在多模态数据处理和复杂环境适应性的局限性，并在多个基准数据集上取得了最先进的洪涝分类性能。


<details>
  <summary>Details</summary>
Motivation: 在气候变化加剧的时代，城市洪涝对可持续城市构成严峻挑战。传统洪涝检测方法受限于单模态数据和静态规则，无法捕捉洪涝事件的动态非线性关系。现有注意力机制和集成学习方法在分层细化、跨模态特征整合及噪声环境适应性方面存在局限，导致洪涝分类性能不佳。

Method: 本文提出了XFloodNet框架，通过以下三个新颖组件重新定义城市洪涝分类：
1.  **分层跨模态门控注意力机制：** 动态对齐视觉和文本特征，实现精确的多粒度交互并解决上下文模糊性。
2.  **异构卷积自适应多尺度注意力模块：** 利用频率增强通道注意力和频率调制空间注意力，从频谱和空间域提取并优先处理判别性洪涝相关特征。
3.  **级联卷积Transformer特征细化技术：** 通过自适应缩放和级联操作协调分层特征，确保鲁棒且抗噪声的洪涝检测。

Result: 在Chennai Floods、Rhine18 Floods和Harz17 Floods三个基准数据集上，XFloodNet取得了最先进的F1分数，分别为93.33%、82.24%和88.60%，显著超越现有方法。

Conclusion: XFloodNet通过其创新的深度学习组件，有效解决了城市洪涝分类中传统方法面临的多模态数据整合、特征提取和噪声鲁棒性问题，极大地提升了洪涝检测的性能，为城市洪涝分类提供了强大的解决方案。

Abstract: In an era of escalating climate change, urban flooding has emerged as a
critical challenge for sustainable cities, threatening lives, infrastructure,
and ecosystems. Traditional flood detection methods are constrained by their
reliance on unimodal data and static rule-based systems, which fail to capture
the dynamic, non-linear relationships inherent in flood events. Furthermore,
existing attention mechanisms and ensemble learning approaches exhibit
limitations in hierarchical refinement, cross-modal feature integration, and
adaptability to noisy or unstructured environments, resulting in suboptimal
flood classification performance. To address these challenges, we present
XFloodNet, a novel framework that redefines urban flood classification through
advanced deep-learning techniques. XFloodNet integrates three novel components:
(1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically
aligns visual and textual features, enabling precise multi-granularity
interactions and resolving contextual ambiguities; (2) a Heterogeneous
Convolutional Adaptive Multi-Scale Attention module, which leverages
frequency-enhanced channel attention and frequency-modulated spatial attention
to extract and prioritize discriminative flood-related features across spectral
and spatial domains; and (3) a Cascading Convolutional Transformer Feature
Refinement technique that harmonizes hierarchical features through adaptive
scaling and cascading operations, ensuring robust and noise-resistant flood
detection. We evaluate our proposed method on three benchmark datasets, such as
Chennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves
state-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively,
surpassing existing methods by significant margins.

</details>


### [22] [Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs](https://arxiv.org/abs/2509.08016)
*Hyungjin Chung,Hyelin Nam,Jiyeon Kim,Hyojun Go,Byeongjun Park,Junho Kim,Joonseok Lee,Seongsu Ha,Byung-Hoon Kim*

Main category: cs.CV

TL;DR: 针对VideoLLM处理长视频时的计算与性能瓶颈，本文提出推理时方法Video Parallel Scaling (VPS)。VPS通过并行处理视频子集并聚合结果，在不增加上下文长度的前提下，有效提升模型感知带宽和时间推理能力，且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型（VideoLLMs）在捕获细粒度时间细节时，因输入帧数增加导致计算成本过高和长上下文长度引起的性能下降，面临关键瓶颈。

Method: 本文引入视频并行扩展（VPS）方法。这是一种推理时方法，通过运行多个并行推理流来扩展模型感知带宽，每个流处理视频帧的独特且不相交的子集。VPS通过聚合这些互补流的输出概率来整合更丰富的视觉信息。理论上，该方法利用不相关的视觉证据有效地收缩了Chinchilla缩放定律，无需额外训练即可提高性能。

Result: 广泛实验表明，VPS在各种模型架构和规模（2B-32B）上，于Video-MME和EventHallusion等基准测试中持续显著提升性能。它比其他并行替代方案（如Self-consistency）更具扩展性，并与现有解码策略互补。

Conclusion: VPS为增强VideoLLMs的时间推理能力提供了一个内存高效且稳健的框架，有效解决了现有模型在处理长视频时面临的计算和性能瓶颈。

Abstract: Video Large Language Models (VideoLLMs) face a critical bottleneck:
increasing the number of input frames to capture fine-grained temporal detail
leads to prohibitive computational costs and performance degradation from long
context lengths. We introduce Video Parallel Scaling (VPS), an inference-time
method that expands a model's perceptual bandwidth without increasing its
context window. VPS operates by running multiple parallel inference streams,
each processing a unique, disjoint subset of the video's frames. By aggregating
the output probabilities from these complementary streams, VPS integrates a
richer set of visual information than is possible with a single pass. We
theoretically show that this approach effectively contracts the Chinchilla
scaling law by leveraging uncorrelated visual evidence, thereby improving
performance without additional training. Extensive experiments across various
model architectures and scales (2B-32B) on benchmarks such as Video-MME and
EventHallusion demonstrate that VPS consistently and significantly improves
performance. It scales more favorably than other parallel alternatives (e.g.
Self-consistency) and is complementary to other decoding strategies, offering a
memory-efficient and robust framework for enhancing the temporal reasoning
capabilities of VideoLLMs.

</details>


### [23] [Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change](https://arxiv.org/abs/2509.08024)
*Lata Pangtey,Omkar Kabde,Shahid Shafi Dar,Nagendra Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种分层融合的多模态立场检测框架，通过LLM处理文本、图像字幕生成器处理视觉信息，并利用专门的Transformer模块融合多模态数据，在MultiClimate数据集上取得了超越SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测方法主要关注文本数据，但实际社交媒体内容日益结合文本和视觉元素，这要求开发更先进的多模态方法来填补这一空白。

Method: 提出一个分层融合的多模态立场检测框架。该方法首先使用大型语言模型从源文本中提取立场相关摘要，同时利用领域感知图像字幕生成器解释视觉内容。然后，通过一个专门的Transformer模块，将这些模态（以及回复文本）联合建模，以捕捉文本和图像之间的交互，从而实现鲁棒的立场分类。

Result: 在MultiClimate数据集上进行评估，取得了76.2%的准确率、76.3%的精确率、76.2%的召回率和76.2%的F1分数，优于现有的最先进方法。

Conclusion: 所提出的多模态立场检测框架通过有效整合文本和视觉信息，实现了鲁棒的立场分类，并在基准数据集上表现优异，成功解决了社交媒体中多模态内容立场检测的挑战。

Abstract: With the rapid proliferation of information across digital platforms, stance
detection has emerged as a pivotal challenge in social media analysis. While
most of the existing approaches focus solely on textual data, real-world social
media content increasingly combines text with visual elements creating a need
for advanced multimodal methods. To address this gap, we propose a multimodal
stance detection framework that integrates textual and visual information
through a hierarchical fusion approach. Our method first employs a Large
Language Model to retrieve stance-relevant summaries from source text, while a
domain-aware image caption generator interprets visual content in the context
of the target topic. These modalities are then jointly modeled along with the
reply text, through a specialized transformer module that captures interactions
between the texts and images. The proposed modality fusion framework integrates
diverse modalities to facilitate robust stance classification. We evaluate our
approach on the MultiClimate dataset, a benchmark for climate change-related
stance detection containing aligned video frames and transcripts. We achieve
accuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%,
respectively, outperforming existing state-of-the-art approaches.

</details>


### [24] [Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.08026)
*Zeinab Ghasemi Darehnaei,Mohammad Shokouhifar,Hossein Yazdanjouei,S. M. J. Rastegar Fatemi*

Main category: cs.CV

TL;DR: 本文提出SI-EDTL，一个两阶段的群智能集成深度迁移学习模型，用于无人机图像中的多车辆检测。


<details>
  <summary>Details</summary>
Motivation: 提升无人机图像中多类型车辆检测的准确性和效率。

Method: SI-EDTL模型结合三个预训练的Faster R-CNN特征提取器（InceptionV3, ResNet50, GoogLeNet）和五个迁移分类器（KNN, SVM, MLP, C4.5, Naive Bayes），构建15个基础学习器。这些学习器通过加权平均进行聚合，用于分类汽车、货车、卡车、巴士或背景。超参数使用鲸鱼优化算法（WOA）进行优化，以平衡准确率、精确率和召回率。模型在MATLAB R2020b中并行实现。

Result: SI-EDTL模型在AU-AIR无人机数据集上的性能优于现有方法。

Conclusion: SI-EDTL为无人机图像中的多车辆检测提供了一种高效且性能卓越的解决方案。

Abstract: This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep
transfer learning model for detecting multiple vehicles in UAV images. It
combines three pre-trained Faster R-CNN feature extractor models (InceptionV3,
ResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5,
Na\"ive Bayes), resulting in 15 different base learners. These are aggregated
via weighted averaging to classify regions as Car, Van, Truck, Bus, or
background. Hyperparameters are optimized with the whale optimization algorithm
to balance accuracy, precision, and recall. Implemented in MATLAB R2020b with
parallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV
dataset.

</details>


### [25] [MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery](https://arxiv.org/abs/2509.08027)
*Rafał Osadnik,Pablo Gómez,Eleni Bohacek,Rickbir Bahia*

Main category: cs.CV

TL;DR: 本文提出了一个名为MCTED的火星数字高程模型（DEM）预测新数据集，专为机器学习应用设计。该数据集通过处理高分辨率火星正射影像和DEM对生成，包含80,898个样本，并解决了原始数据中的伪影和缺失数据问题。实验表明，在该数据集上训练的小型U-Net模型在火星DEM预测任务上优于通用的深度估计基础模型DepthAnythingV2的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 为火星DEM预测任务提供一个高质量、适用于机器学习的新数据集，解决现有大规模DEM数据中常见的伪影和数据缺失问题，以促进火星表面测绘和相关研究。

Method: 1. **数据集生成**: 开发了一个综合流程，处理来自火星勘测轨道飞行器CTX仪器的高分辨率火星正射影像和DEM对，生成了包含80,898个样本的MCTED数据集。
2. **数据清洗**: 开发了工具来解决或减轻原始DEM数据中伪影和缺失数据点的影响。
3. **数据结构**: 每个样本包含光学图像块、DEM块和两个指示原始缺失或修改值的掩码块。
4. **数据划分**: 将处理后的样本划分为训练集和验证集，确保两部分样本不覆盖共同区域以避免数据泄露。
5. **性能评估**: 使用一个小型U-Net架构在MCTED数据集上进行训练，并将其在海拔预测任务上的性能与单目深度估计基础模型DepthAnythingV2进行比较。

Result: 1. 成功生成了包含80,898个独特数据样本的MCTED数据集。
2. 即使是一个非常小的、专门为此数据集训练的U-Net架构，其在海拔预测任务上的性能也超越了DepthAnythingV2等深度估计基础模型的零样本表现。

Conclusion: MCTED数据集为火星DEM预测任务提供了宝贵的资源。针对特定领域的数据集训练，即使是小型模型，也能显著优于通用基础模型的零样本性能，突显了领域专用数据和模型的重要性。数据集及其生成代码已完全开源，以促进未来研究。

Abstract: This work presents a new dataset for the Martian digital elevation model
prediction task, ready for machine learning applications called MCTED. The
dataset has been generated using a comprehensive pipeline designed to process
high-resolution Mars orthoimage and DEM pairs from Day et al., yielding a
dataset consisting of 80,898 data samples. The source images are data gathered
by the Mars Reconnaissance Orbiter using the CTX instrument, providing a very
diverse and comprehensive coverage of the Martian surface. Given the complexity
of the processing pipelines used in large-scale DEMs, there are often artefacts
and missing data points in the original data, for which we developed tools to
solve or mitigate their impact. We divide the processed samples into training
and validation splits, ensuring samples in both splits cover no mutual areas to
avoid data leakage. Every sample in the dataset is represented by the optical
image patch, DEM patch, and two mask patches, indicating values that were
originally missing or were altered by us. This allows future users of the
dataset to handle altered elevation regions as they please. We provide
statistical insights of the generated dataset, including the spatial
distribution of samples, the distributions of elevation values, slopes and
more. Finally, we train a small U-Net architecture on the MCTED dataset and
compare its performance to a monocular depth estimation foundation model,
DepthAnythingV2, on the task of elevation prediction. We find that even a very
small architecture trained on this dataset specifically, beats a zero-shot
performance of a depth estimation foundation model like DepthAnythingV2. We
make the dataset and code used for its generation completely open source in
public repositories.

</details>


### [26] [APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction](https://arxiv.org/abs/2509.08104)
*Sasan Sharifipour,Constantino Álvarez Casado,Mohammad Sabokrou,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 本文提出了一种名为APML的自适应概率匹配损失函数，用于点云预测任务。它通过可微分的一对一匹配近似解决了现有损失函数的缺陷，实现了更快的收敛、更优的空间分布和更高的性能。


<details>
  <summary>Details</summary>
Motivation: 点云预测任务中常用的损失函数（如Chamfer Distance）依赖最近邻分配，导致多对一匹配、稠密区域点拥堵、稀疏区域覆盖差以及非可微操作。Earth Mover Distance（EMD）虽能实现一对一匹配并捕获结构相似性，但其立方级的计算复杂度限制了实际应用。

Method: 我们提出了自适应概率匹配损失（APML），它是一种完全可微分的一对一匹配近似方法。APML利用Sinkhorn迭代在基于成对距离的温度标度相似性矩阵上进行计算，并通过分析计算温度以保证最小分配概率，无需手动调优。APML实现了接近二次方的运行时间，与基于Chamfer的损失相当，并避免了非可微操作。

Result: 将APML集成到最先进的架构（PoinTr、PCN、FoldingNet）在ShapeNet基准上，以及应用于从WiFi CSI测量生成3D人体点云的时空Transformer（CSI2PC）时，APML损失带来了更快的收敛、卓越的空间分布（尤其是在低密度区域），并在不进行额外超参数搜索的情况下，实现了性能提升或持平。

Conclusion: APML是一种高效且可微分的点云预测损失函数，有效解决了现有方法的局限性。它通过提供一对一匹配的近似，在保证计算效率的同时，显著改善了点云的质量和分布，是点云处理领域的重要进展。

Abstract: Training deep learning models for point cloud prediction tasks such as shape
completion and generation depends critically on loss functions that measure
discrepancies between predicted and ground-truth point sets. Commonly used
functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on
nearest-neighbor assignments, which often induce many-to-one correspondences,
leading to point congestion in dense regions and poor coverage in sparse
regions. These losses also involve non-differentiable operations due to index
selection, which may affect gradient-based optimization. Earth Mover Distance
(EMD) enforces one-to-one correspondences and captures structural similarity
more effectively, but its cubic computational complexity limits its practical
use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully
differentiable approximation of one-to-one matching that leverages Sinkhorn
iterations on a temperature-scaled similarity matrix derived from pairwise
distances. We analytically compute the temperature to guarantee a minimum
assignment probability, eliminating manual tuning. APML achieves near-quadratic
runtime, comparable to Chamfer-based losses, and avoids non-differentiable
operations. When integrated into state-of-the-art architectures (PoinTr, PCN,
FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC)
that generates 3D human point clouds from WiFi CSI measurements, APM loss
yields faster convergence, superior spatial distribution, especially in
low-density regions, and improved or on-par quantitative performance without
additional hyperparameter search. The code is available at:
https://github.com/apm-loss/apml.

</details>


### [27] [Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection](https://arxiv.org/abs/2509.08205)
*Jingjing Liu,Yinchao Han,Xianchao Xiu,Jianhua Zhang,Wanquan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于鲁棒主成分分析（RPCA）的轻量级深度展开网络L-RPCANet，用于红外小目标检测，通过分层瓶颈结构、降噪模块和通道注意力机制，显著提升了模型的轻量性和噪声鲁棒性，并在实验中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测（ISTD）是图像处理的关键技术。尽管深度展开网络（DUNs）在ISTD中表现出色，但现有方法在参数轻量化和噪声鲁棒性方面仍面临重大挑战。

Method: 研究者提出了L-RPCANet框架，技术上构建了分层瓶颈结构以实现通道特征细化和参数轻量化；嵌入了降噪模块以增强对复杂噪声的鲁棒性；并利用挤压-激励网络（SENets）作为通道注意力机制，以关注不同特征的重要性。

Result: 在ISTD数据集上进行的大量实验验证了所提方法L-RPCANet相对于RPCANet、DRPCANet和RPCANet++等最先进方法的优越性，实现了卓越的性能，同时保持了轻量化和鲁棒性。

Conclusion: L-RPCANet通过创新的网络结构设计，成功解决了红外小目标检测中现有方法在轻量化和噪声鲁棒性方面的不足，为该领域提供了一种高效且高性能的解决方案。

Abstract: Infrared small target detection (ISTD) is one of the key techniques in image
processing. Although deep unfolding networks (DUNs) have demonstrated promising
performance in ISTD due to their model interpretability and data adaptability,
existing methods still face significant challenges in parameter lightweightness
and noise robustness. In this regard, we propose a highly lightweight framework
based on robust principal component analysis (RPCA) called L-RPCANet.
Technically, a hierarchical bottleneck structure is constructed to reduce and
increase the channel dimension in the single-channel input infrared image to
achieve channel-wise feature refinement, with bottleneck layers designed in
each module to extract features. This reduces the number of channels in feature
extraction and improves the lightweightness of network parameters. Furthermore,
a noise reduction module is embedded to enhance the robustness against complex
noise. In addition, squeeze-and-excitation networks (SENets) are leveraged as a
channel attention mechanism to focus on the varying importance of different
features across channels, thereby achieving excellent performance while
maintaining both lightweightness and robustness. Extensive experiments on the
ISTD datasets validate the superiority of our proposed method compared with
state-of-the-art methods covering RPCANet, DRPCANet, and RPCANet++. The code
will be available at https://github.com/xianchaoxiu/L-RPCANet.

</details>


### [28] [Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing](https://arxiv.org/abs/2509.08228)
*Miao Cao,Siming Zheng,Lishun Wang,Ziyang Chen,David Brady,Xin Yuan*

Main category: cs.CV

TL;DR: 为解决高分辨率、高帧率视频捕获的巨大功耗问题，本文提出超稀疏采样（USS）策略和稀疏Transformer（BSTFormer）算法，用于高效压缩感知成像，并在模拟和实际数据上显著超越现有技术，同时USS策略具有更高动态范围和片上实现潜力。


<details>
  <summary>Details</summary>
Motivation: 数码相机在高分辨率、高帧率视频捕获时功耗巨大（例如4K@30fps约20W），未来千兆像素相机以100-1000 fps运行时，现有处理模型不可持续。虽然物理层压缩测量（如视频快照压缩成像SCI）能降低功耗，但现有随机采样（RS）策略有局限。图像修复（I2P）技术启发了更稀疏的采样思路。

Method: 本文提出**超稀疏采样（USS）**策略，即在每个空间位置，仅将一个子帧设为1，其余设为0。构建了**数字微镜设备（DMD）编码系统**验证USS策略。针对DMD与CCD不匹配导致USS测量无法完美分解的问题，提出**BSTFormer**，这是一种稀疏Transformer，利用局部块注意力、全局稀疏注意力和全局时间注意力，以充分利用USS测量的稀疏性进行高速帧恢复。

Result: 在模拟和真实世界数据上进行的广泛实验表明，所提出的方法显著优于所有先前的最先进算法。此外，USS策略相比随机采样（RS）策略具有更高的动态范围。

Conclusion: USS策略结合BSTFormer是解决高分辨率、高帧率视频捕获高功耗问题的有效方案。由于其固定的曝光时间，USS策略是实现完整视频SCI片上系统的理想选择，具有良好的应用前景。

Abstract: Digital cameras consume ~0.1 microjoule per pixel to capture and encode
video, resulting in a power usage of ~20W for a 4K sensor operating at 30 fps.
Imagining gigapixel cameras operating at 100-1000 fps, the current processing
model is unsustainable. To address this, physical layer compressive measurement
has been proposed to reduce power consumption per pixel by 10-100X. Video
Snapshot Compressive Imaging (SCI) introduces high frequency modulation in the
optical sensor layer to increase effective frame rate. A commonly used sampling
strategy of video SCI is Random Sampling (RS) where each mask element value is
randomly set to be 0 or 1. Similarly, image inpainting (I2P) has demonstrated
that images can be recovered from a fraction of the image pixels. Inspired by
I2P, we propose Ultra-Sparse Sampling (USS) regime, where at each spatial
location, only one sub-frame is set to 1 and all others are set to 0. We then
build a Digital Micro-mirror Device (DMD) encoding system to verify the
effectiveness of our USS strategy. Ideally, we can decompose the USS
measurement into sub-measurements for which we can utilize I2P algorithms to
recover high-speed frames. However, due to the mismatch between the DMD and
CCD, the USS measurement cannot be perfectly decomposed. To this end, we
propose BSTFormer, a sparse TransFormer that utilizes local Block attention,
global Sparse attention, and global Temporal attention to exploit the sparsity
of the USS measurement. Extensive results on both simulated and real-world data
show that our method significantly outperforms all previous state-of-the-art
algorithms. Additionally, an essential advantage of the USS strategy is its
higher dynamic range than that of the RS strategy. Finally, from the
application perspective, the USS strategy is a good choice to implement a
complete video SCI system on chip due to its fixed exposure time.

</details>


### [29] [GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation](https://arxiv.org/abs/2509.08232)
*Seongho Kim,Sejong Ryu,Hyoukjun You,Je Hyeong Hong*

Main category: cs.CV

TL;DR: 本文介绍了一个名为GTA-Crime的致命视频异常检测数据集和生成框架，利用《侠盗猎车手5》生成模拟数据，并提出了一种领域适应策略以提高现实世界中致命暴力事件的检测准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管视频异常检测（VAD）在识别监控视频中的犯罪活动方面有所进展，但致命事件（如枪击和刺伤）由于其稀有性以及数据收集的伦理问题，仍然难以检测。

Method: 1. 引入了GTA-Crime数据集和生成框架，利用《侠盗猎车手5》生成包含枪击和刺伤等致命场景的视频，涵盖多种视角和条件。2. 提出了一种基于Wasserstein对抗训练的片段级领域适应策略，以弥合合成GTA-Crime特征与真实世界特征（如UCF-Crime）之间的差距。

Result: 实验结果验证了GTA-Crime数据集的有效性，并表明将GTA-Crime与所提出的领域适应策略相结合，能持续提高现实世界中致命暴力检测的准确性。

Conclusion: GTA-Crime数据集和数据生成框架已公开发布，通过结合合成数据和领域适应策略，可以有效提升现实世界中致命暴力事件的检测能力。

Abstract: Recent advancements in video anomaly detection (VAD) have enabled
identification of various criminal activities in surveillance videos, but
detecting fatal incidents such as shootings and stabbings remains difficult due
to their rarity and ethical issues in data collection. Recognizing this
limitation, we introduce GTA-Crime, a fatal video anomaly dataset and
generation framework using Grand Theft Auto 5 (GTA5). Our dataset contains
fatal situations such as shootings and stabbings, captured from CCTV multiview
perspectives under diverse conditions including action types, weather, time of
day, and viewpoints. To address the rarity of such scenarios, we also release a
framework for generating these types of videos. Additionally, we propose a
snippet-level domain adaptation strategy using Wasserstein adversarial training
to bridge the gap between synthetic GTA-Crime features and real-world features
like UCF-Crime. Experimental results validate our GTA-Crime dataset and
demonstrate that incorporating GTA-Crime with our domain adaptation strategy
consistently enhances real world fatal violence detection accuracy. Our dataset
and the data generation framework are publicly available at
https://github.com/ta-ho/GTA-Crime.

</details>


### [30] [RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification](https://arxiv.org/abs/2509.08234)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 本文提出RepViT-CXR，一种通道复制策略，使Vision Transformers（ViTs）能有效处理灰度胸部X射线（CXR）图像。该方法在结核病和肺炎检测任务中均取得了新的最先进（SOTA）性能，展现了其在临床应用中的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs) 在自动化医学图像分析中表现出强大潜力，但它们通常需要三通道输入且预训练于自然图像。胸部X射线 (CXR) 图像本质上是灰度的单通道图像，这限制了ViTs在其上的直接应用，存在一个通道不匹配的空白。

Method: 为了解决灰度CXR与ViT三通道输入要求之间的不匹配，作者提出RepViT-CXR，这是一种通道复制策略，通过简单地复制单通道CXR图像以生成ViT兼容的三通道格式，同时避免引入额外的信息损失。

Result: RepViT-CXR在三个基准数据集上均表现优异：在TB-CXR数据集上，准确率99.9%，AUC 99.9%，超越了Topo-CXR等现有SOTA方法。在儿童肺炎数据集上，准确率99.0%，AUC 99.0%，优于DCNN和VGG16等强基线。在深圳TB数据集上，准确率91.1%，AUC 91.2%，性能优于此前报道的CNN方法。

Conclusion: RepViT-CXR证明了简单而有效的通道复制策略能够使ViTs充分发挥其在灰度医学影像任务中的表示能力。该方法在胸部X射线结核病和肺炎检测方面建立了新的SOTA，并具有在实际临床筛查系统中部署的巨大潜力。

Abstract: Chest X-ray (CXR) imaging remains one of the most widely used diagnostic
tools for detecting pulmonary diseases such as tuberculosis (TB) and pneumonia.
Recent advances in deep learning, particularly Vision Transformers (ViTs), have
shown strong potential for automated medical image analysis. However, most ViT
architectures are pretrained on natural images and require three-channel
inputs, while CXR scans are inherently grayscale. To address this gap, we
propose RepViT-CXR, a channel replication strategy that adapts single-channel
CXR images into a ViT-compatible format without introducing additional
information loss. We evaluate RepViT-CXR on three benchmark datasets. On the
TB-CXR dataset,our method achieved an accuracy of 99.9% and an AUC of 99.9%,
surpassing prior state-of-the-art methods such as Topo-CXR (99.3% accuracy,
99.8% AUC). For the Pediatric Pneumonia dataset, RepViT-CXR obtained 99.0%
accuracy, with 99.2% recall, 99.3% precision, and an AUC of 99.0%,
outperforming strong baselines including DCNN and VGG16. On the Shenzhen TB
dataset, our approach achieved 91.1% accuracy and an AUC of 91.2%, marking a
performance improvement over previously reported CNN-based methods. These
results demonstrate that a simple yet effective channel replication strategy
allows ViTs to fully leverage their representational power on grayscale medical
imaging tasks. RepViT-CXR establishes a new state of the art for TB and
pneumonia detection from chest X-rays, showing strong potential for deployment
in real-world clinical screening systems.

</details>


### [31] [Symmetry Interactive Transformer with CNN Framework for Diagnosis of Alzheimer's Disease Using Structural MRI](https://arxiv.org/abs/2509.08243)
*Zheng Yang,Yanteng Zhang,Xupeng Kou,Yang Liu,Chao Ren*

Main category: cs.CV

TL;DR: 本研究提出一种结合3D CNN编码器和对称交互式Transformer (SIT) 的端到端网络，用于检测阿尔茨海默病（AD）引起的脑部不对称性，并在ADNI数据集上取得了92.5%的诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的AD诊断方法多依赖预训练或忽略了脑部疾病导致的不对称特征。本研究旨在解决这一问题，通过关注左右脑萎缩引起的不对称性来提高诊断性能。

Method: 提出一个端到端网络，由3D CNN编码器和对称交互式Transformer (SIT) 组成。该方法通过“inter-equal grid block fetch”操作对齐左右半球特征，然后将其输入SIT进行诊断分析。SIT旨在使模型更关注结构变化引起的不对称区域。

Result: 在ADNI数据集上进行评估，该方法实现了92.5%的诊断准确率，优于几种CNN方法和结合通用Transformer的CNN方法。可视化结果表明，该网络更关注脑萎缩区域，特别是AD引起的不对称病理特征。

Conclusion: 本研究提出的方法通过有效地捕捉AD引起的左右脑不对称特征，显著提高了诊断性能和可解释性，展示了其在AD诊断中的有效性。

Abstract: Structural magnetic resonance imaging (sMRI) combined with deep learning has
achieved remarkable progress in the prediction and diagnosis of Alzheimer's
disease (AD). Existing studies have used CNN and transformer to build a
well-performing network, but most of them are based on pretraining or ignoring
the asymmetrical character caused by brain disorders. We propose an end-to-end
network for the detection of disease-based asymmetric induced by left and right
brain atrophy which consist of 3D CNN Encoder and Symmetry Interactive
Transformer (SIT). Following the inter-equal grid block fetch operation, the
corresponding left and right hemisphere features are aligned and subsequently
fed into the SIT for diagnostic analysis. SIT can help the model focus more on
the regions of asymmetry caused by structural changes, thus improving
diagnostic performance. We evaluated our method based on the ADNI dataset, and
the results show that the method achieves better diagnostic accuracy (92.5\%)
compared to several CNN methods and CNNs combined with a general transformer.
The visualization results show that our network pays more attention in regions
of brain atrophy, especially for the asymmetric pathological characteristics
induced by AD, demonstrating the interpretability and effectiveness of the
method.

</details>


### [32] [EVDI++: Event-based Video Deblurring and Interpolation via Self-Supervised Learning](https://arxiv.org/abs/2509.08260)
*Chi Zhang,Xiang Zhang,Chenxu Jiang,Gui-Song Xia,Lei Yu*

Main category: cs.CV

TL;DR: EVDI++是一个统一的自监督框架，利用事件相机的高时间分辨率，解决传统帧相机因长时间曝光导致的视频模糊和帧间信息丢失问题，实现视频去模糊和插帧，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统帧相机长时间曝光会导致感知上的视觉模糊和帧间信息损失，严重降低视频质量。现有方法难以有效缓解运动模糊并实现中间帧预测，亟需一种新的解决方案。

Method: 引入EVDI++自监督框架，包含：1. 可学习双积分(LDI)网络，用于估计参考帧和清晰潜在图像的映射关系；2. 基于学习的分区重建模块，精炼结果并优化训练效率，支持不同曝光间隔转换；3. 自适应无参数融合策略，利用并发事件LDI输出的置信度获取最终结果；4. 通过探索模糊帧、潜在图像和事件流之间的相互约束，提出自监督学习框架以用真实世界数据训练；5. 构建了包含真实世界模糊图像和事件的数据集。

Result: 在合成和真实世界数据集上的广泛实验表明，EVDI++在视频去模糊和插帧任务中均达到了最先进的性能，并展示了在真实世界场景中的泛化能力。

Conclusion: EVDI++成功地利用事件相机数据解决了视频模糊和插帧的挑战，通过其创新的自监督框架和模块设计，实现了卓越的去模糊和插帧效果，并在实际应用中表现出强大的鲁棒性。

Abstract: Frame-based cameras with extended exposure times often produce perceptible
visual blurring and information loss between frames, significantly degrading
video quality. To address this challenge, we introduce EVDI++, a unified
self-supervised framework for Event-based Video Deblurring and Interpolation
that leverages the high temporal resolution of event cameras to mitigate motion
blur and enable intermediate frame prediction. Specifically, the Learnable
Double Integral (LDI) network is designed to estimate the mapping relation
between reference frames and sharp latent images. Then, we refine the coarse
results and optimize overall training efficiency by introducing a
learning-based division reconstruction module, enabling images to be converted
with varying exposure intervals. We devise an adaptive parameter-free fusion
strategy to obtain the final results, utilizing the confidence embedded in the
LDI outputs of concurrent events. A self-supervised learning framework is
proposed to enable network training with real-world blurry videos and events by
exploring the mutual constraints among blurry frames, latent images, and event
streams. We further construct a dataset with real-world blurry images and
events using a DAVIS346c camera, demonstrating the generalizability of the
proposed EVDI++ in real-world scenarios. Extensive experiments on both
synthetic and real-world datasets show that our method achieves
state-of-the-art performance in video deblurring and interpolation tasks.

</details>


### [33] [Hyperspectral Mamba for Hyperspectral Object Tracking](https://arxiv.org/abs/2509.08265)
*Long Gao,Yunhe Zhang,Yan Jiang,Weiying Xie,Yunsong Li*

Main category: cs.CV

TL;DR: 提出HyMamba，一种基于Mamba的超光谱目标跟踪网络，通过状态空间模块（SSMs）统一建模光谱、跨深度和时间信息，取得了最先进的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有超光谱跟踪器未能有效捕获内在光谱信息、时间依赖性及跨深度交互，限制了其在复杂场景中的表现。

Method: 本文提出HyMamba超光谱目标跟踪网络，利用状态空间模块（SSMs）统一光谱、跨深度和时间建模。其核心是光谱状态集成（SSI）模块，实现光谱特征的渐进式提炼和传播；SSI内嵌超光谱Mamba（HSM）模块，通过三向扫描SSMs同步学习空间和光谱信息。HyMamba通过交互作用，结合伪彩色和超光谱输入构建联合特征，并利用原始光谱特征进行增强。

Result: 在七个基准数据集上进行了广泛实验，结果表明HyMamba取得了最先进的性能。例如，在HOTC2020数据集上，AUC分数为73.0%，DP@20分数为96.3%。

Conclusion: HyMamba通过有效建模光谱、跨深度和时间信息，成功克服了现有超光谱跟踪器的局限性，显著提升了超光谱目标跟踪的性能。

Abstract: Hyperspectral object tracking holds great promise due to the rich spectral
information and fine-grained material distinctions in hyperspectral images,
which are beneficial in challenging scenarios. While existing hyperspectral
trackers have made progress by either transforming hyperspectral data into
false-color images or incorporating modality fusion strategies, they often fail
to capture the intrinsic spectral information, temporal dependencies, and
cross-depth interactions. To address these limitations, a new hyperspectral
object tracking network equipped with Mamba (HyMamba), is proposed. It unifies
spectral, cross-depth, and temporal modeling through state space modules
(SSMs). The core of HyMamba lies in the Spectral State Integration (SSI)
module, which enables progressive refinement and propagation of spectral
features with cross-depth and temporal spectral information. Embedded within
each SSI, the Hyperspectral Mamba (HSM) module is introduced to learn spatial
and spectral information synchronously via three directional scanning SSMs.
Based on SSI and HSM, HyMamba constructs joint features from false-color and
hyperspectral inputs, and enhances them through interaction with original
spectral features extracted from raw hyperspectral images. Extensive
experiments conducted on seven benchmark datasets demonstrate that HyMamba
achieves state-of-the-art performance. For instance, it achieves 73.0\% of the
AUC score and 96.3\% of the DP@20 score on the HOTC2020 dataset. The code will
be released at https://github.com/lgao001/HyMamba.

</details>


### [34] [Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features](https://arxiv.org/abs/2509.08266)
*Saurav Sengupta,Nazanin Moradinasab,Jiebei Liu,Donald E. Brown*

Main category: cs.CV

TL;DR: 现有视觉语言模型(VLM)在处理具体视觉问题时易受偏差影响。本研究开发了一个多维框架，系统分析图像和提示特征如何影响VLM性能和注意力，发现微小输入变化可导致VLM行为及性能的显著波动。


<details>
  <summary>Details</summary>
Motivation: VLMs在回答图像特定视觉属性问题时，会依赖训练偏见，尤其在面对高度具体的问题时，这种偏见会加剧并导致不准确。研究旨在系统地探究导致VLM性能差异的输入数据（图像和提示）特性，并了解其行为如何变化。

Method: 1. 开发了一个多维检查框架，以系统性地确定图像和伴随提示的哪些特征导致VLM的性能差异。2. 使用开源VLM，进一步检查注意力值如何随不同的输入参数（例如图像大小、图像中物体数量、背景颜色、提示特异性）而波动。

Result: 研究结果表明，即使图像特征和提示特异性的微小修改，也可能导致VLM形成答案的方式及其整体性能的巨大变化。

Conclusion: VLMs对输入数据（图像特性和提示特异性）的微小变化表现出高度敏感性，这会显著影响它们的行为和最终性能。因此，理解并表征这些变化对于改进VLM至关重要。

Abstract: Recent research on Vision Language Models (VLMs) suggests that they rely on
inherent biases learned during training to respond to questions about visual
properties of an image. These biases are exacerbated when VLMs are asked highly
specific questions that require focusing on specific areas of the image. For
example, a VLM tasked with counting stars on a modified American flag (e.g.,
with more than 50 stars) will often disregard the visual evidence and fail to
answer accurately. We build upon this research and develop a multi-dimensional
examination framework to systematically determine which characteristics of the
input data, including both the image and the accompanying prompt, lead to such
differences in performance. Using open-source VLMs, we further examine how
attention values fluctuate with varying input parameters (e.g., image size,
number of objects in the image, background color, prompt specificity). This
research aims to learn how the behavior of vision language models changes and
to explore methods for characterizing such changes. Our results suggest, among
other things, that even minor modifications in image characteristics and prompt
specificity can lead to large changes in how a VLM formulates its answer and,
subsequently, its overall performance.

</details>


### [35] [Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration](https://arxiv.org/abs/2509.08280)
*Hyeonseok Kim,Byeongkeun Kang,Yeejin Lee*

Main category: cs.CV

TL;DR: 本文提出E3DPC-GZSL方法，通过集成基于证据的不确定性估计器并优化语义空间，解决了3D点云广义零样本语义分割中模型对已知类别过拟合的问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 3D点云的广义零样本语义分割面临模型预测偏向于训练中见过的类别（seen classes）的问题，尤其是在3D数据量相对较小的情况下。这导致对未见过类别（unseen classes）的预测不准确。

Method: 本文提出E3DPC-GZSL方法，主要包括：1) 将基于证据的不确定性估计器整合到分类器中，以减少对已知类别的过自信预测；2) 使用动态校准堆叠因子，根据逐点预测不确定性调整预测概率；3) 引入新颖的训练策略，通过将可学习参数与文本派生特征融合来细化语义空间，从而改进不确定性估计并优化模型对未见过数据的学习。

Result: E3DPC-GZSL方法在ScanNet v2和S3DIS等广义零样本语义分割数据集上，取得了最先进的性能。

Conclusion: E3DPC-GZSL通过有效解决已知类别偏置问题，显著提升了3D点云广义零样本语义分割的性能，为该领域提供了新的解决方案。

Abstract: Generalized zero-shot semantic segmentation of 3D point clouds aims to
classify each point into both seen and unseen classes. A significant challenge
with these models is their tendency to make biased predictions, often favoring
the classes encountered during training. This problem is more pronounced in 3D
applications, where the scale of the training data is typically smaller than in
image-based tasks. To address this problem, we propose a novel method called
E3DPC-GZSL, which reduces overconfident predictions towards seen classes
without relying on separate classifiers for seen and unseen data. E3DPC-GZSL
tackles the overconfidence problem by integrating an evidence-based uncertainty
estimator into a classifier. This estimator is then used to adjust prediction
probabilities using a dynamic calibrated stacking factor that accounts for
pointwise prediction uncertainty. In addition, E3DPC-GZSL introduces a novel
training strategy that improves uncertainty estimation by refining the semantic
space. This is achieved by merging learnable parameters with text-derived
features, thereby improving model optimization for unseen data. Extensive
experiments demonstrate that the proposed approach achieves state-of-the-art
performance on generalized zero-shot semantic segmentation datasets, including
ScanNet v2 and S3DIS.

</details>


### [36] [Dual-Thresholding Heatmaps to Cluster Proposals for Weakly Supervised Object Detection](https://arxiv.org/abs/2509.08289)
*Yuelin Guo,Haoyu He,Zhiyuan Chen,Zitong Huang,Renhao Lu,Lu Shi,Zejun Wang,Weizhe Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的弱监督目标检测（WSOD）框架，通过引入热图引导的建议区域选择器、弱监督基础检测网络和负确定性监督损失，解决了现有WSOD方法在伪真值生成、背景表示和收敛速度方面的局限性，并达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有WSOD方法存在三个主要局限性：1. 伪真值框生成不准确，要么只关注判别性部分导致目标不完整，要么无法区分相邻同类实例；2. WSDDN架构缺乏背景类表示，且分支间存在语义鸿沟；3. 优化过程中丢弃被忽略的建议区域，导致收敛缓慢。

Method: 1. 设计了热图引导的建议区域选择器（HGPS）算法，利用热图双阈值预选建议区域，以捕捉完整目标并区分相邻实例。2. 提出了弱监督基础检测网络（WSBDN），为每个建议区域增加背景类表示，并利用热图进行预监督以弥合语义鸿沟。3. 引入了对被忽略建议区域的负确定性监督损失，以加速收敛。

Result: 在PASCAL VOC 2007数据集上，mAP/mCorLoc分数达到58.5%/81.8%；在PASCAL VOC 2012数据集上，mAP/mCorLoc分数达到55.6%/80.5%。这些结果优于现有的WSOD方法。

Conclusion: 所提出的框架有效解决了弱监督目标检测中的关键挑战，通过改进伪真值生成、增强网络架构和加速收敛，显著提升了WSOD性能，达到了当前最先进的水平。

Abstract: Weakly supervised object detection (WSOD) has attracted significant attention
in recent years, as it does not require box-level annotations. State-of-the-art
methods generally adopt a multi-module network, which employs WSDDN as the
multiple instance detection network module and multiple instance refinement
modules to refine performance. However, these approaches suffer from three key
limitations. First, existing methods tend to generate pseudo GT boxes that
either focus only on discriminative parts, failing to capture the whole object,
or cover the entire object but fail to distinguish between adjacent intra-class
instances. Second, the foundational WSDDN architecture lacks a crucial
background class representation for each proposal and exhibits a large semantic
gap between its branches. Third, prior methods discard ignored proposals during
optimization, leading to slow convergence. To address these challenges, we
first design a heatmap-guided proposal selector (HGPS) algorithm, which
utilizes dual thresholds on heatmaps to pre-select proposals, enabling pseudo
GT boxes to both capture the full object extent and distinguish between
adjacent intra-class instances. We then present a weakly supervised basic
detection network (WSBDN), which augments each proposal with a background class
representation and uses heatmaps for pre-supervision to bridge the semantic gap
between matrices. At last, we introduce a negative certainty supervision loss
on ignored proposals to accelerate convergence. Extensive experiments on the
challenging PASCAL VOC 2007 and 2012 datasets demonstrate the effectiveness of
our framework. We achieve mAP/mCorLoc scores of 58.5%/81.8% on VOC 2007 and
55.6%/80.5% on VOC 2012, performing favorably against the state-of-the-art WSOD
methods. Our code is publicly available at
https://github.com/gyl2565309278/DTH-CP.

</details>


### [37] [An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm Mapping in Indonesia](https://arxiv.org/abs/2509.08303)
*M. Warizmi Wafiq,Peter Cutter,Ate Poortinga,Daniel Marc G. dela Torre,Karis Tenneson,Vanna Teck,Enikoe Bihari,Chanarun Saisaward,Weraphong Suaruang,Andrea McMahon,Andi Vika Faradiba Muin,Karno B. Batiran,Chairil A,Nurul Qomar,Arya Arismaya Metananda,David Ganz,David Saah*

Main category: cs.CV

TL;DR: 本文发布了一个开放获取的印度尼西亚油棕种植园及其相关土地覆盖类型的地理空间数据集，该数据集通过专家标注高分辨率卫星图像创建，旨在提高土地覆盖测绘精度并支持森林砍伐监测。


<details>
  <summary>Details</summary>
Motivation: 印度尼西亚的油棕种植是森林砍伐的主要原因之一。为有效追踪并应对此挑战，急需详细可靠的地图数据以支持可持续发展工作和新兴监管框架。

Method: 通过专家标注2020年至2024年的高分辨率卫星图像，生成了一个开放获取的、基于多边形的、全覆盖的地理空间数据集。该数据集包含区分油棕种植阶段及类似多年生作物的分层类型学。数据质量通过多解释器共识和实地验证确保，并采用大网格上的全覆盖数字化技术。

Result: 该数据集适合训练和基准测试传统卷积神经网络及新型地理空间基础模型。它填补了遥感训练数据的关键空白，旨在显著提高土地覆盖类型测绘的准确性。

Conclusion: 该数据集通过支持对油棕扩张的透明监测，有助于实现全球减少森林砍伐的目标，并遵循FAIR数据原则，对可持续发展和环境治理具有重要意义。

Abstract: Oil palm cultivation remains one of the leading causes of deforestation in
Indonesia. To better track and address this challenge, detailed and reliable
mapping is needed to support sustainability efforts and emerging regulatory
frameworks. We present an open-access geospatial dataset of oil palm
plantations and related land cover types in Indonesia, produced through expert
labeling of high-resolution satellite imagery from 2020 to 2024. The dataset
provides polygon-based, wall-to-wall annotations across a range of
agro-ecological zones and includes a hierarchical typology that distinguishes
oil palm planting stages as well as similar perennial crops. Quality was
ensured through multi-interpreter consensus and field validation. The dataset
was created using wall-to-wall digitization over large grids, making it
suitable for training and benchmarking both conventional convolutional neural
networks and newer geospatial foundation models. Released under a CC-BY
license, it fills a key gap in training data for remote sensing and aims to
improve the accuracy of land cover types mapping. By supporting transparent
monitoring of oil palm expansion, the resource contributes to global
deforestation reduction goals and follows FAIR data principles.

</details>


### [38] [SimCroP: Radiograph Representation Learning with Similarity-driven Cross-granularity Pre-training](https://arxiv.org/abs/2509.08311)
*Rongsheng Wang,Fenghe Tang,Qingsong Yao,Rui Yan,Xu Zhang,Zhen Huang,Haoran Lai,Zhiyang He,Xiaodong Tao,Zihang Jiang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出SimCroP框架，通过相似性驱动对齐和跨粒度融合，解决了CT影像中病灶稀疏性和报告-图像复杂对应关系问题，显著提升了放射影像解读在分类和分割任务上的性能，超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 在CT扫描中，病灶分布具有空间稀疏性且结构复杂。此外，报告中不同病理描述与CT图像对应子区域之间的关系复杂且隐蔽，给医学视觉-语言预训练带来了额外挑战。

Method: 本文提出了名为SimCroP（Similarity-Driven Cross-Granularity Pre-training）的框架，该框架结合了相似性驱动对齐和跨粒度融合：1. 利用多模态掩码建模优化编码器以理解低级语义。2. 设计相似性驱动对齐来预训练编码器，以自适应地选择并对齐报告中每个句子对应的图像块。3. 引入跨粒度融合模块，整合实例级别和词-图像块级别的多模态信息，以更好地捕获稀疏影像中的关键病理结构。

Result: SimCroP在大规模CT-报告配对数据集上进行预训练，并在五个公共数据集上的图像分类和分割任务中进行了验证。实验结果表明，SimCroP优于最先进的医学自监督学习方法和医学视觉-语言预训练方法。

Conclusion: SimCroP框架通过有效结合相似性驱动对齐和跨粒度融合，能够更好地捕获稀疏放射影像中的关键病理结构，从而显著提高多尺度下游任务的性能，改善了放射影像解读效果。

Abstract: Medical vision-language pre-training shows great potential in learning
representative features from massive paired radiographs and reports. However,
in computed tomography (CT) scans, the distribution of lesions which contain
intricate structures is characterized by spatial sparsity. Besides, the complex
and implicit relationships between different pathological descriptions in each
sentence of the report and their corresponding sub-regions in radiographs pose
additional challenges. In this paper, we propose a Similarity-Driven
Cross-Granularity Pre-training (SimCroP) framework on chest CTs, which combines
similarity-driven alignment and cross-granularity fusion to improve radiograph
interpretation. We first leverage multi-modal masked modeling to optimize the
encoder for understanding precise low-level semantics from radiographs. Then,
similarity-driven alignment is designed to pre-train the encoder to adaptively
select and align the correct patches corresponding to each sentence in reports.
The cross-granularity fusion module integrates multimodal information across
instance level and word-patch level, which helps the model better capture key
pathology structures in sparse radiographs, resulting in improved performance
for multi-scale downstream tasks. SimCroP is pre-trained on a large-scale
paired CT-reports dataset and validated on image classification and
segmentation tasks across five public datasets. Experimental results
demonstrate that SimCroP outperforms both cutting-edge medical self-supervised
learning methods and medical vision-language pre-training methods. Codes and
models are available at https://github.com/ToniChopp/SimCroP.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [39] [Learning-Based Planning for Improving Science Return of Earth Observation Satellites](https://arxiv.org/abs/2509.07997)
*Abigail Breitfeld,Alberto Candela,Juan Delfa,Akseli Kangaslahti,Itai Zilberstein,Steve Chien,David Wettergreen*

Main category: cs.AI

TL;DR: 本文提出了基于强化学习和模仿学习的两种动态目标定位方法，用于优化地球观测卫星的数据采集，实验证明这些方法比传统启发式方法能更有效地收集科学信息，且对数据量要求不高。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星在轨道、视场和资源消耗方面存在局限性，需要优化数据采集以仅获取最重要的信息。动态目标定位是新兴概念，旨在智能地重新配置和指向主仪器以增加科学信息量，但现有方法有改进空间。

Method: 本研究提出了两种基于学习的方法：强化学习（RL）和模仿学习（IL）。这些方法基于动态规划解决方案来规划采样位置序列。通过与现有的启发式方法进行比较来评估其性能。

Result: 模仿学习平均比最佳启发式方法性能提高10.0%，强化学习平均提高13.7%。两种学习方法都能用相对少量的数据进行有效训练。

Conclusion: 基于学习的方法（强化学习和模仿学习）在地球观测卫星的动态目标定位应用中具有显著优势，能够有效提升科学信息收集量，并且训练效率高。

Abstract: Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.

</details>


### [40] [EnvX: Agentize Everything with Agentic AI](https://arxiv.org/abs/2509.08088)
*Linyao Chen,Zimian Peng,Yingxuan Yang,Yikun Wang,Wenzheng Tom Tang,Hiroki H. Kobayashi,Weinan Zhang*

Main category: cs.AI

TL;DR: EnvX框架利用Agentic AI将GitHub仓库转化为智能、自治的代理，通过自然语言交互和代理间协作，自动化了开源组件的理解、初始化和操作，显著提高了软件复用效率，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管开源组件众多，但其利用过程仍是手动、易错且分散的。开发者需手动理解文档、API并编写集成代码，这严重阻碍了高效的软件复用。

Method: 提出EnvX框架，通过Agentic AI将GitHub仓库“代理化”，使其成为智能、自治的代理。该框架包含三个阶段：1) TODO引导的环境初始化；2) 人类对齐的代理自动化，执行实际任务；3) 代理间(A2A)协议，实现多代理协作。它结合大语言模型能力与结构化工具集成，自动化了仓库功能的理解、初始化和操作全过程。

Result: EnvX在GitTaskBench基准测试（涵盖18个仓库）中，实现了74.07%的执行完成率和51.85%的任务通过率，优于现有框架。案例研究进一步证明了EnvX通过A2A协议实现多仓库协作的能力。

Conclusion: 这项工作标志着从将仓库视为被动代码资源转变为智能、交互式代理的范式转变，促进了开源生态系统中更高的可访问性和协作性。

Abstract: The widespread availability of open-source repositories has led to a vast
collection of reusable software components, yet their utilization remains
manual, error-prone, and disconnected. Developers must navigate documentation,
understand APIs, and write integration code, creating significant barriers to
efficient software reuse. To address this, we present EnvX, a framework that
leverages Agentic AI to agentize GitHub repositories, transforming them into
intelligent, autonomous agents capable of natural language interaction and
inter-agent collaboration. Unlike existing approaches that treat repositories
as static code resources, EnvX reimagines them as active agents through a
three-phase process: (1) TODO-guided environment initialization, which sets up
the necessary dependencies, data, and validation datasets; (2) human-aligned
agentic automation, allowing repository-specific agents to autonomously perform
real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple
agents to collaborate. By combining large language model capabilities with
structured tool integration, EnvX automates not just code generation, but the
entire process of understanding, initializing, and operationalizing repository
functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18
repositories across domains such as image processing, speech recognition,
document analysis, and video manipulation. Our results show that EnvX achieves
a 74.07% execution completion rate and 51.85% task pass rate, outperforming
existing frameworks. Case studies further demonstrate EnvX's ability to enable
multi-repository collaboration via the A2A protocol. This work marks a shift
from treating repositories as passive code resources to intelligent,
interactive agents, fostering greater accessibility and collaboration within
the open-source ecosystem.

</details>


### [41] [Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI](https://arxiv.org/abs/2509.08151)
*Botao Zhu,Jeslyn Wang,Dusit Niyato,Xianbin Wang*

Main category: cs.AI

TL;DR: 针对分布式计算任务中设备信任评估效率低和开销大的问题，提出基于大型AI模型驱动的2TSD师生代理模型，通过信任语义蒸馏实现快速准确的协作设备选择。


<details>
  <summary>Details</summary>
Motivation: 当每个任务所有者独立评估所有协作设备的信任度时，频繁的数据交换、复杂的推理和动态情境变化会导致显著的开销和信任评估的退化。

Method: 提出任务特定信任语义蒸馏（2TSD）模型，该模型基于大型AI模型（LAM）驱动的师生代理架构。教师代理部署在服务器端，负责收集多维信任数据、提取任务特定信任语义并进行匹配分析；学生代理在设备端接收教师代理传递的信任语义，从而快速准确地选择协作设备。

Result: 实验结果表明，所提出的2TSD模型能够减少协作设备评估时间，降低设备资源消耗，并提高协作设备选择的准确性。

Conclusion: 2TSD模型通过其创新的师生代理架构和信任语义蒸馏方法，有效解决了分布式任务协作中设备信任评估的效率、开销和准确性挑战，显著提升了任务执行的有效性。

Abstract: Accurate trustworthiness evaluation of potential collaborating devices is
essential for the effective execution of complex computing tasks. This
evaluation process involves collecting diverse trust-related data from
potential collaborators, including historical performance and available
resources, for collaborator selection. However, when each task owner
independently assesses all collaborators' trustworthiness, frequent data
exchange, complex reasoning, and dynamic situation changes can result in
significant overhead and deteriorated trust evaluation. To overcome these
challenges, we propose a task-specific trust semantics distillation (2TSD)
model based on a large AI model (LAM)-driven teacher-student agent
architecture. The teacher agent is deployed on a server with powerful
computational capabilities and an augmented memory module dedicated to
multidimensional trust-related data collection, task-specific trust semantics
extraction, and task-collaborator matching analysis. Upon receiving
task-specific requests from device-side student agents, the teacher agent
transfers the trust semantics of potential collaborators to the student agents,
enabling rapid and accurate collaborator selection. Experimental results
demonstrate that the proposed 2TSD model can reduce collaborator evaluation
time, decrease device resource consumption, and improve the accuracy of
collaborator selection.

</details>


### [42] [Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following](https://arxiv.org/abs/2509.08222)
*Minjong Yoo,Jinwoo Jang,Wei-jin Park,Honguk Woo*

Main category: cs.AI

TL;DR: 本研究提出ExRAP框架，通过高效探索环境和建立上下文记忆，增强LLM在动态非静态环境中持续指令遵循任务的具身推理能力，并整合信息探索和时间一致性优化，在多项具身任务中表现优于SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能体在动态、非静态环境中进行持续指令遵循任务的挑战，特别是增强大型语言模型（LLMs）的具身推理能力，使其能有效利用时变环境上下文进行任务规划。

Method: 1. 提出**Exploratory Retrieval-Augmented Planning (ExRAP)**框架，通过高效探索物理环境并建立环境上下文记忆，将任务规划与时变环境上下文有效结合。2. 将持续指令分解为对环境上下文记忆的查询和基于查询结果的任务执行。3. 实现**探索集成任务规划方案**，将**信息探索**整合到LLM的规划过程中。4. 结合**记忆增强查询评估**，平衡环境上下文记忆的有效性和探索负载，同时提高任务性能。5. 设计**时间一致性细化方案**用于查询评估，以解决记忆中知识的固有衰减问题。

Result: 1. 通过在VirtualHome、ALFRED和CARLA上的实验，证明了该方法在多种具身指令遵循场景（包括不同指令规模、类型和非静态程度）下的鲁棒性。2. 在**目标成功率**和**执行效率**方面，始终优于其他最先进的基于LLM的任务规划方法。

Conclusion: ExRAP框架通过有效地探索环境、建立并维护上下文记忆（包括时间一致性优化），显著提升了LLM在动态非静态环境中处理持续具身指令遵循任务的能力，并在关键性能指标上超越了现有先进方法，展现出强大的实用价值和鲁棒性。

Abstract: This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)
framework, designed to tackle continual instruction following tasks of embodied
agents in dynamic, non-stationary environments. The framework enhances Large
Language Models' (LLMs) embodied reasoning capabilities by efficiently
exploring the physical environment and establishing the environmental context
memory, thereby effectively grounding the task planning process in time-varying
environment contexts. In ExRAP, given multiple continual instruction following
tasks, each instruction is decomposed into queries on the environmental context
memory and task executions conditioned on the query results. To efficiently
handle these multiple tasks that are performed continuously and simultaneously,
we implement an exploration-integrated task planning scheme by incorporating
the {information-based exploration} into the LLM-based planning process.
Combined with memory-augmented query evaluation, this integrated scheme not
only allows for a better balance between the validity of the environmental
context memory and the load of environment exploration, but also improves
overall task performance. Furthermore, we devise a {temporal consistency
refinement} scheme for query evaluation to address the inherent decay of
knowledge in the memory. Through experiments with VirtualHome, ALFRED, and
CARLA, our approach demonstrates robustness against a variety of embodied
instruction following scenarios involving different instruction scales and
types, and non-stationarity degrees, and it consistently outperforms other
state-of-the-art LLM-based task planning approaches in terms of both goal
success rate and execution efficiency.

</details>


### [43] [Real-world Music Plagiarism Detection With Music Segment Transcription System](https://arxiv.org/abs/2509.08282)
*Seonghyeon Go*

Main category: cs.AI

TL;DR: 本文提出了一种结合多种音乐信息检索（MIR）技术的音乐抄袭检测系统，通过提取音乐片段并基于多维特征计算相似度，并在实验中取得了良好效果。同时，公开了一个基于真实案例的相似音乐对（SMP）数据集。


<details>
  <summary>Details</summary>
Motivation: 随着MIR技术的进步，音乐的生成和分发变得更加多样和便捷，因此对保护个人音乐版权和知识产权的需求日益增长。

Method: 开发了一个音乐片段转录系统，从音频记录中提取具有音乐意义的片段，以实现跨不同音乐格式的抄袭检测。随后，利用多种音乐特征计算相似度分数，并通过全面的音乐分析进行评估。

Result: 所提出的方法在音乐抄袭检测实验中展现出良好的前景，并可应用于实际音乐场景。此外，收集并公开发布了一个基于真实案例的相似音乐对（SMP）数据集。

Conclusion: 本研究提供了一个利用MIR技术有效检测音乐抄袭的系统，为音乐版权保护提供了实用解决方案，并公开发布了有助于音乐相似性研究的SMP数据集。

Abstract: As a result of continuous advances in Music Information Retrieval (MIR)
technology, generating and distributing music has become more diverse and
accessible. In this context, interest in music intellectual property protection
is increasing to safeguard individual music copyrights. In this work, we
propose a system for detecting music plagiarism by combining various MIR
technologies. We developed a music segment transcription system that extracts
musically meaningful segments from audio recordings to detect plagiarism across
different musical formats. With this system, we compute similarity scores based
on multiple musical features that can be evaluated through comprehensive
musical analysis. Our approach demonstrated promising results in music
plagiarism detection experiments, and the proposed method can be applied to
real-world music scenarios. We also collected a Similar Music Pair (SMP)
dataset for musical similarity research using real-world cases. The dataset are
publicly available.

</details>


### [44] [Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies](https://arxiv.org/abs/2509.08312)
*Binghan Wu,Shoufeng Wang,Yunxin Liu,Ya-Qin Zhang,Joseph Sifakis,Ye Ouyang*

Main category: cs.AI

TL;DR: 本文实现了一种基于Joseph Sifakis AN Agent参考架构的功能性认知系统，通过5G RAN链路自适应代理案例研究，验证了其在实现L4自治网络方面的潜力，展示了亚10毫秒实时控制、6%的下行吞吐量提升和67%的块错误率降低。


<details>
  <summary>Details</summary>
Motivation: 电信网络正向L4自治网络演进，需要超越被动自动化，实现真正的认知能力，以满足TM Forum关于自配置、自修复、自优化、零等待、零接触、零故障服务的愿景。研究旨在弥合架构理论与操作现实之间的鸿沟。

Method: 通过实现Joseph Sifakis的AN Agent参考架构，构建了一个功能性的认知系统。该系统部署了由混合知识表示驱动的协调式主动-被动运行时。通过对无线接入网络（RAN）链路自适应（LA）代理的实证案例研究来验证其框架。

Result: 该框架在5G NR sub-6 GHz中实现了亚10毫秒的实时控制，下行吞吐量比OLLA算法高出6%，并通过动态调制和编码方案（MCS）优化，使超可靠服务的块错误率（BLER）降低了67%。

Conclusion: 研究结果证实了该架构在克服传统自治障碍、推进L4级关键能力以实现下一代目标方面的可行性和变革潜力。

Abstract: The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a
strategic inflection point in telecommunications, where networks must transcend
reactive automation to achieve genuine cognitive capabilities--fulfilling TM
Forum's vision of self-configuring, self-healing, and self-optimizing systems
that deliver zero-wait, zero-touch, and zero-fault services. This work bridges
the gap between architectural theory and operational reality by implementing
Joseph Sifakis's AN Agent reference architecture in a functional cognitive
system, deploying coordinated proactive-reactive runtimes driven by hybrid
knowledge representation. Through an empirical case study of a Radio Access
Network (RAN) Link Adaptation (LA) Agent, we validate this framework's
transformative potential: demonstrating sub-10 ms real-time control in 5G NR
sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link
Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for
ultra-reliable services through dynamic Modulation and Coding Scheme (MCS)
optimization. These improvements confirm the architecture's viability in
overcoming traditional autonomy barriers and advancing critical L4-enabling
capabilities toward next-generation objectives.

</details>


### [45] [Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives](https://arxiv.org/abs/2509.08380)
*Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu*

Main category: cs.AI

TL;DR: 本文介绍了一个名为Co-Investigator AI的代理框架，旨在以更快的速度和更高的准确性生成符合监管要求的可疑活动报告（SAR），解决传统方法的高成本和低可扩展性，并克服大型语言模型在合规性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 反洗钱（AML）工作流程中，生成符合监管要求的可疑活动报告（SAR）成本高、可扩展性差，是一个瓶颈。大型语言模型（LLM）虽然语言流畅，但存在事实幻觉、犯罪类型对齐不足和可解释性差等问题，在合规性要求严格的领域构成不可接受的风险。

Method: 该研究提出了Co-Investigator AI，一个受自主代理架构启发（如AI Co-Scientist）的代理框架。它集成了专门的代理，用于规划、犯罪类型检测、外部情报收集和合规性验证。系统还具备动态内存管理、AI隐私保护层以及采用“代理即法官”范式的实时验证代理，确保叙述质量。人类调查员仍深度参与，进行审核和完善。

Result: Co-Investigator AI能够比传统方法更快、更准确地生成SAR。它在复杂金融犯罪场景中展现了多功能性，有效简化了SAR起草过程，使叙述符合监管期望，并使合规团队能够专注于更高层次的分析工作。

Conclusion: 该方法标志着合规报告新时代的开始，将AI代理的变革性优势引入监管流程核心，为可扩展、可靠和透明的SAR生成铺平道路，实现了AI效率与领域专业知识的结合。

Abstract: Generating regulatorily compliant Suspicious Activity Report (SAR) remains a
high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.
While large language models (LLMs) offer promising fluency, they suffer from
factual hallucination, limited crime typology alignment, and poor
explainability -- posing unacceptable risks in compliance-critical domains.
This paper introduces Co-Investigator AI, an agentic framework optimized to
produce Suspicious Activity Reports (SARs) significantly faster and with
greater accuracy than traditional methods. Drawing inspiration from recent
advances in autonomous agent architectures, such as the AI Co-Scientist, our
approach integrates specialized agents for planning, crime type detection,
external intelligence gathering, and compliance validation. The system features
dynamic memory management, an AI-Privacy Guard layer for sensitive data
handling, and a real-time validation agent employing the Agent-as-a-Judge
paradigm to ensure continuous narrative quality assurance. Human investigators
remain firmly in the loop, empowered to review and refine drafts in a
collaborative workflow that blends AI efficiency with domain expertise. We
demonstrate the versatility of Co-Investigator AI across a range of complex
financial crime scenarios, highlighting its ability to streamline SAR drafting,
align narratives with regulatory expectations, and enable compliance teams to
focus on higher-order analytical work. This approach marks the beginning of a
new era in compliance reporting -- bringing the transformative benefits of AI
agents to the core of regulatory processes and paving the way for scalable,
reliable, and transparent SAR generation.

</details>


### [46] [TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making](https://arxiv.org/abs/2509.08500)
*Kechen Jiao,Zhirui Fang,Jiahao Liu,Bei Li,Qifan Wang,Xinyu Liu,Junhao Ruan,Zhongjian Qiao,Yifan Zhu,Yaxin Xu,Jingang Wang,Xiu Li*

Main category: cs.AI

TL;DR: 本文提出Thought-Centric Preference Optimization (TCPO)方法，通过逐步偏好优化和思维过程对齐，解决了具身AI中视觉语言模型在动态任务中响应迟缓、幻觉及模型退化等问题，在ALFWorld环境中的成功率提升了6%。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLM)在具身AI的动态任务中有效泛化能力面临挑战。尽管SFT模型能与物理世界对齐，但在动态环境中仍存在响应迟缓和幻觉问题。现有后SFT方法（如强化学习和思维链）受限于稀疏奖励和仅行动优化，导致样本效率低、一致性差和模型退化。

Method: 本文提出“以思维为中心的偏好优化”（Thought-Centric Preference Optimization, TCPO）。该方法引入逐步偏好优化，将稀疏奖励转化为更丰富的步骤样本对；它强调对模型中间推理过程的对齐，以减轻模型退化；此外，通过引入“行动策略一致性约束”（Action Policy Consistency Constraint, APC），进一步施加模型输出的一致性约束。

Result: 在ALFWorld环境中的实验结果显示，TCPO的平均成功率为26.67%，比RL4VLM提高了6%。这验证了该方法在微调后减轻模型退化的有效性。

Conclusion: 研究结果表明，将基于偏好的学习技术与思维链(CoT)过程相结合，具有增强具身智能体中视觉语言模型决策能力的潜力。

Abstract: Using effective generalization capabilities of vision language models (VLMs)
in context-specific dynamic tasks for embodied artificial intelligence remains
a significant challenge. Although supervised fine-tuned models can better align
with the real physical world, they still exhibit sluggish responses and
hallucination issues in dynamically changing environments, necessitating
further alignment. Existing post-SFT methods, reliant on reinforcement learning
and chain-of-thought (CoT) approaches, are constrained by sparse rewards and
action-only optimization, resulting in low sample efficiency, poor consistency,
and model degradation. To address these issues, this paper proposes
Thought-Centric Preference Optimization (TCPO) for effective embodied
decision-making. Specifically, TCPO introduces a stepwise preference-based
optimization approach, transforming sparse reward signals into richer step
sample pairs. It emphasizes the alignment of the model's intermediate reasoning
process, mitigating the problem of model degradation. Moreover, by
incorporating Action Policy Consistency Constraint (APC), it further imposes
consistency constraints on the model output. Experiments in the ALFWorld
environment demonstrate an average success rate of 26.67%, achieving a 6%
improvement over RL4VLM and validating the effectiveness of our approach in
mitigating model degradation after fine-tuning. These results highlight the
potential of integrating preference-based learning techniques with CoT
processes to enhance the decision-making capabilities of vision-language models
in embodied agents.

</details>


### [47] [No-Knowledge Alarms for Misaligned LLMs-as-Judges](https://arxiv.org/abs/2509.08593)
*Andrés Corrada-Emmanuel*

Main category: cs.AI

TL;DR: 本研究利用LLM评审之间的逻辑一致性，通过线性规划问题，无需真实答案即可识别出不一致的LLM评审，并提供零误报的警报。


<details>
  <summary>Details</summary>
Motivation: 当使用LLM作为评审来评估其他LLM的复杂决策时，在缺乏真实答案且不信任评审的情况下，如何有效监控评审本身，避免无限监控链是亟待解决的问题。

Method: 通过利用不同LLM评审之间的逻辑一致性来缓解评估不确定性。具体方法是，观察LLM评审在评分时的同意与分歧情况，并将此逻辑形式化为一个在整数响应计数空间中的线性规划问题。

Result: 开发了用于检测不一致LLM评审的“无知识警报”。这些警报能够以零误报率检测出评审团中至少一名或多名成员违反了用户指定评分能力要求的情况。

Conclusion: 通过分析评审间的逻辑一致性并结合线性规划，本方法能有效且零误报地检测LLM评审的不一致性，为缺乏真实答案的复杂评估场景提供了一种可靠的评审监测机制。

Abstract: If we use LLMs as judges to evaluate the complex decisions of other LLMs, who
or what monitors the judges? Infinite monitoring chains are inevitable whenever
we do not know the ground truth of the decisions by experts and we do not want
to trust them. One way to ameliorate our evaluation uncertainty is to exploit
the use of logical consistency between disagreeing experts. By observing how
LLM judges agree and disagree while grading other LLMs, we can compute the only
possible evaluations of their grading ability. For example, if two LLM judges
disagree on which tasks a third one completed correctly, they cannot both be
100\% correct in their judgments. This logic can be formalized as a Linear
Programming problem in the space of integer response counts for any finite
test. We use it here to develop no-knowledge alarms for misaligned LLM judges.
The alarms can detect, with no false positives, that at least one member or
more of an ensemble of judges are violating a user specified grading ability
requirement.

</details>


### [48] [Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference](https://arxiv.org/abs/2509.08682)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Jiawei Shen,Jingjiang Liu,Yidan Liang*

Main category: cs.AI

TL;DR: 本文提出了一种基于多粒度因果推断的多智能体系统故障归因框架，显著提升了故障定位准确性和任务成功率，以解决现有诊断工具的不足。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在实际部署中面临严重的故障归因挑战，现有基于统计关联的诊断工具效果不佳（如在Who&When基准上准确率低于15%），急需一个能准确定位故障根本原因的解决方案。

Method: 引入了基于多粒度因果推断的故障归因框架。主要贡献包括：1) 性能因果反转原理结合Shapley值，通过反转执行日志中的数据流来准确分配智能体级别的责任；2) 新颖的因果发现算法CDC-MAS，用于处理MAS交互数据的非平稳性，以识别关键故障步骤。归因结果直接驱动自动化优化循环，并通过反事实模拟验证其有效性。

Result: 在Who&When和TRAIL基准测试中，方法表现出显著提升。步骤级准确率最高达到36.2%。生成的优化建议平均将整体任务成功率提高了22.4%。

Conclusion: 该工作为调试复杂智能体交互提供了一个有原则且有效的解决方案，为开发更可靠、更可解释的多智能体系统铺平了道路。

Abstract: Multi-agent systems (MAS) are critical for automating complex tasks, yet
their practical deployment is severely hampered by the challenge of failure
attribution. Current diagnostic tools, which rely on statistical correlations,
are fundamentally inadequate; on challenging benchmarks like Who\&When,
state-of-the-art methods achieve less than 15\% accuracy in locating the
root-cause step of a failure. To address this critical gap, we introduce the
first failure attribution framework for MAS grounded in multi-granularity
causal inference. Our approach makes two key technical contributions: (1) a
performance causal inversion principle, which correctly models performance
dependencies by reversing the data flow in execution logs, combined with
Shapley values to accurately assign agent-level blame; (2) a novel causal
discovery algorithm, CDC-MAS, that robustly identifies critical failure steps
by tackling the non-stationary nature of MAS interaction data. The framework's
attribution results directly fuel an automated optimization loop, generating
targeted suggestions whose efficacy is validated via counterfactual
simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a
significant leap in performance. Our method achieves up to 36.2\% step-level
accuracy. Crucially, the generated optimizations boost overall task success
rates by an average of 22.4\%. This work provides a principled and effective
solution for debugging complex agent interactions, paving the way for more
reliable and interpretable multi-agent systems.

</details>


### [49] [One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases](https://arxiv.org/abs/2509.08705)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文提出一个受认知科学双加工理论启发的心理理论（ToM）框架，结合图卷积网络（GCN）和元学习，能动态平衡直觉与审慎推理，成功复制人类认知偏差，并实现鲁棒泛化，为类人AI社交认知与决策奠定基础。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个受人类认知科学双加工理论启发的心理理论（ToM）框架，以模拟人类复杂的社交认知和自适应决策过程，并理解认知偏差的机制。

Method: 引入一个双加工ToM框架，其中System 1通过图卷积网络（GCN）实现快速、习惯性推理，System 2通过元学习技术驱动慢速、上下文敏感的元适应性学习。模型通过学习到的上下文门机制动态平衡这两种推理方式。在经典错误信念任务上进行验证，并系统性探索其复制锚定效应、认知负荷疲劳、框架效应和启动效应等认知偏差的能力。

Result: 实验结果表明，该双加工方法能够密切模拟人类的适应性行为，实现对未见上下文的鲁棒泛化，并阐明了推理偏差背后的认知机制。

Conclusion: 该工作弥合了人工智能和认知理论之间的鸿沟，为开发具有细致类人社交认知和适应性决策能力的人工智能系统铺平了道路。

Abstract: We introduce a novel Theory of Mind (ToM) framework inspired by dual-process
theories from cognitive science, integrating a fast, habitual graph-based
reasoning system (System 1), implemented via graph convolutional networks
(GCNs), and a slower, context-sensitive meta-adaptive learning system (System
2), driven by meta-learning techniques. Our model dynamically balances
intuitive and deliberative reasoning through a learned context gate mechanism.
We validate our architecture on canonical false-belief tasks and systematically
explore its capacity to replicate hallmark cognitive biases associated with
dual-process theory, including anchoring, cognitive-load fatigue, framing
effects, and priming effects. Experimental results demonstrate that our
dual-process approach closely mirrors human adaptive behavior, achieves robust
generalization to unseen contexts, and elucidates cognitive mechanisms
underlying reasoning biases. This work bridges artificial intelligence and
cognitive theory, paving the way for AI systems exhibiting nuanced, human-like
social cognition and adaptive decision-making capabilities.

</details>


### [50] [The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems](https://arxiv.org/abs/2509.08713)
*Ziming Luo,Atoosa Kasirzadeh,Nihar B. Shah*

Main category: cs.AI

TL;DR: 本文分析了AI科学家系统内部工作流程的潜在缺陷，识别了四种主要故障模式（如不当基准选择、数据泄露等），并通过实验在现有开源系统中发现了这些缺陷。研究强调了提交AI生成研究的完整日志和代码以确保透明度、可信度和可复现性的重要性。


<details>
  <summary>Details</summary>
Motivation: AI科学家系统虽有加速科学发现的巨大潜力，但其内部工作流程缺乏审查。这种审查缺失可能引入缺陷，损害其研究输出的完整性、可靠性和可信度。因此，有必要识别并检查这些系统中的潜在故障模式。

Method: 研究识别了当代AI科学家系统的四种潜在故障模式：不当的基准选择、数据泄露、度量滥用和事后选择偏差。为检验这些风险，设计了受控实验以隔离每种故障模式，并解决了评估AI科学家系统所特有的挑战。对两个知名的开源AI科学家系统进行了评估，并利用完整自动化工作流程的跟踪日志和代码来有效检测故障。

Result: 对两个知名开源AI科学家系统的评估揭示了存在一系列严重程度不一的失败，这些失败在实践中很容易被忽视。研究还表明，访问自动化工作流程的完整跟踪日志和代码比仅检查最终论文能更有效地检测此类故障。

Conclusion: 为确保透明度、问责制和可复现性，建议期刊和会议在评估AI生成的研究时，强制要求提交论文的同时附带完整的跟踪日志和代码等人工制品。

Abstract: AI scientist systems, capable of autonomously executing the full research
workflow from hypothesis generation and experimentation to paper writing, hold
significant potential for accelerating scientific discovery. However, the
internal workflow of these systems have not been closely examined. This lack of
scrutiny poses a risk of introducing flaws that could undermine the integrity,
reliability, and trustworthiness of their research outputs. In this paper, we
identify four potential failure modes in contemporary AI scientist systems:
inappropriate benchmark selection, data leakage, metric misuse, and post-hoc
selection bias. To examine these risks, we design controlled experiments that
isolate each failure mode while addressing challenges unique to evaluating AI
scientist systems. Our assessment of two prominent open-source AI scientist
systems reveals the presence of several failures, across a spectrum of
severity, which can be easily overlooked in practice. Finally, we demonstrate
that access to trace logs and code from the full automated workflow enables far
more effective detection of such failures than examining the final paper alone.
We thus recommend journals and conferences evaluating AI-generated research to
mandate submission of these artifacts alongside the paper to ensure
transparency, accountability, and reproducibility.

</details>


### [51] [Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making](https://arxiv.org/abs/2509.08785)
*Anup Tuladhar,Araz Minhas,Adam Kirton,Eli Kinney-Lang*

Main category: cs.AI

TL;DR: 本研究提出了一个结合强化学习和语言模型推理的初步实验平台，旨在探索叙事元素如何影响AI决策。


<details>
  <summary>Details</summary>
Motivation: AI的决策能力和叙事推理能力通常被分开研究，本平台旨在弥合这一鸿沟，探索叙事框架如何影响基于奖励的学习。

Method: 采用双系统架构，包含一个基于过往经验建议行动的强化学习策略和一个通过不同叙事框架处理这些建议以指导决策的语言模型。该架构在一个可配置的网格世界环境中实现，并具备模块化设计和详细的日志系统，用于捕获决策指标。

Result: 成功构建了一个初步的实验平台，该平台能够实现叙事元素与奖励结构保持一致的初步实验，并能进行环境复杂度、叙事参数以及强化学习与叙事决策之间交互的受控测试。

Conclusion: 该初步实施为研究不同叙事框架如何影响基于奖励的决策，以及探索AI系统中基于优化的学习与符号推理之间的潜在互动，奠定了重要的基础。

Abstract: We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [52] [Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization](https://arxiv.org/abs/2509.07993)
*Federico Fontana,Anxhelo Diko,Romeo Lanzino,Marco Raoul Marini,Bachir Kaddar,Gian Luca Foresti,Luigi Cinque*

Main category: cs.LG

TL;DR: 深度伪造检测面临技术快速演进挑战。本文将检测重构为持续学习问题，提出一个高效框架，能增量适应新作弊技术并保留历史知识。研究发现，虽然能高效适应历史，但现有方法对未来生成器的泛化能力接近随机，并据此提出“非普适性深度伪造分布假设”。


<details>
  <summary>Details</summary>
Motivation: 深度伪造生成技术发展迅速，导致现有非持续学习检测方法需要频繁且昂贵的再训练，难以有效适应不断涌现的新伪造技术，对检测系统构成严峻挑战。

Method: 将深度伪造检测（DFD）重构为持续学习（CL）问题，并提出一个高效框架。该框架通过模拟长达7年的真实世界深度伪造技术演变，而非依赖虚假模拟序列，以增量适应新兴视觉操作技术并保留历史知识。同时，采用轻量级视觉骨干网络以支持DFD系统的实时性能。此外，贡献了Continual AUC (C-AUC) 和Forward Transfer AUC (FWT-AUC) 两个新指标，分别用于评估历史性能和未来泛化能力。

Result: 通过600多次模拟实验证明：1) 框架能够实现高效适应（比完全再训练快155倍）并稳健保留历史知识。2) 然而，由于每个现有生成器独特的特征印记，当前方法在未额外训练的情况下，对未来生成器的泛化能力接近随机（FWT-AUC ≈ 0.5）。

Conclusion: 基于实验观察，提出了“非普适性深度伪造分布假设 (Non-Universal Deepfake Distribution Hypothesis)”，指出当前方法在未进行额外训练的情况下，难以有效泛化到未来的深度伪造生成器。

Abstract: The rapid evolution of deepfake generation technologies poses critical
challenges for detection systems, as non-continual learning methods demand
frequent and expensive retraining. We reframe deepfake detection (DFD) as a
Continual Learning (CL) problem, proposing an efficient framework that
incrementally adapts to emerging visual manipulation techniques while retaining
knowledge of past generators. Our framework, unlike prior approaches that rely
on unreal simulation sequences, simulates the real-world chronological
evolution of deepfake technologies in extended periods across 7 years.
Simultaneously, our framework builds upon lightweight visual backbones to allow
for the real-time performance of DFD systems. Additionally, we contribute two
novel metrics: Continual AUC (C-AUC) for historical performance and Forward
Transfer AUC (FWT-AUC) for future generalization. Through extensive
experimentation (over 600 simulations), we empirically demonstrate that while
efficient adaptation (+155 times faster than full retraining) and robust
retention of historical knowledge is possible, the generalization of current
approaches to future generators without additional training remains near-random
(FWT-AUC $\approx$ 0.5) due to the unique imprint characterizing each existing
generator. Such observations are the foundation of our newly proposed
Non-Universal Deepfake Distribution Hypothesis.
  \textbf{Code will be released upon acceptance.}

</details>


### [53] [How Far Are We from True Unlearnability?](https://arxiv.org/abs/2509.08058)
*Kai Ye,Liangcai Su,Chenxiong Qian*

Main category: cs.LG

TL;DR: 现有不可学习示例（UEs）在多任务场景下未能实现跨任务不可学习性。本文从模型优化角度探究原因，提出了基于损失平面的Sharpness-Aware Learnability (SAL) 和 Unlearnable Distance (UD) 来量化参数和数据不可学习性，并以此基准测试了主流不可学习方法，揭示了其能力边界。


<details>
  <summary>Details</summary>
Motivation: 大模型时代高质量数据至关重要，但未经授权的数据训练模型损害了数据所有者利益。为应对此威胁，已提出了多种不可学习方法。然而，研究发现，在Taskonomy等多任务数据集上，现有不可学习示例（UEs）在语义分割等任务上表现良好，未能展现跨任务不可学习性。这引发了疑问：我们距离实现真正不可学习的示例还有多远？

Method: 本文从模型优化角度分析，观察干净模型和受污染模型在简单架构下的收敛过程差异。从损失平面中发现，只有部分关键参数优化路径显示显著差异，暗示损失平面与不可学习性紧密相关。基于此，提出了Sharpness-Aware Learnability (SAL) 来量化参数的不可学习性，并进一步提出了Unlearnable Distance (UD) 来衡量数据的不可学习性（基于SAL分布）。最后，利用UD对主流不可学习方法进行了基准测试。

Result: 研究发现，在Taskonomy等多任务数据集上，现有不可学习示例（UEs）未能展现出预期的跨任务不可学习性，在部分任务中仍表现良好。通过模型优化分析，证实了损失平面与不可学习性之间的紧密关系，且干净模型与受污染模型在关键参数优化路径上仅部分显示显著差异。本文成功提出了SAL用于量化参数不可学习性，并提出了UD来衡量数据不可学习性。

Conclusion: 现有不可学习方法在实现真正跨任务不可学习性方面存在局限性。本文通过损失平面分析，提出SAL和UD量化不可学习性，旨在加深社区对现有不可学习方法能力边界的理解和认识，以期推动未来研究方向。

Abstract: High-quality data plays an indispensable role in the era of large models, but
the use of unauthorized data for model training greatly damages the interests
of data owners. To overcome this threat, several unlearnable methods have been
proposed, which generate unlearnable examples (UEs) by compromising the
training availability of data. Clearly, due to unknown training purposes and
the powerful representation learning capabilities of existing models, these
data are expected to be unlearnable for models across multiple tasks, i.e.,
they will not help improve the model's performance. However, unexpectedly, we
find that on the multi-task dataset Taskonomy, UEs still perform well in tasks
such as semantic segmentation, failing to exhibit cross-task unlearnability.
This phenomenon leads us to question: How far are we from attaining truly
unlearnable examples? We attempt to answer this question from the perspective
of model optimization. To this end, we observe the difference in the
convergence process between clean and poisoned models using a simple model
architecture. Subsequently, from the loss landscape we find that only a part of
the critical parameter optimization paths show significant differences,
implying a close relationship between the loss landscape and unlearnability.
Consequently, we employ the loss landscape to explain the underlying reasons
for UEs and propose Sharpness-Aware Learnability (SAL) to quantify the
unlearnability of parameters based on this explanation. Furthermore, we propose
an Unlearnable Distance (UD) to measure the unlearnability of data based on the
SAL distribution of parameters in clean and poisoned models. Finally, we
conduct benchmark tests on mainstream unlearnable methods using the proposed
UD, aiming to promote community awareness of the capability boundaries of
existing unlearnable methods.

</details>


### [54] [JEL: A Novel Model Linking Knowledge Graph entities to News Mentions](https://arxiv.org/abs/2509.08086)
*Michael Kishelev,Pranab Bhadani,Wanying Ding,Vinay Chaudhri*

Main category: cs.LG

TL;DR: JEL是一种新型高效的端到端多神经网络实体链接模型，性能优于当前最佳模型，旨在解决将文本提及链接到知识图谱的关键问题，尤其在新闻分析等领域具有重要应用价值。


<details>
  <summary>Details</summary>
Motivation: 利用知识图谱的核心问题是将文本中的提及正确链接到实体，这项任务（实体链接，EL）对自然语言处理和新闻分析平台等多种应用至关重要。在摩根大通，新闻分析是一项关键任务，面临巨大的市场需求（25个团队寻求解决方案）和高昂的外部供应商成本（每年超过200万美元）。有效的实体链接对于将非结构化新闻文本与知识图谱连接，从而使用户访问大量精选数据并提高工作效率至关重要。

Method: 提出并开发了JEL模型。JEL是一个新颖的、计算高效的端到端多神经网络实体链接模型。

Result: JEL模型在实体链接任务上的性能超越了当前最先进的模型。

Conclusion: JEL提供了一种高性能且计算高效的实体链接解决方案，能够有效桥接非结构化新闻文本与知识图谱，解决了在金融新闻分析等领域中面临的实际业务痛点，并能显著提升企业的数据利用效率。

Abstract: We present JEL, a novel computationally efficient end-to-end multi-neural
network based entity linking model, which beats current state-of-art model.
Knowledge Graphs have emerged as a compelling abstraction for capturing
critical relationships among the entities of interest and integrating data from
multiple heterogeneous sources. A core problem in leveraging a knowledge graph
is linking its entities to the mentions (e.g., people, company names) that are
encountered in textual sources (e.g., news, blogs., etc) correctly, since there
are thousands of entities to consider for each mention. This task of linking
mentions and entities is referred as Entity Linking (EL). It is a fundamental
task in natural language processing and is beneficial in various uses cases,
such as building a New Analytics platform. News Analytics, in JPMorgan, is an
essential task that benefits multiple groups across the firm. According to a
survey conducted by the Innovation Digital team 1 , around 25 teams across the
firm are actively looking for news analytics solutions, and more than \$2
million is being spent annually on external vendor costs. Entity linking is
critical for bridging unstructured news text with knowledge graphs, enabling
users access to vast amounts of curated data in a knowledge graph and
dramatically facilitating their daily work.

</details>


### [55] [Performance Assessment Strategies for Generative AI Applications in Healthcare](https://arxiv.org/abs/2509.08087)
*Victor Garcia,Mariia Sidulova,Aldo Badano*

Main category: cs.LG

TL;DR: 本文讨论了评估医疗领域生成式AI（GenAI）应用的现有先进方法，指出当前定量基准的局限性，并强调了结合人类专业知识和计算模型的评估策略日益受到关注。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在医疗领域有广泛应用，但其评估面临挑战。当前普遍使用的定量基准存在局限性，可能导致“训练过度拟合测试集”和泛化能力差的问题。因此，需要更全面和有效的评估策略。

Method: 本文采用讨论和分析的方法，探讨并总结了评估医疗保健和医疗设备中GenAI应用性能的当前最先进方法。

Result: 研究发现，当前用于评估生成模型的定量基准存在局限性，如易发生训练集过度拟合测试集、牺牲泛化能力等问题。同时，利用人类专业知识和经济高效的计算模型作为评估者的策略正受到越来越多的关注。

Conclusion: 评估医疗领域的GenAI应用需要深入理解临床任务和实际环境中的性能变异性。为克服现有定量基准的局限性，未来应更多地采用结合人类专业知识和计算模型的评估策略，以确保GenAI的泛化能力和可靠性。

Abstract: Generative artificial intelligence (GenAI) represent an emerging paradigm
within artificial intelligence, with applications throughout the medical
enterprise. Assessing GenAI applications necessitates a comprehensive
understanding of the clinical task and awareness of the variability in
performance when implemented in actual clinical environments. Presently, a
prevalent method for evaluating the performance of generative models relies on
quantitative benchmarks. Such benchmarks have limitations and may suffer from
train-to-the-test overfitting, optimizing performance for a specified test set
at the cost of generalizability across other task and data distributions.
Evaluation strategies leveraging human expertise and utilizing cost-effective
computational models as evaluators are gaining interest. We discuss current
state-of-the-art methodologies for assessing the performance of GenAI
applications in healthcare and medical devices.

</details>


### [56] [Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning](https://arxiv.org/abs/2509.08089)
*Lucas Fenaux,Zheng Wang,Jacob Yan,Nathan Chung,Florian Kerschbaum*

Main category: cs.LG

TL;DR: 本文提出一种新型自适应攻击，在联邦学习中仅需少量恶意客户端即可攻破现有SOTA后门防御。同时，提出“Hammer and Anvil”组合防御框架，其中Krum+能有效抵御这种新型攻击和现有SOTA攻击。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的分布式环境容易受到恶意客户端的后门攻击，而现有防御措施，尤其是在面对强大的自适应攻击者时，未能通过时间考验。因此，需要开发更强大的攻击来暴露现有防御的不足，并设计更鲁棒的防御策略。

Method: 首先，设计了一种超越现有对手能力的新型自适应攻击者，该攻击者只需20个客户端中的1-2个恶意客户端即可攻破最先进的防御。其次，提出“Hammer and Anvil”这一原则性防御方法，该方法结合了两种基于正交原理的防御机制，旨在形成一个在正确参数设置下能成功抵御任何攻击的组合防御。其中，Krum+是最佳的组合防御。

Result: 所设计的新型自适应攻击者能够以极低的恶意客户端比例（1-2/20）成功攻破现有最先进的防御。实验证明，最佳组合防御Krum+能有效抵御这种新型自适应攻击者以及现有的最先进攻击。

Conclusion: 现有联邦学习后门防御对自适应攻击者效果不佳。本文通过提出一种强大的新型自适应攻击者，揭示了现有防御的脆弱性，并成功开发了“Hammer and Anvil”防御框架下的Krum+组合防御，为联邦学习中抵御复杂后门攻击提供了有效且原则性的解决方案。

Abstract: Federated Learning is a distributed learning technique in which multiple
clients cooperate to train a machine learning model. Distributed settings
facilitate backdoor attacks by malicious clients, who can embed malicious
behaviors into the model during their participation in the training process.
These malicious behaviors are activated during inference by a specific trigger.
No defense against backdoor attacks has stood the test of time, especially
against adaptive attackers, a powerful but not fully explored category of
attackers. In this work, we first devise a new adaptive adversary that
surpasses existing adversaries in capabilities, yielding attacks that only
require one or two malicious clients out of 20 to break existing
state-of-the-art defenses. Then, we present Hammer and Anvil, a principled
defense approach that combines two defenses orthogonal in their underlying
principle to produce a combined defense that, given the right set of
parameters, must succeed against any attack. We show that our best combined
defense, Krum+, is successful against our new adaptive adversary and
state-of-the-art attacks.

</details>


### [57] [Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography](https://arxiv.org/abs/2509.08116)
*Nooshin Maghsoodi,Sarah Nassar,Paul F R Wilson,Minh Nguyen Nhat To,Sophia Mannina,Shamel Addas,Stephanie Sibley,David Maslove,Purang Abolmaesumi,Parvin Mousavi*

Main category: cs.LG

TL;DR: 提出PhysioCLR，一个结合生理学知识的对比学习框架，解决了AI-ECG分析中标记数据不足的问题，显著提升了心电图分类的泛化性和临床相关性。


<details>
  <summary>Details</summary>
Motivation: AI-ECG分析受限于标记数据稀缺，影响其有效性。自监督学习（SSL）能利用大量未标记数据解决此问题。本研究旨在通过结合领域特有的生理学先验知识，提升AI-ECG心律失常分类的泛化性和临床相关性。

Method: 引入PhysioCLR，一个生理学感知的对比学习框架。在预训练阶段，它通过整合ECG生理相似性线索，使具有相似临床相关特征的样本嵌入靠近，不相似的样本嵌入远离。此外，还提出了保留ECG类别特性的数据增强方法和混合损失函数来优化表示学习。

Result: 在Chapman、Georgia两个公共数据集和一份私有ICU数据集上进行评估。PhysioCLR相比最强基线，平均AUROC提升了12%，展示了强大的跨数据集泛化能力。

Conclusion: PhysioCLR通过将生理学知识融入对比学习，使模型能够学习到具有临床意义和可迁移的ECG特征，为实现更有效、标签高效的ECG诊断提供了有前景的途径。

Abstract: Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart
conditions; however, the effectiveness of artificial intelligence (AI)-based
ECG analysis is often hindered by the limited availability of labeled data.
Self-supervised learning (SSL) can address this by leveraging large-scale
unlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning
Representation for ECG), a physiology-aware contrastive learning framework that
incorporates domain-specific priors to enhance the generalizability and
clinical relevance of ECG-based arrhythmia classification. Methods: During
pretraining, PhysioCLR learns to bring together embeddings of samples that
share similar clinically relevant features while pushing apart those that are
dissimilar. Unlike existing methods, our method integrates ECG physiological
similarity cues into contrastive learning, promoting the learning of clinically
meaningful representations. Additionally, we introduce ECG- specific
augmentations that preserve the ECG category post augmentation and propose a
hybrid loss function to further refine the quality of learned representations.
Results: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia,
for multilabel ECG diagnoses, as well as a private ICU dataset labeled for
binary classification. Across the Chapman, Georgia, and private cohorts,
PhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline,
underscoring its robust cross-dataset generalization. Conclusion: By embedding
physiological knowledge into contrastive learning, PhysioCLR enables the model
to learn clinically meaningful and transferable ECG eatures. Significance:
PhysioCLR demonstrates the potential of physiology-informed SSL to offer a
promising path toward more effective and label-efficient ECG diagnostics.

</details>


### [58] [Optimization Methods and Software for Federated Learning](https://arxiv.org/abs/2509.08120)
*Konstantin Burlachenko*

Main category: cs.LG

TL;DR: 本文旨在解决联邦学习(FL)在去中心化和非受控环境中面临的异构性、通信和隐私挑战，通过提出新方法来弥合FL理论与实践间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 联邦学习(FL)的训练过程本质上是去中心化且常在非受控环境下进行，这带来了数据和设备异构性、通信问题以及客户端隐私等独特挑战。此外，已有的FL理论进展缺乏多样的实践实现，限制了其现实应用性。

Method: 作者在论文中识别了联邦学习的五个关键挑战，并提出了新颖的方法来应对这些挑战。

Result: 论文通过提出的新方法推进了FL算法和系统，成功地将理论进展与实际实现相结合。

Conclusion: 本研究不仅为将FL理论方法转化为高效的实际实现提供了指导，也为从实践角度反哺理论算法设计提供了深刻见解，有助于更深入理解算法的底层机制和灵活性。

Abstract: Federated Learning (FL) is a novel, multidisciplinary Machine Learning
paradigm where multiple clients, such as mobile devices, collaborate to solve
machine learning problems. Initially introduced in Kone{\v{c}}n{\'y} et al.
(2016a,b); McMahan et al. (2017), FL has gained further attention through its
inclusion in the National AI Research and Development Strategic Plan (2023
Update) of the United States (Science and on Artificial Intelligence, 2023).
The FL training process is inherently decentralized and often takes place in
less controlled settings compared to data centers, posing unique challenges
distinct from those in fully controlled environments. In this thesis, we
identify five key challenges in Federated Learning and propose novel approaches
to address them. These challenges arise from the heterogeneity of data and
devices, communication issues, and privacy concerns for clients in FL training.
Moreover, even well-established theoretical advances in FL require diverse
forms of practical implementation to enhance their real-world applicability.
Our contributions advance FL algorithms and systems, bridging theoretical
advancements and practical implementations. More broadly, our work serves as a
guide for researchers navigating the complexities of translating theoretical
methods into efficient real-world implementations and software. Additionally,
it offers insights into the reverse process of adapting practical
implementation aspects back into theoretical algorithm design. This reverse
process is particularly intriguing, as the practical perspective compels us to
examine the underlying mechanics and flexibilities of algorithms more deeply,
often uncovering new dimensions of the algorithms under study.

</details>


### [59] [In-Context Learning Enhanced Credibility Transformer](https://arxiv.org/abs/2509.08122)
*Kishan Padayachy,Ronald Richman,Salvatore Scognamiglio,Mario V. Wüthrich*

Main category: cs.LG

TL;DR: 本文提出将Credibility Transformer与上下文学习机制结合，通过引入相似实例的上下文批次来增强CLS令牌表示，从而提高预测准确性和对新实例（包括未见特征水平）的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在Credibility Transformer基础上，通过引入上下文学习机制，进一步提高模型学习和预测性能，尤其是增强其对输入特征的CLS令牌表示，并使其能更好地适应和泛化到新颖的数据模式。

Method: 将现有的Credibility Transformer架构通过上下文学习机制进行增强。具体而言，通过添加一个由相似实例组成的上下文批次来增加信息集，从而通过额外的上下文信息和微调来增强实例的CLS令牌表示。

Result: 经验证，这种上下文学习机制通过适应相似的风险模式，提高了预测准确性。此外，它还使模型能够泛化到新实例，包括那些在训练时未出现的分类协变量特征水平（例如，新型汽车模型）。

Conclusion: 通过引入上下文学习机制，成功增强了Credibility Transformer，不仅提升了预测准确性，更显著改善了模型对全新实例和未见特征水平的泛化能力。

Abstract: The starting point of our network architecture is the Credibility Transformer
which extends the classical Transformer architecture by a credibility mechanism
to improve model learning and predictive performance. This Credibility
Transformer learns credibilitized CLS tokens that serve as learned
representations of the original input features. In this paper we present a new
paradigm that augments this architecture by an in-context learning mechanism,
i.e., we increase the information set by a context batch consisting of similar
instances. This allows the model to enhance the CLS token representations of
the instances by additional in-context information and fine-tuning. We
empirically verify that this in-context learning enhances predictive accuracy
by adapting to similar risk patterns. Moreover, this in-context learning also
allows the model to generalize to new instances which, e.g., have feature
levels in the categorical covariates that have not been present when the model
was trained -- for a relevant example, think of a new vehicle model which has
just been developed by a car manufacturer.

</details>


### [60] [torchmil: A PyTorch-based library for deep Multiple Instance Learning](https://arxiv.org/abs/2509.08129)
*Francisco M. Castro-Macías,Francisco J. Sáez-Maldonado,Pablo Morales-Álvarez,Rafael Molina*

Main category: cs.LG

TL;DR: 本文介绍了torchmil，一个基于PyTorch的开源Python库，旨在为深度多示例学习（Deep MIL）提供标准化工具、数据格式、基准数据集和模型，以提高研究的可复现性和可及性。


<details>
  <summary>Details</summary>
Motivation: 深度多示例学习（MIL）领域缺乏模型开发、评估和比较的标准化工具，阻碍了研究的可复现性和可及性。

Method: 开发了torchmil，一个基于PyTorch的开源Python库，提供统一、模块化、可扩展的框架，包含MIL模型的基本构建块、标准化数据格式、精选的基准数据集和模型，以及全面的文档和教程。

Result: torchmil成功构建了一个统一的MIL开发平台，集成了基础模块、标准化数据格式、基准数据集和模型，并提供了详尽的文档和教程。

Conclusion: torchmil旨在加速MIL领域的研究进展，降低新用户的入门门槛，从而提升该领域的可复现性和可及性。

Abstract: Multiple Instance Learning (MIL) is a powerful framework for weakly
supervised learning, particularly useful when fine-grained annotations are
unavailable. Despite growing interest in deep MIL methods, the field lacks
standardized tools for model development, evaluation, and comparison, which
hinders reproducibility and accessibility. To address this, we present
torchmil, an open-source Python library built on PyTorch. torchmil offers a
unified, modular, and extensible framework, featuring basic building blocks for
MIL models, a standardized data format, and a curated collection of benchmark
datasets and models. The library includes comprehensive documentation and
tutorials to support both practitioners and researchers. torchmil aims to
accelerate progress in MIL and lower the entry barrier for new users. Available
at https://torchmil.readthedocs.io.

</details>


### [61] [From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital](https://arxiv.org/abs/2509.08140)
*Mihir Kumar,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Afriyie Kwesi Samuel,Fuat Alican,Yigit Ihlamur*

Main category: cs.LG

TL;DR: 本文提出了一个结合大语言模型（LLMs）和多模型机器学习（ML）架构的框架，用于预测罕见、高影响事件。该框架应用于风险投资（VC）领域，取得了显著的预测性能，并揭示了可解释的成功驱动因素。


<details>
  <summary>Details</summary>
Motivation: 预测罕见、高影响事件面临挑战，尤其是在风险投资等领域，投资者需要评估数据有限且嘈杂的早期创业公司。研究旨在开发一个结合黑盒模型预测能力与可靠决策所需可解释性的方法。

Method: 该方法利用LLM进行特征工程，从非结构化数据中提取和综合复杂信号。这些信号随后由一个分层模型集成进行处理，包括XGBoost、随机森林和线性回归。该集成模型首先生成成功可能性的连续估计，然后通过阈值处理生成二元罕见事件预测。

Result: 在风险投资领域的实证结果显示出强大的性能：在三个独立的测试子集中，模型的精确度比随机分类器基线高9.8到11.1倍。特征敏感性分析揭示了可解释的成功驱动因素：创业公司的类别列表贡献了15.6%的预测影响，其次是创始人数量，而教育水平和领域专业知识也提供了较小但一致的影响。

Conclusion: 所提出的框架能够有效预测罕见、高影响事件，并在风险投资领域展现出卓越的预测性能和可解释性。通过LLM驱动的特征工程和多模型集成，该方法不仅提高了预测精度，还为决策者提供了有价值的洞察，揭示了关键的成功驱动因素。

Abstract: This paper presents a framework for predicting rare, high-impact outcomes by
integrating large language models (LLMs) with a multi-model machine learning
(ML) architecture. The approach combines the predictive strength of black-box
models with the interpretability required for reliable decision-making. We use
LLM-powered feature engineering to extract and synthesize complex signals from
unstructured data, which are then processed within a layered ensemble of models
including XGBoost, Random Forest, and Linear Regression. The ensemble first
produces a continuous estimate of success likelihood, which is then thresholded
to produce a binary rare-event prediction. We apply this framework to the
domain of Venture Capital (VC), where investors must evaluate startups with
limited and noisy early-stage data. The empirical results show strong
performance: the model achieves precision between 9.8X and 11.1X the random
classifier baseline in three independent test subsets. Feature sensitivity
analysis further reveals interpretable success drivers: the startup's category
list accounts for 15.6% of predictive influence, followed by the number of
founders, while education level and domain expertise contribute smaller yet
consistent effects.

</details>


### [62] [MMM-fair: An Interactive Toolkit for Exploring and Operationalizing Multi-Fairness Trade-offs](https://arxiv.org/abs/2509.08156)
*Swati Swati,Arjun Roy,Emmanouil Panagiotou,Eirini Ntoutsi*

Main category: cs.LG

TL;DR: mmm-fair是一个开源工具包，通过基于boosting的集成方法和多目标优化，动态平衡模型性能与多维度（包括交叉偏见）公平性，并提供用户友好的界面和高级功能，以解决公平性感知分类中的现有挑战。


<details>
  <summary>Details</summary>
Motivation: 公平性感知分类需平衡性能与公平性，但交叉偏见和冲突的公平性定义使其复杂化。尽管对公平AI的需求日益增长，现有工具包在探索多维度公平性和权衡方面支持有限。

Method: 我们提出了mmm-fair，一个开源工具包，利用基于boosting的集成方法，动态优化模型权重，以共同最小化分类误差和多种公平性违规，实现灵活的多目标优化。它还提供无代码、基于聊天的界面，LLM驱动的解释，交互式帕累托探索，自定义公平性约束定义，并生成可部署模型。

Result: mmm-fair使用户能够部署符合其特定上下文需求的模型，并可靠地发现现有先进方法常遗漏的交叉偏见。它独特地结合了深度多属性公平性、多目标优化、无代码界面、LLM解释、交互式帕累托探索、自定义公平性约束定义和可部署模型于一个开源工具包中，这是现有公平性工具中罕见的组合。

Conclusion: mmm-fair是一个全面且创新的开源工具包，通过其先进的多维度公平性分析、多目标优化和用户友好的特性，弥补了公平性感知AI中的关键空白，从而促进了更公平和符合上下文的AI部署。

Abstract: Fairness-aware classification requires balancing performance and fairness,
often intensified by intersectional biases. Conflicting fairness definitions
further complicate the task, making it difficult to identify universally fair
solutions. Despite growing regulatory and societal demands for equitable AI,
popular toolkits offer limited support for exploring multi-dimensional fairness
and related trade-offs. To address this, we present mmm-fair, an open-source
toolkit leveraging boosting-based ensemble approaches that dynamically
optimizes model weights to jointly minimize classification errors and diverse
fairness violations, enabling flexible multi-objective optimization. The system
empowers users to deploy models that align with their context-specific needs
while reliably uncovering intersectional biases often missed by
state-of-the-art methods. In a nutshell, mmm-fair uniquely combines in-depth
multi-attribute fairness, multi-objective optimization, a no-code, chat-based
interface, LLM-powered explanations, interactive Pareto exploration for model
selection, custom fairness constraint definition, and deployment-ready models
in a single open-source toolkit, a combination rarely found in existing
fairness tools. Demo walkthrough available at: https://youtu.be/_rcpjlXFqkw.

</details>


### [63] [Machine Learning with Multitype Protected Attributes: Intersectional Fairness through Regularisation](https://arxiv.org/abs/2509.08163)
*Ho Ming Lee,Katrien Antonio,Benjamin Avanzi,Lorenzo Marchi,Rui Zhou*

Main category: cs.LG

TL;DR: 本文提出一种基于距离协方差的正则化框架，用于解决机器学习中回归和分类任务的公平性问题，特别是在处理多重受保护属性和交叉子群体差异（即“公平性选区划分”）方面，通过引入联合距离协方差（JdCov）和连接距离协方差（CCdCov）来提升适用性。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的公平性（尤其是在受保护属性上）至关重要，但现有研究多集中于二元分类，忽视了回归任务（如保险定价、招聘评估）中的公平性需求。同时，许多现有方法不适用于年龄等连续受保护属性，且在处理多重受保护属性时，常忽略“公平性选区划分”问题，导致交叉子群体（如特定民族女性）间的差异被忽视。

Method: 本文提出一种距离协方差正则化框架，旨在根据人口统计学平等原则，减弱模型预测与受保护属性之间的关联，并能捕获线性和非线性依赖关系。为处理多重受保护属性，该框架通过引入两种基于距离协方差的多元依赖性度量进行扩展：已有的联合距离协方差（JdCov）和新提出的连接距离协方差（CCdCov）。这些方法能有效解决回归和分类任务中涉及多种类型受保护属性的“公平性选区划分”问题。同时，讨论了包括基于Jensen-Shannon散度的方法在内的正则化强度校准技术。

Result: 将所提出的框架应用于COMPAS累犯数据集和大型汽车保险索赔数据集进行了验证。

Conclusion: 该框架通过结合距离协方差正则化及改进的多元依赖性度量（JdCov和CCdCov），能够有效减轻模型预测与受保护属性之间的关联，处理多重属性，并解决回归和分类任务中“公平性选区划分”导致的交叉子群体差异问题。

Abstract: Ensuring equitable treatment (fairness) across protected attributes (such as
gender or ethnicity) is a critical issue in machine learning. Most existing
literature focuses on binary classification, but achieving fairness in
regression tasks-such as insurance pricing or hiring score assessments-is
equally important. Moreover, anti-discrimination laws also apply to continuous
attributes, such as age, for which many existing methods are not applicable. In
practice, multiple protected attributes can exist simultaneously; however,
methods targeting fairness across several attributes often overlook so-called
"fairness gerrymandering", thereby ignoring disparities among intersectional
subgroups (e.g., African-American women or Hispanic men). In this paper, we
propose a distance covariance regularisation framework that mitigates the
association between model predictions and protected attributes, in line with
the fairness definition of demographic parity, and that captures both linear
and nonlinear dependencies. To enhance applicability in the presence of
multiple protected attributes, we extend our framework by incorporating two
multivariate dependence measures based on distance covariance: the previously
proposed joint distance covariance (JdCov) and our novel concatenated distance
covariance (CCdCov), which effectively address fairness gerrymandering in both
regression and classification tasks involving protected attributes of various
types. We discuss and illustrate how to calibrate regularisation strength,
including a method based on Jensen-Shannon divergence, which quantifies
dissimilarities in prediction distributions across groups. We apply our
framework to the COMPAS recidivism dataset and a large motor insurance claims
dataset.

</details>


### [64] [MARLINE: Multi-Source Mapping Transfer Learning for Non-Stationary Environments](https://arxiv.org/abs/2509.08176)
*Honghui Du,Leandro Minku,Huiyu Zhou*

Main category: cs.LG

TL;DR: 提出MARLINE方法，通过将目标概念投影到源概念空间，即使源与目标概念不匹配，也能在概念漂移环境下利用多源知识提升数据流预测精度。


<details>
  <summary>Details</summary>
Motivation: 概念漂移严重影响在线学习的预测性能。现有利用多源数据流解决概念漂移的方法，假设源概念与目标概念相似，这在许多实际场景中往往不成立。

Method: 提出MARLINE（Multi-source mApping with tRansfer LearnIng for Non-stationary Environments）。该方法通过将目标概念投影到每个源概念的空间，使多个源子分类器能以集成方式协同预测目标概念，从而在源与目标概念不匹配时也能从多源知识中获益。

Result: 在多个合成和真实世界数据集上的实验结果表明，MARLINE比几种最先进的数据流学习方法具有更高的预测准确性。

Conclusion: MARLINE成功解决了多源数据流学习在概念漂移中源与目标概念不匹配的挑战，显著提升了在线学习系统的预测性能。

Abstract: Concept drift is a major problem in online learning due to its impact on the
predictive performance of data stream mining systems. Recent studies have
started exploring data streams from different sources as a strategy to tackle
concept drift in a given target domain. These approaches make the assumption
that at least one of the source models represents a concept similar to the
target concept, which may not hold in many real-world scenarios. In this paper,
we propose a novel approach called Multi-source mApping with tRansfer LearnIng
for Non-stationary Environments (MARLINE). MARLINE can benefit from knowledge
from multiple data sources in non-stationary environments even when source and
target concepts do not match. This is achieved by projecting the target concept
to the space of each source concept, enabling multiple source sub-classifiers
to contribute towards the prediction of the target concept as part of an
ensemble. Experiments on several synthetic and real-world datasets show that
MARLINE was more accurate than several state-of-the-art data stream learning
approaches.

</details>


### [65] [The Domain Mixed Unit: A New Neural Arithmetic Layer](https://arxiv.org/abs/2509.08180)
*Paul Curry*

Main category: cs.LG

TL;DR: Domain Mixed Unit (DMU) 是一种新型神经算术单元，通过混合对数和线性空间表示来执行加减法。它在NALM基准测试的乘法和除法任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 开发一种新型神经算术单元，以提高神经网络在算术操作（特别是乘法和除法）上的泛化能力和性能。

Method: DMU是一个新的神经算术单元，它通过学习一个单参数门控来混合对数空间和线性空间表示，从而执行加法（DMU add）或减法（DMU sub）。研究提出了两种DMU初始化方案：一种用于加法和乘法，另一种用于减法和除法。

Result: DMU在NALM基准测试上取得了最先进的性能，尤其是在乘法和除法任务中，其在所有实验设置中都达到了最高的解决百分比。

Conclusion: DMU是一种有效的新型神经算术单元，能够显著提升神经网络在乘法和除法等算术操作上的泛化能力。该研究的代码将开源并提交至NALM基准测试项目。

Abstract: The Domain Mixed Unit (DMU) is a new neural arithmetic unit that learns a
single parameter gate that mixes between log-space and linear-space
representations while performing either addition (DMU add) or subtraction (DMU
sub). Two initializations are proposed for the DMU: one covering addition and
multiplication, and another covering subtraction and division. The DMU achieves
state-of-the-art performance on the NALM Benchmark, a dataset designed to test
the ability of neural arithmetic units to generalize arithmetic operations,
specifically performing with the highest percentage solved over all seeds on
multiplication and division. The DMU will be submitted as a pull request to the
open-source NALM benchmark, and its code is available on GitHub at
https://github.com/marict?tab=repositories

</details>


### [66] [Multi-Label Transfer Learning in Non-Stationary Data Streams](https://arxiv.org/abs/2509.08181)
*Honghui Du,Leandro Minku,Aonghus Lawlor,Huiyu Zhou*

Main category: cs.LG

TL;DR: 针对多标签数据流中的概念漂移问题，本文提出了两种新的迁移学习方法BR-MARLENE和BRPW-MARLENE，通过标签间知识迁移显著提高了非平稳环境下的预测性能，并优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 多标签数据流中的概念常在非平稳环境中发生漂移，且标签间可能相互关联。尽管相关标签间的知识迁移能加速适应，但针对数据流的多标签迁移学习研究仍然有限。

Method: 本文提出两种新颖的迁移学习方法：1. BR-MARLENE利用源和目标数据流中不同标签的知识进行多标签分类；2. BRPW-MARLENE在此基础上，通过显式建模和迁移成对标签依赖关系来增强学习性能。

Result: 通过全面的实验证明，所提出的两种方法在非平稳环境中均优于现有的最先进多标签数据流方法。

Conclusion: 研究结果表明，标签间知识迁移能有效提高预测性能，尤其在处理多标签数据流的概念漂移问题上表现出色。

Abstract: Label concepts in multi-label data streams often experience drift in
non-stationary environments, either independently or in relation to other
labels. Transferring knowledge between related labels can accelerate
adaptation, yet research on multi-label transfer learning for data streams
remains limited. To address this, we propose two novel transfer learning
methods: BR-MARLENE leverages knowledge from different labels in both source
and target streams for multi-label classification; BRPW-MARLENE builds on this
by explicitly modelling and transferring pairwise label dependencies to enhance
learning performance. Comprehensive experiments show that both methods
outperform state-of-the-art multi-label stream approaches in non-stationary
environments, demonstrating the effectiveness of inter-label knowledge transfer
for improved predictive performance.

</details>


### [67] [Selective Induction Heads: How Transformers Select Causal Structures In Context](https://arxiv.org/abs/2509.08184)
*Francesco D'Angelo,Francesco Croce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 本研究揭示了Transformers如何通过“选择性归纳头”动态处理因果结构，该机制使其能够根据上下文选择正确的因果滞后并复制相应标记。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖固定因果结构（如马尔可夫链）来分析Transformers的归纳头，但这种方法无法捕捉自然语言中动态变化的标记关系。因此，需要一个能处理动态因果结构的新框架。

Method: 我们引入了一个新框架，通过交错具有不同滞后的马尔可夫链来动态改变因果结构，同时固定转移概率。通过构建一个3层Transformer来演示选择性归纳头的实现，并进行了实证验证及理论分析。

Result: 我们揭示了“选择性归纳头”的形成，这是一种使Transformers能够在上下文中选择正确因果结构的新电路。实证表明，Transformers学习了通过识别正确滞后并复制过去标记来预测下一个标记的机制，理论分析证明该机制渐近收敛到最大似然解。

Conclusion: 本研究增进了对Transformers如何选择因果结构的理解，为深入认识其工作原理和提高可解释性提供了新见解。

Abstract: Transformers have exhibited exceptional capabilities in sequence modeling
tasks, leveraging self-attention and in-context learning. Critical to this
success are induction heads, attention circuits that enable copying tokens
based on their previous occurrences. In this work, we introduce a novel
framework that showcases transformers' ability to dynamically handle causal
structures. Existing works rely on Markov Chains to study the formation of
induction heads, revealing how transformers capture causal dependencies and
learn transition probabilities in-context. However, they rely on a fixed causal
structure that fails to capture the complexity of natural languages, where the
relationship between tokens dynamically changes with context. To this end, our
framework varies the causal structure through interleaved Markov chains with
different lags while keeping the transition probabilities fixed. This setting
unveils the formation of Selective Induction Heads, a new circuit that endows
transformers with the ability to select the correct causal structure
in-context. We empirically demonstrate that transformers learn this mechanism
to predict the next token by identifying the correct lag and copying the
corresponding token from the past. We provide a detailed construction of a
3-layer transformer to implement the selective induction head, and a
theoretical analysis proving that this mechanism asymptotically converges to
the maximum likelihood solution. Our findings advance the understanding of how
transformers select causal structures, providing new insights into their
functioning and interpretability.

</details>


### [68] [ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis](https://arxiv.org/abs/2509.08188)
*Hritik Arasu,Faisal R Jahangiri*

Main category: cs.LG

TL;DR: 研究使用生成模型（WGAN-GP和1D扩散模型）合成EEG伪影数据。WGAN-GP在频谱保真度上表现更优，但两个模型在类别条件恢复方面均表现不佳，限制了直接的数据增强效果。研究发布了可复现的基线管道。


<details>
  <summary>Details</summary>
Motivation: EEG伪影（如肌肉、眼动、电极等）会严重混淆自动化分析，且大规模手动标注成本极高。因此，需要探索使用现代生成模型合成逼真、标签感知的伪影数据，以用于数据增强和系统压力测试。

Method: 使用TUH EEG Artifact (TUAR) 语料库，进行基于受试者的分割和固定长度多通道窗处理，并根据模型（WGAN-GP或扩散模型）定制预处理方法。比较了带投影判别器的条件WGAN-GP和带无分类器引导的1D去噪扩散模型。评估指标包括：(i) 真实性（通过Welch带功率差值、通道协方差Frobenius距离、自相关$L_2$和分布度量MMD/PRD）；(ii) 特异性（通过轻量级kNN/分类器的类别条件恢复能力）；(iii) 实用性（通过对伪影识别的增强效果）。

Result: 研究发现，WGAN-GP在频谱对齐和MMD值方面更接近真实数据。然而，两种模型都表现出较弱的类别条件恢复能力，这限制了它们在即时数据增强方面的收益，并揭示了在更强条件化和覆盖范围方面的改进机会。

Conclusion: 生成模型合成EEG伪影具有一定潜力，尤其WGAN-GP在频谱保真度上表现良好。但目前模型在类别条件恢复方面的不足，限制了其作为即时数据增强工具的有效性。本研究发布了一个可复现的管道，为EEG伪影合成建立了基线，并指出了未来工作可改进的具挑战性领域。

Abstract: Artifacts in electroencephalography (EEG) -- muscle, eye movement, electrode,
chewing, and shiver -- confound automated analysis yet are costly to label at
scale. We study whether modern generative models can synthesize realistic,
label-aware artifact segments suitable for augmentation and stress-testing.
Using the TUH EEG Artifact (TUAR) corpus, we curate subject-wise splits and
fixed-length multi-channel windows (e.g., 250 samples) with preprocessing
tailored to each model (per-window min-max for adversarial training;
per-recording/channel $z$-score for diffusion). We compare a conditional
WGAN-GP with a projection discriminator to a 1D denoising diffusion model with
classifier-free guidance, and evaluate along three axes: (i) fidelity via Welch
band-power deltas ($\Delta\delta,\ \Delta\theta,\ \Delta\alpha,\ \Delta\beta$),
channel-covariance Frobenius distance, autocorrelation $L_2$, and
distributional metrics (MMD/PRD); (ii) specificity via class-conditional
recovery with lightweight $k$NN/classifiers; and (iii) utility via augmentation
effects on artifact recognition. In our setting, WGAN-GP achieves closer
spectral alignment and lower MMD to real data, while both models exhibit weak
class-conditional recovery, limiting immediate augmentation gains and revealing
opportunities for stronger conditioning and coverage. We release a reproducible
pipeline -- data manifests, training configurations, and evaluation scripts --
to establish a baseline for EEG artifact synthesis and to surface actionable
failure modes for future work.

</details>


### [69] [Rollout-LaSDI: Enhancing the long-term accuracy of Latent Space Dynamics](https://arxiv.org/abs/2509.08191)
*Robert Stephany,Youngsoo Choi*

Main category: cs.LG

TL;DR: 为解决降阶模型（ROMs）在长时间预测偏微分方程（PDEs）时准确性下降的问题，本文提出一种新的有限差分方案和Rollout损失，以提高ROMs在任意时间尺度上的预测能力，并在2D Burgers方程上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 复杂偏微分方程的求解在物理科学中至关重要，但传统数值方法计算成本高昂。现有降阶模型虽能提供快速近似，但在长时间尺度上其预测能力会显著下降。

Method: ['引入一种灵活、高阶且计算成本低的有限差分方案。', '提出一种“Rollout损失”（Rollout loss），用于训练降阶模型，使其能在任意时间尺度上进行准确预测。']

Result: 所提出的方法在二维Burgers方程上得到了有效验证。

Conclusion: 结合新的有限差分方案和Rollout损失可以显著提升降阶模型在任意长时间尺度上对偏微分方程的预测准确性。

Abstract: Solving complex partial differential equations is vital in the physical
sciences, but often requires computationally expensive numerical methods.
Reduced-order models (ROMs) address this by exploiting dimensionality reduction
to create fast approximations. While modern ROMs can solve parameterized
families of PDEs, their predictive power degrades over long time horizons. We
address this by (1) introducing a flexible, high-order, yet inexpensive
finite-difference scheme and (2) proposing a Rollout loss that trains ROMs to
make accurate predictions over arbitrary time horizons. We demonstrate our
approach on the 2D Burgers equation.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [70] [Matisse: Visualizing Measured Internet Latencies as Manifolds](https://arxiv.org/abs/2509.08097)
*Stephen Jasina,Loqman Salamatian,Joshua Mathews,Scott Anderson,Paul Barford,Mark Crovella,Walter Willinger*

Main category: cs.NI

TL;DR: 本文提出了一种名为 Matisse 的新方法和系统，用于将从互联网延迟测量中推断出的流形可视化并投影到地理地图上，以揭示网络拓扑特性和关键连接区域。


<details>
  <summary>Details</summary>
Motivation: 流形能够表示复杂数据集并可视化其拓扑特性（如曲率）和数据属性（如异常）。将互联网延迟测量数据转换为流形并进行可视化，有助于深入理解网络结构和性能。

Method: 该方法通过一系列图来捕获数据关键信息（顶点地理位置和边的Ricci曲率），从城市间的互联网延迟测量中推断出流形。可视化过程将流形投影到2D地理空间，保持顶点的地理位置，并根据图边上的Ricci曲率值确定流形的曲率特性。该系统名为Matisse。

Result: 生成的流形突出了关键连接区域，并定义了一个“互联网延迟空间”，其中延迟测量表现为测地线。Matisse工具成功实现了流形的生成、可视化和操作，并通过两个案例研究（包括美国公共互联网的可视化）展示了其有效性。

Conclusion: 研究成功开发了Matisse工具，提供了一种新颖的基于图的流形可视化方法，用于分析互联网延迟数据。通过将地理位置与Ricci曲率相结合，Matisse能有效揭示网络关键连接和延迟空间特性，具有重要的实用价值。

Abstract: Manifolds are complex topological spaces that can be used to represent
datasets of real-world measurements. Visualizing such manifolds can help with
illustrating their topological characteristics (e.g., curvature) and providing
insights into important properties of the underlying data (e.g., anomalies in
the measurements). In this paper, we describe a new methodology and system for
generating and visualizing manifolds that are inferred from actual Internet
latency measurements between different cities and are projected over a 2D
Euclidean space (e.g., a geographic map). Our method leverages a series of
graphs that capture critical information contained in the data, including
well-defined locations (for vertices) and Ricci curvature information (for
edges). Our visualization approach then generates a curved surface (manifold)
in which (a) geographical locations of vertices are maintained and (b) the
Ricci curvature values of the graph edges determine the curvature properties of
the manifold. The resulting manifold highlights areas of critical connectivity
and defines an instance of "Internet delay space" where latency measurements
manifest as geodesics. We describe details of our method and its implementation
in a tool, which we call Matisse, for generating, visualizing and manipulating
manifolds projected onto a base map. We illustrate Matisse with two case
studies: a simple example to demonstrate key concepts, and visualizations of
the US public Internet to show Matisse's utility.

</details>


### [71] [UTM Performance Under Stressing Scenarios](https://arxiv.org/abs/2509.08124)
*Ian Jessen*

Main category: cs.NI

TL;DR: 本文介绍了一个虚拟仿真环境ANAMLL，用于在压力条件下测试UTM（无人交通管理）网络，揭示了飞行中重规划的局限性以及网络连接对空域访问的影响。


<details>
  <summary>Details</summary>
Motivation: 随着新型空域参与者（如无人机和先进空中交通工具）的激增，急需开发新型空域管理解决方案（如UTM和PSU网络）。现有系统在有限真实环境中的验证不足以探索其在压力条件下的行为，因此需要合适的建模与仿真环境。

Method: 本文利用林肯实验室的ANAMLL（Autonomy Networks for Advanced Mobility at Lincoln Laboratory），这是一个虚拟系统集成实验室（SIL），用于托管和测试联邦自主网络，并支持在真实部署无法实现的规模下进行测试和验证。研究通过ANAMLL探索了一个代表性UTM网络在极端需求场景下的性能。

Result: 在一次需求场景的详细检查中，ANAMLL展示了UTM系统的一个需求点，在该点上，飞行中重新规划无法在允许的时间窗口内完成。在对同一场景的第二次分析中，ANAMLL展示了网络连接性能对最终用户空域访问的影响。

Conclusion: ANAMLL作为一个虚拟仿真平台，有效证明了其在测试和验证大规模空域管理系统（如UTM网络）在压力条件下的性能和局限性方面的实用性，并识别了关键的性能瓶颈。

Abstract: Proliferation of new classes of airspace participants, including uncrewed and
advanced aerial mobility vehicles, necessitates the development and deployment
of novel airspace management solutions, such as the Unmanned Traffic Management
(UTM) system and the Provider of Services to UAM (PSU) Network. The efficacy of
such systems has been demonstrated on multiple occasions via real-world
deployments in limited test environments, however exploration of system
behavior under stressing conditions requires the development of appropriate
modeling and simulation (M&S) environments. Autonomy Networks for Advanced
Mobility at Lincoln Laboratory (ANAMLL) is a virtual Systems Integration
Laboratory (SIL) designed to host federated autonomy networks, such as a UTM or
PSU Network, and to enable test and validation at scales not available in
real-world deployments. As an example of ANAMLL's utility, we explore the
performance of a representative UTM network during a stressing demand scenario.
In a close examination of the demand scenario, ANAMLL demonstrates a UTM system
demand point at which in-flight replanning can no longer be accomplished within
an allowable time window. In a second analysis of the same scenario, ANAMLL
demonstrates the impact of network connectivity performance on end-user
airspace access.

</details>


### [72] [Enhancing 6G Network Security and Incident Response through Integrated VNF and SDN Technologies](https://arxiv.org/abs/2509.08274)
*Abdul Razaque,Abitkhanova Zhadyra Abitkhanovna*

Main category: cs.NI

TL;DR: 本文提出VNFSDN（虚拟网络功能服务交付网络），通过整合VNF和SDN技术并结合机器学习/人工智能，旨在解决低速互联网下事件响应效率低下以及6G网络海量数据处理的挑战，从而增强网络安全、韧性和威胁检测能力。


<details>
  <summary>Details</summary>
Motivation: 低速互联网严重影响事件响应（如检测延迟、行动低效），增加安全风险。现有安全团队难以有效获取和处理必要信息，特别是未来6G网络将产生海量数据，传统方式难以应对，导致组织更易受攻击。

Method: 通过整合虚拟网络功能（VNF）和软件定义网络（SDN）技术，构建虚拟网络功能服务交付网络（VNFSDN）。该方法还建议融入机器学习和人工智能技术，以进一步增强网络安全和威胁检测能力。

Result: VNFSDN显著提升了网络安全有效性和效率，降低了安全漏洞风险。它能协助安全服务快速评估6G网络产生的海量数据，并根据安全需求和连接条件动态调整。这使得企业能够迅速识别和应对安全威胁，从而减轻或阻止网络攻击的影响，增强网络韧性，并实现主动安全攻击缓解和停机时间最小化。

Conclusion: VNFSDN通过集成VNF和SDN技术（并可结合ML/AI），为解决低速互联网对事件响应的负面影响及6G网络海量数据的安全分析需求提供了一个动态、高效且有弹性的解决方案，显著提升了网络安全和威胁检测能力。

Abstract: Low-speed internet can negatively affect incident response in a number of
ways, including decreased teamwork, delayed detection, inefficient action, and
elevated risk. Delayed data acquisition and processing may result from
inadequate internet connectivity, hindering security teams' ability to obtain
the necessary information for timely and effective responses. Each of these
factors may augment the organization's susceptibility to security incidents and
their subsequent ramifications. This article establishes a virtual network
function service delivery network (VNFSDN) through the integration of virtual
network function (VNF) and software-defined networking (SDN) technologies. The
VNFSDN approach enhances network security effectiveness and efficiency while
reducing the danger of breaches. This method assists security services in
rapidly assessing vast quantities of data generated by 6G networks. VNFSDN
adapts dynamically to changing safety requirements and connection conditions
through the use of SDN and VNF. This flexibility enables enterprises to
mitigate or halt the impact of cyberattacks by swiftly identifying and
addressing security threats. The VNFSDN enhances network resilience, allowing
operators to proactively mitigate possible security attacks and minimize
downtime. The incorporation of machine learning and artificial intelligence
into VNFSDN can significantly improve network security and threat detection
capabilities. The VNFSDN integrates VNF and SDN technologies to deliver
security services that analyze vast quantities of 6G data in real time. As
security requirements and network conditions evolve, it adapts dynamically to
enhance network resilience and facilitate proactive threat detection.

</details>


### [73] [Ubiquitous Intelligence Via Wireless Network-Driven LLMs Evolution](https://arxiv.org/abs/2509.08400)
*Xingkun Yin,Feiran You,Hongyang Du,Kaibin Huang*

Main category: cs.NI

TL;DR: 引入普适智能范式，实现大语言模型（LLMs）与无线网络生态系统的协同演进，以达到可伸缩、持续、自进化的智能提升。


<details>
  <summary>Details</summary>
Motivation: 旨在克服LLMs静态部署的局限性，通过网络与LLMs的协同，实现智能在多样化和资源受限环境中的持续、可伸缩增长。

Method: 提出LLMs与无线网络协同演进的范式：无线网络支持系统编排的终身学习，而LLMs则推动下一代网络的自适应和响应式发展。

Result: 实现了自改进的系统，使其能力在多样化和资源受限环境中持续增长。

Conclusion: 普适智能通过LLMs与无线网络的共生发展，开创了智能系统的新篇章，具备在复杂环境下持续自我提升的能力。

Abstract: We introduce ubiquitous intelligence as a paradigm where Large Language
Models (LLMs) evolve within wireless network-driven ecosystems. Unlike static
model deployments, this approach enables scalable and continuous intelligence
ascension through coordination between networks and LLMs. Wireless networks
support system-orchestrated lifelong learning, while LLMs drive the
next-generation network development that is more adaptive and responsive. This
co-evolution highlights a shift toward self-improving systems, sustaining
capability growth across diverse and resource-constrained environments.

</details>


### [74] [SKYLINK: Scalable and Resilient Link Management in LEO Satellite Network](https://arxiv.org/abs/2509.08455)
*Wanja de Sombre,Arash Asadi,Debopam Bhattacherjee,Deepak Vasisht,Andrea Ortiz*

Main category: cs.NI

TL;DR: 提出SKYLINK，一种针对LEO卫星网络的全分布式学习路由策略，有效应对高动态性挑战，显著降低延迟和丢包率，提高吞吐量，并具备高可扩展性和实时响应能力。


<details>
  <summary>Details</summary>
Motivation: LEO卫星网络有望提供全球宽带连接，尤其通过星间链路（ISL）实现更快更可靠的通信。然而，卫星高移动性、动态流量模式和潜在链路故障给高效弹性路由带来了巨大挑战，且在大规模网络中难以找到最优解。本研究旨在最小化平均延迟和丢包率的加权和。

Method: 将LEO卫星网络建模为包含卫星和地面站的时变图。每个卫星实时独立决定如何分配传入流量。提出SKYLINK，一种新颖的全分布式学习策略用于链路管理，使其能适应时变网络条件，确保实时响应、可扩展性和网络故障弹性。为支持全球规模的评估，开发了新的大规模LEO卫星网络模拟器。

Result: 对于2540万用户，SKYLINK相比bent-pipe将平均延迟和丢包率的加权和降低29%，相比Dijkstra降低92%。在丢包率方面，比k-shortest paths低95%，比Dijkstra低99%，比bent-pipe低74%。同时，吞吐量提高高达46%。此外，SKYLINK的计算复杂度与星座规模保持恒定。

Conclusion: SKYLINK作为一种全分布式学习策略，能有效解决LEO卫星网络的复杂路由挑战，在延迟、丢包率和吞吐量方面均表现出卓越性能，且具备实时响应、可扩展性、韧性、低通信开销和计算复杂性，为下一代LEO网络提供了可行且高效的解决方案。

Abstract: The rapid growth of space-based services has established LEO satellite
networks as a promising option for global broadband connectivity.
Next-generation LEO networks leverage inter-satellite links (ISLs) to provide
faster and more reliable communications compared to traditional bent-pipe
architectures, even in remote regions. However, the high mobility of
satellites, dynamic traffic patterns, and potential link failures pose
significant challenges for efficient and resilient routing. To address these
challenges, we model the LEO satellite network as a time-varying graph
comprising a constellation of satellites and ground stations. Our objective is
to minimize a weighted sum of average delay and packet drop rate. Each
satellite independently decides how to distribute its incoming traffic to
neighboring nodes in real time. Given the infeasibility of finding optimal
solutions at scale, due to the exponential growth of routing options and
uncertainties in link capacities, we propose SKYLINK, a novel fully distributed
learning strategy for link management in LEO satellite networks. SKYLINK
enables each satellite to adapt to the time-varying network conditions,
ensuring real-time responsiveness, scalability to millions of users, and
resilience to network failures, while maintaining low communication overhead
and computational complexity. To support the evaluation of SKYLINK at global
scale, we develop a new simulator for large-scale LEO satellite networks. For
25.4 million users, SKYLINK reduces the weighted sum of average delay and drop
rate by 29% compared to the bent-pipe approach, and by 92% compared to
Dijkstra. It lowers drop rates by 95% relative to k-shortest paths, 99%
relative to Dijkstra, and 74% compared to the bent-pipe baseline, while
achieving up to 46% higher throughput. At the same time, SKYLINK maintains
constant computational complexity with respect to constellation size.

</details>


### [75] [Design and Development of a Scalable and Energy-Efficient Localization Framework Leveraging LoRa Ranging-Capable Transceivers](https://arxiv.org/abs/2509.08488)
*Hasan Albinsaid,Bodhibrata Mukhopadhyay,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文提出一种协调框架，通过同步短唤醒窗口显著降低LoRa SX1280在IoT定位中的功耗，实现了长电池寿命（9个月）和高精度（5米内）的按需测距。


<details>
  <summary>Details</summary>
Motivation: 大规模IoT应用对精确和节能定位有关键需求，Semtech SX1280 LoRa收发器虽具低成本、低功耗和精准测距能力，但其测距过程需两设备同时活跃，导致高能耗。现有系统级框架未能有效管理休眠-唤醒协调及角色分配以实现节能运行。

Method: 本文提出了一个协调框架，通过调度发起者和响应者之间同步的短唤醒窗口，使设备大部分时间处于深度睡眠模式。该策略旨在最小化对连续精确计时的依赖，并减轻低成本振荡器的漂移。为验证框架，设计并开发了符合协议的定制节点。

Result: 实验结果表明，该方法使节点能保持超低功耗模式并周期性唤醒检查指令。节点在单颗纽扣电池下可待机长达九个月，并能按需近实时执行测距操作，同时保持五米以内的定位精度。

Conclusion: 所提出的协调框架有效解决了LoRa SX1280在节能与精确测距之间的矛盾，为IoT应用中的能源高效、高精度定位提供了可行的系统级解决方案。

Abstract: Precise and energy-efficient localization is a critical requirement in many
Internet of Things (IoT) applications, particularly in large-scale deployments
such as asset tagging, agriculture, and smart cities, where long battery life
and cost-effectiveness are crucial. The Semtech SX1280 LoRa transceiver
presents a promising solution for IoT localization. It combines low cost, low
power, and precise ranging capability over distances of up to 1 km. However,
the ranging process requires two devices to be simultaneously active, one
initiating the ranging request and the other responding to it, which can lead
to significant energy expenditure if not properly managed. Despite the
transceiver's excellent performance, no existing system-level framework
effectively manages sleep-wake coordination and role assignment needed for
energy-efficient operation. This paper presents a coordination framework that
significantly reduces power consumption while maintaining the inherent precise
ranging capability of the chip. The framework schedules short, synchronized
wake-up windows between the initiator and the responder, allowing devices to
remain in deep sleep for most of their duty cycle. This scheduling strategy
minimizes reliance on precise continuous timing and mitigates drift in low-cost
oscillators. To validate the framework, we designed and developed custom nodes
that are compliant with the framework's protocol. Experimental results show
that the proposed approach allows a node to stay in ultra-low power mode and
wake periodically to check for instructions. The node can remain in standby
mode for up to nine months on a single coin cell battery and can perform
ranging operations on demand in near real-time, all while maintaining a
localization accuracy within five meters.

</details>


### [76] [The Role of Legacy Mobile Networks in Infrastructure Resilience: Evidence from the Southern Brazil Flood](https://arxiv.org/abs/2509.08595)
*Daniel Meyer,Lisandro Z Granville,Leandro M. Bertholdo*

Main category: cs.NI

TL;DR: 分析了2024年巴西洪灾期间移动网络的弹性，发现4G/5G易受影响，2G/3G在灾难中发挥关键作用，强调需规划更具韧性的基础设施。


<details>
  <summary>Details</summary>
Motivation: 调查2024年5月巴西里奥格兰德州极端洪灾期间移动通信网络的韧性，并识别导致网络中断的主要原因。

Method: 基于监管数据和运营商提供的技术洞察进行研究。

Result: 网络中断主要由洪灾和长时间停电引起；现代网络（4G/5G）在此次事件中表现出显著脆弱性；传统技术（2G/3G）在恶劣条件下对维持基本连接发挥了重要作用。

Conclusion: 未来危机中，有必要进行灾害感知的基础设施规划，考虑传统系统的持续重要性，采取多样化的供电策略，并设计更具韧性的网络，以增强服务连续性。

Abstract: This paper investigates the resilience of mobile communication networks
during the extreme flooding that affected Rio Grande do Sul, Brazil, in May
2024. Based on regulatory data and technical insights from operators, the study
identifies the leading causes of mobile network disruptions, primarily related
to flooding and prolonged power outages. The results reveal the significant
vulnerability of modern networks (4G/5G) during the event and the essential
role played by legacy technologies (2G/3G) in sustaining basic connectivity
under adverse conditions. The findings underscore the necessity of
disaster-aware infrastructure planning, taking into account the ongoing
significance of legacy systems, diversified power supply strategies, and
resilient network designs to enhance service continuity during future crises.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [77] [Signals vs. Videos: Advancing Motion Intention Recognition for Human-Robot Collaboration in Construction](https://arxiv.org/abs/2509.07990)
*Charan Gajjala Chenchu,Kinam Kim,Gao Lu,Zia Ud Din*

Main category: eess.SP

TL;DR: 本研究通过深度学习模型比较表面肌电信号(sEMG)和视频两种模态在建筑人机协作中早期识别人类运动意图的性能，发现视频模态准确率更高但预测时间更长。


<details>
  <summary>Details</summary>
Motivation: 建筑业人机协作(HRC)需要机器人精确及时识别工人运动意图以提高安全性和效率，但在运动意图识别方面，对比信号和视频等不同数据模态的研究存在空白。

Method: 本研究利用深度学习评估两种数据模态（表面肌电信号sEMG和视频）在石膏板安装任务运动早期识别工人运动意图。具体方法是：对sEMG数据采用CNN-LSTM模型；对视频序列采用预训练的Video Swin Transformer结合迁移学习。

Result: 使用sEMG数据的CNN-LSTM模型实现了约87%的准确率，平均预测时间为0.04秒。使用视频序列的Video Swin Transformer模型实现了94%的准确率，但平均预测时间为0.15秒。

Conclusion: 本研究强调了sEMG和视频两种数据格式在运动意图识别方面的独特优势和权衡，为在实际建筑项目中系统部署它们以增强人机协作提供了方向。

Abstract: Human-robot collaboration (HRC) in the construction industry depends on
precise and prompt recognition of human motion intentions and actions by robots
to maximize safety and workflow efficiency. There is a research gap in
comparing data modalities, specifically signals and videos, for motion
intention recognition. To address this, the study leverages deep learning to
assess two different modalities in recognizing workers' motion intention at the
early stage of movement in drywall installation tasks. The Convolutional Neural
Network - Long Short-Term Memory (CNN-LSTM) model utilizing surface
electromyography (sEMG) data achieved an accuracy of around 87% with an average
time of 0.04 seconds to perform prediction on a sample input. Meanwhile, the
pre-trained Video Swin Transformer combined with transfer learning harnessed
video sequences as input to recognize motion intention and attained an accuracy
of 94% but with a longer average time of 0.15 seconds for a similar prediction.
This study emphasizes the unique strengths and trade-offs of both data formats,
directing their systematic deployments to enhance HRC in real-world
construction projects.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [78] [ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic Communications](https://arxiv.org/abs/2505.10946)
*Li Qiao,Mahdi Boloursaz Mashhadi,Zhen Gao,Robert Schober,Deniz Gündüz*

Main category: cs.IT

TL;DR: 提出一种令牌域多址接入（ToDMA）方案，利用MLLM和压缩感知实现高效的生成式语义通信，显著降低延迟并提高文本和图像传输质量，并能有效缓解令牌冲突。


<details>
  <summary>Details</summary>
Motivation: 令牌通信（TokCom）通过上下文和MLLM减少传输速率，作为新兴的生成式语义通信概念。本文旨在为大量设备提供一种在令牌域内高效共享资源并进行语义多址接入的方案。

Method: 发送端将源信号令牌化并调制为码字。接收端首先利用压缩感知检测叠加信号中的活跃令牌和信道状态信息（CSI），然后通过聚类多时隙的令牌相关CSI重建源令牌序列。为缓解令牌冲突，采用预训练的MLLM利用上下文预测被掩盖的令牌。

Result: ToDMA框架在文本和图像传输任务中均有效。与上下文无关的正交通信方案相比，实现了显著更低的延迟。与现有上下文无关的非正交通信方法相比，提供了更优越的失真和感知质量。

Conclusion: ToDMA是一个高效且性能优越的语义多址接入框架，通过结合令牌处理、压缩感知和MLLM的上下文预测能力，在生成式语义通信中显著提升了传输效率和质量，特别是在降低延迟和改善感知质量方面表现出色。

Abstract: Token communications (TokCom) is an emerging generative semantic
communication concept that reduces transmission rates by using context and
multimodal large language model (MLLM)-based token processing, with tokens
serving as universal semantic units across modalities. In this paper, we
propose a semantic multiple access scheme in the token domain, referred to as
token domain multiple access (ToDMA), where a large number of devices share a
token codebook and a modulation codebook for source and channel coding,
respectively. Specifically, each transmitter first tokenizes its source signal
and modulate each token to a codeword. At the receiver, compressed sensing is
employed first to detect active tokens and the corresponding channel state
information (CSI) from the superposed signals. Then, the source token sequences
are reconstructed by clustering the token-associated CSI across multiple time
slots. In case of token collisions, some active tokens cannot be assigned and
some positions in the reconstructed token sequences are empty. We propose to
use pre-trained MLLMs to leverage the context, predict masked tokens, and thus
mitigate token collisions. Simulation results demonstrate the effectiveness of
the proposed ToDMA framework for both text and image transmission tasks,
achieving significantly lower latency compared to context-unaware orthogonal
communication schemes, while also delivering superior distortion and perceptual
quality compared to state-of-the-art context-unaware non-orthogonal
communication methods.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [79] [EFPIX: A zero-trust encrypted flood protocol](https://arxiv.org/abs/2509.08248)
*Arin Upadhyay*

Main category: cs.CR

TL;DR: 提出一种基于洪泛的中继通信协议，旨在实现端到端加密、用户可否认性及消息不可追溯性，并能隐藏元数据，同时抵抗拓扑变化和基础设施故障。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有通信协议在安全性、隐私性（如端到端加密、用户可否认性、消息不可追溯性及元数据隐藏）和鲁棒性（抵抗拓扑变化和基础设施故障）方面的挑战。

Method: 提出并设计了一种基于洪泛（flood-based）的中继通信协议。

Result: 该协议成功实现了端到端加密、用户可否认性、消息不可追溯性，能够抵抗拓扑变化和基础设施故障，并能向无关方隐藏发送方和接收方等元数据。

Conclusion: 该研究成功提供了一种高度安全、隐私保护且对环境变化具有鲁棒性的通信解决方案。

Abstract: We propose a flood-based relay communication protocol that achieves
end-to-end encryption, plausible deniability for users, and untraceable
messages. It is resistant to changes in topology and infrastructure failures.
It is also designed to hide metadata, such as sender and receiver, from those
not involved.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [80] [DLGE: Dual Local-Global Encoding for Generalizable Cross-BCI-Paradigm](https://arxiv.org/abs/2509.07991)
*Jingyuan Wang,Junhua Li*

Main category: q-bio.NC

TL;DR: 本研究提出了一种双局部-全局编码器（DLGE）模型，旨在通过标准化EEG通道配置和学习共享/特定范式特征，实现跨不同脑机接口（BCI）范式的通用分类，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型难以用单一模型解码多个BCI范式，原因在于通道配置和任务相关表征的异质性。需要开发一个能够处理多种BCI范式的通用模型。

Method: 提出DLGE模型。通过解剖学启发的大脑区域划分和填充策略标准化EEG通道配置。局部编码器学习每个大脑区域内基于时频信息的共享特征，整合通道内时间注意力和通道间空间注意力。全局编码器聚合这些共享特征形成范式特定的特征表示。使用运动想象、静息状态和驾驶疲劳三种BCI范式进行评估。

Result: DLGE模型无需重新训练和调优即可处理多种BCI范式，平均宏观精确率、召回率和F1分数分别达到60.16%、59.88%和59.56%。

Conclusion: 本研究首次尝试开发了一种用于跨BCI范式分类的通用模型，避免了为每个范式进行重新训练或重新开发。这为开发有效且简单的通用BCI解码模型奠定了基础，有利于便携式设备的设计。

Abstract: Deep learning models have been frequently used to decode a single
brain-computer interface (BCI) paradigm based on electroencephalography (EEG).
It is challenging to decode multiple BCI paradigms using one model due to
diverse barriers, such as different channel configurations and disparate
task-related representations. In this study, we propose Dual Local-Global
Encoder (DLGE), enabling the classification across different BCI paradigms. To
address the heterogeneity in EEG channel configurations across paradigms, we
employ an anatomically inspired brain-region partitioning and padding strategy
to standardize EEG channel configuration. In the proposed model, the local
encoder is designed to learn shared features across BCI paradigms within each
brain region based on time-frequency information, which integrates temporal
attention on individual channels with spatial attention among channels for each
brain region. These shared features are subsequently aggregated in the global
encoder to form respective paradigm-specific feature representations. Three BCI
paradigms (motor imagery, resting state, and driving fatigue) were used to
evaluate the proposed model. The results demonstrate that our model is capable
of processing diverse BCI paradigms without retraining and retuning, achieving
average macro precision, recall, and F1-score of 60.16\%, 59.88\%, and 59.56\%,
respectively. We made an initial attempt to develop a general model for
cross-BCI-paradigm classification, avoiding retraining or redevelopment for
each paradigm. This study paves the way for the development of an effective but
simple model for cross-BCI-paradigm decoding, which might benefit the design of
portable devices for universal BCI decoding.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [81] [From Physical to Logical: Graph-State-Based Connectivity in Quantum Networks](https://arxiv.org/abs/2509.08384)
*Mateo M. Blanco,Manuel Fernández-Veiga,Ana Fernández-Vilas,Rebeca P. Díaz-Redondo*

Main category: quant-ph

TL;DR: 该论文扩展了基于双星配置的图态方法，以实现多星拓扑中的多方纠缠管理，旨在提高量子网络的连接性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 量子通信中的双向纠缠方案不足以支持高级协议，需要更灵活的多方纠缠管理方式。图态提供了解决方案，但现有配置（如双星）在实现丰富连接性方面存在局限性。

Method: 将现有基于双星配置的方法扩展到更复杂的多星拓扑结构。分析由$m$个交换机（每个连接$n$个客户端，包括不对称情况）组成的网络中可实现的最大连接性，并提出远距离节点间逻辑通信的方法。

Result: 研究确定了在多星拓扑网络中可实现的最大连接性，并提出了实现远距离节点间逻辑通信的方法。这些结果支持开发超越传统双向结构的可扩展量子网络。

Conclusion: 该研究通过多星拓扑扩展了图态方法，为构建具有高连接性和可扩展性、能够支持高级量子协议的量子网络提供了基础和方法支持。

Abstract: Entanglement is a key resource in quantum communication, but bipartite
schemes are often insufficient for advanced protocols like quantum secret
sharing or distributed computing. Graph states offer a flexible way to
represent and manage multipartite entanglement in quantum networks, enabling
logical connectivity through local operations and classical communication
(LOCC). In this work, we extend existing approaches based on bi-star
configurations to more complex multi-star topologies. We analyze the maximum
connectivity that can be achieved in networks of $m$ switches, each connected
to $n$ clients, including asymmetric cases where the number of clients varies
per switch. We also propose methods to enable logical communication between
distant nodes. Our results support the development of scalable quantum networks
with rich connectivity beyond traditional bipartite structures.

</details>


### [82] [Robust Belief-State Policy Learning for Quantum Network Routing Under Decoherence and Time-Varying Conditions](https://arxiv.org/abs/2509.08654)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: quant-ph

TL;DR: 本文提出了一种结合信念状态规划和图神经网络（GNNs）的基于特征的POMDP框架，用于解决量子网络路由中的部分可观测性、退相干和可伸缩性挑战。


<details>
  <summary>Details</summary>
Motivation: 解决动态量子系统中量子网络路由面临的部分可观测性、退相干和可伸缩性挑战，并处理复杂的量子网络动态，如纠缠退化和时变信道噪声。

Method: 提出了一种基于特征的POMDP框架，结合信念状态规划与GNNs。该方法将量子网络动态编码到低维特征空间，采用混合GNN-POMDP架构学习路由策略，并融合噪声自适应机制。同时提供了信念收敛、策略改进和鲁棒性的理论分析。

Result: 在高达100个节点的模拟量子网络上的实验表明，与现有基线相比，本方法在路由保真度和纠缠传输速率方面有显著提升，尤其是在高退相干和非平稳条件下表现更优。

Conclusion: 该框架有效解决了量子网络路由中的关键挑战，并在复杂动态条件下表现出优越的性能，显著提高了路由保真度和纠缠传输速率。

Abstract: This paper presents a feature-based Partially Observable Markov Decision
Process (POMDP) framework for quantum network routing, combining belief-state
planning with Graph Neural Networks (GNNs) to address partial observability,
decoherence, and scalability challenges in dynamic quantum systems. Our
approach encodes complex quantum network dynamics, including entanglement
degradation and time-varying channel noise, into a low-dimensional feature
space, enabling efficient belief updates and scalable policy learning. The core
of our framework is a hybrid GNN-POMDP architecture that processes
graph-structured representations of entangled links to learn routing policies,
coupled with a noise-adaptive mechanism that fuses POMDP belief updates with
GNN outputs for robust decision making. We provide a theoretical analysis
establishing guarantees for belief convergence, policy improvement, and
robustness to noise. Experiments on simulated quantum networks with up to 100
nodes demonstrate significant improvements in routing fidelity and entanglement
delivery rates compared to state-of-the-art baselines, particularly under high
decoherence and nonstationary conditions.

</details>
