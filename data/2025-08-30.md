<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 该系统综述分析了多语言模型中的社会偏见评估与缓解方法，揭示了当前研究的不足（如语言偏好、多语言缓解实验稀缺）并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 预训练多语言模型与英语处理模型一样存在社会偏见，需要对非英语和多语言语境下的偏见评估与缓解方法进行系统性分析。

Method: 通过系统综述的方式，分析了扩展偏见评估和缓解方法到多语言及非英语语境的新兴研究，重点考察了语言多样性、文化意识、评估指标和缓解技术。

Result: 研究揭示了当前领域方法设计中的空白（例如，对某些语言的偏好，多语言偏见缓解实验的稀缺性），并梳理了在跨语言和文化适应偏见基准时遇到的常见问题和已实施的解决方案。

Conclusion: 基于研究发现，论文为未来的多语言偏见研究指明了方向，旨在增强其包容性、跨文化适用性以及与最新NLP进展的契合度。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本研究利用语言模型（Gemma和GPT-3.5）通过结构化提示和微调，自动生成形态学评估的多选题，旨在降低人工开发成本并提高一致性。结果表明，结构化提示和微调能有效提升中型模型表现，并提出了一种结合自动、专家和大型模型模拟评估的实用工作流程。


<details>
  <summary>Details</summary>
Motivation: 为了降低人工开发形态学评估多选题（MCQs）的成本并解决其一致性问题，研究旨在探索利用语言模型进行自动生成（AIG）的方法。

Method: 1. **模型对比**：比较了微调过的中型模型Gemma (2B) 与未微调的大型模型GPT-3.5 (175B)。2. **提示策略评估**：评估了零样本、少样本、思维链、角色扮演、序列化及其组合等七种结构化提示策略。3. **题目评估**：使用自动化指标和专家在五个维度上进行评分。4. **大规模评估模拟**：利用经过专家评分样本训练的GPT-4.1来模拟人类评分。

Result: 1. 结构化提示，特别是结合了思维链和序列化设计的策略，显著提升了Gemma模型的输出质量。2. 与GPT-3.5的零样本响应相比，Gemma生成的题目在构念对齐和教学适宜性方面通常表现更优，其中提示设计对中型模型性能起着关键作用。

Conclusion: 1. 在数据有限的条件下，结构化提示和高效微调能够有效增强中型模型进行自动生成（AIG）的能力。2. 结合自动化指标、专家判断和大型模型模拟的评估方法，对于确保与评估目标一致性具有重要价值。3. 本研究提出的工作流程为K-12语言评估项目的开发和验证提供了一种实用且可扩展的方法。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 本文提出一种开源方法，通过将SystemC TLM模型封装为FMI 3.0 FMU，实现SystemC TLM与FMI协同仿真工作流的集成，以解决跨域互操作性挑战。


<details>
  <summary>Details</summary>
Motivation: 随着网络物理系统（尤其在汽车应用中）的日益复杂，对高效建模和跨域协同仿真技术的需求增加。SystemC TLM虽能有效进行硬件/软件协同设计，但其与其他工程领域模型的有限互操作性带来了集成难题。

Method: 本文提出一种完全开源的方法，通过将SystemC TLM组件封装为FMI 3.0协同仿真功能模型单元（FMU），实现SystemC TLM模型到FMI协同仿真工作流的集成。该方法引入了一个轻量级开源工具链，并解决了时间同步和数据交换等关键技术挑战。

Result: 通过代表性案例研究，证明了所提出的集成方法的可行性和有效性。

Conclusion: 该方法通过标准化且无缝的集成，有效解决了SystemC TLM模型在异构仿真环境中的互操作性问题，从而促进了跨域协同仿真。

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 针对紧凑型语言模型通过强化学习实现Agentic RAG行为时遇到的难题，本文提出Distillation-Guided Policy Optimization (DGPO) 方法，通过教师引导使其能实现复杂的Agentic搜索行为，甚至超越大型教师模型，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 紧凑型语言模型（如0.5B参数）在通过强化学习（RL）实现Agentic RAG行为时，因推理能力不足，面临稀疏奖励和训练不稳定的挑战。

Method: 本文提出Distillation-Guided Policy Optimization (DGPO) 方法，通过教师演示进行冷启动初始化，并在策略优化过程中提供持续的教师指导。此外，为系统评估方法，引入了Agentic RAG Capabilities (ARC) 细粒度指标，用于分析推理、搜索协调和响应合成能力。

Result: 全面的实验证明，DGPO使紧凑型模型能够实现复杂的Agentic搜索行为，在某些情况下甚至超越了大型教师模型。

Conclusion: DGPO使得在计算资源受限的环境中实现Agentic RAG成为可能。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 本文提出GUARD方法，通过自动化生成违规问题并结合越狱诊断（GUARD-JD），将高层级伦理指南转化为可操作的测试，以评估大型语言模型（LLMs）的合规性并识别潜在安全漏洞，最终生成合规报告。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）生成有害内容的潜力引发了社会和监管担忧。政府发布了伦理指南，但这些指南通常是高层级要求，缺乏将其转化为具体可操作的测试问题来验证LLM合规性的方法。

Method: GUARD方法通过自动化生成基于政府指南的违规问题来测试LLMs的合规性。对于直接违规的响应，GUARD会报告不一致性。对于未直接违规的响应，GUARD-JD引入“越狱”概念，创建场景以诱发不道德或违规响应，从而识别绕过内置安全机制的潜在漏洞。最终生成详细的合规报告。

Result: GUARD在七个LLMs（包括Vicuna-13B、LongChat-7B、Llama2-7B、Llama-3-8B、GPT-3.5、GPT-4、GPT-4o和Claude-3.7）上进行了实证验证，测试了在三项政府指南下的合规性并进行了越狱诊断。GUARD-JD还能将越狱诊断转移到视觉-语言模型上。

Conclusion: GUARD方法有效解决了将伦理指南转化为LLM合规性测试的挑战，能够识别LLM的违规行为和安全漏洞，并有助于推广可靠的LLM应用。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出CHAIR-DPO方法，利用CHAIR指标构建偏好数据，并通过DPO对多模态大语言模型（MLLMs）进行微调，以有效减少其幻觉生成问题，且无需复杂的合成数据管道。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）尽管性能卓越，但存在严重的幻觉问题，即生成与视觉输入不符的内容。现有的解决方案通常需要复杂的合成偏好数据生成流程和专有模型。

Method: 将幻觉问题视为对齐问题。利用现有的CHAIR指标，根据生成的答案对（一个无幻觉，一个有幻觉）来区分“优胜”和“劣势”选项。然后，通过直接偏好优化（DPO）对现有MLLMs进行微调，使用基于CHAIR的奖励来引导模型生成无幻觉内容，该方法命名为CHAIR-DPO。

Result: CHAIR-DPO方法在多个幻觉基准测试中有效减少了幻觉答案的数量，证明了使用基于CHAIR的奖励来微调MLLM的有效性。

Conclusion: CHAIR-DPO提供了一种简单而有效的方法，通过利用CHAIR指标和DPO微调MLLM，显著缓解了MLLM的幻觉问题，避免了复杂的数据生成过程。

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation](https://arxiv.org/abs/2508.20131)
*Yuqicheng Zhu,Nico Potyka,Daniel Hernández,Yuan He,Zifeng Ding,Bo Xiong,Dongzhuoran Zhou,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: 本文提出ArgRAG，一种可解释且可争议的RAG替代方案，它利用定量两极论证框架（QBAF）进行结构化、确定性推理，以解决传统RAG在噪声敏感性和不透明决策方面的局限性，并在事实核查任务中表现出高准确性和显著的透明度提升。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）通过引入外部知识提升了大型语言模型，但在高风险领域存在关键限制，即对噪声或矛盾证据的敏感性以及不透明、随机的决策过程。

Method: 本文提出了ArgRAG，通过使用定量两极论证框架（QBAF）进行结构化推理，取代了传统的黑盒推理。ArgRAG从检索到的文档中构建QBAF，并在渐进语义下执行确定性推理，从而实现决策的忠实解释和争议。

Result: 在PubHealth和RAGuard这两个事实核查基准上进行评估，ArgRAG实现了强大的准确性，同时显著提高了透明度。

Conclusion: ArgRAG提供了一个可解释且可争议的RAG替代方案，通过结构化推理解决了RAG的黑盒决策和噪声敏感性问题，并在保持高准确性的同时显著提升了决策的透明度。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models by
incorporating external knowledge, yet suffers from critical limitations in
high-stakes domains -- namely, sensitivity to noisy or contradictory evidence
and opaque, stochastic decision-making. We propose ArgRAG, an explainable, and
contestable alternative that replaces black-box reasoning with structured
inference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG
constructs a QBAF from retrieved documents and performs deterministic reasoning
under gradual semantics. This allows faithfully explaining and contesting
decisions. Evaluated on two fact verification benchmarks, PubHealth and
RAGuard, ArgRAG achieves strong accuracy while significantly improving
transparency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [CrystalICL: Enabling In-Context Learning for Crystal Generation](https://arxiv.org/abs/2508.20143)
*Ruobing Wang,Qiaoyu Tan,Yili Wang,Ying Wang,Xin Wang*

Main category: cs.LG

TL;DR: 针对现有LLM晶体生成无法利用少样本学习的挑战，本文提出CrystalICL模型。通过空间群标记化和指令微调，CrystalICL实现了少样本晶体生成，并在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 设计具有所需理化性质的晶体材料是材料科学的基本挑战。现有基于大型语言模型（LLM）的晶体生成方法受限于零样本（zero-shot）场景，无法受益于少样本（few-shot）学习。人类专家通过修改已知结构进行材料设计，这与少样本上下文学习（ICL）范式高度契合。因此，研究动机是开发一种能够利用少样本ICL进行晶体生成的模型。

Method: 提出CrystalICL模型，专为少样本晶体生成设计。具体方法包括：1) 引入基于空间群的晶体标记化方法，以有效降低LLM建模晶体对称性的复杂性；2) 引入条件结构感知的混合指令微调框架；3) 采用多任务指令微调策略，使模型能从有限数据中捕获结构-性质关系，从而更好地利用ICL。

Result: 在四个晶体生成基准测试上进行了广泛实验，结果表明CrystalICL在有条件和无条件生成任务中均表现出优于领先基线方法的性能。

Conclusion: CrystalICL成功地将少样本上下文学习应用于晶体生成，克服了现有LLM方法的局限性。所提出的方法，包括空间群标记化和混合指令微调，显著提升了模型在晶体设计中的性能。

Abstract: Designing crystal materials with desired physicochemical properties remains a
fundamental challenge in materials science. While large language models (LLMs)
have demonstrated strong in-context learning (ICL) capabilities, existing
LLM-based crystal generation approaches are limited to zero-shot scenarios and
are unable to benefit from few-shot scenarios. In contrast, human experts
typically design new materials by modifying relevant known structures which
aligns closely with the few-shot ICL paradigm. Motivated by this, we propose
CrystalICL, a novel model designed for few-shot crystal generation.
Specifically, we introduce a space-group based crystal tokenization method,
which effectively reduces the complexity of modeling crystal symmetry in LLMs.
We further introduce a condition-structure aware hybrid instruction tuning
framework and a multi-task instruction tuning strategy, enabling the model to
better exploit ICL by capturing structure-property relationships from limited
data. Extensive experiments on four crystal generation benchmarks demonstrate
the superiority of CrystalICL over the leading baseline methods on conditional
and unconditional generation tasks.

</details>


### [9] [Filter then Attend: Improving attention-based Time Series Forecasting with Spectral Filtering](https://arxiv.org/abs/2508.20206)
*Elisha Dayag,Nhat Thanh Van Tran,Jack Xin*

Main category: cs.LG

TL;DR: 本文提出在Transformer模型中加入可学习频率滤波器，以改善长序列时间预测（LTSF）的性能，解决其低频偏差及高资源消耗问题，并显著提升预测准确性和模型效率。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在长序列时间预测中面临低频偏差以及高计算和内存开销问题。现有利用可学习频率滤波器的工作虽能增强光谱利用，但未能解决Transformer模型的固有问题。

Method: 研究者在多个Transformer模型的前端添加了可学习的频率滤波器，这些滤波器仅增加了大约1000个参数。此外，他们还尝试降低模型的嵌入维度，并进行了合成实验来分析滤波器如何帮助模型更好地利用全频谱进行预测。

Result: 通过添加滤波器，模型在多个实例中实现了5-10%的相对预测性能提升。同时，研究发现添加滤波器后可以减小模型的嵌入维度，使得Transformer架构更小且比无滤波器的基础模型更有效。合成实验表明滤波器使Transformer模型能更好地利用全频谱进行预测。

Conclusion: 为Transformer模型添加可学习频率滤波器能有效提升其在长序列时间预测中的性能，不仅提高了预测准确性，还使得模型更紧凑高效，并增强了模型对数据全频谱的利用能力。

Abstract: Transformer-based models are at the forefront in long time-series forecasting
(LTSF). While in many cases, these models are able to achieve state of the art
results, they suffer from a bias toward low-frequencies in the data and high
computational and memory requirements. Recent work has established that
learnable frequency filters can be an integral part of a deep forecasting model
by enhancing the model's spectral utilization. These works choose to use a
multilayer perceptron to process their filtered signals and thus do not solve
the issues found with transformer-based models. In this paper, we establish
that adding a filter to the beginning of transformer-based models enhances
their performance in long time-series forecasting. We add learnable filters,
which only add an additional $\approx 1000$ parameters to several
transformer-based models and observe in multiple instances 5-10 \% relative
improvement in forecasting performance. Additionally, we find that with filters
added, we are able to decrease the embedding dimension of our models, resulting
in transformer-based architectures that are both smaller and more effective
than their non-filtering base models. We also conduct synthetic experiments to
analyze how the filters enable Transformer-based models to better utilize the
full spectrum for forecasting.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [10] [A Comprehensive Survey of 5G URLLC and Challenges in the 6G Era](https://arxiv.org/abs/2508.20205)
*Md. Emadul Haque,Faisal Tariq,Muhammad R A Khandaker,Md. Sakir Hossain,Muhammad Ali Imran,Kai-Kit Wong*

Main category: cs.NI

TL;DR: 本文对5G系统中的超可靠低延迟通信（URLLC）方法进行了全面综述，涵盖其发展历史、分层技术、设计考量以及面向6G的未来挑战和展望。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信从以人为中心转向以机器为中心，对速率、延迟和可靠性提出了更高要求。URLLC作为5G和6G的关键技术应运而生，但其高可靠性与低延迟目标本质上相互冲突，需要深入研究和解决。

Method: 本文采用综合调查方法，详细分析了5G系统中的URLLC方案。研究追溯了无线通信中延迟和可靠性问题的历史及演变，并采用分层方法（物理层、MAC层和跨层技术）进行讨论。同时，还涵盖了各种5G及未来垂直领域的URLLC设计考量。

Result: 文章详细分析了5G系统中URLLC的各种实现方法，包括物理层、MAC层及跨层技术，并探讨了不同5G垂直领域的设计考虑。结果呈现了URLLC在满足高可靠性和低延迟双重挑战方面的当前进展。

Conclusion: URLLC是5G和6G的关键，但实现其冲突目标仍面临重大挑战。文章最后讨论了现有挑战，并对未来发展进行了展望，特别关注新兴的6G范式。

Abstract: As the wireless communication paradigm is being transformed from human
centered communication services towards machine centered communication
services, the requirements of rate, latency and reliability for these services
have also been transformed drastically. Thus the concept of Ultra Reliable and
Low Latency Communication (URLLC) has emerged as a dominant theme for 5G and 6G
systems. Though the latency and reliability requirement varies from one use
case to another, URLLC services generally aim to achieve very high reliability
in the range of 99.999\% while ensuring the latency of up to 1 ms. These two
targets are however inherently opposed to one another. Significant amounts of
work have been carried out to meet these ambitious but conflicting targets. In
this article a comprehensive survey of the URLLC approaches in 5G systems are
analysed in detail. Effort has been made to trace the history and evolution of
latency and reliability issues in wireless communication. A layered approach is
taken where physical layer, Medium Access Control (MAC) layer as well as cross
layer techniques are discussed in detail. It also covers the design
consideration for various 5G and beyond verticals. Finally the article
concludes by providing a detailed discussion on challenges and future outlook
with particular focus on the emerging 6G paradigm.

</details>


### [11] [DRR-MDPF: A Queue Management Strategy Based on Dynamic Resource Allocation and Markov Decision Process in Named Data Networking (NDN)](https://arxiv.org/abs/2508.20272)
*Fatemeh Roshanzadeh,Hamid Barati,Ali Barati*

Main category: cs.NI

TL;DR: 本文提出DRR-MDPF，一种结合MDPF和DRR的混合策略，用于命名数据网络（NDN）的队列和资源管理，通过多指标决策实现高效和自适应的数据转发，并在仿真中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 在动态和高流量条件下，NDN的效率高度依赖于有效的队列和资源管理，以优化数据传播。

Method: 引入DRR-MDPF，一种混合策略，将基于带宽、延迟和未满足兴趣数量预测最优转发决策的马尔可夫决策过程转发（MDPF）模型，与确保公平带宽分配的亏空轮询（DRR）算法相结合。路由器被建模为通过连续反馈和概率更新调整策略的学习代理，并在ndnSIM中进行仿真。

Result: DRR-MDPF在吞吐量、兴趣满足率（ISR）、丢包率、内容检索时间和负载均衡等指标上显著优于现有策略（SAF, RFA, SMDPF, LA-MDPF）。它在有限缓存和高流量下仍保持鲁棒性，具有增强的适应性和较低的计算复杂度，并且多指标决策能力能实现更准确的接口选择。

Conclusion: DRR-MDPF是NDN的一种智能、自适应且可扩展的队列管理解决方案，有效解决了动态网络环境中的资源分配、拥塞控制和路由优化等核心挑战。

Abstract: Named Data Networking (NDN) represents a transformative shift in network
architecture, prioritizing content names over host addresses to enhance data
dissemination. Efficient queue and resource management are critical to NDN
performance, especially under dynamic and high-traffic conditions. This paper
introduces DRR-MDPF, a novel hybrid strategy that integrates the Markov
Decision Process Forwarding (MDPF) model with the Deficit Round Robin (DRR)
algorithm. MDPF enables routers to intelligently predict optimal forwarding
decisions based on key metrics such as bandwidth, delay, and the number of
unsatisfied Interests, while DRR ensures fair and adaptive bandwidth allocation
among competing data flows. The proposed method models each router as a
learning agent capable of adjusting its strategies through continuous feedback
and probabilistic updates. Simulation results using ndnSIM demonstrate that
DRR-MDPF significantly outperforms state-of-the-art strategies including SAF,
RFA, SMDPF, and LA-MDPF across various metrics such as throughput, Interest
Satisfaction Rate (ISR), packet drop rate, content retrieval time, and load
balancing. Notably, DRR-MDPF maintains robustness under limited cache sizes and
heavy traffic, offering enhanced adaptability and lower computational
complexity due to its single-path routing design. Furthermore, its multi-metric
decision-making capability enables more accurate interface selection, leading
to optimized network performance. Overall, DRR-MDPF serves as an intelligent,
adaptive, and scalable queue management solution for NDN, effectively
addressing core challenges such as resource allocation, congestion control, and
route optimization in dynamic networking environments.

</details>
