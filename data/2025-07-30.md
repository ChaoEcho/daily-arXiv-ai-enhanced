<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 4]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.DL](#cs.DL) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Categorical Classification of Book Summaries Using Word Embedding Techniques](https://arxiv.org/abs/2507.21058)
*Kerem Keskin,Mümine Kaya Keleş*

Main category: cs.CL

TL;DR: 本研究使用词嵌入、NLP和机器学习算法对图书摘要和类别进行分类。结果显示，对于土耳其文本，支持向量机、朴素贝叶斯和逻辑回归模型结合TF-IDF和One-Hot Encoder词嵌入技术表现更优。


<details>
  <summary>Details</summary>
Motivation: 论文旨在利用词嵌入方法、自然语言处理技术和机器学习算法对图书摘要和类别进行分类，并比较不同词嵌入方法的分类效果。

Method: 研究采用词嵌入方法、自然语言处理技术和机器学习算法进行分类。具体使用的词嵌入方法包括One-hot encoding、Word2Vec和TF-IDF，并对它们的成功率进行了比较。此外，还展示了所用预处理方法的组合表格。

Result: 研究结果表明，对于土耳其文本，支持向量机（SVM）、朴素贝叶斯（Naive Bayes）和逻辑回归（Logistic Regression）模型，结合TF-IDF和One-Hot Encoder词嵌入技术，取得了更成功的分类结果。

Conclusion: TF-IDF和One-Hot Encoder词嵌入技术与支持向量机、朴素贝叶斯和逻辑回归模型结合，是有效分类土耳其语图书摘要和类别的成功方法。

Abstract: In this study, book summaries and categories taken from book sites were
classified using word embedding methods, natural language processing techniques
and machine learning algorithms. In addition, one hot encoding, Word2Vec and
Term Frequency - Inverse Document Frequency (TF-IDF) methods, which are
frequently used word embedding methods were used in this study and their
success was compared. Additionally, the combination table of the pre-processing
methods used is shown and added to the table. Looking at the results, it was
observed that Support Vector Machine, Naive Bayes and Logistic Regression
Models and TF-IDF and One-Hot Encoder word embedding techniques gave more
successful results for Turkish texts.

</details>


### [2] [Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions](https://arxiv.org/abs/2507.21065)
*Sabrina Patania,Luca Annese,Cansu Koyuturk,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.CL

TL;DR: 该研究引入对话式学习范式，受维果茨基理论启发，通过AI师生互动显著提升大型语言模型（LLMs）的在线知识获取与应用能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽擅长处理离线数据，但在获取和整合复杂在线知识方面存在挑战。传统的基于监督学习或强化学习的AI训练范式效率低下，且难以从稀疏反馈和交互中有效学习。

Method: 研究引入“AI社交健身房”动态环境，其中AI学习代理与AI教师代理进行二元教学对话。该方法强调外部、结构化对话作为知识获取的核心机制，并聚焦于不同教学策略对本体论获取的影响。

Result: 实证结果表明，对话式学习方法，尤其是结合自上而下解释和学习者提问的混合方向交互，能显著增强LLM获取和应用新知识的能力。其表现优于单向教学法和直接访问结构化知识的传统方式。

Conclusion: 研究结果表明，将教学和心理学见解融入AI和机器人训练，可以大幅提升模型在训练后的知识获取和响应质量，为现有策略（如提示工程）提供了一条补充途径。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
processing extensive offline datasets. However, they often face challenges in
acquiring and integrating complex, knowledge online. Traditional AI training
paradigms, predominantly based on supervised learning or reinforcement
learning, mirror a 'Piagetian' model of independent exploration. These
approaches typically rely on large datasets and sparse feedback signals,
limiting the models' ability to learn efficiently from interactions. Drawing
inspiration from Vygotsky's sociocultural theory, this study explores the
potential of socially mediated learning paradigms to address these limitations.
  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI
learner agent engages in dyadic pedagogical dialogues with knowledgeable AI
teacher agents. These interactions emphasize external, structured dialogue as a
core mechanism for knowledge acquisition, contrasting with methods that depend
solely on internal inference or pattern recognition.
  Our investigation focuses on how different pedagogical strategies impact the
AI learning process in the context of ontology acquisition. Empirical results
indicate that such dialogic approaches-particularly those involving
mixed-direction interactions combining top-down explanations with
learner-initiated questioning-significantly enhance the LLM's ability to
acquire and apply new knowledge, outperforming both unidirectional
instructional methods and direct access to structured knowledge, formats
typically present in training datasets.
  These findings suggest that integrating pedagogical and psychological
insights into AI and robot training can substantially improve post-training
knowledge acquisition and response quality. This approach offers a
complementary pathway to existing strategies like prompt engineering

</details>


### [3] [Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing](https://arxiv.org/abs/2507.21073)
*David James Woo,Yangyang Yu,Kai Guo,Yilin Huang,April Ka Yeng Fung*

Main category: cs.CL

TL;DR: 本研究探讨了EFL中学生编辑AI生成文本的行为及其对说明文写作质量的影响，发现AI生成词汇量与得分正相关，但学生的编辑努力对文章质量提升效果不显著，表明AI是辅助而非替代写作技能。


<details>
  <summary>Details</summary>
Motivation: 人工智能聊天机器人生成的文本在EFL写作中日益普及，但其对学生说明文写作过程和作品的影响仍未得到充分研究。本研究旨在填补这一空白，考察学生如何编辑AI文本及其对写作质量的影响。

Method: 研究招募了39名香港中学生，他们在工作坊中使用AI聊天机器人撰写说明文。采用汇聚设计，通过分析屏幕录像和作品，结合定性编码、描述性统计、时间序列分析、人工评分和多元线性回归分析来考察学生的编辑行为和写作质量。分析了超过260个编辑数据。

Result: 研究识别出两种编辑模式：一是学生反复修改引言部分，二是快速转向主体部分（如主题句和支撑句）的大量修改。多元线性回归分析显示，AI生成的词汇量与所有评分维度（内容、组织、语言、整体质量）呈正相关，而大多数编辑变量对得分影响甚微。这表明学生的显著编辑努力与作文质量的提升之间存在脱节。

Conclusion: 研究结果表明AI辅助而非取代写作技能。在整合AI之前，强调体裁特定的教学和过程导向的写作至关重要。教育者应发展重视过程和成果的评估方式，以鼓励学生批判性地使用AI文本。

Abstract: Text generated by artificial intelligence (AI) chatbots is increasingly used
in English as a foreign language (EFL) writing contexts, yet its impact on
students' expository writing process and compositions remains understudied.
This research examines how EFL secondary students edit AI-generated text.
Exploring editing behaviors in their expository writing process and in
expository compositions, and their effect on human-rated scores for content,
organization, language, and overall quality. Participants were 39 Hong Kong
secondary students who wrote an expository composition with AI chatbots in a
workshop. A convergent design was employed to analyze their screen recordings
and compositions to examine students' editing behaviors and writing qualities.
Analytical methods included qualitative coding, descriptive statistics,
temporal sequence analysis, human-rated scoring, and multiple linear regression
analysis. We analyzed over 260 edits per dataset, and identified two editing
patterns: one where students refined introductory units repeatedly before
progressing, and another where they quickly shifted to extensive edits in body
units (e.g., topic and supporting sentences). MLR analyses revealed that the
number of AI-generated words positively predicted all score dimensions, while
most editing variables showed minimal impact. These results suggest a
disconnect between students' significant editing effort and improved
composition quality, indicating AI supports but does not replace writing
skills. The findings highlight the importance of genre-specific instruction and
process-focused writing before AI integration. Educators should also develop
assessments valuing both process and product to encourage critical engagement
with AI text.

</details>


### [4] [Which symbol grounding problem should we try to solve?](https://arxiv.org/abs/2507.21080)
*Vincent C. Müller*

Main category: cs.CL

TL;DR: 本文批判了Floridi和Taddeo提出的“零语义承诺”条件及其基础问题解决方案，并重新定义了基础问题，认为其应关注人工计算智能体中意义的功能。


<details>
  <summary>Details</summary>
Motivation: 指出Floridi和Taddeo的“零语义承诺”条件不可实现，并认为需要重新思考基础问题的本质及其在系统中“目标”的作用。

Method: 分析并批判Floridi和Taddeo的观点，审视Luc Steels等人的不同建议，并基于对计算的理解，重新界定基础问题。

Result: Floridi和Taddeo的“零语义承诺”条件及其解决方案无法实现。基础问题需要被重新理解。

Conclusion: 唯一有意义的基础问题是如何解释和再现人工计算智能体中意义的行为能力和功能。

Abstract: Floridi and Taddeo propose a condition of "zero semantic commitment" for
solutions to the grounding problem, and a solution to it. I argue briefly that
their condition cannot be fulfilled, not even by their own solution. After a
look at Luc Steels' very different competing suggestion, I suggest that we need
to re-think what the problem is and what role the 'goals' in a system play in
formulating the problem. On the basis of a proper understanding of computing, I
come to the conclusion that the only sensible grounding problem is how we can
explain and re-produce the behavioral ability and function of meaning in
artificial computational agents

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [GAITEX: Human motion dataset from impaired gait and rehabilitation exercises of inertial and optical sensor data](https://arxiv.org/abs/2507.21069)
*Andreas Spilz,Heiko Oppel,Jochen Werner,Kathrin Stucke-Straub,Felix Capanni,Michael Munz*

Main category: cs.CV

TL;DR: 一个包含物理治疗运动和步态数据的多模态（IMU+MoCap）数据集，涵盖正常及异常模式，旨在加速机器学习驱动的人体运动分析研究。


<details>
  <summary>Details</summary>
Motivation: 可穿戴惯性测量单元（IMU）在人体运动质量评估中具有成本效益和可扩展性，但开发鲁棒的基于传感器的运动分类模型需要大量多样化数据集，而此类数据收集成本高昂且耗时。

Method: 本研究从19名参与者处收集了一个多模态数据集，包含同步的IMU和光学标记运动捕捉（MoCap）数据。数据集包括9个IMU的原始数据和35个光学标记的全身体运动学数据。为支持进一步分析，还提供了处理后的IMU方向、主体特异性OpenSim模型、逆运动学结果、可视化工具，以及运动执行质量和时间戳标注，并提供了用于后处理和验证的代码。

Result: 成功构建并提供了一个大型、多样化的多模态数据集，包含IMU和MoCap原始数据、处理后的运动学信息及相关分析工具。该数据集支持机器学习模型在自动运动评估、步态分析、时间活动分割和生物力学参数估计等任务上的开发和基准测试。

Conclusion: 该数据集提供高质量、多样化的运动数据和分析工具，旨在加速机器学习驱动的人体运动分析领域的研究，从而促进相关模型的开发和基准测试。

Abstract: Wearable inertial measurement units (IMUs) offer a cost-effective and
scalable means to assess human movement quality in clinical and everyday
settings. However, the development of robust sensor-based classification models
for physiotherapeutic exercises and gait analysis requires large, diverse
datasets, which are costly and time-consuming to collect. Here, we present a
multimodal dataset of physiotherapeutic exercises - including correct and
clinically relevant variants - and gait-related exercises - including both
normal and impaired gait patterns - recorded from 19 participants using
synchronized IMUs and marker-based motion capture (MoCap). The dataset includes
raw data from nine IMUs and thirty-five optical markers capturing full-body
kinematics. Each IMU is additionally equipped with four optical markers,
enabling precise comparison between IMU-derived orientation estimates and
reference values from the MoCap system. To support further analysis, we also
provide processed IMU orientations aligned with common segment coordinate
systems, subject-specific OpenSim models, inverse kinematics results, and tools
for visualizing IMU orientations in the musculoskeletal context. Detailed
annotations of movement execution quality and time-stamped segmentations
support diverse analysis goals. This dataset supports the development and
benchmarking of machine learning models for tasks such as automatic exercise
evaluation, gait analysis, temporal activity segmentation, and biomechanical
parameter estimation. To facilitate reproducibility, we provide code for
postprocessing, sensor-to-segment alignment, inverse kinematics computation,
and technical validation. This resource is intended to accelerate research in
machine learning-driven human movement analysis.

</details>


### [6] [Seeing Beyond Frames: Zero-Shot Pedestrian Intention Prediction with Raw Temporal Video and Multimodal Cues](https://arxiv.org/abs/2507.21161)
*Pallavi Zambare,Venkata Nikhil Thanikella,Ying Liu*

Main category: cs.CV

TL;DR: BF-PIP是一种基于Gemini 2.5 Pro的零样本行人意图预测方法，通过处理连续视频片段和结合上下文线索，实现了高精度预测，并优于基于GPT-4V的方法。


<details>
  <summary>Details</summary>
Motivation: 在复杂的城市环境中，行人意图预测对自动驾驶至关重要。传统方法依赖于监督学习和帧序列，需要大量再训练以适应新场景。

Method: 本文提出BF-PIP（Beyond Frames Pedestrian Intention Prediction），一种基于Gemini 2.5 Pro的零样本方法。它直接从包含JAAD元数据的短连续视频片段中推断行人过街意图。与基于GPT-4V的离散帧方法不同，BF-PIP处理不间断的时间片段，并通过多模态提示整合边界框标注和自车速度。

Result: 在无需额外训练的情况下，BF-PIP实现了73%的预测准确率，比基于GPT-4V的基线方法高出18%。

Conclusion: 研究结果表明，结合时间视频输入和上下文线索可以增强时空感知，并在模糊条件下改善意图推断。这种方法为智能交通系统中的敏捷、免再训练的感知模块铺平了道路。

Abstract: Pedestrian intention prediction is essential for autonomous driving in
complex urban environments. Conventional approaches depend on supervised
learning over frame sequences and require extensive retraining to adapt to new
scenarios. Here, we introduce BF-PIP (Beyond Frames Pedestrian Intention
Prediction), a zero-shot approach built upon Gemini 2.5 Pro. It infers crossing
intentions directly from short, continuous video clips enriched with structured
JAAD metadata. In contrast to GPT-4V based methods that operate on discrete
frames, BF-PIP processes uninterrupted temporal clips. It also incorporates
bounding-box annotations and ego-vehicle speed via specialized multimodal
prompts. Without any additional training, BF-PIP achieves 73% prediction
accuracy, outperforming a GPT-4V baseline by 18 %. These findings illustrate
that combining temporal video inputs with contextual cues enhances
spatiotemporal perception and improves intent inference under ambiguous
conditions. This approach paves the way for agile, retraining-free perception
module in intelligent transportation system.

</details>


### [7] [ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions](https://arxiv.org/abs/2507.21167)
*Danglu Yang,Liang Zhang,Zihao Yue,Liangyu Chen,Yichen Xu,Wenxuan Wang,Qin Jin*

Main category: cs.CV

TL;DR: 本文提出了一种多模态图表编辑的新范式，并构建了ChartM3基准和ChartM3-Train训练集，以解决现有方法的局限性并提升多模态大语言模型的图表编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有图表编辑方法主要依赖自然语言指令，但其模糊性难以支持细粒度编辑。用户期望通过结合自然语言和视觉指示来表达编辑意图，但当前的多模态大语言模型（MLLMs）在理解和执行视觉指示方面存在显著局限性。

Method: 引入了结合自然语言和视觉指示的多模态图表编辑新范式。构建了ChartM3基准数据集，包含1,000个样本，涵盖四种编辑难度，每个样本包含（图表、代码、多模态指令）三元组。设计了评估图表视觉外观和代码正确性的多维度指标。进一步构建了ChartM3-Train大规模训练集（24,000个样本），并使用该数据集对MLLMs进行微调。

Result: 通过ChartM3基准测试发现，包括GPT-4o在内的当前MLLMs在解释和响应视觉指示方面存在显著局限性。在ChartM3-Train数据集上对MLLMs进行微调后，模型性能得到显著提升。

Conclusion: 研究表明，多模态监督对于构建实用的图表编辑系统至关重要。本文提供的基准、代码和评估工具可促进未来研究。

Abstract: Charts are a fundamental visualization format widely used in data analysis
across research and industry. While enabling users to edit charts based on
high-level intentions is of great practical value, existing methods primarily
rely on natural language instructions, which are often too ambiguous to support
fine-grained editing. In this work, we introduce a novel paradigm for
multimodal chart editing, where user intent is expressed through a combination
of natural language and visual indicators that explicitly highlight the
elements to be modified. To support this paradigm, we present
Chart$\text{M}^3$, a new benchmark for Multimodal chart editing with
Multi-level complexity and Multi-perspective evaluation. Chart$\text{M}^3$
contains 1,000 samples spanning four levels of editing difficulty. Each sample
includes triplets in the form of (chart, code, multimodal instructions). To
comprehensively evaluate chart editing models, Chart$\text{M}^3$ provides
metrics that assess both visual appearance and code correctness. Our benchmark
reveals significant limitations in current multimodal large language models
(MLLMs), including GPT-4o, particularly in their ability to interpret and act
on visual indicators. To address this, we construct Chart$\text{M}^3$-Train, a
large-scale training set with 24,000 multimodal chart editing samples.
Fine-tuning MLLMs on this dataset leads to substantial improvements,
demonstrating the importance of multimodal supervision in building practical
chart editing systems. Our datasets, codes, and evaluation tools are available
at https://github.com/MLrollIT/ChartM3. %https://github.com/MLrollIT/ChartM3Our
datasets, codes, and evaluation tools are available at
https://github.com/yaolinli/VCE.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration](https://arxiv.org/abs/2507.21067)
*Jan Kapusta*

Main category: cs.AI

TL;DR: 提出共生认知论作为人机认知伙伴的哲学基础，并引入SynLang协议，通过双层透明推理模式和置信度评估，促进人机之间校准信任和深度协作，旨在增强人类智能并确保伦理责任。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统推理过程不透明，阻碍人类监督和协作潜力。现有可解释AI（XAI）方法多为事后解释，未能建立真正共生的人机协作关系。

Method: 1. 提出“共生认知论”作为人机认知伙伴关系的哲学基础，将AI定位为推理伙伴。2. 引入“SynLang（共生句法语言）”作为透明人机协作的正式协议，包含TRACE（高层推理模式）和TRACE_FE（详细因素解释）两种互补机制，并整合置信度量化、声明式控制和上下文继承。3. 通过真实人机对话对该框架进行经验验证。

Result: 经验验证表明AI能够适应结构化推理协议并成功进行元认知干预。SynLang协议通过结构化通信和置信度校准的透明度，使AI系统能够增强人类智能、保留人类能动性并维护协作决策中的伦理责任。双层透明度（从高层到细节解释）促进了快速理解和彻底验证AI决策。

Conclusion: 本研究通过共生认知论和SynLang协议，为实现透明、可信赖的人机认知伙伴关系提供了解决方案，旨在提升人类智能、保留人类主导权并确保协作决策的伦理责任和问责制。

Abstract: Current AI systems rely on opaque reasoning processes that hinder human
oversight and collaborative potential. Conventional explainable AI approaches
offer post-hoc justifications and often fail to establish genuine symbiotic
collaboration. In this paper, the Symbiotic Epistemology is presented as a
philosophical foundation for human-AI cognitive partnerships. Unlike frameworks
that treat AI as a mere tool or replacement, symbiotic epistemology positions
AI as a reasoning partner, fostering calibrated trust by aligning human
confidence with AI reliability through explicit reasoning patterns and
confidence assessments. SynLang (Symbiotic Syntactic Language) is introduced as
a formal protocol for transparent human-AI collaboration. The framework is
empirically validated through actual human-AI dialogues demonstrating AI's
adaptation to structured reasoning protocols and successful metacognitive
intervention. The protocol defines two complementary mechanisms: TRACE for
high-level reasoning patterns and TRACE_FE for detailed factor explanations. It
also integrates confidence quantification, declarative control over AI
behavior, and context inheritance for multi-agent coordination. By structuring
communication and embedding confidence-calibrated transparency, SynLang,
together with symbiotic epistemology, enables AI systems that enhance human
intelligence, preserve human agency, and uphold ethical accountability in
collaborative decision-making. Through dual-level transparency, beginning with
high-level reasoning patterns and progressing to granular explanations, the
protocol facilitates rapid comprehension and supports thorough verification of
AI decision-making.

</details>


### [9] [Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks](https://arxiv.org/abs/2507.21974)
*Mohamed Sana,Nicola Piovesan,Antonio De Domenico,Yibin Kang,Haozhe Zhang,Merouane Debbah,Fadhel Ayed*

Main category: cs.AI

TL;DR: 本文提出了一个轻量级框架，利用大型语言模型（LLMs）进行移动网络中的根因分析（RCA），并通过两阶段训练方法显著提高了LLMs在该领域的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 移动网络中的根因分析（RCA）由于需要可解释性、领域专业知识和因果推理，仍然是一个具有挑战性的任务。

Method: 1. 提出了一个利用LLMs进行RCA的轻量级框架。2. 构建了名为TeleLogs的带注释故障排除数据集，用于RCA能力基准测试。3. 提出了一种结合监督微调（SFT）和强化学习（RL）的两阶段训练方法，以提高LLMs的准确性和推理质量。4. 微调了一系列RCA模型以整合领域知识并生成结构化、多步骤的诊断解释。

Result: 1. 现有开源推理LLMs在TeleLogs数据集上表现不佳。2. 所提出的方法在多尺寸LLM上均实现了显著的性能提升，超越了现有最先进的推理和非推理模型。3. 模型对随机化测试变体表现出强大的泛化能力。

Conclusion: 领域适应和推理增强的LLMs在网络运营和管理中，对于实用且可解释的根因分析具有广阔前景。

Abstract: Root Cause Analysis (RCA) in mobile networks remains a challenging task due
to the need for interpretability, domain expertise, and causal reasoning. In
this work, we propose a lightweight framework that leverages Large Language
Models (LLMs) for RCA. To do so, we introduce TeleLogs, a curated dataset of
annotated troubleshooting problems designed to benchmark RCA capabilities. Our
evaluation reveals that existing open-source reasoning LLMs struggle with these
problems, underscoring the need for domain-specific adaptation. To address this
issue, we propose a two-stage training methodology that combines supervised
fine-tuning with reinforcement learning to improve the accuracy and reasoning
quality of LLMs. The proposed approach fine-tunes a series of RCA models to
integrate domain knowledge and generate structured, multi-step diagnostic
explanations, improving both interpretability and effectiveness. Extensive
experiments across multiple LLM sizes show significant performance gains over
state-of-the-art reasoning and non-reasoning models, including strong
generalization to randomized test variants. These results demonstrate the
promise of domain-adapted, reasoning-enhanced LLMs for practical and
explainable RCA in network operation and management.

</details>


### [10] [Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism](https://arxiv.org/abs/2507.21098)
*Marta Sidorkiewicz,Karolina Królikowska,Berenika Dyczek,Edyta Pijet-Migon,Anna Dubel*

Main category: cs.AI

TL;DR: 本研究探讨人工智能（AI）在葡萄酒产业中，通过智能管理提升可持续性和效率的作用。


<details>
  <summary>Details</summary>
Motivation: 葡萄酒产业面临环境和经济挑战，AI有望通过优化资源、减少环境影响和改善客户体验来提供创新解决方案，从而促进负责任和高效的行业实践。

Method: 研究方法包括对波兰酿酒师进行问卷调查，并结合对适用于葡萄栽培、葡萄酒生产和葡萄酒旅游的关键AI技术（如预测分析、机器学习和计算机视觉）的综合分析。

Result: 研究结果表明，AI能增强葡萄园监测、优化灌溉并简化生产流程，促进可持续资源管理。在葡萄酒旅游中，AI聊天机器人、推荐系统和虚拟品鉴能个性化消费者体验。AI对经济、环境和社会可持续性均有积极影响，并支持当地葡萄酒企业和文化遗产。

Conclusion: AI在葡萄酒产业的智能管理中，尤其在葡萄栽培、生产和旅游方面，能够显著提升效率，并对经济、环境和社会的可持续发展产生积极而重要的影响。

Abstract: This study examines the role of Artificial Intelligence (AI) in enhancing
sustainability and efficiency within the wine industry. It focuses on AI-driven
intelligent management in viticulture, wine production, and enotourism. As the
wine industry faces environmental and economic challenges, AI offers innovative
solutions to optimize resource use, reduce environmental impact, and improve
customer engagement. Understanding AI's potential in sustainable winemaking is
crucial for fostering responsible and efficient industry practices. The
research is based on a questionnaire survey conducted among Polish winemakers,
combined with a comprehensive analysis of AI methods applicable to viticulture,
production, and tourism. Key AI technologies, including predictive analytics,
machine learning, and computer vision, are explored. The findings indicate that
AI enhances vineyard monitoring, optimizes irrigation, and streamlines
production processes, contributing to sustainable resource management. In
enotourism, AI-powered chatbots, recommendation systems, and virtual tastings
personalize consumer experiences. The study highlights AI's impact on economic,
environmental, and social sustainability, supporting local wine enterprises and
cultural heritage. Keywords: Artificial Intelligence, Sustainable Development,
AI-Driven Management, Viticulture, Wine Production, Enotourism, Wine
Enterprises, Local Communities

</details>


### [11] [Leveraging Generative AI to Enhance Synthea Module Development](https://arxiv.org/abs/2507.21123)
*Mark A. Kramer,Aanchal Mathur,Caroline E. Adams,Jason A. Walonoski*

Main category: cs.AI

TL;DR: 本文探讨使用大型语言模型（LLMs）辅助Synthea疾病模块的开发，旨在提升效率和数据质量，并讨论了其应用方式、潜在收益及面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 将LLMs整合到Synthea疾病模块开发过程中，以减少开发时间、降低所需专业知识、扩展模型多样性并提高合成患者数据的整体质量。

Method: 展示了LLMs支持Synthea模块创建的四种方式：生成疾病概况、根据疾病概况生成疾病模块、评估现有Synthea模块和精修现有模块。引入了“渐进式精修”概念，通过迭代评估LLM生成模块的语法正确性和临床准确性来修改模块。

Result: LLMs在此背景下显示出潜力，但存在挑战和局限性，例如需要人工监督、严格的测试和验证，以及LLM生成内容可能不准确。

Conclusion: LLM辅助合成数据创建潜力巨大，但需要未来的研究和开发来充分实现其潜力。

Abstract: This paper explores the use of large language models (LLMs) to assist in the
development of new disease modules for Synthea, an open-source synthetic health
data generator. Incorporating LLMs into the module development process has the
potential to reduce development time, reduce required expertise, expand model
diversity, and improve the overall quality of synthetic patient data. We
demonstrate four ways that LLMs can support Synthea module creation: generating
a disease profile, generating a disease module from a disease profile,
evaluating an existing Synthea module, and refining an existing module. We
introduce the concept of progressive refinement, which involves iteratively
evaluating the LLM-generated module by checking its syntactic correctness and
clinical accuracy, and then using that information to modify the module. While
the use of LLMs in this context shows promise, we also acknowledge the
challenges and limitations, such as the need for human oversight, the
importance of rigorous testing and validation, and the potential for
inaccuracies in LLM-generated content. The paper concludes with recommendations
for future research and development to fully realize the potential of LLM-aided
synthetic data creation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students](https://arxiv.org/abs/2507.21109)
*Prital Bamnodkar*

Main category: cs.LG

TL;DR: 本文提出TFC-SR，一种受人类学习策略启发的持续学习方法，通过引入“主动回忆探针”来稳定过往知识，有效缓解深度神经网络的灾难性遗忘问题，并取得了显著优于现有基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在学习新任务时，往往会遭遇“灾难性遗忘”，导致对过去任务的性能显著下降。

Method: 研究者提出一种名为“Task Focused Consolidation with Spaced Recall (TFC-SR)”的新型持续学习方法。该方法受人类主动回忆、刻意练习和间隔重复等学习策略启发，通过引入“主动回忆探针”（Active Recall Probe）来增强标准经验回放机制。此探针能周期性地、任务感知地评估模型记忆，从而稳定过往知识的表示。

Result: TFC-SR在Split MNIST和Split CIFAR-100基准测试中，表现显著优于主流的基于正则化和基于回放的基线方法。例如，在Split CIFAR-100上，其最终准确率达到13.17%，远高于标准回放的7.40%。研究表明，这种优势源于探针本身的稳定作用，而非回放量的差异。此外，TFC-SR在内存受限环境下表现更佳，但在内存充足时，更大的回放量仍更有效。

Conclusion: TFC-SR是一种鲁棒且高效的持续学习方法，凸显了将主动记忆检索机制整合到持续学习系统中的重要性。

Abstract: Deep Neural Networks often suffer from a critical limitation known as
Catastrophic Forgetting, where performance on past tasks degrades after
learning new ones. This paper introduces a novel continual learning approach
inspired by human learning strategies like Active Recall, Deliberate Practice
and Spaced Repetition, named Task Focused Consolidation with Spaced Recall
(TFC-SR). TFC-SR enhances the standard experience replay with a mechanism we
termed the Active Recall Probe. It is a periodic, task-aware evaluation of the
model's memory that stabilizes the representations of past knowledge. We test
TFC-SR on the Split MNIST and Split CIFAR-100 benchmarks against leading
regularization-based and replay-based baselines. Our results show that TFC-SR
performs significantly better than these methods. For instance, on the Split
CIFAR-100, it achieves a final accuracy of 13.17% compared to standard replay's
7.40%. We demonstrate that this advantage comes from the stabilizing effect of
the probe itself, and not from the difference in replay volume. Additionally,
we analyze the trade-off between memory size and performance and show that
while TFC-SR performs better in memory-constrained environments, higher replay
volume is still more effective when available memory is abundant. We conclude
that TFC-SR is a robust and efficient approach, highlighting the importance of
integrating active memory retrieval mechanisms into continual learning systems.

</details>


### [13] [Pre-, In-, and Post-Processing Class Imbalance Mitigation Techniques for Failure Detection in Optical Networks](https://arxiv.org/abs/2507.21119)
*Yousuf Moiz Ali,Jaroslaw E. Prilepsky,Nicola Sambo,João Pedro,Mohammad M. Hosseini,Antonio Napoli,Sergei K. Turitsyn,Pedro Freire*

Main category: cs.LG

TL;DR: 比较了光网络故障检测中处理类不平衡的预处理、内部处理和后处理技术。


<details>
  <summary>Details</summary>
Motivation: 旨在解决光网络故障检测中的类不平衡问题，以提升检测性能。

Method: 对多种预处理、内部处理和后处理技术进行了比较分析。

Result: 阈值调整实现了最高的F1增益（15.3%），而随机欠采样（RUS）提供了最快的推理速度。

Conclusion: 研究揭示了处理光网络故障检测中类不平衡时，性能与复杂性之间存在关键的权衡。

Abstract: We compare pre-, in-, and post-processing techniques for class imbalance
mitigation in optical network failure detection. Threshold Adjustment achieves
the highest F1 gain (15.3%), while Random Under-sampling (RUS) offers the
fastest inference, highlighting a key performance-complexity trade-off.

</details>


### [14] [Quantum Geometry of Data](https://arxiv.org/abs/2507.21135)
*Alexander G. Abanov,Luca Candelori,Harold C. Steinacker,Martin T. Wells,Jerome R. Busemeyer,Cameron J. Hogan,Vahagn Kirakosyan,Nicola Marzari,Sunil Pinnamaneni,Dario Villani,Mengjia Xu,Kharen Musaelian*

Main category: cs.LG

TL;DR: 量子认知机器学习（QCML）将数据编码为量子几何，揭示其内在结构并避免维度灾难，对认知研究有潜在价值。


<details>
  <summary>Details</summary>
Motivation: 旨在在量子认知框架内，通过展示QCML如何将数据编码为量子几何，从而推进对认知现象的理解。

Method: 开发了量子认知机器学习（QCML）模型，其中数据特征由学习的厄米矩阵表示，数据点映射到希尔伯特空间状态。通过合成和真实世界示例进行了验证。

Result: QCML成功将数据编码为量子几何，从中导出了内在维度、量子度量和贝里曲率等丰富的几何和拓扑结构。该方法能捕获数据的全局属性，并有效避免局部方法中固有的维度灾难。

Conclusion: QCML的量子几何表示有望在量子认知框架内，加深我们对认知现象的理解。

Abstract: We demonstrate how Quantum Cognition Machine Learning (QCML) encodes data as
quantum geometry. In QCML, features of the data are represented by learned
Hermitian matrices, and data points are mapped to states in Hilbert space. The
quantum geometry description endows the dataset with rich geometric and
topological structure - including intrinsic dimension, quantum metric, and
Berry curvature - derived directly from the data. QCML captures global
properties of data, while avoiding the curse of dimensionality inherent in
local methods. We illustrate this on a number of synthetic and real-world
examples. Quantum geometric representation of QCML could advance our
understanding of cognitive phenomena within the framework of quantum cognition.

</details>


### [15] [A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning](https://arxiv.org/abs/2507.21136)
*Mojtaba Moattari*

Main category: cs.LG

TL;DR: 论文提出新的独立性判据，并基于它们设计了优于现有基线的无监督和有监督降维方法，显著提升了可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在捕获数据非线性时，难以确保所选非线性最大化数据变异性和多样性，这促使研究者寻求更好的独立性判据来设计学习器。

Method: 研究审查了所有独立性判据，提出了三种新的独立性判据，并利用它们设计了无监督和有监督的降维方法。这些方法在线性和神经网络非线性环境中，对对比度、准确性和可解释性进行了评估。

Result: 结果显示，所提出的方法在性能上超越了包括tSNE、PCA、正则化LDA和VAE变体在内的多种基线方法，并在可解释性方面取得了突破。

Conclusion: 该研究为可解释机器学习领域开辟了新的研究方向，为研究人员提供了设计更有效、更具可解释性模型的新途径。

Abstract: Unsupervised and supervised learning methods conventionally use kernels to
capture nonlinearities inherent in data structure. However experts have to
ensure their proposed nonlinearity maximizes variability and capture inherent
diversity of data. We reviewed all independence criteria to design unsupervised
learners. Then we proposed 3 independence criteria and used them to design
unsupervised and supervised dimensionality reduction methods. We evaluated
contrast, accuracy and interpretability of these methods in both linear and
neural nonlinear settings. The results show that the methods have outperformed
the baseline (tSNE, PCA, regularized LDA, VAE with (un)supervised learner and
layer sharing) and opened a new line of interpretable machine learning (ML) for
the researchers.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [16] [Load Balancing for AI Training Workloads](https://arxiv.org/abs/2507.21372)
*Sarah McClure,Sylvia Ratnasamy,Scott Shenker*

Main category: cs.NI

TL;DR: 研究专用基础设施上大规模AI训练负载的负载均衡算法性能，并探讨拥塞控制与丢包恢复算法的适宜选择。


<details>
  <summary>Details</summary>
Motivation: 了解和优化在专用基础设施上运行的大规模AI训练工作负载的负载均衡性能，同时为相关的拥塞控制和丢包恢复算法设计提供选择依据。

Method: 通过评估各种负载均衡算法的性能来调查其表现，并分析拥塞控制和丢包恢复算法对性能的影响。

Result: 抽象中未直接给出具体研究结果，仅说明研究旨在揭示性能表现并提供设计选择的洞察。

Conclusion: 抽象中未直接给出明确结论，但研究目标是为大规模AI训练环境中的负载均衡、拥塞控制和丢包恢复算法的选择提供指导。

Abstract: We investigate the performance of various load balancing algorithms for
large-scale AI training workloads that are running on dedicated infrastructure.
The performance of load balancing depends on both the congestion control and
loss recovery algorithms, so our evaluation also sheds light on the appropriate
choices for those designs as well.

</details>


### [17] [Deep Reinforcement Learning-based Cell DTX/DRX Configuration for Network Energy Saving](https://arxiv.org/abs/2507.21385)
*Wei Mao,Lili Wei,Omid Semiari,Shu-ping Yeh,Hosein Nikopour*

Main category: cs.NI

TL;DR: 本文提出一种基于深度强化学习（DRL）的智能体，通过DQN在上下文强盗模型上运行，并优化奖励函数，以在5G蜂窝DTX/DRX中平衡节能与数据延迟。仿真结果表明，该方法在保持低QoS下降的同时，可实现高达45%的节能。


<details>
  <summary>Details</summary>
Motivation: 3GPP Release 18蜂窝DTX/DRX是5G重要的网络节能特性，通过周期性聚合数据实现静默期以开启高级睡眠模式。然而，静默期不可避免地增加了数据包延迟。研究动机在于，如何在不同的网络和流量条件下，为延迟敏感型业务最优配置DTX/DRX，以在最小化服务质量（QoS）下降的同时，最大化能量节省。

Method: 本研究采用深度强化学习（DRL）框架来训练一个AI智能体。具体方法包括：1) 学习算法设计为在上下文强盗（Contextual Bandit, CB）模型上实现的深度Q网络（Deep Q-network, DQN）；2) 奖励函数利用理论最优但非连续奖励函数的平滑近似。这些设计旨在使AI智能体能够始终选择任何网络和流量条件下的最佳Cell DTX/DRX配置。

Result: 仿真结果表明，与不使用Cell DTX/DRX的情况相比，本文提出的AI智能体能够实现高达约45%的能量节省（取决于流量负载场景），同时始终将服务质量（QoS）的下降控制在不超过约1%的范围内。

Conclusion: 本研究成功地通过深度强化学习框架解决了5G蜂窝DTX/DRX的配置优化问题，有效平衡了能量节省与数据包延迟。所训练的AI智能体能够在各种网络和流量条件下，在保持极低QoS下降的同时实现显著的能量效率提升。

Abstract: 3GPP Release 18 cell discontinuous transmission and reception (cell DTX/DRX)
is an important new network energy saving feature for 5G. As a time-domain
technique, it periodically aggregates the user data transmissions in a given
duration of time when the traffic load is not heavy, so that the remaining time
can be kept silent and advanced sleep modes (ASM) can be enabled to shut down
more radio components and save more energy for the cell. However, inevitably
the packet delay is increased, as during the silent period no transmission is
allowed. In this paper we study how to configure cell DTX/DRX to optimally
balance energy saving and packet delay, so that for delay-sensitive traffic
maximum energy saving can be achieved while the degradation of quality of
service (QoS) is minimized. As the optimal configuration can be different for
different network and traffic conditions, the problem is complex and we resort
to deep reinforcement learning (DRL) framework to train an AI agent to solve
it. Through careful design of 1) the learning algorithm, which implements a
deep Q-network (DQN) on a contextual bandit (CB) model, and 2) the reward
function, which utilizes a smooth approximation of a theoretically optimal but
discontinuous reward function, we are able to train an AI agent that always
tries to select the best possible Cell DTX/DRX configuration under any network
and traffic conditions. Simulation results show that compared to the case when
cell DTX/DRX is not used, our agent can achieve up to ~45% energy saving
depending on the traffic load scenario, while always maintaining no more than
~1% QoS degradation.

</details>


### [18] [Generalized few-shot transfer learning architecture for modeling the EDFA gain spectrum](https://arxiv.org/abs/2507.21728)
*Agastya Raj,Zehao Wang,Tingjun Chen,Daniel C Kilper,Marco Ruffini*

Main category: cs.NI

TL;DR: 提出一种基于半监督自归一化神经网络（SS-NN）的广义少样本迁移学习架构，利用EDFA内部特征预测其增益谱，显著减少测量需求并提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 精确建模掺铒光纤放大器（EDFA）的增益谱对于优化光网络性能至关重要，尤其是在光网络向多厂商解决方案演进的背景下。

Method: 本研究提出了一种基于半监督自归一化神经网络（SS-NN）的广义少样本迁移学习架构，该架构利用EDFA内部特征（如VOA输入/输出功率和衰减）来改进增益谱预测。SS-NN模型采用两阶段训练策略：无监督噪声增强预训练和带自定义加权MSE损失的监督微调。此外，框架通过迁移学习（TL）技术扩展，支持同构和异构模型在不同类型EDFA（如增益放大器、前置放大器和线路放大器）间的适应。为解决异构迁移学习中的特征不匹配问题，引入协方差匹配损失来对齐源域和目标域的二阶特征统计。

Result: 在COSMOS和Open Ireland测试平台上的26个EDFA上进行的大量实验表明，所提出的方法显著减少了系统所需的测量数量，并且与基准方法相比，实现了更低的平均绝对误差和改进的误差分布。

Conclusion: 所提出的基于SS-NN的迁移学习方法能够有效且高效地预测EDFA增益谱，显著降低了数据测量需求，并提高了预测准确性，对于优化光网络性能具有重要意义。

Abstract: Accurate modeling of the gain spectrum in Erbium-Doped Fiber Amplifiers
(EDFAs) is essential for optimizing optical network performance, particularly
as networks evolve toward multi-vendor solutions. In this work, we propose a
generalized few-shot transfer learning architecture based on a Semi-Supervised
Self-Normalizing Neural Network (SS-NN) that leverages internal EDFA features -
such as VOA input or output power and attenuation, to improve gain spectrum
prediction. Our SS-NN model employs a two-phase training strategy comprising
unsupervised pre-training with noise-augmented measurements and supervised
fine-tuning with a custom weighted MSE loss. Furthermore, we extend the
framework with transfer learning (TL) techniques that enable both homogeneous
(same-feature space) and heterogeneous (different-feature sets) model
adaptation across booster, preamplifier, and ILA EDFAs. To address feature
mismatches in heterogeneous TL, we incorporate a covariance matching loss to
align second-order feature statistics between source and target domains.
Extensive experiments conducted across 26 EDFAs in the COSMOS and Open Ireland
testbeds demonstrate that the proposed approach significantly reduces the
number of measurements requirements on the system while achieving lower mean
absolute errors and improved error distributions compared to benchmark methods.

</details>


### [19] [RRTO: A High-Performance Transparent Offloading System for Model Inference in Mobile Edge Computing](https://arxiv.org/abs/2507.21739)
*Zekai Sun,Xiuxian Guan,Zheng Lin,Yuhao Qing,Haoze Song,Zihan Fang,Zhe Chen,Fangming Liu,Heming Cui,Wei Ni,Jun Luo*

Main category: cs.NI

TL;DR: 提出RRTO，一种高性能透明卸载系统，通过记录/回放机制消除重复RPCs，显著降低移动设备ML推理的延迟和能耗，同时无需修改源码。


<details>
  <summary>Details</summary>
Motivation: 在资源受限移动设备上部署ML应用面临计算资源和兼容性挑战。MEC卸载存在两类方法：非透明方法性能高但需修改源码，兼容性差；透明方法兼容性好但因每次操作符RPC导致传输延迟大。本研究旨在解决透明卸载的传输延迟问题，同时保持其兼容性优势。

Method: 提出RRTO系统，引入记录/回放机制，利用ML模型中静态操作符序列来消除重复的RPCs。为可靠识别此序列，RRTO集成了新颖的操作符序列搜索算法，该算法能检测重复模式、过滤初始化噪声并通过双层策略加速匹配。

Result: 评估表明，与现有最先进的透明方法相比，RRTO将每次推理的延迟和能耗均大幅降低高达98%。其性能可与非透明方法媲美，且无需任何源代码修改。

Conclusion: RRTO在不牺牲兼容性的前提下，成功解决了移动边缘计算中ML推理透明卸载的性能瓶颈，显著提升了推理速度和能效，为移动设备上ML应用部署提供了有效解决方案。

Abstract: Deploying Machine Learning (ML) applications on resource-constrained mobile
devices remains challenging due to limited computational resources and poor
platform compatibility. While Mobile Edge Computing (MEC) offers
offloading-based inference paradigm using GPU servers, existing approaches are
divided into non-transparent and transparent methods, with the latter
necessitating modifications to the source code. Non-transparent offloading
achieves high performance but requires intrusive code modification, limiting
compatibility with diverse applications. Transparent offloading, in contrast,
offers wide compatibility but introduces significant transmission delays due to
per-operator remote procedure calls (RPCs). To overcome this limitation, we
propose RRTO, the first high-performance transparent offloading system tailored
for MEC inference. RRTO introduces a record/replay mechanism that leverages the
static operator sequence in ML models to eliminate repetitive RPCs. To reliably
identify this sequence, RRTO integrates a novel Operator Sequence Search
algorithm that detects repeated patterns, filters initialization noise, and
accelerates matching via a two-level strategy. Evaluation demonstrates that
RRTO achieves substantial reductions of up to 98% in both per-inference latency
and energy consumption compared to state-of-the-art transparent methods and
yields results comparable to non-transparent approaches, all without
necessitating any source code modification.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [20] [Not Here, Go There: Analyzing Redirection Patterns on the Web](https://arxiv.org/abs/2507.22019)
*Kritika Garg,Sawood Alam,Dietrich Ayala,Michele C. Weigle,Michael L. Nelson*

Main category: cs.DL

TL;DR: 本研究分析了1100万URI重定向数据，揭示了重定向的成功率、错误率、常见类型（规范与非规范）、特殊模式（如“汇聚URI”）及自定义404页面的普遍性，强调了重定向在网络管理中的关键作用及所面临的挑战。


<details>
  <summary>Details</summary>
Motivation: URI重定向虽对网络管理至关重要（如结构调整、SEO、安全），但其复杂性也带来了可用性、SEO表现和数字保存方面的挑战。本研究旨在深入理解重定向实践的模式和影响。

Method: 对1100万个独立重定向URI进行了分析，每个URI最多跟踪10跳重定向。

Result: ['50%的URI重定向成功，50%导致错误（其中0.06%超过10跳）。', '规范重定向（如HTTP到HTTPS）普遍存在，非规范重定向（如域名/路径变更）揭示了大规模迁移和潜在安全风险。', '发现“汇聚URI”模式，即多个重定向汇聚到同一目标。', '识别出62,000个自定义404 URI，近半数为软404，可能损害SEO和用户体验。']

Conclusion: URI重定向对网络塑造至关重要，但面临过期URI、服务器不稳定和错误处理等挑战。本研究的深入分析有助于网络管理员、研究人员和数字档案员改进网络可用性、优化资源并保护在线内容。

Abstract: URI redirections are integral to web management, supporting structural
changes, SEO optimization, and security. However, their complexities affect
usability, SEO performance, and digital preservation. This study analyzed 11
million unique redirecting URIs, following redirections up to 10 hops per URI,
to uncover patterns and implications of redirection practices. Our findings
revealed that 50% of the URIs terminated successfully, while 50% resulted in
errors, including 0.06% exceeding 10 hops. Canonical redirects, such as HTTP to
HTTPS transitions, were prevalent, reflecting adherence to SEO best practices.
Non-canonical redirects, often involving domain or path changes, highlighted
significant web migrations, rebranding, and security risks. Notable patterns
included "sink" URIs, where multiple redirects converged, ranging from traffic
consolidation by global websites to deliberate "Rickrolling." The study also
identified 62,000 custom 404 URIs, almost half being soft 404s, which could
compromise SEO and user experience. These findings underscore the critical role
of URI redirects in shaping the web while exposing challenges such as outdated
URIs, server instability, and improper error handling. This research offers a
detailed analysis of URI redirection practices, providing insights into their
prevalence, types, and outcomes. By examining a large dataset, we highlight
inefficiencies in redirection chains and examine patterns such as the use of
"sink" URIs and custom error pages. This information can help webmasters,
researchers, and digital archivists improve web usability, optimize resource
allocation, and safeguard valuable online content.

</details>
