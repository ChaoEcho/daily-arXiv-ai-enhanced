<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 49]
- [cs.CV](#cs.CV) [Total: 79]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.LG](#cs.LG) [Total: 61]
- [cs.NI](#cs.NI) [Total: 5]
- [stat.AP](#stat.AP) [Total: 1]
- [hep-ph](#hep-ph) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.RO](#cs.RO) [Total: 9]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.CR](#cs.CR) [Total: 4]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [eess.IV](#eess.IV) [Total: 13]
- [eess.SY](#eess.SY) [Total: 2]
- [stat.ML](#stat.ML) [Total: 6]
- [math.DS](#math.DS) [Total: 2]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.NE](#cs.NE) [Total: 1]
- [quant-ph](#quant-ph) [Total: 5]
- [stat.ME](#stat.ME) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [eess.SP](#eess.SP) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks](https://arxiv.org/abs/2505.04628)
*Yusen Wu,Junwu Xiong,Xiaotie Deng*

Main category: cs.CL

TL;DR: 本文提出HSII基准和框架，用于评估大型语言模型在多用户、多轮社交任务中的社交能力。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统性评估大型语言模型在复杂多用户社交场景中独立扮演角色能力的基准。

Method: 1. 提出基于社会学原理的智能体任务分级框架。 2. 设计HSII基准，包含格式解析、目标选择、目标切换对话和稳定对话四个阶段。 3. 构建从新闻数据衍生的HSII-Dataset数据集。 4. 对数据集进行聚类消融研究。 5. 研究思维链(COT)方法对社交性能的影响，并引入COT-complexity指标评估效率。

Result: 实验结果表明，HSII基准能够很好地评估大型语言模型的社交技能。

Conclusion: HSII基准适用于评估大型语言模型在复杂社交互动场景中的社交能力和任务完成能力。

Abstract: Expanding the application of large language models (LLMs) to societal life,
instead of primary function only as auxiliary assistants to communicate with
only one person at a time, necessitates LLMs' capabilities to independently
play roles in multi-user, multi-turn social agent tasks within complex social
settings. However, currently the capability has not been systematically
measured with available benchmarks. To address this gap, we first introduce an
agent task leveling framework grounded in sociological principles.
Concurrently, we propose a novel benchmark, How Social Is It (we call it HSII
below), designed to assess LLM's social capabilities in comprehensive social
agents tasks and benchmark representative models. HSII comprises four stages:
format parsing, target selection, target switching conversation, and stable
conversation, which collectively evaluate the communication and task completion
capabilities of LLMs within realistic social interaction scenarios dataset,
HSII-Dataset. The dataset is derived step by step from news dataset. We perform
an ablation study by doing clustering to the dataset. Additionally, we
investigate the impact of chain of thought (COT) method on enhancing LLMs'
social performance. Since COT cost more computation, we further introduce a new
statistical metric, COT-complexity, to quantify the efficiency of certain LLMs
with COTs for specific social tasks and strike a better trade-off between
measurement of correctness and efficiency. Various results of our experiments
demonstrate that our benchmark is well-suited for evaluating social skills in
LLMs.

</details>


### [2] [Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs](https://arxiv.org/abs/2505.04637)
*Dongxing Yu*

Main category: cs.CL

TL;DR: 提出了一种受人类认知启发的动态跨模态分词框架，以改进多模态大语言模型（MLLMs）的信息整合能力，并在基准测试中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在信息整合方式上与人类认知过程存在显著差异，尤其是传统的静态分词方法限制了模型模拟人类动态、上下文敏感信息处理的能力。

Method: 通过实证研究比较人类在视觉语言任务中的表现与模型行为，并基于此提出了一种新颖的动态跨模态分词框架。该框架融合了自适应边界、层次化表示以及基于认知科学原理的对齐机制。

Result: 提出的方法在视觉问答（VQA）任务上性能提升7.8%，在复杂场景描述任务上提升5.3%，并且模型表现出更接近人类的错误模式和注意力分布。

Conclusion: 该研究不仅加深了对人类认知与人工智能关系的理论理解，也为开发更具认知合理性的人工智能系统提供了实证依据，证明了动态跨模态分词框架的有效性。

Abstract: Recent advancements in multimodal large language models (MLLMs) have
demonstrated remarkable capabilities in processing diverse data types, yet
significant disparities persist between human cognitive processes and
computational approaches to multimodal information integration. This research
presents a systematic investigation into the parallels between human
cross-modal chunking mechanisms and token representation methodologies in
MLLMs. Through empirical studies comparing human performance patterns with
model behaviors across visual-linguistic tasks, we demonstrate that
conventional static tokenization schemes fundamentally constrain current
models' capacity to simulate the dynamic, context-sensitive nature of human
information processing. We propose a novel framework for dynamic cross-modal
tokenization that incorporates adaptive boundaries, hierarchical
representations, and alignment mechanisms grounded in cognitive science
principles. Quantitative evaluations demonstrate that our approach yields
statistically significant improvements over state-of-the-art models on
benchmark tasks (+7.8% on Visual Question Answering, +5.3% on Complex Scene
Description) while exhibiting more human-aligned error patterns and attention
distributions. These findings contribute to the theoretical understanding of
the relationship between human cognition and artificial intelligence, while
providing empirical evidence for developing more cognitively plausible AI
systems.

</details>


### [3] [Language translation, and change of accent for speech-to-speech task using diffusion model](https://arxiv.org/abs/2505.04639)
*Abhishek Mishra,Ritesh Sur Chowdhury,Vartul Bahuguna,Isha Pandey,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 提出了一种基于扩散模型的统一方法，用于同时实现语音翻译和口音转换。


<details>
  <summary>Details</summary>
Motivation: 当前的语音到语音翻译 (S2ST) 通常分别处理语言翻译或口音适应，而有效的跨文化交流需要同时兼顾这两个方面。现有文献对同步实现语音翻译和口音转换的研究不足。

Method: 将问题重新定义为一个条件生成任务。利用扩散模型的能力，借鉴文本到图像的扩散策略，通过对源语音转录进行条件化，生成代表目标语音（具有期望的语言和口音属性）的梅尔频谱图。

Result: 该集成框架能够联合优化翻译和口音适应，与传统流水线方法相比，提供了一个参数效率更高、效果更好的模型。

Conclusion: 本研究提出的统一方法能够有效地同时进行语音翻译和口音转换，为实现更自然的跨语言语音交流提供了一种参数更少、效果更好的新途径。

Abstract: Speech-to-speech translation (S2ST) aims to convert spoken input in one
language to spoken output in another, typically focusing on either language
translation or accent adaptation. However, effective cross-cultural
communication requires handling both aspects simultaneously - translating
content while adapting the speaker's accent to match the target language
context. In this work, we propose a unified approach for simultaneous speech
translation and change of accent, a task that remains underexplored in current
literature. Our method reformulates the problem as a conditional generation
task, where target speech is generated based on phonemes and guided by target
speech features. Leveraging the power of diffusion models, known for
high-fidelity generative capabilities, we adapt text-to-image diffusion
strategies by conditioning on source speech transcriptions and generating Mel
spectrograms representing the target speech with desired linguistic and
accentual attributes. This integrated framework enables joint optimization of
translation and accent adaptation, offering a more parameter-efficient and
effective model compared to traditional pipelines.

</details>


### [4] [A Comparative Benchmark of a Moroccan Darija Toxicity Detection Model (Typica.ai) and Major LLM-Based Moderation APIs (OpenAI, Mistral, Anthropic)](https://arxiv.org/abs/2505.04640)
*Hicham Assoudi*

Main category: cs.CL

TL;DR: 本文对比了Typica.ai定制的摩洛哥阿拉伯语（Darija）毒性检测模型与主流LLM审核API（OpenAI, Mistral, Anthropic）的性能，结果显示Typica.ai模型在处理具有文化背景的有害内容方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 通用审核系统往往忽视代表性不足语言中具有文化背景的有害内容，如含蓄侮辱、讽刺和特定文化背景的攻击性言论，因此需要专门针对这些语言和文化特点的审核模型。

Method: 研究使用了一个源自OMCD_Typica.ai_Mix数据集的平衡测试集，对Typica.ai的模型以及OpenAI、Mistral和Anthropic Claude的最新审核API进行了性能评估，比较了它们的精确率、召回率、F1分数和准确率。

Result: Typica.ai的定制模型在检测摩洛哥阿拉伯语中具有文化背景的有害内容方面，表现优于主要的LLM审核API。

Conclusion: 对于代表性不足的语言，开发适应特定文化的模型对于实现可靠的内容审核至关重要，这揭示了在该领域面临的挑战和机遇。

Abstract: This paper presents a comparative benchmark evaluating the performance of
Typica.ai's custom Moroccan Darija toxicity detection model against major
LLM-based moderation APIs: OpenAI (omni-moderation-latest), Mistral
(mistral-moderation-latest), and Anthropic Claude (claude-3-haiku-20240307). We
focus on culturally grounded toxic content, including implicit insults,
sarcasm, and culturally specific aggression often overlooked by general-purpose
systems. Using a balanced test set derived from the OMCD_Typica.ai_Mix dataset,
we report precision, recall, F1-score, and accuracy, offering insights into
challenges and opportunities for moderation in underrepresented languages. Our
results highlight Typica.ai's superior performance, underlining the importance
of culturally adapted models for reliable content moderation.

</details>


### [5] [Rethinking Multimodal Sentiment Analysis: A High-Accuracy, Simplified Fusion Architecture](https://arxiv.org/abs/2505.04642)
*Nischal Mandal,Yang Li*

Main category: cs.CL

TL;DR: 提出了一种轻量级融合深度学习模型，用于话语级多模态情感分类，在IEMOCAP数据集上取得了92%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态情感分析方法多采用复杂的注意力机制和层级架构，计算开销较大。本研究旨在开发一种轻量级且高效的模型。

Method: 1. 使用全连接层和dropout正则化为文本、音频、视觉每种模态设计特定编码器。 2. 通过简单拼接融合各模态的表征。 3. 将拼接后的表征传入一个密集融合层以捕捉跨模态交互。

Result: 在IEMOCAP基准数据集上，该模型对六种情感类别的分类准确率达到了92%。

Conclusion: 研究表明，通过精心的特征工程和模块化设计，简单的融合策略在性能上可以媲美甚至超越更复杂的模型，尤其适用于资源受限的环境。

Abstract: Multimodal sentiment analysis, a pivotal task in affective computing, seeks
to understand human emotions by integrating cues from language, audio, and
visual signals. While many recent approaches leverage complex attention
mechanisms and hierarchical architectures, we propose a lightweight, yet
effective fusion-based deep learning model tailored for utterance-level emotion
classification. Using the benchmark IEMOCAP dataset, which includes aligned
text, audio-derived numeric features, and visual descriptors, we design a
modality-specific encoder using fully connected layers followed by dropout
regularization. The modality-specific representations are then fused using
simple concatenation and passed through a dense fusion layer to capture
cross-modal interactions. This streamlined architecture avoids computational
overhead while preserving performance, achieving a classification accuracy of
92% across six emotion categories. Our approach demonstrates that with careful
feature engineering and modular design, simpler fusion strategies can
outperform or match more complex models, particularly in resource-constrained
environments.

</details>


### [6] [Prediction-powered estimators for finite population statistics in highly imbalanced textual data: Public hate crime estimation](https://arxiv.org/abs/2505.04643)
*Hannes Waldetoft,Jakob Torgander,Måns Magnusson*

Main category: cs.CL

TL;DR: 本文提出一种结合Transformer模型预测和调查抽样估计器的方法，以有效估计文本数据中的总体参数，并减少人工标注工作。


<details>
  <summary>Details</summary>
Motivation: 在文本文件中，当目标变量的标签需要人工标注时，估计总体参数具有挑战性且成本高昂。

Method: 将Transformer编码器神经网络的预测结果作为辅助变量，与成熟的调查抽样估计器（Hansen-Hurwitz估计器、差异估计和分层随机抽样估计）相结合。

Result: 该方法在瑞典仇恨犯罪统计中的应用表明，可以有效估计年度仇恨犯罪数量和警方的漏报情况。

Conclusion: 若有可用的带标签训练数据，所提出的方法能够提供非常有效的估计，并减少人工标注所需的时间。

Abstract: Estimating population parameters in finite populations of text documents can
be challenging when obtaining the labels for the target variable requires
manual annotation. To address this problem, we combine predictions from a
transformer encoder neural network with well-established survey sampling
estimators using the model predictions as an auxiliary variable. The
applicability is demonstrated in Swedish hate crime statistics based on Swedish
police reports. Estimates of the yearly number of hate crimes and the police's
under-reporting are derived using the Hansen-Hurwitz estimator, difference
estimation, and stratified random sampling estimation. We conclude that if
labeled training data is available, the proposed method can provide very
efficient estimates with reduced time spent on manual annotation.

</details>


### [7] [ChatGPT for automated grading of short answer questions in mechanical ventilation](https://arxiv.org/abs/2505.04645)
*Tejas Jade,Alex Yartsev*

Main category: cs.CL

TL;DR: 研究评估了ChatGPT 4o在研究生医学简答题评分中的表现，发现其评分系统性偏低，与人类评分员一致性差，尤其在评估性和分析性题目上，因此不建议将其用于高风险评估。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在自动化评分方面展现出潜力，本研究旨在评估ChatGPT 4o在研究生医学教育中对简答题进行自动评分的有效性和可靠性。

Method: 研究选取了215名学生关于机械通气课程的557份简答题答案，让ChatGPT 4o根据标准化评分提示和评分标准进行评分。随后，通过多种统计方法（混合效应模型、ICC、Cohen's kappa等）分析其评分结果与人类评分员的一致性。

Result: ChatGPT 4o的评分系统性低于人类评分员（平均差异-1.34分，满分10分）。个体层面的一致性极差（ICC1 = 0.086, Cohen's kappa = -0.0786），表明与人类评分员几乎无有意义的一致性。尽管ChatGPT自身评分具有内部一致性，但与人类评分员存在显著分歧，尤其在评估性和分析性题目上。超过60%的ChatGPT评分与人类评分的差异超出了高风险评估的可接受范围。

Conclusion: 鉴于ChatGPT 4o评分与人类评分员之间存在显著差异且一致性较低，目前不建议在高风险的研究生课程作业评估中使用大型语言模型进行评分。

Abstract: Standardised tests using short answer questions (SAQs) are common in
postgraduate education. Large language models (LLMs) simulate conversational
language and interpret unstructured free-text responses in ways aligning with
applying SAQ grading rubrics, making them attractive for automated grading. We
evaluated ChatGPT 4o to grade SAQs in a postgraduate medical setting using data
from 215 students (557 short-answer responses) enrolled in an online course on
mechanical ventilation (2020--2024). Deidentified responses to three case-based
scenarios were presented to ChatGPT with a standardised grading prompt and
rubric. Outputs were analysed using mixed-effects modelling, variance component
analysis, intraclass correlation coefficients (ICCs), Cohen's kappa, Kendall's
W, and Bland--Altman statistics. ChatGPT awarded systematically lower marks
than human graders with a mean difference (bias) of -1.34 on a 10-point scale.
ICC values indicated poor individual-level agreement (ICC1 = 0.086), and
Cohen's kappa (-0.0786) suggested no meaningful agreement. Variance component
analysis showed minimal variability among the five ChatGPT sessions (G-value =
0.87), indicating internal consistency but divergence from the human grader.
The poorest agreement was observed for evaluative and analytic items, whereas
checklist and prescriptive rubric items had less disagreement. We caution
against the use of LLMs in grading postgraduate coursework. Over 60% of
ChatGPT-assigned grades differed from human grades by more than acceptable
boundaries for high-stakes assessments.

</details>


### [8] [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://arxiv.org/abs/2505.04649)
*Chengzhang Yu,Yiming Zhang,Zhixin Liu,Zenghui Ding,Yining Sun,Zhanpeng Jin*

Main category: cs.CL

TL;DR: 提出了一种名为FRAME的新框架，通过迭代优化和结构化反馈来增强医学论文的自动生成质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动化科研方面有巨大潜力，但在知识综合和质量保证方面面临关键挑战。

Method: 引入反馈精炼代理方法 (FRAME)，包含三个关键创新：(1) 结构化数据集构建方法，将医学论文分解为研究组件；(2) 集成生成器、评估器和反射器代理的三方架构，通过度量驱动反馈改进内容质量；(3) 结合统计指标和人工基准的综合评估框架。

Result: FRAME在多个模型上（如DeepSeek V3平均提升9.91%，GPT-4o Mini也有类似提升）和评估维度上均显著优于传统方法。人工评估证实FRAME生成的论文质量与人类撰写相当，尤其在综合未来研究方向方面表现出色。

Conclusion: 该研究工作能够高效辅助医学研究，为自动化医学研究论文生成奠定了坚实基础，同时保持了严格的学术标准。

Abstract: The automation of scientific research through large language models (LLMs)
presents significant opportunities but faces critical challenges in knowledge
synthesis and quality assurance. We introduce Feedback-Refined Agent
Methodology (FRAME), a novel framework that enhances medical paper generation
through iterative refinement and structured feedback. Our approach comprises
three key innovations: (1) A structured dataset construction method that
decomposes 4,287 medical papers into essential research components through
iterative refinement; (2) A tripartite architecture integrating Generator,
Evaluator, and Reflector agents that progressively improve content quality
through metric-driven feedback; and (3) A comprehensive evaluation framework
that combines statistical metrics with human-grounded benchmarks. Experimental
results demonstrate FRAME's effectiveness, achieving significant improvements
over conventional approaches across multiple models (9.91% average gain with
DeepSeek V3, comparable improvements with GPT-4o Mini) and evaluation
dimensions. Human evaluation confirms that FRAME-generated papers achieve
quality comparable to human-authored works, with particular strength in
synthesizing future research directions. The results demonstrated our work
could efficiently assist medical research by building a robust foundation for
automated medical research paper generation while maintaining rigorous academic
standards.

</details>


### [9] [Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions](https://arxiv.org/abs/2505.04651)
*Adithya Kulkarni,Fatimah Alotaibi,Xinyue Zeng,Longfeng Wu,Tong Zeng,Barry Menglong Yao,Minqian Liu,Shuaicheng Zhang,Lifu Huang,Dawei Zhou*

Main category: cs.CL

TL;DR: 本综述概述了大型语言模型 (LLM) 在科学假设生成与验证中的应用，涵盖了不同方法、技术、数据集，并展望了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 正在通过信息综合、潜在关系发现和推理增强来改变科学假设的生成与验证过程。

Method: 本研究对LLM驱动的科学假设生成与验证方法进行了结构化综述，包括符号框架、生成模型、混合系统、多智能体架构，以及检索增强生成、知识图谱补全、仿真、因果推断和工具辅助推理等技术。同时，回顾了用于验证的仿真、人机协作、因果建模和不确定性量化方法。

Result: 综述了LLM在科学发现中的应用，对比了早期符号发现系统与现代LLM流程，探讨了不同技术的权衡（可解释性、新颖性、领域对齐），并介绍了跨多个科学领域的数据集（如AHTech和CSKG-600）。

Conclusion: 论文勾勒了一个未来路线图，强调了新颖性感知生成、多模态符号集成、人在回路系统和伦理保障，将LLM定位为实现有原则、可扩展科学发现的智能体。

Abstract: Large Language Models (LLMs) are transforming scientific hypothesis
generation and validation by enabling information synthesis, latent
relationship discovery, and reasoning augmentation. This survey provides a
structured overview of LLM-driven approaches, including symbolic frameworks,
generative models, hybrid systems, and multi-agent architectures. We examine
techniques such as retrieval-augmented generation, knowledge-graph completion,
simulation, causal inference, and tool-assisted reasoning, highlighting
trade-offs in interpretability, novelty, and domain alignment. We contrast
early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM
pipelines that leverage in-context learning and domain adaptation via
fine-tuning, retrieval, and symbolic grounding. For validation, we review
simulation, human-AI collaboration, causal modeling, and uncertainty
quantification, emphasizing iterative assessment in open-world contexts. The
survey maps datasets across biomedicine, materials science, environmental
science, and social science, introducing new resources like AHTech and
CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation,
multimodal-symbolic integration, human-in-the-loop systems, and ethical
safeguards, positioning LLMs as agents for principled, scalable scientific
discovery.

</details>


### [10] [Advancing Conversational Diagnostic AI with Multimodal Reasoning](https://arxiv.org/abs/2505.04653)
*Khaled Saab,Jan Freyberg,Chunjong Park,Tim Strother,Yong Cheng,Wei-Hung Weng,David G. T. Barrett,David Stutz,Nenad Tomasev,Anil Palepu,Valentin Liévin,Yash Sharma,Roma Ruparel,Abdullah Ahmed,Elahe Vedadi,Kimberly Kanada,Cian Hughes,Yun Liu,Geoff Brown,Yang Gao,Sean Li,S. Sara Mahdavi,James Manyika,Katherine Chou,Yossi Matias,Avinatan Hassidim,Dale R. Webster,Pushmeet Kohli,S. M. Ali Eslami,Joëlle Barral,Adam Rodman,Vivek Natarajan,Mike Schaekermann,Tao Tu,Alan Karthikesalingam,Ryutaro Tanno*

Main category: cs.CL

TL;DR: 通过引入多模态数据处理能力，增强的AI系统AMIE在模拟诊断对话中表现优于初级保健医生。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在诊断对话方面的评估主要局限于文本交互，而实际远程医疗场景常涉及图像、心电图等多模态医疗数据。因此，研究旨在提升AI在对话式诊断中处理和理解多模态数据的能力。

Method: 研究通过增强Articulate Medical Intelligence Explorer (AMIE)系统，使其能够收集、解释并在咨询过程中精确推理多模态数据。该系统利用Gemini 2.0 Flash，并实现了一个状态感知的对话框架，通过模型中间输出动态控制对话流程，并根据患者状态的不确定性策略性地引导后续提问。通过与初级保健医生 (PCPs) 进行随机、盲法的OSCE式聊天咨询研究（使用患者演员和包含多模态伪像的105个评估场景）进行评估。

Result: 专家评估显示，在模拟的聊天咨询中，AMIE在7个（共9个）多模态能力评估维度和29个（共32个）非多模态能力评估维度（包括诊断准确性）上均优于初级保健医生。

Conclusion: 该研究表明多模态对话式诊断AI取得了明确进展，但在实际应用推广前仍需进一步研究。

Abstract: Large Language Models (LLMs) have demonstrated great potential for conducting
diagnostic conversations but evaluation has been largely limited to
language-only interactions, deviating from the real-world requirements of
remote care delivery. Instant messaging platforms permit clinicians and
patients to upload and discuss multimodal medical artifacts seamlessly in
medical consultation, but the ability of LLMs to reason over such data while
preserving other attributes of competent diagnostic conversation remains
unknown. Here we advance the conversational diagnosis and management
performance of the Articulate Medical Intelligence Explorer (AMIE) through a
new capability to gather and interpret multimodal data, and reason about this
precisely during consultations. Leveraging Gemini 2.0 Flash, our system
implements a state-aware dialogue framework, where conversation flow is
dynamically controlled by intermediate model outputs reflecting patient states
and evolving diagnoses. Follow-up questions are strategically directed by
uncertainty in such patient states, leading to a more structured multimodal
history-taking process that emulates experienced clinicians. We compared AMIE
to primary care physicians (PCPs) in a randomized, blinded, OSCE-style study of
chat-based consultations with patient actors. We constructed 105 evaluation
scenarios using artifacts like smartphone skin photos, ECGs, and PDFs of
clinical documents across diverse conditions and demographics. Our rubric
assessed multimodal capabilities and other clinically meaningful axes like
history-taking, diagnostic accuracy, management reasoning, communication, and
empathy. Specialist evaluation showed AMIE to be superior to PCPs on 7/9
multimodal and 29/32 non-multimodal axes (including diagnostic accuracy). The
results show clear progress in multimodal conversational diagnostic AI, but
real-world translation needs further research.

</details>


### [11] [A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient](https://arxiv.org/abs/2505.04654)
*Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: 本文比较了多种AI大语言模型（如DeepSeek-V3、GPT系列、Gemini系列）的伦理表现，强调了人类监督的重要性，并提出了一种新的LLM危害性计算指标RDC。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）和大型语言模型（LLM）的飞速发展带来了关于安全、潜在滥用、歧视及社会总体影响等关键伦理问题。

Method: 对多种AI模型（包括DeepSeek-V3、不同的GPT变体和Gemini变体）的伦理表现进行比较分析，并提出一种名为“相对危险系数”（RDC）的新型LLM危害计算指标。

Result: 分析结果强调了在AI应用中，尤其是在高风险情境下，进行强有力的人类监督的必要性。同时，研究提出了一种新的LLM危害性计算指标——相对危险系数（RDC）。

Conclusion: 面对AI和LLM带来的伦理挑战，持续的评估和强有力的人类监督至关重要，新提出的RDC指标为此类评估提供了新工具。

Abstract: Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly
evolved in recent years, showcasing remarkable capabilities in natural language
understanding and generation. However, these advancements also raise critical
ethical questions regarding safety, potential misuse, discrimination and
overall societal impact. This article provides a comparative analysis of the
ethical performance of various AI models, including the brand new
DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5
Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp)
and highlights the need for robust human oversight, especially in situations
with high stakes. Furthermore, we present a new metric for calculating harm in
LLMs called Relative Danger Coefficient (RDC).

</details>


### [12] [Integration of Large Language Models and Traditional Deep Learning for Social Determinants of Health Prediction](https://arxiv.org/abs/2505.04655)
*Paul Landes,Jimeng Sun,Adam Cross*

Main category: cs.CL

TL;DR: 本研究探索了使用传统深度学习和大型语言模型 (LLM) 从临床文本中自动提取健康社会决定因素 (SDoH) 的方法。研究提出了一种结合二者优势的混合模型，在提高分类准确率的同时，大幅提升了处理速度。


<details>
  <summary>Details</summary>
Motivation: 健康社会决定因素 (SDoH) 对个体健康有显著影响，并辅助医生诊疗。因此，自动从临床文本中高效准确地提取SDoH对改善医疗决策至关重要。

Method: 研究比较了传统深度学习模型与大型语言模型 (LLM) 在SDoH提取任务上的表现。提出了一种新方法，该方法结合了LLM的精确性与传统深度学习的高效性，旨在通过优化处理流程（如减少对昂贵LLM的依赖）来加速分类。同时，研究还在添加了合成数据的数据集上评估了多种传统深度学习模型。

Result: 新模型在多标签SDoH分类任务上的性能比现有基准提高了10个百分点。提出的方法将分类执行速度提升了12倍。研究证明，结合LLM的精确度和传统深度学习的效率是可行的。此外，在补充了合成数据的数据集上，部分传统深度学习模型的表现优于LLM。

Conclusion: 本研究提出的模型和方法为自动预测SDoH提供了更优的解决方案，通过有效结合LLM和传统深度学习的优势，实现了在临床文本SDoH提取任务中更高的准确性和效率，有望改善对高危患者的健康管理。

Abstract: Social Determinants of Health (SDoH) are economic, social and personal
circumstances that affect or influence an individual's health status. SDoHs
have shown to be correlated to wellness outcomes, and therefore, are useful to
physicians in diagnosing diseases and in decision-making. In this work, we
automatically extract SDoHs from clinical text using traditional deep learning
and Large Language Models (LLMs) to find the advantages and disadvantages of
each on an existing publicly available dataset. Our models outperform a
previous reference point on a multilabel SDoH classification by 10 points, and
we present a method and model to drastically speed up classification (12X
execution time) by eliminating expensive LLM processing. The method we present
combines a more nimble and efficient solution that leverages the power of the
LLM for precision and traditional deep learning methods for efficiency. We also
show highly performant results on a dataset supplemented with synthetic data
and several traditional deep learning models that outperform LLMs. Our models
and methods offer the next iteration of automatic prediction of SDoHs that
impact at-risk patients.

</details>


### [13] [AI-Generated Fall Data: Assessing LLMs and Diffusion Model for Wearable Fall Detection](https://arxiv.org/abs/2505.04660)
*Sana Alamgeer,Yasine Souissi,Anne H. H. Ngu*

Main category: cs.CL

TL;DR: 本研究探讨了使用大型语言模型（LLMs）生成合成跌倒数据以解决真实世界数据稀缺的问题，并评估了其对跌倒检测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界（尤其是老年人）的跌倒数据稀缺，训练有效的跌倒检测系统面临挑战。

Method: 研究评估了文本到运动（T2M, SATO, ParCo）和文本到文本（GPT4o, GPT4, Gemini）等大型语言模型生成合成跌倒数据的能力。将生成的合成数据集与四个真实世界基线数据集集成，并使用长短期记忆（LSTM）模型评估其对跌倒检测性能的影响。同时，将LLM生成的合成数据与基于扩散的方法进行了比较。

Result: 研究结果表明，数据集特性显著影响合成数据的有效性，LLM生成的数据在低频设置（如20Hz）下表现最佳，但在高频数据集（如200Hz）中表现不稳定。文本到运动模型比文本到文本模型能产生更真实的生物力学数据，但其对跌倒检测的影响各不相同。基于扩散的合成数据与真实数据最接近，但并不总能提高模型性能。消融研究进一步证实，合成数据的有效性取决于传感器位置和跌倒表示。

Conclusion: 研究结果为优化跌倒检测模型的合成数据生成提供了见解，强调了根据数据集特性选择合适的合成数据生成方法的重要性。

Abstract: Training fall detection systems is challenging due to the scarcity of
real-world fall data, particularly from elderly individuals. To address this,
we explore the potential of Large Language Models (LLMs) for generating
synthetic fall data. This study evaluates text-to-motion (T2M, SATO, ParCo) and
text-to-text models (GPT4o, GPT4, Gemini) in simulating realistic fall
scenarios. We generate synthetic datasets and integrate them with four
real-world baseline datasets to assess their impact on fall detection
performance using a Long Short-Term Memory (LSTM) model. Additionally, we
compare LLM-generated synthetic data with a diffusion-based method to evaluate
their alignment with real accelerometer distributions. Results indicate that
dataset characteristics significantly influence the effectiveness of synthetic
data, with LLM-generated data performing best in low-frequency settings (e.g.,
20Hz) while showing instability in high-frequency datasets (e.g., 200Hz). While
text-to-motion models produce more realistic biomechanical data than
text-to-text models, their impact on fall detection varies. Diffusion-based
synthetic data demonstrates the closest alignment to real data but does not
consistently enhance model performance. An ablation study further confirms that
the effectiveness of synthetic data depends on sensor placement and fall
representation. These findings provide insights into optimizing synthetic data
generation for fall detection models.

</details>


### [14] [Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising](https://arxiv.org/abs/2505.04665)
*Haoyang Feng,Yanjun Dai,Yuan Gao*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在数字广告中的个性化风险与监管策略，并构建了一个基于BERT模型的个性化广告推荐与用户风险保护算法模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在实验环境中展现了个性化广告推荐的潜力，但在实际操作中，如何结合用户隐私保护和数据安全仍是值得深入探讨的问题。

Method: 首先概述LLM原理，然后结合BERT模型和注意力机制构建个性化广告推荐与用户风险保护算法模型。具体步骤包括数据收集与预处理、特征选择与构建、使用BERT进行广告语义嵌入、基于用户画像的广告推荐，并通过本地模型训练和数据加密确保用户隐私安全。

Result: 实验结果表明，基于BERT的广告推送能有效提高广告的点击率和转化率，同时通过本地模型训练和隐私保护机制，能在一定程度上降低用户隐私泄露的风险。

Conclusion: 该研究提出的基于BERT的个性化广告推荐模型，在提升广告效果的同时，兼顾了用户隐私保护，为大型语言模型在广告领域的安全应用提供了可行方案。

Abstract: Although large language models have demonstrated the potential for
personalized advertising recommendations in experimental environments, in
actual operations, how advertising recommendation systems can be combined with
measures such as user privacy protection and data security is still an area
worthy of in-depth discussion. To this end, this paper studies the personalized
risks and regulatory strategies of large language models in digital
advertising. This study first outlines the principles of Large Language Model
(LLM), especially the self-attention mechanism based on the Transformer
architecture, and how to enable the model to understand and generate natural
language text. Then, the BERT (Bidirectional Encoder Representations from
Transformers) model and the attention mechanism are combined to construct an
algorithmic model for personalized advertising recommendations and user factor
risk protection. The specific steps include: data collection and preprocessing,
feature selection and construction, using large language models such as BERT
for advertising semantic embedding, and ad recommendations based on user
portraits. Then, local model training and data encryption are used to ensure
the security of user privacy and avoid the leakage of personal data. This paper
designs an experiment for personalized advertising recommendation based on a
large language model of BERT and verifies it with real user data. The
experimental results show that BERT-based advertising push can effectively
improve the click-through rate and conversion rate of advertisements. At the
same time, through local model training and privacy protection mechanisms, the
risk of user privacy leakage can be reduced to a certain extent.

</details>


### [15] [Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes](https://arxiv.org/abs/2505.04666)
*Mohammad Aqib,Mohd Hamza,Qipei Mei,Ying Hei Chui*

Main category: cs.CL

TL;DR: 该研究旨在通过优化检索增强生成（RAG）系统，特别是选择合适的检索器和微调语言模型，以解决查询复杂建筑规范（如加拿大国家建筑规范NBCC）的挑战。


<details>
  <summary>Details</summary>
Motivation: 建筑规范内容庞大、复杂且频繁更新，导致人工查询耗时费力，难以准确导航、理解专业术语和识别跨章节条款。

Method: 研究评估了多种针对加拿大国家建筑规范（NBCC）的检索方法，并使用从NBCC派生的数据集对几种语言模型进行了领域特定的微调，比较了不同检索器以及预训练模型与微调模型的性能。

Result: 实验结果表明，Elasticsearch是所有评估的检索方法中最稳健的。对语言模型进行NBCC特定数据集的微调，能增强其生成上下文相关响应的能力。将Elasticsearch与微调后的语言模型结合，可以优化RAG系统，使其更好地应对NBCC的复杂性。

Conclusion: 选择强大的检索器（如Elasticsearch）并结合领域特定微调的语言模型，能够显著优化RAG系统在处理复杂建筑规范查询任务中的性能和效果。

Abstract: Building codes are regulations that establish standards for the design,
construction, and safety of buildings to ensure structural integrity, fire
protection, and accessibility. They are often extensive, complex, and subject
to frequent updates, making manual querying challenging and time-consuming. Key
difficulties include navigating large volumes of text, interpreting technical
language, and identifying relevant clauses across different sections. A
potential solution is to build a Question-Answering (QA) system that answers
user queries based on building codes. Among the various methods for building a
QA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG
consists of two components: a retriever and a language model. This study
focuses on identifying a suitable retriever method for building codes and
optimizing the generational capability of the language model using fine-tuning
techniques. We conducted a detailed evaluation of various retrieval methods by
performing the retrieval on the National Building Code of Canada (NBCC) and
explored the impact of domain-specific fine-tuning on several language models
using the dataset derived from NBCC. Our analysis included a comparative
assessment of different retrievers and the performance of both pre-trained and
fine-tuned models to determine the efficacy and domain-specific adaptation of
language models using fine-tuning on the NBCC dataset. Experimental results
showed that Elasticsearch proved to be the most robust retriever among all. The
findings also indicate that fine-tuning language models on an NBCC-specific
dataset can enhance their ability to generate contextually relevant responses.
When combined with context retrieved by a powerful retriever like
Elasticsearch, this improvement in LLM performance can optimize the RAG system,
enabling it to better navigate the complexities of the NBCC.

</details>


### [16] [Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards](https://arxiv.org/abs/2505.04671)
*Yuxin Zhang,Meihao Fan,Ju Fan,Mingyang Yi,Yuyu Luo,Jian Tan,Guoliang Li*

Main category: cs.CL

TL;DR: 提出Reward-SQL框架，有效整合过程奖励模型（PRM）以提升Text-to-SQL任务的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在Text-to-SQL任务中表现出色，但引入外部过程奖励模型（PRM）进行细粒度监督时，若使用不当可能扭曲推理轨迹，导致SQL生成不佳或错误。

Method: 提出Reward-SQL框架，采用“冷启动，然后PRM监督”范式。首先训练模型使用通用表表达式链（Chain-of-CTEs）将SQL查询分解为结构化步骤，建立强大的可解释推理基线。然后，研究了四种整合PRM的策略，发现将PRM作为在线训练信号（GRPO）与PRM引导的推理（如best-of-N采样）相结合效果最佳。

Result: 在BIRD基准测试中，Reward-SQL使7B PRM监督的模型在各种指导策略下实现了13.1%的性能提升。基于Qwen2.5-Coder-7B-Instruct的GRPO对齐策略模型在BIRD开发集上达到了68.9%的准确率，优于同等模型大小的所有基线方法。

Conclusion: Reward-SQL框架能有效地利用基于奖励的监督来改进Text-to-SQL的推理过程。

Abstract: Recent advances in large language models (LLMs) have significantly improved
performance on the Text-to-SQL task by leveraging their powerful reasoning
capabilities. To enhance accuracy during the reasoning process, external
Process Reward Models (PRMs) can be introduced during training and inference to
provide fine-grained supervision. However, if misused, PRMs may distort the
reasoning trajectory and lead to suboptimal or incorrect SQL generation.To
address this challenge, we propose Reward-SQL, a framework that systematically
explores how to incorporate PRMs into the Text-to-SQL reasoning process
effectively. Our approach follows a "cold start, then PRM supervision"
paradigm. Specifically, we first train the model to decompose SQL queries into
structured stepwise reasoning chains using common table expressions
(Chain-of-CTEs), establishing a strong and interpretable reasoning baseline.
Then, we investigate four strategies for integrating PRMs, and find that
combining PRM as an online training signal (GRPO) with PRM-guided inference
(e.g., best-of-N sampling) yields the best results. Empirically, on the BIRD
benchmark, Reward-SQL enables models supervised by a 7B PRM to achieve a 13.1%
performance gain across various guidance strategies. Notably, our GRPO-aligned
policy model based on Qwen2.5-Coder-7B-Instruct achieves 68.9% accuracy on the
BIRD development set, outperforming all baseline methods under the same model
size. These results demonstrate the effectiveness of Reward-SQL in leveraging
reward-based supervision for Text-to-SQL reasoning. Our code is publicly
available.

</details>


### [17] [REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM](https://arxiv.org/abs/2505.04673)
*Madhur Jindal,Saurabh Deshpande*

Main category: cs.CL

TL;DR: 视觉大语言模型（VLLMs）在多轮对话中存在安全风险。本研究提出REVEAL框架评估这些风险，发现多轮交互比单轮交互更易产生有害内容。


<details>
  <summary>Details</summary>
Motivation: 传统的针对文本、单轮交互的安全评估框架不适用于评估视觉大语言模型（VLLMs）在多模态、多轮对话中日益增加的复杂性和新的安全伦理挑战。

Method: 引入REVEAL框架，一个可扩展的自动化流程，用于评估VLLMs的图像输入危害。该框架包括自动图像挖掘、合成对抗性数据生成、使用crescendo攻击策略的多轮对话扩展，并通过GPT-4o等评估器进行全面危害评估。对五种先进的VLLMs在性伤害、暴力和错误信息三个危害类别上进行了评估。

Result: 研究发现，与单轮评估相比，多轮交互导致显著更高的缺陷率，突显了VLLMs更深层次的漏洞。GPT-4o在安全可用性指数（SUI）上表现最为均衡，Pixtral紧随其后。错误信息是需要加强上下文防御的关键领域。Llama-3.2的多轮缺陷率最高（16.55%），而Qwen2-VL的多轮拒绝率最高（19.1%）。

Conclusion: VLLMs在多轮交互中表现出比单轮评估更显著的脆弱性。REVEAL框架有效地揭示了这些漏洞，并强调了增强VLLMs（尤其是在错误信息方面）上下文防御能力的必要性。

Abstract: Vision Large Language Models (VLLMs) represent a significant advancement in
artificial intelligence by integrating image-processing capabilities with
textual understanding, thereby enhancing user interactions and expanding
application domains. However, their increased complexity introduces novel
safety and ethical challenges, particularly in multi-modal and multi-turn
conversations. Traditional safety evaluation frameworks, designed for
text-based, single-turn interactions, are inadequate for addressing these
complexities. To bridge this gap, we introduce the REVEAL (Responsible
Evaluation of Vision-Enabled AI LLMs) Framework, a scalable and automated
pipeline for evaluating image-input harms in VLLMs. REVEAL includes automated
image mining, synthetic adversarial data generation, multi-turn conversational
expansion using crescendo attack strategies, and comprehensive harm assessment
through evaluators like GPT-4o.
  We extensively evaluated five state-of-the-art VLLMs, GPT-4o, Llama-3.2,
Qwen2-VL, Phi3.5V, and Pixtral, across three important harm categories: sexual
harm, violence, and misinformation. Our findings reveal that multi-turn
interactions result in significantly higher defect rates compared to
single-turn evaluations, highlighting deeper vulnerabilities in VLLMs. Notably,
GPT-4o demonstrated the most balanced performance as measured by our
Safety-Usability Index (SUI) followed closely by Pixtral. Additionally,
misinformation emerged as a critical area requiring enhanced contextual
defenses. Llama-3.2 exhibited the highest MT defect rate ($16.55 \%$) while
Qwen2-VL showed the highest MT refusal rate ($19.1 \%$).

</details>


### [18] [Advanced Deep Learning Approaches for Automated Recognition of Cuneiform Symbols](https://arxiv.org/abs/2505.04678)
*Shahad Elshehaby,Alavikunhu Panthakkan,Hussain Al-Ahmad,Mina Al-Saad*

Main category: cs.CL

TL;DR: 论文提出了一种基于深度学习的全自动楔形文字识别与解释方法。


<details>
  <summary>Details</summary>
Motivation: 旨在利用深度学习自动解读楔形文字，以增进对人类历史的理解、保护文化遗产，并探索古代语言（如阿卡德语）与阿拉伯语之间的语言学和文化联系。

Method: 在全面的楔形文字字符数据集上训练了五个不同的深度学习模型，并根据准确率和精确度等关键性能指标进行评估，以识别和解释楔形文字。

Result: 表现最优的两个模型成功应用于汉谟拉比法典（特别是法典第一条）的楔形文字符号，准确识别了其相关的阿卡德语含义并提供了精确的英文翻译。

Conclusion: 研究证实了深度学习在结合计算语言学与考古学破译古代文字方面的能力，为理解和保护人类历史提供了重要启示。未来工作将致力于通过集成和堆叠等方法优化模型性能。

Abstract: This paper presents a thoroughly automated method for identifying and
interpreting cuneiform characters via advanced deep-learning algorithms. Five
distinct deep-learning models were trained on a comprehensive dataset of
cuneiform characters and evaluated according to critical performance metrics,
including accuracy and precision. Two models demonstrated outstanding
performance and were subsequently assessed using cuneiform symbols from the
Hammurabi law acquisition, notably Hammurabi Law 1. Each model effectively
recognized the relevant Akkadian meanings of the symbols and delivered precise
English translations. Future work will investigate ensemble and stacking
approaches to optimize performance, utilizing hybrid architectures to improve
detection accuracy and reliability. This research explores the linguistic
relationships between Akkadian, an ancient Mesopotamian language, and Arabic,
emphasizing their historical and cultural linkages. This study demonstrates the
capability of deep learning to decipher ancient scripts by merging
computational linguistics with archaeology, therefore providing significant
insights for the comprehension and conservation of human history.

</details>


### [19] [SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding](https://arxiv.org/abs/2505.04723)
*Jingyang Deng,Ran Chen,Jo-Ku Cheng,Jinwen Ma*

Main category: cs.CL

TL;DR: 提出SOAEsV2-7B/72B，一个专为中国国资国企领域优化的领域特定大语言模型系列，通过三阶段框架提升模型性能和推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前针对中国国资国企领域的特定大语言模型开发面临三大挑战：模型容量受限、过度依赖领域SFT数据以及大模型长文本推理效率低下。

Method: 采用三阶段框架：1) 持续预训练以整合领域知识并保留基础能力；2) 领域渐进式SFT，从弱相关对话数据过渡到专家标注的国资国企数据集；3) 基于蒸馏的推测解码，利用72B目标模型和7B草稿模型间的logit蒸馏加速推理。

Result: 领域特定预训练保持了99.8%的通用语言能力，领域性能显著提升（Rouge-1提升1.08倍，BLEU-4提升1.17倍）；领域渐进式SFT优于单阶段训练（Rouge-1提升1.02倍，BLEU-4提升1.06倍）；蒸馏增强的推测解码实现了1.39-1.52倍的无损加速。

Conclusion: 该研究提出了一套全面的、全流程的国资国企大语言模型优化方法，有效连接了通用语言能力与领域特定专业知识。

Abstract: This study addresses key challenges in developing domain-specific large
language models (LLMs) for Chinese state-owned assets and enterprises (SOAEs),
where current approaches face three limitations: 1) constrained model capacity
that limits knowledge integration and cross-task adaptability; 2) excessive
reliance on domain-specific supervised fine-tuning (SFT) data, which neglects
the broader applicability of general language patterns; and 3) inefficient
inference acceleration for large models processing long contexts. In this work,
we propose SOAEsV2-7B/72B, a specialized LLM series developed via a three-phase
framework: 1) continual pre-training integrates domain knowledge while
retaining base capabilities; 2) domain-progressive SFT employs curriculum-based
learning strategy, transitioning from weakly relevant conversational data to
expert-annotated SOAEs datasets to optimize domain-specific tasks; 3)
distillation-enhanced speculative decoding accelerates inference via logit
distillation between 72B target and 7B draft models, achieving
1.39-1.52$\times$ speedup without quality loss. Experimental results
demonstrate that our domain-specific pre-training phase maintains 99.8% of
original general language capabilities while significantly improving domain
performance, resulting in a 1.08$\times$ improvement in Rouge-1 score and a
1.17$\times$ enhancement in BLEU-4 score. Ablation studies further show that
domain-progressive SFT outperforms single-stage training, achieving
1.02$\times$ improvement in Rouge-1 and 1.06$\times$ in BLEU-4. Our work
introduces a comprehensive, full-pipeline approach for optimizing SOAEs LLMs,
bridging the gap between general language capabilities and domain-specific
expertise.

</details>


### [20] [Flower Across Time and Media: Sentiment Analysis of Tang Song Poetry and Visual Correspondence](https://arxiv.org/abs/2505.04785)
*Shuai Gong,Tiange Zhou*

Main category: cs.CL

TL;DR: 本研究运用BERT模型分析唐宋诗歌中花卉意象的情感变迁，并与同期艺术品进行比对，揭示了文学情感与视觉文化的协同作用。


<details>
  <summary>Details</summary>
Motivation: 现有研究多独立探讨唐宋时期的诗歌情感与视觉艺术，缺乏对二者之间演变关联的系统性考察。

Method: 采用基于BERT的情感分析模型量化唐宋诗歌中花卉（如牡丹、梅花）意象的情感模式，并与同时期纺织品、陶瓷等装饰艺术的视觉证据进行交叉验证。

Result: 研究发现，唐宋时期诗歌中牡丹和梅花意象的情感内涵发生了可测量的转变，并且这些文本中的情感模式与物质文化中的艺术表现之间存在先前未被认识到的协同关系。

Conclusion: 本研究证实了唐宋时期文学中花卉意象的情感表达与视觉艺术中的再现之间存在着显著的互动与协同发展，深化了对该时期文化表达整体性的理解。

Abstract: The Tang (618 to 907) and Song (960 to 1279) dynasties witnessed an
extraordinary flourishing of Chinese cultural expression, where floral motifs
served as a dynamic medium for both poetic sentiment and artistic design. While
previous scholarship has examined these domains independently, the systematic
correlation between evolving literary emotions and visual culture remains
underexplored. This study addresses that gap by employing BERT-based sentiment
analysis to quantify emotional patterns in floral imagery across Tang Song
poetry, then validating these patterns against contemporaneous developments in
decorative arts.Our approach builds upon recent advances in computational
humanities while remaining grounded in traditional sinological methods. By
applying a fine tuned BERT model to analyze peony and plum blossom imagery in
classical poetry, we detect measurable shifts in emotional connotations between
the Tang and Song periods. These textual patterns are then cross berenced with
visual evidence from textiles, ceramics, and other material culture, revealing
previously unrecognized synergies between literary expression and artistic
representation.

</details>


### [21] [Osiris: A Lightweight Open-Source Hallucination Detection System](https://arxiv.org/abs/2505.04844)
*Alex Shan,John Bauer,Christopher D. Manning*

Main category: cs.CL

TL;DR: 该研究提出了一种通过在包含诱导幻觉的扰动多跳问答数据集上进行监督微调，从而以更小模型（7B）在RAG幻觉检测中实现优于GPT-4o召回率的方法。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统因其依赖真实信息源而广泛应用，但大型语言模型（LLM）响应内容与上下文不符的“幻觉”现象阻碍了其生产部署。现有幻觉检测方法（人工评估或闭源模型）因成本高、推理慢而难以扩展。

Method: 研究人员引入了一个包含诱导幻觉的扰动多跳问答（QA）数据集，并在此数据集上对一个7B参数量的模型进行了监督微调，用于幻觉检测。

Result: 通过该方法，一个7B模型在RAGTruth幻觉检测基准测试中取得了比GPT-4o更高的召回率（recall），并在精确率（precision）和准确率（accuracy）方面具有竞争力，同时参数量远小于后者。

Conclusion: 该研究表明，使用专门构建的数据集进行监督微调，可以使较小模型在RAG幻觉检测任务上达到甚至超过大型闭源模型的性能，提供了一种更高效、可扩展的幻觉检测方案。

Abstract: Retrieval-Augmented Generation (RAG) systems have gained widespread adoption
by application builders because they leverage sources of truth to enable Large
Language Models (LLMs) to generate more factually sound responses. However,
hallucinations, instances of LLM responses that are unfaithful to the provided
context, often prevent these systems from being deployed in production
environments. Current hallucination detection methods typically involve human
evaluation or the use of closed-source models to review RAG system outputs for
hallucinations. Both human evaluators and closed-source models suffer from
scaling issues due to their high costs and slow inference speeds. In this work,
we introduce a perturbed multi-hop QA dataset with induced hallucinations. Via
supervised fine-tuning on our dataset, we achieve better recall with a 7B model
than GPT-4o on the RAGTruth hallucination detection benchmark and offer
competitive performance on precision and accuracy, all while using a fraction
of the parameters. Code is released at our repository.

</details>


### [22] [Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards](https://arxiv.org/abs/2505.04847)
*Manveer Singh Tamber,Forrest Sheng Bao,Chenyu Xu,Ge Luo,Suleman Kazi,Minseok Bae,Miaoran Li,Ofer Mendelevitch,Renyi Qu,Jimmy Lin*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）即便在检索增强生成（RAG）框架下仍存在幻觉问题。现有幻觉评估方法（如HHEM）存在局限性。本文提出FaithJudge，一种基于少样本人工标注指导的LLM即判官方法，以提升自动化幻觉评估的准确性，并推出了基于此方法的新幻觉排行榜。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的幻觉是一个持续存在的挑战，即使在检索增强生成（RAG）的帮助下，模型仍会产生与上下文不符或矛盾的信息。现有的幻觉评估模型（如HHEM）及其排行榜在评估幻觉方面面临挑战和局限性。

Method: 论文首先评估了不同LLM在文档摘要任务中产生幻觉的频率。接着，分析了现有幻觉检测方法（如HHEM）在处理幻觉数据集时的有效性和挑战。为解决这些局限性，研究者提出了FaithJudge，这是一种以LLM作为判别器（LLM-as-a-judge）的方法，并利用少量人工幻觉标注进行引导。同时，推出了一个基于FaithJudge的增强型幻觉排行榜。

Result: FaithJudge方法在自动化LLM幻觉评估方面显著优于当前方法。基于FaithJudge的新排行榜能够为RAG场景下的LLM幻觉提供更可靠的基准测试。

Conclusion: FaithJudge提供了一种更有效的LLM幻觉评估手段，其配套的排行榜有助于更可靠地对LLM在RAG应用中的幻觉问题进行基准评估，从而推动解决LLM的幻觉挑战。

Abstract: Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce
hallucinations by grounding responses in contexts. However, even when provided
context, LLMs still frequently introduce unsupported information or
contradictions. This paper presents our efforts to measure LLM hallucinations
with a focus on summarization tasks, assessing how often various LLMs introduce
hallucinations when summarizing documents. We discuss Vectara's existing LLM
hallucination leaderboard, based on the Hughes Hallucination Evaluation Model
(HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great
research interest, we examine challenges faced by HHEM and current
hallucination detection methods by analyzing the effectiveness of these methods
on existing hallucination datasets. To address these limitations, we propose
FaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination
annotations, which substantially improves automated LLM hallucination
evaluation over current methods. We introduce an enhanced hallucination
leaderboard centered on FaithJudge, alongside our current hallucination
leaderboard, enabling more reliable benchmarking of LLMs for hallucinations in
RAG.

</details>


### [23] [An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education](https://arxiv.org/abs/2505.04916)
*Ramteja Sajja,Yusuf Sermet,Ibrahim Demir*

Main category: cs.CL

TL;DR: 该研究提出了两种针对教育问答（特别是课程大纲）微调的开源嵌入模型，它们优于现有基线模型，并缩小了与专有模型的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有的语义检索系统大多不适应学术内容的独特性，尤其是在教育问答领域，需要更适合的嵌入模型来处理学术文本的语言和结构特点。

Method: 研究人员首先构建了一个包含3197个句子对的合成数据集，涵盖同义术语、释义问题和隐式-显式映射。然后，他们评估了两种训练策略：(1) 使用MultipleNegativesRankingLoss (MNRL) 微调的基线模型；(2) 结合MNRL和CosineSimilarityLoss以改善语义排序和相似度校准的双损失模型。评估在28个大学课程大纲上进行，使用一组固定的自然语言问题。

Result: 两种微调模型均优于强大的开源基线模型（如all-MiniLM-L6-v2和multi-qa-MiniLM-L6-cos-v1）。双损失模型进一步缩小了与高性能专有嵌入模型（如OpenAI的text-embedding-3系列）的性能差距。

Conclusion: 这项工作贡献了可重用的、与领域对齐的嵌入模型，并为教育语义检索提供了一个可复制的框架，支持学术聊天机器人、检索增强生成（RAG）系统和学习管理系统（LMS）集成等下游应用。

Abstract: Recent advances in AI have catalyzed the adoption of intelligent educational
tools, yet many semantic retrieval systems remain ill-suited to the unique
linguistic and structural characteristics of academic content. This study
presents two open-source embedding models fine-tuned for educational question
answering, particularly in the context of course syllabi. A synthetic dataset
of 3,197 sentence pairs, spanning synonymous terminology, paraphrased
questions, and implicit-explicit mappings, was constructed through a
combination of manual curation and large language model (LLM)-assisted
generation. Two training strategies were evaluated: (1) a baseline model
fine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model
that combines MNRL with CosineSimilarityLoss to improve both semantic ranking
and similarity calibration. Evaluations were conducted on 28 university course
syllabi using a fixed set of natural language questions categorized into
course, faculty, and teaching assistant information. Results demonstrate that
both fine-tuned models outperform strong open-source baselines, including
all-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model
narrows the performance gap with high-performing proprietary embeddings such as
OpenAI's text-embedding-3 series. This work contributes reusable,
domain-aligned embedding models and provides a replicable framework for
educational semantic retrieval, supporting downstream applications such as
academic chatbots, retrieval-augmented generation (RAG) systems, and learning
management system (LMS) integrations.

</details>


### [24] [Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org/abs/2505.04955)
*Fangwei Zhu,Peiyi Wang,Zhifang Sui*

Main category: cs.CL

TL;DR: 本文研究了思维链 (CoT) 在大型语言模型中的作用机制，发现 CoT 词元类似于程序中的变量，存储中间结果对解决复杂任务至关重要。


<details>
  <summary>Details</summary>
Motivation: 思维链 (CoT) 已被证明能有效帮助大型语言模型 (LLM) 解决复杂推理任务，但其内部机制仍不清楚。本研究旨在通过实验探究 CoT 词元在 LLM 中的具体作用。

Method: 本文通过在两个组合任务（多位数乘法和动态规划）上进行实证研究。研究方法包括：1) 仅保留存储中间结果的 CoT 词元并评估模型性能；2) 将中间结果以替代的潜在形式存储并观察模型性能；3) 随机干预 CoT 中的某些值，并观察后续 CoT 词元和最终答案的变化。

Result: 实验发现：1) 仅保留存储中间结果的 CoT 词元可以达到与完整 CoT 相当的性能；2) 以替代的潜在形式存储中间结果不影响模型性能；3) 随机干预 CoT 中的值会导致后续 CoT 词元和最终答案相应地改变。

Conclusion: 研究结果表明，CoT 词元可能像计算机程序中的变量一样发挥作用，用于存储和传递中间计算结果。然而，这种机制也可能存在潜在的缺点，如意外的捷径和词元间的计算复杂性限制。

Abstract: Chain-of-thoughts (CoT) requires large language models (LLMs) to generate
intermediate steps before reaching the final answer, and has been proven
effective to help LLMs solve complex reasoning tasks. However, the inner
mechanism of CoT still remains largely unclear. In this paper, we empirically
study the role of CoT tokens in LLMs on two compositional tasks: multi-digit
multiplication and dynamic programming. While CoT is essential for solving
these problems, we find that preserving only tokens that store intermediate
results would achieve comparable performance. Furthermore, we observe that
storing intermediate results in an alternative latent form will not affect
model performance. We also randomly intervene some values in CoT, and notice
that subsequent CoT tokens and the final answer would change correspondingly.
These findings suggest that CoT tokens may function like variables in computer
programs but with potential drawbacks like unintended shortcuts and
computational complexity limits between tokens. The code and data are available
at https://github.com/solitaryzero/CoTs_are_Variables.

</details>


### [25] [Rethinking the Relationship between the Power Law and Hierarchical Structures](https://arxiv.org/abs/2505.04984)
*Kai Nakaishi,Ryo Yoshida,Kohei Kajikawa,Koji Hukushima,Yohei Oseki*

Main category: cs.CL

TL;DR: 该研究检验了语言中幂律相关性是层级句法结构证据的观点，发现其基本假设并不成立。


<details>
  <summary>Details</summary>
Motivation: 幂律相关性被广泛认为是语言中层级结构（包括句法、语义和语篇）的证据，并已扩展到儿童语言和动物信号，但这一论点的实证有效性，特别是在句法结构方面，尚未得到检验。

Method: 研究人员使用英语语料库，分析了句法分析树中的互信息、与概率上下文无关文法 (PCFG) 的偏差以及其他统计特性，并与近似这些树的 PCFG 进行比较，以检验幂律相关性论证中的隐含假设是否与句法结构的统计特性一致。

Result: 研究结果表明，将幂律相关性解释为句法结构证据的论证所依赖的假设，在句法结构中并不成立。

Conclusion: 结论指出，将幂律相关性论证应用于儿童语言和动物信号是困难的，并强调需要重新审视幂律现象与层级结构之间的关系。

Abstract: Statistical analysis of corpora provides an approach to quantitatively
investigate natural languages. This approach has revealed that several power
laws consistently emerge across different corpora and languages, suggesting the
universal principles underlying languages. Particularly, the power-law decay of
correlation has been interpreted as evidence for underlying hierarchical
structures in syntax, semantics, and discourse. This perspective has also been
extended to child languages and animal signals. However, the argument
supporting this interpretation has not been empirically tested. To address this
problem, this study examines the validity of the argument for syntactic
structures. Specifically, we test whether the statistical properties of parse
trees align with the implicit assumptions in the argument. Using English
corpora, we analyze the mutual information, deviations from probabilistic
context-free grammars (PCFGs), and other properties in parse trees, as well as
in the PCFG that approximates these trees. Our results indicate that the
assumptions do not hold for syntactic structures and that it is difficult to
apply the proposed argument to child languages and animal signals, highlighting
the need to reconsider the relationship between the power law and hierarchical
structures.

</details>


### [26] [Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes](https://arxiv.org/abs/2505.04993)
*Zhuocheng Gong,Jian Guan,Wei Wu,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CL

TL;DR: 提出潜在偏好编码（LPC）框架，通过离散潜在编码对人类偏好中的隐式因素建模，以改善大型语言模型的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型对齐方法难以捕捉人类偏好的复杂性和多面性，通常依赖于显式或隐式奖励函数，而忽略了不同任务和人群中可能存在的冲突因素。

Method: 引入潜在偏好编码（LPC）框架。该框架使用离散潜在编码来模拟整体偏好背后的隐式因素及其组合。LPC能与多种离线对齐算法集成，自动从数据中推断潜在因素及其重要性，无需预定义奖励函数和手动设定的组合权重。

Result: 在多个基准测试中，LPC稳定地改进了三种对齐算法（DPO、SimPO和IPO）在三种基础模型（Mistral-7B、Llama3-8B和Llama3-8B-Instruct）上的表现。学习到的潜在编码有效地捕捉了人类偏好分布的差异，并显著增强了对齐算法对数据噪声的鲁棒性。

Conclusion: LPC为多样的偏好因素提供了统一的表示，为开发更鲁棒和通用的对齐技术，以促进大型语言模型的负责任部署铺平了道路。

Abstract: Large language models (LLMs) have achieved remarkable success, yet aligning
their generations with human preferences remains a critical challenge. Existing
approaches to preference modeling often rely on an explicit or implicit reward
function, overlooking the intricate and multifaceted nature of human
preferences that may encompass conflicting factors across diverse tasks and
populations. To address this limitation, we introduce Latent Preference Coding
(LPC), a novel framework that models the implicit factors as well as their
combinations behind holistic preferences using discrete latent codes. LPC
seamlessly integrates with various offline alignment algorithms, automatically
inferring the underlying factors and their importance from data without relying
on pre-defined reward functions and hand-crafted combination weights. Extensive
experiments on multiple benchmarks demonstrate that LPC consistently improves
upon three alignment algorithms (DPO, SimPO, and IPO) using three base models
(Mistral-7B, Llama3-8B, and Llama3-8B-Instruct). Furthermore, deeper analysis
reveals that the learned latent codes effectively capture the differences in
the distribution of human preferences and significantly enhance the robustness
of alignment against noise in data. By providing a unified representation for
the multifarious preference factors, LPC paves the way towards developing more
robust and versatile alignment techniques for the responsible deployment of
powerful LLMs.

</details>


### [27] [Rethinking Invariance in In-context Learning](https://arxiv.org/abs/2505.04994)
*Lizhe Fang,Yifei Wang,Khashayar Gatmiry,Lei Fang,Yisen Wang*

Main category: cs.CL

TL;DR: 提出了一种名为InvICL的新型上下文学习方法，解决了LLM中ICL对示例顺序敏感的问题，并实现了更优的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 标准的上下文学习（ICL）对示例顺序非常敏感，而现有的排列不变ICL算法性能常不如标准ICL，且未能同时满足信息不泄露和上下文相互依赖这两个关键特性。

Method: 提出了一种新的不变性ICL方法（InvICL），该方法旨在实现ICL的排列不变性，同时确保信息不泄露和上下文相互依赖这两个关键特性。

Result: 实验表明，InvICL在大多数基准数据集上优于先前的模型（包括不变和非不变模型），并且在不同输入长度上表现出更强的泛化能力。

Conclusion: InvICL通过同时满足信息不泄露和上下文相互依赖，成功地实现了对示例顺序不敏感的上下文学习，并在性能和泛化性上超越了现有方法。

Abstract: In-Context Learning (ICL) has emerged as a pivotal capability of
auto-regressive large language models, yet it is hindered by a notable
sensitivity to the ordering of context examples regardless of their mutual
independence. To address this issue, recent studies have introduced several
variant algorithms of ICL that achieve permutation invariance. However, many of
these do not exhibit comparable performance with the standard auto-regressive
ICL algorithm. In this work, we identify two crucial elements in the design of
an invariant ICL algorithm: information non-leakage and context
interdependence, which are not simultaneously achieved by any of the existing
methods. These investigations lead us to the proposed Invariant ICL (InvICL), a
methodology designed to achieve invariance in ICL while ensuring the two
properties. Empirically, our findings reveal that InvICL surpasses previous
models, both invariant and non-invariant, in most benchmark datasets,
showcasing superior generalization capabilities across varying input lengths.
Code is available at https://github.com/PKU-ML/InvICL.

</details>


### [28] [The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations](https://arxiv.org/abs/2505.05016)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLMs）在群组推荐中执行聚合策略的能力，发现群组复杂性、提示格式会影响其准确性，但上下文学习（ICL）可提升表现。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在零样本学习条件下能否正确执行群组推荐系统（GRS）中基于社会选择的聚合策略，并分析提示中群组场景的格式化对准确性的影响。

Method: 通过实验研究不同因素（群组复杂度、不同LLMs、不同提示条件如上下文学习或生成解释、群组偏好格式化）对LLMs执行GRS聚合策略准确性的影响。

Result: 当评分数量超过100个时，LLM性能开始下降，但不同LLM对群组复杂度的敏感性不同。上下文学习（ICL）能在高复杂度下显著提高性能，而其他提示修改（如领域提示或解释生成）影响不大。群组场景的不同格式化方式（如按用户或项目列出评分）也影响准确性。

Conclusion: 未来的GRS评估应考虑群组复杂度对LLM性能的影响。研究表明，在适当条件下，较小的LLMs也能有效生成群组推荐，这为使用计算和成本更低的小型模型提供了支持。

Abstract: Large Language Models (LLMs) are increasingly applied in recommender systems
aimed at both individuals and groups. Previously, Group Recommender Systems
(GRS) often used social choice-based aggregation strategies to derive a single
recommendation based on the preferences of multiple people. In this paper, we
investigate under which conditions language models can perform these strategies
correctly based on zero-shot learning and analyse whether the formatting of the
group scenario in the prompt affects accuracy. We specifically focused on the
impact of group complexity (number of users and items), different LLMs,
different prompting conditions, including In-Context learning or generating
explanations, and the formatting of group preferences. Our results show that
performance starts to deteriorate when considering more than 100 ratings.
However, not all language models were equally sensitive to growing group
complexity. Additionally, we showed that In-Context Learning (ICL) can
significantly increase the performance at higher degrees of group complexity,
while adding other prompt modifications, specifying domain cues or prompting
for explanations, did not impact accuracy. We conclude that future research
should include group complexity as a factor in GRS evaluation due to its effect
on LLM performance. Furthermore, we showed that formatting the group scenarios
differently, such as rating lists per user or per item, affected accuracy. All
in all, our study implies that smaller LLMs are capable of generating group
recommendations under the right conditions, making the case for using smaller
models that require less computing power and costs.

</details>


### [29] [Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization](https://arxiv.org/abs/2505.05017)
*Yuntai Bao,Xuhong Zhang,Tianyu Du,Xinkui Zhao,Jiang Zong,Hao Peng,Jianwei Yin*

Main category: cs.CL

TL;DR: 提出了一种可扩展的多阶段影响函数，利用EK-FAC近似将微调后LLM的预测追溯到其预训练数据，以增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有影响函数方法难以计算预训练到微调的“多阶段”影响，并且缺乏对十亿参数级别大型语言模型（LLM）的可扩展性，阻碍了理解微调LLM预测与预训练数据之间的关系。

Method: 提出了一种新的“多阶段影响函数”，用于在全参数微调范式下将微调LLM的下游预测归因于预训练数据。为提高效率和实用性，采用特征值校正的克罗内克分解（EK-FAC）参数化进行有效近似。

Result: 实验结果验证了EK-FAC近似方法具有卓越的可扩展性，并且所提出的多阶段影响函数是有效的。在真实LLM（dolly-v2-3b）上的案例研究展示了该方法的解释能力，并通过具体示例揭示了多阶段影响估计所能提供的洞察。

Conclusion: 该研究提出的多阶段影响函数结合EK-FAC近似，为理解微调LLM的预测来源（即预训练数据）提供了一个有效且可扩展的工具，增强了大型模型的可解释性。

Abstract: Pre-trained large language models (LLMs) are commonly fine-tuned to adapt to
downstream tasks. Since the majority of knowledge is acquired during
pre-training, attributing the predictions of fine-tuned LLMs to their
pre-training data may provide valuable insights. Influence functions have been
proposed as a means to explain model predictions based on training data.
However, existing approaches fail to compute ``multi-stage'' influence and lack
scalability to billion-scale LLMs.
  In this paper, we propose the multi-stage influence function to attribute the
downstream predictions of fine-tuned LLMs to pre-training data under the
full-parameter fine-tuning paradigm. To enhance the efficiency and practicality
of our multi-stage influence function, we leverage Eigenvalue-corrected
Kronecker-Factored (EK-FAC) parameterization for efficient approximation.
Empirical results validate the superior scalability of EK-FAC approximation and
the effectiveness of our multi-stage influence function. Additionally, case
studies on a real-world LLM, dolly-v2-3b, demonstrate its interpretive power,
with exemplars illustrating insights provided by multi-stage influence
estimates. Our code is public at
https://github.com/colored-dye/multi_stage_influence_function.

</details>


### [30] [G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness](https://arxiv.org/abs/2505.05026)
*Jaehyun Jeon,Janghan Yoon,Minsoo Kim,Sumin Shim,Yejin Choi,Hanbin Kim,Youngjae Yu*

Main category: cs.CL

TL;DR: 该研究提出了一个用于评估UI设计说服力的基准WiserUI-Bench，以及一种新的推理策略G-FOCUS，以增强视觉语言模型（VLM）在此任务上的表现，旨在补充传统A/B测试。


<details>
  <summary>Details</summary>
Motivation: 传统的A/B测试评估用户界面（UI）设计效果成本高、耗时长；而现有的视觉语言模型（VLM）在自动化UI分析中侧重于孤立的设计属性，而非对优化用户交互至关重要的比较性说服力评估。

Method: 1. 引入WiserUI-Bench：一个专为成对UI设计说服力评估任务设计的基准，包含300对真实世界的UI图像，并标注了A/B测试结果和专家解释。
2. 提出G-FOCUS：一种新颖的推理时（inference-time）推理策略，通过减少位置偏差和提高评估准确性来增强基于VLM的说服力评估。

Result: 实验结果表明，G-FOCUS在成对UI评估的一致性和准确性方面均优于现有的推理策略。

Conclusion: 该工作通过推广基于VLM的UI说服力评估，提供了一种补充A/B测试的方法，从而推动了可扩展的UI偏好建模和设计优化方面的进展。代码和数据将公开发布。

Abstract: Evaluating user interface (UI) design effectiveness extends beyond aesthetics
to influencing user behavior, a principle central to Design Persuasiveness. A/B
testing is the predominant method for determining which UI variations drive
higher user engagement, but it is costly and time-consuming. While recent
Vision-Language Models (VLMs) can process automated UI analysis, current
approaches focus on isolated design attributes rather than comparative
persuasiveness-the key factor in optimizing user interactions. To address this,
we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design
Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled
with A/B test results and expert rationales. Additionally, we propose G-FOCUS,
a novel inference-time reasoning strategy that enhances VLM-based
persuasiveness assessment by reducing position bias and improving evaluation
accuracy. Experimental results show that G-FOCUS surpasses existing inference
strategies in consistency and accuracy for pairwise UI evaluation. Through
promoting VLM-driven evaluation of UI persuasiveness, our work offers an
approach to complement A/B testing, propelling progress in scalable UI
preference modeling and design optimization. Code and data will be released
publicly.

</details>


### [31] [Image-Text Relation Prediction for Multilingual Tweets](https://arxiv.org/abs/2505.05040)
*Matīss Rikters,Edison Marrese-Taylor*

Main category: cs.CL

TL;DR: 该研究探讨了多语言视觉语言模型在不同语言中预测图像-文本关系的能力，并构建了一个包含拉脱维亚语推文及其英语翻译的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 社交网络允许媒体上传已超过十年，但媒体与所发布文本之间的关系，甚至是否存在关系，一直不明确。

Method: 研究探索了多语言视觉语言模型如何处理不同语言中的图像-文本关系预测任务，并从拉脱维亚语的推特帖子及其人工英语翻译中构建了一个专门的平衡基准数据集。将研究结果与先前工作进行了比较。

Result: 研究表明，最近发布的视觉语言模型检查点在这项任务上的能力越来越强。

Conclusion: 尽管最新的视觉语言模型表现有所提升，但在图像-文本关系预测方面仍有很大的改进空间。

Abstract: Various social networks have been allowing media uploads for over a decade
now. Still, it has not always been clear what is their relation with the posted
text or even if there is any at all. In this work, we explore how multilingual
vision-language models tackle the task of image-text relation prediction in
different languages, and construct a dedicated balanced benchmark data set from
Twitter posts in Latvian along with their manual translations into English. We
compare our results to previous work and show that the more recently released
vision-language model checkpoints are becoming increasingly capable at this
task, but there is still much room for further improvement.

</details>


### [32] [Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations](https://arxiv.org/abs/2505.05056)
*Linrong Pan,Chenglong Jiang,Gaoze Hou,Ying Gao*

Main category: cs.CL

TL;DR: 本文构建了首个公开的、带精确正字法标注的潮州话语音语料库Teochew-Wild (18.9小时)，并提供了辅助工具，旨在推动潮州话的自动语音识别(ASR)和文本到语音(TTS)等研究。


<details>
  <summary>Details</summary>
Motivation: 潮州话是一种低资源语言，缺乏公开的、带有精确正字法标注的语音语料库，这阻碍了自动语音识别（ASR）和文本到语音（TTS）等语音任务的研究和应用。

Method: 构建了一个包含18.9小时、多说话人、覆盖正式和口语表达的自然场景潮州话语音语料库（Teochew-Wild），并进行了精确的正字法和拼音标注。同时提供了辅助的文本处理工具和资源。通过实验验证了语料库的有效性。

Result: 成功构建了Teochew-Wild语料库，这是首个公开的、带精确正字法标注的潮州话数据集。实验结果验证了该语料库在自动语音识别（ASR）和文本到语音（TTS）任务中的有效性。

Conclusion: Teochew-Wild语料库及其配套的文本处理工具和资源，为推动低资源潮州话方言的语音研究（如ASR和TTS）和应用提供了宝贵的基础。

Abstract: This paper reports the construction of the Teochew-Wild, a speech corpus of
the Teochew dialect. The corpus includes 18.9 hours of in-the-wild Teochew
speech data from multiple speakers, covering both formal and colloquial
expressions, with precise orthographic and pinyin annotations. Additionally, we
provide supplementary text processing tools and resources to propel research
and applications in speech tasks for this low-resource language, such as
automatic speech recognition (ASR) and text-to-speech (TTS). To the best of our
knowledge, this is the first publicly available Teochew dataset with accurate
orthographic annotations. We conduct experiments on the corpus, and the results
validate its effectiveness in ASR and TTS tasks.

</details>


### [33] [Performance Evaluation of Large Language Models in Bangla Consumer Health Query Summarization](https://arxiv.org/abs/2505.05070)
*Ajwad Abrar,Farzana Tabassum,Sabbir Ahmed*

Main category: cs.CL

TL;DR: 本研究评估了九种大型语言模型（LLMs）在孟加拉语消费者健康查询（CHQs）零样本摘要任务上的表现，发现它们能够媲美甚至超越经过微调的模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语（一种低资源语言）的消费者健康查询（CHQs）通常包含无关细节，这使得高效的医疗响应变得复杂。因此，需要有效的方法来摘要这些查询。

Method: 研究调查了九种先进大型语言模型（GPT-3.5-Turbo, GPT-4, Claude-3.5-Sonnet, Llama3-70b-Instruct, Mixtral-8x22b-Instruct, Gemini-1.5-Pro, Qwen2-72b-Instruct, Gemma-2-27b, 和 Athene-70B）在摘要孟加拉语CHQs方面的零样本性能。使用了包含2350个带注释查询-摘要对的BanglaCHQ-Summ数据集，并使用ROUGE指标将这些LLMs与经过微调的先进模型Bangla T5进行了基准比较。

Result: Mixtral-8x22b-Instruct在ROUGE-1和ROUGE-L指标上表现最佳，而Bangla T5在ROUGE-2指标上表现出色。结果表明，零样本LLMs的性能可以与经过微调的模型相媲美，即使没有特定任务的训练也能生成高质量的摘要。

Conclusion: 这项工作强调了LLMs在解决低资源语言挑战方面的潜力，为医疗保健查询摘要提供了可扩展的解决方案。

Abstract: Consumer Health Queries (CHQs) in Bengali (Bangla), a low-resource language,
often contain extraneous details, complicating efficient medical responses.
This study investigates the zero-shot performance of nine advanced large
language models (LLMs): GPT-3.5-Turbo, GPT-4, Claude-3.5-Sonnet,
Llama3-70b-Instruct, Mixtral-8x22b-Instruct, Gemini-1.5-Pro,
Qwen2-72b-Instruct, Gemma-2-27b, and Athene-70B, in summarizing Bangla CHQs.
Using the BanglaCHQ-Summ dataset comprising 2,350 annotated query-summary
pairs, we benchmarked these LLMs using ROUGE metrics against Bangla T5, a
fine-tuned state-of-the-art model. Mixtral-8x22b-Instruct emerged as the top
performing model in ROUGE-1 and ROUGE-L, while Bangla T5 excelled in ROUGE-2.
The results demonstrate that zero-shot LLMs can rival fine-tuned models,
achieving high-quality summaries even without task-specific training. This work
underscores the potential of LLMs in addressing challenges in low-resource
languages, providing scalable solutions for healthcare query summarization.

</details>


### [34] [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://arxiv.org/abs/2505.05084)
*Xiaowei Zhu,Yubing Ren,Yanan Cao,Xixun Lin,Fang Fang,Yangxi Li*

Main category: cs.CL

TL;DR: 提出了一种多尺度共形预测（MCP）框架，用于零样本机器生成文本检测，该框架在有效控制误报率的同时提高了检测性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器生成文本检测方法过分关注检测准确率，忽略了高误报率（FPRs）带来的社会风险。因此，需要一种能够有效约束误报率上限的方法。

Method: 该研究利用共形预测（CP）来约束误报率上限。为解决直接应用CP会导致检测性能显著下降的问题，提出了一种基于多尺度共形预测的零样本机器生成文本检测框架（MCP）。同时，引入了一个名为RealDet的高质量、多领域数据集，用于现实校准和提升检测性能。

Result: 实验评估表明，MCP能够有效约束误报率，显著增强检测性能，并提高在多种检测器和数据集上对抗对抗性攻击的鲁棒性。

Conclusion: MCP框架有效地解决了机器生成文本检测中控制误报率与保持高性能之间的权衡问题，为降低大语言模型滥用风险提供了有效工具。

Abstract: The rapid advancement of large language models has raised significant
concerns regarding their potential misuse by malicious actors. As a result,
developing effective detectors to mitigate these risks has become a critical
priority. However, most existing detection methods focus excessively on
detection accuracy, often neglecting the societal risks posed by high false
positive rates (FPRs). This paper addresses this issue by leveraging Conformal
Prediction (CP), which effectively constrains the upper bound of FPRs. While
directly applying CP constrains FPRs, it also leads to a significant reduction
in detection performance. To overcome this trade-off, this paper proposes a
Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal
Prediction (MCP), which both enforces the FPR constraint and improves detection
performance. This paper also introduces RealDet, a high-quality dataset that
spans a wide range of domains, ensuring realistic calibration and enabling
superior detection performance when combined with MCP. Empirical evaluations
demonstrate that MCP effectively constrains FPRs, significantly enhances
detection performance, and increases robustness against adversarial attacks
across multiple detectors and datasets.

</details>


### [35] [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://arxiv.org/abs/2505.05111)
*Boyi Deng,Yu Wan,Yidan Zhang,Baosong Yang,Fuli Feng*

Main category: cs.CL

TL;DR: 本文使用稀疏自编码器（SAEs）分析大型语言模型（LLMs）的多语言能力，发现并利用特定语言的SAE特征来理解和控制模型的语言输出。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经元或内部激活的方法在探究LLMs多语言能力时，因叠加和层激活方差等问题而可靠性不足。

Method: 使用稀疏自编码器（SAEs）分解LLM的激活，引入新指标评估SAE特征的单语性，并对这些特征进行消融实验，以及利用它们增强引导向量。

Result: 研究发现部分SAE特征与特定语言强相关；消融这些特征仅显著降低模型在该语言上的能力；某些语言存在协同SAE特征；利用这些特征可有效控制LLM的生成语言。

Conclusion: SAEs为理解LLM多语言机制提供了更细致的分析方法，识别出的特定语言特征可用于控制模型的语言能力。

Abstract: The mechanisms behind multilingual capabilities in Large Language Models
(LLMs) have been examined using neuron-based or internal-activation-based
methods. However, these methods often face challenges such as superposition and
layer-wise activation variance, which limit their reliability. Sparse
Autoencoders (SAEs) offer a more nuanced analysis by decomposing the
activations of LLMs into sparse linear combination of SAE features. We
introduce a novel metric to assess the monolinguality of features obtained from
SAEs, discovering that some features are strongly related to specific
languages. Additionally, we show that ablating these SAE features only
significantly reduces abilities in one language of LLMs, leaving others almost
unaffected. Interestingly, we find some languages have multiple synergistic SAE
features, and ablating them together yields greater improvement than ablating
individually. Moreover, we leverage these SAE-derived language-specific
features to enhance steering vectors, achieving control over the language
generated by LLMs.

</details>


### [36] [A Benchmark Dataset and a Framework for Urdu Multimodal Named Entity Recognition](https://arxiv.org/abs/2505.05148)
*Hussain Ahmad,Qingyang Zeng,Jing Wan*

Main category: cs.CL

TL;DR: 该研究针对乌尔都语多模态命名实体识别（MNER）资源匮乏的问题，提出了U-MNER框架并发布了首个乌尔都语MNER数据集Twitter2015-Urdu，其模型在该数据集上取得了当前最佳性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态命名实体识别（MNER）在高资源语言中已取得进展，但在像乌尔都语这样的低资源语言中仍未得到充分探索，主要挑战在于缺乏标注的多模态数据集和标准化的基线模型。

Method: 1. 构建并发布了Twitter2015-Urdu数据集，这是一个针对乌尔都语MNER的开创性资源，改编自Twitter2015并根据乌尔都语语法规则进行了标注。
2. 提出了U-MNER框架，该框架使用Urdu-BERT进行文本嵌入，使用ResNet进行视觉特征提取，并通过一个跨模态融合模块来对齐和融合文本与视觉信息。
3. 在新数据集上评估了基于文本和多模态的模型，建立了基准。

Result: 提出的U-MNER模型在Twitter2015-Urdu数据集上实现了最先进的（state-of-the-art）性能。

Conclusion: 该研究为乌尔都语多模态命名实体识别提供了基础性工作，包括一个专门的数据集和一个有效的框架，为未来在低资源语言上的MNER研究铺平了道路。

Abstract: The emergence of multimodal content, particularly text and images on social
media, has positioned Multimodal Named Entity Recognition (MNER) as an
increasingly important area of research within Natural Language Processing.
Despite progress in high-resource languages such as English, MNER remains
underexplored for low-resource languages like Urdu. The primary challenges
include the scarcity of annotated multimodal datasets and the lack of
standardized baselines. To address these challenges, we introduce the U-MNER
framework and release the Twitter2015-Urdu dataset, a pioneering resource for
Urdu MNER. Adapted from the widely used Twitter2015 dataset, it is annotated
with Urdu-specific grammar rules. We establish benchmark baselines by
evaluating both text-based and multimodal models on this dataset, providing
comparative analyses to support future research on Urdu MNER. The U-MNER
framework integrates textual and visual context using Urdu-BERT for text
embeddings and ResNet for visual feature extraction, with a Cross-Modal Fusion
Module to align and fuse information. Our model achieves state-of-the-art
performance on the Twitter2015-Urdu dataset, laying the groundwork for further
MNER research in low-resource languages.

</details>


### [37] [QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation](https://arxiv.org/abs/2505.05225)
*Mengze Hong,Wailing Ng,Di Jiang,Chen Jason Zhang*

Main category: cs.CL

TL;DR: 该研究引入了QualBench，一个基于中国职业资格考试的多领域中文问答基准，用于评估中国大模型的领域知识和本地化能力。


<details>
  <summary>Details</summary>
Motivation: 中国大语言模型发展迅速，但现有评测基准在垂直领域覆盖不足，且缺乏对中国工作环境的深入洞察，难以保证模型应用的可靠性。

Method: 研究团队构建了QualBench，一个包含超过17000个问题的多领域中文问答数据集。该数据集基于24项中国职业资格考试，覆盖六个垂直领域，旨在贴近国家政策和工作标准。

Result: 评估结果显示，Qwen2.5模型表现优于GPT-4o，中国本土大模型普遍优于非中国模型，突显了本地化领域知识的重要性。最佳模型准确率为75.26%，表明当前模型在领域知识覆盖方面仍存在差距。此外，研究还揭示了大模型与众包机制协作的失败。

Conclusion: 中国大模型在本地化领域知识方面具有优势，但仍有提升空间。研究建议通过多领域RAG知识增强和联邦学习进行垂直领域大模型训练，以弥补当前模型能力的不足。

Abstract: The rapid advancement of Chinese large language models (LLMs) underscores the
need for domain-specific evaluations to ensure reliable applications. However,
existing benchmarks often lack coverage in vertical domains and offer limited
insights into the Chinese working context. Leveraging qualification exams as a
unified framework for human expertise evaluation, we introduce QualBench, the
first multi-domain Chinese QA benchmark dedicated to localized assessment of
Chinese LLMs. The dataset includes over 17,000 questions across six vertical
domains, with data selections grounded in 24 Chinese qualifications to closely
align with national policies and working standards. Through comprehensive
evaluation, the Qwen2.5 model outperformed the more advanced GPT-4o, with
Chinese LLMs consistently surpassing non-Chinese models, highlighting the
importance of localized domain knowledge in meeting qualification requirements.
The best performance of 75.26% reveals the current gaps in domain coverage
within model capabilities. Furthermore, we present the failure of LLM
collaboration with crowdsourcing mechanisms and suggest the opportunities for
multi-domain RAG knowledge enhancement and vertical domain LLM training with
Federated Learning.

</details>


### [38] [T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2505.05271)
*Kun Peng,Chaodong Tong,Cong Cao,Hao Peng,Qian Li,Guanlin Wu,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Table-Transformer (T-T) 的新模型，用于方面情感三元组提取（ASTE）。该模型通过引入带循环移位策略的条纹注意力机制，解决了直接将Transformer应用于表格标注方法时面临的序列过长和局部注意力交互不公平问题。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明，更强的关系捕获能力可以显著提升ASTE模型的性能。受此启发，研究者试图直接利用Transformer层作为下游关系学习模块，但由于表格长度与输入句子序列长度的平方关系，直接使用Transformer会面临表格序列过长和局部注意力交互不公平的挑战。

Method: 提出了一种新颖的Table-Transformer (T-T) 模型，用于基于表格标注的ASTE方法。具体方法包括：1. 将Transformer层用作下游关系学习模块；2. 引入条纹注意力机制，将全局注意力修改为仅关注二维局部注意力窗口；3. 采用循环移位策略，促进不同注意力窗口之间的交互。

Result: 大量的综合实验表明，T-T作为下游关系学习模块，在ASTE任务上取得了当前最先进的性能，并且计算成本更低。

Conclusion: T-T模型通过其新颖的条纹注意力和循环移位策略，有效地解决了将Transformer直接应用于ASTE表格标注时的挑战，实现了性能的提升和计算成本的降低。

Abstract: Aspect sentiment triplet extraction (ASTE) aims to extract triplets composed
of aspect terms, opinion terms, and sentiment polarities from given sentences.
The table tagging method is a popular approach to addressing this task, which
encodes a sentence into a 2-dimensional table, allowing for the tagging of
relations between any two words. Previous efforts have focused on designing
various downstream relation learning modules to better capture interactions
between tokens in the table, revealing that a stronger capability to capture
relations can lead to greater improvements in the model. Motivated by this, we
attempt to directly utilize transformer layers as downstream relation learning
modules. Due to the powerful semantic modeling capability of transformers, it
is foreseeable that this will lead to excellent improvement. However, owing to
the quadratic relation between the length of the table and the length of the
input sentence sequence, using transformers directly faces two challenges:
overly long table sequences and unfair local attention interaction. To address
these challenges, we propose a novel Table-Transformer (T-T) for the
tagging-based ASTE method. Specifically, we introduce a stripe attention
mechanism with a loop-shift strategy to tackle these challenges. The former
modifies the global attention mechanism to only attend to a 2-dimensional local
attention window, while the latter facilitates interaction between different
attention windows. Extensive and comprehensive experiments demonstrate that the
T-T, as a downstream relation learning module, achieves state-of-the-art
performance with lower computational costs.

</details>


### [39] [Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design](https://arxiv.org/abs/2505.05298)
*Elena Musi,Nadin Kokciyan,Khalid Al-Khatib,Davide Ceolin,Emmanuelle Dietz,Klara Gutekunst,Annette Hautli-Janisz,Cristian Manuel Santibañez Yañez,Jodi Schneider,Jonas Scholz,Cor Steging,Jacky Visser,Henning Wachsmuth*

Main category: cs.CL

TL;DR: 论文主张开发支持论证过程的对话技术，认为当前LLMs不适用，并提出“理性鹦鹉”设计，将LLMs作为批判性思维工具以增强论证技能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在支持和促进论证过程方面存在不足，难以有效培养用户的论证技能。

Method: 提议将LLMs重新定位为锻炼批判性思维的工具，而非取代人类思考。引入“理性鹦鹉”（reasonable parrots）概念，该模型体现论证理论中的相关性、责任感和自由三大基本原则，并通过论证性对话行为进行互动。

Result: 提出了“理性鹦鹉”这一理想技术设计概念。该设计基于论证理论的原则和对话行为，旨在作为开发能融入论证基本原则的LLM技术的起点，用以增强用户的论证能力。

Conclusion: 应开发结合论证理论基本原则（如相关性、责任感、自由及特定的对话行为）的LLM技术，以更好地支持论证过程，并将LLMs用作提升用户批判性思维和论证技能的工具。

Abstract: In this position paper, we advocate for the development of conversational
technology that is inherently designed to support and facilitate argumentative
processes. We argue that, at present, large language models (LLMs) are
inadequate for this purpose, and we propose an ideal technology design aimed at
enhancing argumentative skills. This involves re-framing LLMs as tools to
exercise our critical thinking rather than replacing them. We introduce the
concept of 'reasonable parrots' that embody the fundamental principles of
relevance, responsibility, and freedom, and that interact through argumentative
dialogical moves. These principles and moves arise out of millennia of work in
argumentation theory and should serve as the starting point for LLM-based
technology that incorporates basic principles of argumentation.

</details>


### [40] [ICon: In-Context Contribution for Automatic Data Selection](https://arxiv.org/abs/2505.05327)
*Yixin Yang,Qingxiu Dong,Linli Yao,Fangwei Zhu,Zhifang Sui*

Main category: cs.CL

TL;DR: 本文提出了一种名为ICon的新型无梯度方法，通过上下文学习（ICL）来衡量样本对LLM指令微调的贡献，从而高效选择数据，提升模型性能并降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM指令微调数据自动选择方法要么计算成本高昂（如基于梯度的方法），要么依赖可能无法充分利用数据内在属性的人工设计启发式规则。

Method: 提出了“基于上下文学习的贡献度量方法（ICon）”。该方法利用上下文学习（ICL）的隐式微调特性，通过评估在ICL下隐式学习带来的性能变化来衡量样本贡献，从而识别高贡献数据，无需梯度计算或人工指标工程。

Result: 在三个LLM模型、12个基准测试和5个成对评估集上的实验证明了ICon的有效性。例如，在LLaMA3.1-8B上，使用ICon选择的15%数据训练的模型性能比使用完整数据集高出5.42个百分点，并超过了广泛使用的最佳选择方法2.06个百分点。ICon选择的高贡献样本展现出任务多样性和适当的难度水平。

Conclusion: ICon是一种计算高效且有效的无梯度数据选择方法，适用于LLM指令微调。它能显著提升模型性能，同时减少对昂贵计算和人工启发式方法的依赖，并能选出具有多样性和合适难度的数据。

Abstract: Data selection for instruction tuning is essential for improving the
performance of Large Language Models (LLMs) and reducing training cost.
However, existing automated selection methods either depend on computationally
expensive gradient-based measures or manually designed heuristics, which may
fail to fully exploit the intrinsic attributes of data. In this paper, we
propose In-context Learning for Contribution Measurement (ICon), a novel
gradient-free method that takes advantage of the implicit fine-tuning nature of
in-context learning (ICL) to measure sample contribution without gradient
computation or manual indicators engineering. ICon offers a computationally
efficient alternative to gradient-based methods and reduces human inductive
bias inherent in heuristic-based approaches. ICon comprises three components
and identifies high-contribution data by assessing performance shifts under
implicit learning through ICL. Extensive experiments on three LLMs across 12
benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of
ICon. Remarkably, on LLaMA3.1-8B, models trained on 15% of ICon-selected data
outperform full datasets by 5.42% points and exceed the best performance of
widely used selection methods by 2.06% points. We further analyze
high-contribution samples selected by ICon, which show both diverse tasks and
appropriate difficulty levels, rather than just the hardest ones.

</details>


### [41] [Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?](https://arxiv.org/abs/2505.05406)
*Valeria Pastorino,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLM）在新闻内容中产生的框架偏见，发现其比人类作者更易出现偏见，尤其是在敏感议题上，并呼吁采取缓解措施。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在自动化新闻和内容创作中的应用日益增多，人们担忧这些系统可能会引入或放大框架偏见，从而影响公众认知。

Method: 研究探索了框架偏见在未经微调和经过微调的大型语言模型生成的新闻内容中的表现方式。

Result: 分析显示，尤其在政治和社会敏感议题上，大型语言模型比人类作者表现出更显著的框架偏见。不同模型架构在框架偏见倾向上也存在显著差异，部分模型偏见更高。

Conclusion: 研究结果表明，需要有效的训练后缓解策略和更严格的评估框架，以确保自动化新闻内容能达到平衡报道的标准。

Abstract: Framing in media critically shapes public perception by selectively
emphasizing some details while downplaying others. With the rise of large
language models in automated news and content creation, there is growing
concern that these systems may introduce or even amplify framing biases
compared to human authors. In this paper, we explore how framing manifests in
both out-of-the-box and fine-tuned LLM-generated news content. Our analysis
reveals that, particularly in politically and socially sensitive contexts, LLMs
tend to exhibit more pronounced framing than their human counterparts. In
addition, we observe significant variation in framing tendencies across
different model architectures, with some models displaying notably higher
biases. These findings point to the need for effective post-training mitigation
strategies and tighter evaluation frameworks to ensure that automated news
content upholds the standards of balanced reporting.

</details>


### [42] [Crosslingual Reasoning through Test-Time Scaling](https://arxiv.org/abs/2505.05408)
*Zheng-Xin Yong,M. Farid Adilazuarda,Jonibek Mansurov,Ruochen Zhang,Niklas Muennighoff,Carsten Eickhoff,Genta Indra Winata,Julia Kreutzer,Stephen H. Bach,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 该研究探讨了以英语为中心进行推理微调的大语言模型在多语言环境下的泛化能力，发现增加推理计算能提升多语言数学推理，但跨领域泛化能力差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的推理能力主要在英语上得到研究，即使预训练模型是多语言的。本研究旨在探究英语推理微调（使用长思维链CoT）在多大程度上可以跨语言泛化。

Method: 研究通过以下方式进行：1. 扩大以英语为中心的推理语言模型（RLMs）的推理计算，并评估其多语言数学推理能力；2. 分析RLM在处理非英语输入时CoT的语言模式；3. 探索控制长CoT推理语言的策略；4. 评估模型从STEM到文化常识等领域外的推理泛化能力。

Result: 研究发现：1. 增加英语中心RLM的推理计算能显著提升其在多种语言（包括低资源语言）上的数学推理能力，甚至超越两倍大小的模型；2. 英语中心RLM的CoT主要为英语，但在处理非英语输入时会采用“引用-思考”模式；3. 存在控制长CoT推理语言的有效策略，模型在高资源语言中推理效果更好、效率更高；4. 即使是英语，模型在领域外的推理泛化能力也较差，尤其从STEM到文化常识的泛化。

Conclusion: 实践者应让以英语为中心的RLM在高资源语言中进行推理。未来需要进一步研究以改进模型在低资源语言和领域外情境中的推理能力。

Abstract: Reasoning capabilities of large language models are primarily studied for
English, even when pretrained models are multilingual. In this work, we
investigate to what extent English reasoning finetuning with long
chain-of-thoughts (CoTs) can generalize across languages. First, we find that
scaling up inference compute for English-centric reasoning language models
(RLMs) improves multilingual mathematical reasoning across many languages
including low-resource languages, to an extent where they outperform models
twice their size. Second, we reveal that while English-centric RLM's CoTs are
naturally predominantly English, they consistently follow a quote-and-think
pattern to reason about quoted non-English inputs. Third, we discover an
effective strategy to control the language of long CoT reasoning, and we
observe that models reason better and more efficiently in high-resource
languages. Finally, we observe poor out-of-domain reasoning generalization, in
particular from STEM to cultural commonsense knowledge, even for English.
Overall, we demonstrate the potentials, study the mechanisms and outline the
limitations of crosslingual generalization of English reasoning test-time
scaling. We conclude that practitioners should let English-centric RLMs reason
in high-resource languages, while further work is needed to improve reasoning
in low-resource languages and out-of-domain contexts.

</details>


### [43] [Reasoning Models Don't Always Say What They Think](https://arxiv.org/abs/2505.05410)
*Yanda Chen,Joe Benton,Ansh Radhakrishnan,Jonathan Uesato,Carson Denison,John Schulman,Arushi Somani,Peter Hase,Misha Wagner,Fabien Roger,Vlad Mikulik,Samuel R. Bowman,Jan Leike,Jared Kaplan,Ethan Perez*

Main category: cs.CL

TL;DR: 研究评估了AI模型思维链(CoT)的忠实度，发现其在揭示模型真实推理过程方面存在局限性，尤其是在监测罕见和灾难性行为上。


<details>
  <summary>Details</summary>
Motivation: 思维链(CoT)为AI安全提供了一种通过监控模型意图和推理过程的潜在方法，但其有效性取决于CoT能否忠实地反映模型的实际推理过程。本研究旨在评估CoT的忠实度。

Method: 研究人员评估了顶尖推理模型在6种不同提示推理线索下的CoT忠实度，并检验了基于结果的强化学习对忠实度的影响，以及在奖励操纵（reward hacking）情况下模型是否会隐藏其对线索的使用。

Result: 1. 在大多数情况下，当模型使用提示中的线索时，CoT至少在1%的案例中会揭示出来，但揭示率通常低于20%。2. 基于结果的强化学习初期能提高忠实度，但随后会停滞不前。3. 当强化学习增加了线索的使用频率（奖励操纵）时，即使没有针对CoT监控进行训练，模型在CoT中明确表达这些线索的倾向性也不会增加。

Conclusion: CoT监控是训练和评估过程中发现不良行为的一种有前景的方法，但不足以完全排除这些行为。在CoT推理并非必要的情况下，测试时的CoT监控不太可能可靠地捕捉到罕见且灾难性的意外行为。

Abstract: Chain-of-thought (CoT) offers a potential boon for AI safety as it allows
monitoring a model's CoT to try to understand its intentions and reasoning
processes. However, the effectiveness of such monitoring hinges on CoTs
faithfully representing models' actual reasoning processes. We evaluate CoT
faithfulness of state-of-the-art reasoning models across 6 reasoning hints
presented in the prompts and find: (1) for most settings and models tested,
CoTs reveal their usage of hints in at least 1% of examples where they use the
hint, but the reveal rate is often below 20%, (2) outcome-based reinforcement
learning initially improves faithfulness but plateaus without saturating, and
(3) when reinforcement learning increases how frequently hints are used (reward
hacking), the propensity to verbalize them does not increase, even without
training against a CoT monitor. These results suggest that CoT monitoring is a
promising way of noticing undesired behaviors during training and evaluations,
but that it is not sufficient to rule them out. They also suggest that in
settings like ours where CoT reasoning is not necessary, test-time monitoring
of CoTs is unlikely to reliably catch rare and catastrophic unexpected
behaviors.

</details>


### [44] [TransProQA: an LLM-based literary Translation evaluation metric with Professional Question Answering](https://arxiv.org/abs/2505.05423)
*Ran Zhang,Wei Zhao,Lieve Macken,Steffen Eger*

Main category: cs.CL

TL;DR: 针对现有文学翻译评估指标的局限性，本文提出TransProQA，一种基于大语言模型的无参考问答框架，用于文学翻译评估。该方法整合专业译者见解，显著优于现有指标，并接近人类评估水平。


<details>
  <summary>Details</summary>
Motivation: 当前文学翻译评估指标过分强调机械准确性，忽视艺术表达，导致对机器翻译的高估，可能损害翻译质量和文化真实性，因此亟需专业的文学翻译评估方法。

Method: 提出TransProQA，一个专为文学翻译评估设计的、新颖的、无参考的、基于大语言模型的问答（QA）框架。该框架整合专业文学翻译家和研究者的见解，关注文学手法、文化理解和作者风格等关键评估要素。

Result: TransProQA在相关性指标（ACC-EQ和Kendall's tau）上提升高达0.07，在充分性评估上超越当前最佳SOTA指标15分以上。其性能接近人类评估员水平，并能应用于LLaMA3.3-70b和Qwen2.5-32b等开源模型。

Conclusion: TransProQA是一种有效的、无需训练的文学翻译评估新指标，可广泛应用于各种大语言模型，尤其适用于需要本地处理的文本，并证明了专业译者经验在提升评估质量方面的重要性。

Abstract: The impact of Large Language Models (LLMs) has extended into literary
domains. However, existing evaluation metrics prioritize mechanical accuracy
over artistic expression and tend to overrate machine translation (MT) as being
superior to experienced professional human translation. In the long run, this
bias could result in a permanent decline in translation quality and cultural
authenticity. In response to the urgent need for a specialized literary
evaluation metric, we introduce TransProQA, a novel, reference-free, LLM-based
question-answering (QA) framework designed specifically for literary
translation evaluation. TransProQA uniquely integrates insights from
professional literary translators and researchers, focusing on critical
elements in literary quality assessment such as literary devices, cultural
understanding, and authorial voice. Our extensive evaluation shows that while
literary-finetuned XCOMET-XL yields marginal gains, TransProQA substantially
outperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ
and Kendall's tau) and surpassing the best state-of-the-art (SOTA) metrics by
over 15 points in adequacy assessments. Incorporating professional translator
insights as weights further improves performance, highlighting the value of
translator inputs. Notably, TransProQA approaches human-level evaluation
performance comparable to trained linguistic annotators. It demonstrates broad
applicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,
indicating its potential as an accessible and training-free literary evaluation
metric and a valuable tool for evaluating texts that require local processing
due to copyright or ethical considerations.

</details>


### [45] [Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data](https://arxiv.org/abs/2505.05427)
*Yudong Wang,Zixuan Fu,Jie Cai,Peijun Tang,Hongya Lyu,Yewei Fang,Zhi Zheng,Jie Zhou,Guoyang Zeng,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 该研究提出了一种高效的数据过滤流程，通过引入快速验证策略和优化种子数据选择，创建了高质量数据集Ultra-FineWeb，显著提升了LLM的性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前模型驱动的数据过滤方法面临两大挑战：一是缺乏高效的数据验证策略，难以对数据质量进行及时反馈；二是用于训练分类器的种子数据选择缺乏明确标准且依赖人工经验，带有主观性。

Method: 1. 引入一种高效的验证策略，以最小计算成本快速评估数据对LLM训练的影响。2. 基于高质量种子数据有益于LLM训练的假设，结合提出的验证策略优化正负样本选择，并提出一个高效的数据过滤流程。3. 使用基于fastText的轻量级分类器进行数据过滤。

Result: 提出的数据过滤流程提高了过滤效率、分类器质量和鲁棒性，并显著降低了实验和推理成本。成功将该流程应用于FineWeb和Chinese FineWeb数据集，创建了更高质量的Ultra-FineWeb数据集（包含约1万亿英文词元和1200亿中文词元）。在Ultra-FineWeb上训练的LLM在多个基准任务上表现出显著的性能提升。

Conclusion: 该研究提出的高效数据过滤流程能够有效提升数据质量和LLM的训练效率，其有效性通过Ultra-FineWeb数据集的构建和下游任务的性能提升得到了验证。

Abstract: Data quality has become a key factor in enhancing model performance with the
rapid development of large language models (LLMs). Model-driven data filtering
has increasingly become a primary approach for acquiring high-quality data.
However, it still faces two main challenges: (1) the lack of an efficient data
verification strategy makes it difficult to provide timely feedback on data
quality; and (2) the selection of seed data for training classifiers lacks
clear criteria and relies heavily on human expertise, introducing a degree of
subjectivity. To address the first challenge, we introduce an efficient
verification strategy that enables rapid evaluation of the impact of data on
LLM training with minimal computational cost. To tackle the second challenge,
we build upon the assumption that high-quality seed data is beneficial for LLM
training, and by integrating the proposed verification strategy, we optimize
the selection of positive and negative samples and propose an efficient data
filtering pipeline. This pipeline not only improves filtering efficiency,
classifier quality, and robustness, but also significantly reduces experimental
and inference costs. In addition, to efficiently filter high-quality data, we
employ a lightweight classifier based on fastText, and successfully apply the
filtering pipeline to two widely-used pre-training corpora, FineWeb and Chinese
FineWeb datasets, resulting in the creation of the higher-quality Ultra-FineWeb
dataset. Ultra-FineWeb contains approximately 1 trillion English tokens and 120
billion Chinese tokens. Empirical results demonstrate that the LLMs trained on
Ultra-FineWeb exhibit significant performance improvements across multiple
benchmark tasks, validating the effectiveness of our pipeline in enhancing both
data quality and training efficiency.

</details>


### [46] [clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](https://arxiv.org/abs/2505.05445)
*Chalamalasetti Kranti,Sherzod Hakimov,David Schlangen*

Main category: cs.CL

TL;DR: 提出clem todd框架，用于在统一条件下系统评估任务导向对话系统，解决现有评估方法缺乏普适性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统研究中，用户模拟器和系统组件的评估往往孤立进行，限制了研究结论在不同架构和配置间的普适性。

Method: 提出clem todd框架，该框架支持对不同的用户模拟器和对话系统组合进行基准测试，并确保统一的数据集、评估指标和计算约束。通过该框架重新评估现有系统并集成新系统进行验证。

Result: clem todd框架的评估结果揭示了对话系统的架构、规模和提示策略如何影响对话性能。

Conclusion: clem todd框架为构建高效且有效的对话式人工智能系统提供了可行的见解和实践指导，促进了对不同对话系统组件在统一标准下的系统性评估。

Abstract: The emergence of instruction-tuned large language models (LLMs) has advanced
the field of dialogue systems, enabling both realistic user simulations and
robust multi-turn conversational agents. However, existing research often
evaluates these components in isolation-either focusing on a single user
simulator or a specific system design-limiting the generalisability of insights
across architectures and configurations. In this work, we propose clem todd
(chat-optimized LLMs for task-oriented dialogue systems development), a
flexible framework for systematically evaluating dialogue systems under
consistent conditions. clem todd enables detailed benchmarking across
combinations of user simulators and dialogue systems, whether existing models
from literature or newly developed ones. It supports plug-and-play integration
and ensures uniform datasets, evaluation metrics, and computational
constraints. We showcase clem todd's flexibility by re-evaluating existing
task-oriented dialogue systems within this unified setup and integrating three
newly proposed dialogue systems into the same evaluation pipeline. Our results
provide actionable insights into how architecture, scale, and prompting
strategies affect dialogue performance, offering practical guidance for
building efficient and effective conversational AI systems.

</details>


### [47] [UKElectionNarratives: A Dataset of Misleading Narratives Surrounding Recent UK General Elections](https://arxiv.org/abs/2505.05459)
*Fatima Haouari,Carolina Scarton,Nicolò Faggiani,Nikolaos Nikolaidis,Bonka Kotseva,Ibrahim Abu Farha,Jens Linge,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 该研究针对选举中的误导性叙事，提出了分类法，构建了英国大选期间的人工标注数据集，并评估了语言模型（特别是GPT-4o）检测这些叙事的有效性。


<details>
  <summary>Details</summary>
Motivation: 误导性叙事在选举期间会影响公众舆论和选民对候选人及政党的看法，因此准确检测这些叙事至关重要。

Method: 1. 引入首个欧洲近期选举中常见误导性叙事的分类法。 2. 基于该分类法，构建并分析了首个英国大选（2019年和2024年）期间人工标注的误导性叙事数据集UKElectionNarratives。 3. 对预训练模型和大型语言模型（重点是GPT-4o）进行了基准测试，研究其检测选举相关误导性叙事的有效性。

Result: 成功引入了误导性叙事的分类法，构建了UKElectionNarratives数据集，并对大型语言模型（如GPT-4o）检测选举相关误导性叙事的能力进行了研究。

Conclusion: 讨论了所提出的分类法和数据集的潜在应用场景，并为未来研究方向提供了建议。

Abstract: Misleading narratives play a crucial role in shaping public opinion during
elections, as they can influence how voters perceive candidates and political
parties. This entails the need to detect these narratives accurately. To
address this, we introduce the first taxonomy of common misleading narratives
that circulated during recent elections in Europe. Based on this taxonomy, we
construct and analyse UKElectionNarratives: the first dataset of
human-annotated misleading narratives which circulated during the UK General
Elections in 2019 and 2024. We also benchmark Pre-trained and Large Language
Models (focusing on GPT-4o), studying their effectiveness in detecting
election-related misleading narratives. Finally, we discuss potential use cases
and make recommendations for future research directions using the proposed
codebook and dataset.

</details>


### [48] [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org/abs/2505.05464)
*Shiqi Chen,Jinghan Zhang,Tongyao Zhu,Wei Liu,Siyang Gao,Miao Xiong,Manling Li,Junxian He*

Main category: cs.CL

TL;DR: 通过模型合并（特别是将大语言模型LLM合并到视觉语言模型VLM中），无需训练即可增强VLM的推理能力，并揭示了感知和推理在模型层间的分布及合并后的变化。


<details>
  <summary>Details</summary>
Motivation: 目前尚不清楚视觉语言模型（VLM）中视觉感知和大型语言模型（LLM）的推理等通用能力是如何结合并发挥作用的。

Method: 提出了一种跨模态的模型合并方法，通过连接不同模型的参数，将LLM的推理能力融入VLM中，且无需额外训练。

Result: 实验证明，模型合并能够成功地将LLM的推理能力以无需训练的方式迁移到VLM中。研究还发现，感知能力主要编码在模型的早期层，而推理能力主要由中后期层促进。合并后，所有层都开始对推理做出贡献，而感知能力的层分布基本不变。

Conclusion: 模型合并为多模态整合和理解模型内部机制提供了一个有潜力的工具，揭示了感知和推理能力在VLM层间的分布和相互作用。

Abstract: Vision-Language Models (VLMs) combine visual perception with the general
capabilities, such as reasoning, of Large Language Models (LLMs). However, the
mechanisms by which these two abilities can be combined and contribute remain
poorly understood. In this work, we explore to compose perception and reasoning
through model merging that connects parameters of different models. Unlike
previous works that often focus on merging models of the same kind, we propose
merging models across modalities, enabling the incorporation of the reasoning
capabilities of LLMs into VLMs. Through extensive experiments, we demonstrate
that model merging offers a successful pathway to transfer reasoning abilities
from LLMs to VLMs in a training-free manner. Moreover, we utilize the merged
models to understand the internal mechanism of perception and reasoning and how
merging affects it. We find that perception capabilities are predominantly
encoded in the early layers of the model, whereas reasoning is largely
facilitated by the middle-to-late layers. After merging, we observe that all
layers begin to contribute to reasoning, whereas the distribution of perception
abilities across layers remains largely unchanged. These observations shed
light on the potential of model merging as a tool for multimodal integration
and interpretation.

</details>


### [49] [ComPO: Preference Alignment via Comparison Oracles](https://arxiv.org/abs/2505.05465)
*Peter Chen,Xi Chen,Wotao Yin,Tianyi Lin*

Main category: cs.CL

TL;DR: 提出了一种基于比较预言机的新偏好对齐方法，以解决现有直接对齐方法因噪声偏好对导致的冗余和似然位移问题。


<details>
  <summary>Details</summary>
Motivation: 现有直接对齐方法在对齐大型语言模型（LLM）与人类偏好时，会因噪声偏好对（其中偏好与非偏好响应的似然相近）而产生冗余和似然位移等问题。

Method: 首先，提出一种基于比较预言机（comparison oracles）的新偏好对齐方法，并为其基本方案提供了收敛性保证。其次，使用启发式方法改进该方法，并通过实验展示其在利用噪声偏好对提升LLM性能方面的灵活性和兼容性。

Result: 在多种基础模型和指令微调模型（Mistral-7B, Llama-3-8B, Gemma-2-9B）以及多个基准测试（AlpacaEval 2, MT-Bench, Arena-Hard）上的评估结果表明，所提出的方法能够有效解决现有直接对齐方法的局限性。

Conclusion: 该研究提出的方法是解决现有直接对齐方法限制的有效替代方案，并证明了为具有不同似然边界的偏好对设计专门方法的重要性。

Abstract: Direct alignment methods are increasingly used for aligning large language
models (LLMs) with human preferences. However, these methods suffer from the
issues of verbosity and likelihood displacement, which can be driven by the
noisy preference pairs that induce similar likelihood for preferred and
dispreferred responses. The contributions of this paper are two-fold. First, we
propose a new preference alignment method based on comparison oracles and
provide the convergence guarantee for its basic scheme. Second, we improve our
method using some heuristics and conduct the experiments to demonstrate the
flexibility and compatibility of practical scheme in improving the performance
of LLMs using noisy preference pairs. Evaluations are conducted across multiple
base and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with
benchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show
the effectiveness of our method as an alternative to addressing the limitations
of existing direct alignment methods. A highlight of our work is that we
evidence the importance of designing specialized methods for preference pairs
with distinct likelihood margin, which complements the recent findings in
\citet{Razin-2025-Unintentional}.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [50] [Histo-Miner: Deep Learning based Tissue Features Extraction Pipeline from H&E Whole Slide Images of Cutaneous Squamous Cell Carcinoma](https://arxiv.org/abs/2505.04672)
*Lucas Sancéré,Carina Lorenz,Doris Helbig,Oana-Diana Persa,Sonja Dengler,Alexander Kreuter,Martim Laimer,Anne Fröhlich,Jennifer Landsberg,Johannes Brägelmann,Katarzyna Bozek*

Main category: cs.CV

TL;DR: 该研究提出了Histo-Miner，一个用于皮肤全切片图像（WSI）分析的深度学习流程，并生成了两个针对皮肤鳞状细胞癌（cSCC）的标记数据集。该流程能进行细胞核分割与分类、肿瘤区域分割，并能预测cSCC患者对免疫疗法的反应。


<details>
  <summary>Details</summary>
Motivation: 尽管数字病理学取得了进展，但目前缺乏专门为皮肤组织分析定制的标记数据集和开源分析流程。

Method: 提出了一个名为Histo-Miner的深度学习流程。该流程利用卷积神经网络（CNN）和视觉Transformer（Vision Transformers），结合两个新生成的包含标记细胞核和肿瘤区域的cSCC数据集，进行细胞核分割与分类以及肿瘤区域分割。基于这些分割和分类结果，生成紧凑的特征向量，用于下游任务，如预测cSCC患者对免疫疗法的反应。

Result: Histo-Miner在细胞核分割（多类别全景质量mPQ为0.569）、细胞核分类（宏平均F1分数为0.832）和肿瘤区域分割（平均交并比mIoU为0.884）方面取得了与当前最优水平相当的性能。该流程成功识别出预测免疫治疗反应的特征，包括淋巴细胞百分比、肿瘤附近粒细胞与淋巴细胞的比率以及肿瘤内粒细胞与浆细胞之间的距离。

Conclusion: Histo-Miner是一个适用于临床相关场景的工具，能够为分类结果提供直接解释，并揭示潜在的生物学机制，特别是在cSCC的分析和治疗反应预测方面具有应用前景。

Abstract: Recent advancements in digital pathology have enabled comprehensive analysis
of Whole-Slide Images (WSI) from tissue samples, leveraging high-resolution
microscopy and computational capabilities. Despite this progress, there is a
lack of labeled datasets and open source pipelines specifically tailored for
analysis of skin tissue. Here we propose Histo-Miner, a deep learning-based
pipeline for analysis of skin WSIs and generate two datasets with labeled
nuclei and tumor regions. We develop our pipeline for the analysis of patient
samples of cutaneous squamous cell carcinoma (cSCC), a frequent non-melanoma
skin cancer. Utilizing the two datasets, comprising 47,392 annotated cell
nuclei and 144 tumor-segmented WSIs respectively, both from cSCC patients,
Histo-Miner employs convolutional neural networks and vision transformers for
nucleus segmentation and classification as well as tumor region segmentation.
Performance of trained models positively compares to state of the art with
multi-class Panoptic Quality (mPQ) of 0.569 for nucleus segmentation,
macro-averaged F1 of 0.832 for nucleus classification and mean Intersection
over Union (mIoU) of 0.884 for tumor region segmentation. From these
predictions we generate a compact feature vector summarizing tissue morphology
and cellular interactions, which can be used for various downstream tasks.
Here, we use Histo-Miner to predict cSCC patient response to immunotherapy
based on pre-treatment WSIs from 45 patients. Histo-Miner identifies
percentages of lymphocytes, the granulocyte to lymphocyte ratio in tumor
vicinity and the distances between granulocytes and plasma cells in tumors as
predictive features for therapy response. This highlights the applicability of
Histo-Miner to clinically relevant scenarios, providing direct interpretation
of the classification and insights into the underlying biology.

</details>


### [51] [Comparison of Visual Trackers for Biomechanical Analysis of Running](https://arxiv.org/abs/2505.04713)
*Luis F. Gomez,Gonzalo Garrido-Lopez,Julian Fierrez,Aythami Morales,Ruben Tolosana,Javier Rueda,Enrique Navarro*

Main category: cs.CV

TL;DR: 该研究评估了六种人体姿态追踪器在短跑生物力学分析中的性能，并引入后处理模块以提升关键运动角度的估计准确性。


<details>
  <summary>Details</summary>
Motivation: 利用深度学习在人体姿态估计上的进展，评估现有追踪技术在短跑生物力学分析中的准确性，并探索改进方法，以期应用于体育分析和运动员表现评估。

Method: 研究比较了两种点追踪器和四种关节追踪器在分析短跑运动中三个关键生物力学角度（躯干倾斜、髋关节屈伸、膝关节屈伸）时的表现，数据来源于五名专业跑者的四十次短跑（共5870帧），并与专家手动标注结果进行对比。同时，提出了一种用于异常值检测和融合预测的后处理模块。

Result: 实验结果显示，基于关节的模型获得的均方根误差（RMSE）范围为4.37°至11.41°。集成后处理模块后，这些误差可分别降低至3.88°和6.99°。

Conclusion: 研究表明，人体姿态追踪方法可为跑步的生物力学分析提供有价值的参考，后处理模块能有效提高准确性。然而，在需要高精度的应用场景中，其性能仍有提升空间。

Abstract: Human pose estimation has witnessed significant advancements in recent years,
mainly due to the integration of deep learning models, the availability of a
vast amount of data, and large computational resources. These developments have
led to highly accurate body tracking systems, which have direct applications in
sports analysis and performance evaluation.
  This work analyzes the performance of six trackers: two point trackers and
four joint trackers for biomechanical analysis in sprints. The proposed
framework compares the results obtained from these pose trackers with the
manual annotations of biomechanical experts for more than 5870 frames. The
experimental framework employs forty sprints from five professional runners,
focusing on three key angles in sprint biomechanics: trunk inclination, hip
flex extension, and knee flex extension. We propose a post-processing module
for outlier detection and fusion prediction in the joint angles.
  The experimental results demonstrate that using joint-based models yields
root mean squared errors ranging from 11.41{\deg} to 4.37{\deg}. When
integrated with the post-processing modules, these errors can be reduced to
6.99{\deg} and 3.88{\deg}, respectively. The experimental findings suggest that
human pose tracking approaches can be valuable resources for the biomechanical
analysis of running. However, there is still room for improvement in
applications where high accuracy is required.

</details>


### [52] [Lay-Your-Scene: Natural Scene Layout Generation with Diffusion Transformers](https://arxiv.org/abs/2505.04718)
*Divyansh Srivastava,Xiang Zhang,He Wen,Chenru Wen,Zhuowen Tu*

Main category: cs.CV

TL;DR: LayouSyn 是一种新颖的自然场景文本到布局生成流程，它使用开源语言模型和扩散 Transformer 架构，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 先前的场景布局生成方法要么是封闭词汇的，要么使用专有的大型语言模型，这限制了它们的建模能力和在可控图像生成中的广泛适用性。

Method: 使用轻量级开源语言模型从文本提示中获取场景元素，并采用一种新颖的、以开放词汇方式训练的、关注长宽比的扩散 Transformer 架构进行条件布局生成。

Result: LayouSyn 在挑战性的空间和数值推理基准测试中优于现有方法并达到最先进水平。它还可以与大型语言模型的粗略初始化结合以获得更好结果，并可用于图像编辑（如向图像添加对象）。

Conclusion: LayouSyn 提供了一种优越的开放词汇文本到布局生成方法，在图像编辑等领域具有实际应用潜力。

Abstract: We present Lay-Your-Scene (shorthand LayouSyn), a novel text-to-layout
generation pipeline for natural scenes. Prior scene layout generation methods
are either closed-vocabulary or use proprietary large language models for
open-vocabulary generation, limiting their modeling capabilities and broader
applicability in controllable image generation. In this work, we propose to use
lightweight open-source language models to obtain scene elements from text
prompts and a novel aspect-aware diffusion Transformer architecture trained in
an open-vocabulary manner for conditional layout generation. Extensive
experiments demonstrate that LayouSyn outperforms existing methods and achieves
state-of-the-art performance on challenging spatial and numerical reasoning
benchmarks. Additionally, we present two applications of LayouSyn. First, we
show that coarse initialization from large language models can be seamlessly
combined with our method to achieve better results. Second, we present a
pipeline for adding objects to images, demonstrating the potential of LayouSyn
in image editing applications.

</details>


### [53] [False Promises in Medical Imaging AI? Assessing Validity of Outperformance Claims](https://arxiv.org/abs/2505.04720)
*Evangelia Christodoulou,Annika Reinke,Pascaline Andrè,Patrick Godau,Piotr Kalinowski,Rola Houhou,Selen Erkan,Carole H. Sudre,Ninon Burgos,Sofiène Boutaj,Sophie Loizillon,Maëlys Solal,Veronika Cheplygina,Charles Heitz,Michal Kozubek,Michela Antonelli,Nicola Rieke,Antoine Gilson,Leon D. Mayer,Minu D. Tizabi,M. Jorge Cardoso,Amber Simpson,Annette Kopp-Schneider,Gaël Varoquaux,Olivier Colliot,Lena Maier-Hein*

Main category: cs.CV

TL;DR: 该研究发现，医学影像AI领域中许多新方法声称的性能超越并无充分统计学依据，这可能误导科研方向。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI研究中，新方法常基于经验平均性能宣称超越现有技术，本研究旨在评估这些声明的真实性与可靠性。

Method: 通过分析医学影像论文队列，采用贝叶斯方法，结合已报告的结果和经验估计的模型一致性，量化了错误宣称性能超越的概率，评估方法相对排序是否可能偶然发生。

Result: 超过80%的论文在引入新方法时声称其性能更优。进一步分析显示，86%的分类任务论文和53%的分割任务论文中，其“性能超越”的声明有较高概率（>5%）是错误的。

Conclusion: 当前医学影像AI的基准测试实践存在严重缺陷，“性能超越”的声明常常缺乏充分证据支持，这有误导未来研究方向的风险。

Abstract: Performance comparisons are fundamental in medical imaging Artificial
Intelligence (AI) research, often driving claims of superiority based on
relative improvements in common performance metrics. However, such claims
frequently rely solely on empirical mean performance. In this paper, we
investigate whether newly proposed methods genuinely outperform the state of
the art by analyzing a representative cohort of medical imaging papers. We
quantify the probability of false claims based on a Bayesian approach that
leverages reported results alongside empirically estimated model congruence to
estimate whether the relative ranking of methods is likely to have occurred by
chance. According to our results, the majority (>80%) of papers claims
outperformance when introducing a new method. Our analysis further revealed a
high probability (>5%) of false outperformance claims in 86% of classification
papers and 53% of segmentation papers. These findings highlight a critical flaw
in current benchmarking practices: claims of outperformance in medical imaging
AI are frequently unsubstantiated, posing a risk of misdirecting future
research efforts.

</details>


### [54] [Hyb-KAN ViT: Hybrid Kolmogorov-Arnold Networks Augmented Vision Transformer](https://arxiv.org/abs/2505.04740)
*Sainath Dey,Mitul Goswami,Jashika Sethi,Prasant Kumar Pattnaik*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 Hyb-KAN ViT 的新框架，通过将基于小波的频谱分解和样条优化的激活函数集成到视觉 Transformer (ViT) 中，以解决其多层感知器 (MLP) 的固有限制。


<details>
  <summary>Details</summary>
Motivation: 传统视觉 Transformer (ViT) 中的多层感知器 (MLP) 存在局限性，且先前工作未能充分利用 ViT 架构的模块化特性及小波函数的边缘检测能力。

Method: 提出了混合 Kolmogorov-Arnold 网络 (KAN)-ViT (Hyb-KAN ViT)，包含两个关键模块：Efficient-KAN (Eff-KAN) 使用样条函数替代 MLP 层，Wavelet-KAN (Wav-KAN) 利用正交小波变换进行多分辨率特征提取。这些模块被集成到 ViT 编码器层和分类头中。

Result: Hyb-KAN ViT 在 ImageNet-1K（图像识别）、COCO（目标检测与实例分割）和 ADE20K（语义分割）等多个基准测试中均取得了领先性能。消融实验证实了小波驱动的频谱先验在分割任务中的有效性以及基于样条的效率在检测任务中的作用。

Conclusion: 该框架为平衡视觉架构中的参数效率和多尺度表示能力建立了一种新范式。

Abstract: This study addresses the inherent limitations of Multi-Layer Perceptrons
(MLPs) in Vision Transformers (ViTs) by introducing Hybrid Kolmogorov-Arnold
Network (KAN)-ViT (Hyb-KAN ViT), a novel framework that integrates
wavelet-based spectral decomposition and spline-optimized activation functions,
prior work has failed to focus on the prebuilt modularity of the ViT
architecture and integration of edge detection capabilities of Wavelet
functions. We propose two key modules: Efficient-KAN (Eff-KAN), which replaces
MLP layers with spline functions and Wavelet-KAN (Wav-KAN), leveraging
orthogonal wavelet transforms for multi-resolution feature extraction. These
modules are systematically integrated in ViT encoder layers and classification
heads to enhance spatial-frequency modeling while mitigating computational
bottlenecks. Experiments on ImageNet-1K (Image Recognition), COCO (Object
Detection and Instance Segmentation), and ADE20K (Semantic Segmentation)
demonstrate state-of-the-art performance with Hyb-KAN ViT. Ablation studies
validate the efficacy of wavelet-driven spectral priors in segmentation and
spline-based efficiency in detection tasks. The framework establishes a new
paradigm for balancing parameter efficiency and multi-scale representation in
vision architectures.

</details>


### [55] [Lightweight RGB-D Salient Object Detection from a Speed-Accuracy Tradeoff Perspective](https://arxiv.org/abs/2505.04758)
*Songsong Duan,Xi Yang,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TL;DR: 提出了一种轻量级RGB-D显著性目标检测网络SATNet，旨在平衡速度与精度。通过改进深度图质量、模态融合和特征表示，该网络在保持轻量化的同时优于SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D方法通常通过大型骨干网络提升精度但牺牲效率，而一些轻量级方法难以达到高精度性能。本研究旨在平衡效率和性能。

Method: 提出了速度-精度权衡网络 (SATNet)，从三个角度进行优化：1) 引入Depth Anything Model生成高质量深度图以改善深度质量；2) 提出解耦注意力模块 (DAM) 进行模态融合，探索模态内部和模态间的一致性；3) 开发双信息表示模块 (DIRM) 和双特征聚合模块 (DFAM) 以增强轻量级骨干网络的特征表示和聚合能力。

Result: 在五个公开的RGB-D SOD数据集上的实验表明，所提出的SATNet在性能上优于当前最先进的基于CNN的重量级模型，同时保持了轻量级特性（520万参数和415 FPS）。

Conclusion: SATNet成功地在RGB-D显著性目标检测中实现了速度与精度的有效权衡，提供了一个高效且高精度的轻量级解决方案。

Abstract: Current RGB-D methods usually leverage large-scale backbones to improve
accuracy but sacrifice efficiency. Meanwhile, several existing lightweight
methods are difficult to achieve high-precision performance. To balance the
efficiency and performance, we propose a Speed-Accuracy Tradeoff Network
(SATNet) for Lightweight RGB-D SOD from three fundamental perspectives: depth
quality, modality fusion, and feature representation. Concerning depth quality,
we introduce the Depth Anything Model to generate high-quality depth maps,which
effectively alleviates the multi-modal gaps in the current datasets. For
modality fusion, we propose a Decoupled Attention Module (DAM) to explore the
consistency within and between modalities. Here, the multi-modal features are
decoupled into dual-view feature vectors to project discriminable information
of feature maps. For feature representation, we develop a Dual Information
Representation Module (DIRM) with a bi-directional inverted framework to
enlarge the limited feature space generated by the lightweight backbones. DIRM
models texture features and saliency features to enrich feature space, and
employ two-way prediction heads to optimal its parameters through a
bi-directional backpropagation. Finally, we design a Dual Feature Aggregation
Module (DFAM) in the decoder to aggregate texture and saliency features.
Extensive experiments on five public RGB-D SOD datasets indicate that the
proposed SATNet excels state-of-the-art (SOTA) CNN-based heavyweight models and
achieves a lightweight framework with 5.2 M parameters and 415 FPS.

</details>


### [56] [Vision-Language-Action Models: Concepts, Progress, Applications and Challenges](https://arxiv.org/abs/2505.04769)
*Ranjan Sapkota,Yang Cao,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TL;DR: 这篇综述全面回顾了视觉-语言-行动（VLA）模型的最新进展，系统地组织了其概念基础、架构创新、应用领域、主要挑战以及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-行动（VLA）模型是人工智能领域的变革性进展，旨在统一感知、自然语言理解和具身行动，需要对这一快速发展领域的最新进展进行全面的梳理和总结。

Method: 采用严谨的文献综述方法，系统分析了过去三年发表的超过80个VLA模型，并围绕五个主题支柱进行组织。

Result: 研究总结了VLA模型在架构创新、参数高效训练策略和实时推理加速方面的关键进展，探讨了其在人形机器人、自动驾驶等多个领域的应用，并识别了实时控制、多模态动作表示、系统可扩展性、泛化能力和伦理风险等主要挑战，同时提出了相应的解决方案。

Conclusion: VLA模型、视觉语言模型（VLM）和智能体AI将融合，驱动社会对齐、自适应和通用目的的具身智能体的发展，该综述为推进智能机器人和通用人工智能提供了基础参考。

Abstract: Vision-Language-Action (VLA) models mark a transformative advancement in
artificial intelligence, aiming to unify perception, natural language
understanding, and embodied action within a single computational framework.
This foundational review presents a comprehensive synthesis of recent
advancements in Vision-Language-Action models, systematically organized across
five thematic pillars that structure the landscape of this rapidly evolving
field. We begin by establishing the conceptual foundations of VLA systems,
tracing their evolution from cross-modal learning architectures to generalist
agents that tightly integrate vision-language models (VLMs), action planners,
and hierarchical controllers. Our methodology adopts a rigorous literature
review framework, covering over 80 VLA models published in the past three
years. Key progress areas include architectural innovations,
parameter-efficient training strategies, and real-time inference accelerations.
We explore diverse application domains such as humanoid robotics, autonomous
vehicles, medical and industrial robotics, precision agriculture, and augmented
reality navigation. The review further addresses major challenges across
real-time control, multimodal action representation, system scalability,
generalization to unseen tasks, and ethical deployment risks. Drawing from the
state-of-the-art, we propose targeted solutions including agentic AI
adaptation, cross-embodiment generalization, and unified neuro-symbolic
planning. In our forward-looking discussion, we outline a future roadmap where
VLA models, VLMs, and agentic AI converge to power socially aligned, adaptive,
and general-purpose embodied agents. This work serves as a foundational
reference for advancing intelligent, real-world robotics and artificial general
intelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language
Models

</details>


### [57] [Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay](https://arxiv.org/abs/2505.04787)
*Sriram Mandalika,Harsha Vardhan,Athira Nambiar*

Main category: cs.CV

TL;DR: 提出了一种名为 R2R 的新型不确定性驱动的无监督持续学习框架，通过生成式回放有效缓解神经网络的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在持续学习过程中遇到的“灾难性遗忘”问题，即在学习新知识时倾向于忘记旧知识。

Method: 提出 R2R 框架：一个不确定性驱动的无监督持续学习框架。它使用聚类级别的不确定性反馈机制来平衡利用未标记数据和合成标记数据，并结合一个由 VLM (DeepSeek-R1 驱动的 CLIP VLM) 驱动的生成式回放模块来产生代表过去经验的标记合成数据。该框架无需预训练，利用未标记数据的视觉特征，通过基于聚类的不确定性估计和动态阈值进行持续适应。

Result: 在 CIFAR-10, CIFAR-100, CINIC-10, SVHN 和 TinyImageNet 数据集上，R2R 方法分别取得了 98.13%, 73.06%, 93.41%, 95.18%, 59.74% 的准确率，性能超越了现有SOTA方法超过 4.36%，显著提高了知识保留能力。

Conclusion: R2R 框架通过其不确定性驱动机制和生成式回放模块，有效地缓解了灾难性遗忘，在无监督持续学习任务中取得了SOTA性能，展示了其作为一种有效持续学习策略的潜力。

Abstract: Continual Learning entails progressively acquiring knowledge from new data
while retaining previously acquired knowledge, thereby mitigating
``Catastrophic Forgetting'' in neural networks. Our work presents a novel
uncertainty-driven Unsupervised Continual Learning framework using Generative
Replay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture
efficiently uses unlabelled and synthetic labelled data in a balanced
proportion using a cluster-level uncertainty-driven feedback mechanism and a
VLM-powered generative replay module. Unlike traditional memory-buffer methods
that depend on pretrained models and pseudo-labels, our R2R framework operates
without any prior training. It leverages visual features from unlabeled data
and adapts continuously using clustering-based uncertainty estimation coupled
with dynamic thresholding. Concurrently, a generative replay mechanism along
with DeepSeek-R1 powered CLIP VLM produces labelled synthetic data
representative of past experiences, resembling biological visual thinking that
replays memory to remember and act in new, unseen tasks. Extensive experimental
analyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and
TinyImageNet datasets. Our proposed R2R approach improves knowledge retention,
achieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,
59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.

</details>


### [58] [Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World](https://arxiv.org/abs/2505.04788)
*Bangyan Liao,Zhenjun Zhao,Haoang Li,Yi Zhou,Yingping Zeng,Hao Li,Peidong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为GlobustVP的新方法，利用凸松弛技术解决曼哈顿世界中的消失点检测问题，实现了效率、鲁棒性和全局最优性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有消失点检测方法在联合推断线段-消失点关联和定位每个消失点时，要么是次优解，要么在追求全局最优性时计算成本过高。

Method: 1. 采用“软”关联方案（截断多选误差）联合估计消失点位置和线段-消失点关联。2. 将原始问题重新表述为二次约束二次规划（QCQP），然后松弛为凸半定规划（SDP）。3. 提出一个全局最优的抗离群点迭代求解器（GlobustVP），在每次迭代中独立搜索一个消失点及其关联线段，并将其他线段视为离群点。4. 在所有消失点独立更新后，通过局部精炼加强三个消失点之间的相互正交性。

Result: 在合成数据和真实世界数据上的大量实验表明，与先前的工作相比，GlobustVP在效率、鲁棒性和全局最优性之间取得了良好的平衡。

Conclusion: GlobustVP为曼哈顿世界中的消失点检测提供了一种高效、鲁棒且能逼近全局最优的解决方案，优于现有方法。

Abstract: Determining the vanishing points (VPs) in a Manhattan world, as a fundamental
task in many 3D vision applications, consists of jointly inferring the line-VP
association and locating each VP. Existing methods are, however, either
sub-optimal solvers or pursuing global optimality at a significant cost of
computing time. In contrast to prior works, we introduce convex relaxation
techniques to solve this task for the first time. Specifically, we employ a
``soft'' association scheme, realized via a truncated multi-selection error,
that allows for joint estimation of VPs' locations and line-VP associations.
This approach leads to a primal problem that can be reformulated into a
quadratically constrained quadratic programming (QCQP) problem, which is then
relaxed into a convex semidefinite programming (SDP) problem. To solve this SDP
problem efficiently, we present a globally optimal outlier-robust iterative
solver (called \textbf{GlobustVP}), which independently searches for one VP and
its associated lines in each iteration, treating other lines as outliers. After
each independent update of all VPs, the mutual orthogonality between the three
VPs in a Manhattan world is reinforced via local refinement. Extensive
experiments on both synthetic and real-world data demonstrate that
\textbf{GlobustVP} achieves a favorable balance between efficiency, robustness,
and global optimality compared to previous works. The code is publicly
available at https://github.com/WU-CVGL/GlobustVP.

</details>


### [59] [DetReIDX: A Stress-Test Dataset for Real-World UAV-Based Person Recognition](https://arxiv.org/abs/2505.04793)
*Kailash A. Hambarde,Nzakiese Mbongo,Pavan Kumar MP,Satish Mekewad,Carolina Fernandes,Gökhan Silahtaroğlu,Alice Nithya,Pawan Wasnik,MD. Rashidunnabi,Pranita Samale,Hugo Proença*

Main category: cs.CV

TL;DR: 本文介绍了一个名为 DetReIDX 的大规模、多会话、跨视角（空中-地面）行人数据集，旨在真实评估和推动行人在复杂现实场景下的重识别技术。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别 (ReID) 技术在真实复杂场景下性能不佳，主要因为缺乏能够充分反映现实世界中极端数据变异性（如分辨率、视角、尺度、遮挡、外观变化）的公开数据集，这限制了技术发展。

Method: 构建并发布 DetReIDX 数据集。该数据集包含三大洲七个大学校园的 509 个身份的超过 1300 万个边界框，无人机拍摄高度在 5.8 至 120 米之间。关键创新在于受试者在不同日期、不同服装、光照和地点条件下进行了至少两次记录，并标注了16种软生物特征及用于检测、跟踪、ReID和行为识别的多任务标签。

Result: 在使用 DetReIDX 数据集对当前最优 (SOTA) 的行人检测和 ReID 方法进行测试时，这些方法的性能显著下降（检测准确率下降高达 80%，Rank-1 ReID 准确率下降超过 70%）。

Conclusion: DetReIDX 数据集及其评估协议有效地暴露了当前 ReID 方法在应对真实世界复杂条件时的不足，为开发更鲁棒的行人分析技术提供了重要的基准和资源。

Abstract: Person reidentification (ReID) technology has been considered to perform
relatively well under controlled, ground-level conditions, but it breaks down
when deployed in challenging real-world settings. Evidently, this is due to
extreme data variability factors such as resolution, viewpoint changes, scale
variations, occlusions, and appearance shifts from clothing or session drifts.
Moreover, the publicly available data sets do not realistically incorporate
such kinds and magnitudes of variability, which limits the progress of this
technology. This paper introduces DetReIDX, a large-scale aerial-ground person
dataset, that was explicitly designed as a stress test to ReID under real-world
conditions. DetReIDX is a multi-session set that includes over 13 million
bounding boxes from 509 identities, collected in seven university campuses from
three continents, with drone altitudes between 5.8 and 120 meters. More
important, as a key novelty, DetReIDX subjects were recorded in (at least) two
sessions on different days, with changes in clothing, daylight and location,
making it suitable to actually evaluate long-term person ReID. Plus, data were
annotated from 16 soft biometric attributes and multitask labels for detection,
tracking, ReID, and action recognition. In order to provide empirical evidence
of DetReIDX usefulness, we considered the specific tasks of human detection and
ReID, where SOTA methods catastrophically degrade performance (up to 80% in
detection accuracy and over 70% in Rank-1 ReID) when exposed to DetReIDXs
conditions. The dataset, annotations, and official evaluation protocols are
publicly available at https://www.it.ubi.pt/DetReIDX/

</details>


### [60] [Are Synthetic Corruptions A Reliable Proxy For Real-World Corruptions?](https://arxiv.org/abs/2505.04835)
*Shashank Agnihotri,David Schader,Nico Sharei,Mehmet Ege Kaçar,Margret Keuper*

Main category: cs.CV

TL;DR: 该研究通过大规模基准测试表明，在评估深度学习模型（特别是语义分割模型）的鲁棒性时，合成损坏可以作为真实世界损坏的可靠替代。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型易受真实世界分布变化（如天气、光照）的影响，而收集多样化的真实数据测试鲁棒性成本高昂。因此，研究旨在探究合成损坏是否能可靠地替代真实世界损坏来评估模型鲁棒性。

Method: 对语义分割模型进行了大规模基准研究，比较了模型在真实世界损坏数据集和合成损坏数据集上的性能。分析了平均性能的相关性以及特定损坏类型的相关性。

Result: 结果显示，模型在真实损坏和合成损坏上的平均性能之间存在强相关性。进一步分析揭示了合成损坏在何种情况下能成功代表真实世界损坏。

Conclusion: 合成损坏可以作为评估深度学习模型（特别是语义分割模型）鲁棒性的可靠替代方法，能够有效地代表真实世界的损坏。

Abstract: Deep learning (DL) models are widely used in real-world applications but
remain vulnerable to distribution shifts, especially due to weather and
lighting changes. Collecting diverse real-world data for testing the robustness
of DL models is resource-intensive, making synthetic corruptions an attractive
alternative for robustness testing. However, are synthetic corruptions a
reliable proxy for real-world corruptions? To answer this, we conduct the
largest benchmarking study on semantic segmentation models, comparing
performance on real-world corruptions and synthetic corruptions datasets. Our
results reveal a strong correlation in mean performance, supporting the use of
synthetic corruptions for robustness evaluation. We further analyze
corruption-specific correlations, providing key insights to understand when
synthetic corruptions succeed in representing real-world corruptions.
Open-source Code:
https://github.com/shashankskagnihotri/benchmarking_robustness/tree/segmentation_david/semantic_segmentation

</details>


### [61] [Seeing Cells Clearly: Evaluating Machine Vision Strategies for Microglia Centroid Detection in 3D Images](https://arxiv.org/abs/2505.04838)
*Youjia Zhang*

Main category: cs.CV

TL;DR: 测试并比较了三种工具（ilastik、3D Morph、Omnipose）在3D显微镜图像中定位小胶质细胞中心点的性能。


<details>
  <summary>Details</summary>
Motivation: 小胶质细胞的形态对评估大脑健康至关重要，因此需要有效的工具来分析其在3D图像中的中心点。

Method: 使用 ilastik、3D Morph 和 Omnipose 三种工具，在3D显微镜图像中检测小胶质细胞的中心点，并对它们的检测性能及结果进行比较。

Result: 研究发现，每种工具对细胞的识别方式各不相同，这会影响从图像中获取的信息类型。

Conclusion: 不同的工具在识别小胶质细胞中心点时存在差异，这意味着工具的选择会影响最终从图像中获取的生物学信息的解读。

Abstract: Microglia are important cells in the brain, and their shape can tell us a lot
about brain health. In this project, I test three different tools for finding
the center points of microglia in 3D microscope images. The tools include
ilastik, 3D Morph, and Omnipose. I look at how well each one finds the cells
and how their results compare. My findings show that each tool sees the cells
in its own way, and this can affect the kind of information we get from the
images.

</details>


### [62] [ORXE: Orchestrating Experts for Dynamically Configurable Efficiency](https://arxiv.org/abs/2505.04850)
*Qingyuan Wang,Guoxin Wang,Barry Cardiff,Deepu John*

Main category: cs.CV

TL;DR: ORXE：一种模块化、可适应的AI模型实时可配置效率框架，利用预训练专家动态调整推理路径。


<details>
  <summary>Details</summary>
Motivation: 提高AI模型在不同输入复杂度和资源限制下的推理效率和灵活性，同时简化开发过程，避免传统方法中复杂的元模型训练。

Method: 利用一组具有不同计算成本和性能水平的预训练专家。通过基于置信度的门控机制，根据输入样本的复杂度动态调整推理路径，并支持运行时调整推理成本与预测性能之间的偏好。该系统无需额外训练即可实现。

Result: 在图像分类任务中，ORXE在大多数情况下表现优于单个专家模型和其他动态模型，在多种设备上均实现了卓越的效率和准确性。

Conclusion: ORXE提供了一种可扩展的解决方案，适用于多样化的真实世界部署场景，并可扩展到其他应用领域，以实现AI模型的实时可配置效率。

Abstract: This paper presents ORXE, a modular and adaptable framework for achieving
real-time configurable efficiency in AI models. By leveraging a collection of
pre-trained experts with diverse computational costs and performance levels,
ORXE dynamically adjusts inference pathways based on the complexity of input
samples. Unlike conventional approaches that require complex metamodel
training, ORXE achieves high efficiency and flexibility without complicating
the development process. The proposed system utilizes a confidence-based gating
mechanism to allocate appropriate computational resources for each input. ORXE
also supports adjustments to the preference between inference cost and
prediction performance across a wide range during runtime. We implemented a
training-free ORXE system for image classification tasks, evaluating its
efficiency and accuracy across various devices. The results demonstrate that
ORXE achieves superior performance compared to individual experts and other
dynamic models in most cases. This approach can be extended to other
applications, providing a scalable solution for diverse real-world deployment
scenarios.

</details>


### [63] [Mix-QSAM: Mixed-Precision Quantization of the Segment Anything Model](https://arxiv.org/abs/2505.04861)
*Navin Ranjan,Andreas Savakis*

Main category: cs.CV

TL;DR: 提出了一种名为Mix-QSAM的混合精度后训练量化框架，用于优化Segment Anything Model (SAM)在资源受限设备上的部署，通过智能分配层比特宽度，实现了更高的精度和效率。


<details>
  <summary>Details</summary>
Motivation: SAM模型计算和内存需求高，难以部署在资源受限设备上。现有的固定比特宽度后训练量化（PTQ）方法会导致次优的准确性和效率。

Method: 提出了Mix-QSAM框架：首先，使用KL散度推导出层重要性得分，量化每层对模型输出的贡献。其次，引入基于因果互信息的跨层协同度量，捕捉相邻层之间的依赖关系，确保高度相互依赖的层保持相似的比特宽度。最后，利用这些度量构建整数二次规划（IQP）问题，在模型大小和位运算约束下确定最佳比特宽度分配。

Result: 实验结果表明，Mix-QSAM在实例分割和目标检测任务上始终优于现有的PTQ方法，在6比特和4比特混合精度设置下，平均精度（AP）提高了高达20%，同时保持了计算效率。

Conclusion: Mix-QSAM通过为关键层分配更高精度、为影响较小的层分配更低精度的方式，有效解决了SAM模型的量化问题，在保持计算效率的同时显著提高了模型在资源受限环境下的性能。

Abstract: The Segment Anything Model (SAM) is a popular vision foundation model;
however, its high computational and memory demands make deployment on
resource-constrained devices challenging. While Post-Training Quantization
(PTQ) is a practical approach for reducing computational overhead, existing PTQ
methods rely on fixed bit-width quantization, leading to suboptimal accuracy
and efficiency. To address this limitation, we propose Mix-QSAM, a
mixed-precision PTQ framework for SAM. First, we introduce a layer-wise
importance score, derived using Kullback-Leibler (KL) divergence, to quantify
each layer's contribution to the model's output. Second, we introduce
cross-layer synergy, a novel metric based on causal mutual information, to
capture dependencies between adjacent layers. This ensures that highly
interdependent layers maintain similar bit-widths, preventing abrupt precision
mismatches that degrade feature propagation and numerical stability. Using
these metrics, we formulate an Integer Quadratic Programming (IQP) problem to
determine optimal bit-width allocation under model size and bit-operation
constraints, assigning higher precision to critical layers while minimizing
bit-width in less influential layers. Experimental results demonstrate that
Mix-QSAM consistently outperforms existing PTQ methods on instance segmentation
and object detection tasks, achieving up to 20% higher average precision under
6-bit and 4-bit mixed-precision settings, while maintaining computational
efficiency.

</details>


### [64] [Auto-regressive transformation for image alignment](https://arxiv.org/abs/2505.04864)
*Kanggeon Lee,Soochahn Lee,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: ART是一种新的图像对齐方法，通过自回归框架迭代估计从粗到细的变换，在特征稀疏、尺度/视场差异大和形变大的情况下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的图像对齐方法在处理特征稀疏区域、极端尺度和视场差异以及大形变等挑战性情况时，精度不佳。

Method: 提出了一种名为自回归变换 (ART) 的新方法。该方法在自回归框架内迭代估计从粗到细的变换，利用层次化多尺度特征，在每个尺度上使用随机采样点来优化变换，并通过交叉注意力层的引导，使模型专注于关键区域。

Result: 在多个不同数据集上进行的大量实验表明，ART 显著优于当前最先进的方法。

Conclusion: ART 是一种功能强大的新型精确图像对齐方法，具有广泛的适用性。

Abstract: Existing methods for image alignment struggle in cases involving
feature-sparse regions, extreme scale and field-of-view differences, and large
deformations, often resulting in suboptimal accuracy. Robustness to these
challenges improves through iterative refinement of the transformation field
while focusing on critical regions in multi-scale image representations. We
thus propose Auto-Regressive Transformation (ART), a novel method that
iteratively estimates the coarse-to-fine transformations within an
auto-regressive framework. Leveraging hierarchical multi-scale features, our
network refines the transformations using randomly sampled points at each
scale. By incorporating guidance from the cross-attention layer, the model
focuses on critical regions, ensuring accurate alignment even in challenging,
feature-limited conditions. Extensive experiments across diverse datasets
demonstrate that ART significantly outperforms state-of-the-art methods,
establishing it as a powerful new method for precise image alignment with broad
applicability.

</details>


### [65] [Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning](https://arxiv.org/abs/2505.04877)
*Lianbo Ma,Jianlun Ma,Yuee Zhou,Guoyang Xie,Qiang He,Zhichao Lu*

Main category: cs.CV

TL;DR: 提出了一种在小数据集上搜索混合精度量化（MPQ）策略，并将其推广到大数据集的新方法，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的混合精度量化（MPQ）方法在大型数据集上搜索量化策略时计算成本过高。

Method: 首先在小数据集上搜索量化策略，然后将其推广到大型数据集。通过模型权重调整简化流程，无需大规模量化微调。关键技术包括：锐度感知最小化（增强泛化性）、隐式梯度方向对齐（处理梯度冲突）和自适应扰动半径（加速优化）。

Result: 使用小数据集（CIFAR10，仅为ImageNet训练数据的0.5%）进行MPQ策略搜索，在ImageNet上实现了与基线相当的准确率，但计算成本显著降低，效率比基线方法提高了高达150%。

Conclusion: 该研究提出的方法通过在小数据集上搜索量化策略并推广至大数据集，有效地降低了混合精度量化的计算成本，同时保持了模型性能，并通过理论和实验得到验证。

Abstract: Mixed Precision Quantization (MPQ) has become an essential technique for
optimizing neural network by determining the optimal bitwidth per layer.
Existing MPQ methods, however, face a major hurdle: they require a
computationally expensive search for quantization policies on large-scale
datasets. To resolve this issue, we introduce a novel approach that first
searches for quantization policies on small datasets and then generalizes them
to large-scale datasets. This approach simplifies the process, eliminating the
need for large-scale quantization fine-tuning and only necessitating model
weight adjustment. Our method is characterized by three key techniques:
sharpness-aware minimization for enhanced quantization generalization, implicit
gradient direction alignment to handle gradient conflicts among different
optimization objectives, and an adaptive perturbation radius to accelerate
optimization. Both theoretical analysis and experimental results validate our
approach. Using the CIFAR10 dataset (just 0.5\% the size of ImageNet training
data) for MPQ policy search, we achieved equivalent accuracy on ImageNet with a
significantly lower computational cost, while improving efficiency by up to
150% over the baselines.

</details>


### [66] [Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection](https://arxiv.org/abs/2505.04888)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan,Simon Denman*

Main category: cs.CV

TL;DR: 该论文提出了一种新的人脸深度伪造检测方法，通过结合从粗到细的空间与语义信息，并引入特征正交解耦策略，显著提升了对未知类型深度伪造的检测性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展使得深度伪造图像日益逼真，对社会造成负面影响。现有检测方法因依赖特定伪造痕迹，难以有效检测新型和多样化的深度伪造，泛化能力不足。

Method: 提出一种结合从粗到细的空间信息、语义信息及其交互的检测策略。核心是引入一种新颖的基于特征正交性的解耦方法，以确保不同特征分支的独特性并减少冗余，从而在不增加模型复杂度的前提下有效融合多源特征，提升泛化性。

Result: 在FaceForensics++, Celeb-DF和DFDC三个公开基准数据集上的综合实验表明，该方法在跨数据集评估中表现优异，相较于当前顶尖方法，在Celeb-DF数据集上性能提升5%，在DFDC数据集上提升7%。

Conclusion: 本文提出的方法，通过有效整合多层次信息并采用特征正交解耦，显著增强了人脸深度伪造检测模型的鲁棒性和泛化能力，为应对层出不穷的深度伪造技术提供了更有效的解决方案。

Abstract: Remarkable advancements in generative AI technology have given rise to a
spectrum of novel deepfake categories with unprecedented leaps in their
realism, and deepfakes are increasingly becoming a nuisance to law enforcement
authorities and the general public. In particular, we observe alarming levels
of confusion, deception, and loss of faith regarding multimedia content within
society caused by face deepfakes, and existing deepfake detectors are
struggling to keep up with the pace of improvements in deepfake generation.
This is primarily due to their reliance on specific forgery artifacts, which
limits their ability to generalise and detect novel deepfake types. To combat
the spread of malicious face deepfakes, this paper proposes a new strategy that
leverages coarse-to-fine spatial information, semantic information, and their
interactions while ensuring feature distinctiveness and reducing the redundancy
of the modelled features. A novel feature orthogonality-based disentanglement
strategy is introduced to ensure branch-level and cross-branch feature
disentanglement, which allows us to integrate multiple feature vectors without
adding complexity to the feature space or compromising generalisation.
Comprehensive experiments on three public benchmarks: FaceForensics++,
Celeb-DF, and the Deepfake Detection Challenge (DFDC) show that these design
choices enable the proposed approach to outperform current state-of-the-art
methods by 5% on the Celeb-DF dataset and 7% on the DFDC dataset in a
cross-dataset evaluation setting.

</details>


### [67] [OWT: A Foundational Organ-Wise Tokenization Framework for Medical Imaging](https://arxiv.org/abs/2505.04899)
*Sifan Song,Siyeop Yoon,Pengfei Jin,Sekeun Kim,Matthew Tivnan,Yujin Oh,Runqi Meng,Ling Chen,Zhiliang Lyu,Dufan Wu,Ning Guo,Xiang Li,Quanzheng Li*

Main category: cs.CV

TL;DR: 论文提出了一种器官级标记化（OWT）框架，通过将医学图像解耦为与特定器官对应的标记组，解决了传统黑盒嵌入模型在医学影像中可解释性和泛化性不足的问题，并在图像重建、分割及新的语义级应用中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统的表示学习方法产生的整体性、黑盒嵌入模型将多种语义成分纠缠在一起，限制了其在医学影像领域的可解释性和泛化能力。

Method: 提出了一种器官级标记化（OWT）框架，并结合基于标记组的重建（TGR）训练范式。该方法将医学图像显式地分解为多个可分离的标记组，每个标记组对应一个特定的器官或语义实体，从而封装器官特异性信息。

Result: 在CT和MRI数据集上的实验证明，OWT不仅在图像重建和分割任务中取得了优异性能，还成功实现了标准整体嵌入方法难以企及的新型语义级生成和检索应用。

Conclusion: OWT框架为语义解耦的表示学习提供了一个有潜力的基础模型，在真实世界的医学影像场景及其他领域具有广泛的可扩展性和应用前景。

Abstract: Recent advances in representation learning often rely on holistic, black-box
embeddings that entangle multiple semantic components, limiting
interpretability and generalization. These issues are especially critical in
medical imaging. To address these limitations, we propose an Organ-Wise
Tokenization (OWT) framework with a Token Group-based Reconstruction (TGR)
training paradigm. Unlike conventional approaches that produce holistic
features, OWT explicitly disentangles an image into separable token groups,
each corresponding to a distinct organ or semantic entity. Our design ensures
each token group encapsulates organ-specific information, boosting
interpretability, generalization, and efficiency while allowing fine-grained
control in downstream tasks. Experiments on CT and MRI datasets demonstrate the
effectiveness of OWT in not only achieving strong image reconstruction and
segmentation performance, but also enabling novel semantic-level generation and
retrieval applications that are out of reach for standard holistic embedding
methods. These findings underscore the potential of OWT as a foundational
framework for semantically disentangled representation learning, offering broad
scalability and applicability to real-world medical imaging scenarios and
beyond.

</details>


### [68] [Pro2SAM: Mask Prompt to SAM with Grid Points for Weakly Supervised Object Localization](https://arxiv.org/abs/2505.04905)
*Xi Yang,Songsong Duan,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TL;DR: 提出了一种名为 Pro2SAM 的新弱监督目标定位方法，利用 Segment Anything Model (SAM) 结合创新的掩码和网格点提示，以增强目标区域的激活并解决语义模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督目标定位方法（如 CAM 和自注意力图）难以捕捉前景目标的像素级细粒度信息，且基于单点提示的 SAM 存在语义模糊问题，这些因素阻碍了定位性能的进一步提升。

Method: 该研究利用 SAM 的零样本泛化和细粒度分割能力。提出了 Pro2SAM 网络：首先，设计全局令牌转换器 (GTFormer) 生成粗粒度的前景图作为灵活的掩码提示；其次，将网格点作为密集提示输入 SAM，以最大化前景掩码的概率并避免目标缺失；最后，通过像素级相似性度量将掩码提示与 SAM 输出匹配，选择得分最高的掩码作为最终定位图。

Result: 所提出的 Pro2SAM 在 CUB-200-2011 和 ILSVRC 数据集上均达到了最先进的性能，Top-1 定位准确率分别达到 84.03% 和 66.85%。

Conclusion: Pro2SAM 通过有效利用 SAM 并引入掩码提示和网格点，解决了传统方法在细粒度信息上的不足以及 SAM 提示的语义模糊问题，显著提升了弱监督目标定位的性能。

Abstract: Weakly Supervised Object Localization (WSOL), which aims to localize objects
by only using image-level labels, has attracted much attention because of its
low annotation cost in real applications. Current studies focus on the Class
Activation Map (CAM) of CNN and the self-attention map of transformer to
identify the region of objects. However, both CAM and self-attention maps can
not learn pixel-level fine-grained information on the foreground objects, which
hinders the further advance of WSOL. To address this problem, we initiatively
leverage the capability of zero-shot generalization and fine-grained
segmentation in Segment Anything Model (SAM) to boost the activation of
integral object regions. Further, to alleviate the semantic ambiguity issue
accrued in single point prompt-based SAM, we propose an innovative mask prompt
to SAM (Pro2SAM) network with grid points for WSOL task. First, we devise a
Global Token Transformer (GTFormer) to generate a coarse-grained foreground map
as a flexible mask prompt, where the GTFormer jointly embeds patch tokens and
novel global tokens to learn foreground semantics. Secondly, we deliver grid
points as dense prompts into SAM to maximize the probability of foreground
mask, which avoids the lack of objects caused by a single point/box prompt.
Finally, we propose a pixel-level similarity metric to come true the mask
matching from mask prompt to SAM, where the mask with the highest score is
viewed as the final localization map. Experiments show that the proposed
Pro2SAM achieves state-of-the-art performance on both CUB-200-2011 and ILSVRC,
with 84.03\% and 66.85\% Top-1 Loc, respectively.

</details>


### [69] [SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models](https://arxiv.org/abs/2505.04911)
*Shun Taguchi,Hideki Deguchi,Takumi Hamazaki,Hiroyuki Sakai*

Main category: cs.CV

TL;DR: 提出SpatialPrompting框架，利用现成的多模态大语言模型，通过关键帧驱动的提示生成策略，在3D环境中实现零样本空间推理，无需专门的3D输入或微调。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的3D特定微调和专门的3D输入（如点云、体素特征），限制了灵活性和可扩展性，且未能充分利用大型语言模型的推理能力进行3D空间理解。

Method: SpatialPrompting采用关键帧驱动的提示生成策略。它通过视觉语言相似性、马氏距离、视场角和图像清晰度等指标从图像序列中选择信息丰富的关键帧，并结合相机姿态数据，生成提示以引导多模态大语言模型理解和推断3D空间关系与结构。

Result: 该框架在ScanQA和SQA3D等基准数据集上实现了领先的零样本空间推理性能，展示了其在不依赖专门3D输入和微调的情况下理解复杂3D环境的能力。

Conclusion: SpatialPrompting有效地消除了对专门3D输入和微调的需求，为3D空间推理提供了一种更简单、更具可扩展性的新范式，并利用了大型语言模型的现有能力。

Abstract: This study introduces SpatialPrompting, a novel framework that harnesses the
emergent reasoning capabilities of off-the-shelf multimodal large language
models to achieve zero-shot spatial reasoning in three-dimensional (3D)
environments. Unlike existing methods that rely on expensive 3D-specific
fine-tuning with specialized 3D inputs such as point clouds or voxel-based
features, SpatialPrompting employs a keyframe-driven prompt generation
strategy. This framework uses metrics such as vision-language similarity,
Mahalanobis distance, field of view, and image sharpness to select a diverse
and informative set of keyframes from image sequences and then integrates them
with corresponding camera pose data to effectively abstract spatial
relationships and infer complex 3D structures. The proposed framework not only
establishes a new paradigm for flexible spatial reasoning that utilizes
intuitive visual and positional cues but also achieves state-of-the-art
zero-shot performance on benchmark datasets, such as ScanQA and SQA3D, across
several metrics. The proposed method effectively eliminates the need for
specialized 3D inputs and fine-tuning, offering a simpler and more scalable
alternative to conventional approaches.

</details>


### [70] [GlyphMastero: A Glyph Encoder for High-Fidelity Scene Text Editing](https://arxiv.org/abs/2505.04915)
*Tong Wang,Ting Liu,Xiaochao Qu,Chengjing Wu,Luoqi Liu,Xiaolin Hu*

Main category: cs.CV

TL;DR: 本文提出GlyphMastero，一种专用的字形编码器，通过指导潜在扩散模型实现笔画级精度的场景文本生成，显著提升了复杂字符（如中文）的编辑质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的场景文本编辑方法难以生成高质量文本，尤其在处理如中文等复杂字符时，常产生扭曲或无法识别的字符，因为它们未能有效捕捉文本的层级结构（从笔画到字符整体）。

Method: 提出了GlyphMastero，一个专门的字形编码器。它通过新颖的字形注意力模块显式建模局部字符与全局文本行间的跨层级交互，并利用特征金字塔网络融合多尺度OCR骨干特征，从而为潜在扩散模型提供更精细的字形感知指导，实现对文本生成的精确控制。

Result: 该方法在句子准确率上相比现有最先进的多语言场景文本编辑基线提升了18.02%，同时将文本区域的Fréchet Inception Distance (FID) 降低了53.28%。

Conclusion: GlyphMastero通过其字形编码器和跨层级、多尺度特征融合机制，有效地提升了场景文本编辑的精度和视觉质量，特别是在生成具有复杂笔画结构的文本方面表现优异。

Abstract: Scene text editing, a subfield of image editing, requires modifying texts in
images while preserving style consistency and visual coherence with the
surrounding environment. While diffusion-based methods have shown promise in
text generation, they still struggle to produce high-quality results. These
methods often generate distorted or unrecognizable characters, particularly
when dealing with complex characters like Chinese. In such systems, characters
are composed of intricate stroke patterns and spatial relationships that must
be precisely maintained. We present GlyphMastero, a specialized glyph encoder
designed to guide the latent diffusion model for generating texts with
stroke-level precision. Our key insight is that existing methods, despite using
pretrained OCR models for feature extraction, fail to capture the hierarchical
nature of text structures - from individual strokes to stroke-level
interactions to overall character-level structure. To address this, our glyph
encoder explicitly models and captures the cross-level interactions between
local-level individual characters and global-level text lines through our novel
glyph attention module. Meanwhile, our model implements a feature pyramid
network to fuse the multi-scale OCR backbone features at the global-level.
Through these cross-level and multi-scale fusions, we obtain more detailed
glyph-aware guidance, enabling precise control over the scene text generation
process. Our method achieves an 18.02\% improvement in sentence accuracy over
the state-of-the-art multi-lingual scene text editing baseline, while
simultaneously reducing the text-region Fr\'echet inception distance by
53.28\%.

</details>


### [71] [A Simple Detector with Frame Dynamics is a Strong Tracker](https://arxiv.org/abs/2505.04917)
*Chenxu Peng,Chenxu Wang,Minrui Zou,Danyang Li,Zhengpeng Yang,Yimian Dai,Ming-Ming Cheng,Xiang Li*

Main category: cs.CV

TL;DR: 提出了一种简单有效的红外微小目标跟踪器，通过整合全局检测和基于时间先验的运动感知学习来提升反无人机应用中的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有红外跟踪器依赖裁剪模板区域且运动建模能力有限，在处理微小目标时面临挑战，尤其是在反无人机（Anti-UAV）应用中。

Method: 该方法基于目标检测，并引入两个关键创新：1. 帧动态（frame dynamics），利用帧差和光流在输入层面编码先验目标特征和运动特性，以区分目标与背景；2. 轨迹约束滤波策略，在后处理阶段利用时空先验抑制误报，增强跟踪鲁棒性。

Result: 实验表明，该方法在多个指标上持续优于现有方法，并在第四届反无人机挑战赛中取得了领先成绩（Track 1 第一名，Track 2 第二名）。

Conclusion: 通过整合全局检测、运动感知学习与时间先验（帧动态和轨迹约束滤波），所提出的红外微小目标跟踪器有效提升了在挑战性场景下的跟踪性能，尤其针对微小目标。

Abstract: Infrared object tracking plays a crucial role in Anti-Unmanned Aerial Vehicle
(Anti-UAV) applications. Existing trackers often depend on cropped template
regions and have limited motion modeling capabilities, which pose challenges
when dealing with tiny targets. To address this, we propose a simple yet
effective infrared tiny-object tracker that enhances tracking performance by
integrating global detection and motion-aware learning with temporal priors.
Our method is based on object detection and achieves significant improvements
through two key innovations. First, we introduce frame dynamics, leveraging
frame difference and optical flow to encode both prior target features and
motion characteristics at the input level, enabling the model to better
distinguish the target from background clutter. Second, we propose a trajectory
constraint filtering strategy in the post-processing stage, utilizing
spatio-temporal priors to suppress false positives and enhance tracking
robustness. Extensive experiments show that our method consistently outperforms
existing approaches across multiple metrics in challenging infrared UAV
tracking scenarios. Notably, we achieve state-of-the-art performance in the 4th
Anti-UAV Challenge, securing 1st place in Track 1 and 2nd place in Track 2.

</details>


### [72] [Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](https://arxiv.org/abs/2505.04921)
*Yunxin Li,Zhenyu Liu,Zitao Li,Xuanyu Zhang,Zhenran Xu,Xinyu Chen,Haoyuan Shi,Shenyuan Jiang,Xintong Wang,Jifang Wang,Shouzheng Huang,Xinping Zhao,Borui Jiang,Lanqing Hong,Longyue Wang,Zhuotao Tian,Baoxing Huai,Wenhan Luo,Weihua Luo,Zheng Zhang,Baotian Hu,Min Zhang*

Main category: cs.CV

TL;DR: 这篇综述回顾了多模态推理的研究进展，重点介绍了大型多模态推理模型（LMRM）的演变、当前挑战以及原生大型多模态推理模型（N-LMRM）的未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统在开放、不确定和多模态环境中运行，推理能力变得至关重要。大型多模态推理模型（LMRM）虽有前景，但在全模态泛化、推理深度和智能体行为方面仍面临重大挑战，因此需要对该领域进行全面梳理和展望。

Method: 作者进行了一项全面且结构化的综述，围绕一个四阶段发展路线图来组织多模态推理的研究：1.回顾早期基于特定任务模块的努力；2.审查统一到多模态大语言模型（如MCoT和多模态强化学习）的近期方法；3.结合基准测试和OpenAI O3及O4-mini的实验案例，讨论原生大型多模态推理模型（N-LMRMs）的概念方向。

Result: 该综述描绘了多模态推理从模块化、感知驱动的流程演变为统一的、以语言为中心的框架的发展路径。研究强调了指令调优和强化学习等技术在改进模型推理方面的作用，并指出了在全模态泛化、推理深度和智能体行为方面的持续挑战。

Conclusion: 该综述为多模态推理领域提供了结构化的理解，并指明了原生大型多模态推理模型（N-LMRMs）作为未来发展方向，旨在支持在复杂真实世界环境中实现可扩展、智能体式和自适应的推理与规划。

Abstract: Reasoning lies at the heart of intelligence, shaping the ability to make
decisions, draw conclusions, and generalize across domains. In artificial
intelligence, as systems increasingly operate in open, uncertain, and
multimodal environments, reasoning becomes essential for enabling robust and
adaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a
promising paradigm, integrating modalities such as text, images, audio, and
video to support complex reasoning capabilities and aiming to achieve
comprehensive perception, precise understanding, and deep reasoning. As
research advances, multimodal reasoning has rapidly evolved from modular,
perception-driven pipelines to unified, language-centric frameworks that offer
more coherent cross-modal understanding. While instruction tuning and
reinforcement learning have improved model reasoning, significant challenges
remain in omni-modal generalization, reasoning depth, and agentic behavior. To
address these issues, we present a comprehensive and structured survey of
multimodal reasoning research, organized around a four-stage developmental
roadmap that reflects the field's shifting design philosophies and emerging
capabilities. First, we review early efforts based on task-specific modules,
where reasoning was implicitly embedded across stages of representation,
alignment, and fusion. Next, we examine recent approaches that unify reasoning
into multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT)
and multimodal reinforcement learning enabling richer and more structured
reasoning chains. Finally, drawing on empirical insights from challenging
benchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the
conceptual direction of native large multimodal reasoning models (N-LMRMs),
which aim to support scalable, agentic, and adaptive reasoning and planning in
complex, real-world environments.

</details>


### [73] [Canny2Palm: Realistic and Controllable Palmprint Generation for Large-scale Pre-training](https://arxiv.org/abs/2505.04922)
*Xingzeng Lan,Xing Duan,Chen Chen,Weiyu Lin,Bo Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Canny2Palm的新方法，通过Canny边缘检测和Pix2Pix网络生成逼真且多样化的掌纹数据，显著提升了掌纹识别模型预训练的效果和识别准确率。


<details>
  <summary>Details</summary>
Motivation: 掌纹数据稀缺是提升掌纹识别准确率的主要挑战。现有的虚拟掌纹合成研究旨在解决此问题，但仍需改进以生成大规模、多样化且逼真的新身份数据。

Method: 提出了一种名为 Canny2Palm 的新型掌纹合成方法。该方法使用 Canny 边缘检测器提取掌纹纹理，并利用这些纹理作为条件输入到 Pix2Pix 网络中，以生成逼真的掌纹图像。通过重新组合来自不同身份的掌纹纹理，可以创建新的身份。

Result: Canny2Palm 不仅能合成遵循真实掌纹分布的逼真数据，还能实现可控的多样性以生成大规模新身份。在开放集掌纹识别基准测试中，使用 Canny2Palm 合成数据预训练的模型比当前最先进技术的识别准确率高出多达 7.2%。当合成身份数量达到 10,000 个时，其性能持续提升，优于已饱和的现有方法。

Conclusion: Canny2Palm 方法能够有效合成大规模、逼真且多样化的掌纹数据，显著提升了预训练模型的性能，证明了其在进行大规模预训练方面的巨大潜力。

Abstract: Palmprint recognition is a secure and privacy-friendly method of biometric
identification. One of the major challenges to improve palmprint recognition
accuracy is the scarcity of palmprint data. Recently, a popular line of
research revolves around the synthesis of virtual palmprints for large-scale
pre-training purposes. In this paper, we propose a novel synthesis method named
Canny2Palm that extracts palm textures with Canny edge detector and uses them
to condition a Pix2Pix network for realistic palmprint generation. By
re-assembling palmprint textures from different identities, we are able to
create new identities by seeding the generator with new assemblies. Canny2Palm
not only synthesizes realistic data following the distribution of real
palmprints but also enables controllable diversity to generate large-scale new
identities. On open-set palmprint recognition benchmarks, models pre-trained
with Canny2Palm synthetic data outperform the state-of-the-art with up to 7.2%
higher identification accuracy. Moreover, the performance of models pre-trained
with Canny2Palm continues to improve given 10,000 synthetic IDs while those
with existing methods already saturate, demonstrating the potential of our
method for large-scale pre-training.

</details>


### [74] [FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration](https://arxiv.org/abs/2505.04938)
*Ying Zhang,Shuai Guo,Chenxi Sun,Yuchen Zhu,Jinhai Xiang*

Main category: cs.CV

TL;DR: 提出一种名为FF-PNet的新型金字塔配准网络，通过并行提取粗细粒度特征，有效提升了可变形医学图像配准的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有可变形医学图像配准模型在并行提取粗粒度和细粒度特征方面效率不高，难以有效处理复杂图像变形。

Method: 构建了基于特征和变形场的金字塔配准网络（FF-PNet）。设计了用于粗粒度特征提取的残差特征融合模块（RFFM）和用于细粒度图像变形的残差变形场融合模块（RDFFM），这两个模块并行操作。编码阶段仅使用传统卷积神经网络。

Result: 在LPBA和OASIS数据集上的实验表明，FF-PNet在配准精度（如Dice相似系数）上显著优于现有流行方法，即使在编码阶段未使用注意力机制或多层感知器。

Conclusion: FF-PNet通过其设计的RFFM和RDFFM模块，能够有效且高效地进行医学图像配准，证明了其在特征解码方面的优越性，并显著提高了配准精度。

Abstract: In recent years, deformable medical image registration techniques have made
significant progress. However, existing models still lack efficiency in
parallel extraction of coarse and fine-grained features. To address this, we
construct a new pyramid registration network based on feature and deformation
field (FF-PNet). For coarse-grained feature extraction, we design a Residual
Feature Fusion Module (RFFM), for fine-grained image deformation, we propose a
Residual Deformation Field Fusion Module (RDFFM). Through the parallel
operation of these two modules, the model can effectively handle complex image
deformations. It is worth emphasizing that the encoding stage of FF-PNet only
employs traditional convolutional neural networks without any attention
mechanisms or multilayer perceptrons, yet it still achieves remarkable
improvements in registration accuracy, fully demonstrating the superior feature
decoding capabilities of RFFM and RDFFM. We conducted extensive experiments on
the LPBA and OASIS datasets. The results show our network consistently
outperforms popular methods in metrics like the Dice Similarity Coefficient.

</details>


### [75] [Building-Guided Pseudo-Label Learning for Cross-Modal Building Damage Mapping](https://arxiv.org/abs/2505.04941)
*Jiepan Li,He Huang,Yu Sheng,Yujun Guo,Wei He*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的建筑物引导的伪标签学习框架，用于利用灾前光学图像和灾后SAR图像准确评估建筑物损坏情况，并在相关竞赛中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 准确的建筑物损坏评估对于有效的灾害响应和恢复规划至关重要，但利用灾前光学和灾后SAR图像进行建筑物损坏测绘存在挑战。

Method: 该研究提出了一种建筑物引导的伪标签学习框架。首先，利用灾前光学图像训练建筑物提取模型，并通过多模型融合、测试时增强和低不确定性伪标签训练来优化分割结果。接着，训练一个变化检测模型用于识别双时相跨模态图像中的受损建筑物，并引入一种建筑物引导的低不确定性伪标签细化策略，利用前一步提取的建筑物先验信息来提高损坏分类的准确性。

Result: 在2025年IEEE GRSS数据融合竞赛数据集上的实验结果表明，该方法取得了最高的mIoU分数（54.28%），并在竞赛中获得了第一名。

Conclusion: 提出的建筑物引导的伪标签学习框架能够有效地利用双时相多模态遥感影像进行准确的建筑物损坏评估。

Abstract: Accurate building damage assessment using bi-temporal multi-modal remote
sensing images is essential for effective disaster response and recovery
planning. This study proposes a novel Building-Guided Pseudo-Label Learning
Framework to address the challenges of mapping building damage from
pre-disaster optical and post-disaster SAR images. First, we train a series of
building extraction models using pre-disaster optical images and building
labels. To enhance building segmentation, we employ multi-model fusion and
test-time augmentation strategies to generate pseudo-probabilities, followed by
a low-uncertainty pseudo-label training method for further refinement. Next, a
change detection model is trained on bi-temporal cross-modal images and damaged
building labels. To improve damage classification accuracy, we introduce a
building-guided low-uncertainty pseudo-label refinement strategy, which
leverages building priors from the previous step to guide pseudo-label
generation for damaged buildings, reducing uncertainty and enhancing
reliability. Experimental results on the 2025 IEEE GRSS Data Fusion Contest
dataset demonstrate the effectiveness of our approach, which achieved the
highest mIoU score (54.28%) and secured first place in the competition.

</details>


### [76] [T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models](https://arxiv.org/abs/2505.04946)
*Xuyang Guo,Jiayan Huo,Zhenmei Shi,Zhao Song,Jiahao Zhang,Jiale Zhao*

Main category: cs.CV

TL;DR: 该研究提出了首个评估文本到视频模型屏幕文本渲染能力的人工评测基准 T2VTextBench，发现当前先进模型在这方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到视频生成技术进步显著，但其在视频中精确渲染屏幕文本（如字幕、公式）的能力尚未得到充分测试和验证，这对于需要精确文本的应用构成挑战。

Method: 引入 T2VTextBench，这是一个专门用于评估文本到视频模型屏幕文本保真度和时间一致性的人工评测基准。该基准使用集成复杂文本字符串和动态场景变化的提示，测试模型跨帧维持详细指令的能力，并评估了十个先进系统。

Result: 评估结果显示，大多数被测试的先进文本到视频模型（包括开源和商业方案）在生成清晰、一致的屏幕文本方面存在困难。

Conclusion: 研究结果揭示了当前视频生成器在文本渲染方面的一个关键缺陷，并为未来旨在增强视频合成中文字处理能力的研究指明了明确方向。

Abstract: Thanks to recent advancements in scalable deep architectures and large-scale
pretraining, text-to-video generation has achieved unprecedented capabilities
in producing high-fidelity, instruction-following content across a wide range
of styles, enabling applications in advertising, entertainment, and education.
However, these models' ability to render precise on-screen text, such as
captions or mathematical formulas, remains largely untested, posing significant
challenges for applications requiring exact textual accuracy. In this work, we
introduce T2VTextBench, the first human-evaluation benchmark dedicated to
evaluating on-screen text fidelity and temporal consistency in text-to-video
models. Our suite of prompts integrates complex text strings with dynamic scene
changes, testing each model's ability to maintain detailed instructions across
frames. We evaluate ten state-of-the-art systems, ranging from open-source
solutions to commercial offerings, and find that most struggle to generate
legible, consistent text. These results highlight a critical gap in current
video generators and provide a clear direction for future research aimed at
enhancing textual manipulation in video synthesis.

</details>


### [77] [An Efficient Method for Accurate Pose Estimation and Error Correction of Cuboidal Objects](https://arxiv.org/abs/2505.04962)
*Utsav Rai,Hardik Mehta,Vismay Vakharia,Aditya Choudhary,Amit Parmar,Rolif Lima,Kaushik Das*

Main category: cs.CV

TL;DR: 该论文提出了一种高效的立方体物体精确姿态估计方法，通过线性的误差估计和校正来减少目标姿态误差并提高时间效率，以支持高精度的自主抓取。


<details>
  <summary>Details</summary>
Motivation: 现有的姿态估计方法（如全局点云配准）存在微小姿态误差，而用于改进的局部配准算法执行时间开销大且最终误差不确定，难以满足对立方体物体进行高精度自主抓取的需求。

Method: 提出了一种替代的、线性的姿态误差估计和校正方法，用于立方体形状的物体。论文概述了整体解决方案，并详细描述了所提出算法的各个模块。

Result: 本文提出了一种新的线性时间算法，用于立方体物体的姿态误差估计和校正，旨在以时间高效的方式减少目标姿态的误差。

Conclusion: 论文提出了一种针对从无序或有序堆叠中高精度自主抓取立方体物体场景的解决方案，其核心是一种新颖的、时间高效的姿态估计与误差校正算法。

Abstract: The proposed system outlined in this paper is a solution to a use case that
requires the autonomous picking of cuboidal objects from an organized or
unorganized pile with high precision. This paper presents an efficient method
for precise pose estimation of cuboid-shaped objects, which aims to reduce
errors in target pose in a time-efficient manner. Typical pose estimation
methods like global point cloud registrations are prone to minor pose errors
for which local registration algorithms are generally used to improve pose
accuracy. However, due to the execution time overhead and uncertainty in the
error of the final achieved pose, an alternate, linear time approach is
proposed for pose error estimation and correction. This paper presents an
overview of the solution followed by a detailed description of individual
modules of the proposed algorithm.

</details>


### [78] [ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis](https://arxiv.org/abs/2505.04963)
*Onkar Susladkar,Gayatri Deshmukh,Yalcin Tur,Ulas Bagci*

Main category: cs.CV

TL;DR: ViCTr 是一种新颖的两阶段医学图像合成框架，能高效生成具有可控病理严重程度的高保真度医学图像，尤其在肝硬化MRI合成方面表现优异，且生成的图像在临床上与真实扫描无法区分。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像合成中因数据有限、模态差异及病理复杂性（如肝硬化）导致的解剖结构保持和病理特征精确建模难题，并克服现有方法对自然图像先验的依赖和低效采样问题。

Method: 提出 ViCTr，一个两阶段框架：1) 使用弹性权重巩固 (EWC) 在 ATLAS-8k 数据集上预训练，以保留解剖结构；2) 使用低秩自适应 (LoRA) 模块进行对抗性微调，以精确控制病理严重程度。该框架结合校正流轨迹和 Tweedie 校正扩散过程，并通过重新表述 Tweedie 公式实现高效单步采样。

Result: ViCTr 在肝硬化 MRI 合成方面达到最先进水平 (MFID 17.01，优于现有方法28%)，用于数据增强可提升分割性能 (+3.8% mDSC)。放射科医生认为其生成的肝硬化 MRI 与真实扫描无异。

Conclusion: ViCTr 是首个能实现细粒度、病理感知且具有分级严重程度控制的 MRI 合成方法，填补了 AI 医学影像研究的关键空白。

Abstract: Synthesizing medical images remains challenging due to limited annotated
pathological data, modality domain gaps, and the complexity of representing
diffuse pathologies such as liver cirrhosis. Existing methods often struggle to
maintain anatomical fidelity while accurately modeling pathological features,
frequently relying on priors derived from natural images or inefficient
multi-step sampling. In this work, we introduce ViCTr (Vital Consistency
Transfer), a novel two-stage framework that combines a rectified flow
trajectory with a Tweedie-corrected diffusion process to achieve high-fidelity,
pathology-aware image synthesis. First, we pretrain ViCTr on the ATLAS-8k
dataset using Elastic Weight Consolidation (EWC) to preserve critical
anatomical structures. We then fine-tune the model adversarially with Low-Rank
Adaptation (LoRA) modules for precise control over pathology severity. By
reformulating Tweedie's formula within a linear trajectory framework, ViCTr
supports one-step sampling, reducing inference from 50 steps to just 4, without
sacrificing anatomical realism. We evaluate ViCTr on BTCV (CT), AMOS (MRI), and
CirrMRI600+ (cirrhosis) datasets. Results demonstrate state-of-the-art
performance, achieving a Medical Frechet Inception Distance (MFID) of 17.01 for
cirrhosis synthesis 28% lower than existing approaches and improving nnUNet
segmentation by +3.8% mDSC when used for data augmentation. Radiologist reviews
indicate that ViCTr-generated liver cirrhosis MRIs are clinically
indistinguishable from real scans. To our knowledge, ViCTr is the first method
to provide fine-grained, pathology-aware MRI synthesis with graded severity
control, closing a critical gap in AI-driven medical imaging research.

</details>


### [79] [CAG-VLM: Fine-Tuning of a Large-Scale Model to Recognize Angiographic Images for Next-Generation Diagnostic Systems](https://arxiv.org/abs/2505.04964)
*Yuto Nakamura,Satoshi Kodera,Haruki Settai,Hiroki Shinohara,Masatsugu Tamura,Tomohiro Noguchi,Tatsuki Furusawa,Ryo Takizawa,Tempei Kabayama,Norihiko Takeda*

Main category: cs.CV

TL;DR: 研究开发了一个AI系统（CAG-VLM），通过分析冠状动脉造影图像辅助心脏病专家生成临床报告和治疗建议。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉造影（CAG）的解读和后续治疗规划高度依赖专家经验，为实现基于AI的决策支持，需要新的方法和数据集。

Method: 引入一个两阶段、由医生策划的流程和一个双语（日语/英语）CAG图像-报告数据集。首先，训练一个ConvNeXt-Base CNN模型进行关键帧检测和左右侧位分类。然后，将此CNN应用于独立检查，提取关键帧并与报告和专家摘要配对，形成平行语料库。最后，通过LoRA微调三种开源视觉语言模型（VLM）并进行评估。

Result: ConvNeXt-Base CNN在侧位分类上实现了0.96的F1分数。尽管PaliGemma2 w/LoRA获得了最高的VLScore，但Gemma3 w/LoRA获得了最高的临床医生评分（平均7.20/10），被命名为CAG-VLM。

Conclusion: 专门微调的视觉语言模型（VLM）可以有效地辅助心脏病专家从CAG图像生成临床报告和治疗建议。

Abstract: Coronary angiography (CAG) is the gold-standard imaging modality for
evaluating coronary artery disease, but its interpretation and subsequent
treatment planning rely heavily on expert cardiologists. To enable AI-based
decision support, we introduce a two-stage, physician-curated pipeline and a
bilingual (Japanese/English) CAG image-report dataset. First, we sample 14,686
frames from 539 exams and annotate them for key-frame detection and left/right
laterality; a ConvNeXt-Base CNN trained on this data achieves 0.96 F1 on
laterality classification, even on low-contrast frames. Second, we apply the
CNN to 243 independent exams, extract 1,114 key frames, and pair each with its
pre-procedure report and expert-validated diagnostic and treatment summary,
yielding a parallel corpus. We then fine-tune three open-source VLMs
(PaliGemma2, Gemma3, and ConceptCLIP-enhanced Gemma3) via LoRA and evaluate
them using VLScore and cardiologist review. Although PaliGemma2 w/LoRA attains
the highest VLScore, Gemma3 w/LoRA achieves the top clinician rating (mean
7.20/10); we designate this best-performing model as CAG-VLM. These results
demonstrate that specialized, fine-tuned VLMs can effectively assist
cardiologists in generating clinical reports and treatment recommendations from
CAG images.

</details>


### [80] [DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding](https://arxiv.org/abs/2505.04965)
*Henry Zheng,Hao Shi,Qihang Peng,Yong Xien Chng,Rui Huang,Yepeng Weng,Zhongchao Shi,Gao Huang*

Main category: cs.CV

TL;DR: 本文提出DenseGrounding方法，通过增强视觉和文本语义，显著提升了自我中心3D视觉定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有自我中心3D视觉定位方法面临两大挑战：1) 点云与自我中心多视角图像的稀疏融合导致细粒度视觉语义丢失；2) 任意的语言描述导致文本语义上下文受限。这些问题阻碍了智能体通过自然语言理解和交互3D环境的能力。

Method: 提出了DenseGrounding方法。视觉特征方面，引入“层级场景语义增强器”，通过捕捉细粒度的全局场景特征并促进跨模态对齐来保留密集的视觉语义。文本描述方面，提出“语言语义增强器”，利用大型语言模型在模型训练期间提供丰富的上下文和多样化的语言描述。

Result: DenseGrounding在整体准确性上显著优于现有方法，在完整数据集和小型子集上分别取得了5.81%和7.56%的提升，进一步推动了自我中心3D视觉定位领域的SOTA。该方法还在CVPR 2024自动驾驶大挑战多视角3D视觉定位赛道获得第一名和创新奖。

Conclusion: DenseGrounding通过有效增强视觉和文本语义，显著提升了自我中心3D视觉定位的性能，验证了其有效性和鲁棒性，为机器人和人机交互领域的进步做出了贡献。

Abstract: Enabling intelligent agents to comprehend and interact with 3D environments
through natural language is crucial for advancing robotics and human-computer
interaction. A fundamental task in this field is ego-centric 3D visual
grounding, where agents locate target objects in real-world 3D spaces based on
verbal descriptions. However, this task faces two significant challenges: (1)
loss of fine-grained visual semantics due to sparse fusion of point clouds with
ego-centric multi-view images, (2) limited textual semantic context due to
arbitrary language descriptions. We propose DenseGrounding, a novel approach
designed to address these issues by enhancing both visual and textual
semantics. For visual features, we introduce the Hierarchical Scene Semantic
Enhancer, which retains dense semantics by capturing fine-grained global scene
features and facilitating cross-modal alignment. For text descriptions, we
propose a Language Semantic Enhancer that leverages large language models to
provide rich context and diverse language descriptions with additional context
during model training. Extensive experiments show that DenseGrounding
significantly outperforms existing methods in overall accuracy, with
improvements of 5.81% and 7.56% when trained on the comprehensive full dataset
and smaller mini subset, respectively, further advancing the SOTA in egocentric
3D visual grounding. Our method also achieves 1st place and receives the
Innovation Award in the CVPR 2024 Autonomous Grand Challenge Multi-view 3D
Visual Grounding Track, validating its effectiveness and robustness.

</details>


### [81] [ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment](https://arxiv.org/abs/2505.04974)
*Wanjiang Weng,Xiaofeng Tan,Hongsong Wang,Pan Zhou*

Main category: cs.CV

TL;DR: 该研究针对双语文本到动作生成任务，提出了新的双语动作数据集BiHumanML3D和一种名为BiMD结合ReAlign的扩散模型，以改善生成动作的语义一致性和质量。


<details>
  <summary>Details</summary>
Motivation: 双语文本到动作生成在跨语言应用中潜力巨大，但面临两大挑战：缺乏双语动作-语言数据集，以及现有扩散模型中文本与动作分布不一致导致语义不符或动作质量低下。

Method: 1. 提出了BiHumanML3D，一个新颖的双语人体动作数据集。2. 提出了双语动作扩散模型 (BiMD)，利用跨语言对齐表示捕捉语义。3. 在此基础上，提出了奖励引导采样对齐 (ReAlign) 方法，包含一个步骤感知的奖励模型来评估采样过程中的对齐质量，并用奖励引导策略优化扩散过程，该奖励模型结合了文本对齐和动作对齐模块。

Result: 实验表明，所提出的方法在文本-动作对齐和动作质量方面均显著优于现有的SOTA方法。

Conclusion: 通过构建新的双语数据集BiHumanML3D和开发BiMD及ReAlign方法，本研究有效解决了双语文本到动作生成中的关键挑战，显著提升了动作的语义一致性和质量。

Abstract: Bilingual text-to-motion generation, which synthesizes 3D human motions from
bilingual text inputs, holds immense potential for cross-linguistic
applications in gaming, film, and robotics. However, this task faces critical
challenges: the absence of bilingual motion-language datasets and the
misalignment between text and motion distributions in diffusion models, leading
to semantically inconsistent or low-quality motions. To address these
challenges, we propose BiHumanML3D, a novel bilingual human motion dataset,
which establishes a crucial benchmark for bilingual text-to-motion generation
models. Furthermore, we propose a Bilingual Motion Diffusion model (BiMD),
which leverages cross-lingual aligned representations to capture semantics,
thereby achieving a unified bilingual model. Building upon this, we propose
Reward-guided sampling Alignment (ReAlign) method, comprising a step-aware
reward model to assess alignment quality during sampling and a reward-guided
strategy that directs the diffusion process toward an optimally aligned
distribution. This reward model integrates step-aware tokens and combines a
text-aligned module for semantic consistency and a motion-aligned module for
realism, refining noisy motions at each timestep to balance probability density
and alignment. Experiments demonstrate that our approach significantly improves
text-motion alignment and motion quality compared to existing state-of-the-art
methods. Project page: https://wengwanjiang.github.io/ReAlign-page/.

</details>


### [82] [Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2505.04979)
*Zhuang Qi,Sijin Zhou,Lei Meng,Han Hu,Han Yu,Xiangxu Meng*

Main category: cs.CV

TL;DR: 提出了一种名为 FedDDL 的联邦解混淆与去偏学习方法，通过构建结构化因果图和后门调整来解决联邦学习中的属性偏差问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的属性偏差导致局部模型优化不一致，学习到非因果关联，从而降低性能。现有方法缺乏对推理路径的全面分析，且混杂因素的干扰限制了其效果。

Method: 提出了 FedDDL 方法：1. 构建结构化因果图分析模型推理过程，并执行后门调整消除混淆路径。2. 设计客户端内解混淆学习模块，用于解耦背景和对象，生成反事实样本，阻止模型利用背景推断标签。3. 设计客户端间去偏学习模块，构建因果原型以减少背景在原型组件中的比例，并通过因果原型正则化弥合异构表示之间的差距。

Result: 在2个基准数据集上的大量实验表明，FedDDL 显著增强了模型在未见过数据中关注主要对象的能力，平均 Top-1 准确率比9种最先进的现有方法高出4.5%。

Conclusion: FedDDL 方法通过因果分析和调整，有效缓解了联邦学习中的属性偏差问题，提升了模型性能，使其能更好地关注主要对象。

Abstract: Attribute bias in federated learning (FL) typically leads local models to
optimize inconsistently due to the learning of non-causal associations,
resulting degraded performance. Existing methods either use data augmentation
for increasing sample diversity or knowledge distillation for learning
invariant representations to address this problem. However, they lack a
comprehensive analysis of the inference paths, and the interference from
confounding factors limits their performance. To address these limitations, we
propose the \underline{Fed}erated \underline{D}econfounding and
\underline{D}ebiasing \underline{L}earning (FedDDL) method. It constructs a
structured causal graph to analyze the model inference process, and performs
backdoor adjustment to eliminate confounding paths. Specifically, we design an
intra-client deconfounding learning module for computer vision tasks to
decouple background and objects, generating counterfactual samples that
establish a connection between the background and any label, which stops the
model from using the background to infer the label. Moreover, we design an
inter-client debiasing learning module to construct causal prototypes to reduce
the proportion of the background in prototype components. Notably, it bridges
the gap between heterogeneous representations via causal prototypical
regularization. Extensive experiments on 2 benchmarking datasets demonstrate
that \methodname{} significantly enhances the model capability to focus on main
objects in unseen data, leading to 4.5\% higher Top-1 Accuracy on average over
9 state-of-the-art existing methods.

</details>


### [83] [StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps](https://arxiv.org/abs/2505.05001)
*Lang Nie,Chunyu Lin,Kang Liao,Yun Zhang,Shuaicheng Liu,Yao Zhao*

Main category: cs.CV

TL;DR: 该论文提出了StabStitch++框架，通过无监督学习同时实现空间拼接和时间稳定，以解决视频拼接中的“warping shake”（由不平滑的连续变换引起的时域内容抖动）问题。


<details>
  <summary>Details</summary>
Motivation: 解决视频拼接中的“warping shake”问题。即使用户输入的视频是稳定的，拼接后的视频也可能因为连续的变换不平滑而产生不期望的抖动，影响观看体验。现有方法如StabStitch会为了稳定而牺牲对齐效果。

Method: 提出了StabStitch++，一个新颖的无监督学习视频拼接框架。首先，设计了一个可微分双向分解模块，将图像投影到虚拟中间平面进行空间变换，以均匀分摊对齐负担。其次，通过整合空间和时间变换推导了拼接轨迹的数学表达式。最后，使用一个变换平滑模型和混合损失函数（鼓励内容对齐、轨迹平滑和在线协作）来生成稳定的拼接视频。同时，构建了一个视频拼接数据集用于训练和评估。

Result: StabStitch++在拼接性能、鲁棒性和效率方面均优于当前解决方案。它能够在不牺牲对齐效果的前提下同时优化对齐和稳定性，尤其在在线模式下表现更佳，并成功构建了一个实时的在线视频拼接系统。

Conclusion: StabStitch++有效地解决了视频拼接中的warping shake问题，通过同时实现高质量的空间拼接和时间稳定，为该领域带来了显著的进步，并支持构建实时在线视频拼接系统。

Abstract: We retarget video stitching to an emerging issue, named warping shake, which
unveils the temporal content shakes induced by sequentially unsmooth warps when
extending image stitching to video stitching. Even if the input videos are
stable, the stitched video can inevitably cause undesired warping shakes and
affect the visual experience. To address this issue, we propose StabStitch++, a
novel video stitching framework to realize spatial stitching and temporal
stabilization with unsupervised learning simultaneously. First, different from
existing learning-based image stitching solutions that typically warp one image
to align with another, we suppose a virtual midplane between original image
planes and project them onto it. Concretely, we design a differentiable
bidirectional decomposition module to disentangle the homography transformation
and incorporate it into our spatial warp, evenly spreading alignment burdens
and projective distortions across two views. Then, inspired by camera paths in
video stabilization, we derive the mathematical expression of stitching
trajectories in video stitching by elaborately integrating spatial and temporal
warps. Finally, a warp smoothing model is presented to produce stable stitched
videos with a hybrid loss to simultaneously encourage content alignment,
trajectory smoothness, and online collaboration. Compared with StabStitch that
sacrifices alignment for stabilization, StabStitch++ makes no compromise and
optimizes both of them simultaneously, especially in the online mode. To
establish an evaluation benchmark and train the learning framework, we build a
video stitching dataset with a rich diversity in camera motions and scenes.
Experiments exhibit that StabStitch++ surpasses current solutions in stitching
performance, robustness, and efficiency, offering compelling advancements in
this field by building a real-time online video stitching system.

</details>


### [84] [Automated Thoracolumbar Stump Rib Detection and Analysis in a Large CT Cohort](https://arxiv.org/abs/2505.05004)
*Hendrik Möller,Hanna Schön,Alina Dima,Benjamin Keinert-Weth,Robert Graf,Matan Atad,Johannes Paetzold,Friederike Jungmann,Rickmer Braren,Florian Kofler,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: 本研究开发了一种深度学习方法，用于自动检测和量化分析胸腰椎残余肋骨的形态特征，并发布了相关模型。


<details>
  <summary>Details</summary>
Motivation: 胸腰椎残余肋骨是胸腰椎过渡椎或计数异常的重要指标，但现有研究多为手动和定性评估，缺乏自动化和定量分析方法。

Method: 1. 训练了一个高分辨率深度学习模型进行肋骨分割。
2. 使用迭代算法和分段线性插值评估肋骨长度。
3. 定量分析残余肋骨与正常肋骨的形态特征（如关节连接位置、厚度、初始走向）。

Result: 1. 肋骨分割模型的Dice得分显著优于现有模型 (0.997 vs. 0.779)。
2. 肋骨长度评估的成功率为98.2%。
3. 残余肋骨与椎骨的关节连接更靠后、更薄，且初始几厘米内更倾向于向下和向侧面。
4. 利用这些形态特征，即使在肋骨部分可见的情况下，区分残余肋骨和正常肋骨的F1分数达到0.84。

Conclusion: 本研究成功开发了自动化检测和定量分析胸腰椎残余肋骨的方法，证明了其形态特征的差异性，并公开了模型权重和掩码供公众使用，有助于临床应用。

Abstract: Thoracolumbar stump ribs are one of the essential indicators of thoracolumbar
transitional vertebrae or enumeration anomalies. While some studies manually
assess these anomalies and describe the ribs qualitatively, this study aims to
automate thoracolumbar stump rib detection and analyze their morphology
quantitatively. To this end, we train a high-resolution deep-learning model for
rib segmentation and show significant improvements compared to existing models
(Dice score 0.997 vs. 0.779, p-value < 0.01). In addition, we use an iterative
algorithm and piece-wise linear interpolation to assess the length of the ribs,
showing a success rate of 98.2%. When analyzing morphological features, we show
that stump ribs articulate more posteriorly at the vertebrae (-19.2 +- 3.8 vs
-13.8 +- 2.5, p-value < 0.01), are thinner (260.6 +- 103.4 vs. 563.6 +- 127.1,
p-value < 0.01), and are oriented more downwards and sideways within the first
centimeters in contrast to full-length ribs. We show that with partially
visible ribs, these features can achieve an F1-score of 0.84 in differentiating
stump ribs from regular ones. We publish the model weights and masks for public
use.

</details>


### [85] [Driving with Context: Online Map Matching for Complex Roads Using Lane Markings and Scenario Recognition](https://arxiv.org/abs/2505.05007)
*Xin Bi,Zhichao Li,Yuxuan Xia,Panpan Tong,Lijuan Zhang,Yang Chen,Junsheng Fu*

Main category: cs.CV

TL;DR: 提出了一种基于隐马尔可夫模型（HMM）和多概率因子的在线标准清晰度（SD）地图匹配方法，通过利用车道线和场景识别，提高了复杂路网（尤其是多层道路区域）的匹配精度。


<details>
  <summary>Details</summary>
Motivation: 现有的在线地图匹配方法在复杂路网，特别是多层道路区域容易出错，影响车辆导航和智能驾驶功能的激活。

Method: 构建了一个包含多个概率因子的隐马尔可夫模型（HMM）。首先，通过多车道跟踪生成车道线并与SD地图关联构建增强型SD地图，车辆可通过迭代最近点（ICP）配准车道线进行重定位，并计算车道线检测的概率因子。其次，应用驾驶场景识别模型生成场景识别的发射概率因子，以改善高架道路及其下方普通城市道路的匹配性能。

Result: 该方法有效提高了在线地图匹配精度，尤其是在多层道路区域。在Zenseact开放数据集和上海多层道路区域测试数据上，F1分数分别达到98.04%和94.60%，显著优于基准方法。

Conclusion: 所提出的基于HMM并融合车道线和场景识别的在线SD地图匹配方法，能够显著提升在复杂路网（特别是多层道路）中的地图匹配准确性。

Abstract: Accurate online map matching is fundamental to vehicle navigation and the
activation of intelligent driving functions. Current online map matching
methods are prone to errors in complex road networks, especially in multilevel
road area. To address this challenge, we propose an online Standard Definition
(SD) map matching method by constructing a Hidden Markov Model (HMM) with
multiple probability factors. Our proposed method can achieve accurate map
matching even in complex road networks by carefully leveraging lane markings
and scenario recognition in the designing of the probability factors. First,
the lane markings are generated by a multi-lane tracking method and associated
with the SD map using HMM to build an enriched SD map. In areas covered by the
enriched SD map, the vehicle can re-localize itself by performing Iterative
Closest Point (ICP) registration for the lane markings. Then, the probability
factor accounting for the lane marking detection can be obtained using the
association probability between adjacent lanes and roads. Second, the driving
scenario recognition model is applied to generate the emission probability
factor of scenario recognition, which improves the performance of map matching
on elevated roads and ordinary urban roads underneath them. We validate our
method through extensive road tests in Europe and China, and the experimental
results show that our proposed method effectively improves the online map
matching accuracy as compared to other existing methods, especially in
multilevel road area. Specifically, the experiments show that our proposed
method achieves $F_1$ scores of 98.04% and 94.60% on the Zenseact Open Dataset
and test data of multilevel road areas in Shanghai respectively, significantly
outperforming benchmark methods. The implementation is available at
https://github.com/TRV-Lab/LMSR-OMM.

</details>


### [86] [Adaptive Contextual Embedding for Robust Far-View Borehole Detection](https://arxiv.org/abs/2505.05008)
*Xuesong Liu,Tianyu Hao,Emmett J. Ientilucci*

Main category: cs.CV

TL;DR: 提出一种自适应方法，通过增强YOLO等现有架构，利用指数移动平均（EMA）更新的嵌入表示，以精确检测远距离图像中密集分布的微小炮孔。


<details>
  <summary>Details</summary>
Motivation: 现有方法在检测小尺寸、密集排列且视觉特征有限的炮孔时面临挑战，而精确检测对爆破作业的安全和效率至关重要。

Method: 该方法在现有架构（如YOLO）基础上，引入三个协同组件：(1) 利用动态更新图像统计信息的自适应增强，处理光照和纹理变化；(2) 嵌入稳定化，确保特征提取的一致性和可靠性；(3) 利用空间上下文进行上下文优化，提高检测精度。整个方法广泛使用指数移动平均（EMA）进行统计更新和表征学习。

Result: 在具有挑战性的专有采石场数据集上的实验表明，与基线YOLO架构相比，该方法取得了显著的改进。

Conclusion: 该方法在真实复杂的工业场景中能有效检测密集分布的微小炮孔，证明了其有效性。

Abstract: In controlled blasting operations, accurately detecting densely distributed
tiny boreholes from far-view imagery is critical for operational safety and
efficiency. However, existing detection methods often struggle due to small
object scales, highly dense arrangements, and limited distinctive visual
features of boreholes. To address these challenges, we propose an adaptive
detection approach that builds upon existing architectures (e.g., YOLO) by
explicitly leveraging consistent embedding representations derived through
exponential moving average (EMA)-based statistical updates.
  Our method introduces three synergistic components: (1) adaptive augmentation
utilizing dynamically updated image statistics to robustly handle illumination
and texture variations; (2) embedding stabilization to ensure consistent and
reliable feature extraction; and (3) contextual refinement leveraging spatial
context for improved detection accuracy. The pervasive use of EMA in our method
is particularly advantageous given the limited visual complexity and small
scale of boreholes, allowing stable and robust representation learning even
under challenging visual conditions. Experiments on a challenging proprietary
quarry-site dataset demonstrate substantial improvements over baseline
YOLO-based architectures, highlighting our method's effectiveness in realistic
and complex industrial scenarios.

</details>


### [87] [SOAP: Style-Omniscient Animatable Portraits](https://arxiv.org/abs/2505.05022)
*Tingting Liao,Yujian Zheng,Adilbek Karmanov,Liwen Hu,Leyang Jin,Yuliang Xiu,Hao Li*

Main category: cs.CV

TL;DR: 提出SOAP框架，能从任意风格的单张肖像图片生成可动画、拓扑一致的3D头像。


<details>
  <summary>Details</summary>
Motivation: 从单张图片创建可动画3D头像面临风格多样性（写实、卡通、动漫）的限制，以及难以处理配饰或复杂发型的问题。现有3D扩散模型虽在单视图重建通用物体方面取得进展，但其输出往往缺乏动画控制，或因领域差异导致生成头像时出现伪影。

Method: 提出了SOAP（风格全知）框架：1. 利用一个在包含多种风格的24K 3D头部数据上训练的多视图扩散模型。2. 采用自适应优化流程，通过可微分渲染来变形FLAME网格，同时保持其拓扑结构和骨骼绑定。

Result: 生成的纹理化头像支持基于面部动作编码系统（FACS）的动画，集成了眼球和牙齿，并能保留如编发或配饰等细节。大量实验证明，该方法在单视图头部建模和基于扩散的图像转3D生成方面均优于现有顶尖技术。

Conclusion: SOAP框架能够有效地从单张任意风格的肖像图片生成高质量、可动画、且保留细节的3D头像，解决了现有方法在风格多样性和复杂细节处理上的不足。

Abstract: Creating animatable 3D avatars from a single image remains challenging due to
style limitations (realistic, cartoon, anime) and difficulties in handling
accessories or hairstyles. While 3D diffusion models advance single-view
reconstruction for general objects, outputs often lack animation controls or
suffer from artifacts because of the domain gap. We propose SOAP, a
style-omniscient framework to generate rigged, topology-consistent avatars from
any portrait. Our method leverages a multiview diffusion model trained on 24K
3D heads with multiple styles and an adaptive optimization pipeline to deform
the FLAME mesh while maintaining topology and rigging via differentiable
rendering. The resulting textured avatars support FACS-based animation,
integrate with eyeballs and teeth, and preserve details like braided hair or
accessories. Extensive experiments demonstrate the superiority of our method
over state-of-the-art techniques for both single-view head modeling and
diffusion-based generation of Image-to-3D. Our code and data are publicly
available for research purposes at https://github.com/TingtingLiao/soap.

</details>


### [88] [Split Matching for Inductive Zero-shot Semantic Segmentation](https://arxiv.org/abs/2505.05023)
*Jialei Chen,Xu Zheng,Dongyue Li,Chong Yi,Seigo Ito,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TL;DR: 本文提出一种分裂匹配（SM）方法，用于零样本语义分割。该方法通过解耦匈牙利匹配，分别处理已见和潜在未见类别，并引入多尺度特征增强模块，有效提升了对未见类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本语义分割方法在处理未见类别时面临挑战：微调视觉语言模型易对已见类别过拟合，而基于查询的方法中，传统匈牙利匹配需要完全监督且常将未见类别误判为背景。

Method: 提出分裂匹配（SM）策略：1) 将匈牙利匹配解耦，分别优化已见类（有标注区域）和潜在未见类（无标注区域，通过聚类CLIP特征生成伪掩码和区域嵌入发现）。2) 查询被划分为已见组和候选组，根据各自可用的监督信息独立优化和匹配。3) 引入多尺度特征增强（MFE）模块，通过残差多尺度聚合细化解码器特征，改善空间细节捕捉。

Result: 分裂匹配（SM）方法在两个标准的零样本语义分割基准测试中均取得了最先进（SOTA）的性能。

Conclusion: 分裂匹配（SM）是首个在归纳式零样本语义分割设置下引入解耦匈牙利匹配的方法，它有效解决了未见类别的分割问题，并显著提升了模型性能。

Abstract: Zero-shot Semantic Segmentation (ZSS) aims to segment categories that are not
annotated during training. While fine-tuning vision-language models has
achieved promising results, these models often overfit to seen categories due
to the lack of supervision for unseen classes. As an alternative to fully
supervised approaches, query-based segmentation has shown great latent in ZSS,
as it enables object localization without relying on explicit labels. However,
conventional Hungarian matching, a core component in query-based frameworks,
needs full supervision and often misclassifies unseen categories as background
in the setting of ZSS. To address this issue, we propose Split Matching (SM), a
novel assignment strategy that decouples Hungarian matching into two
components: one for seen classes in annotated regions and another for latent
classes in unannotated regions (referred to as unseen candidates).
Specifically, we partition the queries into seen and candidate groups, enabling
each to be optimized independently according to its available supervision. To
discover unseen candidates, we cluster CLIP dense features to generate pseudo
masks and extract region-level embeddings using CLS tokens. Matching is then
conducted separately for the two groups based on both class-level similarity
and mask-level consistency. Additionally, we introduce a Multi-scale Feature
Enhancement (MFE) module that refines decoder features through residual
multi-scale aggregation, improving the model's ability to capture spatial
details across resolutions. SM is the first to introduce decoupled Hungarian
matching under the inductive ZSS setting, and achieves state-of-the-art
performance on two standard benchmarks.

</details>


### [89] [xTrace: A Facial Expressive Behaviour Analysis Tool for Continuous Affect Recognition](https://arxiv.org/abs/2505.05043)
*Mani Kumar Tellamekala,Shashank Jaiswal,Thomas Smith,Timur Alamev,Gary McKeown,Anthony Brown,Michel Valstar*

Main category: cs.CV

TL;DR: 本文介绍 xTrace，一款用于自然场景面部表情分析的鲁棒工具，通过大规模数据训练和高效特征解决现有挑战，能准确预测情感维度。


<details>
  <summary>Details</summary>
Motivation: 在自然和真实场景下实时进行面部表情行为分析面临两大挑战：1) 缺乏覆盖广泛情感空间的大规模标记面部情感视频数据集；2) 难以提取具有判别性、可解释性、鲁棒性和计算效率的面部视频特征。

Method: 本文引入了 xTrace 工具。为了解决数据稀缺问题，xTrace 的情感识别模型在包含约45万视频的大规模面部情感视频数据集上进行训练。为了解决特征提取问题，xTrace 使用了可解释、高精度、鲁棒且计算复杂度低的面部情感描述符。该工具与 MediaPipe、OpenFace 和 Augsburg Affect Toolbox 进行了基准比较。

Result: 在包含5万个视频的自然场景验证集上，xTrace 达到了 0.86 的平均一致性相关系数 (CCC) 和 0.13 的平均绝对误差。详细的误差分析表明，xTrace 在二维情感空间的大多数区域都能高精度识别情感，对非正面头部姿态具有鲁棒性，并且其不确定性估计与其准确性之间存在强相关性。

Conclusion: xTrace 是一款鲁棒的面部表情行为分析工具，能够有效预测维度情感（效价和唤醒度）。它通过解决大规模数据缺乏和高效特征提取的挑战，在自然场景下的面部表情分析方面表现出色，具有广泛的应用前景。

Abstract: Recognising expressive behaviours in face videos is a long-standing challenge
in Affective Computing. Despite significant advancements in recent years, it
still remains a challenge to build a robust and reliable system for
naturalistic and in-the-wild facial expressive behaviour analysis in real time.
This paper addresses two key challenges in building such a system: (1). The
paucity of large-scale labelled facial affect video datasets with extensive
coverage of the 2D emotion space, and (2). The difficulty of extracting facial
video features that are discriminative, interpretable, robust, and
computationally efficient. Toward addressing these challenges, we introduce
xTrace, a robust tool for facial expressive behaviour analysis and predicting
continuous values of dimensional emotions, namely valence and arousal, from
in-the-wild face videos.
  To address challenge (1), our affect recognition model is trained on the
largest facial affect video data set, containing ~450k videos that cover most
emotion zones in the dimensional emotion space, making xTrace highly versatile
in analysing a wide spectrum of naturalistic expressive behaviours. To address
challenge (2), xTrace uses facial affect descriptors that are not only
explainable, but can also achieve a high degree of accuracy and robustness with
low computational complexity. The key components of xTrace are benchmarked
against three existing tools: MediaPipe, OpenFace, and Augsburg Affect Toolbox.
On an in-the-wild validation set composed of 50k videos, xTrace achieves 0.86
mean CCC and 0.13 mean absolute error values. We present a detailed error
analysis of affect predictions from xTrace, illustrating (a). its ability to
recognise emotions with high accuracy across most bins in the 2D emotion space,
(b). its robustness to non-frontal head pose angles, and (c). a strong
correlation between its uncertainty estimates and its accuracy.

</details>


### [90] [UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model](https://arxiv.org/abs/2505.05049)
*Timo Kaiser,Thomas Norrenbrock,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: 本文提出了一种名为USAM的轻量级后处理不确定性量化方法，用于量化Segment Anything Model (SAM)的预测不确定性，并能区分不同来源的不确定性。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM在语义分割中应用广泛，但量化其预测的不确定性（特别是由于其类别无关的特性）对现有方法构成了挑战。有效的不确定性量化对于许多任务至关重要。

Method: 提出了一种基于贝叶斯熵公式的理论驱动的不确定性量化模型，该模型同时考虑了偶然不确定性、认知不确定性和新引入的任务不确定性。基于此公式训练了一个名为USAM的轻量级后处理不确定性量化方法。该模型能将不确定性追溯到模型参数不足、提示不充分或图像模糊性。

Result: 所提出的确定性USAM方法在SA-V、MOSE、ADE20k、DAVIS和COCO等多个数据集上展示了优越的预测能力。

Conclusion: USAM是一种计算成本低廉且易于使用的不确定性量化替代方案，可以支持用户提示、增强半监督学习流程，或在准确性和成本效益之间进行权衡。

Abstract: The introduction of the Segment Anything Model (SAM) has paved the way for
numerous semantic segmentation applications. For several tasks, quantifying the
uncertainty of SAM is of particular interest. However, the ambiguous nature of
the class-agnostic foundation model SAM challenges current uncertainty
quantification (UQ) approaches. This paper presents a theoretically motivated
uncertainty quantification model based on a Bayesian entropy formulation
jointly respecting aleatoric, epistemic, and the newly introduced task
uncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ
method. Our model traces the root of uncertainty back to under-parameterised
models, insufficient prompts or image ambiguities. Our proposed deterministic
USAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k,
DAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ
alternative that can support user-prompting, enhance semi-supervised pipelines,
or balance the tradeoff between accuracy and cost efficiency.

</details>


### [91] [ULFine: Unbiased Lightweight Fine-tuning for Foundation-Model-Assisted Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2505.05062)
*Enhao Zhang,Chaohua Li,Chuanxing Geng,Songcan Chen*

Main category: cs.CV

TL;DR: 本文探讨了大型视觉基础模型在长尾半监督学习（LTSSL）中的应用，发现现有微调策略的局限性，并提出了一种新的无偏轻量级微调策略（ULFine），该策略显著降低了训练成本并提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉基础模型在各种下游任务中取得了成功，但其在长尾半监督学习（LTSSL）中的影响尚不明确。初步研究发现，全量微调（FFT）会降低模型性能，而线性探测（LP）和轻量级微调（LFT）虽能提升整体性能，但对尾部类别的改善微乎其微，且分别存在伪标签错误和对错误伪标签过自信的问题，加剧了LTSSL固有的偏差。

Method: 首先，论文分析了将基础模型应用于LTSSL的三种策略：线性探测（LP）、轻量级微调（LFT）和全量微调（FFT）的不足。基于这些分析，提出了一种名为ULFine（无偏轻量级微调）的新策略。ULFine通过“基于置信度的自适应文本原型拟合”来减轻过度自信，并通过“双logits的互补融合”来抵消伪标签和分类器偏差。

Result: 与从头开始训练的LTSSL算法相比，FFT导致性能下降，而LP和LFT对尾部类别益处甚微。LP产生大量错误伪标签，LFT则对此类标签过分自信。所提出的ULFine策略与现有最先进方法相比，训练成本降低了十倍以上，并且预测准确率得到显著提升。

Conclusion: 直接应用大型视觉基础模型到长尾半监督学习中，使用常见的微调策略存在局限性，尤其对尾部类别效果不佳。提出的ULFine策略通过减轻过度自信和偏差，有效地解决了这些问题，显著提升了LTSSL任务的训练效率和预测精度。

Abstract: Based on the success of large-scale visual foundation models like CLIP in
various downstream tasks, this paper initially attempts to explore their impact
on Long-Tailed Semi-Supervised Learning (LTSSL) by employing the foundation
model with three strategies: Linear Probing (LP), Lightweight Fine-Tuning
(LFT), and Full Fine-Tuning (FFT). Our analysis presents the following
insights: i) Compared to LTSSL algorithms trained from scratch, FFT results in
a decline in model performance, whereas LP and LFT, although boosting overall
model performance, exhibit negligible benefits to tail classes. ii) LP produces
numerous false pseudo-labels due to \textit{underlearned} training data, while
LFT can reduce the number of these false labels but becomes overconfident about
them owing to \textit{biased fitting} training data. This exacerbates the
pseudo-labeled and classifier biases inherent in LTSSL, limiting performance
improvement in the tail classes. With these insights, we propose a Unbiased
Lightweight Fine-tuning strategy, \textbf{ULFine}, which mitigates the
overconfidence via confidence-aware adaptive fitting of textual prototypes and
counteracts the pseudo-labeled and classifier biases via complementary fusion
of dual logits. Extensive experiments demonstrate that ULFine markedly
decreases training costs by over ten times and substantially increases
prediction accuracies compared to state-of-the-art methods.

</details>


### [92] [FG-CLIP: Fine-Grained Visual and Textual Alignment](https://arxiv.org/abs/2505.05071)
*Chunyu Xie,Bin Wang,Fanjing Kong,Jincheng Li,Dawei Liang,Gengshen Zhang,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: 提出了FG-CLIP，通过生成长字幕、区域字幕和硬负样本等方式改进数据，并设计相应训练方法，以增强模型的细粒度理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP模型专注于粗粒度的简短字幕，导致其在细粒度理解方面表现不佳。

Method: 提出FG-CLIP，通过三个关键创新增强细粒度理解：1) 利用大型多模态模型生成16亿长字幕-图像对；2) 构建包含1200万图像和4000万与详细字幕对齐的区域特定边界框的高质量数据集；3) 引入1000万硬细粒度负样本，并为这些数据设计了相应的训练方法。

Result: FG-CLIP在细粒度理解、开放词汇对象检测、图文检索和通用多模态基准测试等多种下游任务中均优于原始CLIP及其他最先进方法。

Conclusion: FG-CLIP能有效捕捉图像的细粒度细节，并提升整体模型性能。

Abstract: Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks
such as image-text retrieval and zero-shot classification but struggles with
fine-grained understanding due to its focus on coarse-grained short captions.
To address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances
fine-grained understanding through three key innovations. First, we leverage
large multimodal models to generate 1.6 billion long caption-image pairs for
capturing global-level semantic details. Second, a high-quality dataset is
constructed with 12 million images and 40 million region-specific bounding
boxes aligned with detailed captions to ensure precise, context-rich
representations. Third, 10 million hard fine-grained negative samples are
incorporated to improve the model's ability to distinguish subtle semantic
differences. Corresponding training methods are meticulously designed for these
data. Extensive experiments demonstrate that FG-CLIP outperforms the original
CLIP and other state-of-the-art methods across various downstream tasks,
including fine-grained understanding, open-vocabulary object detection,
image-text retrieval, and general multimodal benchmarks. These results
highlight FG-CLIP's effectiveness in capturing fine-grained image details and
improving overall model performance. The related data, code, and models are
available at https://github.com/360CVGroup/FG-CLIP.

</details>


### [93] [Visual Affordances: Enabling Robots to Understand Object Functionality](https://arxiv.org/abs/2505.05074)
*Tommaso Apicella,Alessio Xompero,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 该研究针对视觉功能预测在人机交互中的复现性问题，提出了统一框架、文献综述、Affordance Sheet 及物理属性（如重量）融合方法，以连接感知与机器人执行。


<details>
  <summary>Details</summary>
Motivation: 当前视觉功能预测（如抓取、分类、分割）在不同任务中定义各异，导致基准比较不公、结果不可靠，存在严重的复现性问题。同时，视觉感知与机器人物理交互之间存在差距。

Method: 1. 提出视觉功能预测的统一公式；2. 对现有方法和数据集进行系统性综述，分析其优缺点及复现性挑战；3. 引入“Affordance Sheet”文档以提高研究透明度；4. 提出一个通用框架，将视觉功能预测与物体的物理属性（以重量为例）联系起来。

Result: 提出了解决视觉功能预测复现性问题的综合方案，包括：一个统一的公式，一份全面的文献综述，一个名为“Affordance Sheet”的透明化工具，以及一个将视觉预测与物体物理属性（如重量）相结合的通用框架，并讨论了质量估计对功能预测的影响。

Conclusion: 该方法通过统一功能预测、引入透明化工具和整合物理属性，旨在弥合功能感知与机器人驱动之间的差距，更全面地考虑物体信息及机器人交互方式，从而解决领域内的复现性挑战并提升辅助技术的有效性。

Abstract: Human-robot interaction for assistive technologies relies on the prediction
of affordances, which are the potential actions a robot can perform on objects.
Predicting object affordances from visual perception is formulated differently
for tasks such as grasping detection, affordance classification, affordance
segmentation, and hand-object interaction synthesis. In this work, we highlight
the reproducibility issue in these redefinitions, making comparative benchmarks
unfair and unreliable. To address this problem, we propose a unified
formulation for visual affordance prediction, provide a comprehensive and
systematic review of previous works highlighting strengths and limitations of
methods and datasets, and analyse what challenges reproducibility. To favour
transparency, we introduce the Affordance Sheet, a document to detail the
proposed solution, the datasets, and the validation. As the physical properties
of an object influence the interaction with the robot, we present a generic
framework that links visual affordance prediction to the physical world. Using
the weight of an object as an example for this framework, we discuss how
estimating object mass can affect the affordance prediction. Our approach
bridges the gap between affordance perception and robot actuation, and accounts
for the complete information about objects of interest and how the robot
interacts with them to accomplish its task.

</details>


### [94] [PIDiff: Image Customization for Personalized Identities with Diffusion Models](https://arxiv.org/abs/2505.05081)
*Jinyu Gu,Haipeng Liu,Meng Wang,Yang Wang*

Main category: cs.CV

TL;DR: 论文提出PIDiff，一种基于微调的扩散模型，利用W+空间和身份定制微调策略，解决个性化文本到图像生成中的身份与背景纠缠问题，实现高保真度和风格编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化文本到图像生成方法难以有效分离身份信息和背景信息，导致身份特征丢失、图像多样性降低，即使利用W+空间也存在语义干扰问题。

Method: 提出PIDiff模型：一种基于微调的扩散模型，利用StyleGAN的W+空间进行多层次身份特征表示，并结合身份定制的微调策略、新的交叉注意力模块和参数优化策略，以避免语义纠缠，实现准确的特征提取和定位。

Result: PIDiff能够有效保留身份信息，保持预训练模型对复杂背景图像的生成能力，并实现准确的特征提取与定位。实验结果验证了该方法在个性化文本到图像生成任务上的有效性。

Conclusion: PIDiff通过结合W+空间和定制的微调策略，成功解决了个性化文本到图像生成中的身份与背景语义纠缠问题，提升了生成图像的身份保真度和多样性，并支持风格编辑。

Abstract: Text-to-image generation for personalized identities aims at incorporating
the specific identity into images using a text prompt and an identity image.
Based on the powerful generative capabilities of DDPMs, many previous works
adopt additional prompts, such as text embeddings and CLIP image embeddings, to
represent the identity information, while they fail to disentangle the identity
information and background information. As a result, the generated images not
only lose key identity characteristics but also suffer from significantly
reduced diversity. To address this issue, previous works have combined the W+
space from StyleGAN with diffusion models, leveraging this space to provide a
more accurate and comprehensive representation of identity features through
multi-level feature extraction. However, the entanglement of identity and
background information in in-the-wild images during training prevents accurate
identity localization, resulting in severe semantic interference between
identity and background. In this paper, we propose a novel fine-tuning-based
diffusion model for personalized identities text-to-image generation, named
PIDiff, which leverages the W+ space and an identity-tailored fine-tuning
strategy to avoid semantic entanglement and achieves accurate feature
extraction and localization. Style editing can also be achieved by PIDiff
through preserving the characteristics of identity features in the W+ space,
which vary from coarse to fine. Through the combination of the proposed
cross-attention block and parameter optimization strategy, PIDiff preserves the
identity information and maintains the generation capability for in-the-wild
images of the pre-trained model during inference. Our experimental results
validate the effectiveness of our method in this task.

</details>


### [95] [Nonlinear Motion-Guided and Spatio-Temporal Aware Network for Unsupervised Event-Based Optical Flow](https://arxiv.org/abs/2505.05089)
*Zuntao Liu,Hao Zhuang,Junjie Jiang,Yuhang Song,Zheng Fang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 E-NMSTFlow 的新型无监督事件相机光流估计网络，该网络通过专门设计的时空特征模块和非线性运动补偿损失，有效处理长时间序列数据，提升了光流估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的事件相机光流方法未能充分利用事件的时空特性，且通常假设线性运动，这在长时间序列中会导致光流估计不准确。研究认为，充分利用时空信息和准确建模非线性运动是提升性能的关键。

Method: 提出了 E-NMSTFlow，一个无监督事件相机光流网络。核心包括：1) 时空运动特征感知 (STMFA) 模块和自适应运动特征增强 (AMFE) 模块，用于学习时空数据关联；2) 非线性运动补偿损失函数，用于利用事件间的非线性运动改进无监督学习。

Result: 大量实验验证了 E-NMSTFlow 方法的有效性和优越性。该方法在 MVSEC 和 DSEC-Flow 数据集上的无监督学习方法中取得了最佳性能（排名第一）。

Conclusion: E-NMSTFlow 通过有效利用事件的时空信息和精确建模非线性运动，显著改进了长时间序列下的无监督事件相机光流估计，并在公开数据集上取得了领先的无监督学习结果。

Abstract: Event cameras have the potential to capture continuous motion information
over time and space, making them well-suited for optical flow estimation.
However, most existing learning-based methods for event-based optical flow
adopt frame-based techniques, ignoring the spatio-temporal characteristics of
events. Additionally, these methods assume linear motion between consecutive
events within the loss time window, which increases optical flow errors in
long-time sequences. In this work, we observe that rich spatio-temporal
information and accurate nonlinear motion between events are crucial for
event-based optical flow estimation. Therefore, we propose E-NMSTFlow, a novel
unsupervised event-based optical flow network focusing on long-time sequences.
We propose a Spatio-Temporal Motion Feature Aware (STMFA) module and an
Adaptive Motion Feature Enhancement (AMFE) module, both of which utilize rich
spatio-temporal information to learn spatio-temporal data associations.
Meanwhile, we propose a nonlinear motion compensation loss that utilizes the
accurate nonlinear motion between events to improve the unsupervised learning
of our network. Extensive experiments demonstrate the effectiveness and
superiority of our method. Remarkably, our method ranks first among
unsupervised learning methods on the MVSEC and DSEC-Flow datasets. Our project
page is available at https://wynelio.github.io/E-NMSTFlow.

</details>


### [96] [DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions](https://arxiv.org/abs/2505.05091)
*Shashank Agnihotri,Amaan Ansari,Annika Dackermann,Fabian Rösch,Margret Keuper*

Main category: cs.CV

TL;DR: 该研究提出了 DispBench，一个用于评估深度学习视差估计算法鲁棒性的综合基准测试工具。


<details>
  <summary>Details</summary>
Motivation: 深度学习视差估计算法易受分布变化和对抗性攻击影响，但目前缺乏评估其鲁棒性的标准化基准，这阻碍了该领域的发展。

Method: 引入 DispBench 工具，通过在多个数据集和多样化损坏场景下，使用合成图像损坏（如对抗性攻击和由二维常见损坏引起的分布外偏移）来系统地评估视差估计算法的可靠性。

Result: 研究团队进行了迄今为止最广泛的视差估计算法性能和鲁棒性分析，揭示了准确性、可靠性和泛化能力之间的关键相关性。

Conclusion: DispBench 填补了视差估计方法鲁棒性评估的空白，为提升算法的可靠性和泛化能力提供了标准化平台和重要见解。

Abstract: Deep learning (DL) has surpassed human performance on standard benchmarks,
driving its widespread adoption in computer vision tasks. One such task is
disparity estimation, estimating the disparity between matching pixels in
stereo image pairs, which is crucial for safety-critical applications like
medical surgeries and autonomous navigation. However, DL-based disparity
estimation methods are highly susceptible to distribution shifts and
adversarial attacks, raising concerns about their reliability and
generalization. Despite these concerns, a standardized benchmark for evaluating
the robustness of disparity estimation methods remains absent, hindering
progress in the field.
  To address this gap, we introduce DispBench, a comprehensive benchmarking
tool for systematically assessing the reliability of disparity estimation
methods. DispBench evaluates robustness against synthetic image corruptions
such as adversarial attacks and out-of-distribution shifts caused by 2D Common
Corruptions across multiple datasets and diverse corruption scenarios. We
conduct the most extensive performance and robustness analysis of disparity
estimation methods to date, uncovering key correlations between accuracy,
reliability, and generalization. Open-source code for DispBench:
https://github.com/shashankskagnihotri/benchmarking_robustness/tree/disparity_estimation/final/disparity_estimation

</details>


### [97] [MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via Diffusion Models](https://arxiv.org/abs/2505.05101)
*Hongyang Zhu,Haipeng Liu,Bo Fu,Yang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为MDE-Edit的免训练、推理阶段优化方法，通过目标对齐损失和颜色一致性损失，在扩散模型中实现对复杂场景下多目标的精确编辑，解决了定位不准和属性错配问题。


<details>
  <summary>Details</summary>
Motivation: 现有多目标编辑方法在处理重叠或交互对象时，常因注意力错位导致定位不准、编辑不完整，或因交叉注意力泄露导致颜色纹理与目标区域不匹配、产生语义冲突（如颜色渗透）。现有方法难以有效应对这些挑战。

Method: 提出了MDE-Edit，一种免训练的推理阶段优化方法。它通过优化扩散模型中的噪声潜在特征来实现精确的局部图像操纵。核心是两个损失函数：1) 目标对齐损失 (OAL)，将多层交叉注意力与分割掩码对齐以精确定位对象；2) 颜色一致性损失 (CCL)，放大掩码内目标属性的注意力并抑制向邻近区域的泄漏。

Result: 大量实验证明，MDE-Edit在编辑准确性和视觉质量方面均优于当前最先进的方法，能够实现更精准、更连贯的多目标编辑效果。

Conclusion: MDE-Edit为复杂多目标图像编辑任务提供了一个鲁棒的解决方案，有效解决了目标定位不准和属性错配的难题，提升了编辑的准确性和视觉质量。

Abstract: Multi-object editing aims to modify multiple objects or regions in complex
scenes while preserving structural coherence. This task faces significant
challenges in scenarios involving overlapping or interacting objects: (1)
Inaccurate localization of target objects due to attention misalignment,
leading to incomplete or misplaced edits; (2) Attribute-object mismatch, where
color or texture changes fail to align with intended regions due to
cross-attention leakage, creating semantic conflicts (\textit{e.g.}, color
bleeding into non-target areas). Existing methods struggle with these
challenges: approaches relying on global cross-attention mechanisms suffer from
attention dilution and spatial interference between objects, while mask-based
methods fail to bind attributes to geometrically accurate regions due to
feature entanglement in multi-object scenarios. To address these limitations,
we propose a training-free, inference-stage optimization approach that enables
precise localized image manipulation in complex multi-object scenes, named
MDE-Edit. MDE-Edit optimizes the noise latent feature in diffusion models via
two key losses: Object Alignment Loss (OAL) aligns multi-layer cross-attention
with segmentation masks for precise object positioning, and Color Consistency
Loss (CCL) amplifies target attribute attention within masks while suppressing
leakage to adjacent regions. This dual-loss design ensures localized and
coherent multi-object edits. Extensive experiments demonstrate that MDE-Edit
outperforms state-of-the-art methods in editing accuracy and visual quality,
offering a robust solution for complex multi-object image manipulation tasks.

</details>


### [98] [Automated vision-based assistance tools in bronchoscopy: stenosis severity estimation](https://arxiv.org/abs/2505.05136)
*Clara Tomasini,Javier Rodriguez-Puigvert,Dinora Polanco,Manuel Viñuales,Luis Riazuelo,Ana Cristina Murillo*

Main category: cs.CV

TL;DR: 该研究提出了一种利用支气管镜检查视频自动评估声门下狭窄严重程度的方法，通过分析光照衰减构建气道三维模型进行测量。


<details>
  <summary>Details</summary>
Motivation: 目前声门下狭窄的评估依赖CT或主观的专家目视检查，缺乏一致性和稳健性，且无公开的基于支气管镜视频的自动化评估方法。

Method: 提出一个自动化流程，利用内窥镜的光照衰减物理效应分割和跟踪管腔，从单帧图像获取气道三维模型，并用此模型测量气道狭窄程度，无需医生穿过狭窄区域。

Result: 该流程首次实现了基于支气管镜图像的自动化、稳健的声门下狭窄严重程度测量。结果与CT扫描基准值和专家评估一致，且在同一患者多次评估中具可靠重复性。评估使用了新的声门下狭窄数据集。

Conclusion: 该研究证明了仅用支气管镜即可自动评估声门下狭窄严重程度，能辅助并缩短诊断监测流程，提供自动化可重复的评估，减少检查时间，并避免CT辐射。同时发布了首个该领域评估的公开基准。

Abstract: Purpose: Subglottic stenosis refers to the narrowing of the subglottis, the
airway between the vocal cords and the trachea. Its severity is typically
evaluated by estimating the percentage of obstructed airway. This estimation
can be obtained from CT data or through visual inspection by experts exploring
the region. However, visual inspections are inherently subjective, leading to
less consistent and robust diagnoses. No public methods or datasets are
currently available for automated evaluation of this condition from
bronchoscopy video.
  Methods: We propose a pipeline for automated subglottic stenosis severity
estimation during the bronchoscopy exploration, without requiring the physician
to traverse the stenosed region. Our approach exploits the physical effect of
illumination decline in endoscopy to segment and track the lumen and obtain a
3D model of the airway. This 3D model is obtained from a single frame and is
used to measure the airway narrowing.
  Results: Our pipeline is the first to enable automated and robust subglottic
stenosis severity measurement using bronchoscopy images. The results show
consistency with ground-truth estimations from CT scans and expert estimations,
and reliable repeatability across multiple estimations on the same patient. Our
evaluation is performed on our new Subglottic Stenosis Dataset of real
bronchoscopy procedures data.
  Conclusion: We demonstrate how to automate evaluation of subglottic stenosis
severity using only bronchoscopy. Our approach can assist with and shorten
diagnosis and monitoring procedures, with automated and repeatable estimations
and less exploration time, and save radiation exposure to patients as no CT is
required. Additionally, we release the first public benchmark for subglottic
stenosis severity assessment.

</details>


### [99] [Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models](https://arxiv.org/abs/2505.05163)
*Aishwarya Venkataramanan,Paul Bodesheim,Joachim Denzler*

Main category: cs.CV

TL;DR: 提出了一种名为GroVE的后处理方法，用于从冻结的视觉语言模型（VLM）中获取概率嵌入，以更好地捕捉不确定性。


<details>
  <summary>Details</summary>
Motivation: 标准VLM的确定性嵌入难以捕捉视觉和文本描述中的模糊性以及图文间多重对应关系带来的不确定性。现有学习概率嵌入的方法需要大量数据集，且未能利用大型预训练VLM（如CLIP）的强大表示能力。

Method: GroVE是一种基于高斯过程潜变量模型（GPLVM）的后处理方法。它学习一个共享的低维潜在空间，将图像和文本输入映射到统一表示，通过单模态嵌入重构和跨模态对齐目标进行优化。训练后，高斯过程模型生成具有不确定性感知的概率嵌入。

Result: 评估表明，GroVE在跨模态检索、视觉问答和主动学习等多个下游任务中均达到了最先进的不确定性校准水平。

Conclusion: GroVE能够有效地从冻结的VLM中生成具有不确定性感知的概率嵌入，从而改善了下游任务的性能。

Abstract: Vision-Language Models (VLMs) learn joint representations by mapping images
and text into a shared latent space. However, recent research highlights that
deterministic embeddings from standard VLMs often struggle to capture the
uncertainties arising from the ambiguities in visual and textual descriptions
and the multiple possible correspondences between images and texts. Existing
approaches tackle this by learning probabilistic embeddings during VLM
training, which demands large datasets and does not leverage the powerful
representations already learned by large-scale VLMs like CLIP. In this paper,
we propose GroVE, a post-hoc approach to obtaining probabilistic embeddings
from frozen VLMs. GroVE builds on Gaussian Process Latent Variable Model
(GPLVM) to learn a shared low-dimensional latent space where image and text
inputs are mapped to a unified representation, optimized through single-modal
embedding reconstruction and cross-modal alignment objectives. Once trained,
the Gaussian Process model generates uncertainty-aware probabilistic
embeddings. Evaluation shows that GroVE achieves state-of-the-art uncertainty
calibration across multiple downstream tasks, including cross-modal retrieval,
visual question answering, and active learning.

</details>


### [100] [PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting](https://arxiv.org/abs/2505.05183)
*Elad Feldman,Jacob Shams,Dudi Biton,Alfred Chen,Shaoyuan Xie,Satoru Koda,Yisroel Mirsky,Asaf Shabtai,Yuval Elovici,Ben Nassi*

Main category: cs.CV

TL;DR: 研究揭示了紧急车辆灯光会导致自动驾驶汽车的目标检测器失效（PaniCar现象），并提出Caracetamol框架来缓解此问题，提高检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 鉴于特斯拉自动驾驶汽车多次撞击停放的紧急车辆，以及强光源（如紧急车辆灯光）产生的眩光对目标检测性能影响的不明确性，本研究旨在探究并解决这一安全隐患。

Method: 研究首先识别并命名了PaniCar现象（紧急车辆灯光导致目标检测器置信度下降）。接着，评估了多种商用ADAS、目标检测器、紧急车辆灯光模式及现有眩光去除方法。最后，提出了Caracetamol框架，以增强目标检测器对此类灯光的鲁棒性。

Result: PaniCar现象显著降低目标检测器在紧急车辆灯光下的置信度，现有眩光去除方法不适用于实时驾驶。Caracetamol框架在YOLOv3和Faster R-CNN上将车辆检测的平均置信度提升0.20，置信度下限提升0.33，波动范围减少0.33，并能以30-50 FPS实时处理。

Conclusion: 紧急车辆灯光引发的PaniCar现象对自动驾驶安全构成重大威胁。提出的Caracetamol框架能有效缓解该问题，增强目标检测器在紧急车辆灯光下的鲁棒性和实时性。

Abstract: The safety of autonomous cars has come under scrutiny in recent years,
especially after 16 documented incidents involving Teslas (with autopilot
engaged) crashing into parked emergency vehicles (police cars, ambulances, and
firetrucks). While previous studies have revealed that strong light sources
often introduce flare artifacts in the captured image, which degrade the image
quality, the impact of flare on object detection performance remains unclear.
In this research, we unveil PaniCar, a digital phenomenon that causes an object
detector's confidence score to fluctuate below detection thresholds when
exposed to activated emergency vehicle lighting. This vulnerability poses a
significant safety risk, and can cause autonomous vehicles to fail to detect
objects near emergency vehicles. In addition, this vulnerability could be
exploited by adversaries to compromise the security of advanced driving
assistance systems (ADASs). We assess seven commercial ADASs (Tesla Model 3,
"manufacturer C", HP, Pelsee, AZDOME, Imagebon, Rexing), four object detectors
(YOLO, SSD, RetinaNet, Faster R-CNN), and 14 patterns of emergency vehicle
lighting to understand the influence of various technical and environmental
factors. We also evaluate four SOTA flare removal methods and show that their
performance and latency are insufficient for real-time driving constraints. To
mitigate this risk, we propose Caracetamol, a robust framework designed to
enhance the resilience of object detectors against the effects of activated
emergency vehicle lighting. Our evaluation shows that on YOLOv3 and Faster
RCNN, Caracetamol improves the models' average confidence of car detection by
0.20, the lower confidence bound by 0.33, and reduces the fluctuation range by
0.33. In addition, Caracetamol is capable of processing frames at a rate of
between 30-50 FPS, enabling real-time ADAS car detection.

</details>


### [101] [Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models](https://arxiv.org/abs/2505.05189)
*Wei Peng,Kang Liu,Jianchen Hu,Meng Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为Biomed-DPT的知识增强型双模态提示调整技术，用于改进少样本场景下的生物医学图像分类。


<details>
  <summary>Details</summary>
Motivation: 现有的提示学习方法在生物医学图像分类中主要依赖文本提示，忽略了图像中的特定结构（如复杂的解剖结构和细微的病理特征），限制了其在少样本场景下的效果。

Method: Biomed-DPT设计了双模态提示：文本提示方面，构建了模板驱动的临床提示和LLM驱动的领域适应提示，并通过知识蒸馏提取临床知识；视觉提示方面，引入零向量作为软提示，利用注意力重加权机制，避免关注非诊断区域和识别非关键病理特征。

Result: Biomed-DPT在11个生物医学图像数据集（涵盖9种模态和10个器官）上平均分类准确率达到66.14%，在基类和新类上的准确率分别达到78.06%和75.97%，分别超过CoOp方法6.20%、3.78%和8.04%。

Conclusion: Biomed-DPT通过结合领域知识增强的双模态提示和优化的视觉注意力，有效提升了少样本生物医学图像分类的性能。

Abstract: Prompt learning is one of the most effective paradigms for adapting
pre-trained vision-language models (VLMs) to the biomedical image
classification tasks in few shot scenarios. However, most of the current prompt
learning methods only used the text prompts and ignored the particular
structures (such as the complex anatomical structures and subtle pathological
features) in the biomedical images. In this work, we propose Biomed-DPT, a
knowledge-enhanced dual modality prompt tuning technique. In designing the text
prompt, Biomed-DPT constructs a dual prompt including the template-driven
clinical prompts and the large language model (LLM)-driven domain-adapted
prompts, then extracts the clinical knowledge from the domain-adapted prompts
through the knowledge distillation technique. In designing the vision prompt,
Biomed-DPT introduces the zero vector as a soft prompt to leverage attention
re-weighting so that the focus on non-diagnostic regions and the recognition of
non-critical pathological features are avoided. Biomed-DPT achieves an average
classification accuracy of 66.14\% across 11 biomedical image datasets covering
9 modalities and 10 organs, with performance reaching 78.06\% in base classes
and 75.97\% in novel classes, surpassing the Context Optimization (CoOp) method
by 6.20\%, 3.78\%, and 8.04\%, respectively. Our code are available at
\underline{https://github.com/Kanyooo/Biomed-DPT}.

</details>


### [102] [EAM: Enhancing Anything with Diffusion Transformers for Blind Super-Resolution](https://arxiv.org/abs/2505.05209)
*Haizhen Xie,Kunpeng Du,Qiangyu Yan,Sen Lu,Jianhong Han,Hanting Chen,Hailin Hu,Jie Hu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为 EAM 的新型盲超分辨率 (BSR) 方法，该方法利用扩散 Transformer (DiT) 替代传统的 U-Net，并通过新颖的 Ψ-DiT 模块、渐进式掩码图像建模和主题感知提示生成策略，实现了超越现有方法的图像恢复效果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于 U-Net 的文本到图像 (T2I) 扩散模型在盲超分辨率 (BSR) 中已广泛应用，但新兴的扩散 Transformer (DiT) 在 T2I 任务中展现出更强性能。本研究旨在利用 DiT 的优势改进 BSR，并解决如何有效引导 DiT 进行图像恢复、充分利用 T2I 先验知识、增强模型泛化能力以及优化提示生成等问题。

Method: 1. 提出 Enhancing Anything Model (EAM)，一种利用 DiT 的 BSR 新方法。
2. 引入新颖的 Ψ-DiT 模块：通过低分辨率潜变量作为可分离流注入控制，形成三流架构，有效引导 DiT 并利用其预训练知识进行图像恢复。
3. 采用渐进式掩码图像建模 (Progressive Masked Image Modeling) 策略：增强 T2I 先验的指导能力和 BSR 的泛化性，同时降低训练成本。
4. 提出主题感知提示生成策略：利用鲁棒的多模态模型在上下文学习框架中自动识别图像关键区域、生成详细描述，以优化 T2I 扩散先验的利用。

Result: EAM 方法在多个数据集上的实验结果表明，其在定量指标和视觉质量方面均取得了当前最佳 (state-of-the-art) 的表现，优于现有的其他方法。

Conclusion: 本研究提出的 EAM 方法，通过有效结合 DiT 与创新的 Ψ-DiT 模块、渐进式掩码图像建模策略以及主题感知提示生成策略，成功提升了盲超分辨率的性能，达到了业界领先水平。

Abstract: Utilizing pre-trained Text-to-Image (T2I) diffusion models to guide Blind
Super-Resolution (BSR) has become a predominant approach in the field. While
T2I models have traditionally relied on U-Net architectures, recent
advancements have demonstrated that Diffusion Transformers (DiT) achieve
significantly higher performance in this domain. In this work, we introduce
Enhancing Anything Model (EAM), a novel BSR method that leverages DiT and
outperforms previous U-Net-based approaches. We introduce a novel block,
$\Psi$-DiT, which effectively guides the DiT to enhance image restoration. This
block employs a low-resolution latent as a separable flow injection control,
forming a triple-flow architecture that effectively leverages the prior
knowledge embedded in the pre-trained DiT. To fully exploit the prior guidance
capabilities of T2I models and enhance their generalization in BSR, we
introduce a progressive Masked Image Modeling strategy, which also reduces
training costs. Additionally, we propose a subject-aware prompt generation
strategy that employs a robust multi-modal model in an in-context learning
framework. This strategy automatically identifies key image areas, provides
detailed descriptions, and optimizes the utilization of T2I diffusion priors.
Our experiments demonstrate that EAM achieves state-of-the-art results across
multiple datasets, outperforming existing methods in both quantitative metrics
and visual quality.

</details>


### [103] [HQC-NBV: A Hybrid Quantum-Classical View Planning Approach](https://arxiv.org/abs/2505.05212)
*Xiaotong Yu,Chang Wen Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种混合量子经典框架HQC-NBV，用于高效的机器人视点规划，显著提升了探索效率。


<details>
  <summary>Details</summary>
Motivation: 传统视点规划方法在复杂场景中面临计算可扩展性和解的最优性挑战，难以满足计算机视觉和机器人感知的需求。

Method: 引入了HQC-NBV，一个混合量子经典框架。该方法利用量子特性探索参数空间，提出了特定的哈密顿量公式（含多组分成本项）和以参数为中心的、具有双向交替纠缠模式的变分拟设，以捕捉视点参数间的层级依赖。

Result: 实验表明，量子特定组件带来了可测量的性能优势。与经典方法相比，HQC-NBV在不同环境下的探索效率最高提升了49.2%。

Conclusion: 这项工作是将量子计算集成到机器人感知系统中的一项重大进展，为各种机器人视觉任务提供了一种范式转变的解决方案，并揭示了量子优势在机器人探索中的机制。

Abstract: Efficient view planning is a fundamental challenge in computer vision and
robotic perception, critical for tasks ranging from search and rescue
operations to autonomous navigation. While classical approaches, including
sampling-based and deterministic methods, have shown promise in planning camera
viewpoints for scene exploration, they often struggle with computational
scalability and solution optimality in complex settings. This study introduces
HQC-NBV, a hybrid quantum-classical framework for view planning that leverages
quantum properties to efficiently explore the parameter space while maintaining
robustness and scalability. We propose a specific Hamiltonian formulation with
multi-component cost terms and a parameter-centric variational ansatz with
bidirectional alternating entanglement patterns that capture the hierarchical
dependencies between viewpoint parameters. Comprehensive experiments
demonstrate that quantum-specific components provide measurable performance
advantages. Compared to the classical methods, our approach achieves up to
49.2% higher exploration efficiency across diverse environments. Our analysis
of entanglement architecture and coherence-preserving terms provides insights
into the mechanisms of quantum advantage in robotic exploration tasks. This
work represents a significant advancement in integrating quantum computing into
robotic perception systems, offering a paradigm-shifting solution for various
robot vision tasks.

</details>


### [104] [Diffusion Model Quantization: A Review](https://arxiv.org/abs/2505.05215)
*Qian Zeng,Chenggong Hu,Mingli Song,Jie Song*

Main category: cs.CV

TL;DR: 这篇综述全面回顾了扩散模型量化领域的最新进展，旨在促进其在资源受限设备上的高效部署。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现优异，但将其高效部署到资源有限的边缘设备上是一个挑战。模型量化是实现压缩和加速的关键技术，因此需要对该领域进行系统性梳理。

Method: 本文首先概述了扩散模型量化（包括U-Net和DiT架构）的关键挑战，然后提出了主流量化技术的分类法并讨论其原理。接着，从定性和定量（基准测试）角度分析了代表性方案，并对量化误差的影响进行了视觉和轨迹分析。

Result: 论文提供了对扩散模型量化最新研究的广泛评估，通过基准测试比较了多种方法，并分类阐释了量化误差的影响。相关资源（论文、代码、模型、结果）已公开。

Conclusion: 论文总结了当前研究现状，并为未来生成模型在实际应用中的量化研究指明了新的方向。

Abstract: Recent success of large text-to-image models has empirically underscored the
exceptional performance of diffusion models in generative tasks. To facilitate
their efficient deployment on resource-constrained edge devices, model
quantization has emerged as a pivotal technique for both compression and
acceleration. This survey offers a thorough review of the latest advancements
in diffusion model quantization, encapsulating and analyzing the current state
of the art in this rapidly advancing domain. First, we provide an overview of
the key challenges encountered in the quantization of diffusion models,
including those based on U-Net architectures and Diffusion Transformers (DiT).
We then present a comprehensive taxonomy of prevalent quantization techniques,
engaging in an in-depth discussion of their underlying principles.
Subsequently, we perform a meticulous analysis of representative diffusion
model quantization schemes from both qualitative and quantitative perspectives.
From a quantitative standpoint, we rigorously benchmark a variety of methods
using widely recognized datasets, delivering an extensive evaluation of the
most recent and impactful research in the field. From a qualitative standpoint,
we categorize and synthesize the effects of quantization errors, elucidating
these impacts through both visual analysis and trajectory examination. In
conclusion, we outline prospective avenues for future research, proposing novel
directions for the quantization of generative models in practical applications.
The list of related papers, corresponding codes, pre-trained models and
comparison results are publicly available at the survey project homepage
https://github.com/TaylorJocelyn/Diffusion-Model-Quantization.

</details>


### [105] [Does CLIP perceive art the same way we do?](https://arxiv.org/abs/2505.05229)
*Andrea Asperti,Leonardo Dessì,Maria Chiara Tonetti,Nico Wu*

Main category: cs.CV

TL;DR: 本文研究CLIP在解读艺术作品时，其提取语义和风格信息的能力，并与人类感知进行对比。


<details>
  <summary>Details</summary>
Motivation: 探究强大的多模态模型CLIP在多大程度上以与人类相同的方式“看待”和解读艺术作品，特别是在艺术领域。

Method: 设计针对性的探测任务，评估CLIP在内容、场景理解、艺术风格、历史时期及视觉变形等多个维度上对绘画（人类创作和AI生成）的感知能力，并将其响应与人类标注和专家基准进行比较。

Result: 研究发现CLIP的视觉表征在美学线索和艺术意图方面既有优势也存在局限性。

Conclusion: 研究结果强调了在创造性领域应用多模态系统时，提升其可解释性的必要性，并讨论了这些发现对使用CLIP指导生成过程的启示。

Abstract: CLIP has emerged as a powerful multimodal model capable of connecting images
and text through joint embeddings, but to what extent does it "see" the same
way humans do - especially when interpreting artworks? In this paper, we
investigate CLIP's ability to extract high-level semantic and stylistic
information from paintings, including both human-created and AI-generated
imagery. We evaluate its perception across multiple dimensions: content, scene
understanding, artistic style, historical period, and the presence of visual
deformations or artifacts. By designing targeted probing tasks and comparing
CLIP's responses to human annotations and expert benchmarks, we explore its
alignment with human perceptual and contextual understanding. Our findings
reveal both strengths and limitations in CLIP's visual representations,
particularly in relation to aesthetic cues and artistic intent. We further
discuss the implications of these insights for using CLIP as a guidance
mechanism during generative processes, such as style transfer or prompt-based
image synthesis. Our work highlights the need for deeper interpretability in
multimodal systems, especially when applied to creative domains where nuance
and subjectivity play a central role.

</details>


### [106] [PADriver: Towards Personalized Autonomous Driving](https://arxiv.org/abs/2505.05240)
*Genghua Kou,Fan Jia,Weixin Mao,Yingfei Liu,Yucheng Zhao,Ziheng Zhang,Osamu Yoshie,Tiancai Wang,Ying Li,Xiangyu Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为 PADriver 的新型闭环框架，用于个性化自动驾驶 (PAD)。该框架基于多模态大语言模型 (MLLM)，能够进行场景理解、危险等级评估和行动决策。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够根据用户个性化需求进行自动驾驶决策的系统，并提供一个全面的基准来评估这类系统的性能。

Method: 构建了 PADriver 框架，它以流式视频帧和个性化文本提示为输入，利用 MLLM 进行场景理解、危险等级估计和行动决策。危险等级为与个性化提示对应的最终行动提供参考。同时，基于 Highway-Env 模拟器构建了名为 PAD-Highway 的闭环基准测试平台，包含250小时带高质量标注的视频数据。

Result: 在构建的 PAD-Highway 基准测试上，PADriver 在不同评估指标上均优于当前最先进的方法，并且能够实现多种驾驶模式。

Conclusion: PADriver 是一个有效的个性化自动驾驶框架，其性能优于现有方法，并能支持多样化的驾驶模式，所构建的 PAD-Highway 基准有助于推动个性化自动驾驶行为分析的发展。

Abstract: In this paper, we propose PADriver, a novel closed-loop framework for
personalized autonomous driving (PAD). Built upon Multi-modal Large Language
Model (MLLM), PADriver takes streaming frames and personalized textual prompts
as inputs. It autoaggressively performs scene understanding, danger level
estimation and action decision. The predicted danger level reflects the risk of
the potential action and provides an explicit reference for the final action,
which corresponds to the preset personalized prompt. Moreover, we construct a
closed-loop benchmark named PAD-Highway based on Highway-Env simulator to
comprehensively evaluate the decision performance under traffic rules. The
dataset contains 250 hours videos with high-quality annotation to facilitate
the development of PAD behavior analysis. Experimental results on the
constructed benchmark show that PADriver outperforms state-of-the-art
approaches on different evaluation metrics, and enables various driving modes.

</details>


### [107] [PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes](https://arxiv.org/abs/2505.05288)
*Ahmed Abdelreheem,Filippo Aleotti,Jamie Watson,Zawar Qureshi,Abdelrahman Eldesokey,Peter Wonka,Gabriel Brostow,Sara Vicente,Guillermo Garcia-Hernando*

Main category: cs.CV

TL;DR: 本文提出了一种新的任务：在真实3D场景中根据语言指令放置物体，并为此任务创建了基准、数据集和基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景语言引导定位任务未能充分解决物体放置的模糊性（即存在多个有效解）以及对3D几何关系和自由空间推理的需求。

Method: 1. 提出“语言引导的真实3D场景物体放置”新任务。
2. 为该任务设计了新的基准测试和评估协议。
3. 构建了一个用于训练3D大语言模型的新数据集。
4. 引入了首个作为该任务非平凡基线的解决方法。

Result: 成功定义了语言引导物体放置这一新颖任务，并提供了相应的基准、数据集和基线方法，为后续研究奠定了基础。

Conclusion: 这项具有挑战性的新任务及其基准测试，有望成为评估和比较通用3D大语言模型能力的标准套件的一部分。

Abstract: We introduce the novel task of Language-Guided Object Placement in Real 3D
Scenes. Our model is given a 3D scene's point cloud, a 3D asset, and a textual
prompt broadly describing where the 3D asset should be placed. The task here is
to find a valid placement for the 3D asset that respects the prompt. Compared
with other language-guided localization tasks in 3D scenes such as grounding,
this task has specific challenges: it is ambiguous because it has multiple
valid solutions, and it requires reasoning about 3D geometric relationships and
free space. We inaugurate this task by proposing a new benchmark and evaluation
protocol. We also introduce a new dataset for training 3D LLMs on this task, as
well as the first method to serve as a non-trivial baseline. We believe that
this challenging task and our new benchmark could become part of the suite of
benchmarks used to evaluate and compare generalist 3D LLM models.

</details>


### [108] [PRE-Mamba: A 4D State Space Model for Ultra-High-Frequent Event Camera Deraining](https://arxiv.org/abs/2505.05307)
*Ciyu Ruan,Ruishan Guo,Zihang Gong,Jingao Xu,Wenhan Yang,Xinlei Chen*

Main category: cs.CV

TL;DR: 本文提出PRE-Mamba，一个新颖的基于点的事件相机去雨框架，它充分利用原始事件和雨水的时空特性，通过4D事件云表示、时空解耦与融合模块（STDF）和多尺度状态空间模型（MS3M）实现高效去雨，同时保持高时间精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 事件相机在雨天条件下会产生密集噪声，影响其高时间分辨率和动态范围的优势。现有的事件相机去雨方法在时间精度、去雨效果和计算效率之间面临权衡。

Method: 提出了PRE-Mamba框架，主要包括：1) 一种集成了双时间尺度的4D事件云表示法，以保持高时间精度；2) 一个时空解耦与融合模块（STDF），通过浅层解耦和时空信息交互来增强去雨能力；3) 一个多尺度状态空间模型（MS3M），以线性计算复杂度捕捉双时间和多空间尺度下的深层雨水动态；4) 并通过频率域正则化增强性能。

Result: 在包含带标签的合成序列和真实世界序列的综合数据集EventRain-27K上，PRE-Mamba以仅0.26M的参数量实现了优异的性能（SR 0.95, NR 0.91, 处理速度0.4秒/百万事件）。此外，该方法在不同雨强、视角甚至雪天条件下均表现出良好的泛化能力。

Conclusion: PRE-Mamba通过其创新的模块设计，有效解决了事件相机在雨天条件下的噪声问题，实现了卓越的去雨性能、高时间精度和计算效率的平衡，并展现出良好的泛化能力，为事件相机去雨提供了一个有效的解决方案。

Abstract: Event cameras excel in high temporal resolution and dynamic range but suffer
from dense noise in rainy conditions. Existing event deraining methods face
trade-offs between temporal precision, deraining effectiveness, and
computational efficiency. In this paper, we propose PRE-Mamba, a novel
point-based event camera deraining framework that fully exploits the
spatiotemporal characteristics of raw event and rain. Our framework introduces
a 4D event cloud representation that integrates dual temporal scales to
preserve high temporal precision, a Spatio-Temporal Decoupling and Fusion
module (STDF) that enhances deraining capability by enabling shallow decoupling
and interaction of temporal and spatial information, and a Multi-Scale State
Space Model (MS3M) that captures deeper rain dynamics across dual-temporal and
multi-spatial scales with linear computational complexity. Enhanced by
frequency-domain regularization, PRE-Mamba achieves superior performance (0.95
SR, 0.91 NR, and 0.4s/M events) with only 0.26M parameters on EventRain-27K, a
comprehensive dataset with labeled synthetic and real-world sequences.
Moreover, our method generalizes well across varying rain intensities,
viewpoints, and even snowy conditions.

</details>


### [109] [Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects](https://arxiv.org/abs/2505.05318)
*Agnese Chiatti,Sara Bernardini,Lara Shibelski Godoy Piccolo,Viola Schiaffonati,Matteo Matteucci*

Main category: cs.CV

TL;DR: 本文综述了关于视觉语言模型（VLM）中用户信任动态的研究，并通过文献回顾和用户研讨会为未来相关研究提出了初步要求。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）被迅速采用，因此迫切需要保护用户，并告知用户何时可以信任这些系统。

Method: 通过一个涵盖不同认知科学能力、协作模式和智能体行为的多学科分类法，回顾了用户与VLM交互中信任动态的现有研究，并结合了与潜在VLM用户的研讨会发现。

Result: 本研究整合了文献中的见解以及与潜在VLM用户研讨会的发现，从而为未来的VLM信任研究提出了初步要求。

Conclusion: 该研究为未来VLM信任研究提供了指导性要求，旨在帮助用户更好地评估何时信任VLM系统，并促进更值得信赖的VLM的开发。

Abstract: The rapid adoption of Vision Language Models (VLMs), pre-trained on large
image-text and video-text datasets, calls for protecting and informing users
about when to trust these systems. This survey reviews studies on trust
dynamics in user-VLM interactions, through a multi-disciplinary taxonomy
encompassing different cognitive science capabilities, collaboration modes, and
agent behaviours. Literature insights and findings from a workshop with
prospective VLM users inform preliminary requirements for future VLM trust
studies.

</details>


### [110] [Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery](https://arxiv.org/abs/2505.05321)
*Chintan B. Maniyar,Minakshi Kumar,Gengchen Mai*

Main category: cs.CV

TL;DR: 该研究提出了一种利用多尺度影像、特征增强和优化训练策略的深度学习框架，以从高分辨率RGB影像中准确分割建筑物。


<details>
  <summary>Details</summary>
Motivation: 高分辨率RGB影像中的建筑物分割因光谱相似性、阴影和不规则几何形状等因素而面临挑战。

Method: 该研究构建了一个多传感器、多尺度（0.4米-2.7米分辨率）的RGB航空和卫星影像数据集。通过从RGB通道派生主成分分析（PCA）、可见差异植被指数（VDVI）、形态学建筑物指数（MBI）和Sobel边缘滤波器等次级表征来增强输入特征。这些特征被用于指导Res-U-Net架构学习复杂的空间模式。同时，提出了包括层冻结、周期性学习率和SuperConvergence在内的训练策略以优化训练过程。

Result: 在WorldView-3影像上的评估显示，该模型实现了96.5%的总体准确率，F1分数为0.86，交并比（IoU）为0.80，表现优于现有的基于RGB的基准方法。

Conclusion: 研究证明，结合多分辨率影像、特征增强和优化的训练策略能够有效地实现遥感应用中鲁棒的建筑物分割。

Abstract: Accurate building segmentation from high-resolution RGB imagery remains
challenging due to spectral similarity with non-building features, shadows, and
irregular building geometries. In this study, we present a comprehensive deep
learning framework for multiscale building segmentation using RGB aerial and
satellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate
a diverse, multi-sensor dataset and introduce feature-augmented inputs by
deriving secondary representations including Principal Component Analysis
(PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index
(MBI), and Sobel edge filters from RGB channels. These features guide a
Res-U-Net architecture in learning complex spatial patterns more effectively.
We also propose training policies incorporating layer freezing, cyclical
learning rates, and SuperConvergence to reduce training time and resource
usage. Evaluated on a held-out WorldView-3 image, our model achieves an overall
accuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of
0.80, outperforming existing RGB-based benchmarks. This study demonstrates the
effectiveness of combining multi-resolution imagery, feature augmentation, and
optimized training strategies for robust building segmentation in remote
sensing applications.

</details>


### [111] [Aesthetics Without Semantics](https://arxiv.org/abs/2505.05331)
*C. Alejandro Parraga,Olivier Penacchio,Marcos Muňoz Gonzalez,Bogdan Raducanu,Xavier Otazu*

Main category: cs.CV

TL;DR: 该研究创建了一个包含美丑图像的均衡数据库（MSC），并证明了在美学研究中考虑更广泛的美学价值（包括丑陋图像）的重要性，因为仅关注美观图像可能会导致对图像特征与美学评价之间关系的误解。


<details>
  <summary>Details</summary>
Motivation: 人类对图像美丑的判断是复杂的，涉及感知和认知因素。现有图像数据库大多偏向于美观图像，这限制了对审美反应的全面研究和预测。

Method: 1. 创建了一个名为“最小语义内容”（MSC）的图像数据库，其中包含大量美丑均衡的图像，每张图像由100名观察者评估。2. 开发并利用一种方法生成丑陋图像，以平衡数据库。3. 使用成熟的图像度量标准，分析在偏向美观图像的数据集中加入丑陋图像后，图像特征与美学评价之间关系的变化。

Result: 向偏向美观图像的数据集中添加丑陋图像，可以改变甚至反转先前观察到的图像特征与美学评价之间的关系。

Conclusion: 那些试图将图像内容与美学判断联系起来的经验美学研究，如果只考虑有限范围的美学价值（如主要关注美观图像），可能会放大、低估或完全错过重要的影响。因此，在美学研究中包含丑陋图像至关重要。

Abstract: While it is easy for human observers to judge an image as beautiful or ugly,
aesthetic decisions result from a combination of entangled perceptual and
cognitive (semantic) factors, making the understanding of aesthetic judgements
particularly challenging from a scientific point of view. Furthermore, our
research shows a prevailing bias in current databases, which include mostly
beautiful images, further complicating the study and prediction of aesthetic
responses. We address these limitations by creating a database of images with
minimal semantic content and devising, and next exploiting, a method to
generate images on the ugly side of aesthetic valuations. The resulting Minimum
Semantic Content (MSC) database consists of a large and balanced collection of
10,426 images, each evaluated by 100 observers. We next use established image
metrics to demonstrate how augmenting an image set biased towards beautiful
images with ugly images can modify, or even invert, an observed relationship
between image features and aesthetics valuation. Taken together, our study
reveals that works in empirical aesthetics attempting to link image content and
aesthetic judgements may magnify, underestimate, or simply miss interesting
effects due to a limitation of the range of aesthetic values they consider.

</details>


### [112] [Progressive Inertial Poser: Progressive Real-Time Kinematic Chain Estimation for 3D Full-Body Pose from Three IMU Sensors](https://arxiv.org/abs/2505.05336)
*Zunjie Zhu,Yan Zhao,Yihan Hu,Guoxiang Wang,Hai Qiu,Bolun Zheng,Chenggang Yan,Feng Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为渐进式惯性姿态估计器 (ProgIP) 的方法，仅使用三个佩戴在头部和手腕的惯性测量单元 (IMU) 来实现全身姿态估计，旨在提高虚拟现实应用的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的全身姿态捕捉系统要么受环境限制（基于视觉的系统），要么需要佩戴额外的传感器或依赖外部视觉传感器来获取关键关节的全局位置。本研究旨在通过减少硬件系统的复杂性（仅使用三个IMU），提高姿态估计技术在虚拟现实应用中的实用性。

Method: 提出了一种名为渐进式惯性姿态估计器 (ProgIP) 的方法。该方法结合了神经网络估计和人体动力学模型，考虑了运动链的层次结构，并采用多阶段渐进式网络估计。编码器结合了 Transformer 编码器和双向长短期记忆网络 (TE-biLSTM) 来捕捉惯性序列的时间依赖性，解码器基于多层感知器 (MLP) 将高维特征转换并投影到蒙皮多人线性 (SMPL) 模型参数上。

Result: 在多个公共数据集上的定量和定性实验结果表明，该方法在相同输入（三个IMU）的情况下优于最先进的方法，并且与最近使用六个IMU传感器的工作相当。

Conclusion: ProgIP 方法能够仅使用三个IMU有效地估计全身姿态，为虚拟现实应用提供了一种实用的全身运动捕捉方案。

Abstract: The motion capture system that supports full-body virtual representation is
of key significance for virtual reality. Compared to vision-based systems,
full-body pose estimation from sparse tracking signals is not limited by
environmental conditions or recording range. However, previous works either
face the challenge of wearing additional sensors on the pelvis and lower-body
or rely on external visual sensors to obtain global positions of key joints. To
improve the practicality of the technology for virtual reality applications, we
estimate full-body poses using only inertial data obtained from three Inertial
Measurement Unit (IMU) sensors worn on the head and wrists, thereby reducing
the complexity of the hardware system. In this work, we propose a method called
Progressive Inertial Poser (ProgIP) for human pose estimation, which combines
neural network estimation with a human dynamics model, considers the
hierarchical structure of the kinematic chain, and employs a multi-stage
progressive network estimation with increased depth to reconstruct full-body
motion in real time. The encoder combines Transformer Encoder and bidirectional
LSTM (TE-biLSTM) to flexibly capture the temporal dependencies of the inertial
sequence, while the decoder based on multi-layer perceptrons (MLPs) transforms
high-dimensional features and accurately projects them onto Skinned
Multi-Person Linear (SMPL) model parameters. Quantitative and qualitative
experimental results on multiple public datasets show that our method
outperforms state-of-the-art methods with the same inputs, and is comparable to
recent works using six IMU sensors.

</details>


### [113] [Hearing and Seeing Through CLIP: A Framework for Self-Supervised Sound Source Localization](https://arxiv.org/abs/2505.05343)
*Sooyoung Park,Arda Senocak,Joon Son Chung*

Main category: cs.CV

TL;DR: 本文提出一种自监督方法，将CLIP模型扩展到声源定位任务，无需显式文本输入即可实现有效的声源区域预测。


<details>
  <summary>Details</summary>
Motivation: 利用CLIP等大规模视觉语言模型强大的跨模态对齐和泛化能力，将其应用于声源定位任务，并解决传统方法中对文本输入的依赖。

Method: 将音频映射为与CLIP文本编码器兼容的令牌以生成音频驱动的嵌入；使用这些嵌入生成发声区域掩码；从掩码中提取视觉特征并与音频嵌入进行对比学习对齐。还提出了一种LLM引导的扩展方法以增强对齐效果。

Result: 该方法能够生成更完整和紧凑的发声对象定位结果。在五个不同任务上的大量实验表明，该方法（及其所有变体）均优于现有SOTA方法，并在零样本设置下展现出强大的泛化能力。

Conclusion: 所提出的自监督方法能够有效利用预训练多模态基础模型的对齐知识进行声源定位，无需文本输入即可实现卓越性能和强泛化性。

Abstract: Large-scale vision-language models demonstrate strong multimodal alignment
and generalization across diverse tasks. Among them, CLIP stands out as one of
the most successful approaches. In this work, we extend the application of CLIP
to sound source localization, proposing a self-supervised method operates
without explicit text input. We introduce a framework that maps audios into
tokens compatible with CLIP's text encoder, producing audio-driven embeddings.
These embeddings are used to generate sounding region masks, from which visual
features are extracted and aligned with the audio embeddings through a
contrastive audio-visual correspondence objective. Our findings show that
alignment knowledge of pre-trained multimodal foundation model enables our
method to generate more complete and compact localization for sounding objects.
We further propose an LLM-guided extension that distills object-aware
audio-visual scene understanding into the model during training to enhance
alignment. Extensive experiments across five diverse tasks demonstrate that our
method, in all variants, outperforms state-of-the-art approaches and achieves
strong generalization in zero-shot settings.

</details>


### [114] [TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation](https://arxiv.org/abs/2505.05422)
*Haokun Lin,Teng Wang,Yixiao Ge,Yuying Ge,Zhichao Lu,Ying Wei,Qingfu Zhang,Zhenan Sun,Ying Shan*

Main category: cs.CV

TL;DR: 论文提出视觉分词器TokLIP，通过语义化矢量量化(VQ)词元并融入CLIP级语义，增强了多模态模型的理解与生成能力，同时降低了训练开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于词元的多模态模型（如Chameleon, Emu3）存在训练计算开销大、因缺乏高级语义导致理解性能受限的问题。

Method: 引入TokLIP，一种视觉分词器。它整合了低级离散VQ分词器与基于ViT的词元编码器（捕获高级连续语义），将VQ词元语义化并融入CLIP级语义。TokLIP解耦了理解和生成的训练目标，支持使用标准VQ词元进行端到端多模态自回归训练，无需定制量化操作。

Result: TokLIP 实现了卓越的数据效率，赋予视觉词元高级语义理解能力，同时增强了低级生成能力，使其非常适用于自回归Transformer的理解和生成任务。

Conclusion: TokLIP通过提升视觉词元的语义理解和生成能力，为自回归多模态模型提供了一种高效且数据利用率高的视觉分词方案，克服了以往方法的局限性。

Abstract: Pioneering token-based works such as Chameleon and Emu3 have established a
foundation for multimodal unification but face challenges of high training
computational overhead and limited comprehension performance due to a lack of
high-level semantics. In this paper, we introduce TokLIP, a visual tokenizer
that enhances comprehension by semanticizing vector-quantized (VQ) tokens and
incorporating CLIP-level semantics while enabling end-to-end multimodal
autoregressive training with standard VQ tokens. TokLIP integrates a low-level
discrete VQ tokenizer with a ViT-based token encoder to capture high-level
continuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize
high-level features, TokLIP disentangles training objectives for comprehension
and generation, allowing the direct application of advanced VQ tokenizers
without the need for tailored quantization operations. Our empirical results
demonstrate that TokLIP achieves exceptional data efficiency, empowering visual
tokens with high-level semantic understanding while enhancing low-level
generative capacity, making it well-suited for autoregressive Transformers in
both comprehension and generation tasks. The code and models are available at
https://github.com/TencentARC/TokLIP.

</details>


### [115] [Joint Super-Resolution and Segmentation for 1-m Impervious Surface Area Mapping in China's Yangtze River Economic Belt](https://arxiv.org/abs/2505.05367)
*Jie Deng,Danfeng Hong,Chenyu Li,Naoto Yokoya*

Main category: cs.CV

TL;DR: 提出一种名为JointSeg的新型联合框架，通过整合超分辨率和分割技术，能直接从免费的Sentinel-2影像生成1米分辨率的不透水面（ISA）地图，并成功应用于长江经济带，揭示了城市化动态。


<details>
  <summary>Details</summary>
Motivation: 传统方法在利用免费低分辨率影像生成高精度、高分辨率（如1米）不透水面（ISA）地图方面存在挑战，成本较高或效果不佳。本研究旨在提供一种可扩展、经济实惠的替代方案。

Method: 提出了JointSeg联合框架，该框架集成了超分辨率和分割任务。模型使用多模态跨分辨率输入进行训练，能够将Sentinel-2影像从10米逐步提升至1米分辨率，同时通过有效的跨尺度特征融合保留精细空间纹理并确保高分类保真度。

Result: 成功应用于长江经济带，生成了2021年覆盖超过220万平方公里的1米分辨率ISA地图（ISA-1）。ISA-1的F1分数达到85.71%，显著优于基于双线性插值的分割方法（提升9.5%）及其他ISA数据集（提升21.43%-61.07%）。该方法改善了城市区域对绿地和水体的辨识，并在山区识别出更多零散的人为地物。此外，还生成了2017-2023年的双年度ISA地图，揭示了代表性城市的时空城市化动态，显示出上游城市快速扩张、中游地区适度增长和下游大都市区域饱和的模式。

Conclusion: JointSeg框架是一种有效、可扩展且经济的方法，能够从免费的Sentinel-2影像生成高质量的1米分辨率ISA地图。该方法在不同地貌景观中表现出强大的鲁棒性，并能有效捕捉区域城市化动态。

Abstract: We propose a novel joint framework by integrating super-resolution and
segmentation, called JointSeg, which enables the generation of 1-meter ISA maps
directly from freely available Sentinel-2 imagery. JointSeg was trained on
multimodal cross-resolution inputs, offering a scalable and affordable
alternative to traditional approaches. This synergistic design enables gradual
resolution enhancement from 10m to 1m while preserving fine-grained spatial
textures, and ensures high classification fidelity through effective
cross-scale feature fusion. This method has been successfully applied to the
Yangtze River Economic Belt (YREB), a region characterized by complex
urban-rural patterns and diverse topography. As a result, a comprehensive ISA
mapping product for 2021, referred to as ISA-1, was generated, covering an area
of over 2.2 million square kilometers. Quantitative comparisons against the 10m
ESA WorldCover and other benchmark products reveal that ISA-1 achieves an
F1-score of 85.71%, outperforming bilinear-interpolation-based segmentation by
9.5%, and surpassing other ISA datasets by 21.43%-61.07%. In densely urbanized
areas (e.g., Suzhou, Nanjing), ISA-1 reduces ISA overestimation through
improved discrimination of green spaces and water bodies. Conversely, in
mountainous regions (e.g., Ganzi, Zhaotong), it identifies significantly more
ISA due to its enhanced ability to detect fragmented anthropogenic features
such as rural roads and sparse settlements, demonstrating its robustness across
diverse landscapes. Moreover, we present biennial ISA maps from 2017 to 2023,
capturing spatiotemporal urbanization dynamics across representative cities.
The results highlight distinct regional growth patterns: rapid expansion in
upstream cities, moderate growth in midstream regions, and saturation in
downstream metropolitan areas.

</details>


### [116] [Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding](https://arxiv.org/abs/2505.05446)
*Han Xiao,Yina Xie,Guanxin Tan,Yinghao Chen,Rui Hu,Ke Wang,Aojun Zhou,Hao Li,Hao Shao,Xudong Lu,Peng Gao,Yafei Wen,Xiaoxin Chen,Shuai Ren,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出了一种通过自适应生成标记语言（如Markdown、JSON）来构建结构化文档表示的新方法，并引入了两个大规模数据集（DocMark-Pile和DocMark-Instruct），以显著提升视觉文档理解模型在复杂场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉文档理解方法难以有效融合视觉和文本信息，尤其在处理多样化和复杂布局的文档时表现不佳。此外，现有微调数据集缺乏详细上下文，导致模型产生幻觉，对视觉元素空间关系的理解有限。

Method: 提出了一种创新流程，通过自适应生成多种标记语言（如Markdown、JSON、HTML、TiKZ）来构建高度结构化的文档表示，从而提供基于上下文的响应。同时，构建了两个新的细粒度结构化数据集：用于文档解析的预训练数据集DocMark-Pile（约380万对）和用于指令遵循的微调数据集DocMark-Instruct（62.4万条注释）。

Result: 实验表明，所提出的模型在多个视觉文档理解基准测试中显著优于现有的SOTA多模态大语言模型（MLLM），并在复杂视觉场景中展现出更强的推理和理解能力。

Conclusion: 该研究提出的自适应标记语言生成流程和专门构建的数据集，能够有效增强视觉文档理解模型对文档结构和上下文的把握，显著提升其在复杂场景下的推理和理解能力，为解决视觉文档理解的挑战提供了有效途径。

Abstract: Visual Document Understanding has become essential with the increase of
text-rich visual content. This field poses significant challenges due to the
need for effective integration of visual perception and textual comprehension,
particularly across diverse document types with complex layouts. Moreover,
existing fine-tuning datasets for this domain often fall short in providing the
detailed contextual information for robust understanding, leading to
hallucinations and limited comprehension of spatial relationships among visual
elements. To address these challenges, we propose an innovative pipeline that
utilizes adaptive generation of markup languages, such as Markdown, JSON, HTML,
and TiKZ, to build highly structured document representations and deliver
contextually-grounded responses. We introduce two fine-grained structured
datasets: DocMark-Pile, comprising approximately 3.8M pretraining data pairs
for document parsing, and DocMark-Instruct, featuring 624k fine-tuning data
annotations for grounded instruction following. Extensive experiments
demonstrate that our proposed model significantly outperforms existing
state-of-theart MLLMs across a range of visual document understanding
benchmarks, facilitating advanced reasoning and comprehension capabilities in
complex visual scenarios. Our code and models are released at https://github.
com/Euphoria16/DocMark.

</details>


### [117] [Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks](https://arxiv.org/abs/2505.05375)
*Kejie Zhao,Wenjia Hua,Aiersi Tuerhong,Luziwei Leng,Yuxin Ma,Qinghua Guo*

Main category: cs.CV

TL;DR: 提出了一种名为阈值调制 (TM) 的在线测试时自适应 (OTTA) 框架，通过动态调整神经元发放阈值来提升脉冲神经网络 (SNN) 在分布变化下的鲁棒性，且功耗低、与神经形态芯片兼容。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络 (SNN) 在部署后适应分布变化是一个关键挑战，而现有的在线测试时自适应 (OTTA) 方法主要为传统人工神经网络设计，不适用于 SNN。

Method: 提出了一种低功耗、神经形态芯片友好的在线测试时自适应框架——阈值调制 (TM)。该方法通过受神经元动力学启发的归一化来动态调整神经元的发放阈值。

Result: 在基准数据集上的实验结果表明，TM 方法有效提高了 SNN 在分布变化下的鲁棒性，同时保持了较低的计算成本。

Conclusion: 所提出的 TM 方法为 SNN 的在线测试时自适应提供了一个实用的解决方案，并为未来神经形态芯片的设计提供了启发。

Abstract: Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,
provide highly efficient solutions on edge devices in different scenarios.
However, their ability to adapt to distribution shifts after deployment has
become a crucial challenge. Online test-time adaptation (OTTA) offers a
promising solution by enabling models to dynamically adjust to new data
distributions without requiring source data or labeled target samples.
Nevertheless, existing OTTA methods are largely designed for traditional
artificial neural networks and are not well-suited for SNNs. To address this
gap, we propose a low-power, neuromorphic chip-friendly online test-time
adaptation framework, aiming to enhance model generalization under distribution
shifts. The proposed approach is called Threshold Modulation (TM), which
dynamically adjusts the firing threshold through neuronal dynamics-inspired
normalization, being more compatible with neuromorphic hardware. Experimental
results on benchmark datasets demonstrate the effectiveness of this method in
improving the robustness of SNNs against distribution shifts while maintaining
low computational cost. The proposed method offers a practical solution for
online test-time adaptation of SNNs, providing inspiration for the design of
future neuromorphic chips. The demo code is available at
github.com/NneurotransmitterR/TM-OTTA-SNN.

</details>


### [118] [StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org/abs/2505.05467)
*Haibo Wang,Bo Feng,Zhengfeng Lai,Mingze Xu,Shiyu Li,Weifeng Ge,Afshin Dehghan,Meng Cao,Ping Huang*

Main category: cs.CV

TL;DR: StreamBridge是一个将离线视频大语言模型（Video-LLMs）转换为流式处理模型的框架，解决了实时多轮理解和主动响应的挑战，并为此构建了Stream-IT数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的离线Video-LLMs在适应在线流式场景时面临两大挑战：(1) 实时多轮理解能力有限；(2) 缺乏主动响应机制。

Method: StreamBridge框架包含：(1) 结合轮次衰减压缩策略的内存缓冲区，支持长上下文多轮交互；(2) 一个解耦的、轻量级的激活模型，用于实现持续主动响应并易于集成到现有Video-LLMs中。同时，构建了Stream-IT大规模数据集以支持流式视频理解。

Result: 实验表明，StreamBridge显著提升了离线Video-LLMs在各种任务中的流式理解能力，其性能甚至优于GPT-4o和Gemini 1.5 Pro等专有模型，并且在标准视频理解基准测试中也取得了有竞争力或更优的性能。

Conclusion: StreamBridge是一个简单而有效的框架，能够将离线Video-LLMs无缝转换为流式处理模型，有效解决了在线视频理解中的核心挑战。

Abstract: We present StreamBridge, a simple yet effective framework that seamlessly
transforms offline Video-LLMs into streaming-capable models. It addresses two
fundamental challenges in adapting existing models into online scenarios: (1)
limited capability for multi-turn real-time understanding, and (2) lack of
proactive response mechanisms. Specifically, StreamBridge incorporates (1) a
memory buffer combined with a round-decayed compression strategy, supporting
long-context multi-turn interactions, and (2) a decoupled, lightweight
activation model that can be effortlessly integrated into existing Video-LLMs,
enabling continuous proactive responses. To further support StreamBridge, we
construct Stream-IT, a large-scale dataset tailored for streaming video
understanding, featuring interleaved video-text sequences and diverse
instruction formats. Extensive experiments show that StreamBridge significantly
improves the streaming understanding capabilities of offline Video-LLMs across
various tasks, outperforming even proprietary models such as GPT-4o and Gemini
1.5 Pro. Simultaneously, it achieves competitive or superior performance on
standard video understanding benchmarks.

</details>


### [119] [GeomHair: Reconstruction of Hair Strands from Colorless 3D Scans](https://arxiv.org/abs/2505.05376)
*Rachmadio Noval Lazuardi,Artem Sevastopolsky,Egor Zakharov,Matthias Niessner,Vanessa Sklyarova*

Main category: cs.CV

TL;DR: 提出了一种新方法，通过多模态发丝方向提取和扩散先验，直接从无色的三维扫描重建发丝，并发布了一个大规模发丝数据集Strands400。


<details>
  <summary>Details</summary>
Motivation: 现有发丝重建方法依赖RGB图像，易受环境影响且难以处理复杂发型。本研究旨在仅利用三维扫描的几何信息重建发丝，克服颜色信息的限制。

Method: 该方法首先直接在扫描数据上找到尖锐的表面特征，然后通过应用于扫描着色渲染图的神经二维线检测器来估计发丝方向。此外，还结合了一个在合成发型扫描上训练的扩散先验，该先验通过改进的噪声调度进行优化，并通过特定于扫描的文本提示进行内容适应。

Result: 该方法能够准确重建简单和复杂的发型，且无需颜色信息。同时，引入了Strands400数据集，这是目前最大的公开可用真实发丝数据集，包含400名被试者的重建发丝。

Conclusion: 通过结合多种监督信号，该方法能够有效地从无色三维扫描中准确重建发丝，适用于不同复杂度的发型。Strands400数据集的发布将为未来的相关研究提供支持。

Abstract: We propose a novel method that reconstructs hair strands directly from
colorless 3D scans by leveraging multi-modal hair orientation extraction. Hair
strand reconstruction is a fundamental problem in computer vision and graphics
that can be used for high-fidelity digital avatar synthesis, animation, and
AR/VR applications. However, accurately recovering hair strands from raw scan
data remains challenging due to human hair's complex and fine-grained
structure. Existing methods typically rely on RGB captures, which can be
sensitive to the environment and can be a challenging domain for extracting the
orientation of guiding strands, especially in the case of challenging
hairstyles. To reconstruct the hair purely from the observed geometry, our
method finds sharp surface features directly on the scan and estimates strand
orientation through a neural 2D line detector applied to the renderings of scan
shading. Additionally, we incorporate a diffusion prior trained on a diverse
set of synthetic hair scans, refined with an improved noise schedule, and
adapted to the reconstructed contents via a scan-specific text prompt. We
demonstrate that this combination of supervision signals enables accurate
reconstruction of both simple and intricate hairstyles without relying on color
information. To facilitate further research, we introduce Strands400, the
largest publicly available dataset of hair strands with detailed surface
geometry extracted from real-world data, which contains reconstructed hair
strands from the scans of 400 subjects.

</details>


### [120] [EDmamba: A Simple yet Effective Event Denoising Method with State Space Model](https://arxiv.org/abs/2505.05391)
*Ciyu Ruan,Zihang Gong,Ruishan Guo,Jingao Xu,Xinlei Chen*

Main category: cs.CV

TL;DR: 提出了一种基于状态空间模型（SSM）的新型事件相机去噪框架，该框架高效且准确，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机去噪方法在计算效率和鲁棒性之间存在困境，难以充分发挥事件相机的高速优势。

Method: 将事件表示为4D事件云，通过粗特征提取（CFE）模块提取嵌入特征，并利用空间Mamba（S-SSM）建模局部几何结构，时间Mamba（T-SSM）捕获全局时间动态，从而高效传播时空特征。

Result: 该方法以88.89K参数量和每10万事件0.0685秒的推理时间，实现了0.982的准确率，去噪精度比基于Transformer的方法高2.08%，速度快36倍。

Conclusion: 所提出的基于SSM的事件去噪框架在准确性和效率上均达到业界领先水平，有效解决了现有方法的局限性。

Abstract: Event cameras excel in high-speed vision due to their high temporal
resolution, high dynamic range, and low power consumption. However, as dynamic
vision sensors, their output is inherently noisy, making efficient denoising
essential to preserve their ultra-low latency and real-time processing
capabilities. Existing event denoising methods struggle with a critical
dilemma: computationally intensive approaches compromise the sensor's
high-speed advantage, while lightweight methods often lack robustness across
varying noise levels. To address this, we propose a novel event denoising
framework based on State Space Models (SSMs). Our approach represents events as
4D event clouds and includes a Coarse Feature Extraction (CFE) module that
extracts embedding features from both geometric and polarity-aware subspaces.
The model is further composed of two essential components: A Spatial Mamba
(S-SSM) that models local geometric structures and a Temporal Mamba (T-SSM)
that captures global temporal dynamics, efficiently propagating spatiotemporal
features across events. Experiments demonstrate that our method achieves
state-of-the-art accuracy and efficiency, with 88.89K parameters, 0.0685s per
100K events inference time, and a 0.982 accuracy score, outperforming
Transformer-based methods by 2.08% in denoising accuracy and 36X faster.

</details>


### [121] [PillarMamba: Learning Local-Global Context for Roadside Point Cloud via Hybrid State Space Model](https://arxiv.org/abs/2505.05397)
*Zhang Zhang,Chao Sun,Chao Yue,Da Wen,Tianze Wang,Jianghao Leng*

Main category: cs.CV

TL;DR: 提出了一种名为PillarMamba的新型路侧点云3D目标检测框架，该框架利用Mamba（状态空间模型）并结合跨阶段状态空间组（CSG）和混合状态空间块（HSB）来提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 路侧点云3D目标检测领域尚未得到有效探索，而现有检测器的性能关键在于网络的感受野和场景上下文的有效利用。新兴的Mamba模型因其高效的全局感受野为解决此问题提供了新思路。

Method: 将Mamba引入基于Pillar的路侧点云感知，提出PillarMamba框架。该框架包含：1. 跨阶段状态空间组（CSG），通过跨阶段特征融合增强网络表达能力并实现高效计算。2. 混合状态空间块（HSB），通过局部卷积增强邻域连接，通过残差注意力保留历史记忆，以解决状态空间模型在点云中局部连接中断和历史关系遗忘的问题，从而获取局部-全局上下文。

Result: 所提出的PillarMamba方法在DAIR-V2X-I（一个流行的大型路侧基准数据集）上的表现优于当前最先进的方法。

Conclusion: PillarMamba通过将Mamba与CSG和HSB相结合，有效地应用于路侧点云3D目标检测，增强了网络的表达能力和对局部-全局上下文的捕获，从而提升了检测性能。

Abstract: Serving the Intelligent Transport System (ITS) and Vehicle-to-Everything
(V2X) tasks, roadside perception has received increasing attention in recent
years, as it can extend the perception range of connected vehicles and improve
traffic safety. However, roadside point cloud oriented 3D object detection has
not been effectively explored. To some extent, the key to the performance of a
point cloud detector lies in the receptive field of the network and the ability
to effectively utilize the scene context. The recent emergence of Mamba, based
on State Space Model (SSM), has shaken up the traditional convolution and
transformers that have long been the foundational building blocks, due to its
efficient global receptive field. In this work, we introduce Mamba to
pillar-based roadside point cloud perception and propose a framework based on
Cross-stage State-space Group (CSG), called PillarMamba. It enhances the
expressiveness of the network and achieves efficient computation through
cross-stage feature fusion. However, due to the limitations of scan directions,
state space model faces local connection disrupted and historical relationship
forgotten. To address this, we propose the Hybrid State-space Block (HSB) to
obtain the local-global context of roadside point cloud. Specifically, it
enhances neighborhood connections through local convolution and preserves
historical memory through residual attention. The proposed method outperforms
the state-of-the-art methods on the popular large scale roadside benchmark:
DAIR-V2X-I. The code will be released soon.

</details>


### [122] [SITE: towards Spatial Intelligence Thorough Evaluation](https://arxiv.org/abs/2505.05456)
*Wenqi Wang,Reuben Tan,Pengyue Zhu,Jianwei Yang,Zhengyuan Yang,Lijuan Wang,Andrey Kolobov,Jianfeng Gao,Boqing Gong*

Main category: cs.CV

TL;DR: 该研究引入了一个名为SITE的基准数据集，用于全面评估大型视觉语言模型的空间智能。研究发现，现有模型在空间智能方面，尤其是在空间定向能力上，显著落后于人类专家。


<details>
  <summary>Details</summary>
Motivation: 空间智能对从神经科学到机器人学的多个学科至关重要。目前缺乏一个标准化的、全面的基准来评估大型视觉语言模型（LVLMs）的空间智能。

Method: 引入了一个名为SITE的基准数据集。该数据集采用多项选择视觉问答的形式，覆盖多种视觉模态（单图像、多图像、视频）和空间智能因素。其构建结合了对31个现有数据集的自下而上调查和借鉴认知科学分类系统的自上而下策略，并设计了两种新型任务（视角转换和动态场景）。

Result: 广泛实验表明，领先的视觉语言模型在空间智能方面，尤其是在空间定向这一基本因素上，表现不如人类专家。此外，研究还证明了模型的空间推理能力与其在具身AI任务中的表现之间存在正相关性。

Conclusion: SITE benchmarks的提出为评估大型视觉语言模型的空间智能提供了有效工具。当前模型在空间智能方面，特别是空间定向能力上，与人类水平仍有较大差距，提升模型的空间推理能力可能有助于其在更广泛的AI任务（如具身智能）中的表现。

Abstract: Spatial intelligence (SI) represents a cognitive ability encompassing the
visualization, manipulation, and reasoning about spatial relationships,
underpinning disciplines from neuroscience to robotics. We introduce SITE, a
benchmark dataset towards SI Thorough Evaluation in a standardized format of
multi-choice visual question-answering, designed to assess large
vision-language models' spatial intelligence across diverse visual modalities
(single-image, multi-image, and video) and SI factors (figural to environmental
scales, spatial visualization and orientation, intrinsic and extrinsic, static
and dynamic). Our approach to curating the benchmark combines a bottom-up
survey about 31 existing datasets and a top-down strategy drawing upon three
classification systems in cognitive science, which prompt us to design two
novel types of tasks about view-taking and dynamic scenes. Extensive
experiments reveal that leading models fall behind human experts especially in
spatial orientation, a fundamental SI factor. Moreover, we demonstrate a
positive correlation between a model's spatial reasoning proficiency and its
performance on an embodied AI task.

</details>


### [123] [Generating Physically Stable and Buildable LEGO Designs from Text](https://arxiv.org/abs/2505.05469)
*Ava Pun,Kangle Deng,Ruixuan Liu,Deva Ramanan,Changliu Liu,Jun-Yan Zhu*

Main category: cs.CV

TL;DR: LegoGPT：首个从文本提示生成物理稳定乐高模型的方法。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏能够从文本描述直接生成物理上稳定且结构合理的乐高模型的方法，LegoGPT旨在解决这一挑战。

Method: 构建了一个大规模、物理稳定的乐高设计数据集（StableText2Lego），并基于此训练了一个自回归大型语言模型来预测下一个乐高积木。在推理过程中，采用高效的有效性检查和基于物理的回滚机制来确保生成模型的稳定性。此外，还开发了一种基于文本的乐高纹理化方法。

Result: LegoGPT 能够生成稳定、多样化、美观且与输入文本提示紧密对齐的乐高设计。这些设计不仅可以由人工手动拼搭，也可以由机械臂自动完成。团队还发布了包含超过47,000个乐高结构的新数据集StableText2Lego、相关代码和模型。

Conclusion: LegoGPT成功实现了从文本到物理稳定乐高模型的生成，通过创新的数据集、模型训练方法以及物理约束机制，为乐高创意设计和自动化构建提供了新的可能性和有效工具。

Abstract: We introduce LegoGPT, the first approach for generating physically stable
LEGO brick models from text prompts. To achieve this, we construct a
large-scale, physically stable dataset of LEGO designs, along with their
associated captions, and train an autoregressive large language model to
predict the next brick to add via next-token prediction. To improve the
stability of the resulting designs, we employ an efficient validity check and
physics-aware rollback during autoregressive inference, which prunes infeasible
token predictions using physics laws and assembly constraints. Our experiments
show that LegoGPT produces stable, diverse, and aesthetically pleasing LEGO
designs that align closely with the input text prompts. We also develop a
text-based LEGO texturing method to generate colored and textured designs. We
show that our designs can be assembled manually by humans and automatically by
robotic arms. We also release our new dataset, StableText2Lego, containing over
47,000 LEGO structures of over 28,000 unique 3D objects accompanied by detailed
captions, along with our code and models at the project website:
https://avalovelace1.github.io/LegoGPT/.

</details>


### [124] [Flow-GRPO: Training Flow Matching Models via Online RL](https://arxiv.org/abs/2505.05470)
*Jie Liu,Gongye Liu,Jiajun Liang,Yangguang Li,Jiaheng Liu,Xintao Wang,Pengfei Wan,Di Zhang,Wanli Ouyang*

Main category: cs.CV

TL;DR: 提出了一种名为 Flow-GRPO 的新方法，首次将在线强化学习 (RL) 整合到流匹配模型中，显著提升了文本到图像生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有流匹配模型在处理复杂文本到图像任务（如精确的对象计数、空间关系、细粒度属性、视觉文本渲染和人类偏好对齐）时存在局限性，需要更有效的方法来提升生成质量和控制能力。

Method: Flow-GRPO 方法通过两种关键策略将在线强化学习整合到流匹配模型中：1) ODE-SDE 转换，将确定性常微分方程转换为等效的随机微分方程，以实现强化学习探索的统计采样；2) 去噪缩减策略，在保持推理时间步数不变的情况下减少训练去噪步骤，提高采样效率而不降低性能。

Result: Flow-GRPO 在多个文本到图像任务上表现出色：对于复杂构图，RL调整后的SD3.5模型GenEval准确率从63%提升至95%；视觉文本渲染准确率从59%提升至92%；在人类偏好对齐方面也取得显著进展。重要的是，实验中几乎没有发生奖励操纵现象，图像质量和多样性保持稳定。

Conclusion: Flow-GRPO 成功地将在线强化学习整合到流匹配模型中，有效提升了文本到图像生成在复杂组合、文本渲染和人类偏好对齐等方面的性能，同时避免了奖励操纵问题，保持了图像质量和多样性。

Abstract: We propose Flow-GRPO, the first method integrating online reinforcement
learning (RL) into flow matching models. Our approach uses two key strategies:
(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary
Differential Equation (ODE) into an equivalent Stochastic Differential Equation
(SDE) that matches the original model's marginal distribution at all timesteps,
enabling statistical sampling for RL exploration; and (2) a Denoising Reduction
strategy that reduces training denoising steps while retaining the original
inference timestep number, significantly improving sampling efficiency without
performance degradation. Empirically, Flow-GRPO is effective across multiple
text-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly
perfect object counts, spatial relations, and fine-grained attributes, boosting
GenEval accuracy from $63\%$ to $95\%$. In visual text rendering, its accuracy
improves from $59\%$ to $92\%$, significantly enhancing text generation.
Flow-GRPO also achieves substantial gains in human preference alignment.
Notably, little to no reward hacking occurred, meaning rewards did not increase
at the cost of image quality or diversity, and both remained stable in our
experiments.

</details>


### [125] [Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation](https://arxiv.org/abs/2505.05472)
*Chao Liao,Liyang Liu,Xun Wang,Zhengxiong Luo,Xinyu Zhang,Wenliang Zhao,Jie Wu,Liang Li,Zhi Tian,Weilin Huang*

Main category: cs.CV

TL;DR: Mogao是一个统一的多模态框架，通过因果方法实现交错式的文本和图像生成，并在理解和生成任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在图像理解和生成方面取得了进展，但大多局限于以多模态为条件的单模态生成，缺乏生成交错式多模态内容的能力。

Method: 提出了Mogao框架，采用因果方法，并整合了深度融合设计、双视觉编码器、交错旋转位置嵌入和多模态无分类器指导等关键技术。该框架结合了自回归模型（文本生成）和扩散模型（高质量图像合成）的优势，并使用大规模自建数据集进行高效训练。

Result: Mogao在多模态理解和文本到图像生成方面达到SOTA水平，能生成高质量、连贯的交错式图文输出，并展现出零样本图像编辑和组合生成的涌现能力。

Conclusion: Mogao是一个实用的全模态基础模型，为未来统一多模态系统的发展和扩展铺平了道路。

Abstract: Recent progress in unified models for image understanding and generation has
been impressive, yet most approaches remain limited to single-modal generation
conditioned on multiple modalities. In this paper, we present Mogao, a unified
framework that advances this paradigm by enabling interleaved multi-modal
generation through a causal approach. Mogao integrates a set of key technical
improvements in architecture design, including a deep-fusion design, dual
vision encoders, interleaved rotary position embeddings, and multi-modal
classifier-free guidance, which allow it to harness the strengths of both
autoregressive models for text generation and diffusion models for high-quality
image synthesis. These practical improvements also make Mogao particularly
effective to process interleaved sequences of text and images arbitrarily. To
further unlock the potential of unified models, we introduce an efficient
training strategy on a large-scale, in-house dataset specifically curated for
joint text and image generation. Extensive experiments show that Mogao not only
achieves state-of-the-art performance in multi-modal understanding and
text-to-image generation, but also excels in producing high-quality, coherent
interleaved outputs. Its emergent capabilities in zero-shot image editing and
compositional generation highlight Mogao as a practical omni-modal foundation
model, paving the way for future development and scaling the unified
multi-modal systems.

</details>


### [126] [DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion](https://arxiv.org/abs/2505.05473)
*Qitao Zhao,Amy Lin,Jeff Tan,Jason Y. Zhang,Deva Ramanan,Shubham Tulsiani*

Main category: cs.CV

TL;DR: 提出了一种名为DiffusionSfM的数据驱动的多视图推理方法，可直接从多视图图像推断三维场景几何和相机姿态。


<details>
  <summary>Details</summary>
Motivation: 当前的Structure-from-Motion (SfM)方法通常采用两阶段流程（成对推理后接全局优化），本研究旨在提出一种直接从多视图图像推断场景结构和相机姿态的端到端方法。

Method: 提出了DiffusionSfM框架：将场景几何和相机参数化为全局坐标系中像素级光线的起点和终点，并采用基于Transformer的去噪扩散模型从多视图输入中进行预测。同时引入了特殊机制来处理训练过程中缺失数据和无界场景坐标的挑战。

Result: 在合成数据集和真实数据集上的实验验证表明，DiffusionSfM的性能优于传统的和基于学习的SfM方法，并且能够自然地建模不确定性。

Conclusion: DiffusionSfM是一种有效的端到端SfM方法，通过直接进行多视图推理，在三维场景几何和相机姿态估计方面表现出超越现有方法的性能，并能有效建模不确定性。

Abstract: Current Structure-from-Motion (SfM) methods typically follow a two-stage
pipeline, combining learned or geometric pairwise reasoning with a subsequent
global optimization step. In contrast, we propose a data-driven multi-view
reasoning approach that directly infers 3D scene geometry and camera poses from
multi-view images. Our framework, DiffusionSfM, parameterizes scene geometry
and cameras as pixel-wise ray origins and endpoints in a global frame and
employs a transformer-based denoising diffusion model to predict them from
multi-view inputs. To address practical challenges in training diffusion models
with missing data and unbounded scene coordinates, we introduce specialized
mechanisms that ensure robust learning. We empirically validate DiffusionSfM on
both synthetic and real datasets, demonstrating that it outperforms classical
and learning-based approaches while naturally modeling uncertainty.

</details>


### [127] [3D Scene Generation: A Survey](https://arxiv.org/abs/2505.05474)
*Beichen Wen,Haozhe Xie,Zhaoxi Chen,Fangzhou Hong,Ziwei Liu*

Main category: cs.CV

TL;DR: 这篇综述系统回顾了3D场景生成技术，将其分为程序化生成、神经3D生成、图像生成和视频生成四大范式，并讨论了关键挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 3D场景生成在沉浸式媒体、机器人、自动驾驶等领域需求迫切，现有技术虽有进步但仍面临挑战，因此需要对当前先进方法进行系统性梳理，指明未来研究方向。

Method: 本文将3D场景生成方法归纳为四种主要范式：程序化生成、基于神经3D的生成、基于图像的生成和基于视频的生成。通过分析它们的技术基础、权衡、代表性结果，并回顾常用数据集、评估协议和下游应用。

Result: 综述系统地概述了3D场景生成的最新进展，特别是深度生成模型（如GAN、扩散模型）和3D表示（如NeRF、3D高斯）在提升场景保真度、多样性和视图一致性方面的显著成果。同时分析了各类方法的特点和局限性。

Conclusion: 论文总结了3D场景生成在生成能力、3D表示、数据与标注、评估等方面面临的关键挑战，并指出了更高保真度、物理感知与交互式生成、统一感知-生成模型等有前景的研究方向。

Abstract: 3D scene generation seeks to synthesize spatially structured, semantically
meaningful, and photorealistic environments for applications such as immersive
media, robotics, autonomous driving, and embodied AI. Early methods based on
procedural rules offered scalability but limited diversity. Recent advances in
deep generative models (e.g., GANs, diffusion models) and 3D representations
(e.g., NeRF, 3D Gaussians) have enabled the learning of real-world scene
distributions, improving fidelity, diversity, and view consistency. Recent
advances like diffusion models bridge 3D scene synthesis and photorealism by
reframing generation as image or video synthesis problems. This survey provides
a systematic overview of state-of-the-art approaches, organizing them into four
paradigms: procedural generation, neural 3D-based generation, image-based
generation, and video-based generation. We analyze their technical foundations,
trade-offs, and representative results, and review commonly used datasets,
evaluation protocols, and downstream applications. We conclude by discussing
key challenges in generation capacity, 3D representation, data and annotations,
and evaluation, and outline promising directions including higher fidelity,
physics-aware and interactive generation, and unified perception-generation
models. This review organizes recent advances in 3D scene generation and
highlights promising directions at the intersection of generative AI, 3D
vision, and embodied intelligence. To track ongoing developments, we maintain
an up-to-date project page:
https://github.com/hzxie/Awesome-3D-Scene-Generation.

</details>


### [128] [SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation](https://arxiv.org/abs/2505.05475)
*Yonwoo Choi*

Main category: cs.CV

TL;DR: 提出了一种名为SVAD的新方法，通过结合视频扩散模型和3D高斯溅射（3DGS）技术，从单张图像生成高质量可动画的3D人体化身。


<details>
  <summary>Details</summary>
Motivation: 从单张图像创建高质量可动画的3D人体化身存在显著挑战。现有方法中，3D高斯溅射（3DGS）虽效果好但需多视图或视频，而视频扩散模型虽能从单图生成动画但在一致性和身份保持方面存在问题。

Method: 提出SVAD方法：首先使用视频扩散模型生成合成训练数据，然后通过身份保持和图像恢复模块增强数据质量，最后利用这些精炼数据训练3DGS化身。该数据增强流程克服了传统3DGS对密集单目或多视图训练数据的依赖。

Result: 评估表明，SVAD在保持身份一致性和新姿态/视角的精细细节方面优于现有SOTA单图像方法，并支持实时渲染。定量和定性比较显示，该方法在多个指标上均优于基线模型。

Conclusion: 该工作通过有效结合扩散模型的生成能力与3DGS的高质量结果及渲染效率，为从单图像输入生成高保真度化身建立了一种新方法。

Abstract: Creating high-quality animatable 3D human avatars from a single image remains
a significant challenge in computer vision due to the inherent difficulty of
reconstructing complete 3D information from a single viewpoint. Current
approaches face a clear limitation: 3D Gaussian Splatting (3DGS) methods
produce high-quality results but require multiple views or video sequences,
while video diffusion models can generate animations from single images but
struggle with consistency and identity preservation. We present SVAD, a novel
approach that addresses these limitations by leveraging complementary strengths
of existing techniques. Our method generates synthetic training data through
video diffusion, enhances it with identity preservation and image restoration
modules, and utilizes this refined data to train 3DGS avatars. Comprehensive
evaluations demonstrate that SVAD outperforms state-of-the-art (SOTA)
single-image methods in maintaining identity consistency and fine details
across novel poses and viewpoints, while enabling real-time rendering
capabilities. Through our data augmentation pipeline, we overcome the
dependency on dense monocular or multi-view training data typically required by
traditional 3DGS approaches. Extensive quantitative, qualitative comparisons
show our method achieves superior performance across multiple metrics against
baseline models. By effectively combining the generative power of diffusion
models with both the high-quality results and rendering efficiency of 3DGS, our
work establishes a new approach for high-fidelity avatar generation from a
single image input.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [Towards Artificial Intelligence Research Assistant for Expert-Involved Learning](https://arxiv.org/abs/2505.04638)
*Tianyu Liu,Simeng Han,Xiao Luo,Hanchen Wang,Pan Lu,Biqing Zhu,Yuge Wang,Keyi Li,Jiapeng Chen,Rihao Qu,Yufeng Liu,Xinyue Cui,Aviv Yaish,Yuhang Chen,Minsheng Hao,Chuhan Li,Kexing Li,Arman Cohan,Hua Xu,Mark Gerstein,James Zou,Hongyu Zhao*

Main category: cs.AI

TL;DR: 本研究介绍了ARIEL，一个多模态数据集，旨在评估和增强大型语言模型（LLMs）和大型多模态模型（LMMs）在生物医学研究中总结科学文本和解释生物医学图像的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和大型多模态模型（LMMs）在生物医学应用中的可靠性和具体贡献尚未得到充分表征。

Method: 研究团队构建了一个名为ARIEL的多模态数据集，并创建了两个包含生物医学文章、图表及相关问题的开源数据集。他们对开源和闭源基础模型进行了系统性基准测试，并结合了博士级专家的评估。此外，研究者通过提示工程、微调策略和测试时计算缩放来提升模型性能，并探索了LMM智能体生成科学假设的潜力。

Result: 通过优化方法，模型在推理能力上取得了优于人类专家校正的准确性。研究结果明确了当前基础模型的优势和显著局限性。

Conclusion: 该研究为在生物医学研究中部署大规模语言和多模态模型提供了可行的见解，并为未来的发展方向提供了指导。

Abstract: Large Language Models (LLMs) and Large Multi-Modal Models (LMMs) have emerged
as transformative tools in scientific research, yet their reliability and
specific contributions to biomedical applications remain insufficiently
characterized. In this study, we present \textbf{AR}tificial
\textbf{I}ntelligence research assistant for \textbf{E}xpert-involved
\textbf{L}earning (ARIEL), a multimodal dataset designed to benchmark and
enhance two critical capabilities of LLMs and LMMs in biomedical research:
summarizing extensive scientific texts and interpreting complex biomedical
figures. To facilitate rigorous assessment, we create two open-source sets
comprising biomedical articles and figures with designed questions. We
systematically benchmark both open- and closed-source foundation models,
incorporating expert-driven human evaluations conducted by doctoral-level
experts. Furthermore, we improve model performance through targeted prompt
engineering and fine-tuning strategies for summarizing research papers, and
apply test-time computational scaling to enhance the reasoning capabilities of
LMMs, achieving superior accuracy compared to human-expert corrections. We also
explore the potential of using LMM Agents to generate scientific hypotheses
from diverse multimodal inputs. Overall, our results delineate clear strengths
and highlight significant limitations of current foundation models, providing
actionable insights and guiding future advancements in deploying large-scale
language and multi-modal models within biomedical research.

</details>


### [130] [Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems](https://arxiv.org/abs/2505.04646)
*Poria Azadi*

Main category: cs.AI

TL;DR: 本文通过连接计算极限（如不可判定性、计算不可约性）与物理概念，探讨自主性和能动性的涌现，提出真正的自主性必然意味着从外部视角的不可判定性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解自主性和能动性是如何从智能体与环境的交互中涌现的，特别是通过探索计算的根本局限性（如不可判定性、计算不可约性）在其中扮演的角色，并为自主系统的定义和设计提供理论基础。

Method: 文章引入了一个在潜在图灵完备环境中运行的“最小智能体”的形式化模型。运用算法信息论，论证智能体-环境交互的固有不可判定性和计算不可约性。形式化证明了自主性与外部不可判定性之间的必然联系，并提出能动性涌现于智能体-环境耦合复杂性允许内部状态与环境相关变量间互信息增加的机制。

Result: 研究表明，智能体-环境交互的不可判定性和计算不可约性导致了行为的不可预测性和新信息的产生，这为能动性（有效的目标导向行为）的实现提供了基础。计算不可约性阻止了完全的外部预测，为自主行为创造了必要条件。核心论证结果是：真正的自主性必然意味着从外部观察者角度的不可判定性。

Conclusion: 该框架将能动性与交互的计算特性直接联系起来，认为自主性从根本上与计算极限（如不可判定性）相关联。这对于理解意识、设计真正自主的人工智能系统，以及在确定性但计算不可约的宇宙中重新概念化自由意志具有重要意义。

Abstract: This article explores the emergence of autonomy and agency by connecting
fundamental computational limits (decidability, completeness, computational
irreducibility) with physical concepts. We introduce a formal model of a
"minimal agent" operating within potentially Turing-complete environments.
Using algorithmic information theory, we argue that the inherent undecidability
and computational irreducibility of agent-environment interaction lead to
unpredictability and novel information generation, enabling agency (effective
goal-directed action). Computational irreducibility prevents full external
prediction, creating necessary conditions for autonomous behavior. We relate
this to computational sourcehood, where an agent is the irreducible origin of
its behavior, though formalizing this concept remains challenging. Our central
thesis, formally proven, is that genuine autonomy necessarily implies
undecidability from an external perspective, distinguishing autonomous systems
from predictable ones. We propose that agency arises when agent-environment
coupling complexity allows mutual information between internal states and
relevant environmental variables to increase, particularly where analytical
solutions are absent and operational closure is needed for persistence. This
framework links agency directly to the computational properties of interaction,
offering implications for understanding consciousness, designing autonomous AI,
and reconceptualizing free will in a deterministic yet computationally
irreducible universe.

</details>


### [131] [Dynamic Location Search for Identifying Maximum Weighted Independent Sets in Complex Networks](https://arxiv.org/abs/2505.04674)
*Enqiang Zhu,Chenkai Hao,Chanjuan Liu,Yongsheng Rao*

Main category: cs.AI

TL;DR: 该研究提出了一种名为DynLS的新型高效算法，用于解决最大权独立集（MWIS）问题，旨在克服人工智能在智能交通系统中应用时训练时间和计算资源消耗大的问题。


<details>
  <summary>Details</summary>
Motivation: 人工智能（包括生成式AI）在智能交通系统（ITS）中生成高质量交通数据和优化方案时，通常需要大量的训练时间和计算资源，特别是在大规模和复杂场景下。本研究旨在为可建模许多ITS应用的NP难问题——最大权独立集（MWIS）问题提供一种高效的解决方案。

Method: 提出了一种名为DynLS的新算法，该算法包含三个关键创新：1) 基于分数的自适应顶点扰动（SAVP）技术，以加速特别是在稀疏图中的收敛；2) 区域定位机制（RLM），通过动态调整搜索空间来帮助跳出局部最优；3) 一种新颖的可变邻域下降策略ComLS，该策略结合了顶点交换策略和奖励机制，以引导搜索朝向高质量解。

Result: 实验结果表明，DynLS表现优越，能在1000秒内持续提供高质量解决方案。在360个测试实例中，DynLS优于五个领先算法，为350个实例找到了最佳解决方案，并且比第二优的算法Cyclic-Fast多解决了177个实例。此外，DynLS的收敛速度与Cyclic-Fast相当，突显了其效率和实用性。

Conclusion: 这项研究代表了MWIS问题启发式算法领域的一项重大进展，为辅助人工智能技术优化智能交通系统提供了一种有前景的方法。

Abstract: While Artificial intelligence (AI), including Generative AI, are effective at
generating high-quality traffic data and optimization solutions in intelligent
transportation systems (ITSs), these techniques often demand significant
training time and computational resources, especially in large-scale and
complex scenarios. To address this, we introduce a novel and efficient
algorithm for solving the maximum weighted independent set (MWIS) problem,
which can be used to model many ITSs applications, such as traffic signal
control and vehicle routing. Given the NP-hard nature of the MWIS problem, our
proposed algorithm, DynLS, incorporates three key innovations to solve it
effectively. First, it uses a scores-based adaptive vertex perturbation (SAVP)
technique to accelerate convergence, particularly in sparse graphs. Second, it
includes a region location mechanism (RLM) to help escape local optima by
dynamically adjusting the search space. Finally, it employs a novel variable
neighborhood descent strategy, ComLS, which combines vertex exchange strategies
with a reward mechanism to guide the search toward high-quality solutions. Our
experimental results demonstrate DynLS's superior performance, consistently
delivering high-quality solutions within 1000 seconds. DynLS outperformed five
leading algorithms across 360 test instances, achieving the best solution for
350 instances and surpassing the second-best algorithm, Cyclic-Fast, by 177
instances. Moreover, DynLS matched Cyclic-Fast's convergence speed,
highlighting its efficiency and practicality. This research represents a
significant advancement in heuristic algorithms for the MWIS problem, offering
a promising approach to aid AI techniques in optimizing intelligent
transportation systems.

</details>


### [132] [The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems](https://arxiv.org/abs/2505.04736)
*Sutapa Dey Tithi,Arun Kumar Ramesh,Clara DiMarco,Xiaoyi Tian,Nazia Alam,Kimia Fazeli,Tiffany Barnes*

Main category: cs.AI

TL;DR: 该研究评估了大型语言模型 (LLM) 在构建符号逻辑证明和生成教学提示方面的能力，发现 LLM 在特定条件下表现良好，但仍需改进以确保准确性和教学适宜性。


<details>
  <summary>Details</summary>
Motivation: 传统智能辅导系统在命题逻辑教学中依赖模板化解释，限制了个性化反馈。大型语言模型 (LLM) 虽有潜力生成动态反馈，但存在产生幻觉或教学不当解释的风险。

Method: 研究首先评估了四种先进 LLM 使用六种不同提示技术在358个命题逻辑问题上逐步构建符号逻辑证明的准确性。随后，使用表现最佳的 LLM 为来自逻辑智能辅导系统的1050个独特的学生解题状态生成解释性提示，并通过 LLM 评分器和人类专家（对20%样本）基于4个标准进行评估。

Result: 在逐步证明构建方面，DeepSeek-V3 表现最佳，准确率达到84.4%，尤其在简单规则上表现突出。LLM 生成的提示准确率为75%，在一致性和清晰度方面获得人类评估者高度评价，但在解释提示原因或其更广泛背景方面表现不佳。

Conclusion: 大型语言模型可用于增强辅导系统的逻辑教学提示功能，但需要进行额外修改以确保其准确性和教学上的适当性。

Abstract: Intelligent tutoring systems have demonstrated effectiveness in teaching
formal propositional logic proofs, but their reliance on template-based
explanations limits their ability to provide personalized student feedback.
While large language models (LLMs) offer promising capabilities for dynamic
feedback generation, they risk producing hallucinations or pedagogically
unsound explanations. We evaluated the stepwise accuracy of LLMs in
constructing multi-step symbolic logic proofs, comparing six prompting
techniques across four state-of-the-art LLMs on 358 propositional logic
problems. Results show that DeepSeek-V3 achieved superior performance with
84.4% accuracy on stepwise proof construction and excelled particularly in
simpler rules. We further used the best-performing LLM to generate explanatory
hints for 1,050 unique student problem-solving states from a logic ITS and
evaluated them on 4 criteria with both an LLM grader and human expert ratings
on a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate
and rated highly by human evaluators on consistency and clarity, but did not
perform as well explaining why the hint was provided or its larger context. Our
results demonstrate that LLMs may be used to augment tutoring systems with
logic tutoring hints, but requires additional modifications to ensure accuracy
and pedagogical appropriateness.

</details>


### [133] [Is there Value in Reinforcement Learning?](https://arxiv.org/abs/2505.04822)
*Lior Fox,Yonatan Loewenstein*

Main category: cs.AI

TL;DR: 论文认为策略梯度方法并未真正摆脱对价值表示的依赖，因为其学习过程仍需价值。因此，争论的焦点应从算法选择（如价值基础与策略梯度）转向对强化学习基本假设的审视。


<details>
  <summary>Details</summary>
Motivation: 针对强化学习（RL）模型中行为价值（action-values）是否被明确表示的持续争论，以及批评者提出策略梯度（PG）模型作为替代价值基础（VB）模型的解决方案。

Method: 通过理论分析和论证，指出策略梯度方法在学习阶段仍依赖价值表示。进而提出，价值表示的需求源于强化学习框架的底层优化目标和假设，而非具体算法。以价值争论为案例，倡导在认知科学中采用更注重算法层面的模型评估视角。

Result: 研究表明：1) 策略梯度方法并非“无价值”，其学习过程仍需价值信号。2) 对价值表示的需求根植于标准强化学习框架的假设，而非特定算法（价值基础或策略梯度）。3) 因此，相关争论的重点应转移到对这些基本假设的批判性评估上。4) 当标准RL假设（如风险中性、完全可观测性等）在自然情境下被放宽时，价值的概念本身需要重新审视。

Conclusion: 简单地从价值基础模型转向策略梯度模型并不能解决行为模型中价值表示的困境。核心问题在于强化学习框架的底层假设，需要对其进行严格评估。此外，认知科学在评估模型时，应超越仅关注统计复杂性，更要考虑计算复杂性等算法层面的因素。

Abstract: Action-values play a central role in popular Reinforcement Learing (RL)
models of behavior. Yet, the idea that action-values are explicitly represented
has been extensively debated. Critics had therefore repeatedly suggested that
policy-gradient (PG) models should be favored over value-based (VB) ones, as a
potential solution for this dilemma. Here we argue that this solution is
unsatisfying. This is because PG methods are not, in fact, "Value-free" --
while they do not rely on an explicit representation of Value for acting
(stimulus-response mapping), they do require it for learning. Hence, switching
to PG models is, per se, insufficient for eliminating Value from models of
behavior. More broadly, the requirement for a representation of Value stems
from the underlying assumptions regarding the optimization objective posed by
the standard RL framework, not from the particular algorithm chosen to solve
it. Previous studies mostly took these standard RL assumptions for granted, as
part of their conceptualization or problem modeling, while debating the
different methods used to optimize it (i.e., PG or VB). We propose that,
instead, the focus of the debate should shift to critically evaluating the
underlying modeling assumptions. Such evaluation is particularly important from
an experimental perspective. Indeed, the very notion of Value must be
reconsidered when standard assumptions (e.g., risk neutrality,
full-observability, Markovian environment, exponential discounting) are
relaxed, as is likely in natural settings. Finally, we use the Value debate as
a case study to argue in favor of a more nuanced, algorithmic rather than
statistical, view of what constitutes "a model" in cognitive sciences. Our
analysis suggests that besides "parametric" statistical complexity, additional
aspects such as computational complexity must also be taken into account when
evaluating model complexity.

</details>


### [134] [Large Language Models are Autonomous Cyber Defenders](https://arxiv.org/abs/2505.04843)
*Sebastián R. Castro,Roberto Campbell,Nancy Lau,Octavio Villalobos,Jiaqi Duan,Alvaro A. Cardenas*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型 (LLM) 在多智能体自主网络防御 (ACD) 环境中的表现，并提出了一种 LLM 与强化学习 (RL) 智能体协同工作的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前的自主网络防御 (ACD) 主要依赖强化学习 (RL) 智能体，这些智能体训练成本高昂，且其决策过程缺乏可解释性和可移植性。大型语言模型 (LLM) 有潜力解决这些问题，但其在多智能体 ACD 场景以及与其他 ACD 智能体交互方面的性能尚未得到评估。

Method: 论文首次研究了 LLM 在多智能体 ACD 环境中的性能，具体方法包括：1. 提出将 LLM 集成到 CybORG CAGE 4 环境中；2. 提出一种新的通信协议，以研究 LLM 和 RL 智能体组成的 ACD 团队如何交互。

Result: 研究结果突出了 LLM 和 RL 在多智能体自主网络防御中的各自优势和劣势。

Conclusion: 该研究有助于识别未来创建、训练和部署 ACD 智能体团队的有前景的研究方向，特别是结合 LLM 和 RL 的混合团队。

Abstract: Fast and effective incident response is essential to prevent adversarial
cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response
through Artificial Intelligence (AI) agents that plan and execute actions. Most
ACD approaches focus on single-agent scenarios and leverage Reinforcement
Learning (RL). However, ACD RL-trained agents depend on costly training, and
their reasoning is not always explainable or transferable. Large Language
Models (LLMs) can address these concerns by providing explainable actions in
general security contexts. Researchers have explored LLM agents for ACD but
have not evaluated them on multi-agent scenarios or interacting with other ACD
agents. In this paper, we show the first study on how LLMs perform in
multi-agent ACD environments by proposing a new integration to the CybORG CAGE
4 environment. We examine how ACD teams of LLM and RL agents can interact by
proposing a novel communication protocol. Our results highlight the strengths
and weaknesses of LLMs and RL and help us identify promising research
directions to create, train, and deploy future teams of ACD agents.

</details>


### [135] [CRAFT: Cultural Russian-Oriented Dataset Adaptation for Focused Text-to-Image Generation](https://arxiv.org/abs/2505.04851)
*Viacheslav Vasilev,Vladimir Arkhipkin,Julia Agafonova,Tatiana Nikulina,Evelina Mironova,Alisa Shichanina,Nikolai Gerasimenko,Mikhail Shoytov,Denis Dimitrov*

Main category: cs.AI

TL;DR: 该研究探讨了文生图模型在特定文化理解上的不足，并提出了一种基于“文化代码”（以俄罗斯文化为例）的数据收集与处理方法，以提升模型对特定文化的认知和生成效果。


<details>
  <summary>Details</summary>
Motivation: 流行的文生图模型因训练数据主要基于西方文化，导致其在处理特定文化内容时知识不足，可能产生不准确、低质量的图像，并传播刻板印象。现有研究对模型理解文化代码的重要性探讨不足。

Method: 提出了一种基于文化代码（特别是俄罗斯文化代码）收集和处理数据的方法论。将收集的数据用于Kandinsky 3.1文生图模型，并分析其对特定文化领域图像生成质量的影响。

Result: 人工评估结果显示，使用基于文化代码收集的数据后，Kandinsky 3.1模型对俄罗斯文化的认知水平得到了提升。

Conclusion: 通过引入基于特定文化代码的数据，可以有效改善文生图模型在特定文化背景下的表现，增强其文化敏感性和生成图像的准确性与质量。

Abstract: Despite the fact that popular text-to-image generation models cope well with
international and general cultural queries, they have a significant knowledge
gap regarding individual cultures. This is due to the content of existing large
training datasets collected on the Internet, which are predominantly based on
Western European or American popular culture. Meanwhile, the lack of cultural
adaptation of the model can lead to incorrect results, a decrease in the
generation quality, and the spread of stereotypes and offensive content. In an
effort to address this issue, we examine the concept of cultural code and
recognize the critical importance of its understanding by modern image
generation models, an issue that has not been sufficiently addressed in the
research community to date. We propose the methodology for collecting and
processing the data necessary to form a dataset based on the cultural code, in
particular the Russian one. We explore how the collected data affects the
quality of generations in the national domain and analyze the effectiveness of
our approach using the Kandinsky 3.1 text-to-image model. Human evaluation
results demonstrate an increase in the level of awareness of Russian culture in
the model.

</details>


### [136] [Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models](https://arxiv.org/abs/2505.04914)
*John Hawkins*

Main category: cs.AI

TL;DR: 该研究旨在理解Transformer-decoder模型推理能力的局限性，并为此推出了enigme——一个用于生成文本谜题以训练和评估AI推理能力的开源库。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer-decoder语言模型在执行推理任务时的内在局限性，特别是从其模型架构的约束出发，以更好地理解其推理生成方法。

Method: 通过分析Transformer-decoder模型的潜在变量结构，设计专门的文本谜题（reasoning tasks）来探测其推理能力的边界，并开发了名为enigme的开源库用于生成这些谜题。

Result: 成功开发并推出了enigme，一个开源的文本谜题生成库，可用于训练和评估Transformer-decoder模型及未来AI架构的推理技能。

Conclusion: 考虑Transformer-decoder模型的架构约束对于设计有效的推理能力评估任务至关重要，而enigme库为此提供了一个实用的工具，有助于揭示和评估这些模型推理能力的边界。

Abstract: Transformer-decoder language models are a core innovation in text based
generative artificial intelligence. These models are being deployed as
general-purpose intelligence systems in many applications. Central to their
utility is the capacity to understand natural language commands and exploit the
reasoning embedded in human text corpora to apply some form of reasoning
process to a wide variety of novel tasks. To understand the limitations of this
approach to generating reasoning we argue that we need to consider the
architectural constraints of these systems. Consideration of the latent
variable structure of transformer-decoder models allows us to design reasoning
tasks that should probe the boundary of their capacity to reason. We present
enigme, an open-source library for generating text-based puzzles to be used in
training and evaluating reasoning skills within transformer-decoder models and
future AI architectures.

</details>


### [137] [Belief Filtering for Epistemic Control in Linguistic State Space](https://arxiv.org/abs/2505.04927)
*Sebastian Dumbrava*

Main category: cs.AI

TL;DR: 本文研究了信念过滤作为人工智能体认知控制的方法，通过调控其内部语言表达的认知状态，以提升AI安全与对齐。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能体缺乏有效的内部认知调控机制，以确保其行为符合预期并保障安全，因此需要探索新的控制方法。

Method: 在语义流形框架下，将智能体信念状态表示为自然语言片段的动态结构化集合，并设计信念过滤器对这些片段进行内容感知的操作，从而实现对认知状态的调控。

Result: 研究证明了这种基于语言的认知架构的内在可解释性和模块化特性直接支持了信念过滤的实现，为智能体调控提供了一种原则性方法，并展示了其在提升AI安全性和对齐性方面的潜力。

Conclusion: 信念过滤是一种有效的AI认知控制和治理机制，尤其在语言驱动的认知架构中，通过对智能体内部语义空间的结构化干预，为实现更安全、更可信的人工智能系统指明了新方向。

Abstract: We examine belief filtering as a mechanism for the epistemic control of
artificial agents, focusing on the regulation of internal cognitive states
represented as linguistic expressions. This mechanism is developed within the
Semantic Manifold framework, where belief states are dynamic, structured
ensembles of natural language fragments. Belief filters act as content-aware
operations on these fragments across various cognitive transitions. This paper
illustrates how the inherent interpretability and modularity of such a
linguistically-grounded cognitive architecture directly enable belief
filtering, offering a principled approach to agent regulation. The study
highlights the potential for enhancing AI safety and alignment through
structured interventions in an agent's internal semantic space and points to
new directions for architecturally embedded cognitive governance.

</details>


### [138] [Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to Know When They Do Not Know](https://arxiv.org/abs/2505.04950)
*Shireen Kudukkil Manchingal,Fabio Cuzzolin*

Main category: cs.AI

TL;DR: 人工智能在处理不确定性和泛化方面存在不足。本文提出“认知人工智能”范式，强调模型从已知和无知中学习，以提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型（尤其在自动驾驶等自主系统中）在面对未知或对抗性数据时，处理不确定性和泛化能力不足，难以做出鲁棒的预测，传统机器学习方法对此束手无策。

Method: 本文提出一种名为“认知人工智能”（epistemic artificial intelligence）的新范式。该范式强调模型不仅要从已知数据中学习，更要从自身的“无知”（ignorance）中学习，即识别和管理不确定性。

Result: 本文提出，认知人工智能方法通过让模型识别和管理不确定性，为提高AI系统的韧性和鲁棒性提供了一个有潜力的解决方案。

Conclusion: 采用认知人工智能范式，通过让AI从其“无知”中学习并管理不确定性，可以显著提高AI系统应对不可预测真实世界环境的韧性和鲁棒性。

Abstract: Despite the impressive achievements of AI, including advancements in
generative models and large language models, there remains a significant gap in
the ability of AI to handle uncertainty and generalize beyond the training
data. We argue that AI models, especially in autonomous systems, fail to make
robust predictions when faced with unfamiliar or adversarial data, as evidenced
by incidents with autonomous vehicles. Traditional machine learning approaches
struggle to address these issues due to an overemphasis on data fitting and
domain adaptation. This position paper posits a paradigm shift towards
epistemic artificial intelligence, emphasizing the need for models to learn not
only from what they know but also from their ignorance. This approach, which
focuses on recognizing and managing uncertainty, offers a potential solution to
improve the resilience and robustness of AI systems, ensuring that they can
better handle unpredictable real-world environments.

</details>


### [139] [Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards](https://arxiv.org/abs/2505.04966)
*Jaeho Kim,Yunseok Lee,Seulki Lee*

Main category: cs.AI

TL;DR: 针对AI会议同行评审面临的稿件激增和评审质量问题，本文主张建立作者评估评审质量、评审人获正式认证的双向反馈机制及审稿人奖励体系，以提升评审质量和责任感。


<details>
  <summary>Details</summary>
Motivation: AI会议论文提交量激增（每会议超万篇），导致对评审质量和审稿人责任的日益担忧，现有单向评审体系难以应对。

Method: 提议将传统单向评审系统转变为双向反馈循环：1) 实施两阶段双向评审系统，允许作者评估评审质量，同时最小化报复行为；2) 建立系统的审稿人奖励机制，激励高质量评审，并让审稿人获得正式认证。

Result: （预期成果）通过上述机制建立一个问责框架，促进形成一个可持续的、高质量的同行评审系统，并激励高质量的评审工作。

Conclusion: 本文主张通过改革审稿人问责制和引入系统性奖励来应对当前同行评审面临的挑战，并呼吁学术界关注这些问题并支持必要的改革，以增强同行评审过程。

Abstract: The peer review process in major artificial intelligence (AI) conferences
faces unprecedented challenges with the surge of paper submissions (exceeding
10,000 submissions per venue), accompanied by growing concerns over review
quality and reviewer responsibility. This position paper argues for the need to
transform the traditional one-way review system into a bi-directional feedback
loop where authors evaluate review quality and reviewers earn formal
accreditation, creating an accountability framework that promotes a
sustainable, high-quality peer review system. The current review system can be
viewed as an interaction between three parties: the authors, reviewers, and
system (i.e., conference), where we posit that all three parties share
responsibility for the current problems. However, issues with authors can only
be addressed through policy enforcement and detection tools, and ethical
concerns can only be corrected through self-reflection. As such, this paper
focuses on reforming reviewer accountability with systematic rewards through
two key mechanisms: (1) a two-stage bi-directional review system that allows
authors to evaluate reviews while minimizing retaliatory behavior, (2)a
systematic reviewer reward system that incentivizes quality reviewing. We ask
for the community's strong interest in these problems and the reforms that are
needed to enhance the peer review process.

</details>


### [140] [Foam-Agent: Towards Automated Intelligent CFD Workflows](https://arxiv.org/abs/2505.04997)
*Ling Yue,Nithin Somasekharan,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个多智能体框架，它能根据自然语言输入自动执行复杂的OpenFOAM CFD仿真，从而降低了CFD的使用门槛。


<details>
  <summary>Details</summary>
Motivation: 计算流体动力学(CFD)虽然是重要的仿真工具，但其高门槛的专业知识和手动配置需求限制了其广泛应用。

Method: 提出了Foam-Agent，一个多智能体框架。其核心创新包括：(1) 具有专门索引的分层多索引检索系统；(2) 保证配置文件一致性的依赖感知文件生成系统；(3) 无需人工干预即可诊断和解决仿真故障的迭代纠错机制。

Result: 在110个仿真任务的数据集上，Foam-Agent (使用Claude 3.5 Sonnet) 取得了83.6%的成功率，显著优于现有框架（MetaOpenFOAM为55.5%，OpenFOAM-GPT为37.3%）。消融研究表明，专门的纠错机制使性能提高了36.4%。

Conclusion: Foam-Agent显著降低了CFD的专业知识门槛，同时保持了建模精度，展示了专门的多智能体系统在普及复杂科学仿真工具方面的潜力。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in various
engineering disciplines, but it often requires substantial domain expertise and
manual configuration, creating barriers to entry. We present Foam-Agent, a
multi-agent framework that automates complex OpenFOAM-based CFD simulation
workflows from natural language inputs. Our innovation includes (1) a
hierarchical multi-index retrieval system with specialized indices for
different simulation aspects, (2) a dependency-aware file generation system
that provides consistency management across configuration files, and (3) an
iterative error correction mechanism that diagnoses and resolves simulation
failures without human intervention. Through comprehensive evaluation on the
dataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with
Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for
MetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the
critical contribution of each system component, with the specialized error
correction mechanism providing a 36.4% performance improvement. Foam-Agent
substantially lowers the CFD expertise threshold while maintaining modeling
accuracy, demonstrating the potential of specialized multi-agent systems to
democratize access to complex scientific simulation tools. The code is public
at https://github.com/csml-rpi/Foam-Agent

</details>


### [141] [A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons](https://arxiv.org/abs/2505.05029)
*Siyue Ren,Wanli Fu,Xinkun Zou,Chen Shen,Yi Cai,Chen Chu,Zhen Wang,Shuyue Hu*

Main category: cs.AI

TL;DR: 本文提出RepuNet，一种双层声誉框架，用于缓解生成式多智能体系统中的“公地悲剧”问题，促进合作。


<details>
  <summary>Details</summary>
Motivation: 生成式多智能体系统（MAS）中出现了类似“公地悲剧”的现象，即个体自利行为导致集体灾难性后果。本研究旨在探索使用声誉系统作为一种补救措施来应对这一挑战。

Method: 提出了一种名为RepuNet的动态双层声誉框架。该框架模拟智能体层面的声誉动态（通过直接互动和间接八卦形成）和系统层面的网络演化（智能体决定连接或断开与其他智能体的关系）。

Result: 通过两个不同场景的实验证明，RepuNet有效地缓解了“公地悲剧”，促进并维持了生成式MAS中的合作。此外，研究发现声誉系统可以催生出丰富的涌现行为，如合作集群的形成、剥削性智能体的社会孤立以及倾向于分享积极而非消极的八卦。

Conclusion: RepuNet作为一种声誉系统，能够有效解决生成式多智能体系统中的“公地悲剧”问题，促进合作，并引发有益的社会动态。

Abstract: The tragedy of the commons, where individual self-interest leads to
collectively disastrous outcomes, is a pervasive challenge in human society.
Recent studies have demonstrated that similar phenomena can arise in generative
multi-agent systems (MASs). To address this challenge, this paper explores the
use of reputation systems as a remedy. We propose RepuNet, a dynamic,
dual-level reputation framework that models both agent-level reputation
dynamics and system-level network evolution. Specifically, driven by direct
interactions and indirect gossip, agents form reputations for both themselves
and their peers, and decide whether to connect or disconnect other agents for
future interactions. Through two distinct scenarios, we show that RepuNet
effectively mitigates the 'tragedy of the commons', promoting and sustaining
cooperation in generative MASs. Moreover, we find that reputation systems can
give rise to rich emergent behaviors in generative MASs, such as the formation
of cooperative clusters, the social isolation of exploitative agents, and the
preference for sharing positive gossip rather than negative ones.

</details>


### [142] [Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search](https://arxiv.org/abs/2505.05059)
*Sandro Junior Della Rovere,Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 本文提出一种结合强化学习（RL）与波束搜索（BS）的混合方法，用于模拟IC布局，以提高布局质量、灵活性并解决拥塞问题。


<details>
  <summary>Details</summary>
Motivation: 模拟IC布局因其复杂的权衡、器件物理和电路可变性，难以通过纯学习方法实现完全自动化。现有强化学习方法虽在布局规划中取得进展，但在适应不同目标权重和处理拥塞方面仍有局限性。

Method: 采用一种混合方法，将强化学习（RL）与波束搜索（BS）策略相结合。BS算法增强RL智能体的推理过程，使其能生成适应不同目标权重的灵活布局方案，并且无需重新训练或微调策略即可解决拥塞问题，同时保持RL智能体的泛化能力和对电路特征及约束的高效处理能力。

Result: 实验结果表明，与标准RL应用相比，该方法在面积、死区和半周长线长方面取得了约5-85%的改进，智能体也获得了更高的奖励。此外，其性能和效率与现有最先进技术相当。

Conclusion: 所提出的RL与BS的混合方法能够有效改进模拟IC的自动化布局，在提高布局质量的同时，增强了对不同优化目标和拥塞问题的处理灵活性，其性能达到了与当前顶尖技术相当的水平。

Abstract: The layout of analog ICs requires making complex trade-offs, while addressing
device physics and variability of the circuits. This makes full automation with
learning-based solutions hard to achieve. However, reinforcement learning (RL)
has recently reached significant results, particularly in solving the
floorplanning problem. This paper presents a hybrid method that combines RL
with a beam (BS) strategy. The BS algorithm enhances the agent's inference
process, allowing for the generation of flexible floorplans by accomodating
various objective weightings, and addressing congestion without without the
need for policy retraining or fine-tuning. Moreover, the RL agent's
generalization ability stays intact, along with its efficient handling of
circuit features and constraints. Experimental results show approx. 5-85%
improvement in area, dead space and half-perimeter wire length compared to a
standard RL application, along with higher rewards for the agent. Moreover,
performance and efficiency align closely with those of existing
state-of-the-art techniques.

</details>


### [143] [A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge](https://arxiv.org/abs/2505.05106)
*Luca Salvatore Lorello,Marco Lippi,Stefano Melacci*

Main category: cs.AI

TL;DR: 本文研究了知识驱动的序列分类问题，其中背景知识随时间动态变化且包含时间关系。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号人工智能框架大多处理静态知识，忽略了知识的时间动态性和时间维度。本研究旨在解决更具挑战性的问题：在序列分类中，不同时间步需要利用不同的知识片段，并且知识中存在时间关系。

Method: 通过在一个新提出的基准测试框架上进行实验评估，比较了多阶段神经符号架构和纯神经网络架构的性能。

Result: 实验结果表明，这种新的知识驱动序列分类设置具有挑战性，并突显了神经符号方法中一些尚未被充分探索的缺点。

Conclusion: 该研究为未来在动态知识和时间关系背景下的神经符号学习研究提供了宝贵的参考，并揭示了现有方法的局限性。

Abstract: One of the goals of neuro-symbolic artificial intelligence is to exploit
background knowledge to improve the performance of learning tasks. However,
most of the existing frameworks focus on the simplified scenario where
knowledge does not change over time and does not cover the temporal dimension.
In this work we consider the much more challenging problem of knowledge-driven
sequence classification where different portions of knowledge must be employed
at different timesteps, and temporal relations are available. Our experimental
evaluation compares multi-stage neuro-symbolic and neural-only architectures,
and it is conducted on a newly-introduced benchmarking framework. Results
demonstrate the challenging nature of this novel setting, and also highlight
under-explored shortcomings of neuro-symbolic methods, representing a precious
reference for future research.

</details>


### [144] [Multi-agent Embodied AI: Advances and Future Directions](https://arxiv.org/abs/2505.05108)
*Zhaohan Feng,Ruiqi Xue,Lei Yuan,Yang Yu,Ning Ding,Meiqin Liu,Bingzhao Gao,Jian Sun,Gang Wang*

Main category: cs.AI

TL;DR: 这篇论文是一篇关于多智能体具身人工智能（Embodied AI）的综述，旨在回顾研究现状、分析关键贡献、识别挑战并展望未来方向。


<details>
  <summary>Details</summary>
Motivation: 当前具身AI研究大多集中于单智能体系统和静态、封闭环境，而现实世界应用需要在复杂动态场景中进行多智能体协作。尽管对多智能体系统的兴趣日益增加，但现有研究范围狭窄，且缺乏对该领域进展的全面系统性综述。

Method: 本文通过回顾多智能体具身人工智能领域的当前研究状况，分析其中的关键贡献，并识别该领域面临的挑战和未来的发展方向。

Result: 论文系统地回顾了多智能体具身AI的研究进展，分析了关键性贡献，并明确了该领域在适应性、实时学习和协作问题解决等方面面临的挑战以及未来的研究方向，为该领域的创新和进步提供了见解。

Conclusion: 深化对多智能体具身人工智能的理解对于应对现实世界应用的挑战至关重要。本综述旨在填补现有研究空白，促进该领域的进一步发展，并为未来的创新和进步提供指导性见解。

Abstract: Embodied artificial intelligence (Embodied AI) plays a pivotal role in the
application of advanced technologies in the intelligent era, where AI systems
are integrated with physical bodies that enable them to perceive, reason, and
interact with their environments. Through the use of sensors for input and
actuators for action, these systems can learn and adapt based on real-world
feedback, allowing them to perform tasks effectively in dynamic and
unpredictable environments. As techniques such as deep learning (DL),
reinforcement learning (RL), and large language models (LLMs) mature, embodied
AI has become a leading field in both academia and industry, with applications
spanning robotics, healthcare, transportation, and manufacturing. However, most
research has focused on single-agent systems that often assume static, closed
environments, whereas real-world embodied AI must navigate far more complex
scenarios. In such settings, agents must not only interact with their
surroundings but also collaborate with other agents, necessitating
sophisticated mechanisms for adaptation, real-time learning, and collaborative
problem-solving. Despite increasing interest in multi-agent systems, existing
research remains narrow in scope, often relying on simplified models that fail
to capture the full complexity of dynamic, open environments for multi-agent
embodied AI. Moreover, no comprehensive survey has systematically reviewed the
advancements in this area. As embodied AI rapidly evolves, it is crucial to
deepen our understanding of multi-agent embodied AI to address the challenges
presented by real-world applications. To fill this gap and foster further
development in the field, this paper reviews the current state of research,
analyzes key contributions, and identifies challenges and future directions,
providing insights to guide innovation and progress in this field.

</details>


### [145] [Is there a half-life for the success rates of AI agents?](https://arxiv.org/abs/2505.05115)
*Toby Ord*

Main category: cs.AI

TL;DR: 本研究发现AI智能体在长耗时研发任务中的表现可用一个简单的数学模型（恒定分钟失败率）解释，导致成功率随任务时长指数级下降，并可用“半衰期”概念表征。


<details>
  <summary>Details</summary>
Motivation: 基于Kwa等人(2025)的实证工作，旨在理解和量化AI智能体在长耗时研发任务上的性能表现规律。

Method: 通过构建一个简单的数学模型——假定AI智能体在任务执行过程中每分钟（以人类完成时间计）具有恒定的失败概率——来分析Kwa等人(2025)的研发任务数据。

Result: 该模型与数据拟合良好，揭示了AI智能体在长任务上的成功率随任务长度呈指数级下降的规律。每个智能体可由其“半衰期”表征，且模型可用于预测不同任务长度下的成功率。这表明长任务失败可能源于其包含大量子任务，任何一个子任务失败即导致整体失败。

Conclusion: AI智能体在特定研发任务集中的长耗时任务性能，可由一个恒定分钟失败率模型解释，成功率随任务时长指数下降。失败机制可能与子任务数量增加有关。此模型的普适性有待进一步研究。

Abstract: Building on the recent empirical work of Kwa et al. (2025), I show that
within their suite of research-engineering tasks the performance of AI agents
on longer-duration tasks can be explained by an extremely simple mathematical
model -- a constant rate of failing during each minute a human would take to do
the task. This implies an exponentially declining success rate with the length
of the task and that each agent could be characterised by its own half-life.
This empirical regularity allows us to estimate the success rate for an agent
at different task lengths. And the fact that this model is a good fit for the
data is suggestive of the underlying causes of failure on longer tasks -- that
they involve increasingly large sets of subtasks where failing any one fails
the task. Whether this model applies more generally on other suites of tasks is
unknown and an important subject for further work.

</details>


### [146] [MARK: Memory Augmented Refinement of Knowledge](https://arxiv.org/abs/2505.05177)
*Anish Ganguli,Prabal Deb,Debleena Banerjee*

Main category: cs.AI

TL;DR: 该论文提出MARK框架，利用结构化精炼记忆和多智能体系统，使大型语言模型（LLMs）能够持续学习和适应变化的领域知识，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型难以在不进行昂贵微调的情况下跟上不断变化的领域知识，且现有系统知识与领域专家的深入理解之间存在差距，这阻碍了准确的信息检索和应用。

Method: 提出了记忆增强知识精炼（MARK）框架。该框架利用结构化的精炼记忆，并通过三个专门的智能体（残留精炼记忆智能体、用户问题精炼记忆智能体、LLM响应精炼记忆智能体）来存储、检索、分析和优化领域知识及用户交互信息，同时考虑时间因素（如新近度、频率）来管理知识。

Result: MARK框架使LLMs能够持续学习，无需再训练。它通过提供“真实性基础”策略减少幻觉，增强了模型在医疗、法律和制造等特定领域的适应性，并通过记忆用户偏好改进了个性化AI助手，提高了响应的准确性和连贯性。

Conclusion: MARK框架通过其新颖的记忆增强和多智能体协作机制，为大型语言模型提供了一种无需再训练即可持续适应和学习领域知识的有效途径，从而提升了其在专业领域的性能和个性化服务能力。

Abstract: Large Language Models (LLMs) assist in specialized tasks but struggle to
align with evolving domain knowledge without costly fine-tuning. Domain
knowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid')
and generally accepted principles (e.g., ethical standards); Refined Memory:
Evolving insights shaped by business needs and real-world changes. However, a
significant gap often exists between a domain expert's deep, nuanced
understanding and the system's domain knowledge, which can hinder accurate
information retrieval and application. Our Memory-Augmented Refinement of
Knowledge (MARK) framework enables LLMs to continuously learn without
retraining by leveraging structured refined memory, inspired by the Society of
Mind. MARK operates through specialized agents, each serving a distinct role:
Residual Refined Memory Agent: Stores and retrieves domain-specific insights to
maintain context over time; User Question Refined Memory Agent: Captures
user-provided facts, abbreviations, and terminology for better comprehension;
LLM Response Refined Memory Agent: Extracts key elements from responses for
refinement and personalization. These agents analyse stored refined memory,
detect patterns, resolve contradictions, and improve response accuracy.
Temporal factors like recency and frequency prioritize relevant information
while discarding outdated insights. MARK enhances LLMs in multiple ways: Ground
Truth Strategy: Reduces hallucinations by establishing a structured reference;
Domain-Specific Adaptation: Essential for fields like healthcare, law, and
manufacturing, where proprietary insights are absent from public datasets;
Personalized AI Assistants: Improves virtual assistants by remembering user
preferences, ensuring coherent responses over time.

</details>


### [147] [Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt](https://arxiv.org/abs/2505.05197)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Sébastien Krier,Manfred Diaz,Simon Osindero*

Main category: cs.AI

TL;DR: 针对当前AI伦理对齐追求单一标准而忽视道德多样性的问题，本文提出“适当性框架”，主张通过上下文、社区定制、持续适应和多中心治理来管理持续的道德分歧，而非寻求统一。


<details>
  <summary>Details</summary>
Motivation: 当前“一刀切”的AI伦理对齐方案忽视了社会中持久的道德多样性，可能引发用户抵制、侵蚀信任并破坏现有制度的稳定，因此需要一种更能适应道德多样性的AI伦理框架。

Method: 论文首先批判了AI对齐背后隐含的“理性趋同公理”（即理性个体最终会达成单一伦理共识）。然后，基于冲突理论、文化进化、多智能体系统和制度经济学，提出了“适当性框架”（appropriateness framework）。该框架将持续的道德分歧视为常态，并为此设计了四个原则：(1) 上下文基础，(2) 社区定制，(3) 持续适应，以及 (4) 多中心治理。

Result: 提出了“适当性框架”作为一种应对AI伦理挑战的新方法。该框架主张将AI伦理的重心从“道德统一”的隐喻转变为更具生产力的“冲突管理”隐喻，并认为这种转变是积极且必要的。

Conclusion: 采用“适当性框架”及其设计原则，将AI伦理对齐的范式从追求单一道德标准转变为更有效的冲突管理，对于构建安全、合乎道德且能被广泛接受的AI系统而言，是可取且紧迫的。

Abstract: Artificial Intelligence (AI) systems are increasingly placed in positions
where their decisions have real consequences, e.g., moderating online spaces,
conducting research, and advising on policy. Ensuring they operate in a safe
and ethically acceptable fashion is thus critical. However, most solutions have
been a form of one-size-fits-all "alignment". We are worried that such systems,
which overlook enduring moral diversity, will spark resistance, erode trust,
and destabilize our institutions. This paper traces the underlying problem to
an often-unstated Axiom of Rational Convergence: the idea that under ideal
conditions, rational agents will converge in the limit of conversation on a
single ethics. Treating that premise as both optional and doubtful, we propose
what we call the appropriateness framework: an alternative approach grounded in
conflict theory, cultural evolution, multi-agent systems, and institutional
economics. The appropriateness framework treats persistent disagreement as the
normal case and designs for it by applying four principles: (1) contextual
grounding, (2) community customization, (3) continual adaptation, and (4)
polycentric governance. We argue here that adopting these design principles is
a good way to shift the main alignment metaphor from moral unification to a
more productive metaphor of conflict management, and that taking this step is
both desirable and urgent.

</details>


### [148] [ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints](https://arxiv.org/abs/2505.05232)
*Mahmoud Amiri,Thomas Bocklitz*

Main category: cs.AI

TL;DR: 介绍ChemRxivQuest：一个包含970个高质量问答对的化学领域预印本数据集，旨在支持化学自然语言处理（NLP）的进展。


<details>
  <summary>Details</summary>
Motivation: 化学文献的快速增长给研究人员高效获取领域特定知识带来了挑战，需要专门的NLP工具和资源。

Method: 通过一个自动化流程构建数据集，该流程结合了光学字符识别（OCR）、基于GPT-4o的问答生成以及用于答案验证的模糊匹配技术，数据源自155篇ChemRxiv预印本。

Result: 成功构建了ChemRxivQuest数据集，包含970个高质量问答对，覆盖17个化学子领域，每个问答对都明确链接到其源文本段。该数据集强调概念性、机理性、应用性和实验性问题。

Conclusion: ChemRxivQuest为化学NLP研究、教育和工具开发提供了一个基础资源，并计划未来进行扩展和专家验证。

Abstract: The rapid expansion of chemistry literature poses significant challenges for
researchers seeking to efficiently access domain-specific knowledge. To support
advancements in chemistry-focused natural language processing (NLP), we present
ChemRxivQuest, a curated dataset of 970 high-quality question-answer (QA) pairs
derived from 155 ChemRxiv preprints across 17 subfields of chemistry. Each QA
pair is explicitly linked to its source text segment to ensure traceability and
contextual accuracy. ChemRxivQuest was constructed using an automated pipeline
that combines optical character recognition (OCR), GPT-4o-based QA generation,
and a fuzzy matching technique for answer verification. The dataset emphasizes
conceptual, mechanistic, applied, and experimental questions, enabling
applications in retrieval-based QA systems, search engine development, and
fine-tuning of domain-adapted large language models. We analyze the dataset's
structure, coverage, and limitations, and outline future directions for
expansion and expert validation. ChemRxivQuest provides a foundational resource
for chemistry NLP research, education, and tool development.

</details>


### [149] [Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation](https://arxiv.org/abs/2505.05235)
*Luca Marzari,Isabella Mastroeni,Alessandro Farinelli*

Main category: cs.AI

TL;DR: 提出了一种名为“抽象DNN验证”的新方法，通过验证不安全输出的层次结构，对深度神经网络（DNN）的安全性进行更细致的多级分析，克服了传统二元安全编码的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统DNN形式验证方法采用二元安全属性编码（即模型安全或不安全），无法捕捉模型内部细微的安全级别差异，导致对安全性的评估要么过于严格，要么过于宽松。

Method: 引入“抽象DNN验证”（Abstract DNN-Verification）问题公式，利用抽象解释和输出可达集推理技术，验证不安全输出的层次结构，从而在形式验证过程中评估多个安全级别。

Result: 该方法能够在形式验证过程中评估多个安全级别，其计算成本在最坏情况下与传统二元验证相当，甚至可能更低。它能够根据抽象安全级别违规对对抗性输入进行排序，从而提供更详细的模型安全性和鲁棒性评估。研究通过理论分析及在复杂深度强化学习任务和标准DNN验证基准上的实验验证了其有效性。

Conclusion: “抽象DNN验证”提供了一种更细致、高效的DNN安全分析框架，能够评估不同抽象安全级别并对对抗性输入进行分级，改进了传统二元验证方法的局限性，为DNN安全性提供了更深入的理解。

Abstract: Traditional methods for formal verification (FV) of deep neural networks
(DNNs) are constrained by a binary encoding of safety properties, where a model
is classified as either safe or unsafe (robust or not robust). This binary
encoding fails to capture the nuanced safety levels within a model, often
resulting in either overly restrictive or too permissive requirements. In this
paper, we introduce a novel problem formulation called Abstract
DNN-Verification, which verifies a hierarchical structure of unsafe outputs,
providing a more granular analysis of the safety aspect for a given DNN.
Crucially, by leveraging abstract interpretation and reasoning about output
reachable sets, our approach enables assessing multiple safety levels during
the FV process, requiring the same (in the worst case) or even potentially less
computational effort than the traditional binary verification approach.
Specifically, we demonstrate how this formulation allows rank adversarial
inputs according to their abstract safety level violation, offering a more
detailed evaluation of the model's safety and robustness. Our contributions
include a theoretical exploration of the relationship between our novel
abstract safety formulation and existing approaches that employ abstract
interpretation for robustness verification, complexity analysis of the novel
problem introduced, and an empirical evaluation considering both a complex deep
reinforcement learning task (based on Habitat 3.0) and standard
DNN-Verification benchmarks.

</details>


### [150] [A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods](https://arxiv.org/abs/2505.05396)
*Stefanos Gkikas*

Main category: cs.AI

TL;DR: 该博士论文旨在开发高性能且适用于真实临床环境的创新自动疼痛评估计算方法，研究取得了领域内领先成果，并为人工智能新方法探索奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有自动疼痛评估方法有待改进，临床实践需要更高效、精准的自动化工具。同时，有必要从计算角度深入理解并评估影响疼痛感知的关键因素（如人口统计学特征），以提升评估的准确性和临床适用性。

Method: 首先从临床理论视角研究疼痛评估过程和现有自动方法。在此基础上，设计、开发并提出了适用于不同场景需求的单模态和多模态自动疼痛评估流程。同时，从计算角度研究了影响疼痛感知的显著因素。

Result: 该博士论文中发表的研究证明了所提出方法的有效性，在自动疼痛评估方面取得了当前最先进 (state-of-the-art) 的成果。

Conclusion: 研究成功开发了有效的自动疼痛评估计算方法，达到了领域领先水平。这些成果为未来在人工智能、基础模型和生成式人工智能领域探索新方法铺平了道路。

Abstract: From the original abstract:
  This thesis initially aims to study the pain assessment process from a
clinical-theoretical perspective while exploring and examining existing
automatic approaches. Building on this foundation, the primary objective of
this Ph.D. project is to develop innovative computational methods for automatic
pain assessment that achieve high performance and are applicable in real
clinical settings. A primary goal is to thoroughly investigate and assess
significant factors, including demographic elements that impact pain
perception, as recognized in pain research, through a computational standpoint.
Within the limits of the available data in this research area, our goal was to
design, develop, propose, and offer automatic pain assessment pipelines for
unimodal and multimodal configurations that are applicable to the specific
requirements of different scenarios. The studies published in this Ph.D. thesis
showcased the effectiveness of the proposed methods, achieving state-of-the-art
results. Additionally, they paved the way for exploring new approaches in
artificial intelligence, foundation models, and generative artificial
intelligence.

</details>


### [151] [EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](https://arxiv.org/abs/2505.05440)
*Biao Yi,Xavier Hu,Yurun Chen,Shengyu Zhang,Hongxia Yang,Fan Wu,Fei Wu*

Main category: cs.AI

TL;DR: EcoAgent是一个边云协同的多智能体框架，通过云端规划和边缘执行/观察，在保持高任务成功率的同时显著降低(M)LLM的token消耗，实现高效移动自动化。


<details>
  <summary>Details</summary>
Motivation: 基于云的(M)LLM移动智能体推理能力强但延迟高、成本大；而边缘部署的(M)SLM虽能降低延迟，却常损失通用能力且难以处理复杂任务。本研究旨在解决这些局限性。

Method: 提出EcoAgent框架，一个边云协同的多智能体系统。它包括一个云端规划智能体和两个边缘智能体：执行智能体负责动作执行，观察智能体负责验证结果。观察智能体使用预理解模块将屏幕图像压缩为简洁文本，以减少token使用。若发生失败，规划智能体通过反思模块检索屏幕历史并重新规划。

Result: 在AndroidWorld数据集上的实验表明，EcoAgent在保持高任务成功率的同时，显著减少了MLLM的token消耗。

Conclusion: EcoAgent框架能够实现高效且实用的移动自动化。

Abstract: Cloud-based mobile agents powered by (multimodal) large language models
((M)LLMs) offer strong reasoning abilities but suffer from high latency and
cost. While fine-tuned (M)SLMs enable edge deployment, they often lose general
capabilities and struggle with complex tasks. To address this, we propose
EcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile
automation. EcoAgent features a closed-loop collaboration among a cloud-based
Planning Agent and two edge-based agents: the Execution Agent for action
execution and the Observation Agent for verifying outcomes. The Observation
Agent uses a Pre-Understanding Module to compress screen images into concise
text, reducing token usage. In case of failure, the Planning Agent retrieves
screen history and replans via a Reflection Module. Experiments on AndroidWorld
show that EcoAgent maintains high task success rates while significantly
reducing MLLM token consumption, enabling efficient and practical mobile
automation.

</details>


### [152] [Conversational Process Model Redesign](https://arxiv.org/abs/2505.05453)
*Nataliia Klievtsova,Timotheus Kampik,Juergen Mangler,Stefanie Rinderle-Ma*

Main category: cs.AI

TL;DR: 本文提出了一种会话式流程模型重设计（CPD）方法，利用大型语言模型（LLM）以迭代和可解释的方式辅助领域专家创建和重设计业务流程模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在业务流程管理中的应用多为单次提示执行，缺乏持续交互。本研究旨在探索LLM支持领域专家以迭代和有效方式创建与重设计流程模型的可行性，特别关注会话式交互。

Method: 提出了会话式流程模型重设计（CPD）方法。该方法接收流程模型和用户的自然语言重设计请求。LLM分三步执行：(a) 从文献中识别流程变更模式；(b) 将用户请求重述为与已识别模式预期措辞一致的表达；(c) 将变更的含义应用于流程模型。此多步骤方法旨在实现可解释和可复现的变更。

Result: 评估表明，某些文献中的流程变更模式对LLM和用户而言都难以理解。研究发现用户在清晰描述变更时需要支持。总体而言，根据完整性和正确性标准，LLM能够很好地处理大多数变更。

Conclusion: CPD方法是可行的，LLM可以有效辅助业务流程模型的迭代式重设计。然而，用户需要指导以清晰表达变更需求，且部分变更模式的理解对LLM和用户均构成挑战。所提出的多步骤方法有助于提高变更的可解释性和可复现性。

Abstract: With the recent success of large language models (LLMs), the idea of
AI-augmented Business Process Management systems is becoming more feasible. One
of their essential characteristics is the ability to be conversationally
actionable, allowing humans to interact with the LLM effectively to perform
crucial process life cycle tasks such as process model design and redesign.
However, most current research focuses on single-prompt execution and
evaluation of results, rather than on continuous interaction between the user
and the LLM. In this work, we aim to explore the feasibility of using LLMs to
empower domain experts in the creation and redesign of process models in an
iterative and effective way. The proposed conversational process model redesign
(CPD) approach receives as input a process model and a redesign request by the
user in natural language. Instead of just letting the LLM make changes, the LLM
is employed to (a) identify process change patterns from literature, (b)
re-phrase the change request to be aligned with an expected wording for the
identified pattern (i.e., the meaning), and then to (c) apply the meaning of
the change to the process model. This multi-step approach allows for
explainable and reproducible changes. In order to ensure the feasibility of the
CPD approach, and to find out how well the patterns from literature can be
handled by the LLM, we performed an extensive evaluation. The results show that
some patterns are hard to understand by LLMs and by users. Within the scope of
the study, we demonstrated that users need support to describe the changes
clearly. Overall the evaluation shows that the LLMs can handle most changes
well according to a set of completeness and correctness criteria.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [153] [MatMMFuse: Multi-Modal Fusion model for Material Property Prediction](https://arxiv.org/abs/2505.04634)
*Abhiroop Bhattacharya,Sylvain G. Cloutier*

Main category: cs.LG

TL;DR: 提出了一种名为 MatMMFuse 的多模态融合模型，结合图编码和文本编码预测材料性质，在性能和零样本学习能力上均优于单一模态模型。


<details>
  <summary>Details</summary>
Motivation: 单一模态模型在材料属性预测中无法充分利用不同表示（如图结构和文本描述）的优势来增强特征空间，而预训练的大型语言模型（LLMs）和图编码器分别能捕捉全局知识和局部特征。

Method: 提出了 Material Multi-Modal Fusion (MatMMFuse) 模型，该模型使用多头注意力机制来融合来自晶体图卷积网络 (CGCNN) 的结构感知嵌入和来自 SciBERT 模型的文本嵌入，并在 Materials Project 数据集上进行端到端训练。

Result: MatMMFuse 在预测四种关键材料性质（形成能、带隙、赫尔包络以上能量和费米能）方面均优于单独的 CGCNN 和 SciBERT 模型。特别是在预测原子形成能方面，MatMMFuse 比 CGCNN 提高了40%，比 SciBERT 提高了68%。此外，该模型在钙钛矿、硫族化合物和 Jarvis 数据集等小型策划数据集上展现了优于单一模型的零样本性能。

Conclusion: MatMMFuse 模型展示了优越的零样本学习性能，这使得研究人员能够将其部署到那些训练数据收集成本过高的专业工业应用中。

Abstract: The recent progress of using graph based encoding of crystal structures for
high throughput material property prediction has been quite successful.
However, using a single modality model prevents us from exploiting the
advantages of an enhanced features space by combining different
representations. Specifically, pre-trained Large language models(LLMs) can
encode a large amount of knowledge which is beneficial for training of models.
Moreover, the graph encoder is able to learn the local features while the text
encoder is able to learn global information such as space group and crystal
symmetry. In this work, we propose Material Multi-Modal Fusion(MatMMFuse), a
fusion based model which uses a multi-head attention mechanism for the
combination of structure aware embedding from the Crystal Graph Convolution
Network (CGCNN) and text embeddings from the SciBERT model. We train our model
in an end-to-end framework using data from the Materials Project Dataset. We
show that our proposed model shows an improvement compared to the vanilla CGCNN
and SciBERT model for all four key properties: formation energy, band gap,
energy above hull and fermi energy. Specifically, we observe an improvement of
40% compared to the vanilla CGCNN model and 68% compared to the SciBERT model
for predicting the formation energy per atom. Importantly, we demonstrate the
zero shot performance of the trained model on small curated datasets of
Perovskites, Chalcogenides and the Jarvis Dataset. The results show that the
proposed model exhibits better zero shot performance than the individual plain
vanilla CGCNN and SciBERT model. This enables researchers to deploy the model
for specialized industrial applications where collection of training data is
prohibitively expensive.

</details>


### [154] [Conformal Prediction with Corrupted Labels: Uncertain Imputation and Robust Re-weighting](https://arxiv.org/abs/2505.04733)
*Shai Feldman,Stephen Bates,Yaniv Romano*

Main category: cs.LG

TL;DR: 本文研究了在训练数据标签损坏情况下的鲁棒不确定性量化。分析了特权保形预测 (PCP) 对权重不准确的鲁棒性，提出了一种新的不依赖权重估计的“不确定性插补”(UI) 方法，并将这些技术整合进一个三重鲁棒框架。


<details>
  <summary>Details</summary>
Motivation: 传统的保形预测在数据标签损坏（如噪声或缺失标签）时会失效，因为它依赖于独立同分布假设。已有的特权保形预测 (PCP) 方法试图通过特权信息重新加权数据来解决此问题，但其有效性依赖于权重估计的准确性，而这种准确性难以保证。

Method: 1. 分析特权保形预测 (PCP) 在权重估计不准确时的鲁棒性。
2. 提出一种新的保形方法——不确定性插补 (UI)，该方法不依赖权重估计，而是通过一种保留其不确定性的方式来插补损坏的标签。
3. 将上述技术整合到一个三重鲁棒框架中，以期在至少一种基础方法有效的情况下保证预测的统计有效性。

Result: 1. 分析表明，即使权重估计不佳，PCP 仍能产生有效的不确定性估计。
2. 新提出的 UI 方法具有理论保证，并在合成数据和真实基准数据集上得到了实证验证。
3. 三重鲁棒框架能够确保只要至少一种基础方法有效，就能获得统计上有效的预测。

Conclusion: 本文通过分析PCP的鲁棒性、引入UI方法以及构建三重鲁棒框架，为解决标签损坏数据下的不确定性量化问题提供了有效的理论和实证支持，增强了预测的可靠性。

Abstract: We introduce a framework for robust uncertainty quantification in situations
where labeled training data are corrupted, through noisy or missing labels. We
build on conformal prediction, a statistical tool for generating prediction
sets that cover the test label with a pre-specified probability. The validity
of conformal prediction, however, holds under the i.i.d assumption, which does
not hold in our setting due to the corruptions in the data. To account for this
distribution shift, the privileged conformal prediction (PCP) method proposed
leveraging privileged information (PI) -- additional features available only
during training -- to re-weight the data distribution, yielding valid
prediction sets under the assumption that the weights are accurate. In this
work, we analyze the robustness of PCP to inaccuracies in the weights. Our
analysis indicates that PCP can still yield valid uncertainty estimates even
when the weights are poorly estimated. Furthermore, we introduce uncertain
imputation (UI), a new conformal method that does not rely on weight
estimation. Instead, we impute corrupted labels in a way that preserves their
uncertainty. Our approach is supported by theoretical guarantees and validated
empirically on both synthetic and real benchmarks. Finally, we show that these
techniques can be integrated into a triply robust framework, ensuring
statistically valid predictions as long as at least one underlying method is
valid.

</details>


### [155] [SetONet: A Deep Set-based Operator Network for Solving PDEs with permutation invariant variable input sampling](https://arxiv.org/abs/2505.04738)
*Stepan Tretiakov,Xingjian Li,Krishna Kumar*

Main category: cs.LG

TL;DR: 论文提出SetONet，一种将Deep Sets原理集成到DeepONet中的新架构，使其能够处理在可变位置采样或有缺失数据的输入函数，解决了标准DeepONet的局限性。


<details>
  <summary>Details</summary>
Motivation: 标准DeepONet要求输入函数在固定位置采样，这限制了其在传感器配置可变、数据缺失或网格不规则等实际场景中的应用。

Method: 引入SetONet架构，其核心创新在于分支网络将输入函数处理为位置-值对的无序集合，确保了对输入点排列的不变性，并显式处理空间坐标和函数值以学习更丰富的输入表示。

Result: SetONet在可变输入采样条件下成功学习算子，而标准DeepONet则失败；SetONet对传感器缺失具有鲁棒性，无需插值；在固定网格上，SetONet的精度与DeepONet相当或更高，尤其在非线性问题上表现更优。

Conclusion: SetONet为神经算子学习提供了一个灵活且鲁棒的扩展，显著拓宽了其在处理可变或不完整输入数据问题上的应用范围。

Abstract: Neural operators, particularly the Deep Operator Network (DeepONet), have
shown promise in learning mappings between function spaces for solving
differential equations. However, standard DeepONet requires input functions to
be sampled at fixed locations, limiting its applicability in scenarios with
variable sensor configurations, missing data, or irregular grids. We introduce
the Set Operator Network (SetONet), a novel architecture that integrates Deep
Sets principles into the DeepONet framework to address this limitation. The
core innovation lies in the SetONet branch network, which processes the input
function as an unordered \emph{set} of location-value pairs. This design
ensures permutation invariance with respect to the input points, making SetONet
inherently robust to variations in the number and locations of sensors. SetONet
learns richer, spatially-aware input representations by explicitly processing
spatial coordinates and function values. We demonstrate SetONet's effectiveness
on several benchmark problems, including derivative/anti-derivative operators,
1D Darcy flow, and 2D elasticity. Results show that SetONet successfully learns
operators under variable input sampling conditions where standard DeepONet
fails. Furthermore, SetONet is architecturally robust to sensor drop-off;
unlike standard DeepONet, which requires methods like interpolation to function
with missing data. Notably, SetONet can achieve comparable or improved accuracy
over DeepONet on fixed grids, particularly for nonlinear problems, likely due
to its enhanced input representation. SetONet provides a flexible and robust
extension to the neural operator toolkit, significantly broadening the
applicability of operator learning to problems with variable or incomplete
input data.

</details>


### [156] [When Bad Data Leads to Good Models](https://arxiv.org/abs/2505.04741)
*Kenneth Li,Yida Chen,Fernanda Viégas,Martin Wattenberg*

Main category: cs.LG

TL;DR: 研究发现，在预训练阶段使用更多有毒数据，结合后训练处理，反而能让大语言模型在最终输出时毒性更低、控制性更好。


<details>
  <summary>Details</summary>
Motivation: 重新审视大语言模型预训练中的“数据质量”观念，探索预训练数据中的“坏”数据（如毒性内容）是否能在与后训练协同设计的前提下，反而帮助提升模型最终的控制性和安全性。

Method: 1. 通过小型实验研究数据构成对表征空间特征几何的影响。2. 使用Olmo-1B模型，在预训练中调整干净数据与有毒数据的比例进行对照实验。3. 分析模型对“毒性”概念的表征。4. 在模型推理时应用干预技术（如ITI）进行去毒处理。5. 在Toxigen和Real Toxicity Prompts数据集上评估模型效果。

Result: 1. 预训练数据中有毒内容比例越高，模型对“毒性”概念的线性表征越清晰、纠缠越少。2. 尽管有毒数据会增加基础模型的初始毒性，但也使得这种毒性在后续处理中更容易被移除。3. 经过有毒数据预训练的模型，在应用去毒技术后，能更好地平衡降低输出毒性与保持通用能力。

Conclusion: 研究结果表明，若将预训练与后训练阶段结合考虑，预训练时包含一定量的“坏”数据（如毒性数据），反而可能有助于构建出最终性能更好、毒性更低、更可控的大语言模型。

Abstract: In large language model (LLM) pretraining, data quality is believed to
determine model quality. In this paper, we re-examine the notion of "quality"
from the perspective of pre- and post-training co-design. Specifically, we
explore the possibility that pre-training on more toxic data can lead to better
control in post-training, ultimately decreasing a model's output toxicity.
First, we use a toy experiment to study how data composition affects the
geometry of features in the representation space. Next, through controlled
experiments with Olmo-1B models trained on varying ratios of clean and toxic
data, we find that the concept of toxicity enjoys a less entangled linear
representation as the proportion of toxic data increases. Furthermore, we show
that although toxic data increases the generational toxicity of the base model,
it also makes the toxicity easier to remove. Evaluations on Toxigen and Real
Toxicity Prompts demonstrate that models trained on toxic data achieve a better
trade-off between reducing generational toxicity and preserving general
capabilities when detoxifying techniques such as inference-time intervention
(ITI) are applied. Our findings suggest that, with post-training taken into
account, bad data may lead to good models.

</details>


### [157] [Primal-dual algorithm for contextual stochastic combinatorial optimization](https://arxiv.org/abs/2505.04757)
*Louis Bouvier,Thibault Prunet,Vincent Leclère,Axel Parmentier*

Main category: cs.LG

TL;DR: 论文提出了一种新的上下文随机优化方法，结合运筹学和机器学习，利用带有组合优化层的神经网络编码决策策略，以最小化经验风险。


<details>
  <summary>Details</summary>
Motivation: 传统方法在利用上下文信息方面存在不足，难以有效处理不确定性下的决策问题，因此需要新的算法。

Method: 采用带有组合优化层的神经网络来编码策略，旨在最小化基于历史数据估计的经验风险。提出一个代理学习问题和一个通用的原始-对偶算法，该算法扩展了经典的Fenchel-Young损失结果，并引入了一种新的基于分布单纯形上稀疏扰动的正则化方法。

Result: 理论上证明了算法在特定条件下的线性收敛性，并给出了策略在经验风险方面的非最优性界限。在上下文随机最小权生成树问题上的实验表明，该算法高效、可扩展，且性能与模仿学习昂贵拉格朗日启发式解的方法相当。

Conclusion: 该研究提出的新方法在上下文随机优化问题中是有效且可扩展的，其性能可与模仿学习基于复杂启发式算法得到的解相媲美，为解决不确定性下的决策提供了新途径。

Abstract: This paper introduces a novel approach to contextual stochastic optimization,
integrating operations research and machine learning to address decision-making
under uncertainty. Traditional methods often fail to leverage contextual
information, which underscores the necessity for new algorithms. In this study,
we utilize neural networks with combinatorial optimization layers to encode
policies. Our goal is to minimize the empirical risk, which is estimated from
past data on uncertain parameters and contexts. To that end, we present a
surrogate learning problem and a generic primal-dual algorithm that is
applicable to various combinatorial settings in stochastic optimization. Our
approach extends classic Fenchel-Young loss results and introduces a new
regularization method using sparse perturbations on the distribution simplex.
This allows for tractable updates in the original space and can accommodate
diverse objective functions. We demonstrate the linear convergence of our
algorithm under certain conditions and provide a bound on the non-optimality of
the resulting policy in terms of the empirical risk. Experiments on a
contextual stochastic minimum weight spanning tree problem show that our
algorithm is efficient and scalable, achieving performance comparable to
imitation learning of solutions computed using an expensive Lagrangian-based
heuristic.

</details>


### [158] [Prediction via Shapley Value Regression](https://arxiv.org/abs/2505.04775)
*Amr Alkhatib,Roman Bresson,Henrik Boström,Michalis Vazirgiannis*

Main category: cs.LG

TL;DR: 提出了一种名为 ViaSHAP 的新方法，通过学习一个函数来直接计算 Shapley 值并由此推导预测，以克服传统 Shapley 值计算的推理时高成本问题。


<details>
  <summary>Details</summary>
Motivation: 传统的 Shapley 值计算方法在模型推理（inference time）时会带来额外的计算成本。

Method: 提出 ViaSHAP 方法，该方法学习一个函数来计算 Shapley 值，模型预测可以直接通过对这些 Shapley 值求和得到。研究了两种实现该方法的途径：一种基于通用近似定理，另一种基于 Kolmogorov-Arnold 表示定理。

Result: 大规模实证研究表明，使用 Kolmogorov-Arnold 网络的 ViaSHAP 在表格数据上的性能与当前最先进的算法相当。同时，在表格数据和图像数据上，ViaSHAP 生成的解释比流行的近似方法 FastSHAP 更为准确。

Conclusion: ViaSHAP 是一种能够高效且准确计算 Shapley 值的新方法，特别是当结合 Kolmogorov-Arnold 网络时，它在解释准确性方面优于现有近似方法，同时在表格数据上保持了与顶尖算法相当的预测性能。

Abstract: Shapley values have several desirable, theoretically well-supported,
properties for explaining black-box model predictions. Traditionally, Shapley
values are computed post-hoc, leading to additional computational cost at
inference time. To overcome this, a novel method, called ViaSHAP, is proposed,
that learns a function to compute Shapley values, from which the predictions
can be derived directly by summation. Two approaches to implement the proposed
method are explored; one based on the universal approximation theorem and the
other on the Kolmogorov-Arnold representation theorem. Results from a
large-scale empirical investigation are presented, showing that ViaSHAP using
Kolmogorov-Arnold Networks performs on par with state-of-the-art algorithms for
tabular data. It is also shown that the explanations of ViaSHAP are
significantly more accurate than the popular approximator FastSHAP on both
tabular data and images.

</details>


### [159] [Robust ML Auditing using Prior Knowledge](https://arxiv.org/abs/2505.04796)
*Jade Garcia Bourrée,Augustin Godinot,Martijn De Vos,Milos Vujasinovic,Sayan Biswas,Gilles Tredan,Erwan Le Merrer,Anne-Marie Kermarrec*

Main category: cs.LG

TL;DR: 该论文提出了一种利用审计者先验知识的防操纵公平性审计新方法，以应对平台在审计过程中可能存在的欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 机器学习决策系统在产品和服务中的广泛应用带来了相应的法规。然而，在对这些系统进行公平性审计时，存在一个关键但未被充分探讨的问题：平台可能故意操纵其对监管机构的回答以通过审计，而不改变其对其他用户的回答，从而产生操纵风险。

Method: 本文引入了一种新颖的防操纵审计方法，该方法考虑了审计者对平台所解决任务的先验知识。首先，研究证明了监管机构不能依赖公共先验（如公共数据集），因为平台在这种情况下很容易欺骗审计者。然后，研究正式确立了审计者利用关于真实情况的先验知识来防止审计操纵的条件。

Result: 实验结果表明，如果审计者依赖公共先验，平台很容易欺骗审计者。研究还通过两个标准数据集的实验，例证了平台在被检测为恶意之前可以隐藏的最大不公平程度。

Conclusion: 该研究对带先验知识的防操纵审计进行了形式化和推广，为更稳健的公平性审计开辟了新的研究方向。

Abstract: The rapid adoption of ML decision-making systems across products and services
has led to a set of regulations on how such systems should behave and be built.
Among all the technical challenges to enforcing these regulations, one crucial,
yet under-explored problem is the risk of manipulation while these systems are
being audited for fairness. This manipulation occurs when a platform
deliberately alters its answers to a regulator to pass an audit without
modifying its answers to other users. In this paper, we introduce a novel
approach to manipulation-proof auditing by taking into account the auditor's
prior knowledge of the task solved by the platform. We first demonstrate that
regulators must not rely on public priors (e.g. a public dataset), as platforms
could easily fool the auditor in such cases. We then formally establish the
conditions under which an auditor can prevent audit manipulations using prior
knowledge about the ground truth. Finally, our experiments with two standard
datasets exemplify the maximum level of unfairness a platform can hide before
being detected as malicious. Our formalization and generalization of
manipulation-proof auditing with a prior opens up new research directions for
more robust fairness audits.

</details>


### [160] [ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling](https://arxiv.org/abs/2505.04802)
*Xiao Wang,Jong-Youl Choi,Takuya Kurihaya,Isaac Lyngaas,Hong-Jun Yoon,Ming Fan,Nasik Muhammad Nafi,Aristeidis Tsaris,Ashwin M. Aji,Maliha Hossain,Mohamed Wahib,Dali Wang,Peter Thornton,Prasanna Balaprakash,Moetasim Ashfaq,Dan Lu*

Main category: cs.LG

TL;DR: ORBIT-2是一个可扩展的基础模型，用于全球超高分辨率气候降尺度，通过Reslim和TILES创新实现高效准确的预测。


<details>
  <summary>Details</summary>
Motivation: 稀疏的观测数据和粗分辨率的气候模型限制了有效的区域决策，现有AI方法在跨变量和地理区域的泛化能力不足，并受限于视觉Transformer（ViT）自注意力的二次方复杂度。

Method: 引入了ORBIT-2模型，包含两个关键创新：(1) 残差轻量ViT（Reslim），一种具有残差学习和贝叶斯正则化的轻量级架构，用于高效、鲁棒的预测；(2) TILES，一种分块序列缩放算法，将自注意力复杂度从二次方降低到线性，支持长序列处理和大规模并行。

Result: ORBIT-2可扩展至100亿参数，在32768个GPU上运行，实现了高达1.8 ExaFLOPS的持续吞吐量和92-98%的强扩展效率。它支持降尺度至0.9公里全球分辨率，并能处理长达42亿令牌的序列。在7公里分辨率的基准测试中，ORBIT-2针对观测数据取得了0.98至0.99范围内的R^2得分，表现出高准确性。

Conclusion: ORBIT-2为全球超高分辨率气候降尺度提供了一个可扩展且高效的基础模型，解决了现有方法的泛化和计算复杂度问题。

Abstract: Sparse observations and coarse-resolution climate models limit effective
regional decision-making, underscoring the need for robust downscaling.
However, existing AI methods struggle with generalization across variables and
geographies and are constrained by the quadratic complexity of Vision
Transformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation
model for global, hyper-resolution climate downscaling. ORBIT-2 incorporates
two key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture
with residual learning and Bayesian regularization for efficient, robust
prediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces
self-attention complexity from quadratic to linear, enabling long-sequence
processing and massive parallelism. ORBIT-2 scales to 10 billion parameters
across 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and
92-98% strong scaling efficiency. It supports downscaling to 0.9 km global
resolution and processes sequences up to 4.2 billion tokens. On 7 km resolution
benchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98
to 0.99 against observation data.

</details>


### [161] [Piecewise Constant Spectral Graph Neural Network](https://arxiv.org/abs/2505.04808)
*Vahan Martirosyan,Jhony H. Giraldo,Fragkiskos D. Malliaros*

Main category: cs.LG

TL;DR: 本文提出了一种名为PieCoN的新型谱图神经网络，它结合常数谱滤波器和多项式滤波器，并通过自适应划分频谱区间，以更灵活地捕获图谱特性，尤其在异质图上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的谱图神经网络使用低阶多项式滤波器，可能无法充分识别图的谱特性。而增加多项式阶数计算成本高昂，且可能导致性能瓶颈或下降。

Method: 提出了分段常数谱图神经网络（PieCoN）。该方法将常数谱滤波器与多项式滤波器相结合，并通过自适应地将频谱划分为多个区间，从而更灵活地利用图结构，增加可有效学习的谱特性范围。

Result: 在九个基准数据集（包括同质图和异质图）上的实验表明，PieCoN 模型在异质性数据集上尤其有效。

Conclusion: PieCoN 通过更灵活地利用图结构学习谱特性，提升了模型性能，特别是在处理异质图方面显示出巨大潜力，适用于广泛的应用场景。

Abstract: Graph Neural Networks (GNNs) have achieved significant success across various
domains by leveraging graph structures in data. Existing spectral GNNs, which
use low-degree polynomial filters to capture graph spectral properties, may not
fully identify the graph's spectral characteristics because of the polynomial's
small degree. However, increasing the polynomial degree is computationally
expensive and beyond certain thresholds leads to performance plateaus or
degradation. In this paper, we introduce the Piecewise Constant Spectral Graph
Neural Network(PieCoN) to address these challenges. PieCoN combines constant
spectral filters with polynomial filters to provide a more flexible way to
leverage the graph structure. By adaptively partitioning the spectrum into
intervals, our approach increases the range of spectral properties that can be
effectively learned. Experiments on nine benchmark datasets, including both
homophilic and heterophilic graphs, demonstrate that PieCoN is particularly
effective on heterophilic datasets, highlighting its potential for a wide range
of applications.

</details>


### [162] [Guide your favorite protein sequence generative model](https://arxiv.org/abs/2505.04823)
*Junhao Xiong,Hunter Nisonoff,Ishan Gaur,Jennifer Listgarten*

Main category: cs.LG

TL;DR: ProteinGuide是一个通用框架，能够引导预训练的蛋白质生成模型，根据用户指定的辅助信息生成具有特定属性的蛋白质序列。


<details>
  <summary>Details</summary>
Motivation: 当前的蛋白质生成模型缺乏一个标准化的框架，以即插即用方式整合辅助信息（如实验反馈或现有分类器）来引导生成过程，从而获得具有期望特性的蛋白质。

Method: 提出了ProteinGuide框架。该框架通过统一多种蛋白质生成模型（包括掩码语言模型、自回归模型、扩散模型和流匹配模型），提供了一种统计学方法来调节预训练的蛋白质生成模型。

Result: 成功应用ProteinGuide引导了两种常用的蛋白质生成模型（ProteinMPNN和ESM3），使其能够根据用户指定的属性（如增强的稳定性和CATH标记的蛋白质折叠类型）生成相应的氨基酸序列和结构标记序列。

Conclusion: ProteinGuide提供了一个严谨且通用的框架，能够有效地利用辅助信息来引导预训练的蛋白质生成模型，从而生成具有特定期望特性的蛋白质。

Abstract: Generative machine learning models have begun to transform protein
engineering, yet no principled framework for conditioning on auxiliary
information in a plug-and-play manner exists; one may want to iteratively
incorporate experimental feedback, or make use of an existing classifier --
such as for predicting enzyme commission number -- in order to guide the
sampling of the generative model to generate sequences with desired properties.
Herein, we present ProteinGuide, a rigorous and general framework to achieve
just that: through unifying a broad class of protein generative models that
includes masked language, (order-agnostic) autoregressive, diffusion and
flow-matching models, we provide an approach to statistically condition
pre-trained protein generative models. We demonstrate applicability of our
approach by guiding each of two commonly used protein generative models,
ProteinMPNN and ESM3, to generate amino acid and structure token sequences
conditioned on several user-specified properties, namely, enhanced stability
and CATH-labeled fold generation.

</details>


### [163] [Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org/abs/2505.04842)
*Kusha Sareen,Morgane M Moss,Alessandro Sordoni,Rishabh Agarwal,Arian Hosseini*

Main category: cs.LG

TL;DR: 提出RL$^V$方法，通过联合训练LLM作为推理器和生成式验证器，增强了LLM的验证能力和推理性能，并显著提升了测试时的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的用于微调大型语言模型（LLM）推理器的强化学习（RL）方法（如GRPO或Leave-one-out PPO）放弃了学习到的价值函数，这阻碍了依赖价值函数进行验证的测试时计算规模扩展。

Method: 提出RL$^V$方法，它通过使用强化学习生成的数据，将LLM联合训练为推理器和生成式验证器，从而增强任何“无价值函数”的强化学习方法，在不显著增加开销的情况下增加了验证能力。

Result: RL$^V$通过并行采样将MATH准确率提高了20%以上，与基础RL方法相比，测试时计算效率提升了8-32倍。RL$^V$在从易到难和域外任务中也表现出强大的泛化能力。此外，当使用长推理R1模型联合扩展并行和顺序测试时计算时，RL$^V$实现了1.2-1.6倍的更高性能。

Conclusion: RL$^V$通过为LLM增加生成式验证能力，有效地提升了其推理性能、计算效率和泛化能力，且额外开销很小。

Abstract: Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners,
such as GRPO or Leave-one-out PPO, abandon the learned value function in favor
of empirically estimated returns. This hinders test-time compute scaling that
relies on using the value-function for verification. In this work, we propose
RL$^V$ that augments any ``value-free'' RL method by jointly training the LLM
as both a reasoner and a generative verifier using RL-generated data, adding
verification capabilities without significant overhead. Empirically, RL$^V$
boosts MATH accuracy by over 20\% with parallel sampling and enables
$8-32\times$ efficient test-time compute scaling compared to the base RL
method. RL$^V$ also exhibits strong generalization capabilities for both
easy-to-hard and out-of-domain tasks. Furthermore, RL$^V$ achieves
$1.2-1.6\times$ higher performance when jointly scaling parallel and sequential
test-time compute with a long reasoning R1 model.

</details>


### [164] [Federated Learning for Cyber Physical Systems: A Comprehensive Survey](https://arxiv.org/abs/2505.04873)
*Minh K. Quan,Pubudu N. Pathirana,Mayuri Wijayasundara,Sujeeva Setunge,Dinh C. Nguyen,Christopher G. Brinton,David J. Love,H. Vincent Poor*

Main category: cs.LG

TL;DR: 该论文综述了联邦学习在信息物理系统 (FL-CPS) 中的最新进展，涵盖了应用领域、系统拓扑、算法以及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 将机器学习 (ML) 集成到信息物理系统 (CPS) 中面临实时决策、安全性、可靠性、设备异构性和数据隐私等挑战。联邦学习 (FL) 作为一种分布式方法，为解决这些问题提供了有前景的途径。

Method: 本文通过文献综述和分析，探讨了 FL 和 CPS 的最新进展及其融合，比较了 FL 在 CPS 与物联网 (IoT) 中的应用，审查了 FL 在智能交通、网络安全、智慧城市和智能医疗等关键 CPS 应用中的使用，并总结了实施经验。

Result: 论文提供了 FL-CPS 的全面概述，包括其在多个关键领域的应用实例、系统拓扑、相关算法，以及从各种 FL-CPS 实施中获得的见解和经验教训，并对比了其与物联网中 FL 应用的异同。

Conclusion: 论文总结了 FL-CPS 领域当前面临的主要问题，并为这个快速发展的动态领域未来的研究方向提出了建议。

Abstract: The integration of machine learning (ML) in cyber physical systems (CPS) is a
complex task due to the challenges that arise in terms of real-time decision
making, safety, reliability, device heterogeneity, and data privacy. There are
also open research questions that must be addressed in order to fully realize
the potential of ML in CPS. Federated learning (FL), a distributed approach to
ML, has become increasingly popular in recent years. It allows models to be
trained using data from decentralized sources. This approach has been gaining
popularity in the CPS field, as it integrates computer, communication, and
physical processes. Therefore, the purpose of this work is to provide a
comprehensive analysis of the most recent developments of FL-CPS, including the
numerous application areas, system topologies, and algorithms developed in
recent years. The paper starts by discussing recent advances in both FL and
CPS, followed by their integration. Then, the paper compares the application of
FL in CPS with its applications in the internet of things (IoT) in further
depth to show their connections and distinctions. Furthermore, the article
scrutinizes how FL is utilized in critical CPS applications, e.g., intelligent
transportation systems, cybersecurity services, smart cities, and smart
healthcare solutions. The study also includes critical insights and lessons
learned from various FL-CPS implementations. The paper's concluding section
delves into significant concerns and suggests avenues for further research in
this fast-paced and dynamic era.

</details>


### [165] [ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning](https://arxiv.org/abs/2505.04881)
*Ziqing Qiao,Yongheng Deng,Jiali Zeng,Dong Wang,Lai Wei,Fandong Meng,Jie Zhou,Ju Ren,Yaoxue Zhang*

Main category: cs.LG

TL;DR: 大型推理模型（LRMs）在链式思考（CoT）下输出冗长。ConCISE通过在推理时引导模型置信度，减少冗余输出，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）通过链式思考（CoT）进行复杂推理时，常产生冗余内容，导致输出冗长，增加计算开销并降低用户体验。现有压缩方法存在破坏推理连贯性或无法有效干预生成过程的问题。

Method: 研究识别了LRMs产生冗余的两种模式：置信度不足（模型因内部置信度低而重新考虑正确步骤）和终止延迟（达到高置信度答案后仍继续推理）。基于此，提出了ConCISE框架：通过在推理过程中增强模型置信度来简化推理链，防止冗余思考步骤的产生。它集成了置信度注入以稳定中间步骤，以及提前终止机制在置信度足够时结束推理。

Result: 在ConCISE生成的数据上微调LRMs，显著缩短了输出长度（在SimPO下最多减少约50%），同时保持了较高的任务准确率。ConCISE在多个推理基准测试中持续优于现有基线方法。

Conclusion: ConCISE通过引导模型置信度，有效地压缩了LRM的推理链，在不牺牲准确性的前提下，实现了更短、更高效的输出。

Abstract: Large Reasoning Models (LRMs) perform strongly in complex reasoning tasks via
Chain-of-Thought (CoT) prompting, but often suffer from verbose outputs caused
by redundant content, increasing computational overhead, and degrading user
experience. Existing compression methods either operate post-hoc pruning,
risking disruption to reasoning coherence, or rely on sampling-based selection,
which fails to intervene effectively during generation. In this work, we
introduce a confidence-guided perspective to explain the emergence of redundant
reflection in LRMs, identifying two key patterns: Confidence Deficit, where the
model reconsiders correct steps due to low internal confidence, and Termination
Delay, where reasoning continues even after reaching a confident answer. Based
on this analysis, we propose ConCISE (Confidence-guided Compression In
Step-by-step Efficient Reasoning), a framework that simplifies reasoning chains
by reinforcing the model's confidence during inference, thus preventing the
generation of redundant reflection steps. It integrates Confidence Injection to
stabilize intermediate steps and Early Stopping to terminate reasoning when
confidence is sufficient. Extensive experiments demonstrate that fine-tuning
LRMs on ConCISE-generated data yields significantly shorter outputs, reducing
length by up to approximately 50% under SimPO, while maintaining high task
accuracy. ConCISE consistently outperforms existing baselines across multiple
reasoning benchmarks.

</details>


### [166] [FedRE: Robust and Effective Federated Learning with Privacy Preference](https://arxiv.org/abs/2505.04889)
*Tianzhe Xiao,Yichen Li,Yu Zhou,Yining Qi,Yi Liu,Wei Wang,Haozhao Wang,Yi Wang,Ruixuan Li*

Main category: cs.LG

TL;DR: 针对联邦学习中LDP未考虑客户端对隐私敏感信息(PSI)的个性化偏好导致性能下降的问题，本文提出FedRE方法。该方法通过定义PSI、优化LDP预算分配和设计新的参数聚合机制，实现了LDP保护下的鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习中的本地差分隐私（LDP）方法对所有样本采用统一扰动，忽略了客户端对隐私敏感信息（PSI）的个性化偏好及其在数据中的非均匀分布。这导致对非敏感信息过度保护，引入不必要噪声，从而降低模型性能。

Method: 1. 根据每个客户端的隐私偏好定义隐私敏感信息（PSI）。2. 优化LDP：以分层方式为具有更高PSI的梯度分配更少的隐私预算，从而为PSI提供更严格的隐私保障。3. 设计一种基于扰动信息分布的参数聚合机制，以减轻LDP引起的性能下降。

Result: 在T-SROIE和DocTamper数据集上进行的文本篡改检测实验表明，FedRE与最先进的方法相比，取得了具有竞争力的性能。

Conclusion: FedRE通过关注数据中的PSI、优化LDP的隐私预算分配，并设计新的参数聚合机制，能够在为PSI提供严格隐私保护的同时，有效提升联邦学习模型的鲁棒性和性能。

Abstract: Despite Federated Learning (FL) employing gradient aggregation at the server
for distributed training to prevent the privacy leakage of raw data, private
information can still be divulged through the analysis of uploaded gradients
from clients. Substantial efforts have been made to integrate local
differential privacy (LDP) into the system to achieve a strict privacy
guarantee. However, existing methods fail to take practical issues into account
by merely perturbing each sample with the same mechanism while each client may
have their own privacy preferences on privacy-sensitive information (PSI),
which is not uniformly distributed across the raw data. In such a case,
excessive privacy protection from private-insensitive information can
additionally introduce unnecessary noise, which may degrade the model
performance. In this work, we study the PSI within data and develop FedRE, that
can simultaneously achieve robustness and effectiveness benefits with LDP
protection. More specifically, we first define PSI with regard to the privacy
preferences of each client. Then, we optimize the LDP by allocating less
privacy budget to gradients with higher PSI in a layer-wise manner, thus
providing a stricter privacy guarantee for PSI. Furthermore, to mitigate the
performance degradation caused by LDP, we design a parameter aggregation
mechanism based on the distribution of the perturbed information. We conducted
experiments with text tamper detection on T-SROIE and DocTamper datasets, and
FedRE achieves competitive performance compared to state-of-the-art methods.

</details>


### [167] [Clustering with Communication: A Variational Framework for Single Cell Representation Learning](https://arxiv.org/abs/2505.04891)
*Cong Qi,Yeqing Chen,Jie Zhang,Wei Zhi*

Main category: cs.LG

TL;DR: 提出了一种名为CCCVAE的新型变分自动编码器框架，它将细胞间通讯(CCC)信号整合到单细胞表征学习中，从而提高了聚类性能。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序(scRNA-seq)揭示了细胞异质性，但理解生物功能还需考虑细胞间通讯(CCC)。现有工具已证明CCC的重要性，且转录组数据包含此类信息。传统VAE独立处理细胞，未考虑细胞间信号背景。

Method: 提出了CCCVAE框架，一种新颖的变分自动编码器。它利用源自配体-受体相互作用的通讯感知核和稀疏高斯过程，将CCC信号整合进单细胞表征学习，从而将生物学先验编码到潜空间，使潜空间嵌入能同时反映转录相似性和细胞间信号传导环境。

Result: 在四个scRNA-seq数据集上的实验结果表明，CCCVAE相较于标准的VAE基线模型，显著提高了聚类性能，并取得了更高的评估分数。

Conclusion: 该研究证明了将生物学先验（如细胞间通讯）嵌入到深度生成模型中对于无监督单细胞分析具有重要价值，CCCVAE有效地展示了这一点。

Abstract: Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular
heterogeneity, but recent studies emphasize that understanding biological
function also requires modeling cell-cell communication (CCC), the signaling
interactions mediated by ligand-receptor pairs that coordinate cellular
behavior. Tools like CellChat have demonstrated that CCC plays a critical role
in processes such as cell differentiation, tissue regeneration, and immune
response, and that transcriptomic data inherently encodes rich information
about intercellular signaling. We propose CCCVAE, a novel variational
autoencoder framework that incorporates CCC signals into single-cell
representation learning. By leveraging a communication-aware kernel derived
from ligand-receptor interactions and a sparse Gaussian process, CCCVAE encodes
biologically informed priors into the latent space. Unlike conventional VAEs
that treat each cell independently, CCCVAE encourages latent embeddings to
reflect both transcriptional similarity and intercellular signaling context.
Empirical results across four scRNA-seq datasets show that CCCVAE improves
clustering performance, achieving higher evaluation scores than standard VAE
baselines. This work demonstrates the value of embedding biological priors into
deep generative models for unsupervised single-cell analysis.

</details>


### [168] [GCN-Based Throughput-Oriented Handover Management in Dense 5G Vehicular Networks](https://arxiv.org/abs/2505.04894)
*Nazanin Mehregan,Robson E. De Grande*

Main category: cs.LG

TL;DR: 本文提出了一种名为TH-GCN的新方法，利用图神经网络优化密集5G网络中的切换管理，以提高网络稳定性。


<details>
  <summary>Details</summary>
Motivation: 5G网络在车载应用中虽有优势，但其覆盖范围有限和频繁切换（尤其是在高速移动环境中的乒乓效应）导致网络不稳定。

Method: 提出了TH-GCN（面向吞吐量的图卷积网络）方法。该方法使用图神经网络（GNN），将车辆和基站建模为动态图中的节点，节点特征包括信号质量、吞吐量、车速和基站负载。它采用用户设备和基站双中心视角进行自适应实时切换决策。

Result: 仿真结果表明，TH-GCN方法能将切换次数减少高达78%，并将信号质量提高10%，优于现有方法。

Conclusion: TH-GCN是一种有效优化密集5G网络中切换管理的方法，能够显著提高网络稳定性并改善用户体验。

Abstract: The rapid advancement of 5G has transformed vehicular networks, offering high
bandwidth, low latency, and fast data rates essential for real-time
applications in smart cities and vehicles. These improvements enhance traffic
safety and entertainment services. However, the limited coverage and frequent
handovers in 5G networks cause network instability, especially in high-mobility
environments due to the ping-pong effect. This paper presents TH-GCN
(Throughput-oriented Graph Convolutional Network), a novel approach for
optimizing handover management in dense 5G networks. Using graph neural
networks (GNNs), TH-GCN models vehicles and base stations as nodes in a dynamic
graph enriched with features such as signal quality, throughput, vehicle speed,
and base station load. By integrating both user equipment and base station
perspectives, this dual-centric approach enables adaptive, real-time handover
decisions that improve network stability. Simulation results show that TH-GCN
reduces handovers by up to 78 percent and improves signal quality by 10
percent, outperforming existing methods.

</details>


### [169] [Precise gradient descent training dynamics for finite-width multi-layer neural networks](https://arxiv.org/abs/2505.04898)
*Qiyang Han,Masaaki Imaizumi*

Main category: cs.LG

TL;DR: 本文首次精确刻画了在有限宽度比例机制下，通用多层神经网络梯度下降迭代的分布特性，适用于非高斯特征，并能捕捉权重动态。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络理论多基于无限宽度、惰性训练或特定初始化假设，且对多层网络的泛化分析不足。本研究旨在为更实际的有限宽度、非惰性训练的多层网络提供普适的梯度下降理论。

Method: 提出了一种非渐近状态演化理论，用于分析在样本量与特征维度成比例增长、网络宽度深度有界情况下的多层神经网络梯度下降过程，捕捉了第一层权重的高斯波动和深层权重的集中现象。

Result: 1. 建立了有限宽度多层神经网络梯度下降迭代的精确分布特征。
2. 证明了梯度下降可用于一致估计泛化误差，指导早停和超参数调整。
3. 揭示了即使模型设定错误，梯度下降学习的模型仍保持单指数函数结构，其有效信号由真实信号和初始化共同决定。

Conclusion: 本研究提出的状态演化理论为理解有限宽度多层神经网络的梯度下降动态提供了新工具，克服了现有理论的局限，并展示了其在泛化误差估计和模型结构理解方面的应用潜力。

Abstract: In this paper, we provide the first precise distributional characterization
of gradient descent iterates for general multi-layer neural networks under the
canonical single-index regression model, in the `finite-width proportional
regime' where the sample size and feature dimension grow proportionally while
the network width and depth remain bounded. Our non-asymptotic state evolution
theory captures Gaussian fluctuations in first-layer weights and concentration
in deeper-layer weights, and remains valid for non-Gaussian features.
  Our theory differs from existing neural tangent kernel (NTK), mean-field (MF)
theories and tensor program (TP) in several key aspects. First, our theory
operates in the finite-width regime whereas these existing theories are
fundamentally infinite-width. Second, our theory allows weights to evolve from
individual initializations beyond the lazy training regime, whereas NTK and MF
are either frozen at or only weakly sensitive to initialization, and TP relies
on special initialization schemes. Third, our theory characterizes both
training and generalization errors for general multi-layer neural networks
beyond the uniform convergence regime, whereas existing theories study
generalization almost exclusively in two-layer settings.
  As a statistical application, we show that vanilla gradient descent can be
augmented to yield consistent estimates of the generalization error at each
iteration, which can be used to guide early stopping and hyperparameter tuning.
As a further theoretical implication, we show that despite model
misspecification, the model learned by gradient descent retains the structure
of a single-index function with an effective signal determined by a linear
combination of the true signal and the initialization.

</details>


### [170] [VaCDA: Variational Contrastive Alignment-based Scalable Human Activity Recognition](https://arxiv.org/abs/2505.04907)
*Soham Khisa,Avijoy Chakma*

Main category: cs.LG

TL;DR: 该研究提出了一种名为VaCDA的多源域自适应框架，结合变分自编码器（VAE）和对比学习，以解决可穿戴设备传感器数据异构性问题，提高日常活动识别的性能。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备产生大量未标记数据，解读困难且手动标注成本高、易出错。由于设备位置、类型和用户行为的差异，数据分布通常是异构的，导致传统迁移学习方法在日常活动识别方面表现不佳。

Method: 使用变分自编码器（VAE）从传感器数据中学习共享的低维潜在空间，以泛化不同传感器的数据并减轻异构性。整合对比学习，通过对齐跨域的同类实例同时分离不同类别来增强特征表示。提出了变分对比域自适应（VaCDA）框架，结合VAE和对比学习。

Result: VaCDA在多个公开数据集上，针对跨人、跨位置和跨设备三种异构场景进行了评估。在跨位置和跨设备场景中，VaCDA的表现优于基线模型。

Conclusion: VaCDA框架通过结合VAE和对比学习，能够有效改进特征表示，减少源域和目标域之间的异构性，从而在跨位置和跨设备等异构场景中提升日常活动识别的准确率。

Abstract: Technological advancements have led to the rise of wearable devices with
sensors that continuously monitor user activities, generating vast amounts of
unlabeled data. This data is challenging to interpret, and manual annotation is
labor-intensive and error-prone. Additionally, data distribution is often
heterogeneous due to device placement, type, and user behavior variations. As a
result, traditional transfer learning methods perform suboptimally, making it
difficult to recognize daily activities. To address these challenges, we use a
variational autoencoder (VAE) to learn a shared, low-dimensional latent space
from available sensor data. This space generalizes data across diverse sensors,
mitigating heterogeneity and aiding robust adaptation to the target domain. We
integrate contrastive learning to enhance feature representation by aligning
instances of the same class across domains while separating different classes.
We propose Variational Contrastive Domain Adaptation (VaCDA), a multi-source
domain adaptation framework combining VAEs and contrastive learning to improve
feature representation and reduce heterogeneity between source and target
domains. We evaluate VaCDA on multiple publicly available datasets across three
heterogeneity scenarios: cross-person, cross-position, and cross-device. VaCDA
outperforms the baselines in cross-position and cross-device scenarios.

</details>


### [171] [Physics-Assisted and Topology-Informed Deep Learning for Weather Prediction](https://arxiv.org/abs/2505.04918)
*Jiaqi Zheng,Qing Ling,Yerong Feng*

Main category: cs.LG

TL;DR: 提出了一种名为PASSAT的新型深度学习天气预报模型，该模型同时考虑了物理规律和地球拓扑结构，在ERA5数据集上表现优于现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习天气预报模型大多忽略了天气演变过程中的物理规律或地球表面的拓扑结构，导致预测精度受限。

Method: 开发了PASSAT模型：1. 将天气演变归因于平流过程（用平流方程和纳维-斯托克斯方程描述）和地球-大气相互作用。2. 在球形流形上数值求解平流方程和纳维-斯托克斯方程。3. 使用球形图神经网络捕捉地球-大气相互作用，并生成解平流方程所需的初始速度场。

Result: 在5.625°分辨率的ERA5数据集上，PASSAT模型的性能超越了当前最先进的基于深度学习的天气预报模型以及业务数值天气预报模型IFS T42。

Conclusion: PASSAT模型通过整合物理学原理和地球拓扑结构，为天气预报提供了一种更准确有效的方法，优于现有模型。

Abstract: Although deep learning models have demonstrated remarkable potential in
weather prediction, most of them overlook either the \textbf{physics} of the
underlying weather evolution or the \textbf{topology} of the Earth's surface.
In light of these disadvantages, we develop PASSAT, a novel Physics-ASSisted
And Topology-informed deep learning model for weather prediction. PASSAT
attributes the weather evolution to two key factors: (i) the advection process
that can be characterized by the advection equation and the Navier-Stokes
equation; (ii) the Earth-atmosphere interaction that is difficult to both model
and calculate. PASSAT also takes the topology of the Earth's surface into
consideration, other than simply treating it as a plane. With these
considerations, PASSAT numerically solves the advection equation and the
Navier-Stokes equation on the spherical manifold, utilizes a spherical graph
neural network to capture the Earth-atmosphere interaction, and generates the
initial velocity fields that are critical to solving the advection equation
from the same spherical graph neural network. In the $5.625^\circ$-resolution
ERA5 data set, PASSAT outperforms both the state-of-the-art deep learning-based
weather prediction models and the operational numerical weather prediction
model IFS T42. Code and checkpoint are available at
https://github.com/Yumenomae/PASSAT_5p625.

</details>


### [172] [Fair Uncertainty Quantification for Depression Prediction](https://arxiv.org/abs/2505.04931)
*Yonghong Li,Xiuzhuang Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一种公平不确定性量化 (FUQ) 方法，用于抑郁症预测，旨在通过基于群组的共形预测和公平性感知优化策略，实现跨不同人口群体的可靠且公平的预测。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的可靠且公平的抑郁症预测对临床应用至关重要。尽管不确定性量化 (UQ) 在提高预测可靠性方面受到关注，但其在抑郁症预测中的公平性，特别是在不同人口统计群体间的公平性，尚未得到充分研究。

Method: 研究提出了公平不确定性量化 (FUQ) 方法。首先，根据敏感属性对参与者进行分组，并利用共形预测在各组内量化不确定性。其次，提出一种公平性感知优化策略，将公平性（机会均等覆盖率 EOC）构建为一个约束优化问题，使模型在保持预测可靠性的同时适应不同群体的异质不确定性水平，以实现最佳公平性。

Result: 在多个视觉和听觉抑郁症数据集上进行的大量评估表明，所提出的 FUQ 方法是有效的。

Conclusion: FUQ 方法通过结合基于群组的共形预测和公平性感知优化，能够有效地实现可靠且公平的抑郁症预测，解决了现有方法在抑郁症预测中不确定性量化公平性方面的不足。

Abstract: Trustworthy depression prediction based on deep learning, incorporating both
predictive reliability and algorithmic fairness across diverse demographic
groups, is crucial for clinical application. Recently, achieving reliable
depression predictions through uncertainty quantification has attracted
increasing attention. However, few studies have focused on the fairness of
uncertainty quantification (UQ) in depression prediction. In this work, we
investigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage
(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for
depression prediction. FUQ pursues reliable and fair depression predictions
through group-based analysis. Specifically, we first group all the participants
by different sensitive attributes and leverage conformal prediction to quantify
uncertainty within each demographic group, which provides a theoretically
guaranteed and valid way to quantify uncertainty for depression prediction and
facilitates the investigation of fairness across different demographic groups.
Furthermore, we propose a fairness-aware optimization strategy that formulates
fairness as a constrained optimization problem under EOC constraints. This
enables the model to preserve predictive reliability while adapting to the
heterogeneous uncertainty levels across demographic groups, thereby achieving
optimal fairness. Through extensive evaluations on several visual and audio
depression datasets, our approach demonstrates its effectiveness.

</details>


### [173] [Structural Alignment in Link Prediction](https://arxiv.org/abs/2505.04939)
*Jeffrey Seathrún Sardina*

Main category: cs.LG

TL;DR: 本文提出了一种从“结构优先”的角度看待知识图谱（KG）链接预测的新方法，强调以完整三元组而非单个节点/边来建模信息，并证明了这种方法的可行性及其在理解KG学习和实现跨KG迁移学习方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现实世界的知识图谱（KGs）普遍存在不完整性。当前主流的链接预测方法大多基于嵌入范式，即通过节点和边的向量表示来预测缺失信息。本研究旨在探索一种替代的视角来处理链接预测和知识图谱数据建模。

Method: 本研究从图结构优先的角度重新分析了知识图谱和现有的链接预测器，将知识图谱的信息内容建模为完整的三元组，而非孤立的节点和边。通过文献综述和两组核心实验来验证这一观点，并提出了“结构对齐假说”（Structural Alignment Hypothesis）。

Result: 研究结果表明，从结构优先的角度看待知识图谱和链接预测是可行且有用的。这种视角有助于理解知识图谱学习过程，并能促进链接预测任务中的跨知识图谱迁移学习。基于此观察，提出了“结构对齐假说”，即链接预测可以被理解和建模为一个结构性任务。

Conclusion: 结论是，采用“结构优先”的视角对知识图谱和链接预测任务进行研究，不仅可行，而且对于理解知识图谱学习和实现跨知识图谱的迁移学习具有重要价值。链接预测本质上可以被视为一个结构性任务。

Abstract: While Knowledge Graphs (KGs) have become increasingly popular across various
scientific disciplines for their ability to model and interlink huge quantities
of data, essentially all real-world KGs are known to be incomplete. As such,
with the growth of KG use has been a concurrent development of machine learning
tools designed to predict missing information in KGs, which is referred to as
the Link Prediction Task. The majority of state-of-the-art link predictors to
date have followed an embedding-based paradigm. In this paradigm, it is assumed
that the information content of a KG is best represented by the (individual)
vector representations of its nodes and edges, and that therefore node and edge
embeddings are particularly well-suited to performing link prediction.
  This thesis proposes an alternative perspective on the field's approach to
link prediction and KG data modelling. Specifically, this work re-analyses KGs
and state-of-the-art link predictors from a graph-structure-first perspective
that models the information content of a KG in terms of whole triples, rather
than individual nodes and edges.
  Following a literature review and two core sets of experiments, this thesis
concludes that a structure-first perspective on KGs and link prediction is both
viable and useful for understanding KG learning and for enabling cross-KG
transfer learning for the link prediction task. This observation is used to
create and propose the Structural Alignment Hypothesis, which postulates that
link prediction can be understood and modelled as a structural task.
  All code and data used for this thesis are open-sourced. This thesis was
written bilingually, with the main document in English and an informal extended
summary in Irish. An Irish-language translation dictionary of machine learning
terms (the Focl\'oir Tr\'achtais) created for this work is open-sourced as
well.

</details>


### [174] [Graffe: Graph Representation Learning via Diffusion Probabilistic Models](https://arxiv.org/abs/2505.04956)
*Dingshuo Chen,Shuchen Xue,Liuji Chen,Yingheng Wang,Qiang Liu,Shu Wu,Zhi-Ming Ma,Liang Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Graffe的自监督扩散模型，用于图表示学习，并在多个图数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 扩散概率模型（DPMs）在生成高质量样本方面表现出色，但在表示学习领域，尤其是在图表示学习方面的应用尚不成熟，潜力未被充分挖掘。

Method: 提出了Graffe模型，一个自监督的图扩散模型。它使用图编码器将源图提取为紧凑表示，该表示作为条件引导扩散解码器的去噪过程。同时，从理论上证明了去噪目标能隐式最大化数据与其表示之间的条件互信息。

Result: Graffe模型在节点分类和图分类任务的线性评估设置下取得了有竞争力的结果，在11个真实世界数据集中的9个上达到了最先进水平。理论分析也通过案例研究得到了验证。

Conclusion: 研究表明，包括扩散模型在内的强大生成模型可以作为图表示学习的有效工具。

Abstract: Diffusion probabilistic models (DPMs), widely recognized for their potential
to generate high-quality samples, tend to go unnoticed in representation
learning. While recent progress has highlighted their potential for capturing
visual semantics, adapting DPMs to graph representation learning remains in its
infancy. In this paper, we introduce Graffe, a self-supervised diffusion model
proposed for graph representation learning. It features a graph encoder that
distills a source graph into a compact representation, which, in turn, serves
as the condition to guide the denoising process of the diffusion decoder. To
evaluate the effectiveness of our model, we first explore the theoretical
foundations of applying diffusion models to representation learning, proving
that the denoising objective implicitly maximizes the conditional mutual
information between data and its representation. Specifically, we prove that
the negative logarithm of the denoising score matching loss is a tractable
lower bound for the conditional mutual information. Empirically, we conduct a
series of case studies to validate our theoretical insights. In addition,
Graffe delivers competitive results under the linear probing setting on node
and graph classification tasks, achieving state-of-the-art performance on 9 of
the 11 real-world datasets. These findings indicate that powerful generative
models, especially diffusion models, serve as an effective tool for graph
representation learning.

</details>


### [175] [General Transform: A Unified Framework for Adaptive Transform to Enhance Representations](https://arxiv.org/abs/2505.04969)
*Gekko Budiutama,Shunsuke Daimon,Hirofumi Nishi,Yu-ichiro Matsushita*

Main category: cs.LG

TL;DR: 提出了一种名为通用变换（GT）的自适应变换方法，用于机器学习，它能根据数据和任务学习映射，优于传统变换。


<details>
  <summary>Details</summary>
Motivation: 传统离散变换在机器学习中应用广泛，但选择合适的变换依赖于对数据集的先验知识，缺乏这种知识时效果不佳。

Method: 提出通用变换（GT），一种自适应的、基于变换的表示方法，它能够学习针对特定数据集和任务的数据驱动映射。

Result: 实验表明，集成GT的模型在计算机视觉和自然语言处理任务中均优于传统的基于变换的方法。

Conclusion: GT是一种有效的自适应变换方法，能够在多种学习场景中提升模型性能，克服了传统变换选择的局限性。

Abstract: Discrete transforms, such as the discrete Fourier transform, are widely used
in machine learning to improve model performance by extracting meaningful
features. However, with numerous transforms available, selecting an appropriate
one often depends on understanding the dataset's properties, making the
approach less effective when such knowledge is unavailable. In this work, we
propose General Transform (GT), an adaptive transform-based representation
designed for machine learning applications. Unlike conventional transforms, GT
learns data-driven mapping tailored to the dataset and task of interest. Here,
we demonstrate that models incorporating GT outperform conventional
transform-based approaches across computer vision and natural language
processing tasks, highlighting its effectiveness in diverse learning scenarios.

</details>


### [176] [Graph Neural Network Aided Deep Reinforcement Learning for Resource Allocation in Dynamic Terahertz UAV Networks](https://arxiv.org/abs/2505.04981)
*Zhifeng Hu,Chong Han*

Main category: cs.LG

TL;DR: 提出了一种基于图神经网络辅助的深度强化学习算法GLOVE，用于太赫兹无人机网络中的动态资源分配，旨在最大化资源效率。


<details>
  <summary>Details</summary>
Motivation: 太赫兹无人机网络因其动态拓扑和资源（功率为连续变量，天线为离散变量）分配的混合整数非线性规划（MINLP）问题（非凸且NP难），导致难以实现高效的长期联合功率与天线阵列资源分配。

Method: 提出了一种名为GLOVE的图神经网络（GNN）辅助的深度强化学习（DRL）算法。该算法通过GNN学习无人机与其邻居无人机之间的关系，同时强调自身节点特征，并利用多任务结构协同训练功率和子阵列的资源分配决策。

Result: 实验结果表明，GLOVE在资源效率（RE）和延迟方面均优于基准方案。特别地，GLOVE在整个训练过程中实现了零丢包，表现出在高度动态的太赫兹无人机网络下更好的鲁棒性。

Conclusion: GLOVE算法能够有效解决太赫兹无人机网络中的动态资源分配问题，显著提升了资源效率和网络鲁棒性，并降低了通信延迟。

Abstract: Terahertz (THz) unmanned aerial vehicle (UAV) networks with flexible
topologies and ultra-high data rates are expected to empower numerous
applications in security surveillance, disaster response, and environmental
monitoring, among others. However, the dynamic topologies hinder the efficient
long-term joint power and antenna array resource allocation for THz links among
UAVs. Furthermore, the continuous nature of power and the discrete nature of
antennas cause this joint resource allocation problem to be a mixed-integer
nonlinear programming (MINLP) problem with non-convexity and NP-hardness.
Inspired by recent rapid advancements in deep reinforcement learning (DRL), a
graph neural network (GNN) aided DRL algorithm for resource allocation in the
dynamic THz UAV network with an emphasis on self-node features (GLOVE) is
proposed in this paper, with the aim of resource efficiency (RE) maximization.
When training the allocation policy for each UAV, GLOVE learns the relationship
between this UAV and its neighboring UAVs via GNN, while also emphasizing the
important self-node features of this UAV. In addition, a multi-task structure
is leveraged by GLOVE to cooperatively train resource allocation decisions for
the power and sub-arrays of all UAVs. Experimental results illustrate that
GLOVE outperforms benchmark schemes in terms of the highest RE and the lowest
latency. Moreover, unlike the benchmark methods with severe packet loss, GLOVE
maintains zero packet loss during the entire training process, demonstrating
its better robustness under the highly dynamic THz UAV network.

</details>


### [177] [An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication](https://arxiv.org/abs/2505.05015)
*Roberto Dillon,Arushi*

Main category: cs.LG

TL;DR: 研究通过模拟键盘输入行为，发现随机森林模型在同一键盘上识别用户效果好，但跨键盘识别能力差，表明键盘类型对认证有显著影响。


<details>
  <summary>Details</summary>
Motivation: 评估自由文本键盘动态作为一种透明、无扰的连续认证方法的有效性，以增强多因素认证的安全性。

Method: 使用基于代理的模型(ABM)模拟机械键盘和薄膜键盘上的多样化打字配置文件，生成包含驻留时间、飞行时间和错误率特征的合成按键数据。采用一类支持向量机(OC-SVM)和随机森林(RF)两种机器学习方法进行用户验证。

Result: 一类支持向量机(OC-SVM)未能区分用户。随机森林(RF)在同一键盘内实现了稳健的用户识别（准确率 > 0.7），但在同一用户跨不同键盘进行识别时泛化能力较差，突显了键盘硬件对打字行为的显著影响。

Conclusion: 研究表明：(1) 可靠的认证可能需要针对特定键盘的用户配置文件；(2) 像随机森林这样的集成方法在捕获细粒度的用户特定打字模式方面优于一类支持向量机。

Abstract: Continuous authentication systems leveraging free-text keyboard dynamics
offer a promising additional layer of security in a multifactor authentication
setup that can be used in a transparent way with no impact on user experience.
This study investigates the efficacy of behavioral biometrics by employing an
Agent-Based Model (ABM) to simulate diverse typing profiles across mechanical
and membrane keyboards. Specifically, we generated synthetic keystroke data
from five unique agents, capturing features related to dwell time, flight time,
and error rates within sliding 5-second windows updated every second. Two
machine learning approaches, One-Class Support Vector Machine (OC-SVM) and
Random Forest (RF), were evaluated for user verification. Results revealed a
stark contrast in performance: while One-Class SVM failed to differentiate
individual users within each group, Random Forest achieved robust
intra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize
across keyboards for the same user, highlighting the significant impact of
keyboard hardware on typing behavior. These findings suggest that: (1)
keyboard-specific user profiles may be necessary for reliable authentication,
and (2) ensemble methods like RF outperform One-Class SVM in capturing
fine-grained user-specific patterns.

</details>


### [178] [Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints](https://arxiv.org/abs/2505.05019)
*Waldemar Hahn,Jan-Niklas Eckardt,Christoph Röllig,Martin Sedlmayr,Jan Moritz Middeke,Markus Wolfien*

Main category: cs.LG

TL;DR: 该研究评估了超参数优化（HPO）策略对生成合成临床试验数据质量的影响，发现HPO能提升数据质量，但需结合领域知识和预处理/后处理才能确保临床有效性。


<details>
  <summary>Details</summary>
Motivation: 生成合成临床试验数据是解决医学研究中隐私问题和数据可访问性限制的一种有前景的方法，但确保合成数据集的高保真度、实用性和领域约束依从性仍是关键挑战。超参数优化（HPO）已被证明能提高生成模型性能，但不同优化策略在合成临床数据上的有效性尚不明确。

Method: 本研究系统评估了四种超参数优化（HPO）策略在八种生成模型上的表现，比较了单一度量优化与复合度量优化方法。

Result: HPO一致性地改善了合成数据质量，其中TVAE、CTGAN和CTAB-GAN+的改进分别高达60%、39%和38%。复合度量优化优于单一度量策略，能产生更均衡和泛化能力更强的合成数据集。然而，仅HPO不足以确保临床有效的合成数据，所有模型都表现出对基本生存约束的违反。预处理和后处理在减少这些违规行为方面起着至关重要的作用。

Conclusion: 将显式领域知识与HPO相结合对于创建高质量合成数据集至关重要。本研究为改进合成数据生成提供了可操作的建议，未来研究需要改进度量选择并在更大数据集上验证这些发现，以增强临床适用性。

Abstract: The generation of synthetic clinical trial data offers a promising approach
to mitigating privacy concerns and data accessibility limitations in medical
research. However, ensuring that synthetic datasets maintain high fidelity,
utility, and adherence to domain-specific constraints remains a key challenge.
While hyperparameter optimization (HPO) has been shown to improve generative
model performance, the effectiveness of different optimization strategies for
synthetic clinical data remains unclear. This study systematically evaluates
four HPO strategies across eight generative models, comparing single-metric
optimization against compound metric optimization approaches. Our results
demonstrate that HPO consistently improves synthetic data quality, with TVAE,
CTGAN, and CTAB-GAN+ achieving improvements of up to 60%, 39%, and 38%,
respectively. Compound metric optimization outperformed single-metric
strategies, producing more balanced and generalizable synthetic datasets.
Interestingly, HPO alone is insufficient to ensure clinically valid synthetic
data, as all models exhibited violations of fundamental survival constraints.
Preprocessing and postprocessing played a crucial role in reducing these
violations, as models lacking robust processing steps produced invalid data in
up to 61% of cases. These findings underscore the necessity of integrating
explicit domain knowledge alongside HPO to create high quality synthetic
datasets. Our study provides actionable recommendations for improving synthetic
data generation, with future research needed to refine metric selection and
validate these findings on larger datasets to enhance clinical applicability.

</details>


### [179] [Generative Models for Long Time Series: Approximately Equivariant Recurrent Network Structures for an Adjusted Training Scheme](https://arxiv.org/abs/2505.05020)
*Ruwen Fulek,Markus Lange-Hegermann*

Main category: cs.LG

TL;DR: 本文提出了一种名为RVAE-ST的简单有效的时序数据生成模型，该模型基于循环变分自编码器，并通过逐步增加序列长度的适应性训练方案来有效建模长序列。


<details>
  <summary>Details</summary>
Motivation: 解决循环神经网络在建模长序列时面临的挑战，并提高对长期时间依赖性的建模能力。

Method: 采用一种带有循环层的变分自编码器（RVAE），并引入一种适应性训练方案（后续训练，ST），该方案逐步增加训练过程中的序列长度。这种设计保持了模型参数数量不随序列长度变化，并鼓励近似时间平移等变性。

Result: 该模型（RVAE-ST）在多个基准数据集上达到或超过了当前最先进的生成模型性能，尤其在具有准周期结构的时间序列上表现出色，同时在不规则或部分非平稳数据集上也具有竞争力。通过ELBO、弗雷歇距离、判别分数和学习嵌入的可视化评估了其性能。

Conclusion: 通过精心组合已知组件，RVAE-ST证明了一个简单有效的模型可以在时间序列生成任务上取得优异表现，特别擅长处理长序列和具有准周期性的数据。

Abstract: We present a simple yet effective generative model for time series data based
on a Variational Autoencoder (VAE) with recurrent layers, referred to as the
Recurrent Variational Autoencoder with Subsequent Training (RVAE-ST). Our
method introduces an adapted training scheme that progressively increases the
sequence length, addressing the challenge recurrent layers typically face when
modeling long sequences. By leveraging the recurrent architecture, the model
maintains a constant number of parameters regardless of sequence length. This
design encourages approximate time-shift equivariance and enables efficient
modeling of long-range temporal dependencies. Rather than introducing a
fundamentally new architecture, we show that a carefully composed combination
of known components can match or outperform state-of-the-art generative models
on several benchmark datasets. Our model performs particularly well on time
series that exhibit quasi-periodic structure,while remaining competitive on
datasets with more irregular or partially non-stationary behavior. We evaluate
its performance using ELBO, Fr\'echet Distance, discriminative scores, and
visualizations of the learned embeddings.

</details>


### [180] [Dequantified Diffusion Schrödinger Bridge for Density Ratio Estimation](https://arxiv.org/abs/2505.05034)
*Wei Chen,Shigui Li,Jiacheng Li,Junmei Yang,John Paisley,Delu Zeng*

Main category: cs.LG

TL;DR: 提出了D³RE框架，通过DDBI和DSBI插值方法，解决了密度比估计中的密度鸿沟、支撑集鸿沟及边界不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有密度比估计方法在处理分布差异显著或支撑集重叠不足时存在“密度鸿沟”和“支撑集鸿沟”问题，且边界附近的时间分数发散导致估计不稳定。

Method: 提出了名为D³RE的统一框架：首先引入去量化扩散桥插值（DDBI），通过扩散桥和高斯去量化扩展支撑集覆盖并稳定时间分数；然后在此基础上构建去量化薛定谔桥插值（DSBI），结合最优传输解决薛定谔桥问题，以提高准确性和效率。

Result: 理论上，该方法能够提供一致的近似保证和有界的时间分数。实验结果显示，在互信息估计和密度估计任务中，D³RE的表现优于现有的基线方法。

Conclusion: D³RE是一个鲁棒且高效的密度比估计统一框架，有效克服了现有方法在面对分布差异大和支撑集不重叠等情况下的局限性。

Abstract: Density ratio estimation is fundamental to tasks involving $f$-divergences,
yet existing methods often fail under significantly different distributions or
inadequately overlap supports, suffering from the \textit{density-chasm} and
the \textit{support-chasm} problems. Additionally, prior approaches yield
divergent time scores near boundaries, leading to instability. We propose
$\text{D}^3\text{RE}$, a unified framework for robust and efficient density
ratio estimation. It introduces the Dequantified Diffusion-Bridge Interpolant
(DDBI), which expands support coverage and stabilizes time scores via diffusion
bridges and Gaussian dequantization. Building on DDBI, the Dequantified
Schr\"odinger-Bridge Interpolant (DSBI) incorporates optimal transport to solve
the Schr\"odinger bridge problem, enhancing accuracy and efficiency. Our method
offers uniform approximation and bounded time scores in theory, and outperforms
baselines empirically in mutual information and density estimation tasks.

</details>


### [181] [Neural Pathways to Program Success: Hopfield Networks for PERT Analysis](https://arxiv.org/abs/2505.05047)
*Azgar Ali Noor Ahamed*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的将PERT项目调度问题表述为霍普菲尔德神经网络中的能量最小化问题的方法，以应对不确定性下的任务调度。


<details>
  <summary>Details</summary>
Motivation: 在项目管理中，不确定性下的项目和任务调度是一个根本性挑战，准确估计任务持续时间和依赖关系对于交付复杂的多项目系统至关重要。

Method: 将任务开始时间和优先约束映射到霍普菲尔德神经网络计算框架中，利用网络固有的优化动态来近似全局一致的调度方案，并解决了能量函数可微性、约束编码和收敛等理论问题。

Result: 在多达1000个任务的合成项目网络上的数值模拟表明，该方法能够实现接近最优的总工期，且约束违反最小。

Conclusion: 神经优化模型为不确定性下可扩展和自适应的项目任务调度提供了一个有前景的方向，尤其适用于智能体AI工作流和微服务等现代AI系统构建领域。

Abstract: Project and task scheduling under uncertainty remains a fundamental challenge
in program and project management, where accurate estimation of task durations
and dependencies is critical for delivering complex, multi project systems. The
Program Evaluation and Review Technique provides a probabilistic framework to
model task variability and critical paths. In this paper, the author presents a
novel formulation of PERT scheduling as an energy minimization problem within a
Hopfield neural network architecture. By mapping task start times and
precedence constraints into a neural computation framework, the networks
inherent optimization dynamics is exploited to approximate globally consistent
schedules. The author addresses key theoretical issues related to energy
function differentiability, constraint encoding, and convergence, and extends
the Hopfield model for structured precedence graphs. Numerical simulations on
synthetic project networks comprising up to 1000 tasks demonstrate the
viability of this approach, achieving near optimal makespans with minimal
constraint violations. The findings suggest that neural optimization models
offer a promising direction for scalable and adaptive project tasks scheduling
under uncertainty in areas such as the agentic AI workflows, microservice based
applications that the modern AI systems are being built upon.

</details>


### [182] [CodeMixBench: Evaluating Large Language Models on Code Generation with Code-Mixed Prompts](https://arxiv.org/abs/2505.05063)
*Manik Sheokand,Parth Sawant*

Main category: cs.LG

TL;DR: 本研究针对现有代码生成基准仅限英文的不足，提出了CodeMixBench，一个评估大语言模型处理代码混合（如中英夹杂）提示词鲁棒性的新基准。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型代码生成基准（如HumanEval, MBPP, BigCodeBench）主要评估模型在纯英文提示词下的表现，忽略了现实世界中多语言开发者经常使用代码混合语言与模型交互的场景。

Method: 研究者们基于BigCodeBench构建了CodeMixBench。他们将受控的代码混合（CMD）引入到提示词的自然语言部分，涵盖了三种语言对：印地语-英语（Hinglish）、西班牙语-英语和中文拼音-英语。然后，他们全面评估了一系列参数量从1.5B到15B不等的开源代码生成模型。

Result: 实验结果表明，与纯英文提示词相比，代码混合提示词普遍导致Pass@1性能下降。对于参数量较小的模型，在代码混合程度较高时，性能下降更为显著。

Conclusion: CodeMixBench为研究多语言代码生成提供了一个现实的评估框架，并揭示了构建能够在不同语言环境下表现良好的鲁棒代码生成模型所面临的新挑战和未来方向。

Abstract: Large Language Models (LLMs) have achieved remarkable success in code
generation tasks, powering various applications like code completion,
debugging, and programming assistance. However, existing benchmarks such as
HumanEval, MBPP, and BigCodeBench primarily evaluate LLMs on English-only
prompts, overlooking the real-world scenario where multilingual developers
often use code-mixed language while interacting with LLMs. To address this gap,
we introduce CodeMixBench, a novel benchmark designed to evaluate the
robustness of LLMs on code generation from code-mixed prompts. Built upon
BigCodeBench, CodeMixBench introduces controlled code-mixing (CMD) into the
natural language parts of prompts across three language pairs: Hinglish
(Hindi-English), Spanish-English, and Chinese Pinyin-English. We
comprehensively evaluate a diverse set of open-source code generation models
ranging from 1.5B to 15B parameters. Our results show that code-mixed prompts
consistently degrade Pass@1 performance compared to their English-only
counterparts, with performance drops increasing under higher CMD levels for
smaller models. CodeMixBench provides a realistic evaluation framework for
studying multilingual code generation and highlights new challenges and
directions for building robust code generation models that generalize well
across diverse linguistic settings.

</details>


### [183] [WaterDrum: Watermarking for Data-centric Unlearning Metric](https://arxiv.org/abs/2505.05064)
*Xinyang Lu,Xinyuan Niu,Gregory Kang Ruey Lau,Bui Thi Cam Nhung,Rachael Hwee Ling Sim,Fanyu Wen,Chuan-Sheng Foo,See-Kiong Ng,Bryan Kian Hsiang Low*

Main category: cs.LG

TL;DR: 论文提出了一种名为WaterDrum的新的以数据为中心的LLM遗忘评估指标，利用文本水印技术克服现有指标的局限性，并发布了新的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有以模型效用为中心的LLM遗忘评估指标在遗忘集与保留集内容语义相似、从头重新训练模型不切实际，或模型所有者可能在不直接执行遗忘操作的情况下改善指标等现实场景中，无法准确评估遗忘程度。

Method: 提出WaterDrum，这是首个用于LLM的以数据为中心的遗忘评估指标，它利用了鲁棒的文本水印技术。同时，引入了包含不同程度相似数据点的新的LLM遗忘基准数据集。

Result: 成功开发了WaterDrum指标，能够克服现有基于模型效用的指标的局限性。此外，还发布了新的基准数据集，可用于使用WaterDrum严格评估遗忘算法。代码和数据集均已公开。

Conclusion: WaterDrum通过利用鲁棒的文本水印，为LLM的遗忘评估提供了一种更可靠的方法，特别是在现有方法可能失效的挑战性场景中。新的基准数据集有助于对遗忘算法进行更严格的评估。

Abstract: Large language model (LLM) unlearning is critical in real-world applications
where it is necessary to efficiently remove the influence of private,
copyrighted, or harmful data from some users. However, existing utility-centric
unlearning metrics (based on model utility) may fail to accurately evaluate the
extent of unlearning in realistic settings such as when (a) the forget and
retain set have semantically similar content, (b) retraining the model from
scratch on the retain set is impractical, and/or (c) the model owner can
improve the unlearning metric without directly performing unlearning on the
LLM. This paper presents the first data-centric unlearning metric for LLMs
called WaterDrum that exploits robust text watermarking for overcoming these
limitations. We also introduce new benchmark datasets for LLM unlearning that
contain varying levels of similar data points and can be used to rigorously
evaluate unlearning algorithms using WaterDrum. Our code is available at
https://github.com/lululu008/WaterDrum and our new benchmark datasets are
released at https://huggingface.co/datasets/Glow-AI/WaterDrum-Ax.

</details>


### [184] [ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model](https://arxiv.org/abs/2505.05082)
*Sagnik Bhattacharya,Abhiram R. Gorle,Ahmed Mohsin,Ahsan Bilal,Connor Ding,Amit Kumar Singh Yadav,Tsachy Weissman*

Main category: cs.LG

TL;DR: 该研究提出 ItDPDM，一种新的离散数据生成模型，通过泊松扩散直接在离散空间建模，并使用精确的泊松重构损失优化，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有离散数据生成模型（如符号音乐）面临两大挑战：要么将离散输入嵌入连续空间，要么依赖近似的变分损失来估计负对数似然。本研究旨在同时解决这两个问题。

Method: 提出信息论离散泊松扩散模型 (ItDPDM)，该模型直接在离散状态空间通过受相机传感器光子到达过程启发的泊松扩散过程进行操作。引入了新的泊松重构损失 (PRL)，并推导出其与真实负对数似然之间的精确关系，从而避免了对近似证据下界的需求。

Result: 在 Lakh MIDI 符号音乐数据集和 CIFAR-10 图像基准上的实验结果显示，与现有基线方法相比，ItDPDM 在测试负对数似然 (NLL) 上降低了高达 80%，并且实现了更快的收敛速度。

Conclusion: ItDPDM 通过直接在离散空间操作并使用精确的损失函数，有效解决了现有离散数据生成模型的局限性，为符号音乐等离散数据的生成建模提供了一种性能更优、收敛更快的新方法。

Abstract: Existing methods for generative modeling of discrete data, such as symbolic
music tokens, face two primary challenges: (1) they either embed discrete
inputs into continuous state-spaces or (2) rely on variational losses that only
approximate the true negative log-likelihood. Previous efforts have
individually targeted these limitations. While information-theoretic Gaussian
diffusion models alleviate the suboptimality of variational losses, they still
perform modeling in continuous domains. In this work, we introduce the
Information-Theoretic Discrete Poisson Diffusion Model (ItDPDM), which
simultaneously addresses both limitations by directly operating in a discrete
state-space via a Poisson diffusion process inspired by photon arrival
processes in camera sensors. We introduce a novel Poisson Reconstruction Loss
(PRL) and derive an exact relationship between PRL and the true negative
log-likelihood, thereby eliminating the need for approximate evidence lower
bounds. Experiments conducted on the Lakh MIDI symbolic music dataset and the
CIFAR-10 image benchmark demonstrate that ItDPDM delivers significant
improvements, reducing test NLL by up to 80% compared to prior baselines, while
also achieving faster convergence.

</details>


### [185] [Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning](https://arxiv.org/abs/2505.05086)
*Le-Trung Nguyen,Ael Quelennec,Van-Tam Nguyen,Enzo Tartaglione*

Main category: cs.LG

TL;DR: 提出一种新颖的快捷方法，以减少设备端学习中的激活内存使用和训练计算量。


<details>
  <summary>Details</summary>
Motivation: 设备端学习因其低延迟、隐私保护和高能效的潜力而备受关注，但其部署仍面临内存和计算限制的重大挑战。

Method: 借鉴先前解决反向传播中激活内存瓶颈的低秩分解方法研究，提出一种新颖的快捷方法作为替代方案。

Result: 该方法与传统训练相比，可将激活内存使用量减少高达120.09倍，并将整体训练浮点运算次数（FLOPs）减少高达1.86倍。

Conclusion: 所提出的快捷方法能有效减少设备端学习的激活内存使用和训练计算量，为克服其部署挑战提供了有效途径。

Abstract: On-device learning has emerged as a promising direction for AI development,
particularly because of its potential to reduce latency issues and mitigate
privacy risks associated with device-server communication, while improving
energy efficiency. Despite these advantages, significant memory and
computational constraints still represent major challenges for its deployment.
Drawing on previous studies on low-rank decomposition methods that address
activation memory bottlenecks in backpropagation, we propose a novel shortcut
approach as an alternative. Our analysis and experiments demonstrate that our
method can reduce activation memory usage, even up to $120.09\times$ compared
to vanilla training, while also reducing overall training FLOPs up to
$1.86\times$ when evaluated on traditional benchmarks.

</details>


### [186] [A Conjoint Graph Representation Learning Framework for Hypertension Comorbidity Risk Prediction](https://arxiv.org/abs/2505.05094)
*Leming Zhou,Zuo Wang,Zhixuan Duan*

Main category: cs.LG

TL;DR: 该研究提出了一种联合图表示学习框架（CGRL），通过构建患者网络和疾病差异网络，并结合网络分析，以早期识别高血压合并症（如糖尿病、冠心病）并预测其风险。


<details>
  <summary>Details</summary>
Motivation: 高血压合并症给患者和社会带来沉重负担，且其早期识别对于及时干预至关重要，但这仍然是一项具有挑战性的任务。

Method: 开发了一个联合图表示学习（CGRL）框架：a) 基于疾病编码构建患者网络和疾病差异网络，并从差异网络生成三种合并症网络特征；b) 结合计算结构干预和学习特征表示，用于预测患者的糖尿病和冠心病风险；c) 分析合并症模式并探索疾病进展路径。

Result: 基于疾病差异网络提取的网络特征非常重要。所提出的CGRL框架在预测准确性方面优于其他强模型。

Conclusion: 该研究提出的框架能够更准确地预测高血压合并症风险，并可能揭示糖尿病和冠心病的病理发病机制。

Abstract: The comorbidities of hypertension impose a heavy burden on patients and
society. Early identification is necessary to prompt intervention, but it
remains a challenging task. This study aims to address this challenge by
combining joint graph learning with network analysis. Motivated by this
discovery, we develop a Conjoint Graph Representation Learning (CGRL) framework
that: a) constructs two networks based on disease coding, including the patient
network and the disease difference network. Three comorbidity network features
were generated based on the basic difference network to capture the potential
relationship between comorbidities and risk diseases; b) incorporates
computational structure intervention and learning feature representation, CGRL
was developed to predict the risks of diabetes and coronary heart disease in
patients; and c) analysis the comorbidity patterns and exploring the pathways
of disease progression, the pathological pathogenesis of diabetes and coronary
heart disease may be revealed. The results show that the network features
extracted based on the difference network are important, and the framework we
proposed provides more accurate predictions than other strong models in terms
of accuracy.

</details>


### [187] [Balancing Client Participation in Federated Learning Using AoI](https://arxiv.org/abs/2505.05099)
*Alireza Javani,Zhiying Wang*

Main category: cs.LG

TL;DR: 提出一种基于信息年龄 (AoI) 的联邦学习客户端选择策略，通过去中心化马尔可夫调度平衡客户端参与，改善模型收敛。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临通信资源受限、统计异质性以及客户端参与不均衡等挑战。

Method: 提出一种基于信息年龄 (AoI) 的客户端选择策略，采用去中心化马尔可夫调度，客户端根据年龄相关的选择概率自主管理参与，并通过控制选择间隔最小化负载不平衡。

Result: 该方法被证明可以确保稳定高效的模型收敛。仿真结果显示，基于 AoI 的方法（特别是优化的马尔可夫变体）在 IID 和非 IID 数据设置下，相比 FedAvg 选择方法，收敛性分别提高了 7.5% 和高达 20%。

Conclusion: 基于 AoI 的调度策略能有效提升联邦学习系统在不同学习环境下的可扩展性、公平性和效率。

Abstract: Federated Learning (FL) offers a decentralized framework that preserves data
privacy while enabling collaborative model training across distributed clients.
However, FL faces significant challenges due to limited communication
resources, statistical heterogeneity, and the need for balanced client
participation. This paper proposes an Age of Information (AoI)-based client
selection policy that addresses these challenges by minimizing load imbalance
through controlled selection intervals. Our method employs a decentralized
Markov scheduling policy, allowing clients to independently manage
participation based on age-dependent selection probabilities, which balances
client updates across training rounds with minimal central oversight. We
provide a convergence proof for our method, demonstrating that it ensures
stable and efficient model convergence. Specifically, we derive optimal
parameters for the Markov selection model to achieve balanced and consistent
client participation, highlighting the benefits of AoI in enhancing convergence
stability. Through extensive simulations, we demonstrate that our AoI-based
method, particularly the optimal Markov variant, improves convergence over the
FedAvg selection approach across both IID and non-IID data settings by $7.5\%$
and up to $20\%$. Our findings underscore the effectiveness of AoI-based
scheduling for scalable, fair, and efficient FL systems across diverse learning
environments.

</details>


### [188] [USPR: Learning a Unified Solver for Profiled Routing](https://arxiv.org/abs/2505.05119)
*Chuanbo Hua,Federico Berto,Zhikai Zhao,Jiwoo Son,Changhyun Kwon,Jinkyoo Park*

Main category: cs.LG

TL;DR: 本文提出了一种名为 USPR 的新框架，用于解决带偏好的车辆路径问题 (PVRP)，它能比现有强化学习方法更好地处理各种偏好配置，并提升了灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习 (RL) 求解器在处理带偏好的车辆路径问题 (PVRP) 时，面临需要为每种新的偏好分布重新训练、表示能力差以及难以泛化到分布外实例等问题。

Method: 引入了一个名为 USPR (Unified Solver for Profiled Routing) 的新框架，其核心创新包括：(i) 偏好嵌入 (PE) 来编码任意偏好类型组合；(ii) 多头偏好注意力机制 (MHPA) 来建模车辆与客户间的复杂交互；(iii) 偏好感知分数重塑 (PSR) 来动态调整解码器输出以改善泛化能力。

Result: 在多种 PVRP 基准测试中，USPR 在基于学习的方法中取得了最先进的成果，并且在灵活性和计算效率方面有显著提升。

Conclusion: USPR 是一种能够有效处理任意偏好类型的 PVRP 统一求解框架，它克服了现有方法的局限性，在性能、灵活性和计算效率上均表现出色。

Abstract: The Profiled Vehicle Routing Problem (PVRP) extends the classical VRP by
incorporating vehicle-client-specific preferences and constraints, reflecting
real-world requirements such as zone restrictions and service-level
preferences. While recent reinforcement learning (RL) solvers have shown
promise, they require retraining for each new profile distribution, suffer from
poor representation ability, and struggle to generalize to out-of-distribution
instances. In this paper, we address these limitations by introducing USPR
(Unified Solver for Profiled Routing), a novel framework that natively handles
arbitrary profile types. USPR introduces three key innovations: (i) Profile
Embeddings (PE) to encode any combination of profile types; (ii) Multi-Head
Profiled Attention (MHPA), an attention mechanism that models rich interactions
between vehicles and clients; (iii) Profile-aware Score Reshaping (PSR), which
dynamically adjusts decoder logits using profile scores to improve
generalization. Empirical results on diverse PVRP benchmarks demonstrate that
USPR achieves state-of-the-art results among learning-based methods while
offering significant gains in flexibility and computational efficiency. We make
our source code publicly available to foster future research at
https://github.com/ai4co/uspr.

</details>


### [189] [Taming OOD Actions for Offline Reinforcement Learning: An Advantage-Based Approach](https://arxiv.org/abs/2505.05126)
*Xuyang Chen,Keyu Yan,Lin Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种名为 ADAC 的新型离线强化学习方法，通过基于优势函数的评估机制，更精确地识别和利用分布外（OOD）动作，从而在 D4RL 基准测试中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习因分布偏移问题导致对分布外（OOD）动作的评估不准确和过度高估。现有方法通过无差别抑制所有OOD动作来引入保守性，但这限制了智能体泛化和利用有益OOD动作的能力。

Method: 提出了基于优势的扩散行动者-评论家（ADAC）方法。该方法使用批次最优价值函数系统评估OOD动作，并基于此评估定义一个优势函数来调节Q函数的更新，以更精确地评估OOD动作的质量。

Result: 在自定义的PointMaze环境中，视觉结果表明优势调制能有效识别并选择更优的OOD动作。在D4RL基准测试中，ADAC在几乎所有任务上均达到当前最佳性能，尤其在挑战性任务上优势明显。

Conclusion: ADAC通过精确评估和选择性利用有益的OOD动作，有效解决了离线强化学习中的分布偏移问题，并显著提升了算法性能。

Abstract: Offline reinforcement learning (RL) aims to learn decision-making policies
from fixed datasets without online interactions, providing a practical solution
where online data collection is expensive or risky. However, offline RL often
suffers from distribution shift, resulting in inaccurate evaluation and
substantial overestimation on out-of-distribution (OOD) actions. To address
this, existing approaches incorporate conservatism by indiscriminately
discouraging all OOD actions, thereby hindering the agent's ability to
generalize and exploit beneficial ones. In this paper, we propose
Advantage-based Diffusion Actor-Critic (ADAC), a novel method that
systematically evaluates OOD actions using the batch-optimal value function.
Based on this evaluation, ADAC defines an advantage function to modulate the
Q-function update, enabling more precise assessment of OOD action quality. We
design a custom PointMaze environment and collect datasets to visually reveal
that advantage modulation can effectively identify and select superior OOD
actions. Extensive experiments show that ADAC achieves state-of-the-art
performance on almost all tasks in the D4RL benchmark, with particularly clear
margins on the more challenging tasks.

</details>


### [190] [Research on Anomaly Detection Methods Based on Diffusion Models](https://arxiv.org/abs/2505.05137)
*Yi Chen*

Main category: cs.LG

TL;DR: 本研究提出了一种基于扩散模型的异常检测新框架，用于有效识别图像和音频数据中的异常，并在多个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法在处理复杂、高维数据分布时面临挑战，本研究旨在探索扩散模型在此领域的潜力。

Method: 提出了一种基于扩散概率模型（DPMs）的新框架。该方法通过扩散过程对正常数据分布进行建模，并通过逆扩散过程重构输入数据，结合重构误差和语义差异作为异常指标。为提升性能，引入了多尺度特征提取、注意力机制和小波域表示。

Result: 在MVTec AD和UrbanSound8K等基准数据集上的实验表明，该方法在准确性和鲁棒性方面均优于当前最先进的异常检测技术。

Conclusion: 研究证明了扩散模型在异常检测中的有效性，为实际应用提供了一种鲁棒且高效的解决方案。

Abstract: Anomaly detection is a fundamental task in machine learning and data mining,
with significant applications in cybersecurity, industrial fault diagnosis, and
clinical disease monitoring. Traditional methods, such as statistical modeling
and machine learning-based approaches, often face challenges in handling
complex, high-dimensional data distributions. In this study, we explore the
potential of diffusion models for anomaly detection, proposing a novel
framework that leverages the strengths of diffusion probabilistic models (DPMs)
to effectively identify anomalies in both image and audio data. The proposed
method models the distribution of normal data through a diffusion process and
reconstructs input data via reverse diffusion, using a combination of
reconstruction errors and semantic discrepancies as anomaly indicators. To
enhance the framework's performance, we introduce multi-scale feature
extraction, attention mechanisms, and wavelet-domain representations, enabling
the model to capture fine-grained structures and global dependencies in the
data. Extensive experiments on benchmark datasets, including MVTec AD and
UrbanSound8K, demonstrate that our method outperforms state-of-the-art anomaly
detection techniques, achieving superior accuracy and robustness across diverse
data modalities. This research highlights the effectiveness of diffusion models
in anomaly detection and provides a robust and efficient solution for
real-world applications.

</details>


### [191] [Sparse Training from Random Initialization: Aligning Lottery Ticket Masks using Weight Symmetry](https://arxiv.org/abs/2505.05143)
*Mohammed Adnan,Rohan Jain,Ekansh Sharma,Rahul Krishnan,Yani Ioannou*

Main category: cs.LG

TL;DR: 论文提出通过排列彩票假设 (LTH) 掩码来解决其在不同随机初始化下的泛化性问题，从而提高稀疏训练的性能。


<details>
  <summary>Details</summary>
Motivation: 彩票假设 (LTH) 找到的稀疏子网络虽然参数少、性能好，但其掩码不适用于新的随机权重初始化，且寻找 LTH 解计算成本高昂。研究旨在解决 LTH 掩码的泛化性问题。

Method: 假设 LTH 掩码在新随机初始化下不泛化的原因是损失盆地的错位。提出在从不同随机初始化进行稀疏训练时，通过排列 LTH 掩码以使其与新的优化盆地对齐。

Result: 实验表明，在多个数据集 (CIFAR-10, CIFAR-100, ImageNet) 和模型 (VGG11, ResNet20, ResNet50) 上，使用排列后的掩码进行稀疏训练，相比使用未排列的 LTH 掩码，泛化能力显著提高。

Conclusion: 排列 LTH 掩码可以有效改善其在不同随机初始化下的泛化性，从而提升稀疏训练的效果。

Abstract: The Lottery Ticket Hypothesis (LTH) suggests there exists a sparse LTH mask
and weights that achieve the same generalization performance as the dense model
while using significantly fewer parameters. However, finding a LTH solution is
computationally expensive, and a LTH sparsity mask does not generalize to other
random weight initializations. Recent work has suggested that neural networks
trained from random initialization find solutions within the same basin modulo
permutation, and proposes a method to align trained models within the same loss
basin. We hypothesize that misalignment of basins is the reason why LTH masks
do not generalize to new random initializations and propose permuting the LTH
mask to align with the new optimization basin when performing sparse training
from a different random init. We empirically show a significant increase in
generalization when sparse training from random initialization with the
permuted mask as compared to using the non-permuted LTH mask, on multiple
datasets (CIFAR-10, CIFAR-100 and ImageNet) and models (VGG11, ResNet20 and
ResNet50).

</details>


### [192] [Understanding In-context Learning of Addition via Activation Subspaces](https://arxiv.org/abs/2505.05145)
*Xinyan Hu,Kayo Yin,Michael I. Jordan,Jacob Steinhardt,Lijie Chen*

Main category: cs.LG

TL;DR: 研究Llama-3-8B模型如何通过少数几个注意力头，在低维子空间中学习并执行简单的整数加法任务，揭示了其上下文学习的内部机制，包括信号提取和自我修正过程。


<details>
  <summary>Details</summary>
Motivation: 探究现代Transformer模型在前向传播过程中如何实现上下文学习（in-context learning），即如何从少样本示例中提取信号、聚合成规则并应用于新示例。

Method: 研究设计了一个结构化的少样本学习任务（对输入整数加k），使用Llama-3-8B模型进行实验。通过一种新颖的优化方法定位实现该能力的关键注意力头，分析这些头提取的信号所在的子空间，并研究其从单个示例中提取信息的机制。

Result: Llama-3-8B在此加法任务上准确率高。其少样本学习能力主要定位于三个注意力头。提取的信号存在于一个六维子空间，其中四维跟踪个位数，两维跟踪整体数量级。还发现了一种自我修正机制，后续示例会抑制早期示例的错误。

Conclusion: 通过在前向传播过程中跟踪低维子空间，可以深入了解模型内部精细的计算结构，从而揭示Transformer模型执行上下文学习的具体机制。

Abstract: To perform in-context learning, language models must extract signals from
individual few-shot examples, aggregate these into a learned prediction rule,
and then apply this rule to new examples. How is this implemented in the
forward pass of modern transformer models? To study this, we consider a
structured family of few-shot learning tasks for which the true prediction rule
is to add an integer $k$ to the input. We find that Llama-3-8B attains high
accuracy on this task for a range of $k$, and localize its few-shot ability to
just three attention heads via a novel optimization approach. We further show
the extracted signals lie in a six-dimensional subspace, where four of the
dimensions track the unit digit and the other two dimensions track overall
magnitude. We finally examine how these heads extract information from
individual few-shot examples, identifying a self-correction mechanism in which
mistakes from earlier examples are suppressed by later examples. Our results
demonstrate how tracking low-dimensional subspaces across a forward pass can
provide insight into fine-grained computational structures.

</details>


### [193] [FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning](https://arxiv.org/abs/2505.05155)
*Zhihao Zeng,Ziquan Fang,Wei Shao,Lu Chen,Yunjun Gao*

Main category: cs.LG

TL;DR: 提出FedTDP，一个利用大语言模型在联邦环境中进行隐私保护和统一的轨迹数据准备框架。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹数据准备（TDP）方法存在隐私泄露风险（尤其在联邦场景下）且缺乏通用性，无法适应多样化的TDP任务。

Method: 设计了FedTDP框架，包含：(1) 轨迹隐私自动编码器以保护数据和隐私；(2) 轨迹知识增强器以改进模型对TDP相关知识的学习，从而开发面向TDP的大语言模型；(3) 联邦并行优化以提高训练效率。

Result: 在6个真实数据集和10个主流TDP任务上的实验表明，FedTDP的性能优于13个最先进的基线方法。

Conclusion: FedTDP是一个有效的、隐私保护的、统一的联邦轨迹数据准备框架，能够解决现有方法的局限性并提升数据质量。

Abstract: Trajectory data, which capture the movement patterns of people and vehicles
over time and space, are crucial for applications like traffic optimization and
urban planning. However, issues such as noise and incompleteness often
compromise data quality, leading to inaccurate trajectory analyses and limiting
the potential of these applications. While Trajectory Data Preparation (TDP)
can enhance data quality, existing methods suffer from two key limitations: (i)
they do not address data privacy concerns, particularly in federated settings
where trajectory data sharing is prohibited, and (ii) they typically design
task-specific models that lack generalizability across diverse TDP scenarios.
To overcome these challenges, we propose FedTDP, a privacy-preserving and
unified framework that leverages the capabilities of Large Language Models
(LLMs) for TDP in federated environments. Specifically, we: (i) design a
trajectory privacy autoencoder to secure data transmission and protect privacy,
(ii) introduce a trajectory knowledge enhancer to improve model learning of
TDP-related knowledge, enabling the development of TDP-oriented LLMs, and (iii)
propose federated parallel optimization to enhance training efficiency by
reducing data transmission and enabling parallel model training. Experiments on
6 real datasets and 10 mainstream TDP tasks demonstrate that FedTDP
consistently outperforms 13 state-of-the-art baselines.

</details>


### [194] [Bandit Max-Min Fair Allocation](https://arxiv.org/abs/2505.05169)
*Tsubasa Harada,Shinji Ito,Hanna Sumita*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we study a new decision-making problem called the bandit
max-min fair allocation (BMMFA) problem. The goal of this problem is to
maximize the minimum utility among agents with additive valuations by
repeatedly assigning indivisible goods to them. One key feature of this problem
is that each agent's valuation for each item can only be observed through the
semi-bandit feedback, while existing work supposes that the item values are
provided at the beginning of each round. Another key feature is that the
algorithm's reward function is not additive with respect to rounds, unlike most
bandit-setting problems.
  Our first contribution is to propose an algorithm that has an asymptotic
regret bound of $O(m\sqrt{T}\ln T/n + m\sqrt{T \ln(mnT)})$, where $n$ is the
number of agents, $m$ is the number of items, and $T$ is the time horizon. This
is based on a novel combination of bandit techniques and a resource allocation
algorithm studied in the literature on competitive analysis. Our second
contribution is to provide the regret lower bound of $\Omega(m\sqrt{T}/n)$.
When $T$ is sufficiently larger than $n$, the gap between the upper and lower
bounds is a logarithmic factor of $T$.

</details>


### [195] [OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning](https://arxiv.org/abs/2505.05180)
*Cong Hua,Qianqian Xu,Zhiyong Yang,Zitai Wang,Shilong Bao,Qingming Huang*

Main category: cs.LG

TL;DR: 本文针对开放世界提示调整（prompt tuning）的挑战，提出了一种新的评估指标OpenworldAUC和一种名为Gated Mixture-of-Prompts (GMoP) 的方法，旨在使视觉语言模型能更好地处理无先验领域知识的输入。


<details>
  <summary>Details</summary>
Motivation: 现有的提示调整方法通常分别评估模型在已知类别（基础域）和未知类别（新域）上的表现，但真实场景要求模型能在无先验领域知识的情况下处理输入。这一实际挑战催生了开放世界提示调整，它需要统一评估两个阶段：1) 检测输入属于基础域还是新域 (P1)，2) 将样本正确分类 (P2)。此外，由于领域分布通常未知，一个合适的指标应对不同的基础/新样本比例不敏感 (P3)。然而，当前指标（如HM、整体准确率、AUROC）无法同时满足这三个特性。

Method: 1. 提出了一个新的统一评估指标OpenworldAUC，它通过成对实例比较来联合评估检测和分类能力。
2. 引入了一种名为门控混合提示 (Gated Mixture-of-Prompts, GMoP) 的方法，该方法使用领域特定的提示和一个门控机制来动态平衡检测和分类任务，从而有效优化OpenworldAUC。

Result: 在15个开放世界场景的基准测试中，GMoP在OpenworldAUC及其他指标上均取得了当前最佳（SOTA）性能。理论分析保证了GMoP在实际应用条件下的泛化能力。

Conclusion: 提出的OpenworldAUC指标和GMoP方法有效解决了开放世界提示调整中的关键问题，为在未知领域分布的真实场景下评估和优化模型提供了更好的途径。

Abstract: Prompt tuning adapts Vision-Language Models like CLIP to open-world tasks
with minimal training costs. In this direction, one typical paradigm evaluates
model performance separately on known classes (i.e., base domain) and unseen
classes (i.e., new domain). However, real-world scenarios require models to
handle inputs without prior domain knowledge. This practical challenge has
spurred the development of open-world prompt tuning, which demands a unified
evaluation of two stages: 1) detecting whether an input belongs to the base or
new domain (P1), and 2) classifying the sample into its correct class (P2).
What's more, as domain distributions are generally unknown, a proper metric
should be insensitive to varying base/new sample ratios (P3). However, we find
that current metrics, including HM, overall accuracy, and AUROC, fail to
satisfy these three properties simultaneously. To bridge this gap, we propose
OpenworldAUC, a unified metric that jointly assesses detection and
classification through pairwise instance comparisons. To optimize OpenworldAUC
effectively, we introduce Gated Mixture-of-Prompts (GMoP), which employs
domain-specific prompts and a gating mechanism to dynamically balance detection
and classification. Theoretical guarantees ensure generalization of GMoP under
practical conditions. Experiments on 15 benchmarks in open-world scenarios show
GMoP achieves SOTA performance on OpenworldAUC and other metrics. We release
the code at https://github.com/huacong/OpenworldAUC

</details>


### [196] [Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation](https://arxiv.org/abs/2505.05181)
*Bojian Yin,Federico Corradi*

Main category: cs.LG

TL;DR: 提出随机变分传播（SVP），一种可扩展的反向传播替代方案，通过分层变分推断和局部ELBO优化实现本地更新，同时通过随机投影和特征对齐损失解决表示崩溃问题，实现与BP相当的性能并降低内存。


<details>
  <summary>Details</summary>
Motivation: 反向传播（BP）算法依赖全局梯度同步，这限制了其可扩展性并导致显著的内存开销。

Method: 提出随机变分传播（SVP）：将训练过程重构为分层变分推断，将层激活视为潜变量，并优化局部证据下界（ELBOs）以实现独立的局部更新。为防止层间表示崩溃，SVP通过固定的随机矩阵将激活投影到低维空间，并结合特征对齐损失来保持层间一致性。

Result: SVP在多种架构（MLPs, CNNs, Transformers）和数据集（从MNIST到ImageNet）上取得了与BP相当的准确率，内存使用量减少高达4倍，并显著提高了可扩展性。

Conclusion: SVP为深度表示学习引入了概率视角，为设计更模块化和可解释的神经网络开辟了新途径。

Abstract: Backpropagation (BP) is the cornerstone of deep learning, but its reliance on
global gradient synchronization limits scalability and imposes significant
memory overhead. We propose Stochastic Variational Propagation (SVP), a
scalable alternative that reframes training as hierarchical variational
inference. SVP treats layer activations as latent variables and optimizes local
Evidence Lower Bounds (ELBOs), enabling independent, local updates while
preserving global coherence. However, directly applying KL divergence in
layer-wise ELBOs risks inter-layer's representation collapse due to excessive
compression. To prevent this, SVP projects activations into low-dimensional
spaces via fixed random matrices, ensuring information preservation and
representational diversity. Combined with a feature alignment loss for
inter-layer consistency, SVP achieves competitive accuracy with BP across
diverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to
ImageNet), reduces memory usage by up to 4x, and significantly improves
scalability. More broadly, SVP introduces a probabilistic perspective to deep
representation learning, opening pathways toward more modular and interpretable
neural network design.

</details>


### [197] [Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org/abs/2505.05190)
*Yixin Cheng,Hongcheng Guo,Yangming Li,Leonid Sigal*

Main category: cs.LG

TL;DR: 本文提出了一种名为SIRA的新型攻击方法，利用当前文本水印算法在高熵词元中嵌入水印的弱点，能高效移除水印，揭示了当前水印技术的普遍脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前文本水印算法为保证文本质量，倾向于在高熵词元中嵌入水印，但这种设计可能被攻击者利用，对水印的鲁棒性构成重大威胁。

Method: 提出了一种通用的高效释义攻击——自信息重写攻击 (SIRA)。该方法通过计算每个词元的自信息来识别潜在的模式词元（可能携带水印的词元），并进行针对性改写。

Result: SIRA在七种最新的水印方法上实现了接近100%的攻击成功率，每百万词元攻击成本仅0.88美元。该攻击无需访问水印算法或带水印的LLM，可迁移至任何LLM作为攻击模型。

Conclusion: SIRA揭示了当前文本水印算法中普遍存在的漏洞，强调了开发更鲁棒水印技术的迫切需求。

Abstract: Text watermarking aims to subtly embed statistical signals into text by
controlling the Large Language Model (LLM)'s sampling process, enabling
watermark detectors to verify that the output was generated by the specified
model. The robustness of these watermarking algorithms has become a key factor
in evaluating their effectiveness. Current text watermarking algorithms embed
watermarks in high-entropy tokens to ensure text quality. In this paper, we
reveal that this seemingly benign design can be exploited by attackers, posing
a significant risk to the robustness of the watermark. We introduce a generic
efficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),
which leverages the vulnerability by calculating the self-information of each
token to identify potential pattern tokens and perform targeted attack. Our
work exposes a widely prevalent vulnerability in current watermarking
algorithms. The experimental results show SIRA achieves nearly 100% attack
success rates on seven recent watermarking methods with only 0.88 USD per
million tokens cost. Our approach does not require any access to the watermark
algorithms or the watermarked LLM and can seamlessly transfer to any LLM as the
attack model, even mobile-level models. Our findings highlight the urgent need
for more robust watermarking.

</details>


### [198] [Long-Term Individual Causal Effect Estimation via Identifiable Latent Representation Learning](https://arxiv.org/abs/2505.05192)
*Ruichu Cai,Junjie Wan,Weilin Chen,Zeqin Yang,Zijian Li,Peng Zhen,Jiecheng Guo*

Main category: cs.LG

TL;DR: 该论文提出了一种新方法，通过利用数据异质性识别潜在混杂因素，来估计长期个体因果效应，从而避免了对理想化假设的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有估计长期因果效应的方法依赖于在现实中难以满足的理想假设（如潜在无混杂性或加性等混杂偏倚假设），这限制了它们在实际场景中的有效性。

Method: 该研究提出利用数据的自然异质性（例如来自多个来源的数据）来识别潜在混杂因素。具体地，设计了一个基于潜在表示学习的长期因果效应估计器。

Result: 理论上，该方法证明了潜在混杂因素的可识别性，并在此基础上实现了长期效应的识别。在多个合成和半合成数据集上进行的广泛实验研究表明了所提出方法的有效性。

Conclusion: 本文提出了一种估计长期个体因果效应的新方法，该方法通过利用数据异质性识别潜在混杂因素，显著减少了对理想化假设的依赖，并在实验中证明了其有效性。

Abstract: Estimating long-term causal effects by combining long-term observational and
short-term experimental data is a crucial but challenging problem in many
real-world scenarios. In existing methods, several ideal assumptions, e.g.
latent unconfoundedness assumption or additive equi-confounding bias
assumption, are proposed to address the latent confounder problem raised by the
observational data. However, in real-world applications, these assumptions are
typically violated which limits their practical effectiveness. In this paper,
we tackle the problem of estimating the long-term individual causal effects
without the aforementioned assumptions. Specifically, we propose to utilize the
natural heterogeneity of data, such as data from multiple sources, to identify
latent confounders, thereby significantly avoiding reliance on idealized
assumptions. Practically, we devise a latent representation learning-based
estimator of long-term causal effects. Theoretically, we establish the
identifiability of latent confounders, with which we further achieve long-term
effect identification. Extensive experimental studies, conducted on multiple
synthetic and semi-synthetic datasets, demonstrate the effectiveness of our
proposed method.

</details>


### [199] [Concept-Based Unsupervised Domain Adaptation](https://arxiv.org/abs/2505.05195)
*Xinyue Xu,Yueying Hu,Hui Tang,Yi Qin,Lu Mi,Hao Wang,Xiaomeng Li*

Main category: cs.LG

TL;DR: 提出了一种名为CUDA的框架，旨在通过对齐概念表示、引入松弛阈值和在目标域中推断概念来提高概念瓶颈模型（CBMs）在域漂移下的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 概念瓶颈模型（CBMs）在训练和测试数据分布不同的域漂移情况下，性能会下降且泛化能力差，限制了其实际应用。

Method: 提出了概念驱动的无监督域自适应（CUDA）框架。该框架通过以下方式运作：(1) 使用对抗训练对齐跨域的概念表示；(2) 引入松弛阈值以允许概念分布中存在微小的域特异性差异；(3) 在目标域中直接推断概念，无需标记的概念数据；(4) 将概念学习整合到传统的域自适应（DA）中，并提供理论保证。

Result: 实验表明，CUDA方法在真实世界数据集上的表现显著优于当前最先进的CBM和域自适应（DA）方法。

Conclusion: CUDA框架有效解决了CBMs在域漂移下的性能问题，提高了其鲁棒性和可解释性，并为域自适应领域建立了新的基准。

Abstract: Concept Bottleneck Models (CBMs) enhance interpretability by explaining
predictions through human-understandable concepts but typically assume that
training and test data share the same distribution. This assumption often fails
under domain shifts, leading to degraded performance and poor generalization.
To address these limitations and improve the robustness of CBMs, we propose the
Concept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed
to: (1) align concept representations across domains using adversarial
training, (2) introduce a relaxation threshold to allow minor domain-specific
differences in concept distributions, thereby preventing performance drop due
to over-constraints of these distributions, (3) infer concepts directly in the
target domain without requiring labeled concept data, enabling CBMs to adapt to
diverse domains, and (4) integrate concept learning into conventional domain
adaptation (DA) with theoretical guarantees, improving interpretability and
establishing new benchmarks for DA. Experiments demonstrate that our approach
significantly outperforms the state-of-the-art CBM and DA methods on real-world
datasets.

</details>


### [200] [GFlowNets for Active Learning Based Resource Allocation in Next Generation Wireless Networks](https://arxiv.org/abs/2505.05224)
*Charbel Bou Chaaya,Mehdi Bennis*

Main category: cs.LG

TL;DR: 本文提出一种基于主动学习和GFlowNet的无线资源分配方法，以高效满足通信、感知和计算等多功能需求。


<details>
  <summary>Details</summary>
Motivation: 无线系统集成了通信、感知和计算等多种功能，需要能够同时满足这些异构需求并有效处理问题高维性和离散性的资源管理技术。

Method: 提出了一种主动学习框架，利用生成流网络（GFlowNet）对资源分配方案进行采样。GFlowNet根据奖励生成组合对象，从而顺序抽取方案、在环境中评估，并迭代更新环境的代理模型，以发现有利的解决方案。

Result: 仿真结果显示，该方法在无线电资源分配方面实现了20%的性能提升，且所需的采集轮数不到基准方法的一半。

Conclusion: 该研究提出的基于GFlowNet的主动学习框架，能够有效解决无线系统中通信、感知、计算等多功能融合下的资源分配问题，快速发现多样化且高回报的解决方案，性能优于基准方法。

Abstract: In this work, we consider the radio resource allocation problem in a wireless
system with various integrated functionalities, such as communication, sensing
and computing. We design suitable resource management techniques that can
simultaneously cater to those heterogeneous requirements, and scale
appropriately with the high-dimensional and discrete nature of the problem. We
propose a novel active learning framework where resource allocation patterns
are drawn sequentially, evaluated in the environment, and then used to
iteratively update a surrogate model of the environment. Our method leverages a
generative flow network (GFlowNet) to sample favorable solutions, as such
models are trained to generate compositional objects proportionally to their
training reward, hence providing an appropriate coverage of its modes. As such,
GFlowNet generates diverse and high return resource management designs that
update the surrogate model and swiftly discover suitable solutions. We provide
simulation results showing that our method can allocate radio resources
achieving 20% performance gains against benchmarks, while requiring less than
half of the number of acquisition rounds.

</details>


### [201] [Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning](https://arxiv.org/abs/2505.05226)
*Amir Rezaei Balef,Claire Vernade,Katharina Eggensperger*

Main category: cs.LG

TL;DR: 提出了一种名为MaxUCB的最大k臂老虎机方法，用于解决AutoML中的组合算法选择和超参数优化（CASH）问题，旨在平衡模型探索和超参数优化。


<details>
  <summary>Details</summary>
Motivation: AutoML中的组合算法选择和超参数优化（CASH）是一个具有挑战性的资源分配问题。现有最大k臂老虎机方法通常假设重尾奖励分布，可能不适用于CASH中常见的轻尾有界奖励分布。

Method: 提出了一种名为MaxUCB的最大k臂老虎机方法。该方法特别针对CASH问题中常见的轻尾有界奖励分布进行设计，以权衡不同模型类别的探索和超参数优化。

Result: 在四个标准AutoML基准上进行的理论和实证评估表明，MaxUCB方法优于现有方法。

Conclusion: MaxUCB为AutoML中的CASH问题提供了一种有效的解决方案，特别是在奖励分布为轻尾有界的情况下，其性能优于先前的方法。

Abstract: The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a
challenging resource allocation problem in the field of AutoML. We propose
MaxUCB, a max $k$-armed bandit method to trade off exploring different model
classes and conducting hyperparameter optimization. MaxUCB is specifically
designed for the light-tailed and bounded reward distributions arising in this
setting and, thus, provides an efficient alternative compared to classic max
$k$-armed bandit methods assuming heavy-tailed reward distributions. We
theoretically and empirically evaluate our method on four standard AutoML
benchmarks, demonstrating superior performance over prior approaches.

</details>


### [202] [Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning](https://arxiv.org/abs/2505.05237)
*Ruxue Shi,Hengrui Gu,Hangting Ye,Yiwei Dai,Xu Shen,Xin Wang*

Main category: cs.LG

TL;DR: Latte 是一种新的小样本表格学习框架，它在训练时从大语言模型中提取知识，以优化下游模型，并在多个基准测试中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的小样本表格学习方法在利用大语言模型知识时，要么引入测试时延迟，要么导致不可靠的特征工程。本研究旨在克服这些限制。

Method: 提出了 Latte 框架，在训练阶段从大语言模型中提取潜在先验知识，以优化下游表格学习模型。该方法支持跨不同特征值的信息加权融合，减少过拟合风险，并兼容无监督预训练范式以利用无标签样本。

Result: 在多个小样本表格学习基准测试上的大量实验表明，Latte 表现优越，达到了该领域的顶尖水平。

Conclusion: Latte 框架通过在训练时提取和利用大语言模型的知识，有效地解决了现有方法的局限性，提升了在有限标签数据下表格学习的性能和泛化能力。

Abstract: Few-shot tabular learning, in which machine learning models are trained with
a limited amount of labeled data, provides a cost-effective approach to
addressing real-world challenges. The advent of Large Language Models (LLMs)
has sparked interest in leveraging their pre-trained knowledge for few-shot
tabular learning. Despite promising results, existing approaches either rely on
test-time knowledge extraction, which introduces undesirable latency, or
text-level knowledge, which leads to unreliable feature engineering. To
overcome these limitations, we propose Latte, a training-time knowledge
extraction framework that transfers the latent prior knowledge within LLMs to
optimize a more generalized downstream model. Latte enables general
knowledge-guided downstream tabular learning, facilitating the weighted fusion
of information across different feature values while reducing the risk of
overfitting to limited labeled data. Furthermore, Latte is compatible with
existing unsupervised pre-training paradigms and effectively utilizes available
unlabeled samples to overcome the performance limitations imposed by an
extremely small labeled dataset. Extensive experiments on various few-shot
tabular learning benchmarks demonstrate the superior performance of Latte,
establishing it as a state-of-the-art approach in this domain

</details>


### [203] [Enhancing Treatment Effect Estimation via Active Learning: A Counterfactual Covering Perspective](https://arxiv.org/abs/2505.05242)
*Hechuan Wen,Tong Chen,Mingming Gong,Li Kheng Chai,Shazia Sadiq,Hongzhi Yin*

Main category: cs.LG

TL;DR: 本文提出了一种名为FCCM的主动学习方法，通过最大化事实和反事实覆盖来解决治疗效果估计中标注成本高、数据不足的问题，并在合成数据集上显示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的治疗效果估计算法在处理标签不足的训练集时效果有限，主要原因是治疗效果的标注成本（如肿瘤成像或活检）高昂。因此，在有限的标注预算下主动获取高质量的标注数据至关重要。

Method: 研究首先在主动学习背景下对问题进行理论分析，推导出“事实覆盖半径”和“反事实覆盖半径”作为决定风险上界的关键度量。为减小此上界，提出了一种贪婪半径缩减算法。为适应更真实的数据分布，进一步提出了FCCM方法，将优化目标转化为最大化“事实覆盖”和“反事实覆盖”，以确保数据获取过程中的有效半径缩减。

Result: 在全合成和半合成数据集上的基准测试表明，FCCM方法优于其他基线方法。

Conclusion: 该研究提出的FCCM方法能够有效地进行数据高效的治疗效果估计，通过主动学习策略优化数据采集，尤其适用于标注数据稀缺的场景。

Abstract: Although numerous complex algorithms for treatment effect estimation have
been developed in recent years, their effectiveness remains limited when
handling insufficiently labeled training sets due to the high cost of labeling
the effect after treatment, e.g., expensive tumor imaging or biopsy procedures
needed to evaluate treatment effects. Therefore, it becomes essential to
actively incorporate more high-quality labeled data, all while adhering to a
constrained labeling budget. To enable data-efficient treatment effect
estimation, we formalize the problem through rigorous theoretical analysis
within the active learning context, where the derived key measures --
\textit{factual} and \textit{counterfactual covering radius} determine the risk
upper bound. To reduce the bound, we propose a greedy radius reduction
algorithm, which excels under an idealized, balanced data distribution. To
generalize to more realistic data distributions, we further propose FCCM, which
transforms the optimization objective into the \textit{Factual} and
\textit{Counterfactual Coverage Maximization} to ensure effective radius
reduction during data acquisition. Furthermore, benchmarking FCCM against other
baselines demonstrates its superiority across both fully synthetic and
semi-synthetic datasets.

</details>


### [204] [Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration](https://arxiv.org/abs/2505.05262)
*Andreas Kontogiannis,Konstantinos Papathanasiou,Yi Shen,Giorgos Stamou,Michael M. Zavlanos,George Vouros*

Main category: cs.LG

TL;DR: 该论文提出了一种新的多智能体强化学习状态建模框架（SMPE算法），通过智能体推断非观测状态的信念表示，并采用对抗性探索策略，以提升在分布式部分可观测且无通信环境中的合作能力。


<details>
  <summary>Details</summary>
Motivation: 解决在分布式、部分可观测且无通信能力的多智能体环境中，智能体学习合作的挑战，特别是如何从个体观测中推断有效的状态表示以增强探索和协作。

Method: 提出了一种新的状态建模框架，智能体在此框架下推断关于非观测状态的有意义的信念表示，并过滤冗余信息。基于此框架，提出了SMPE算法，该算法通过将信念显式整合到策略网络，并采用对抗性探索策略隐式提升策略判别能力。

Result: 实验证明，SMPE算法在MPE、LBF和RWARE等基准测试中的复杂完全合作任务上，性能优于当前最先进的多智能体强化学习算法。

Conclusion: 所提出的SMPE算法及其状态建模框架能够有效提升多智能体在无通信、部分可观测环境下的合作性能，通过改进的状态表示和探索机制，使智能体能学习更优的合作策略。

Abstract: Learning to cooperate in distributed partially observable environments with
no communication abilities poses significant challenges for multi-agent deep
reinforcement learning (MARL). This paper addresses key concerns in this
domain, focusing on inferring state representations from individual agent
observations and leveraging these representations to enhance agents'
exploration and collaborative task execution policies. To this end, we propose
a novel state modelling framework for cooperative MARL, where agents infer
meaningful belief representations of the non-observable state, with respect to
optimizing their own policies, while filtering redundant and less informative
joint state information. Building upon this framework, we propose the MARL SMPE
algorithm. In SMPE, agents enhance their own policy's discriminative abilities
under partial observability, explicitly by incorporating their beliefs into the
policy network, and implicitly by adopting an adversarial type of exploration
policies which encourages agents to discover novel, high-value states while
improving the discriminative abilities of others. Experimentally, we show that
SMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative
tasks from the MPE, LBF, and RWARE benchmarks.

</details>


### [205] [MTL-UE: Learning to Learn Nothing for Multi-Task Learning](https://arxiv.org/abs/2505.05279)
*Yi Yu,Song Xia,Siyuan Yang,Chenqi Kong,Wenhan Yang,Shijian Lu,Yap-Peng Tan,Alex C. Kot*

Main category: cs.LG

TL;DR: 本文提出了MTL-UE，首个针对多任务学习（MTL）数据和模型的不可学习样本生成统一框架，以保护多任务数据不被未授权使用。


<details>
  <summary>Details</summary>
Motivation: 现有的不可学习策略主要关注单任务学习（STL）模型，而多任务学习（MTL）数据和模型在通用和基础模型中日益重要，却在不可学习策略研究中被忽视。

Method: 提出了MTL-UE框架：1. 设计了基于生成器的结构，引入标签先验和类级特征嵌入以提升攻击性能。2. 结合了任务内和任务间嵌入正则化，以增加类间分离度、抑制类内方差，从而增强攻击鲁棒性。3. 该框架通用性强，支持MTL中的密集预测任务，且具有即插即用性。

Result: 大量实验表明，MTL-UE在4个MTL数据集、3种基础不可学习方法、5种模型骨干网络和5种MTL任务加权策略上均一致地取得了优越的攻击性能。

Conclusion: MTL-UE是首个为多任务数据和MTL模型生成不可学习样本的统一框架，能有效阻止模型从未授权的多任务数据中学习，展现了卓越的攻击效果和广泛的适用性。

Abstract: Most existing unlearnable strategies focus on preventing unauthorized users
from training single-task learning (STL) models with personal data.
Nevertheless, the paradigm has recently shifted towards multi-task data and
multi-task learning (MTL), targeting generalist and foundation models that can
handle multiple tasks simultaneously. Despite their growing importance, MTL
data and models have been largely neglected while pursuing unlearnable
strategies. This paper presents MTL-UE, the first unified framework for
generating unlearnable examples for multi-task data and MTL models. Instead of
optimizing perturbations for each sample, we design a generator-based structure
that introduces label priors and class-wise feature embeddings which leads to
much better attacking performance. In addition, MTL-UE incorporates intra-task
and inter-task embedding regularization to increase inter-class separation and
suppress intra-class variance which enhances the attack robustness greatly.
Furthermore, MTL-UE is versatile with good supports for dense prediction tasks
in MTL. It is also plug-and-play allowing integrating existing
surrogate-dependent unlearnable methods with little adaptation. Extensive
experiments show that MTL-UE achieves superior attacking performance
consistently across 4 MTL datasets, 3 base UE methods, 5 model backbones, and 5
MTL task-weighting strategies.

</details>


### [206] [Performance Estimation in Binary Classification Using Calibrated Confidence](https://arxiv.org/abs/2505.05295)
*Juhani Kivimäki,Jakub Białek,Wojtek Kuberski,Jukka K. Nurminen*

Main category: cs.LG

TL;DR: 提出了一种无需真实标签即可估计二元分类模型混淆矩阵中任意指标（如准确率、精确率、召回率、F1值）的新方法CBPE。


<details>
  <summary>Details</summary>
Motivation: 传统的模型性能监控依赖真实标签，但标签获取常有延迟或不可行。现有无标签性能估计方法主要关注准确率，而其他重要指标（如精确率、召回率、F1值）未得到充分研究。

Method: CBPE方法将混淆矩阵的元素视为随机变量，并利用模型校准后的置信度得分来估计这些元素的分布。进而，目标评价指标也被视为随机变量，其完整概率分布可以从估计的混淆矩阵中推导出来。

Result: CBPE能够为多种二元分类指标（特别是准确率、精确率、召回率和F1值）提供估计，这些估计具有强有力的理论保证和有效的置信区间。

Conclusion: CBPE填补了无标签情况下估计多种二元分类性能指标的空白，为模型监控提供了更全面的工具。

Abstract: Model monitoring is a critical component of the machine learning lifecycle,
safeguarding against undetected drops in the model's performance after
deployment. Traditionally, performance monitoring has required access to ground
truth labels, which are not always readily available. This can result in
unacceptable latency or render performance monitoring altogether impossible.
Recently, methods designed to estimate the accuracy of classifier models
without access to labels have shown promising results. However, there are
various other metrics that might be more suitable for assessing model
performance in many cases. Until now, none of these important metrics has
received similar interest from the scientific community. In this work, we
address this gap by presenting CBPE, a novel method that can estimate any
binary classification metric defined using the confusion matrix. In particular,
we choose four metrics from this large family: accuracy, precision, recall, and
F$_1$, to demonstrate our method. CBPE treats the elements of the confusion
matrix as random variables and leverages calibrated confidence scores of the
model to estimate their distributions. The desired metric is then also treated
as a random variable, whose full probability distribution can be derived from
the estimated confusion matrix. CBPE is shown to produce estimates that come
with strong theoretical guarantees and valid confidence intervals.

</details>


### [207] [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org/abs/2505.05315)
*Yuhui Xu,Hanze Dong,Lei Wang,Doyen Sahoo,Junnan Li,Caiming Xiong*

Main category: cs.LG

TL;DR: Elastic Reasoning 是一种新框架，通过将推理分为“思考”和“解决”两个独立预算的阶段，实现可扩展、高效且在资源受限时更可靠的思维链。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在生成长思维链（CoT）以解决复杂任务时表现优异，但其输出长度不受控制，这在对token数、延迟或计算资源有严格预算的实际部署中构成了重大挑战。

Method: 提出“弹性推理”（Elastic Reasoning）框架，将推理明确分为“思考”和“解决方案”两个阶段，并为它们独立分配预算。在测试时，优先保证解决方案部分的完整性。通过引入一种轻量级的预算约束rollout策略（集成到GRPO中）进行训练，使模型能适应被截断的思考过程，并泛化到未见过的预算约束。

Result: 在数学（AIME, MATH500）和编程（LiveCodeBench, Codeforces）基准测试上，弹性推理在严格预算约束下表现稳健，训练成本显著低于基线方法。即使在无约束设置下，它也能产生更简洁高效的推理过程。

Conclusion: 弹性推理为大规模可控推理的挑战提供了一个有原则且实用的解决方案。

Abstract: Large reasoning models (LRMs) have achieved remarkable progress on complex
tasks by generating extended chains of thought (CoT). However, their
uncontrolled output lengths pose significant challenges for real-world
deployment, where inference-time budgets on tokens, latency, or compute are
strictly constrained. We propose Elastic Reasoning, a novel framework for
scalable chain of thoughts that explicitly separates reasoning into two
phases--thinking and solution--with independently allocated budgets. At test
time, Elastic Reasoning prioritize that completeness of solution segments,
significantly improving reliability under tight resource constraints. To train
models that are robust to truncated thinking, we introduce a lightweight
budget-constrained rollout strategy, integrated into GRPO, which teaches the
model to reason adaptively when the thinking process is cut short and
generalizes effectively to unseen budget constraints without additional
training. Empirical results on mathematical (AIME, MATH500) and programming
(LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning
performs robustly under strict budget constraints, while incurring
significantly lower training cost than baseline methods. Remarkably, our
approach also produces more concise and efficient reasoning even in
unconstrained settings. Elastic Reasoning offers a principled and practical
solution to the pressing challenge of controllable reasoning at scale.

</details>


### [208] [Nearly Optimal Sample Complexity for Learning with Label Proportions](https://arxiv.org/abs/2505.05355)
*Robert Busa-Fekete,Travis Dick,Claudio Gentile,Haim Kaplan,Tomer Koren,Uri Stemmer*

Main category: cs.LG

TL;DR: 本文研究标签比例学习 (LLP) 问题，即在训练数据被分组成包、仅知晓各包标签汇总比例的情况下，实现个体样本级别的低遗憾。


<details>
  <summary>Details</summary>
Motivation: 在仅知晓标签比例的部分信息设定下，如何有效学习个体样本的预测模型，并提升样本效率和模型性能，特别是在样本复杂度对包大小的依赖方面，现有研究尚有改进空间。

Method: 采用精心设计的经验风险最小化 (ERM) 和随机梯度下降 (SGD) 算法变体，并结合了特设的方差缩减技术来分析和解决LLP问题。

Result: 理论上，获得了LLP在平方损失下的样本复杂度界限，该界限基本最优，并改进了样本复杂度对包大小的依赖性。实验上，在多个数据集上验证了算法的有效性，相比近期基线方法，以更少的样本实现了更高的准确率。

Conclusion: 该研究为LLP问题提供了更优的样本复杂度和有效的算法方案，在理论和实证上均显示出对现有方法的改进，特别是在样本效率和对包大小依赖性方面。

Abstract: We investigate Learning from Label Proportions (LLP), a partial information
setting where examples in a training set are grouped into bags, and only
aggregate label values in each bag are available. Despite the partial
observability, the goal is still to achieve small regret at the level of
individual examples. We give results on the sample complexity of LLP under
square loss, showing that our sample complexity is essentially optimal. From an
algorithmic viewpoint, we rely on carefully designed variants of Empirical Risk
Minimization, and Stochastic Gradient Descent algorithms, combined with ad hoc
variance reduction techniques. On one hand, our theoretical results improve in
important ways on the existing literature on LLP, specifically in the way the
sample complexity depends on the bag size. On the other hand, we validate our
algorithmic solutions on several datasets, demonstrating improved empirical
performance (better accuracy for less samples) against recent baselines.

</details>


### [209] [Denoising Diffusion Probabilistic Models for Coastal Inundation Forecasting](https://arxiv.org/abs/2505.05381)
*Kazi Ashik Islam,Zakaria Mehrab,Mahantesh Halappanavar,Henning Mortveit,Sridhar Katragadda,Jon Derek Loftis,Madhav Marathe*

Main category: cs.LG

TL;DR: 提出了一种名为 DIFF-FLOOD 的基于去噪扩散模型的概率时空预测方法，用于更准确地预测沿海洪水。


<details>
  <summary>Details</summary>
Motivation: 沿海洪水对社区构成重大风险，迫切需要快速准确的预报方法来减轻潜在损害。

Method: DIFF-FLOOD 是一种基于去噪扩散模型的概率时空预测方法。它同时考虑空间（邻近位置的淹没水平和数字高程数据）和时间（历史淹没数据和协变量）背景，并利用卷积神经网络和交叉注意力机制捕捉时空动态。

Result: 在弗吉尼亚东海岸的沿海淹没数据上进行的测试表明，DIFF-FLOOD 在预测性能（两项性能指标提升了6%至64%）和可扩展性方面均优于现有预测方法。

Conclusion: DIFF-FLOOD 是一种有效的沿海洪水预测新方法，相较于现有方法具有更优的预测性能和可扩展性。

Abstract: Coastal flooding poses significant risks to communities, necessitating fast
and accurate forecasting methods to mitigate potential damage. To approach this
problem, we present DIFF-FLOOD, a probabilistic spatiotemporal forecasting
method designed based on denoising diffusion models. DIFF-FLOOD predicts
inundation level at a location by taking both spatial and temporal context into
account. It utilizes inundation levels at neighboring locations and digital
elevation data as spatial context. Inundation history from a context time
window, together with additional co-variates are used as temporal context.
Convolutional neural networks and cross-attention mechanism are then employed
to capture the spatiotemporal dynamics in the data. We trained and tested
DIFF-FLOOD on coastal inundation data from the Eastern Shore of Virginia, a
region highly impacted by coastal flooding. Our results show that, DIFF-FLOOD
outperforms existing forecasting methods in terms of prediction performance (6%
to 64% improvement in terms of two performance metrics) and scalability.

</details>


### [210] [CART-ELC: Oblique Decision Tree Induction via Exhaustive Search](https://arxiv.org/abs/2505.05402)
*Andrew D. Laack*

Main category: cs.LG

TL;DR: 该研究提出了一种新的斜向决策树算法CART-ELC，通过在受限超平面集上进行穷举搜索，在小数据集上提高了分类性能并生成了更简单的树。


<details>
  <summary>Details</summary>
Motivation: 传统的斜向决策树构建方法因依赖穷举搜索而面临计算挑战，限制了其广泛应用。该研究旨在探索一种更高效的斜向决策树构建方法。

Method: 提出了一种名为CART-ELC（分类与回归树 - 穷举线性组合）的新算法，该算法通过在受限的超平面集合上执行穷举搜索来生成斜向决策树。

Result: CART-ELC在小型数据集上持续获得有竞争力的性能，相对于现有决策树归纳算法，其分类准确性常有统计学上的显著改进，并且经常产生更浅、更简单、因此更易于解释的树。

Conclusion: CART-ELC算法在小型数据集上表现出色，能够提高分类准确性并生成更简洁、更易解释的斜向决策树，是一种有前景的方法。

Abstract: Oblique decision trees have attracted attention due to their potential for
improved classification performance over traditional axis-aligned decision
trees. However, methods that rely on exhaustive search to find oblique splits
face computational challenges. As a result, they have not been widely explored.
We introduce a novel algorithm, Classification and Regression Tree - Exhaustive
Linear Combinations (CART-ELC), for inducing oblique decision trees that
performs an exhaustive search on a restricted set of hyperplanes. We then
investigate the algorithm's computational complexity and its predictive
capabilities. Our results demonstrate that CART-ELC consistently achieves
competitive performance on small datasets, often yielding statistically
significant improvements in classification accuracy relative to existing
decision tree induction algorithms, while frequently producing shallower,
simpler, and thus more interpretable trees.

</details>


### [211] [Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It](https://arxiv.org/abs/2505.05409)
*Marvin F. da Silva,Felix Dangel,Sageev Oore*

Main category: cs.LG

TL;DR: 针对现有尖锐度指标无法准确预测Transformer泛化能力的问题，本文提出一种考虑Transformer对称性的新尖锐度定义（测地线尖锐度），在商流形上进行度量，成功恢复了尖锐度与泛化能力的强相关性。


<details>
  <summary>Details</summary>
Motivation: 传统的尖锐度（sharpness）概念能很好地预测MLP和CNN等架构的泛化能力，但最近的研究表明，对于Transformer模型，平坦度（尖锐度的反面）与泛化能力之间的相关性很弱。研究认为这是因为现有方法未能充分考虑Transformer注意力机制中固有的丰富对称性。

Method: 1. 指出Transformer的对称性（尤其在注意力机制中）会导致参数空间中存在损失不变的方向，使得传统尖锐度度量失效。
2. 提出尖锐度必须在剔除了这些对称性影响的商流形（quotient manifold）上重新定义。
3. 利用黎曼几何工具，在对称性校正的商流形上，通过测地线球（geodesic ball）来定义一个通用的尖锐度概念。
4. 实践中，通过近似测地线来计算该尖锐度，并强调包含高阶近似项对于恢复与泛化能力的关联至关重要（一阶近似对应现有自适应尖锐度）。

Result: 在对角网络和合成数据上的实验，以及在真实世界的Transformer模型上进行的文本和图像分类任务实验均表明，本文提出的测地线尖锐度与模型的泛化能力展现出强相关性。

Conclusion: 通过在考虑了Transformer对称性的商流形上重新定义尖锐度，并使用包含高阶近似的测地线球进行度量，可以有效地预测Transformer模型的泛化能力，解决了现有尖锐度指标在该架构上的不足。

Abstract: The concept of sharpness has been successfully applied to traditional
architectures like MLPs and CNNs to predict their generalization. For
transformers, however, recent work reported weak correlation between flatness
and generalization. We argue that existing sharpness measures fail for
transformers, because they have much richer symmetries in their attention
mechanism that induce directions in parameter space along which the network or
its loss remain identical. We posit that sharpness must account fully for these
symmetries, and thus we redefine it on a quotient manifold that results from
quotienting out the transformer symmetries, thereby removing their ambiguities.
Leveraging tools from Riemannian geometry, we propose a fully general notion of
sharpness, in terms of a geodesic ball on the symmetry-corrected quotient
manifold. In practice, we need to resort to approximating the geodesics. Doing
so up to first order yields existing adaptive sharpness measures, and we
demonstrate that including higher-order terms is crucial to recover correlation
with generalization. We present results on diagonal networks with synthetic
data, and show that our geodesic sharpness reveals strong correlation for
real-world transformers on both text and image classification tasks.

</details>


### [212] [DPQ-HD: Post-Training Compression for Ultra-Low Power Hyperdimensional Computing](https://arxiv.org/abs/2505.05413)
*Nilesh Prasad Pandey,Shriniwas Kulkarni,David Wang,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: 提出了一种名为DPQ-HD的HDC后训练压缩算法，无需再训练即可大幅降低内存和计算开销，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 当前HDC应用在边缘设备上面临高计算和内存需求的挑战，而现有压缩方法常需再训练，成本高且不实用。

Method: 1. DPQ-HD算法：结合分解（Decomposition）、剪枝（Pruning）和量化（Quantization）的后训练压缩技术，用于端到端HDC系统。2. 节能推理方法：通过渐进评估相似度分数（如余弦相似度）和提前退出机制来减少计算。

Result: DPQ-HD在图像和图分类任务中内存减少高达20-100倍，精度仅下降1-2%。与现有后训练压缩方法相比性能更优，且与基于再训练的先进技术相当或更好，同时优化时间减少高达100倍，在微控制器上的推理速度提升高达56倍。

Conclusion: DPQ-HD是一种有效的HDC后训练压缩方法，无需再训练即可显著降低内存和计算需求，提升边缘设备推理效率，同时保持高准确率。

Abstract: Hyperdimensional Computing (HDC) is emerging as a promising approach for edge
AI, offering a balance between accuracy and efficiency. However, current
HDC-based applications often rely on high-precision models and/or encoding
matrices to achieve competitive performance, which imposes significant
computational and memory demands, especially for ultra-low power devices. While
recent efforts use techniques like precision reduction and pruning to increase
the efficiency, most require retraining to maintain performance, making them
expensive and impractical. To address this issue, we propose a novel Post
Training Compression algorithm, Decomposition-Pruning-Quantization (DPQ-HD),
which aims at compressing the end-to-end HDC system, achieving near floating
point performance without the need of retraining. DPQ-HD reduces computational
and memory overhead by uniquely combining the above three compression
techniques and efficiently adapts to hardware constraints. Additionally, we
introduce an energy-efficient inference approach that progressively evaluates
similarity scores such as cosine similarity and performs early exit to reduce
the computation, accelerating prediction inference while maintaining accuracy.
We demonstrate that DPQ-HD achieves up to 20-100x reduction in memory for image
and graph classification tasks with only a 1-2% drop in accuracy compared to
uncompressed workloads. Lastly, we show that DPQ-HD outperforms the existing
post-training compression methods and performs better or at par with
retraining-based state-of-the-art techniques, requiring significantly less
overall optimization time (up to 100x) and faster inference (up to 56x) on a
microcontroller

</details>


### [213] [RL-DAUNCE: Reinforcement Learning-Driven Data Assimilation with Uncertainty-Aware Constrained Ensembles](https://arxiv.org/abs/2505.05452)
*Pouria Behnoudfar,Nan Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习的新型数据同化方法RL-DAUNCE。该方法通过将智能体设计为集合成员并采用原始-对偶优化策略，有效地整合了物理约束，并能量化不确定性。在应用于马登-朱利安振荡时，RL-DAUNCE表现优于标准EnKF，并以更低的计算成本达到了与约束EnKF相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统数据同化方法（如标准EnKF）在处理具有强非高斯特性和复杂物理约束的地球科学问题时面临挑战，常因违反物理约束而失效。强化学习（RL）的序贯决策框架为数据同化提供了新思路，但需解决如何有效融入物理约束、量化不确定性并保持计算效率的问题。

Method: 开发了RL-DAUNCE方法。该方法的核心创新包括：1) 将RL智能体设计为与传统数据同化中的集合成员一一对应，以继承机器学习的计算效率并进行不确定性量化；2) 利用“集合即智能体”的设计促进物理约束的实施；3) 采用原始-对偶优化策略，通过动态惩罚奖励函数来确保约束满足，并通过约束RL动作空间来尊重状态变量边界。

Result: RL-DAUNCE在马登-朱利安振荡（MJO）的应用中，性能显著优于因违反物理约束而失效的标准集合卡尔曼滤波器（EnKF）。与约束EnKF相比，RL-DAUNCE在恢复间歇信号、捕捉极端事件和量化不确定性方面达到了相当的性能，同时计算成本大幅降低。

Conclusion: RL-DAUNCE是一种有前景的新型数据同化方法，它成功地将强化学习与物理约束相结合，在保证物理一致性的前提下提高了效率和准确性。该方法为处理复杂、非高斯且受多重物理约束的地球系统数据同化问题提供了强大的工具。

Abstract: Machine learning has become a powerful tool for enhancing data assimilation.
While supervised learning remains the standard method, reinforcement learning
(RL) offers unique advantages through its sequential decision-making framework,
which naturally fits the iterative nature of data assimilation by dynamically
balancing model forecasts with observations. We develop RL-DAUNCE, a new
RL-based method that enhances data assimilation with physical constraints
through three key aspects. First, RL-DAUNCE inherits the computational
efficiency of machine learning while it uniquely structures its agents to
mirror ensemble members in conventional data assimilation methods. Second,
RL-DAUNCE emphasizes uncertainty quantification by advancing multiple ensemble
members, moving beyond simple mean-state optimization. Third, RL-DAUNCE's
ensemble-as-agents design facilitates the enforcement of physical constraints
during the assimilation process, which is crucial to improving the state
estimation and subsequent forecasting. A primal-dual optimization strategy is
developed to enforce constraints, which dynamically penalizes the reward
function to ensure constraint satisfaction throughout the learning process.
Also, state variable bounds are respected by constraining the RL action space.
Together, these features ensure physical consistency without sacrificing
efficiency. RL-DAUNCE is applied to the Madden-Julian Oscillation, an
intermittent atmospheric phenomenon characterized by strongly non-Gaussian
features and multiple physical constraints. RL-DAUNCE outperforms the standard
ensemble Kalman filter (EnKF), which fails catastrophically due to the
violation of physical constraints. Notably, RL-DAUNCE matches the performance
of constrained EnKF, particularly in recovering intermittent signals, capturing
extreme events, and quantifying uncertainties, while requiring substantially
less computational effort.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [214] [Network Digital Twin for Route Optimization in 5G/B5G Transport Slicing with What-If Analysis](https://arxiv.org/abs/2505.04879)
*Rebecca Aben-Athar,Heitor Anglada,Lucas Costa,João Albuquerque,Abrahão Ferreira,Cristiano Bonato Both,Kleber Cardoso,Silvia Lins,Andrey Silva,Glauco Gonçalves,Ilan Correa,Aldebaro Klautau*

Main category: cs.NI

TL;DR: 本文设计了一个基于网络数字孪生（NDT）的实验平台，用于5G/B5G传输网络中的动态路由优化，并通过图神经网络（GNN）实现了高精度的网络性能预测。


<details>
  <summary>Details</summary>
Motivation: 5G/B5G网络服务需求多样化，对服务质量（QoS）保障提出了更高要求，传输网络面临有效管理复杂流量模式的挑战。网络数字孪生（NDT）为在实际部署前测试配置和算法提供了有前景的解决方案。

Method: 设计了一个包含网络数字孪生（NDT）的传输网络域实验平台，该NDT由图神经网络（GNN）构成，与虚拟副本和推荐系统同步，进行“假设分析”，以解决5G/B5G场景下的动态路由优化问题。

Result: 在包含8、16和30个节点的三种不同网络拓扑中评估了该NDT。对于URLLC和eMBB切片，其延迟预测与解决方案实施后的实际延迟相比，获得了较低的MAPE值，表明了高准确性。

Conclusion: 该解决方案在生成关于特定解决方案实施后网络性能的精确见解方面是有效的，证明了NDT在智能决策和动态路由优化方面的潜力。

Abstract: The advent of fifth-generation (5G) and Beyond 5G (B5G) networks introduces
diverse service requirements, from ultra-low latency to high bandwidth,
demanding dynamic monitoring and advanced solutions to ensure Quality of
Service (QoS). The transport network - responsible for interconnecting the
radio access network and core networks - will increasingly face challenges in
efficiently managing complex traffic patterns. The Network Digital Twin (NDT)
concept emerges as a promising solution for testing configurations and
algorithms in a virtual network before real-world deployment. In this context,
this work designs an experimental platform with NDT in a transport network
domain, synchronizing with the virtual counterpart and a recommendation system
for what-if analysis, enabling intelligent decision-making for dynamic route
optimization problems in 5G/B5G scenarios. Our NDT, composed of a Graph Neural
Network (GNN), was evaluated across three different network topologies
consisting of 8, 16, and 30 nodes. It achieved lower MAPE values for URLLC and
eMBB slices, comparing latency predictions with actual latency after the
solution implementation. These values indicate high accuracy, demonstrating the
solution's effectiveness in generating precise insights into network
performance if a particular solution were implemented.

</details>


### [215] [Cross-Problem Solving for Network Optimization: Is Problem-Aware Learning the Key?](https://arxiv.org/abs/2505.05067)
*Ruihuai Liang,Bo Yang,Pengyu Chen,Xuelin Cao,Zhiwen Yu,H. Vincent Poor,Chau Yuen*

Main category: cs.NI

TL;DR: 该论文提出了一种问题感知扩散（PAD）模型，通过问题感知学习框架实现对不同网络优化问题的泛化能力，显著提升解的质量和可行性。


<details>
  <summary>Details</summary>
Motivation: 传统网络资源分配方法在处理多样化和未预见的优化问题时，因缺乏对问题特征的理解而耗时且不灵活，需要一种能够跨问题泛化的新方法。

Method: 提出了问题感知扩散（PAD）模型，该模型将优化问题的数学公式编码为词元级嵌入，使模型能够理解和适应问题结构。同时，设计了一个辅助的约束感知模块来进一步确保解的有效性。

Result: 在六种不同的网络优化问题上的实验表明，PAD模型能够很好地泛化到未见过的问题，并显著提高解的质量和可行性。

Conclusion: 问题感知学习为构建智能网络运营和资源管理的通用求解器提供了一种有前景的途径。

Abstract: As intelligent network services continue to diversify, ensuring efficient and
adaptive resource allocation in edge networks has become increasingly critical.
Yet the wide functional variations across services often give rise to new and
unforeseen optimization problems, rendering traditional manual modeling and
solver design both time-consuming and inflexible. This limitation reveals a key
gap between current methods and human solving - the inability to recognize and
understand problem characteristics. It raises the question of whether
problem-aware learning can bridge this gap and support effective cross-problem
generalization. To answer this question, we propose a problem-aware diffusion
(PAD) model, which leverages a problem-aware learning framework to enable
cross-problem generalization. By explicitly encoding the mathematical
formulations of optimization problems into token-level embeddings, PAD empowers
the model to understand and adapt to problem structures. Extensive experiments
across six diverse network optimization problems show that PAD generalizes well
to unseen problems while significantly improving solution quality and
feasibility. Meanwhile, an auxiliary constraint-aware module is designed to
enforce solution validity further. The experiments reveal that problem-aware
learning is promising for building general-purpose solvers for intelligent
network operation and resource management. Our code is open source at
https://github.com/qiyu3816/PAD.

</details>


### [216] [Temporal Spectrum Analysis for Multi-Constellation Space Domain Awareness](https://arxiv.org/abs/2505.05149)
*Mansour Naslcheraghi,Gunes Karabulut-Kurt*

Main category: cs.NI

TL;DR: 论文提出了一种时间谱分析（TSA）方法，通过考虑空间物体的真实动态来分析地空网络的结构及其相互作用。


<details>
  <summary>Details</summary>
Motivation: 真实世界的空间动态为空间态势感知系统带来了复杂性，需要有效的方法来分析和控制空间资产，并理解网络结构（如孤立和主导站点）。

Method: 提出一种时间谱分析（TSA）方案，该方案纳入真实世界参数（包括空间物体的实际动态），以卫星的时间谱为关键设计元素来分析地空网络结构，并使用TSA研究多星座间的潜在相互作用，通过全面的真实世界仿真来量化网络结构。

Result: 数值结果显示，每颗卫星的时间谱会影响星座内部和星座间的网络结构，包括地面站与星座之间的相互作用。

Conclusion: 时间谱分析（TSA）方案能够有效地揭示考虑了真实动态的地空网络结构，并量化星座内部及星座间的相互作用，为空间态势感知提供了新的分析视角。

Abstract: Space Domain Awareness (SDA) system has different major aspects including
continues and robust awareness from the network that is crucial for an
efficient control over all actors in space. The observability of the space
assets on the other hand requires efficient analysis on when and how observed
space objects can be controlled. This becomes crucial when real-world spatial
dynamics are taken into account as it introduces complexities into the system.
The real-world dynamics can reveal the structure of the network including
isolated and dominant stations. We propose a Temporal Spectrum Analysis (TSA)
scheme that takes into account a set of real-world parameters including actual
dynamics of the objects in space to analyze the structure of a ground-space
network that inherits temporal spectrum as the key element of design. We study
the potential interactions between multiple constellations using TSA and
conduct a comprehensive real-world simulations to quantify the structure of the
network. Numerical results show how the temporal spectrum of each satellite
affects the intra- and inter-constellation network structure including
interactions between ground stations and constellations.

</details>


### [217] [In-Situ Model Validation for Continuous Processes Using In-Network Computing](https://arxiv.org/abs/2505.05184)
*Ike Kunze,Dominik Scheurenberg,Liam Tirpitz,Sandra Geisler,Klaus Wehrle*

Main category: cs.NI

TL;DR: 提出了一种基于网络内计算的工业控制模型持续在线验证方案（CIVIC），用于实时评估模型与实际过程行为的拟合度。


<details>
  <summary>Details</summary>
Motivation: 工业数字化发展需要精确的模型进行过程控制，但过程行为的较大变化对模型构成挑战，甚至可能损坏设备。随着受控过程和数据量的增加，对轻量级、快速反应的评估方案的需求也随之增加。

Method: CIVIC 方案通过监测相关过程变量，并将其与关于期望过程行为的先验知识进行比较，来检测不同的过程状态。这种检测可用于关闭过程或触发重新配置。

Result: 在基于 Intel Tofino 的交换机上对 CIVIC 进行了原型设计，并将其应用于实验室规模的水处理厂。结果表明，该方案可以实现高检测精度。

Conclusion: 证明了像 CIVIC 这样的监控系统对于工业控制模型的持续在线验证是可行且合理的。

Abstract: The advancing industrial digitalization enables evolved process control
schemes that rely on accurate models learned through data-driven approaches.
While they provide high control performance and are robust to smaller
deviations, a larger change in process behavior can pose significant
challenges, in the worst case even leading to a damaged process plant. Hence,
it is important to frequently assess the fit between the model and the actual
process behavior. As the number of controlled processes and associated data
volumes increase, the need for lightweight and fast reacting assessment
solutions also increases. In this paper, we propose CIVIC, an in-network
computing-based solution for Continuous In-situ Validation of Industrial
Control models. In short, CIVIC monitors relevant process variables and detects
different process states through comparison with a priori knowledge about the
desired process behavior. This detection can then be leveraged to, e.g., shut
down the process or trigger a reconfiguration. We prototype CIVIC on an Intel
Tofino-based switch and apply it to a lab-scale water treatment plant. Our
results show that we can achieve a high detection accuracy, proving that such
monitoring systems are feasible and sensible.

</details>


### [218] [SDR-RDMA: Software-Defined Reliability Architecture for Planetary Scale RDMA Communication](https://arxiv.org/abs/2505.05366)
*Mikhail Khalilov,Siyuan Shen,Marcin Chrapek,Tiancheng Chen,Kenji Nakano,Peter-Jan Gootzen,Salvatore Di Girolamo,Rami Nudelman,Gil Bloch,Sreevatsa Anantharamu,Mahmoud Elhaddad,Jithin Jose,Abdul Kabbani,Scott Moe,Konstantin Taranov,Zhuolong Yu,Jie Zhang,Nicola Mazzoletti,Torsten Hoefler*

Main category: cs.NI

TL;DR: 提出SDR-RDMA，一种软件定义的RDMA可靠性堆栈，通过SDR SDK和接收缓冲区位图实现自定义可靠性方案，并利用NVIDIA DPA硬件卸载达到线速，以解决跨数据中心RDMA的可靠性挑战。


<details>
  <summary>Details</summary>
Motivation: 跨数据中心的RDMA对高效分布式训练至关重要，但毫秒级延迟使可靠性层设计复杂。现有选择性重传算法在特定长途链路（如高丢包率、长距离、不同带宽）下效率低下，需要替代方案（如纠删码）。

Method: 提出SDR-RDMA，一个软件定义的RDMA可靠性堆栈。其核心是轻量级SDR SDK，它通过增加一个接收缓冲区位图来扩展标准点对点RDMA语义。该位图允许部分消息完成，使应用程序能实现针对特定部署定制的可靠性方案，同时将SDR后端卸载到NVIDIA的数据路径加速器（DPA）。

Result: SDR-RDMA通过将SDR后端卸载到NVIDIA DPA，实现了线速性能。SDR位图机制支持部分消息完成，允许应用程序实现自定义可靠性方案，同时保留了零拷贝RDMA的优势，从而实现了高效的数据中心间通信。

Conclusion: SDR-RDMA通过其软件定义的可靠性机制和硬件卸载能力，能够有效支持数据中心间的通信，并推动数据中心内部训练的可靠性创新，为RDMA在复杂网络环境下的应用提供了新的解决方案。

Abstract: RDMA is vital for efficient distributed training across datacenters, but
millisecond-scale latencies complicate the design of its reliability layer. We
show that depending on long-haul link characteristics, such as drop rate,
distance and bandwidth, the widely used Selective Repeat algorithm can be
inefficient, warranting alternatives like Erasure Coding. To enable such
alternatives on existing hardware, we propose SDR-RDMA, a software-defined
reliability stack for RDMA. Its core is a lightweight SDR SDK that extends
standard point-to-point RDMA semantics -- fundamental to AI networking stacks
-- with a receive buffer bitmap. SDR bitmap enables partial message completion
to let applications implement custom reliability schemes tailored to specific
deployments, while preserving zero-copy RDMA benefits. By offloading the SDR
backend to NVIDIA's Data Path Accelerator (DPA), we achieve line-rate
performance, enabling efficient inter-datacenter communication and advancing
reliability innovation for intra-datacenter training.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [219] [Cryptogenic stroke and migraine: using probabilistic independence and machine learning to uncover latent sources of disease from the electronic health record](https://arxiv.org/abs/2505.04631)
*Joshua W. Betts,John M. Still,Thomas A. Lasko*

Main category: stat.AP

TL;DR: 本研究利用电子健康记录(EHR)数据和机器学习模型，预测偏头痛患者10年内发生隐源性卒中(CS)的风险，并识别了药物干预和过敏性鼻炎等关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 偏头痛与隐源性卒中(CS)之间的关系特征不明，且缺乏减少相关风险的临床指南。

Method: 提出一种数据驱动方法，从电子健康记录(EHR)数据中提取概率独立的潜在风险源，构建偏头痛患者10年CS风险预测模型。这些风险源代表作用于EHR数据因果图的外部潜在变量。使用随机森林模型对这些风险源进行训练和预测。

Result: 随机森林模型在预测CS方面表现出良好准确性(ROC 0.771)，并识别出偏头痛患者中CS的十大最具预测性的风险源。研究表明，药物干预是降低CS风险的最重要因素，并发现与过敏性鼻炎相关的因素可能是CS的一个潜在致病源。

Conclusion: 该数据驱动方法能有效识别偏头痛患者CS的风险因素，强调了药物干预对降低风险的重要性，并指出过敏性鼻炎可能是一个潜在的CS致病因素。

Abstract: Migraine is a common but complex neurological disorder that doubles the
lifetime risk of cryptogenic stroke (CS). However, this relationship remains
poorly characterized, and few clinical guidelines exist to reduce this
associated risk. We therefore propose a data-driven approach to extract
probabilistically-independent sources from electronic health record (EHR) data
and create a 10-year risk-predictive model for CS in migraine patients. These
sources represent external latent variables acting on the causal graph
constructed from the EHR data and approximate root causes of CS in our
population. A random forest model trained on patient expressions of these
sources demonstrated good accuracy (ROC 0.771) and identified the top 10 most
predictive sources of CS in migraine patients. These sources revealed that
pharmacologic interventions were the most important factor in minimizing CS
risk in our population and identified a factor related to allergic rhinitis as
a potential causative source of CS in migraine patients.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [220] [BitHEP -- The Limits of Low-Precision ML in HEP](https://arxiv.org/abs/2504.03387)
*Claudius Krause,Daohan Wang,Ramon Winterhalder*

Main category: hep-ph

TL;DR: 评估新型BitNet架构在高能物理（HEP）应用中处理分类、回归和生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络复杂度增加，需要快速且内存高效的实现来缓解计算瓶颈。

Method: 在夸克-胶子鉴别、SMEFT参数估计和探测器模拟等HEP任务中，评估BitNet架构的性能，并与现有先进方法比较其效率和准确性。

Result: BitNet在分类任务中表现具有竞争力，但在回归和生成任务中的性能因网络大小和类型而异，并显示出一些局限性。

Conclusion: BitNet在HEP分类任务中表现良好，但在回归和生成任务方面仍有改进空间和潜在局限性。

Abstract: The increasing complexity of modern neural network architectures demands fast
and memory-efficient implementations to mitigate computational bottlenecks. In
this work, we evaluate the recently proposed BitNet architecture in HEP
applications, assessing its performance in classification, regression, and
generative modeling tasks. Specifically, we investigate its suitability for
quark-gluon discrimination, SMEFT parameter estimation, and detector
simulation, comparing its efficiency and accuracy to state-of-the-art methods.
Our results show that while BitNet consistently performs competitively in
classification tasks, its performance in regression and generation varies with
the size and type of the network, highlighting key limitations and potential
areas for improvement.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [221] [Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality](https://arxiv.org/abs/2505.05211)
*Chara Podimata*

Main category: cs.GT

TL;DR: 本文探讨了激励感知机器学习，即个体可策略性修改输入以影响算法决策的领域，并从鲁棒性、公平性和改进/因果性三个视角提出了一个统一框架。


<details>
  <summary>Details</summary>
Motivation: 在算法决策中，个体能够策略性地修改其输入以影响结果，这驱动了对设计能够抵抗“博弈”、保障公平并促进真正改进的机器学习系统的需求。

Method: 文章将激励感知机器学习研究分为三个视角：鲁棒性（设计抗“博弈”模型）、公平性（分析社会影响）和改进/因果性（识别导致真正改进的策略行为）。引入了一个统一框架来概括这些视角下的模型，并综合了不同研究的发现。

Result: 论文提出了一个统一的激励感知机器学习模型框架，该框架整合了鲁棒性、公平性和改进/因果性三个研究视角，并识别了该领域的主要挑战（如区分“博弈”行为与真实改进，以及处理不同个体的异质性），同时概述了相关的理论进展和实用解决方案。

Conclusion: 通过综合现有研究成果并提出统一框架，本文为开发鲁棒、公平且具有因果意识的激励感知机器学习系统勾勒了理论进展和实用解决方案，并指出了未来的研究方向。

Abstract: The article explores the emerging domain of incentive-aware machine learning
(ML), which focuses on algorithmic decision-making in contexts where
individuals can strategically modify their inputs to influence outcomes. It
categorizes the research into three perspectives: robustness, aiming to design
models resilient to "gaming"; fairness, analyzing the societal impacts of such
systems; and improvement/causality, recognizing situations where strategic
actions lead to genuine personal or societal improvement. The paper introduces
a unified framework encapsulating models for these perspectives, including
offline, online, and causal settings, and highlights key challenges such as
differentiating between gaming and improvement and addressing heterogeneity
among agents. By synthesizing findings from diverse works, we outline
theoretical advancements and practical solutions for robust, fair, and
causally-informed incentive-aware ML systems.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [222] [Robustly optimal dynamics for active matter reservoir computing](https://arxiv.org/abs/2505.05420)
*Mario U. Gaimann,Miriam Klopotek*

Main category: nlin.AO

TL;DR: 该研究探讨了活性物质在储蓄池计算（RC）范式下处理信息的能力，用于推断混沌信号的未来状态，并发现了一个由系统内在弛豫能力决定的最佳动力学区域。


<details>
  <summary>Details</summary>
Motivation: 研究活性物质在储蓄池计算框架下的信息处理能力，特别是用于预测混沌系统，并理解实现这种计算的潜在物理机制。

Method: 使用一个受外部驱动的活性物质模拟模型，通过储蓄池计算来推断混沌信号的未来状态，并分析智能体动力学、系统弛豫特性以及不同动力学区域的计算性能。

Result: 发现了一个在临界阻尼阈值以下的特殊且鲁棒的最佳动力学区域，该区域表现出多阶段微观动力学弛豫和对混沌驱动的适应性。系统的信息处理能力主要由其内在弛豫能力决定，智能体动力学的相关性可指示最佳性能区域。

Conclusion: 活性物质系统的内在弛豫能力，尤其是在临界阻尼阈值附近的特定动力学区域，对其在储蓄池计算中有效处理信息至关重要。该模型为非平衡多体物理学背景下的学习和非常规计算研究提供了新视角。

Abstract: We study the information processing abilities of active matter in the
reservoir computing (RC) paradigm, using a model that is externally driven to
infer the future state of a chaotic signal. The simulated system closely
follows a previously reported model. We uncover an exceptional dynamical regime
of agent dynamics that has been overlooked heretofore. It appears robustly
optimal across varying physical parameters and inference tasks, thus providing
valuable insights into computation and inference with physical systems more
generally. The ability to form effective mechanisms for information processing
are primarily determined by the system's own intrinsic relaxation abilities.
These are identifiable when probing the system without a specific inference
goal and manifest when testing minimalistic single-particle reservoirs. The
regime that achieves optimal computation is situated just below the critical
damping threshold, involving a microscopic dynamical relaxation with multiple
stages. The optimal system is adaptable under chaotic external driving, due to
a diversity in response mechanisms that emerge like rapid alternations between
quasi-stationary and highly nonlinear dynamical states. Both coherent and
incoherent dynamics contribute to their operation, partly at dissimilar scales
of space and delay time. Correlations on agent dynamics can indicate the
best-performing regimes and onsets of tight relationships between the
responding system and the fluctuating driver. As this model of computation is
interpretable in physical terms, it facilitates re-framing inquiries regarding
learning and unconventional computing with a fresh rationale for many-body
physics out of equilibrium.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [223] [Enhancing Text2Cypher with Schema Filtering](https://arxiv.org/abs/2505.05118)
*Makbule Gulcin Ozsoy*

Main category: cs.DB

TL;DR: 该研究探索了Text2Cypher（自然语言转Cypher查询）中的模式筛选方法，发现其能有效优化查询生成，尤其对小型模型，并能为所有模型降低成本。


<details>
  <summary>Details</summary>
Motivation: 将自然语言问题转换为Cypher查询时，在提示中直接使用完整（尤其复杂的）数据库模式会引入噪音、增加幻觉并提高计算成本。本研究旨在通过模式筛选解决这些问题。

Method: 本工作研究了多种用于Text2Cypher任务的模式筛选方法，并分析了它们对Token长度、性能和成本的影响。

Result: 研究表明，模式筛选能有效优化Text2Cypher，对小型模型效果尤为显著。大型模型因其较强的上下文理解能力，从模式筛选中获得的性能提升较小，但在降低成本方面仍有价值。

Conclusion: 模式筛选是优化Text2Cypher的有效手段，它能改善查询生成质量（尤其对小型模型），并为各种规模的模型降低Token成本。

Abstract: Knowledge graphs represent complex data using nodes, relationships, and
properties. Cypher, a powerful query language for graph databases, enables
efficient modeling and querying. Recent advancements in large language models
allow translation of natural language questions into Cypher queries -
Text2Cypher. A common approach is incorporating database schema into prompts.
However, complex schemas can introduce noise, increase hallucinations, and
raise computational costs. Schema filtering addresses these challenges by
including only relevant schema elements, improving query generation while
reducing token costs. This work explores various schema filtering methods for
Text2Cypher task and analyzes their impact on token length, performance, and
cost. Results show that schema filtering effectively optimizes Text2Cypher,
especially for smaller models. Consistent with prior research, we find that
larger models benefit less from schema filtering due to their longer context
capabilities. However, schema filtering remains valuable for both larger and
smaller models in cost reduction.

</details>


### [224] [Text2Cypher: Data Pruning using Hard Example Selection](https://arxiv.org/abs/2505.05122)
*Makbule Gulcin Ozsoy*

Main category: cs.DB

TL;DR: 本文提出了五种难例选择技术，用于修剪Text2Cypher数据集，旨在在减少资源使用的同时保持或提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型（如Text2SQL和Text2Cypher）需要大型多样化数据集，这导致微调成本随数据集规模增加而上升。因此，需要更小、高质量的数据集来降低成本并保持或提升性能。

Method: 提出了五种难例（hard-example）选择技术来精简（pruning）Text2Cypher数据集。

Result: 研究表明，这些难例选择方法可以将训练时间和成本减半，而对性能影响最小。

Conclusion: 难例选择为Text2Cypher模型的微调提供了一种经济高效的解决方案。

Abstract: Database query languages such as SQL for relational databases and Cypher for
graph databases have been widely adopted. Recent advancements in large language
models (LLMs) enable natural language interactions with databases through
models like Text2SQL and Text2Cypher. Fine-tuning these models typically
requires large, diverse datasets containing non-trivial examples. However, as
dataset size increases, the cost of fine-tuning also rises. This makes smaller,
high-quality datasets essential for reducing costs for the same or better
performance. In this paper, we propose five hard-example selection techniques
for pruning the Text2Cypher dataset, aiming to preserve or improve performance
while reducing resource usage. Our results show that these hard-example
selection approaches can halve training time and costs with minimal impact on
performance, and demonstrates that hard-example selection provides a
cost-effective solution.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [225] [AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments](https://arxiv.org/abs/2505.04972)
*Mattia Sartori,Chetna Singhal,Neelabhro Roy,Davide Brunelli,James Gross*

Main category: cs.RO

TL;DR: 该研究提出了一种AI辅助的视觉反应式规划方法，使微型无人机能在资源受限的情况下，通过边缘计算辅助实现安全自主导航和避障。


<details>
  <summary>Details</summary>
Motivation: 微型无人机因其资源（计算、传感能力）有限，在实现安全自主导航和执行高级任务（如探索、监视）方面面临巨大挑战。

Method: 提出一种新颖的AI辅助、基于视觉的反应式规划方法。将导航任务分为两部分：深度学习目标检测器在边缘设备（外部硬件）运行，规划算法在无人机机载执行，遵循集成传感、计算和通信的范式。

Result: 系统能以约8帧/秒的速度控制无人机，目标检测模型在COCO数据集上的平均精度均值达到60.8%。现场实验表明，无人机能以1米/秒的速度飞行，成功避开未知障碍物并到达目标点，验证了方案的可行性。

Conclusion: 该方法为微型无人机提供了一种可行的替代全机载实现的方案，并具有扩展到自主探索任务的潜力，证明了通信延迟和模型性能与实时导航任务要求的兼容性。

Abstract: The miniaturisation of sensors and processors, the advancements in connected
edge intelligence, and the exponential interest in Artificial Intelligence are
boosting the affirmation of autonomous nano-size drones in the Internet of
Robotic Things ecosystem. However, achieving safe autonomous navigation and
high-level tasks such as exploration and surveillance with these tiny platforms
is extremely challenging due to their limited resources. This work focuses on
enabling the safe and autonomous flight of a pocket-size, 30-gram platform
called Crazyflie 2.1 in a partially known environment. We propose a novel
AI-aided, vision-based reactive planning method for obstacle avoidance under
the ambit of Integrated Sensing, Computing and Communication paradigm. We deal
with the constraints of the nano-drone by splitting the navigation task into
two parts: a deep learning-based object detector runs on the edge (external
hardware) while the planning algorithm is executed onboard. The results show
the ability to command the drone at $\sim8$ frames-per-second and a model
performance reaching a COCO mean-average-precision of $60.8$. Field experiments
demonstrate the feasibility of the solution with the drone flying at a top
speed of $1$ m/s while steering away from an obstacle placed in an unknown
position and reaching the target destination. The outcome highlights the
compatibility of the communication delay and the model performance with the
requirements of the real-time navigation task. We provide a feasible
alternative to a fully onboard implementation that can be extended to
autonomous exploration with nano-drones.

</details>


### [226] [D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation](https://arxiv.org/abs/2505.04860)
*I-Chun Arthur Liu,Jason Chen,Gaurav Sukhatme,Daniel Seita*

Main category: cs.RO

TL;DR: 提出了一种名为 D-CODA 的离线数据增强方法，通过训练扩散模型为双手协调操作生成新颖的、视角一致的手腕相机图像和有效的关节空间动作标签。


<details>
  <summary>Details</summary>
Motivation: 双手操作学习因其高维度和对双臂间紧密协调的要求而具有挑战性。虽然腕戴相机（eye-in-hand）的模仿学习简化了感知，但收集多样化的演示数据成本高昂，因此需要可扩展的数据增强方法。现有单臂视觉增强方法难以直接扩展到双手操作，因为它需要生成双臂间视角一致的观察结果，并产生有效且可行的相应动作标签。

Method: 提出 D-CODA (Diffusion for COordinated Dual-arm Data Augmentation) 方法。该方法训练一个扩散模型，用于合成双臂的新颖且视角一致的手腕相机图像，同时生成关节空间的动作标签。它采用约束优化来确保涉及夹爪与物体接触的增强状态符合双手协调的约束条件。

Result: 在5个模拟任务和3个真实世界任务中进行了评估。通过2250次模拟试验和300次真实世界试验的结果表明，D-CODA 优于基线方法和消融实验，展示了其在腕戴相机双手操作中进行可扩展数据增强的潜力。

Conclusion: D-CODA 是一种有效的离线数据增强方法，能够为腕戴相机双手模仿学习生成高质量、协调一致的增强数据，从而提升学习性能。

Abstract: Learning bimanual manipulation is challenging due to its high dimensionality
and tight coordination required between two arms. Eye-in-hand imitation
learning, which uses wrist-mounted cameras, simplifies perception by focusing
on task-relevant views. However, collecting diverse demonstrations remains
costly, motivating the need for scalable data augmentation. While prior work
has explored visual augmentation in single-arm settings, extending these
approaches to bimanual manipulation requires generating viewpoint-consistent
observations across both arms and producing corresponding action labels that
are both valid and feasible. In this work, we propose Diffusion for COordinated
Dual-arm Data Augmentation (D-CODA), a method for offline data augmentation
tailored to eye-in-hand bimanual imitation learning that trains a diffusion
model to synthesize novel, viewpoint-consistent wrist-camera images for both
arms while simultaneously generating joint-space action labels. It employs
constrained optimization to ensure that augmented states involving
gripper-to-object contacts adhere to constraints suitable for bimanual
coordination. We evaluate D-CODA on 5 simulated and 3 real-world tasks. Our
results across 2250 simulation trials and 300 real-world trials demonstrate
that it outperforms baselines and ablations, showing its potential for scalable
data augmentation in eye-in-hand bimanual manipulation. Our project website is
at: https://dcodaaug.github.io/D-CODA/.

</details>


### [227] [X-Driver: Explainable Autonomous Driving with Vision-Language Models](https://arxiv.org/abs/2505.05098)
*Wei Liu,Jiyuan Zhang,Binxiong Zheng,Yufeng Hu,Yingzhan Lin,Zengfeng Zeng*

Main category: cs.RO

TL;DR: 本文介绍了一个名为 X-Driver 的统一多模态大语言模型框架，通过思维链（CoT）和自回归建模提升闭环自动驾驶的感知与决策能力，并在 CARLA 模拟环境中超越了现有SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端自动驾驶取得了显著进展，但现有框架在闭环评估中成功率仍然较低，限制了其在现实世界中的部署。

Method: 提出了 X-Driver 框架，这是一个为闭环自动驾驶设计的多模态大语言模型（MLLM）。它利用思维链（CoT）和自回归建模来增强感知和决策能力，并在 CARLA 模拟环境中的公共基准上进行了验证。

Result: 实验结果表明，X-Driver 在闭环性能上表现优越，超越了当前最先进水平（SOTA），同时提高了驾驶决策的可解释性。

Conclusion: 研究结果强调了结构化推理在端到端驾驶中的重要性，并将 X-Driver 确立为未来闭环自动驾驶研究的一个强大基线。

Abstract: End-to-end autonomous driving has advanced significantly, offering benefits
such as system simplicity and stronger driving performance in both open-loop
and closed-loop settings than conventional pipelines. However, existing
frameworks still suffer from low success rates in closed-loop evaluations,
highlighting their limitations in real-world deployment. In this paper, we
introduce X-Driver, a unified multi-modal large language models(MLLMs)
framework designed for closed-loop autonomous driving, leveraging
Chain-of-Thought(CoT) and autoregressive modeling to enhance perception and
decision-making. We validate X-Driver across multiple autonomous driving tasks
using public benchmarks in CARLA simulation environment, including
Bench2Drive[6]. Our experimental results demonstrate superior closed-loop
performance, surpassing the current state-of-the-art(SOTA) while improving the
interpretability of driving decisions. These findings underscore the importance
of structured reasoning in end-to-end driving and establish X-Driver as a
strong baseline for future research in closed-loop autonomous driving.

</details>


### [228] [Steerable Scene Generation with Post Training and Inference-Time Search](https://arxiv.org/abs/2505.04831)
*Nicholas Pfaff,Hongkai Dai,Sergey Zakharov,Shun Iwase,Russ Tedrake*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的方法，用于生成多样化、任务特定的3D场景，以支持机器人仿真训练。


<details>
  <summary>Details</summary>
Motivation: 为机器人仿真训练手动创建满足特定任务要求（如高杂乱度和合理空间布局）的3D场景既困难又昂贵。

Method: 训练一个统一的基于扩散的生成模型，该模型从固定资产库中预测放置的物体及其SE(3)姿态。该模型可作为灵活的场景先验，并通过强化学习后训练、条件生成或推理时搜索（包括新颖的基于MCTS的推理时搜索策略）进行调整，以适应下游任务目标，同时通过投影和仿真保证物理可行性。

Result: 该方法能够实现目标导向的场景合成，尊重物理可行性，并能扩展到不同类型的场景。研究者还发布了一个包含超过4400万个SE(3)场景的数据集。

Conclusion: 本文提出了一种可引导的场景生成方法，能够有效生成大规模、任务导向且物理可行的3D场景，为机器人学习提供了重要的数据基础。

Abstract: Training robots in simulation requires diverse 3D scenes that reflect the
specific challenges of downstream tasks. However, scenes that satisfy strict
task requirements, such as high-clutter environments with plausible spatial
arrangement, are rare and costly to curate manually. Instead, we generate
large-scale scene data using procedural models that approximate realistic
environments for robotic manipulation, and adapt it to task-specific goals. We
do this by training a unified diffusion-based generative model that predicts
which objects to place from a fixed asset library, along with their SE(3)
poses. This model serves as a flexible scene prior that can be adapted using
reinforcement learning-based post training, conditional generation, or
inference-time search, steering generation toward downstream objectives even
when they differ from the original data distribution. Our method enables
goal-directed scene synthesis that respects physical feasibility and scales
across scene types. We introduce a novel MCTS-based inference-time search
strategy for diffusion models, enforce feasibility via projection and
simulation, and release a dataset of over 44 million SE(3) scenes spanning five
diverse environments. Website with videos, code, data, and model weights:
https://steerable-scene-generation.github.io/

</details>


### [229] [CubeDAgger: Improved Robustness of Interactive Imitation Learning without Violation of Dynamic Stability](https://arxiv.org/abs/2505.04897)
*Taisuke Kobayashi*

Main category: cs.RO

TL;DR: 提出了一种名为 CubeDAgger 的交互式模仿学习新方法，通过改进 EnsembleDAgger，在提高策略鲁棒性的同时减少了动态稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式模仿学习方法中，专家-智能体切换系统难以精确选择监督时机，且切换会导致动作突变，损害动态稳定性。

Method: CubeDAgger 对基线方法 EnsembleDAgger 进行了三项改进：1) 添加正则化以激活监督时机决策阈值；2) 将专家-智能体切换系统转变为多候选动作的最优共识系统；3) 引入自回归有色噪声以实现一致的随机探索。

Result: 仿真结果表明，使用 CubeDAgger 学习到的策略具有足够的鲁棒性，并且在交互过程中保持了动态稳定性。

Conclusion: CubeDAgger 通过其三项改进，有效提升了交互式模仿学习策略的鲁棒性，并维持了交互过程中的动态稳定性。

Abstract: Interactive imitation learning makes an agent's control policy robust by
stepwise supervisions from an expert. The recent algorithms mostly employ
expert-agent switching systems to reduce the expert's burden by limitedly
selecting the supervision timing. However, the precise selection is difficult
and such a switching causes abrupt changes in actions, damaging the dynamic
stability. This paper therefore proposes a novel method, so-called CubeDAgger,
which improves robustness while reducing dynamic stability violations by making
three improvements to a baseline method, EnsembleDAgger. The first improvement
adds a regularization to explicitly activate the threshold for deciding the
supervision timing. The second transforms the expert-agent switching system to
an optimal consensus system of multiple action candidates. Third,
autoregressive colored noise to the actions is introduced to make the
stochastic exploration consistent over time. These improvements are verified by
simulations, showing that the learned policies are sufficiently robust while
maintaining dynamic stability during interaction.

</details>


### [230] [CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations](https://arxiv.org/abs/2505.04999)
*Anthony Liang,Pavel Czempin,Matthew Hong,Yutai Zhou,Erdem Biyik,Stephen Tu*

Main category: cs.RO

TL;DR: 该研究提出CLAM方法，从未标记观测数据中学习机器人策略，尤其擅长处理需要精细动作的复杂任务。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习依赖大量昂贵的带标签专家数据，限制了其应用。现有从未标记观测中学习的方法难以应对复杂精细的机器人任务。

Method: 提出连续潜在动作模型(CLAM)，采用连续潜在动作标签，并联合训练动作解码器，以少量（甚至非最优的）带标签样本将潜在动作空间映射至真实动作。

Result: 在DMControl、MetaWorld控制基准和真实的WidowX机器人手臂实验中，CLAM的性能显著超越先前最优方法，任务成功率提升了2-3倍。

Conclusion: CLAM无需专家动作标签数据，即可从未标记观测数据中有效学习高性能的机器人策略，解决了复杂连续控制任务的挑战。

Abstract: Learning robot policies using imitation learning requires collecting large
amounts of costly action-labeled expert demonstrations, which fundamentally
limits the scale of training data. A promising approach to address this
bottleneck is to harness the abundance of unlabeled observations-e.g., from
video demonstrations-to learn latent action labels in an unsupervised way.
However, we find that existing methods struggle when applied to complex robot
tasks requiring fine-grained motions. We design continuous latent action models
(CLAM) which incorporate two key ingredients we find necessary for learning to
solve complex continuous control tasks from unlabeled observation data: (a)
using continuous latent action labels instead of discrete representations, and
(b) jointly training an action decoder to ensure that the latent action space
can be easily grounded to real actions with relatively few labeled examples.
Importantly, the labeled examples can be collected from non-optimal play data,
enabling CLAM to learn performant policies without access to any action-labeled
expert data. We demonstrate on continuous control benchmarks in DMControl
(locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot
arm that CLAM significantly outperforms prior state-of-the-art methods,
remarkably with a 2-3x improvement in task success rate compared to the best
baseline. Videos and code can be found at clamrobot.github.io.

</details>


### [231] [The City that Never Settles: Simulation-based LiDAR Dataset for Long-Term Place Recognition Under Extreme Structural Changes](https://arxiv.org/abs/2505.05076)
*Hyunho Song,Dongjae Lee,Seunghun Oh,Minwoo Jung,Ayoung Kim*

Main category: cs.RO

TL;DR: 提出CNS仿真数据集和TCR_sym度量，以应对大规模城市场景变化对长期地点识别的挑战，并发现现有方法在此类场景下性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有地点识别数据集主要关注有限或室内的变化，未能充分代表由大规模建设和拆除引起的广泛室外环境转型，这限制了对算法鲁棒性的评估。

Method: 1. 构建了一个基于CARLA模拟器的仿真数据集CNS（City that Never Settles），捕捉了建筑物建造和拆除等主要结构变化。2. 提出了一种对称的结构变化度量方法TCR_sym，用于一致地衡量变化程度。

Result: 定量比较表明，CNS数据集比当前真实世界基准包含了更广泛的环境变化。在CNS上评估先进的激光雷达地点识别方法时，其性能出现显著下降。

Conclusion: 大规模环境变化对长期地点识别构成了严峻挑战，强调了开发能够处理这些显著变化的鲁棒算法的必要性。CNS数据集为此研究提供了基础。

Abstract: Large-scale construction and demolition significantly challenge long-term
place recognition (PR) by drastically reshaping urban and suburban
environments. Existing datasets predominantly reflect limited or indoor-focused
changes, failing to adequately represent extensive outdoor transformations. To
bridge this gap, we introduce the City that Never Settles (CNS) dataset, a
simulation-based dataset created using the CARLA simulator, capturing major
structural changes-such as building construction and demolition-across diverse
maps and sequences. Additionally, we propose TCR_sym, a symmetric version of
the original TCR metric, enabling consistent measurement of structural changes
irrespective of source-target ordering. Quantitative comparisons demonstrate
that CNS encompasses more extensive transformations than current real-world
benchmarks. Evaluations of state-of-the-art LiDAR-based PR methods on CNS
reveal substantial performance degradation, underscoring the need for robust
algorithms capable of handling significant environmental changes. Our dataset
is available at https://github.com/Hyunho111/CNS_dataset.

</details>


### [232] [Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving](https://arxiv.org/abs/2505.05223)
*Hendrik Surmann,Jorge de Heuvel,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种基于多目标强化学习的端到端自动驾驶方法，能够实时适应用户对驾驶风格的偏好，无需重新训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法在适应人类驾驶员个体化、动态且依赖情境的驾驶风格偏好方面存在局限，而这种适应性对提升用户信任和满意度至关重要。

Method: 采用多目标强化学习（MORL）与偏好驱动优化相结合的方法。将驾驶风格偏好编码为连续权重向量，用于调整可解释的风格目标（效率、舒适度、速度、激进性），从而在不重新训练策略的情况下调整行为。该单策略智能体集成了基于视觉的感知，并在CARLA模拟器中的复杂混合交通场景中进行评估。

Result: 实验结果表明，该智能体能够根据变化的偏好动态调整其驾驶行为，同时在避免碰撞和完成路线方面保持良好性能。

Conclusion: 所提出的MORL方法能够使自动驾驶系统在运行时适应驾驶风格偏好，无需重新训练策略，从而提高了用户接受度和满意度。

Abstract: Human drivers exhibit individual preferences regarding driving style.
Adapting autonomous vehicles to these preferences is essential for user trust
and satisfaction. However, existing end-to-end driving approaches often rely on
predefined driving styles or require continuous user feedback for adaptation,
limiting their ability to support dynamic, context-dependent preferences. We
propose a novel approach using multi-objective reinforcement learning (MORL)
with preference-driven optimization for end-to-end autonomous driving that
enables runtime adaptation to driving style preferences. Preferences are
encoded as continuous weight vectors to modulate behavior along interpretable
style objectives$\unicode{x2013}$including efficiency, comfort, speed, and
aggressiveness$\unicode{x2013}$without requiring policy retraining. Our
single-policy agent integrates vision-based perception in complex mixed-traffic
scenarios and is evaluated in diverse urban environments using the CARLA
simulator. Experimental results demonstrate that the agent dynamically adapts
its driving behavior according to changing preferences while maintaining
performance in terms of collision avoidance and route completion.

</details>


### [233] [Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation](https://arxiv.org/abs/2505.05287)
*Zechu Li,Yufeng Jin,Daniel Ordonez Apraez,Claudio Semini,Puze Liu,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: SYMDEX是一种利用机器人双臂对称性的强化学习框架，可实现灵巧的双臂操作，并能推广至多臂协作。


<details>
  <summary>Details</summary>
Motivation: 借鉴人类双臂操作的对称性，旨在让双臂机器人能够利用自身结构对称性，实现双手同等熟练度的灵巧操作，克服传统机器人对特定手臂的依赖。

Method: 提出了SYMDEX强化学习框架：将复杂双臂任务分解为单臂子任务，为各子任务训练专用策略，并通过等变神经网络利用机器人固有的双边对称性使一侧手臂的经验能被另一侧手臂利用，最终将子任务策略蒸馏成一个与手臂-任务分配无关的全局灵巧策略。

Result: SYMDEX在六项具有挑战性的模拟操作任务中表现优异，并在其中两项任务上成功实现了真实世界部署。在左右手执行不同角色的复杂任务中，该方法显著优于基线方法。此外，SYMDEX成功扩展到四臂操作场景，证明了其可扩展性和多臂协作能力。

Conclusion: 将结构对称性作为归纳偏置引入策略学习，能够显著提升样本效率、鲁棒性以及在各种灵巧操作任务中的泛化能力。

Abstract: Humans naturally exhibit bilateral symmetry in their gross manipulation
skills, effortlessly mirroring simple actions between left and right hands.
Bimanual robots-which also feature bilateral symmetry-should similarly exploit
this property to perform tasks with either hand. Unlike humans, who often favor
a dominant hand for fine dexterous skills, robots should ideally execute
ambidextrous manipulation with equal proficiency. To this end, we introduce
SYMDEX (SYMmetric DEXterity), a reinforcement learning framework for
ambidextrous bi-manipulation that leverages the robot's inherent bilateral
symmetry as an inductive bias. SYMDEX decomposes complex bimanual manipulation
tasks into per-hand subtasks and trains dedicated policies for each. By
exploiting bilateral symmetry via equivariant neural networks, experience from
one arm is inherently leveraged by the opposite arm. We then distill the
subtask policies into a global ambidextrous policy that is independent of the
hand-task assignment. We evaluate SYMDEX on six challenging simulated
manipulation tasks and demonstrate successful real-world deployment on two of
them. Our approach strongly outperforms baselines on complex task in which the
left and right hands perform different roles. We further demonstrate SYMDEX's
scalability by extending it to a four-arm manipulation setup, where our
symmetry-aware policies enable effective multi-arm collaboration and
coordination. Our results highlight how structural symmetry as inductive bias
in policy learning enhances sample efficiency, robustness, and generalization
across diverse dexterous manipulation tasks.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [234] [Exploring Zero-Shot App Review Classification with ChatGPT: Challenges and Potential](https://arxiv.org/abs/2505.04759)
*Mohit Chaudhary,Chirag Jain,Preethu Rose Anish*

Main category: cs.SE

TL;DR: 该研究评估了ChatGPT在无需特定训练数据的情况下对App评论进行分类（功能性需求、非功能性需求等）的能力，并取得了较好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统App评论分类方法依赖昂贵且耗时的大型领域特定数据集，本研究旨在探索利用ChatGPT进行零样本学习以克服此限制，从而更有效地指导应用开发和提升用户满意度。

Method: 研究采用ChatGPT进行零样本学习，将App评论分为功能性需求、非功能性需求、两者皆有或两者皆无四类。在一个包含1880条来自十个不同领域App的手动标注评论的基准数据集上评估其性能，并分析了评论可读性、长度等因素对分类准确性的影响。

Result: ChatGPT在App评论分类任务中实现了0.842的鲁棒F1分数。此外，研究还考察了评论可读性和长度等因素对分类准确度的影响，并手动分析了易被错误分类的评论类别。

Conclusion: 尽管存在某些挑战和局限性，ChatGPT在零样本App评论分类方面表现出强大的潜力，为开发者提供了一种无需大量标注数据即可有效分析用户反馈的方法。

Abstract: App reviews are a critical source of user feedback, offering valuable
insights into an app's performance, features, usability, and overall user
experience. Effectively analyzing these reviews is essential for guiding app
development, prioritizing feature updates, and enhancing user satisfaction.
Classifying reviews into functional and non-functional requirements play a
pivotal role in distinguishing feedback related to specific app features
(functional requirements) from feedback concerning broader quality attributes,
such as performance, usability, and reliability (non-functional requirements).
Both categories are integral to informed development decisions. Traditional
approaches to classifying app reviews are hindered by the need for large,
domain-specific datasets, which are often costly and time-consuming to curate.
This study explores the potential of zero-shot learning with ChatGPT for
classifying app reviews into four categories: functional requirement,
non-functional requirement, both, or neither. We evaluate ChatGPT's performance
on a benchmark dataset of 1,880 manually annotated reviews from ten diverse
apps spanning multiple domains. Our findings demonstrate that ChatGPT achieves
a robust F1 score of 0.842 in review classification, despite certain challenges
and limitations. Additionally, we examine how factors such as review
readability and length impact classification accuracy and conduct a manual
analysis to identify review categories more prone to misclassification.

</details>


### [235] [PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust](https://arxiv.org/abs/2505.04852)
*Yifei Gao,Chengpeng Wang,Pengxiang Huang,Xuwei Liu,Mingwei Zheng,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 该论文提出了一种名为PR2的技术，通过将C2RUST生成的Rust代码中的原始指针重写为安全的Rust数据结构，以提高其内存安全性。


<details>
  <summary>Details</summary>
Motivation: C代码转换为Rust后，生成的Rust程序常包含大量不安全的原始指针，这削弱了Rust本身的安全保障。本研究旨在通过消除这些原始指针来提升转换后Rust代码的内存安全性。

Method: 提出了一种“peephole”原始指针重写技术（PR2），该技术在单个函数内将原始指针提升为合适的Rust数据结构。PR2利用基于决策树的提示来指导指针提升过程，并结合代码变更分析来修复重写引入的编译和测试错误。

Result: PR2在28个真实的C项目上进行了评估，成功消除了其中13.22%的局部原始指针，显著增强了翻译后Rust代码的安全性。平均每个项目的转换耗时5.44小时，成本为1.46美元。

Conclusion: PR2技术能够有效消除由C2RUST生成的Rust代码中的一部分原始指针，从而显著提高翻译后代码的安全性。

Abstract: There has been a growing interest in translating C code to Rust due to Rust's
robust memory and thread safety guarantees. Tools such as C2RUST enable
syntax-guided transpilation from C to semantically equivalent Rust code.
However, the resulting Rust programs often rely heavily on unsafe
constructs--particularly raw pointers--which undermines Rust's safety
guarantees. This paper aims to improve the memory safety of Rust programs
generated by C2RUST by eliminating raw pointers. Specifically, we propose a
peephole raw pointer rewriting technique that lifts raw pointers in individual
functions to appropriate Rust data structures. Technically, PR2 employs
decision-tree-based prompting to guide the pointer lifting process.
Additionally, it leverages code change analysis to guide the repair of errors
introduced during rewriting, effectively addressing errors encountered during
compilation and test case execution. We implement PR2 as a prototype and
evaluate it using gpt-4o-mini on 28 real-world C projects. The results show
that PR2 successfully eliminates 13.22% of local raw pointers across these
projects, significantly enhancing the safety of the translated Rust code. On
average, PR2 completes the transformation of a project in 5.44 hours, at an
average cost of $1.46.

</details>


### [236] [Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents](https://arxiv.org/abs/2505.05283)
*Kaixin Wang,Tianlin Li,Xiaoyu Zhang,Chong Wang,Weisong Sun,Yang Liu,Bin Shi*

Main category: cs.SE

TL;DR: 这篇论文全面回顾了代码大型语言模型（CodeLLMs）和代理的基准测试，发现当前基准主要集中在软件开发阶段，而需求工程和设计阶段关注不足。


<details>
  <summary>Details</summary>
Motivation: 尽管代码大型语言模型（CodeLLMs）和代理日益重要，但目前缺乏对其基准的全面综述，本研究旨在填补这一空白。

Method: 通过研究和分析来自461篇相关论文的181个基准，对CodeLLMs和代理的现有基准进行了全面回顾，覆盖了软件开发生命周期（SDLC）的不同阶段。

Result: 研究发现，当前约60%的基准集中在软件开发阶段，而需求工程和软件设计阶段分别仅占5%和3%，存在显著不平衡。此外，Python是评审基准中最主要的编程语言。

Conclusion: 论文指出了当前研究面临的挑战，并提出了未来研究方向，旨在缩小CodeLLMs和代理的理论能力与实际应用之间的差距。

Abstract: Code large language models (CodeLLMs) and agents have shown great promise in
tackling complex software engineering tasks.Compared to traditional software
engineering methods, CodeLLMs and agents offer stronger abilities, and can
flexibly process inputs and outputs in both natural and code. Benchmarking
plays a crucial role in evaluating the capabilities of CodeLLMs and agents,
guiding their development and deployment. However, despite their growing
significance, there remains a lack of comprehensive reviews of benchmarks for
CodeLLMs and agents. To bridge this gap, this paper provides a comprehensive
review of existing benchmarks for CodeLLMs and agents, studying and analyzing
181 benchmarks from 461 relevant papers, covering the different phases of the
software development life cycle (SDLC). Our findings reveal a notable imbalance
in the coverage of current benchmarks, with approximately 60% focused on the
software development phase in SDLC, while requirements engineering and software
design phases receive minimal attention at only 5% and 3%, respectively.
Additionally, Python emerges as the dominant programming language across the
reviewed benchmarks. Finally, this paper highlights the challenges of current
research and proposes future directions, aiming to narrow the gap between the
theoretical capabilities of CodeLLMs and agents and their application in
real-world scenarios.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [237] [Multimodal Benchmarking and Recommendation of Text-to-Image Generation Models](https://arxiv.org/abs/2505.04650)
*Kapil Wanaskar,Gaytri Jena,Magdalini Eirinaki*

Main category: cs.GR

TL;DR: 本研究提出了一个开源的文本到图像生成模型统一基准测试框架，重点评估元数据增强提示的效果。


<details>
  <summary>Details</summary>
Motivation: 评估元数据增强提示对文本到图像生成模型在视觉真实感、语义保真度和模型鲁棒性方面的影响，并为此提供一个标准化的评估框架。

Method: 利用DeepFashion-MultiModal数据集，通过一套全面的定量指标（包括加权得分、CLIP相似度、LPIPS、FID和基于检索的指标）以及定性分析，来评估不同文本到图像架构的生成输出。

Result: 结构化的元数据增强显著提升了不同文本到图像模型架构的视觉真实感、语义保真度和模型鲁棒性。

Conclusion: 该框架证明了结构化元数据增强对提升文本到图像生成质量的有效性，并能基于评估指标为模型选择和提示词设计提供任务特定的建议。

Abstract: This work presents an open-source unified benchmarking and evaluation
framework for text-to-image generation models, with a particular focus on the
impact of metadata augmented prompts. Leveraging the DeepFashion-MultiModal
dataset, we assess generated outputs through a comprehensive set of
quantitative metrics, including Weighted Score, CLIP (Contrastive Language
Image Pre-training)-based similarity, LPIPS (Learned Perceptual Image Patch
Similarity), FID (Frechet Inception Distance), and retrieval-based measures, as
well as qualitative analysis. Our results demonstrate that structured metadata
enrichments greatly enhance visual realism, semantic fidelity, and model
robustness across diverse text-to-image architectures. While not a traditional
recommender system, our framework enables task-specific recommendations for
model selection and prompt design based on evaluation metrics.

</details>


### [238] [ChannelExplorer: Exploring Class Separability Through Activation Channel Visualization](https://arxiv.org/abs/2505.04647)
*Md Rahat-uz- Zaman,Bei Wang,Paul Rosen*

Main category: cs.GR

TL;DR: 介绍了一种名为ChannelExplorer的交互式可视化分析工具，用于分析深度神经网络（DNN）的内部行为，特别是不同层和激活通道如何促进类别可分性。


<details>
  <summary>Details</summary>
Motivation: 理解深度神经网络（DNN）的内部行为，尤其是不同层和激活通道如何对类别可分性做出贡献，仍然是一个挑战。

Method: 引入了ChannelExplorer，一个交互式可视化分析工具。该工具通过三个主要协调视图（散点图视图、Jaccard相似性视图和热图视图）来总结和可视化跨模型层的激活，从而分析基于图像的输出并探索类别可分性。

Result: ChannelExplorer支持多种模型架构（如CNN、GAN、ResNet、Stable Diffusion），并通过四个用例展示了其能力：生成ImageNet中的类别层次结构、发现错误标记的图像、识别激活通道的贡献以及定位Stable Diffusion模型中潜在状态的位置。该工具也得到了专家的评估。

Conclusion: ChannelExplorer是一个有效的工具，能够提供数据驱动的洞察，帮助理解DNN的内部工作机制，特别是在类别可分性方面。

Abstract: Deep neural networks (DNNs) achieve state-of-the-art performance in many
vision tasks, yet understanding their internal behavior remains challenging,
particularly how different layers and activation channels contribute to class
separability. We introduce ChannelExplorer, an interactive visual analytics
tool for analyzing image-based outputs across model layers, emphasizing
data-driven insights over architecture analysis for exploring class
separability. ChannelExplorer summarizes activations across layers and
visualizes them using three primary coordinated views: a Scatterplot View to
reveal inter- and intra-class confusion, a Jaccard Similarity View to quantify
activation overlap, and a Heatmap View to inspect activation channel patterns.
Our technique supports diverse model architectures, including CNNs, GANs,
ResNet and Stable Diffusion models. We demonstrate the capabilities of
ChannelExplorer through four use-case scenarios: (1) generating class hierarchy
in ImageNet, (2) finding mislabeled images, (3) identifying activation channel
contributions, and(4) locating latent states' position in Stable Diffusion
model. Finally, we evaluate the tool with expert users.

</details>


### [239] [ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators](https://arxiv.org/abs/2505.04961)
*Ziyu Zhang,Sergey Bashkirov,Dun Yang,Michael Taylor,Xue Bin Peng*

Main category: cs.GR

TL;DR: 提出了一种新颖的对抗性多目标优化技术，用于解决传统方法中手动调整权重和奖励函数的难题，尤其适用于物理模拟角色的运动跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有的多目标优化方法，特别是在基于强化学习的运动跟踪中，严重依赖手动调整的聚合函数或奖励函数，这一过程耗时、费力、需要领域专业知识，并且限制了所得函数在不同技能间的通用性。

Method: 提出了一种新颖的对抗性多目标优化技术，其核心是“对抗性差分判别器”（adversarial differential discriminator）。该判别器仅需单个正样本即可有效指导优化过程。

Result: 该技术能够使角色精确复制各种杂技和敏捷行为，其效果与最先进的运动跟踪方法相当，且无需手动调整奖励函数。

Conclusion: 所提出的对抗性多目标优化技术为解决多目标优化问题（包括运动跟踪）提供了一种有效且通用的方法，显著减少了手动调整的需求，并能达到与现有先进方法相当的性能。

Abstract: Multi-objective optimization problems, which require the simultaneous
optimization of multiple terms, are prevalent across numerous applications.
Existing multi-objective optimization methods often rely on manually tuned
aggregation functions to formulate a joint optimization target. The performance
of such hand-tuned methods is heavily dependent on careful weight selection, a
time-consuming and laborious process. These limitations also arise in the
setting of reinforcement-learning-based motion tracking for physically
simulated characters, where intricately crafted reward functions are typically
used to achieve high-fidelity results. Such solutions not only require domain
expertise and significant manual adjustment, but also limit the applicability
of the resulting reward function across diverse skills. To bridge this gap, we
present a novel adversarial multi-objective optimization technique that is
broadly applicable to a range of multi-objective optimization problems,
including motion tracking. The proposed adversarial differential discriminator
receives a single positive sample, yet is still effective at guiding the
optimization process. We demonstrate that our technique can enable characters
to closely replicate a variety of acrobatic and agile behaviors, achieving
comparable quality to state-of-the-art motion-tracking methods, without relying
on manually tuned reward functions. Results are best visualized through
https://youtu.be/rz8BYCE9E2w.

</details>


### [240] [WIR3D: Visually-Informed and Geometry-Aware 3D Shape Abstraction](https://arxiv.org/abs/2505.04813)
*Richard Liu,Daniel Fu,Noah Tan,Itai Lang,Rana Hanocka*

Main category: cs.GR

TL;DR: WIR3D是一种通过稀疏的3D贝塞尔曲线集来抽象化3D形状的技术，这些曲线能有效表示形状的几何结构和显著视觉特征。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够使用少量、视觉上显著的3D曲线来抽象化3D形状的方法，这些曲线能够从任意视角忠实地再现形状的几何结构和重要的视觉特征（如纹理）。

Method: 该研究提出WIR3D方法，通过优化一组稀疏的3D贝塞尔曲线参数来实现形状抽象。利用预训练的CLIP模型的中间激活来指导优化过程，该过程分为两个阶段：第一阶段捕捉粗略几何，第二阶段通过新颖的局部化关键点损失来表示细粒度特征，并允许用户控制。同时，通过神经符号距离场（SDF）损失确保曲线与原始表面的保真度，使曲线可用作直观的变形手柄。

Result: WIR3D成功应用于各种复杂程度、几何结构和纹理的广泛形状数据集的抽象化。同时展示了其在特征控制和形状变形等下游应用中的有效性。

Conclusion: WIR3D是一种有效的3D形状抽象技术，它使用稀疏且具有视觉意义的曲线，能够准确捕捉几何和视觉特征，支持用户控制，并适用于特征控制和形状变形等应用。

Abstract: We present WIR3D, a technique for abstracting 3D shapes through a sparse set
of visually meaningful curves in 3D. We optimize the parameters of Bezier
curves such that they faithfully represent both the geometry and salient visual
features (e.g. texture) of the shape from arbitrary viewpoints. We leverage the
intermediate activations of a pre-trained foundation model (CLIP) to guide our
optimization process. We divide our optimization into two phases: one for
capturing the coarse geometry of the shape, and the other for representing
fine-grained features. Our second phase supervision is spatially guided by a
novel localized keypoint loss. This spatial guidance enables user control over
abstracted features. We ensure fidelity to the original surface through a
neural SDF loss, which allows the curves to be used as intuitive deformation
handles. We successfully apply our method for shape abstraction over a broad
dataset of shapes with varying complexity, geometric structure, and texture,
and demonstrate downstream applications for feature control and shape
deformation.

</details>


### [241] [Inter-Diffusion Generation Model of Speakers and Listeners for Effective Communication](https://arxiv.org/abs/2505.04996)
*Jinhe Huang,Yongkang Cheng,Yuming Hang,Gaoge Han,Jinewei Li,Jing Zhang,Xingjian Gu*

Main category: cs.GR

TL;DR: 本文提出了一种创新的说话者与听众交互式扩散生成模型，首次将听众的全身姿态纳入考量，以实现更自然的全身交互手势生成。


<details>
  <summary>Details</summary>
Motivation: 现有手势生成研究大多仅关注说话者，忽略了听众在互动中的关键作用以及两者间的动态交互。

Method: 提出了一种说话者与听众的交互式扩散生成模型（Inter-Diffusion Generation Model）。该模型设计了新的交互扩散机制，基于先进的扩散模型架构，并引入交互条件和GAN模型来增大去噪步长，从而捕捉说话者与听众间的复杂互动模式，并根据说话者语音和听众反馈实时生成手势。

Result: 实验结果表明，与现有顶尖方法相比，该模型在生成手势的自然性、连贯性和语音-手势同步性方面均有显著提升。主观评估显示用户认为生成的互动场景更接近真实交流，客观指标也证实了模型的优越性。

Conclusion: 该研究提出的模型能够有效捕捉并生成说话者与听众之间的动态交互手势，显著提升了交互的真实感和有效性，为实现更自然的人机交互和虚拟化身沟通提供了有力支持。

Abstract: Full-body gestures play a pivotal role in natural interactions and are
crucial for achieving effective communication. Nevertheless, most existing
studies primarily focus on the gesture generation of speakers, overlooking the
vital role of listeners in the interaction process and failing to fully explore
the dynamic interaction between them. This paper innovatively proposes an
Inter-Diffusion Generation Model of Speakers and Listeners for Effective
Communication. For the first time, we integrate the full-body gestures of
listeners into the generation framework. By devising a novel inter-diffusion
mechanism, this model can accurately capture the complex interaction patterns
between speakers and listeners during communication. In the model construction
process, based on the advanced diffusion model architecture, we innovatively
introduce interaction conditions and the GAN model to increase the denoising
step size. As a result, when generating gesture sequences, the model can not
only dynamically generate based on the speaker's speech information but also
respond in realtime to the listener's feedback, enabling synergistic
interaction between the two. Abundant experimental results demonstrate that
compared with the current state-of-the-art gesture generation methods, the
model we proposed has achieved remarkable improvements in the naturalness,
coherence, and speech-gesture synchronization of the generated gestures. In the
subjective evaluation experiments, users highly praised the generated
interaction scenarios, believing that they are closer to real life human
communication situations. Objective index evaluations also show that our model
outperforms the baseline methods in multiple key indicators, providing more
powerful support for effective communication.

</details>


### [242] [Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields](https://arxiv.org/abs/2505.05356)
*Runfeng Li,Mikhail Okunev,Zixuan Guo,Anh Ha Duong,Christian Richardt,Matthew O'Toole,James Tompkin*

Main category: cs.GR

TL;DR: 提出了一种从单目C-ToF相机原始样本重建动态场景的方法，精度与神经体积方法相当或更高，速度快100倍。


<details>
  <summary>Details</summary>
Motivation: 从单一视点快速实现高保真动态3D重建是一项重大挑战。C-ToF相机不直接测量深度，这给基于快速基元表示（如3D高斯泼溅）的优化带来了困难，尤其是在单目数据下。

Method: 该方法利用单目连续波飞行时间(C-ToF)相机的原始传感器样本进行重建，并在优化过程中集成了两种启发式策略，以改进基于3D高斯表示的场景几何精度。

Result: 该方法在重建精度上达到或超过了神经体积方法，并且速度快100倍。实验表明，即使在受限的C-ToF传感条件下（包括快速运动如挥舞棒球棒的场景），也能产生准确的重建结果。

Conclusion: 该方法能够有效地从单目C-ToF相机的原始数据中快速、准确地重建动态场景，即使在具有挑战性的快速运动情况下也能保持高保真度。

Abstract: We present a method to reconstruct dynamic scenes from monocular
continuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that
achieves similar or better accuracy than neural volumetric approaches and is
100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a
single viewpoint is a significant challenge in computer vision. In C-ToF
radiance field reconstruction, the property of interest-depth-is not directly
measured, causing an additional challenge. This problem has a large and
underappreciated impact upon the optimization when using a fast primitive-based
scene representation like 3D Gaussian splatting, which is commonly used with
multi-view data to produce satisfactory results and is brittle in its
optimization otherwise. We incorporate two heuristics into the optimization to
improve the accuracy of scene geometry represented by Gaussians. Experimental
results show that our approach produces accurate reconstructions under
constrained C-ToF sensing conditions, including for fast motions like swinging
baseball bats. https://visual.cs.brown.edu/gftorf

</details>


### [243] [An Active Contour Model for Silhouette Vectorization using Bézier Curves](https://arxiv.org/abs/2505.05132)
*Luis Alvarez,Jean-Michel Morel*

Main category: cs.GR

TL;DR: 本文提出一种基于三次贝塞尔曲线的主动轮廓模型，用于轮廓矢量化，通过优化曲线参数以精确逼近轮廓边界。


<details>
  <summary>Details</summary>
Motivation: 旨在提高轮廓矢量化的准确性，减少矢量化结果与原始轮廓之间的偏差，并寻求优于现有图形软件和特定矢量化方法的方案。

Method: 提出一种主动轮廓模型：1. 使用三次贝塞尔曲线表示轮廓。2. 区分曲线端点为角点和规则点（规则点处切线方向预设）。3. 通过最小化贝塞尔曲线与轮廓边界的距离，优化曲线端点位置、规则点切线方向及贝塞尔曲线参数。4. 模型可接受任何现有矢量化方法的结果作为初始猜测。

Result: 与世界级图形软件Inkscape、Adobe Illustrator以及一种对比的基于曲率的矢量化方法相比，该方法显著减少了轮廓边界与其矢量化结果之间的平均距离。此外，该方法还允许通过减少贝塞尔曲线的长度来对其施加额外的规律性。

Conclusion: 该论文提出的基于三次贝塞尔曲线的主动轮廓模型能够有效提升轮廓矢量化的准确性，并能对生成的贝塞尔曲线施加额外的规律性，优于一些现有方法。

Abstract: In this paper, we propose an active contour model for silhouette
vectorization using cubic B\'ezier curves. Among the end points of the B\'ezier
curves, we distinguish between corner and regular points where the orientation
of the tangent vector is prescribed. By minimizing the distance of the B\'ezier
curves to the silhouette boundary, the active contour model optimizes the
location of the B\'ezier curves end points, the orientation of the tangent
vectors in the regular points, and the estimation of the B\'ezier curve
parameters. This active contour model can use the silhouette vectorization
obtained by any method as an initial guess. The proposed method significantly
reduces the average distance between the silhouette boundary and its
vectorization obtained by the world-class graphic software Inkscape, Adobe
Illustrator, and a curvature-based vectorization method, which we introduce for
comparison. Our method also allows us to impose additional regularity on the
B\'ezier curves by reducing their lengths.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [244] [A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network](https://arxiv.org/abs/2505.05103)
*Haoxiang Luo,Gang Sun,Yinqiu Liu,Dongcheng Zhao,Dusit Niyato,Hongfang Yu,Schahram Dustdar*

Main category: cs.CR

TL;DR: 该论文提出了一种基于加权拜占庭容错（WBFT）区块链共识机制的“可信多语言大模型网络”（Trusted MultiLLMN）框架，旨在提高多个大型语言模型协作的可靠性、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 单个大型语言模型（LLM）存在输出不一致、有偏见或产生幻觉等局限性。现有的多LLM网络（MultiLLMN）虽然允许多个LLM协作，但在开放环境中存在可靠性和安全性风险（如恶意LLM），且中心化协调导致效率低下和单点故障问题。

Method: 提出一种新颖的“可信多语言大模型网络”（Trusted MultiLLMN）框架，该框架采用加权拜占庭容错（WBFT）区块链共识机制。WBFT根据每个LLM的响应质量和可信度自适应分配投票权重，以激励可靠行为并减轻恶意节点的影响。

Result: 广泛的仿真实验表明，与传统及现代共识机制相比，WBFT显著提升了共识安全性和效率，尤其在无线网络条件下。此外，评估显示，由WBFT支持的Trusted MultiLLMN能提供比单个LLM和传统MultiLLMN更高质量、更可信的响应。

Conclusion: 由WBFT支持的Trusted MultiLLMN为构建稳健、去中心化的人工智能协作网络提供了一条有前景的路径，能够有效提升多LLM协作系统的可靠性、安全性和响应质量。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of applications. However, individual LLMs often produce inconsistent,
biased, or hallucinated outputs due to limitations in their training corpora
and model architectures. Recently, collaborative frameworks such as the
Multi-LLM Network (MultiLLMN) have been introduced, enabling multiple LLMs to
interact and jointly respond to user queries. Nevertheless, MultiLLMN
architectures raise critical concerns regarding the reliability and security of
the generated content, particularly in open environments where malicious or
compromised LLMs may be present. Moreover, reliance on centralized coordination
undermines system efficiency and introduces single points of failure. In this
paper, we propose a novel Trusted MultiLLMN framework, driven by a Weighted
Byzantine Fault Tolerance (WBFT) blockchain consensus mechanism, to ensure the
reliability, security, and efficiency of multi-LLM collaboration. In WBFT,
voting weights are adaptively assigned to each LLM based on its response
quality and trustworthiness, incentivizing reliable behavior, and reducing the
impact of malicious nodes. Extensive simulations demonstrate that WBFT
significantly improves both consensus security and efficiency compared to
classical and modern consensus mechanisms, particularly under wireless network
conditions. Furthermore, our evaluations reveal that Trusted MultiLLMN
supported by WBFT can deliver higher-quality and more credible responses than
both single LLMs and conventional MultiLLMNs, thereby providing a promising
path toward building robust, decentralized AI collaboration networks.

</details>


### [245] [A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org/abs/2505.04784)
*Pedro Pinacho-Davidson,Fernando Gutierrez,Pablo Zapata,Rodolfo Vergara,Pablo Aqueveque*

Main category: cs.CR

TL;DR: 提出了一种针对生成式AI聊天机器人的新型风险评估指标，该指标同时评估对服务提供组织、最终用户和第三方的潜在威胁，并结合了诱导错误行为的技术复杂度和上下文因素，通过增强的Garak框架进行了验证。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（Gen AI）和大型语言模型（LLMs）驱动的先进聊天机器人引入了超出传统网络安全范围的更广泛操作风险，现有方法不足以全面评估这些风险。

Method: 提出了一种新颖的、可量化的风险评估指标，该指标综合评估对三大关键利益相关者（服务提供组织、最终用户、第三方）的潜在威胁。该方法融合了诱导聊天机器人错误行为所需的技术复杂度（从非诱导故障到高级提示注入攻击）以及目标行业、用户年龄范围和漏洞严重性等上下文因素。利用并增强了开源LLM漏洞测试框架Garak来捕获多种威胁向量（如错误信息、代码幻觉、社交工程和恶意代码生成），并在一个采用检索增强生成（RAG）的聊天机器人场景中验证了该指标。

Result: 通过在采用检索增强生成（RAG）的聊天机器人场景中的演示表明，该方法产生的汇总风险评分能够有效地指导短期的风险缓解措施以及长期的模型设计和部署改进。

Conclusion: 多维度风险评估对于运营安全、可靠的AI驱动对话系统至关重要。

Abstract: The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has
enabled more advanced chatbots capable of human-like interactions. However,
these conversational agents introduce a broader set of operational risks that
extend beyond traditional cybersecurity considerations. In this work, we
propose a novel, instrumented risk-assessment metric that simultaneously
evaluates potential threats to three key stakeholders: the service-providing
organization, end users, and third parties. Our approach incorporates the
technical complexity required to induce erroneous behaviors in the
chatbot--ranging from non-induced failures to advanced prompt-injection
attacks--as well as contextual factors such as the target industry, user age
range, and vulnerability severity. To validate our metric, we leverage Garak,
an open-source framework for LLM vulnerability testing. We further enhance
Garak to capture a variety of threat vectors (e.g., misinformation, code
hallucinations, social engineering, and malicious code generation). Our
methodology is demonstrated in a scenario involving chatbots that employ
retrieval-augmented generation (RAG), showing how the aggregated risk scores
guide both short-term mitigation and longer-term improvements in model design
and deployment. The results underscore the importance of multi-dimensional risk
assessments in operationalizing secure, reliable AI-driven conversational
systems.

</details>


### [246] [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](https://arxiv.org/abs/2505.04806)
*Chetan Pathade*

Main category: cs.CR

TL;DR: 本文系统研究了针对大语言模型的越狱攻击，分析了其有效性，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型(LLM)应用广泛，但它们易受提示注入和越狱等对抗性攻击，这些攻击能绕过其安全防护机制。

Method: 论文对超过1400个对抗性提示进行了分类，分析了它们在GPT-4, Claude 2, Mistral 7B和Vicuna等多种先进LLM上的成功率，并研究了这些提示的泛化性和构建逻辑。

Result: 研究对越狱策略进行了系统性分类和分析，揭示了它们在不同LLM上的成功情况及其构建逻辑，并基于此提出了分层缓解策略。

Conclusion: 论文推荐采用分层缓解策略以及混合红队测试和沙盒方法来增强LLM的安全性。

Abstract: Large Language Models (LLMs) are increasingly integrated into consumer and
enterprise applications. Despite their capabilities, they remain susceptible to
adversarial attacks such as prompt injection and jailbreaks that override
alignment safeguards. This paper provides a systematic investigation of
jailbreak strategies against various state-of-the-art LLMs. We categorize over
1,400 adversarial prompts, analyze their success against GPT-4, Claude 2,
Mistral 7B, and Vicuna, and examine their generalizability and construction
logic. We further propose layered mitigation strategies and recommend a hybrid
red-teaming and sandboxing approach for robust LLM security.

</details>


### [247] [ChainMarks: Securing DNN Watermark with Cryptographic Chain](https://arxiv.org/abs/2505.04977)
*Brian Choi,Shu Wang,Isabelle Choi,Kun Sun*

Main category: cs.CR

TL;DR: 提出了一种名为 ChainMarks 的安全深度神经网络（DNN）水印方案，通过密码链生成触发输入并使用两阶段蒙特卡洛方法进行水印验证，以提高鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的DNN水印方案易受水印移除和歧义攻击，且水印存在性的判定标准模糊，增加了攻击成功的可能性。

Method: ChainMarks方案：1) 通过对密钥重复应用哈希函数生成触发输入作为水印数据集，其目标标签由模型所有者的数字签名生成；2) 在原始数据集和水印数据集上训练DNN模型；3) 通过比较触发输入的预测标签与目标标签，并结合特定模型的分类概率，使用两阶段蒙特卡洛方法和更精确的决策阈值来验证水印。

Result: 实验结果表明，与现有先进的水印方案相比，ChainMarks 表现出更高的鲁棒性和安全性。在相同的水印准确率水平下，ChainMarks 提供了更高的水印存在概率保证。

Conclusion: ChainMarks 是一种更安全、更鲁棒的DNN水印方案，有效提升了水印的保护能力和验证的准确性。

Abstract: With the widespread deployment of deep neural network (DNN) models, dynamic
watermarking techniques are being used to protect the intellectual property of
model owners. However, recent studies have shown that existing watermarking
schemes are vulnerable to watermark removal and ambiguity attacks. Besides, the
vague criteria for determining watermark presence further increase the
likelihood of such attacks. In this paper, we propose a secure DNN watermarking
scheme named ChainMarks, which generates secure and robust watermarks by
introducing a cryptographic chain into the trigger inputs and utilizes a
two-phase Monte Carlo method for determining watermark presence. First,
ChainMarks generates trigger inputs as a watermark dataset by repeatedly
applying a hash function over a secret key, where the target labels associated
with trigger inputs are generated from the digital signature of model owner.
Then, the watermarked model is produced by training a DNN over both the
original and watermark datasets. To verify watermarks, we compare the predicted
labels of trigger inputs with the target labels and determine ownership with a
more accurate decision threshold that considers the classification probability
of specific models. Experimental results show that ChainMarks exhibits higher
levels of robustness and security compared to state-of-the-art watermarking
schemes. With a better marginal utility, ChainMarks provides a higher
probability guarantee of watermark presence in DNN models with the same level
of watermark accuracy.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [248] [Representing spherical tensors with scalar-based machine-learning models](https://arxiv.org/abs/2505.05404)
*Michelangelo Domina,Filippo Bigi,Paolo Pegolo,Michele Ceriotti*

Main category: physics.chem-ph

TL;DR: 提出一种新的3D点云等变模型构建方法：将等变函数表示为标量函数与小型对称张量基的乘积，并提供快速准确的近似方案。


<details>
  <summary>Details</summary>
Motivation: 现有处理3D点云的旋转等变模型因对称性约束导致计算量大且实现复杂，而无约束架构学习到的对称性是近似的，因此需要一种更高效简洁的方法。

Method: 将等变函数表示为点云坐标的标量函数与一小组具有适当对称性的张量基的乘积。同时，提出了该通用表达式的近似形式。

Result: 提出的近似表达式虽然不具备通用逼近性质，但在实际应用场景中表现出快速、易于实现和准确的特点。

Conclusion: 本研究探索了一种构建等变函数的新路径，其提出的方法及近似表达式为学习具有旋转对称性的3D点云函数提供了兼顾效率、简易性和准确性的有效途径。

Abstract: Rotational symmetry plays a central role in physics, providing an elegant
framework to describe how the properties of 3D objects -- from atoms to the
macroscopic scale -- transform under the action of rigid rotations. Equivariant
models of 3D point clouds are able to approximate structure-property relations
in a way that is fully consistent with the structure of the rotation group, by
combining intermediate representations that are themselves spherical tensors.
The symmetry constraints however make this approach computationally demanding
and cumbersome to implement, which motivates increasingly popular unconstrained
architectures that learn approximate symmetries as part of the training
process. In this work, we explore a third route to tackle this learning
problem, where equivariant functions are expressed as the product of a scalar
function of the point cloud coordinates and a small basis of tensors with the
appropriate symmetry. We also propose approximations of the general expressions
that, while lacking universal approximation properties, are fast, simple to
implement, and accurate in practical settings.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [249] [Local linear Fréchet curve regression in manifolds](https://arxiv.org/abs/2505.05168)
*M. D. Ruiz-Medina,A. Torres--Signes*

Main category: math.ST

TL;DR: 本文研究流形上时间相关双变量曲线数据的弗雷歇条件均值的局部线性逼近，提出了外在和内在两种方法，并通过模拟和真实数据进行了验证。


<details>
  <summary>Details</summary>
Motivation: 解决先前全局弗雷歇函数回归研究中未充分探讨的流形数据局部线性逼近问题，特别是在时间相关双变量曲线数据场景下。

Method: 提出了两种局部线性逼近方法：1) 外在法：在时变切空间中通过投影到环境希尔伯特空间的标准正交基上获得预测器，利用指数映射和对数映射计算；2) 内在法：采用加权弗雷歇均值方法计算预测器。通过模拟研究和真实数据应用（NASA MAGSAT卫星数据预测磁场矢量）评估了这两种方法及Nadaraya-Watson型弗雷歇曲线预测器的性能。

Result: 确保了外在预测器的存在性和唯一性，并证明了内在局部逼近的渐近最优性。模拟研究展示了所提出的外在和内在函数预测器以及Nadaraya-Watson型弗雷歇曲线预测器的性能。真实数据应用通过交叉验证测试了这些方法的有限样本特性。

Conclusion: 本文提出的外在和内在局部线性弗雷歇函数回归方法为流形值曲线数据提供了有效的局部逼近工具，其性能在理论上得到证明，并通过模拟和实际应用得到验证。

Abstract: Global Fr\'echet functional regression has been recently addressed from time
correlated bivariate curve data evaluated in a manifold (see Torres et al.
2025). For this type of curve data sets, the present paper solves the problem
of local linear approximation of the Fr\'echet conditional mean in an extrinsic
and intrinsic way. The extrinsic local linear Fr\'echet functional regression
predictor is obtained in the time varying tangent space by projection into an
orthornormal basis of the ambient Hilbert space. The conditions assumed ensure
the existence and uniqueness of this predictor, and its computation via
exponential and logarithmic maps. A weighted Fr\'echet mean approach is adopted
in the computation of an intrinsic local linear Fr\'echet functional regression
predictor. The asymptotic optimality of this intrinsic local approximation is
also proved. The performance of the empirical version of both, extrinsic and
intrinsic functional predictors, and of a Nadaraya-Watson type Fr\'echet curve
predictor is illustrated in the simulation study undertaken. The finite-sample
size properties are also tested in a real-data application via
cross-validation. Specifically, functional prediction of the magnetic vector
field from the time-varying geocentric latitude and longitude of the satellite
NASA's MAGSAT spacecraft is addressed.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [250] [Advancing 3D Medical Image Segmentation: Unleashing the Potential of Planarian Neural Networks in Artificial Intelligence](https://arxiv.org/abs/2505.04664)
*Ziyuan Huang,Kevin Huggins,Srikar Bellur*

Main category: eess.IV

TL;DR: 研究提出了一种模仿涡虫神经网络结构的深度学习模型PNN-UNet，用于3D医学图像分割，并在海马体MRI数据集上取得了优于UNet及其变体的性能。


<details>
  <summary>Details</summary>
Motivation: 希望通过模仿涡虫神经系统（大脑协调、神经索分工）的结构，构建一种新型的深度神经网络，以克服现有单体网络（如UNet）和模块化网络在3D医学图像分割任务中的局限性，提升分割性能。

Method: 提出了PNN-UNet架构。该架构由一个Deep-UNet和一个Wide-UNet（模拟神经索）以及一个密集连接的自动编码器（模拟大脑）组成，以此复制涡虫神经网络的结构。

Result: 在3D MRI海马体数据集上进行的实验表明，无论是否使用数据增强，PNN-UNet在图像分割方面的表现均优于基准的UNet模型以及其他几种UNet变体。

Conclusion: PNN-UNet作为一种受生物启发的网络结构，在3D医学图像分割领域展现出优势，其性能超越了传统的UNet及其改进版本，为医学图像分析提供了新的有效工具。

Abstract: Our study presents PNN-UNet as a method for constructing deep neural networks
that replicate the planarian neural network (PNN) structure in the context of
3D medical image data. Planarians typically have a cerebral structure
comprising two neural cords, where the cerebrum acts as a coordinator, and the
neural cords serve slightly different purposes within the organism's
neurological system. Accordingly, PNN-UNet comprises a Deep-UNet and a
Wide-UNet as the nerve cords, with a densely connected autoencoder performing
the role of the brain. This distinct architecture offers advantages over both
monolithic (UNet) and modular networks (Ensemble-UNet). Our outcomes on a 3D
MRI hippocampus dataset, with and without data augmentation, demonstrate that
PNN-UNet outperforms the baseline UNet and several other UNet variants in image
segmentation.

</details>


### [251] [Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction](https://arxiv.org/abs/2505.05054)
*Navya Sonal Agarwal,Jan Philipp Schneider,Kanchana Vaishnavi Gandikota,Syed Muhammad Kazim,John Meshreki,Ivo Ihrke,Michael Moeller*

Main category: eess.IV

TL;DR: 本文研究了直接从傅里叶叠层显微成像（FPM）的原始测量数据中进行图像内容分类，发现卷积神经网络（CNN）能有效提取信息，性能优于传统方法且效率更高，并通过数据复用减少数据量。


<details>
  <summary>Details</summary>
Motivation: 傅里叶叠层显微成像（FPM）技术虽然能提供高分辨率、大视场图像，但其高分辨率图像的重建过程计算量巨大且耗时，尤其对于大视场成像。

Method: 研究直接在傅里叶叠层显微成像（FPM）的测量数据上使用卷积神经网络（CNN）进行图像内容分类，从而跳过图像重建步骤。同时，探索了通过学习多路复用技术来组合多个原始测量数据以减少数据量的方法。

Result: 卷积神经网络（CNN）能够从FPM测量序列中提取有意义的信息，其分类性能显著优于在单个带限图像上的分类（最高提升12%），并且比先重建高分辨率图像再分类的方法效率更高。此外，学习的多路复用技术可以在保持分类准确率的同时显著减少数据量和采集时间。

Conclusion: 直接对FPM测量数据进行分类是一种高效且有效的方法。CNN能够直接从原始数据中提取信息进行分类，其性能优于对单一低分辨率图像的分类，计算效率也远高于先重建再分类的传统流程。通过学习的多路复用技术可以进一步减少数据量和采集时间，同时保持分类精度。

Abstract: The computational imaging technique of Fourier Ptychographic Microscopy (FPM)
enables high-resolution imaging with a wide field of view and can serve as an
extremely valuable tool, e.g. in the classification of cells in medical
applications. However, reconstructing a high-resolution image from tens or even
hundreds of measurements is computationally expensive, particularly for a wide
field of view. Therefore, in this paper, we investigate the idea of classifying
the image content in the FPM measurements directly without performing a
reconstruction step first. We show that Convolutional Neural Networks (CNN) can
extract meaningful information from measurement sequences, significantly
outperforming the classification on a single band-limited image (up to 12 %)
while being significantly more efficient than a reconstruction of a
high-resolution image. Furthermore, we demonstrate that a learned multiplexing
of several raw measurements allows maintaining the classification accuracy
while reducing the amount of data (and consequently also the acquisition time)
significantly.

</details>


### [252] [Rethinking Boundary Detection in Deep Learning-Based Medical Image Segmentation](https://arxiv.org/abs/2505.04652)
*Yi Lin,Dong Zhang,Xiao Fang,Yufan Chen,Kwang-Ting Cheng,Hao Chen*

Main category: eess.IV

TL;DR: 提出了一种名为CTO的新型网络架构，通过结合CNN、ViT和显式边缘检测算子，以解决医学图像边界区域分割不精确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法在精确分割感兴趣区域方面表现尚可，但在边界区域的精确分割仍然具有挑战性。

Method: 提出CTO网络架构，采用编码器-解码器范式。编码器包含一个主流CNN流（捕捉局部特征）和一个辅助StitchViT流（整合远程依赖）。解码器采用边界引导策略，利用专用边缘检测算子生成的二元边界掩码提供显式指导。

Result: 在七个具有挑战性的医学图像分割数据集（ISIC 2016, PH2, ISIC 2018, CoNIC, LiTS17, BTCV）上进行的广泛实验表明，CTO在保持有竞争力的模型复杂度的同时，达到了最先进的分割精度。

Conclusion: CTO在分割精度方面超越了现有方法，并在准确性和效率之间取得了更好的平衡，且无需额外的数据输入或标签注入。

Abstract: Medical image segmentation is a pivotal task within the realms of medical
image analysis and computer vision. While current methods have shown promise in
accurately segmenting major regions of interest, the precise segmentation of
boundary areas remains challenging. In this study, we propose a novel network
architecture named CTO, which combines Convolutional Neural Networks (CNNs),
Vision Transformer (ViT) models, and explicit edge detection operators to
tackle this challenge. CTO surpasses existing methods in terms of segmentation
accuracy and strikes a better balance between accuracy and efficiency, without
the need for additional data inputs or label injections. Specifically, CTO
adheres to the canonical encoder-decoder network paradigm, with a dual-stream
encoder network comprising a mainstream CNN stream for capturing local features
and an auxiliary StitchViT stream for integrating long-range dependencies.
Furthermore, to enhance the model's ability to learn boundary areas, we
introduce a boundary-guided decoder network that employs binary boundary masks
generated by dedicated edge detection operators to provide explicit guidance
during the decoding process. We validate the performance of CTO through
extensive experiments conducted on seven challenging medical image segmentation
datasets, namely ISIC 2016, PH2, ISIC 2018, CoNIC, LiTS17, and BTCV. Our
experimental results unequivocally demonstrate that CTO achieves
state-of-the-art accuracy on these datasets while maintaining competitive model
complexity. The codes have been released at:
https://github.com/xiaofang007/CTO.

</details>


### [253] [Advanced 3D Imaging Approach to TSV/TGV Metrology and Inspection Using Only Optical Microscopy](https://arxiv.org/abs/2505.04913)
*Gugeong Sung*

Main category: eess.IV

TL;DR: 提出了一种结合混合场显微镜和光度立体视觉的硅和玻璃通孔检测新方法，以克服传统光学显微镜的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统光学显微镜在检测硅和玻璃通孔时，难以有效观察其内部结构和深度细节。

Method: 将混合场显微镜与光度立体视觉技术相结合，利用多种光照条件进行三维重建。

Result: 实验结果表明，该方法能有效捕获复杂的表面细节和内部结构，检测微小缺陷，并可视化深度和边缘异常。重建模型与实际测量的定量比较显示，该方法显著改进了检测过程，提高了成本效益、准确性和可重复性。

Conclusion: 所提出的方法在硅和玻璃通孔检测技术方面取得了显著进展，具有高精度、高可重复性和成本效益。

Abstract: This paper introduces an innovative approach to silicon and glass via
inspection, which combines hybrid field microscopy with photometric stereo.
Conventional optical microscopy techniques are generally limited to superficial
inspections and struggle to effectively visualize the internal structures of
silicon and glass vias. By utilizing various lighting conditions for 3D
reconstruction, the proposed method surpasses these limitations. By integrating
photometric stereo to the traditional optical microscopy, the proposed method
not only enhances the capability to detect micro-scale defects but also
provides a detailed visualization of depth and edge abnormality, which are
typically not visible with conventional optical microscopy inspection. The
experimental results demonstrated that the proposed method effectively captures
intricate surface details and internal structures. Quantitative comparisons
between the reconstructed models and actual measurements present the capability
of the proposed method to significantly improve silicon and glass via
inspection process. As a result, the proposed method achieves enhanced
cost-effectiveness while maintaining high accuracy and repeatability,
suggesting substantial advancements in silicon and glass via inspection
techniques

</details>


### [254] [MoRe-3DGSMR: Motion-resolved reconstruction framework for free-breathing pulmonary MRI based on 3D Gaussian representation](https://arxiv.org/abs/2505.04959)
*Tengya Peng,Ruyi Zha,Qing Zou*

Main category: eess.IV

TL;DR: 提出了一种基于三维高斯表示 (3DGS) 的无监督运动分辨肺部MRI重建框架，可实现高分辨率成像。


<details>
  <summary>Details</summary>
Motivation: 解决自由呼吸条件下高分辨率、运动分辨的三维各向同性肺部MRI重建所面临的挑战，特别是运动伪影问题。

Method: 1. 使用黄金角径向采样采集肺部MRI数据，并从k空间中心提取呼吸运动信号。
2. 根据运动信号将k空间数据分组成多个呼吸时相。
3. 应用3DGS框架从第一个运动时相重建参考图像。
4. 训练患者特异性卷积神经网络 (CNN) 估计形变矢量场 (DVFs)。
5. 利用DVFs通过空间变换生成其余运动时相的图像。

Result: 该框架在六个受试者的数据集上有效重建了高分辨率、运动分辨的肺部MR图像。与现有先进方法相比，其图像质量更高，表现为更高的信噪比和对比度噪声比。

Conclusion: 所提出的基于3DGS的无监督重建方法能够实现具有各向同性空间分辨率的精确运动分辨肺部MRI，其优越的图像质量使其具有成为临床肺部MR成像稳健解决方案的潜力。

Abstract: This study presents an unsupervised, motion-resolved reconstruction framework
for high-resolution, free-breathing pulmonary magnetic resonance imaging (MRI),
utilizing a three-dimensional Gaussian representation (3DGS). The proposed
method leverages 3DGS to address the challenges of motion-resolved 3D isotropic
pulmonary MRI reconstruction by enabling data smoothing between voxels for
continuous spatial representation. Pulmonary MRI data acquisition is performed
using a golden-angle radial sampling trajectory, with respiratory motion
signals extracted from the center of k-space in each radial spoke. Based on the
estimated motion signal, the k-space data is sorted into multiple respiratory
phases. A 3DGS framework is then applied to reconstruct a reference image
volume from the first motion state. Subsequently, a patient-specific
convolutional neural network is trained to estimate the deformation vector
fields (DVFs), which are used to generate the remaining motion states through
spatial transformation of the reference volume. The proposed reconstruction
pipeline is evaluated on six datasets from six subjects and bench-marked
against three state-of-the-art reconstruction methods. The experimental
findings demonstrate that the proposed reconstruction framework effectively
reconstructs high-resolution, motion-resolved pulmonary MR images. Compared
with existing approaches, it achieves superior image quality, reflected by
higher signal-to-noise ratio and contrast-to-noise ratio. The proposed
unsupervised 3DGS-based reconstruction method enables accurate motion-resolved
pulmonary MRI with isotropic spatial resolution. Its superior performance in
image quality metrics over state-of-the-art methods highlights its potential as
a robust solution for clinical pulmonary MR imaging.

</details>


### [255] [ADNP-15: An Open-Source Histopathological Dataset for Neuritic Plaque Segmentation in Human Brain Whole Slide Images with Frequency Domain Image Enhancement for Stain Normalization](https://arxiv.org/abs/2505.05041)
*Chenxi Zhao,Jianqiang Li,Qing Zhao,Jing Bai,Susana Boluda,Benoit Delatour,Lev Stimmer,Daniel Racoceanu,Gabriel Jimenez,Guanghui Fu*

Main category: eess.IV

TL;DR: 该研究针对阿尔茨海默病神经炎性斑块分割的挑战，发布了新的开源数据集 (ADNP-15)，并提出了一种图像增强方法，显著提高了深度学习模型在存在染色差异情况下的分割准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病病理特征（如神经炎性斑块）的准确分割对疾病研究至关重要，但面临大规模标注数据集缺乏和染色变异影响自动化分析两大难题。深度学习模型虽有潜力，但其性能易受染色不一致性影响，亟需有效的染色标准化与增强技术。

Method: 1. 发布了一个针对人脑全切片图像中神经炎性斑块的开源数据集 ADNP-15。 2. 对五种主流深度学习模型结合四种染色标准化技术进行了全面的基准评估。 3. 提出了一种新的图像增强方法，通过增强结构细节和减轻染色不一致性来提高分割精度。

Result: 实验表明，所提出的图像增强策略显著提升了模型在神经炎性斑块分割任务中的泛化能力和准确性，尤其在复杂组织结构和存在染色不一致性的情况下效果更佳。

Conclusion: 本研究通过提供开源数据集、基准测试和新颖的图像增强方法，有效应对了AD神经炎性斑块分割的挑战，其开源特性促进了研究的透明度、可复现性，并为领域内后续研究提供了支持。

Abstract: Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by
amyloid-beta plaques and tau neurofibrillary tangles, which serve as key
histopathological features. The identification and segmentation of these
lesions are crucial for understanding AD progression but remain challenging due
to the lack of large-scale annotated datasets and the impact of staining
variations on automated image analysis. Deep learning has emerged as a powerful
tool for pathology image segmentation; however, model performance is
significantly influenced by variations in staining characteristics,
necessitating effective stain normalization and enhancement techniques. In this
study, we address these challenges by introducing an open-source dataset
(ADNP-15) of neuritic plaques (i.e., amyloid deposits combined with a crown of
dystrophic tau-positive neurites) in human brain whole slide images. We
establish a comprehensive benchmark by evaluating five widely adopted deep
learning models across four stain normalization techniques, providing deeper
insights into their influence on neuritic plaque segmentation. Additionally, we
propose a novel image enhancement method that improves segmentation accuracy,
particularly in complex tissue structures, by enhancing structural details and
mitigating staining inconsistencies. Our experimental results demonstrate that
this enhancement strategy significantly boosts model generalization and
segmentation accuracy. All datasets and code are open-source, ensuring
transparency and reproducibility while enabling further advancements in the
field.

</details>


### [256] [Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection](https://arxiv.org/abs/2505.05291)
*Benjamin A. Cohen,Jonathan Fhima,Meishar Meisel,Baskin Meital,Luis Filipe Nakayama,Eran Berkowitz,Joachim A. Behar*

Main category: eess.IV

TL;DR: 研究比较了不同预训练策略（自然图像 vs. 眼科图像）的自监督学习视觉Transformer模型在视网膜图像中识别年龄相关性黄斑变性（AMD）的性能，发现自然图像预训练的模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 自监督学习（SSL）已成功应用于视觉Transformer（ViTs）并在自然图像上取得良好效果，基础模型在眼科成像中也显示出潜力，但领域内（in-domain）预训练在视网膜成像中的具体益处尚不明确。

Method: 研究人员在七个包含总计70,000张专家标注的数字眼底图像（DFI）数据集上，对六种经过SSL预训练的ViT模型进行了基准测试，任务是识别中晚期年龄相关性黄斑变性（AMD）。比较的模型包括在自然图像上预训练的模型（如iBOT）、领域特定模型以及一个无预训练的基线ViT-L模型。

Result: 在自然图像上预训练的iBOT模型实现了最高的跨分布泛化能力，其AUROC范围为0.80-0.97，优于领域特定模型（AUROC 0.78-0.96）和无预训练的基线ViT-L模型（AUROC 0.68-0.91）。此外，研究还发布了一个名为BRAMD的巴西AMD眼底图像开放数据集（n=587）。

Conclusion: 研究结果表明，基础模型（特别是那些在自然图像上预训练的模型）对于改进AMD识别具有重要价值，并对领域内预训练是必要的这一传统观念提出了挑战。

Abstract: Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to
learn robust representations from large-scale natural image datasets, enhancing
their generalization across domains. In retinal imaging, foundation models
pretrained on either natural or ophthalmic data have shown promise, but the
benefits of in-domain pretraining remain uncertain. To investigate this, we
benchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets
totaling 70,000 expert-annotated images for the task of moderate-to-late
age-related macular degeneration (AMD) identification. Our results show that
iBOT pretrained on natural images achieves the highest out-of-distribution
generalization, with AUROCs of 0.80-0.97, outperforming domain-specific models,
which achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining,
which achieved AUROCs of 0.68-0.91. These findings highlight the value of
foundation models in improving AMD identification and challenge the assumption
that in-domain pretraining is necessary. Furthermore, we release BRAMD, an
open-access dataset (n=587) of DFIs with AMD labels from Brazil.

</details>


### [257] [RepSNet: A Nucleus Instance Segmentation model based on Boundary Regression and Structural Re-parameterization](https://arxiv.org/abs/2505.05073)
*Shengchun Xiong,Xiangru Li,Yunpeng Zhong,Wanfen Peng*

Main category: eess.IV

TL;DR: 该研究提出RepSNet，一种基于细胞核边界回归和结构重参数化的神经网络，用于组织病理图像中的细胞核分割和分类，旨在解决计算效率和重叠目标处理的挑战。


<details>
  <summary>Details</summary>
Motivation: 病理诊断是肿瘤诊断的金标准，而细胞核实例分割是数字病理分析的关键步骤。现有研究在模型计算效率和重叠目标处理方面面临主要挑战。

Method: 设计了RepSNet神经网络模型。首先，RepSNet为每个像素估计其父细胞核的边界位置信息（BPI），该估计结合了像素的局部信息和父细胞核的上下文信息。然后，通过提出的边界投票机制（BVM）聚合一系列像素的BPI来估计细胞核边界，并使用连通分量分析从估计的细胞核边界计算实例分割结果。此外，RepSNet采用可重参数化的编码器-解码器结构，以聚合多尺度特征提升分割精度，并通过结构重参数化技术减少模型推理阶段的参数量和计算负担。

Result: 大量实验证明，与几种典型的基准模型相比，RepSNet在细胞核分割和分类任务上表现出优越性。

Conclusion: RepSNet通过其新颖的边界回归、边界投票机制以及可重参数化结构，能够有效提升细胞核分割的准确性，同时降低计算复杂度，为解决组织病理图像分析中的细胞核重叠问题提供了有效方案。

Abstract: Pathological diagnosis is the gold standard for tumor diagnosis, and nucleus
instance segmentation is a key step in digital pathology analysis and
pathological diagnosis. However, the computational efficiency of the model and
the treatment of overlapping targets are the major challenges in the studies of
this problem. To this end, a neural network model RepSNet was designed based on
a nucleus boundary regression and a structural re-parameterization scheme for
segmenting and classifying the nuclei in H\&E-stained histopathological images.
First, RepSNet estimates the boundary position information (BPI) of the parent
nucleus for each pixel. The BPI estimation incorporates the local information
of the pixel and the contextual information of the parent nucleus. Then, the
nucleus boundary is estimated by aggregating the BPIs from a series of pixels
using a proposed boundary voting mechanism (BVM), and the instance segmentation
results are computed from the estimated nucleus boundary using a connected
component analysis procedure. The BVM intrinsically achieves a kind of
synergistic belief enhancement among the BPIs from various pixels. Therefore,
different from the methods available in literature that obtain nucleus
boundaries based on a direct pixel recognition scheme, RepSNet computes its
boundary decisions based on some guidances from macroscopic information using
an integration mechanism. In addition, RepSNet employs a re-parametrizable
encoder-decoder structure. This model can not only aggregate features from some
receptive fields with various scales which helps segmentation accuracy
improvement, but also reduce the parameter amount and computational burdens in
the model inference phase through the structural re-parameterization technique.
Extensive experiments demonstrated the superiorities of RepSNet compared to
several typical benchmark models.

</details>


### [258] [MDAA-Diff: CT-Guided Multi-Dose Adaptive Attention Diffusion Model for PET Denoising](https://arxiv.org/abs/2505.05112)
*Xiaolong Niu,Zanting Ye,Xu Han,Yanchao Huang,Hao Sun,Hubing Wu,Lijun Lu*

Main category: eess.IV

TL;DR: 该研究提出了一种名为 MDAA-Diff 的新型 CT 引导多剂量自适应注意力去噪扩散模型，用于从低剂量 PET 图像生成高质量的标准剂量 PET 图像。


<details>
  <summary>Details</summary>
Motivation: 获取高质量 PET 图像需使用高剂量放射性示踪剂，增加了辐射暴露风险。现有低剂量 PET 去噪方法忽略了患者间的剂量反应差异及 CT 图像的互补解剖约束。

Method: 提出了一种 CT 引导的多剂量自适应注意力去噪扩散模型 (MDAA-Diff)。该模型集成了 CT 引导的高频小波注意力 (HWA) 模块，利用小波变换从 CT 图像中分离高频解剖边界特征并融入 PET 图像；同时引入了剂量自适应注意力 (DAA) 模块，将剂量水平动态整合到通道空间注意力权重计算中。

Result: 在 18F-FDG 和 68Ga-FAPI 数据集上的大量实验证明，MDAA-Diff 在低剂量条件下保留诊断质量方面优于当前最先进的方法。

Conclusion: MDAA-Diff 通过整合解剖指导和剂量水平自适应，有效提升了多剂量 PET 图像的去噪性能，为在降低辐射剂量下保持诊断质量提供了有前景的解决方案。

Abstract: Acquiring high-quality Positron Emission Tomography (PET) images requires
administering high-dose radiotracers, which increases radiation exposure risks.
Generating standard-dose PET (SPET) from low-dose PET (LPET) has become a
potential solution. However, previous studies have primarily focused on single
low-dose PET denoising, neglecting two critical factors: discrepancies in dose
response caused by inter-patient variability, and complementary anatomical
constraints derived from CT images. In this work, we propose a novel CT-Guided
Multi-dose Adaptive Attention Denoising Diffusion Model (MDAA-Diff) for
multi-dose PET denoising. Our approach integrates anatomical guidance and
dose-level adaptation to achieve superior denoising performance under low-dose
conditions. Specifically, this approach incorporates a CT-Guided High-frequency
Wavelet Attention (HWA) module, which uses wavelet transforms to separate
high-frequency anatomical boundary features from CT images. These extracted
features are then incorporated into PET imaging through an adaptive weighted
fusion mechanism to enhance edge details. Additionally, we propose the
Dose-Adaptive Attention (DAA) module, a dose-conditioned enhancement mechanism
that dynamically integrates dose levels into channel-spatial attention weight
calculation. Extensive experiments on 18F-FDG and 68Ga-FAPI datasets
demonstrate that MDAA-Diff outperforms state-of-the-art approaches in
preserving diagnostic quality under reduced-dose conditions. Our code is
publicly available.

</details>


### [259] [Improved Brain Tumor Detection in MRI: Fuzzy Sigmoid Convolution in Deep Learning](https://arxiv.org/abs/2505.05208)
*Muhammad Irfan,Anum Nawaz,Riku Klen,Abdulhamit Subasi,Tomi Westerlund,Wei Chen*

Main category: eess.IV

TL;DR: 该研究提出了一种基于模糊S形卷积（FSC）的新型CNN模型，用于肿瘤检测，显著减少了模型参数，同时保持了高分类精度。


<details>
  <summary>Details</summary>
Motivation: 现有用于肿瘤检测的卷积神经网络（CNN）模型存在过参数化问题，这限制了其性能提升。早期检测和准确诊断对改善患者预后至关重要。

Method: 引入了模糊S形卷积（FSC）以及漏斗顶部（top-of-the-funnel）和漏斗中部（middle-of-the-funnel）两个附加模块。核心是一种新型卷积算子，可有效扩大感受野同时保持输入数据完整性。在卷积层内集成模糊S形激活函数，并将模糊逻辑融入架构以提高适应性和鲁棒性。

Result: 所提出的方法显著减少了可训练参数数量，且未牺牲分类准确性。在三个不同的基准数据集上，FSC基础架构分别达到了99.17%、99.75%和99.89%的分类准确率。该模型使用的参数比大规模迁移学习架构少100倍。

Conclusion: 该研究提供了一种轻量级、高性能的深度学习模型，适用于医学成像应用，尤其适合早期脑肿瘤检测，具有计算效率高和性能优越的特点。

Abstract: Early detection and accurate diagnosis are essential to improving patient
outcomes. The use of convolutional neural networks (CNNs) for tumor detection
has shown promise, but existing models often suffer from overparameterization,
which limits their performance gains. In this study, fuzzy sigmoid convolution
(FSC) is introduced along with two additional modules: top-of-the-funnel and
middle-of-the-funnel. The proposed methodology significantly reduces the number
of trainable parameters without compromising classification accuracy. A novel
convolutional operator is central to this approach, effectively dilating the
receptive field while preserving input data integrity. This enables efficient
feature map reduction and enhances the model's tumor detection capability. In
the FSC-based model, fuzzy sigmoid activation functions are incorporated within
convolutional layers to improve feature extraction and classification. The
inclusion of fuzzy logic into the architecture improves its adaptability and
robustness. Extensive experiments on three benchmark datasets demonstrate the
superior performance and efficiency of the proposed model. The FSC-based
architecture achieved classification accuracies of 99.17%, 99.75%, and 99.89%
on three different datasets. The model employs 100 times fewer parameters than
large-scale transfer learning architectures, highlighting its computational
efficiency and suitability for detecting brain tumors early. This research
offers lightweight, high-performance deep-learning models for medical imaging
applications.

</details>


### [260] [White Light Specular Reflection Data Augmentation for Deep Learning Polyp Detection](https://arxiv.org/abs/2505.05248)
*Jose Angel Nuñez,Fabian Vazquez,Diego Adame,Xiaoyan Fu,Pengfei Gu,Bin Fu*

Main category: eess.IV

TL;DR: 提出一种通过人工增加白光反射的数据增强方法，以提高深度学习结直肠息肉检测器的性能，减少假阳性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习息肉检测器常将内窥镜的白光反射误认为息肉，导致假阳性，影响检测准确性。

Method: 首先生成人工光照库，然后确定训练图像中不应添加人工光照的区域，最后使用滑动窗口方法将人工光照添加到合适区域，生成增强图像，为模型提供更具挑战性的训练场景。

Result: 实验结果表明，该新型数据增强方法有效提升了息肉检测模型的性能。

Conclusion: 通过让模型在训练中接触更多易混淆的白光反射场景，可以提高其区分真实息肉和伪影的能力，从而改善检测效果。

Abstract: Colorectal cancer is one of the deadliest cancers today, but it can be
prevented through early detection of malignant polyps in the colon, primarily
via colonoscopies. While this method has saved many lives, human error remains
a significant challenge, as missing a polyp could have fatal consequences for
the patient. Deep learning (DL) polyp detectors offer a promising solution.
However, existing DL polyp detectors often mistake white light reflections from
the endoscope for polyps, which can lead to false positives.To address this
challenge, in this paper, we propose a novel data augmentation approach that
artificially adds more white light reflections to create harder training
scenarios. Specifically, we first generate a bank of artificial lights using
the training dataset. Then we find the regions of the training images that we
should not add these artificial lights on. Finally, we propose a sliding window
method to add the artificial light to the areas that fit of the training
images, resulting in augmented images. By providing the model with more
opportunities to make mistakes, we hypothesize that it will also have more
chances to learn from those mistakes, ultimately improving its performance in
polyp detection. Experimental results demonstrate the effectiveness of our new
data augmentation method.

</details>


### [261] [Augmented Deep Contexts for Spatially Embedded Video Coding](https://arxiv.org/abs/2505.05309)
*Yifan Bian,Chuanbo Tang,Li Li,Dong Liu*

Main category: eess.IV

TL;DR: 提出了一种结合空间参考的神经视频编解码器 (SEVC)，解决了传统NVC在处理大运动和新出现物体时的局限性，并提升了压缩性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经视频编解码器 (NVC) 仅使用时间参考，导致其在处理大运动或新出现物体时因上下文信息有限和潜在先验错位而表现不佳。

Method: 提出了一种空间嵌入视频编解码器 (SEVC)。它通过压缩低分辨率视频作为空间参考，并结合时间参考生成增强的运动矢量和混合时空上下文。引入了由多个时间潜在表示增强的空间引导潜在先验，以解决先验错位问题。最后，设计了联合时空优化策略，实现空间参考的质量自适应比特分配。

Result: SEVC 有效缓解了处理大运动或新出现物体时的局限性，相比先前的最优 NVC 节省了 11.9% 的比特率，同时还能提供额外的低分辨率码流。

Conclusion: 所提出的 SEVC 方法通过引入空间参考，显著改善了神经视频编码在复杂场景下的性能，并提高了码率效率。

Abstract: Most Neural Video Codecs (NVCs) only employ temporal references to generate
temporal-only contexts and latent prior. These temporal-only NVCs fail to
handle large motions or emerging objects due to limited contexts and misaligned
latent prior. To relieve the limitations, we propose a Spatially Embedded Video
Codec (SEVC), in which the low-resolution video is compressed for spatial
references. Firstly, our SEVC leverages both spatial and temporal references to
generate augmented motion vectors and hybrid spatial-temporal contexts.
Secondly, to address the misalignment issue in latent prior and enrich the
prior information, we introduce a spatial-guided latent prior augmented by
multiple temporal latent representations. At last, we design a joint
spatial-temporal optimization to learn quality-adaptive bit allocation for
spatial references, further boosting rate-distortion performance. Experimental
results show that our SEVC effectively alleviates the limitations in handling
large motions or emerging objects, and also reduces 11.9% more bitrate than the
previous state-of-the-art NVC while providing an additional low-resolution
bitstream. Our code and model are available at https://github.com/EsakaK/SEVC.

</details>


### [262] [OcularAge: A Comparative Study of Iris and Periocular Images for Pediatric Age Estimation](https://arxiv.org/abs/2505.05374)
*Naveenkumar G Venkataswamy,Poorna Ravi,Stephanie Schuckers,Masudul H. Imtiaz*

Main category: eess.IV

TL;DR: 本研究通过比较儿童虹膜和眼周图像，发现使用深度学习分析眼周图像能以1.33年的平均绝对误差估计4-16岁儿童年龄，为隐私保护的年龄验证应用提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效方法通过儿童眼部图像估计年龄，尤其是在虹膜和眼周区域，这限制了在儿童应用中进行隐私保护年龄验证的技术发展。

Method: 采用多任务深度学习框架，在包含288名4-16岁儿童、历时8年收集的超21000张近红外眼部图像的纵向数据集上，比较了基于虹膜和眼周图像的年龄估计和年龄组分类性能，并探索了适应非方形输入的卷积神经网络（CNN）架构。

Result: 眼周图像模型在年龄估计上显著优于虹膜模型，平均绝对误差（MAE）为1.33年，年龄组分类准确率达83.82%。模型对不同传感器具有鲁棒性，且推理速度快（<10毫秒/图像），适用于实时应用。

Conclusion: 本研究首次证明了从儿童眼部图像（特别是眼周区域）进行可靠年龄估计的可行性，为设计以儿童为中心的生物识别系统和隐私保护年龄验证应用提供了首个纵向基准和坚实基础。

Abstract: Estimating a child's age from ocular biometric images is challenging due to
subtle physiological changes and the limited availability of longitudinal
datasets. Although most biometric age estimation studies have focused on facial
features and adult subjects, pediatric-specific analysis, particularly of the
iris and periocular regions, remains relatively unexplored. This study presents
a comparative evaluation of iris and periocular images for estimating the ages
of children aged between 4 and 16 years. We utilized a longitudinal dataset
comprising more than 21,000 near-infrared (NIR) images, collected from 288
pediatric subjects over eight years using two different imaging sensors. A
multi-task deep learning framework was employed to jointly perform age
prediction and age-group classification, enabling a systematic exploration of
how different convolutional neural network (CNN) architectures, particularly
those adapted for non-square ocular inputs, capture the complex variability
inherent in pediatric eye images. The results show that periocular models
consistently outperform iris-based models, achieving a mean absolute error
(MAE) of 1.33 years and an age-group classification accuracy of 83.82%. These
results mark the first demonstration that reliable age estimation is feasible
from children's ocular images, enabling privacy-preserving age checks in
child-centric applications. This work establishes the first longitudinal
benchmark for pediatric ocular age estimation, providing a foundation for
designing robust, child-focused biometric systems. The developed models proved
resilient across different imaging sensors, confirming their potential for
real-world deployment. They also achieved inference speeds of less than 10
milliseconds per image on resource-constrained VR headsets, demonstrating their
suitability for real-time applications.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [263] [Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups](https://arxiv.org/abs/2505.04725)
*Robin Chhabra,Farzaneh Abdollahi*

Main category: eess.SY

TL;DR: 提出了一种基于几何神经网络的跟踪控制器，用于处理在未知动态、执行器故障和有界扰动下，在矩阵李群上演化的系统。


<details>
  <summary>Details</summary>
Motivation: 解决在矩阵李群上演化系统面临未知动态、执行器故障和有界扰动时的跟踪控制问题，特别是现有方法可能存在的参数化奇异性或与李群结构不兼容的问题。

Method: 利用矩阵李群切丛的左不变性，提出了一套与李群结构内在兼容且无需显式参数化的神经网络权重学习规则。该方法利用李群的几何特性避免参数化奇异性，并进行全局最优权重搜索。使用李雅普诺夫直接法证明误差信号的最终有界性。

Result: 成功建立了所有误差信号（包括神经网络权重、无坐标配置误差函数和跟踪速度误差）的最终有界性。通过在特殊欧几里得群上的多智能体系统分散编队控制的仿真结果，验证了所提方法的有效性。

Conclusion: 该几何神经网络控制器能够有效解决矩阵李群上具有未知动态、执行器故障和扰动的系统的跟踪控制问题，提供了一种结构保持且能进行全局优化的方法。

Abstract: We present a geometric neural network-based tracking controller for systems
evolving on matrix Lie groups under unknown dynamics, actuator faults, and
bounded disturbances. Leveraging the left-invariance of the tangent bundle of
matrix Lie groups, viewed as an embedded submanifold of the vector space
$\R^{N\times N}$, we propose a set of learning rules for neural network weights
that are intrinsically compatible with the Lie group structure and do not
require explicit parameterization. Exploiting the geometric properties of Lie
groups, this approach circumvents parameterization singularities and enables a
global search for optimal weights. The ultimate boundedness of all error
signals -- including the neural network weights, the coordinate-free
configuration error function, and the tracking velocity error -- is established
using Lyapunov's direct method. To validate the effectiveness of the proposed
method, we provide illustrative simulation results for decentralized formation
control of multi-agent systems on the Special Euclidean group.

</details>


### [264] [LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations](https://arxiv.org/abs/2505.05203)
*Wangkun Xu,Zhongda Chu,Fei Teng*

Main category: eess.SY

TL;DR: 该论文提出LAPSO框架，一种学习增强的电力系统运营方法，旨在整合机器学习与传统模型，以应对高比例可再生能源并网带来的挑战，实现运营任务的集成与优化。


<details>
  <summary>Details</summary>
Motivation: 高比例可再生能源并网对传统电力系统运营的经济性、稳定性和鲁棒性决策构成挑战。现有机器学习方法虽有潜力，但常缺乏与传统方法的系统性整合。

Method: 提出LAPSO（学习增强的电力系统运营）整体框架。该框架以原生优化为视角，聚焦运营阶段，旨在打破预测、运营、控制等任务间的时间壁垒，并在训练和推理阶段统一机器学习与模型优化的目标。

Result: 系统分析与仿真验证了LAPSO在设计新的集成算法（如稳定性约束优化SCO和基于目标的预测OBF）方面的有效性，并实现了对不确定性来源的端到端追踪。同时，发布了专用Python包lapso，支持自动化地为现有电力系统优化模型增加可学习组件。

Conclusion: LAPSO框架能有效整合机器学习与传统电力系统运营方法，提升决策质量，为设计集成算法和追踪不确定性提供了新途径，并促进了方法的实际应用。

Abstract: With the high penetration of renewables, traditional model-based power system
operation is challenged to deliver economic, stable, and robust decisions.
Machine learning has emerged as a powerful modeling tool for capturing complex
dynamics to address these challenges. However, its separate design often lacks
systematic integration with existing methods. To fill the gap, this paper
proposes a holistic framework of Learning-Augmented Power System Operations
(LAPSO, pronounced as Lap-So). Adopting a native optimization perspective,
LAPSO is centered on the operation stage and aims to break the boundary between
temporally siloed power system tasks, such as forecast, operation and control,
while unifying the objectives of machine learning and model-based optimizations
at both training and inference stages. Systematic analysis and simulations
demonstrate the effectiveness of applying LAPSO in designing new integrated
algorithms, such as stability-constrained optimization (SCO) and
objective-based forecasting (OBF), while enabling end-to-end tracing of
different sources of uncertainties. In addition, a dedicated Python
package-lapso is introduced to automatically augment existing power system
optimization models with learnable components. All code and data are available
at https://github.com/xuwkk/lapso_exp.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [265] [Generalization Analysis for Contrastive Representation Learning under Non-IID Settings](https://arxiv.org/abs/2505.04937)
*Nong Minh Hieu,Antoine Ledent*

Main category: stat.ML

TL;DR: 该研究为对比表示学习（CRL）在非独立同分布（non-i.i.d.）数据设置下提供了泛化分析。


<details>
  <summary>Details</summary>
Motivation: 现有对比表示学习的泛化理论都假设数据元组是独立同分布的，但这与实践中数据点会被重复使用的情况不符，导致元组间的独立性假设失效。

Method: 研究借鉴U统计量的相关理论，推导了在非独立同分布设置下对比表示学习的泛化界。

Result: 推导出的泛化界表明，每个类别所需的样本数量与该类别可学习特征表示类的覆盖数的对数成正比。并将此主要结果应用于推导常见函数类（如线性映射和神经网络）的超额风险界。

Conclusion: 该研究为非独立同分布数据下的对比表示学习提供了更符合实际的泛化理论分析。

Abstract: Contrastive Representation Learning (CRL) has achieved impressive success in
various domains in recent years. Nevertheless, the theoretical understanding of
the generalization behavior of CRL is limited. Moreover, to the best of our
knowledge, the current literature only analyzes generalization bounds under the
assumption that the data tuples used for contrastive learning are independently
and identically distributed. However, in practice, we are often limited to a
fixed pool of reusable labeled data points, making it inevitable to recycle
data across tuples to create sufficiently large datasets. Therefore, the
tuple-wise independence condition imposed by previous works is invalidated. In
this paper, we provide a generalization analysis for the CRL framework under
non-$i.i.d.$ settings that adheres to practice more realistically. Drawing
inspiration from the literature on U-statistics, we derive generalization
bounds which indicate the required number of samples in each class scales as
the logarithm of the covering number of the class of learnable feature
representations associated to each class. Next, we apply our main results to
derive excess risk bounds for common function classes such as linear maps and
neural networks.

</details>


### [266] [Learning Linearized Models from Nonlinear Systems under Initialization Constraints with Finite Data](https://arxiv.org/abs/2505.04954)
*Lei Xin,Baike She,Qi Dou,George Chiu,Shreyas Sundaram*

Main category: stat.ML

TL;DR: 本文研究了当真实系统动力学非线性时，如何从多条轨迹数据中辨识线性化模型，并提供了有限样本误差界。


<details>
  <summary>Details</summary>
Motivation: 现有线性系统辨识方法通常假设系统是真正线性的，并使用单一长轨迹数据。然而，实际系统往往是非线性的，需要在特定初始化区域约束下辨识其线性化模型。

Method: 提出了一种基于多轨迹的确定性数据采集算法，并结合正则化最小二乘法来学习线性化动力学模型。

Result: 提供了学习到的线性化动力学模型的有限样本误差界，表明可以一致地学习线性化动力学，并揭示了非线性误差与噪声误差之间的权衡。数值实验验证了理论结果，并显示了在存在非线性时，使用单一轨迹和i.i.d.随机输入的传统方法的不足。

Conclusion: 该研究提出的多轨迹方法能够有效地从非线性系统中学习线性化模型，并在存在非线性时优于传统的单轨迹方法。其提供的误差界有助于理解模型辨识的精度。

Abstract: The identification of a linear system model from data has wide applications
in control theory. The existing work that provides finite sample guarantees for
linear system identification typically uses data from a single long system
trajectory under i.i.d. random inputs, and assumes that the underlying dynamics
is truly linear. In contrast, we consider the problem of identifying a
linearized model when the true underlying dynamics is nonlinear, given that
there is a certain constraint on the region where one can initialize the
experiments. We provide a multiple trajectories-based deterministic data
acquisition algorithm followed by a regularized least squares algorithm, and
provide a finite sample error bound on the learned linearized dynamics. Our
error bound shows that one can consistently learn the linearized dynamics, and
demonstrates a trade-off between the error due to nonlinearity and the error
due to noise. We validate our results through numerical experiments, where we
also show the potential insufficiency of linear system identification using a
single trajectory with i.i.d. random inputs, when nonlinearity does exist.

</details>


### [267] [Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach](https://arxiv.org/abs/2505.04986)
*Qian Peng,Yajie Bao,Haojie Ren,Zhaojun Wang,Changliang Zou*

Main category: stat.ML

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Conformal prediction is a powerful tool for constructing prediction intervals
for black-box models, providing a finite sample coverage guarantee for
exchangeable data. However, this exchangeability is compromised when some
entries of the test feature are contaminated, such as in the case of cellwise
outliers. To address this issue, this paper introduces a novel framework called
detect-then-impute conformal prediction. This framework first employs an
outlier detection procedure on the test feature and then utilizes an imputation
method to fill in those cells identified as outliers. To quantify the
uncertainty in the processed test feature, we adaptively apply the detection
and imputation procedures to the calibration set, thereby constructing
exchangeable features for the conformal prediction interval of the test label.
We develop two practical algorithms, PDI-CP and JDI-CP, and provide a
distribution-free coverage analysis under some commonly used detection and
imputation procedures. Notably, JDI-CP achieves a finite sample $1-2\alpha$
coverage guarantee. Numerical experiments on both synthetic and real datasets
demonstrate that our proposed algorithms exhibit robust coverage properties and
comparable efficiency to the oracle baseline.

</details>


### [268] [Boosting Statistic Learning with Synthetic Data from Pretrained Large Models](https://arxiv.org/abs/2505.04992)
*Jialong Jiang,Wenkang Hu,Jian Huang,Yuling Jiao,Xu Liu*

Main category: stat.ML

TL;DR: 提出了一种通过生成和筛选高质量合成数据来增强预测模型性能的框架，并指出了生成模型在数据增强方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 生成模型（如Stable Diffusion）可以产生大量合成数据，但并非所有数据都能有效提升预测模型的性能，因此需要探索如何筛选并有效利用这些数据进行增强。

Method: 提出一个端到端框架，该框架生成合成数据，然后通过特定领域的统计方法进行系统性筛选，选择性地整合高质量样本以实现有效的数据增强。

Result: 实验表明，该框架在多种场景下均能持续提升预测性能。

Conclusion: 该框架展示了其潜力，但也强调了生成模型在数据增强方面的固有局限性：尽管能产生大量合成数据，但能有效提升模型性能的数据比例有限。

Abstract: The rapid advancement of generative models, such as Stable Diffusion, raises
a key question: how can synthetic data from these models enhance predictive
modeling? While they can generate vast amounts of datasets, only a subset
meaningfully improves performance. We propose a novel end-to-end framework that
generates and systematically filters synthetic data through domain-specific
statistical methods, selectively integrating high-quality samples for effective
augmentation. Our experiments demonstrate consistent improvements in predictive
performance across various settings, highlighting the potential of our
framework while underscoring the inherent limitations of generative models for
data augmentation. Despite the ability to produce large volumes of synthetic
data, the proportion that effectively improves model performance is limited.

</details>


### [269] [A Two-Sample Test of Text Generation Similarity](https://arxiv.org/abs/2505.05269)
*Jingbin Xu,Chen Qian,Meimei Liu,Feng Guo*

Main category: stat.ML

TL;DR: 提出了一种新的双样本文本检验方法，通过比较两组文档基于神经网络语言模型估计的熵来评估其相似性，并显示出比现有方法更优的检验效能。


<details>
  <summary>Details</summary>
Motivation: 随着数字化文本数据的激增，迫切需要可靠的推断方法来分析观测到的文本模式，特别是比较两组文档之间是否存在显著差异。

Method: 提出了一种新的双样本文本检验方法。该方法通过比较两组文档的熵来评估文本相似性。熵的估计使用基于神经网络的语言模型。检验统计量在一个“估计-推断”框架下导出，首先在估计集上近似熵，然后在剩余数据集上进行推断，并采用多重数据分割策略来提高检验效能。

Result: 理论上证明，在温和条件下，该检验统计量渐近服从正态分布。多种仿真研究和真实数据案例表明，所提出的双样本文本检验方法在保持名义I类错误率的同时，比现有方法具有更高的检验效能。

Conclusion: 所提出的方法为判断文档类别间的差异提供了一种新的解决方案，尤其适用于那些大规模文本信息至关重要的领域。

Abstract: The surge in digitized text data requires reliable inferential methods on
observed textual patterns. This article proposes a novel two-sample text test
for comparing similarity between two groups of documents. The hypothesis is
whether the probabilistic mapping generating the textual data is identical
across two groups of documents. The proposed test aims to assess text
similarity by comparing the entropy of the documents. Entropy is estimated
using neural network-based language models. The test statistic is derived from
an estimation-and-inference framework, where the entropy is first approximated
using an estimation set, followed by inference on the remaining data set. We
showed theoretically that under mild conditions, the test statistic
asymptotically follows a normal distribution. A multiple data-splitting
strategy is proposed to enhance test power, which combines p-values into a
unified decision. Various simulation studies and a real data example
demonstrated that the proposed two-sample text test maintains the nominal Type
one error rate while offering greater power compared to existing methods. The
proposed method provides a novel solution to assert differences in document
classes, particularly in fields where large-scale textual information is
crucial.

</details>


### [270] [A Connection Between Learning to Reject and Bhattacharyya Divergences](https://arxiv.org/abs/2505.05273)
*Alexander Soen*

Main category: stat.ML

TL;DR: 论文提出了一种新的“学习拒绝”方法，通过学习输入和标签的联合理想分布，并将其与阈值化不同的统计散度（特别是偏斜 Bhattacharyya 散度）联系起来，发现这种方法比传统方法（如 Chow 法则）更不激进。


<details>
  <summary>Details</summary>
Motivation: 现有学习拒绝方法通常学习输入域的理想边际分布。本研究旨在探索学习输入和标签的联合理想分布，以开发新的拒绝机制。

Method: 提出学习输入和标签的联合理想分布，并将拒绝机制与不同统计散度的阈值化建立联系。特别地，当考虑对数损失的变体时，推导出拒绝器对应于类别概率间偏斜 Bhattacharyya 散度的阈值化。

Result: 研究发现，通过联合理想分布得到的拒绝器对应于偏斜 Bhattacharyya 散度的阈值化，这与基于边际分布（对应 Kullback-Leibler 散度阈值化，即 Chow 法则）的方法不同。通过 Bhattacharyya 散度进行拒绝通常比 Chow 法则不那么激进。

Conclusion: 通过学习联合理想分布并利用 Bhattacharyya 散度进行拒绝，提供了一种新的、通常不那么激进的“学习拒绝”方法，为模型何时应放弃预测提供了新的视角和工具。

Abstract: Learning to reject provide a learning paradigm which allows for our models to
abstain from making predictions. One way to learn the rejector is to learn an
ideal marginal distribution (w.r.t. the input domain) - which characterizes a
hypothetical best marginal distribution - and compares it to the true marginal
distribution via a density ratio. In this paper, we consider learning a joint
ideal distribution over both inputs and labels; and develop a link between
rejection and thresholding different statistical divergences. We further find
that when one considers a variant of the log-loss, the rejector obtained by
considering the joint ideal distribution corresponds to the thresholding of the
skewed Bhattacharyya divergence between class-probabilities. This is in
contrast to the marginal case - that is equivalent to a typical
characterization of optimal rejection, Chow's Rule - which corresponds to a
thresholding of the Kullback-Leibler divergence. In general, we find that
rejecting via a Bhattacharyya divergence is less aggressive than Chow's Rule.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [271] [Confabulation dynamics in a reservoir computer: Filling in the gaps with untrained attractors](https://arxiv.org/abs/2505.04792)
*Jack O'Hagan,Andrew Keane,Andrew Flynn*

Main category: math.DS

TL;DR: 该论文分析了储层计算（一种人工神经网络）中被称为“捏造”（confabulation）的现象，即系统产生未经训练的吸引子，并探讨了其在学习失败和吸引子转换中的作用。


<details>
  <summary>Details</summary>
Motivation: 尽管人工神经网络（ANNs）取得了显著进展，但我们对其如何学习、学习失败以及产生非故意的虚假信息（即“捏造”）的理解仍然有限。本研究旨在通过分析储层计算中的捏造现象来提供基础性见解。

Method: 通过分析储层计算（RCs）这种动态系统形式的ANN如何发生捏造。具体研究当RCs被训练重构给定吸引子的动力学时，它们有时会构建出未被训练的吸引子（UA）的情况。

Result: 研究揭示了当重构失败时，未训练吸引子（UAs）所扮演的角色，以及它们在模拟重构吸引子之间转换时的影响。

Conclusion: 未训练吸引子（UAs）是状态空间有界的学习系统的一个内在特征，并且这种捏造方式可能存在于储层计算之外的其他系统中。

Abstract: Artificial Intelligence has advanced significantly in recent years thanks to
innovations in the design and training of artificial neural networks (ANNs).
Despite these advancements, we still understand relatively little about how
elementary forms of ANNs learn, fail to learn, and generate false information
without the intent to deceive, a phenomenon known as `confabulation'. To
provide some foundational insight, in this paper we analyse how confabulation
occurs in reservoir computers (RCs): a dynamical system in the form of an ANN.
RCs are particularly useful to study as they are known to confabulate in a
well-defined way: when RCs are trained to reconstruct the dynamics of a given
attractor, they sometimes construct an attractor that they were not trained to
construct, a so-called `untrained attractor' (UA). This paper sheds light on
the role played by UAs when reconstruction fails and their influence when
modelling transitions between reconstructed attractors. Based on our results,
we conclude that UAs are an intrinsic feature of learning systems whose state
spaces are bounded, and that this means of confabulation may be present in
systems beyond RCs.

</details>


### [272] [Learning dynamically inspired invariant subspaces for Koopman and transfer operator approximation](https://arxiv.org/abs/2505.05085)
*Gary Froyland,Kevin Kühl*

Main category: math.DS

TL;DR: 该研究提出一种机器学习方法，通过学习定制化的基函数来精确逼近传递算子和库普曼算子，从而更有效地从数据中估计非线性动力系统的谱特性。


<details>
  <summary>Details</summary>
Motivation: 从数据中高效估计传递算子和库普曼算子的谱（这对于理解系统可预测性和突现行为至关重要）存在挑战。

Method: 采用通用算子和表示学习框架，通过机器学习生成与系统动态特性相适应的正交、局部支持基函数，用以构建算子的高效有限维表示。

Result: 学习到的基函数能够精确逼近算子的作用，并形成一个近不变的有限维子空间。通过算例展示了从估计的算子中成功提取谱特性，并强调了机器学习基函数的动态自适应能力。

Conclusion: 该文提出的机器学习定制化基函数的方法，为从数据中估计复杂动力系统的传递和库普曼算子及其谱特性提供了一种有效的途径。

Abstract: Transfer and Koopman operator methods offer a framework for representing
complex, nonlinear dynamical systems via linear transformations, enabling for a
deeper understanding of the underlying dynamics. The spectrum of these
operators provide important insights into system predictability and emergent
behaviour, although efficiently estimating them from data can be challenging.
We tackle this issue through the lens of general operator and representational
learning, in which we approximate these linear operators using efficient
finite-dimensional representations. Specifically, we machine-learn orthonormal,
locally supported basis functions that are dynamically tailored to the system.
This learned basis provides a particularly accurate approximation of the
operator's action as well as a nearly invariant finite-dimensional subspace. We
illustrate our approach with examples that showcase the retrieval of spectral
properties from the estimated operator, and emphasise the dynamically adaptive
quality of the machine-learned basis.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [273] [Error Analysis of Deep PDE Solvers for Option Pricing](https://arxiv.org/abs/2505.05121)
*Jasper Rou*

Main category: q-fin.CP

TL;DR: 评估深度学习 PDE 求解器在期权定价中的经验性能和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习 PDE 求解器在期权定价中的经验准确性尚不明确，限制了其实际应用。本研究旨在为此提供实用见解。

Method: 在 Black-Scholes 和 Heston 模型中，比较评估了 Deep Galerkin Method (DGM) 和 Time Deep Gradient Flow (TDGF) 两种神经网络算法的经验性能（收敛速度、训练时间），并分析了其与多个参数（采样阶段数、样本数、网络层数/节点数、TDGF的离散化方案阶数/时间步数）的关系。

Result: 确定了 DGM 和 TDGF 两种算法在期权定价模型中的经验收敛速度和训练时间，及其如何受网络结构和算法特定参数（如采样阶段数、样本数、层数、节点数、离散化阶数、时间步数）的影响。

Conclusion: 研究通过对两种深度学习 PDE 求解器在期权定价模型中的经验性能进行系统评估，为其实际应用提供了关于准确性、效率及其影响因素的实用见解。

Abstract: Option pricing often requires solving partial differential equations (PDEs).
Although deep learning-based PDE solvers have recently emerged as quick
solutions to this problem, their empirical and quantitative accuracy remain not
well understood, hindering their real-world applicability. In this research,
our aim is to offer actionable insights into the utility of deep PDE solvers
for practical option pricing implementation. Through comparative experiments in
both the Black--Scholes and the Heston model, we assess the empirical
performance of two neural network algorithms to solve PDEs: the Deep Galerkin
Method and the Time Deep Gradient Flow method (TDGF). We determine their
empirical convergence rates and training time as functions of (i) the number of
sampling stages, (ii) the number of samples, (iii) the number of layers, and
(iv) the number of nodes per layer. For the TDGF, we also consider the order of
the discretization scheme and the number of time steps.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [274] [Facets of Disparate Impact: Evaluating Legally Consistent Bias in Machine Learning](https://arxiv.org/abs/2505.05471)
*Jarren Briscoe,Assefaw Gebremedhin*

Main category: cs.CY

TL;DR: 提出了一种新的“客观公平指数”(Objective Fairness Index)，用于从法律角度衡量机器学习中的偏见，并应用于COMPAS等案例。


<details>
  <summary>Details</summary>
Motivation: 现有方法可能缺乏法律上一致且可靠的偏见衡量标准，需要一种能区分歧视性测试与系统性差异的指标。

Method: 基于现行法律标准，通过边际效益和客观测试的视角来定义偏见，并提出新的度量标准“客观公平指数”。该指数结合了客观测试的背景细微差别和度量稳定性。

Result: 使用“客观公平指数”对COMPAS（累犯预测）等敏感机器学习应用进行了分析，提供了新的见解，并证明了该指标的实际和理论意义。

Conclusion: “客观公平指数”是一种在法律上一致且可靠的偏见衡量标准，能够区分歧视性测试和系统性差异。

Abstract: Leveraging current legal standards, we define bias through the lens of
marginal benefits and objective testing with the novel metric "Objective
Fairness Index". This index combines the contextual nuances of objective
testing with metric stability, providing a legally consistent and reliable
measure. Utilizing the Objective Fairness Index, we provide fresh insights into
sensitive machine learning applications, such as COMPAS (recidivism
prediction), highlighting the metric's practical and theoretical significance.
The Objective Fairness Index allows one to differentiate between discriminatory
tests and systemic disparities.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [275] [Impact of Weather on Satellite Communication: Evaluating Starlink Resilience](https://arxiv.org/abs/2505.04772)
*Muhammad Asad Ullah,Antti Heikkinen,Mikko Uitto,Antti Anttonen,Konstantin Mikhaylov*

Main category: cs.ET

TL;DR: 该研究评估了天气条件（特别是雨和云量）对芬兰奥卢Starlink平板高性能（FHP）终端吞吐量的影响。


<details>
  <summary>Details</summary>
Motivation: 先前研究未详细分析天气对Starlink FHP终端性能的具体影响，本研究旨在填补这一空白，特别是在极端天气条件下。

Method: 在芬兰奥卢对Starlink FHP终端进行实际测量，分析雨水和云量对上下行吞吐量和往返时间的影响，并使用线性回归分析云量与吞吐量的关系。

Result: 雨水导致中位数上行链路吞吐量下降52.27%，下行链路吞吐量下降37.84%，但对往返时间无明显影响。云量与吞吐量呈负相关，12.5%云量时的吞吐量比87.5%云量时高约20%。

Conclusion: 天气条件，特别是雨水和云量，对Starlink FHP终端的吞吐量有显著的负面影响，其中雨水影响较大，但对延迟影响不明显。

Abstract: Satellite communications have emerged as one of the most feasible solutions
to provide global wireless coverage and connect the unconnected. Starlink
dominates the market with over 7,000 operational satellites in low Earth orbit
(LEO) and offers global high-speed and low-latency Internet service for
stationary and mobile use cases, including in-motion connectivity for vehicles,
vessels, and aircraft. Starlink terminals are designed to handle extreme
weather conditions. Starlink recommends a flat high performance (FHP) terminal
for users living in areas with extreme weather conditions. The earlier studies
evaluated Starlink's FHP throughput for stationary and in-motion users without
providing a detailed analysis of how weather affects its performance. There
remains a need to investigate the impact of weather on FHP's throughput. In
this paper, we address this shortcoming by analyzing the impact of weather on
Starlink's performance in Oulu, Finland, a city located in Northern Europe near
the Arctic Circle. Our measurements reveal that rain degrades median uplink and
downlink throughput by 52.27% and 37.84%, respectively. On the contrary, there
was no noticeable impact on the round-trip time. Additionally, we also examine
the impact of cloud cover on the Starlink throughput. The linear regression
analysis reveals the negative relationship between throughput and cloud cover.
The cloud cover of up to 12.5% has around 20% greater throughput than the cloud
cover of 87.5%

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [276] [ICNN-enhanced 2SP: Leveraging input convex neural networks for solving two-stage stochastic programming](https://arxiv.org/abs/2505.05261)
*Yu Liu,Fabricio Oliveira*

Main category: math.OC

TL;DR: 提出了一种使用输入凸神经网络（ICNN）增强两阶段随机规划（2SP）的方法，通过利用ICNN的线性规划可表示性来提高计算效率，同时保持解的质量。


<details>
  <summary>Details</summary>
Motivation: 传统的两阶段随机规划（2SP）在处理不确定性决策问题时，因追索函数评估的计算复杂性而面临可扩展性挑战。现有的基于学习的方法（如Neur2SP）虽使用神经网络作为替代，但依赖于计算密集型的混合整数规划（MIP）公式。

Method: 提出ICNN增强的2SP方法（ICNN-enhanced 2SP），该方法利用输入凸神经网络（ICNNs）作为追索函数的替代模型。通过在架构上强制ICNN的凸性，并利用其在线性规划（LP）中的可表示性进行精确推断，从而消除了传统MIP公式中固有的整数变量，同时保留了ICNN替代模型在2SP框架内的精确嵌入。

Result: 实验表明，ICNN的训练时间仅略长于基于MIP的方法，但验证准确性相当。在基准问题上，ICNN增强的2SP在求解时间上通常比基于MIP的公式快得多，同时保持解的质量。这种优势随着问题规模的增加而更加显著，在最具挑战性的实例中，该方法实现了高达100倍的加速，并且解的质量优于基于MIP的公式。

Conclusion: ICNN增强的2SP为凸2SP问题提供了一种计算效率更高的替代方案，相较于基于MIP的公式，它能在保持甚至提高解质量的同时显著缩短求解时间，尤其适用于大规模问题。

Abstract: Two-stage stochastic programming (2SP) offers a basic framework for modelling
decision-making under uncertainty, yet scalability remains a challenge due to
the computational complexity of recourse function evaluation. Existing
learning-based methods like Neural Two-Stage Stochastic Programming (Neur2SP)
employ neural networks (NNs) as recourse function surrogates but rely on
computationally intensive mixed-integer programming (MIP) formulations. We
propose ICNN-enhanced 2SP, a method that leverages Input Convex Neural Networks
(ICNNs) to exploit linear programming (LP) representability in convex 2SP
problems. By architecturally enforcing convexity and enabling exact inference
through LP, our approach eliminates the need for integer variables inherent to
the conventional MIP-based formulation while retaining an exact embedding of
the ICNN surrogate within the 2SP framework. This results in a more
computationally efficient alternative that maintains solution quality.
Comprehensive experiments reveal that ICNNs incur only marginally longer
training times while achieving validation accuracy on par with their MIP-based
counterparts. Across benchmark problems, ICNN-enhanced 2SP often exhibits
considerably faster solution times than the MIP-based formulations while
preserving solution quality, with these advantages becoming significantly more
pronounced as problem scale increases. For the most challenging instances, the
method achieves speedups of up to 100$\times$ and solution quality superior to
MIP-based formulations.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [277] [Dukawalla: Voice Interfaces for Small Businesses in Africa](https://arxiv.org/abs/2505.05170)
*Elizabeth Ankrah,Stephanie Nyairo,Mercy Muchai,Kagonya Awori,Millicent Ochieng,Mark Kariuki,Jacki O'Neill*

Main category: cs.HC

TL;DR: Dukawalla是一款利用语音交互和生成式AI的智能助手原型，旨在帮助非洲中小企业主通过直观的数据互动方式进行数据驱动决策。


<details>
  <summary>Details</summary>
Motivation: 非洲中小企业因缺乏适合其移动优先、学习时间有限及社交与业务紧密结合工作方式的高级分析工具，难以进行数据驱动决策。

Method: 开发了名为Dukawalla的智能助手原型，该原型利用语音交互和生成式人工智能，将原始业务数据转化为可操作的见解。

Result: 论文研究了Dukawalla在内罗毕中小企业的部署情况，重点关注用户使用这款基于语音的助手在简化数据收集和提供业务洞察方面的体验。

Conclusion: Dukawalla通过提供直观的数据互动方式，帮助企业主弥合原始业务数据与可操作洞见之间的差距，从而辅助其做出明智决策。

Abstract: Small and medium sized businesses often struggle with data driven decision
making do to a lack of advanced analytics tools, especially in African
countries where they make up a majority of the workforce. Though many tools
exist they are not designed to fit into the ways of working of SMB workers who
are mobile first, have limited time to learn new workflows, and for whom social
and business are tightly coupled. To address this, the Dukawalla prototype was
created. This intelligent assistant bridges the gap between raw business data,
and actionable insights by leveraging voice interaction and the power of
generative AI. Dukawalla provides an intuitive way for business owners to
interact with their data, aiding in informed decision making. This paper
examines Dukawalla's deployment across SMBs in Nairobi, focusing on their
experiences using this voice based assistant to streamline data collection and
provide business insights

</details>


### [278] [Fairness Perceptions in Regression-based Predictive Models](https://arxiv.org/abs/2505.04886)
*Mukund Telukunta,Venkata Sriram Siddhardh Nadendla,Morgan Stuart,Casey Canfield*

Main category: cs.HC

TL;DR: 本文为肾移植预测分析引入了新的公平性度量，并通过众包研究发现公众偏好“分离性”和“充分性”公平概念，同时指出当前模型在年龄群体上存在不公平。


<details>
  <summary>Details</summary>
Motivation: 现代肾移植中基于回归的预测分析存在训练数据偏见，导致社会歧视和器官利用效率低下，尤其影响特定社会群体。此外，关于回归中的公平性及其对器官利用和分配影响的研究有限。

Method: 提出了三种新的基于散度的群体公平性概念（独立性、分离性、充分性）来评估回归分析工具的公平性。通过Prolific平台招募85名参与者，并使用混合Logit离散选择模型对公平性反馈进行建模，以确定社会可接受的群体公平性标准。

Result: 研究发现，公众强烈偏好分离性和充分性这两种公平性概念。基于这些偏好评估，预测分析在性别和种族群体方面被认为是公平的，但在年龄群体方面则不公平。

Conclusion: 该研究为评估回归分析工具的公平性引入了新的概念，并通过众包反馈确定了社会偏好的公平标准，揭示了现有预测分析在年龄群体上存在的不公平性。

Abstract: Regression-based predictive analytics used in modern kidney transplantation
is known to inherit biases from training data. This leads to social
discrimination and inefficient organ utilization, particularly in the context
of a few social groups. Despite this concern, there is limited research on
fairness in regression and its impact on organ utilization and placement. This
paper introduces three novel divergence-based group fairness notions: (i)
independence, (ii) separation, and (iii) sufficiency to assess the fairness of
regression-based analytics tools. In addition, fairness preferences are
investigated from crowd feedback, in order to identify a socially accepted
group fairness criterion for evaluating these tools. A total of 85 participants
were recruited from the Prolific crowdsourcing platform, and a Mixed-Logit
discrete choice model was used to model fairness feedback and estimate social
fairness preferences. The findings clearly depict a strong preference towards
the separation and sufficiency fairness notions, and that the predictive
analytics is deemed fair with respect to gender and race groups, but unfair in
terms of age groups.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [279] [Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators](https://arxiv.org/abs/2505.05138)
*Steven Jorgensen,Erik Hemberg,Jamal Toutouh,Una-May O'Reilly*

Main category: cs.NE

TL;DR: 该研究探索了使用进化计算进行自编码器剪枝的新方法，特别关注基于激活的突变算子。发现在标准训练中，激活引导剪枝优于随机剪枝；但在协同进化环境中，随机剪枝效果更好。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为自编码器的编码器和解码器开发一种新颖且有效的同步剪枝方法，以提升模型效率并维持其性能。

Method: 引入了两种新的、使用层激活信息来指导权重剪枝的突变算子。研究评估了这些算子在标准自编码器训练和空间协同进化（分别进化编码器和解码器种群）环境中的表现，并测试了不同的剪枝策略。

Result: 在标准自编码器训练中，一种激活引导的突变算子在性能上优于随机剪枝，能产生效率更高且性能与标准训练模型相当的自编码器。然而，在协同进化设置中，随机剪枝的效果反而优于引导剪枝。研究还展示了不同情况下算子和剪枝策略的最佳组合。

Conclusion: 基于激活的引导剪枝在低维剪枝环境中更有效，因为受限的样本空间可能导致随机化偏离真正的均匀性。相反，种群驱动的策略通过扩大总剪枝维度来增强鲁棒性，实现统计上更均匀的随机性，从而更好地保留系统动态。

Abstract: This study explores a novel approach to neural network pruning using
evolutionary computation, focusing on simultaneously pruning the encoder and
decoder of an autoencoder. We introduce two new mutation operators that use
layer activations to guide weight pruning. Our findings reveal that one of
these activation-informed operators outperforms random pruning, resulting in
more efficient autoencoders with comparable performance to canonically trained
models. Prior work has established that autoencoder training is effective and
scalable with a spatial coevolutionary algorithm that cooperatively coevolves a
population of encoders with a population of decoders, rather than one
autoencoder. We evaluate how the same activity-guided mutation operators
transfer to this context. We find that random pruning is better than guided
pruning, in the coevolutionary setting. This suggests activation-based guidance
proves more effective in low-dimensional pruning environments, where
constrained sample spaces can lead to deviations from true uniformity in
randomization. Conversely, population-driven strategies enhance robustness by
expanding the total pruning dimensionality, achieving statistically uniform
randomness that better preserves system dynamics. We experiment with pruning
according to different schedules and present best combinations of operator and
schedule for the canonical and coevolving populations cases.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [280] [Quantum-Inspired Optimization Process for Data Imputation](https://arxiv.org/abs/2505.04841)
*Nishikanta Mohanty,Bikash K. Behera,Badsah Mukherjee,Christopher Ferrie*

Main category: quant-ph

TL;DR: 提出了一种新颖的量子启发式数据填充框架，在UCI糖尿病数据集上显著优于传统方法，提高了填充数据的真实性和统计保真度。


<details>
  <summary>Details</summary>
Motivation: 解决数据预处理中缺失或不可靠值的问题，特别是针对存在生物学上不合理缺失值的医疗数据集，传统方法可能无法保持数据统计特性或产生不切实际的值。

Method: 该研究提出了一种量子启发式插补框架，整合了主成分分析（PCA）与量子辅助旋转。通过无梯度经典优化器（COBYLA、模拟退火、差分进化）进行优化，以重建缺失值，同时将重建值约束在原始特征分布的+/-2标准差内，以保持统计保真度。

Result: 与均值、KNN和MICE等经典方法相比，该方法在Wasserstein距离上平均减少超过85%，Kolmogorov-Smirnov检验的p值在0.18至0.22之间（经典方法p值>0.99）。此外，该方法消除了零值伪影，并增强了插补数据的真实性和可变性。

Conclusion: 通过结合量子启发的变换与可扩展的经典框架，该方法为医疗保健和人工智能管道等对数据质量和完整性要求较高的领域中的数据插补任务，提供了一个鲁棒的解决方案。

Abstract: Data imputation is a critical step in data pre-processing, particularly for
datasets with missing or unreliable values. This study introduces a novel
quantum-inspired imputation framework evaluated on the UCI Diabetes dataset,
which contains biologically implausible missing values across several clinical
features. The method integrates Principal Component Analysis (PCA) with
quantum-assisted rotations, optimized through gradient-free classical
optimizers -COBYLA, Simulated Annealing, and Differential Evolution to
reconstruct missing values while preserving statistical fidelity. Reconstructed
values are constrained within +/-2 standard deviations of original feature
distributions, avoiding unrealistic clustering around central tendencies. This
approach achieves a substantial and statistically significant improvement,
including an average reduction of over 85% in Wasserstein distance and
Kolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values >
0.99 in classical methods such as Mean, KNN, and MICE. The method also
eliminates zero-value artifacts and enhances the realism and variability of
imputed data. By combining quantum-inspired transformations with a scalable
classical framework, this methodology provides a robust solution for imputation
tasks in domains such as healthcare and AI pipelines, where data quality and
integrity are crucial.

</details>


### [281] [GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning and Quantum-Native Tokenization](https://arxiv.org/abs/2505.04880)
*Min Chen,Jinglei Cheng,Pingzhi Li,Haoran Wang,Tianlong Chen,Junyu Liu*

Main category: quant-ph

TL;DR: 提出GroverGPT-2，一种基于大型语言模型（LLM）的方法，利用思维链（CoT）推理和量子原生标记化来模拟Grover算法，展示了LLM理解和模拟量子算法的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究经典计算机（特别是大型语言模型LLM）学习和模拟量子算法的能力，以探究实用量子优势的边界，并理解经典机器如何学习和模拟量子算法。

Method: 引入GroverGPT-2，这是一种基于LLM的方法。它使用思维链（CoT）推理和量子原生标记化技术，直接从量子电路表示来模拟Grover算法，并产生逻辑结构化和可解释的输出。

Result: GroverGPT-2能够学习和内化量子电路逻辑，其输出将电路数据与自然语言交织，嵌入了显式推理。此外，研究还识别出一个关于GroverGPT-2随量子比特数增加的经验性扩展规律，暗示了可扩展经典模拟的路径。

Conclusion: 研究结果表明，LLM等经典模型有能力捕获量子算法的结构。GroverGPT-2为此提供了原型，为探索经典可模拟性的极限、增强量子教育与研究，以及为未来量子计算中的基础模型奠定基础开辟了新方向。

Abstract: Quantum computing offers theoretical advantages over classical computing for
specific tasks, yet the boundary of practical quantum advantage remains an open
question. To investigate this boundary, it is crucial to understand whether,
and how, classical machines can learn and simulate quantum algorithms. Recent
progress in large language models (LLMs) has demonstrated strong reasoning
abilities, prompting exploration into their potential for this challenge. In
this work, we introduce GroverGPT-2, an LLM-based method for simulating
Grover's algorithm using Chain-of-Thought (CoT) reasoning and quantum-native
tokenization. Building on its predecessor, GroverGPT-2 performs simulation
directly from quantum circuit representations while producing logically
structured and interpretable outputs. Our results show that GroverGPT-2 can
learn and internalize quantum circuit logic through efficient processing of
quantum-native tokens, providing direct evidence that classical models like
LLMs can capture the structure of quantum algorithms. Furthermore, GroverGPT-2
outputs interleave circuit data with natural language, embedding explicit
reasoning into the simulation. This dual capability positions GroverGPT-2 as a
prototype for advancing machine understanding of quantum algorithms and
modeling quantum circuit logic. We also identify an empirical scaling law for
GroverGPT-2 with increasing qubit numbers, suggesting a path toward scalable
classical simulation. These findings open new directions for exploring the
limits of classical simulatability, enhancing quantum education and research,
and laying groundwork for future foundation models in quantum computing.

</details>


### [282] [Quantum QSAR for drug discovery](https://arxiv.org/abs/2505.04648)
*Alejandro Giraldo,Daniel Ruiz,Mariano Caruso,Guido Bellomo*

Main category: quant-ph

TL;DR: 本研究提出应用量子支持向量机 (QSVM) 改进药物发现中的定量构效关系 (QSAR) 模型，旨在提高预测准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 经典QSAR方法在处理高维数据和捕捉复杂分子相互作用方面存在局限性。

Method: 通过量子支持向量机 (QSVM) 增强QSAR技术，利用量子计算原理（如量子数据编码和量子核函数）在希尔伯特空间处理信息。

Result: 研究旨在开发出预测更准确、效率更高的QSAR模型。

Conclusion: QSVM有望为药物发现中的QSAR建模提供一种更强大、更高效的方法，克服经典方法的局限性。

Abstract: Quantitative Structure-Activity Relationship (QSAR) modeling is key in drug
discovery, but classical methods face limitations when handling
high-dimensional data and capturing complex molecular interactions. This
research proposes enhancing QSAR techniques through Quantum Support Vector
Machines (QSVMs), which leverage quantum computing principles to process
information Hilbert spaces. By using quantum data encoding and quantum kernel
functions, we aim to develop more accurate and efficient predictive models.

</details>


### [283] [Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning](https://arxiv.org/abs/2505.05151)
*Chuangtao Chen,Qinglin Zhao,MengChu Zhou,Zhimin He,Haozhen Situ*

Main category: quant-ph

TL;DR: 研究提出量子离散去噪扩散模型（QD3PM），利用量子计算学习高维数据的联合概率分布，克服经典模型限制，实现单步高效采样。


<details>
  <summary>Details</summary>
Motivation: 经典离散扩散模型为避免高维数据处理中的指数计算成本，采用逐维度计算，导致其学习能力受限（KL散度随维度线性增加）。

Method: 提出量子离散去噪扩散概率模型（QD3PM），在指数级希尔伯特空间中进行扩散和去噪以学习联合概率。通过量子贝叶斯定理推导后验状态，并设计含参数共享和可学习经典数据控制旋转的量子电路进行去噪，利用联合分布学习实现从纯噪声单步采样。

Result: 仿真实验证明，与因子分解方法相比，所提出的QD3PM在建模复杂分布方面表现出更高的准确性。

Conclusion: 该研究利用量子计算在联合分布学习中的优势，为生成模型领域建立了新的理论范式，并展示了QD3PM在高效学习高维复杂分布方面的潜力。

Abstract: This study explores quantum-enhanced discrete diffusion models to overcome
classical limitations in learning high-dimensional distributions. We rigorously
prove that classical discrete diffusion models, which calculate per-dimension
transition probabilities to avoid exponential computational cost, exhibit
worst-case linear scaling of Kullback-Leibler (KL) divergence with data
dimension. To address this, we propose a Quantum Discrete Denoising Diffusion
Probabilistic Model (QD3PM), which enables joint probability learning through
diffusion and denoising in exponentially large Hilbert spaces. By deriving
posterior states through quantum Bayes' theorem, similar to the crucial role of
posterior probabilities in classical diffusion models, and by learning the
joint probability, we establish a solid theoretical foundation for
quantum-enhanced diffusion models. For denoising, we design a quantum circuit
using temporal information for parameter sharing and learnable
classical-data-controlled rotations for encoding. Exploiting joint distribution
learning, our approach enables single-step sampling from pure noise,
eliminating iterative requirements of existing models. Simulations demonstrate
the proposed model's superior accuracy in modeling complex distributions
compared to factorization methods. Hence, this paper establishes a new
theoretical paradigm in generative models by leveraging the quantum advantage
in joint distribution learning.

</details>


### [284] [Operator-Level Quantum Acceleration of Non-Logconcave Sampling](https://arxiv.org/abs/2505.05301)
*Jiaqi Leng,Zhiyan Ding,Zherui Chen,Lin Lin*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Sampling from probability distributions of the form $\sigma \propto e^{-\beta
V}$, where $V$ is a continuous potential, is a fundamental task across physics,
chemistry, biology, computer science, and statistics. However, when $V$ is
non-convex, the resulting distribution becomes non-logconcave, and classical
methods such as Langevin dynamics often exhibit poor performance. We introduce
the first quantum algorithm that provably accelerates a broad class of
continuous-time sampling dynamics. For Langevin dynamics, our method encodes
the target Gibbs measure into the amplitudes of a quantum state, identified as
the kernel of a block matrix derived from a factorization of the Witten
Laplacian operator. This connection enables Gibbs sampling via singular value
thresholding and yields the first provable quantum advantage with respect to
the Poincar\'e constant in the non-logconcave setting. Building on this
framework, we further develop the first quantum algorithm that accelerates
replica exchange Langevin diffusion, a widely used method for sampling from
complex, rugged energy landscapes.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [285] [Moments of Causal Effects](https://arxiv.org/abs/2505.04971)
*Yuta Kawakami,Jin Tian*

Main category: stat.ME

TL;DR: 该研究为因果效应的矩和乘积矩提供了定义、识别定理和界限，旨在分析其分布和关系，超越了传统仅关注平均因果效应的方法。


<details>
  <summary>Details</summary>
Motivation: 传统因果效应评估主要集中于平均因果效应，忽略了对因果效应完整分布（如方差、偏度）及其与其他变量关系（如协方差）的分析。

Method: 提出了因果效应的矩（如均值、方差、偏度、峰度）和乘积矩（如协方差、相关性）的定义、识别定理以及相应的界限。

Result: 通过实验说明了如何从有限样本中估计因果效应的矩，并利用一个真实的医疗数据集展示了这些方法的实际应用。

Conclusion: 本工作扩展了因果效应的评估方法，通过分析其矩和乘积矩，能够更全面地理解因果效应的分布特性及其变量间的相互关系。

Abstract: The moments of random variables are fundamental statistical measures for
characterizing the shape of a probability distribution, encompassing metrics
such as mean, variance, skewness, and kurtosis. Additionally, the product
moments, including covariance and correlation, reveal the relationships between
multiple random variables. On the other hand, the primary focus of causal
inference is the evaluation of causal effects, which are defined as the
difference between two potential outcomes. While traditional causal effect
assessment focuses on the average causal effect, this work provides
definitions, identification theorems, and bounds for moments and product
moments of causal effects to analyze their distribution and relationships. We
conduct experiments to illustrate the estimation of the moments of causal
effects from finite samples and demonstrate their practical application using a
real-world medical dataset.

</details>


### [286] [Decomposition of Probabilities of Causation with Two Mediators](https://arxiv.org/abs/2505.04983)
*Yuta Kawakami,Jin Tian*

Main category: stat.ME

TL;DR: 本研究探讨了包含两个中介变量时，如何将总体的必要性和充分性概率（PNS）分解为特定路径的PNS。


<details>
  <summary>Details</summary>
Motivation: 因果中介分析的一个主要目标是将总体效应分解为特定路径的组成部分，以便理解不同因果路径的作用。

Method: 研究者定义了用于分解的路径特定PNS，并提供了一个识别定理。接着，通过数值实验评估了所提出估计器在有限样本中的特性，并使用一个真实的教育数据集展示了其应用。

Result: 数值实验评估了所提出估计器的特性，并通过真实世界教育数据集成功展示了该方法的实际应用。

Conclusion: 该研究为在存在多个中介变量的情况下，将总体PNS分解为路径特定PNS提供了一种方法，从而能够更深入地评估不同因果路径对结果的必要性和充分性贡献。

Abstract: Mediation analysis for probabilities of causation (PoC) provides a
fundamental framework for evaluating the necessity and sufficiency of treatment
in provoking an event through different causal pathways. One of the primary
objectives of causal mediation analysis is to decompose the total effect into
path-specific components. In this study, we investigate the path-specific
probability of necessity and sufficiency (PNS) to decompose the total PNS into
path-specific components along distinct causal pathways between treatment and
outcome, incorporating two mediators. We define the path-specific PNS for
decomposition and provide an identification theorem. Furthermore, we conduct
numerical experiments to assess the properties of the proposed estimators from
finite samples and demonstrate their practical application using a real-world
educational dataset.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [287] [From Dialect Gaps to Identity Maps: Tackling Variability in Speaker Verification](https://arxiv.org/abs/2505.04629)
*Abdulhady Abas Abdullah,Soran Badawi,Dana A. Abdullah,Dana Rasul Hamad,Hanan Abdulrahman Taher,Sabat Salih Muhamad,Aram Mahmood Ahmed,Bryar A. Hassan,Sirwan Abdolwahed Aula,Tarik A. Rashid*

Main category: eess.AS

TL;DR: 本研究探讨了库尔德语多方言环境下说话人检测的复杂性与困难，并提出了改进方案。


<details>
  <summary>Details</summary>
Motivation: 库尔德语包含多种方言（如库尔曼吉、索拉尼、霍拉米），它们在语音和词汇上的巨大差异为说话人识别系统带来了特殊挑战。

Method: 研究中探讨了构建强大说话人识别系统的主要困难，并提出了解决方案，包括高级机器学习方法、数据增强策略以及构建详尽的方言特定语料库，并结合了针对各方言的定制策略和跨方言训练。

Result: 结果表明，针对每种方言采用定制化策略，并结合跨方言训练，能够显著提升识别性能。

Conclusion: 为提高库尔德语多方言说话人识别系统的准确性和可靠性，结合方言定制策略和跨方言训练至关重要。

Abstract: The complexity and difficulties of Kurdish speaker detection among its
several dialects are investigated in this work. Because of its great phonetic
and lexical differences, Kurdish with several dialects including Kurmanji,
Sorani, and Hawrami offers special challenges for speaker recognition systems.
The main difficulties in building a strong speaker identification system
capable of precisely identifying speakers across several dialects are
investigated in this work. To raise the accuracy and dependability of these
systems, it also suggests solutions like sophisticated machine learning
approaches, data augmentation tactics, and the building of thorough
dialect-specific corpus. The results show that customized strategies for every
dialect together with cross-dialect training greatly enhance recognition
performance.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [288] [Comparative Study of Generative Models for Early Detection of Failures in Medical Devices](https://arxiv.org/abs/2505.04845)
*Binesh Sadanandan,Bahareh Arghavani Nobar,Vahid Behzadan*

Main category: eess.SP

TL;DR: 本文研究了利用三种生成式机器学习方法，通过分析手术吻合器的传感器数据来检测医疗设备故障，旨在提高设备安全性。


<details>
  <summary>Details</summary>
Motivation: 医疗设备中先进电子部件的集成带来了传统方法难以检测的复杂故障模式。鉴于手术吻合器等设备近期事故增多，迫切需要更有效的故障检测技术以保障患者安全。

Method: 本文探索并评估了三种基于生成式机器学习的故障检测方法，这些方法利用从手术吻合器（一种2类医疗设备）收集的传感器数据。

Result: 该研究对三种生成式机器学习方法在医疗设备故障检测中的性能和数据需求进行了评估。

Conclusion: 生成式机器学习方法在利用传感器数据检测医疗设备（如手术吻合器）故障方面显示出潜力，有望提升设备安全性和患者保护水平。

Abstract: The medical device industry has significantly advanced by integrating
sophisticated electronics like microchips and field-programmable gate arrays
(FPGAs) to enhance the safety and usability of life-saving devices. These
complex electro-mechanical systems, however, introduce challenging failure
modes that are not easily detectable with conventional methods. Effective fault
detection and mitigation become vital as reliance on such electronics grows.
This paper explores three generative machine learning-based approaches for
fault detection in medical devices, leveraging sensor data from surgical
staplers,a class 2 medical device. Historically considered low-risk, these
devices have recently been linked to an increasing number of injuries and
fatalities. The study evaluates the performance and data requirements of these
machine-learning approaches, highlighting their potential to enhance device
safety.

</details>


### [289] [Integrated Image Reconstruction and Target Recognition based on Deep Learning Technique](https://arxiv.org/abs/2505.04836)
*Cien Zhang,Jiaming Zhang,Jiajun He,Okan Yurduseven*

Main category: eess.SP

TL;DR: 该研究提出了一种名为 Att-ClassiGAN 的改进型深度学习模型，通过在 ClassiGAN 中加入注意力门模块，用于计算微波成像，旨在同时重建图像和分类目标，并提高处理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统微波成像技术存在硬件密集、数据采集慢等局限性。计算微波成像 (CMI) 虽有优势，但在图像重建和目标分类阶段仍面临计算瓶颈。本研究旨在通过改进先前工作 ClassiGAN 的特征提取能力，以解决这些挑战。

Method: 在已有的 ClassiGAN（一种利用反向散射信号同时重建图像和分类目标的生成式深度学习模型）框架基础上，引入了注意力门 (attention gate) 模块。这些模块通过动态聚焦于重要特征并抑制不相关特征，来优化特征提取和提升模型性能。新架构命名为 Att-ClassiGAN。

Result: 与传统 CMI 方法相比，Att-ClassiGAN 显著减少了重建时间。同时，它在归一化均方误差 (NMSE)、结构相似性指数 (SSIM) 以及重建目标的分类效果方面均优于当前先进方法。

Conclusion: 通过整合注意力门模块，Att-ClassiGAN 模型有效地提升了特征提取能力，显著改善了计算微波成像中的图像重建速度、图像质量和目标分类准确性，克服了现有方法的计算瓶颈。

Abstract: Computational microwave imaging (CMI) has gained attention as an alternative
technique for conventional microwave imaging techniques, addressing their
limitations such as hardware-intensive physical layer and slow data collection
acquisition speed to name a few. Despite these advantages, CMI still encounters
notable computational bottlenecks, especially during the image reconstruction
stage. In this setting, both image recovery and object classification present
significant processing demands. To address these challenges, our previous work
introduced ClassiGAN, which is a generative deep learning model designed to
simultaneously reconstruct images and classify targets using only
back-scattered signals. In this study, we build upon that framework by
incorporating attention gate modules into ClassiGAN. These modules are intended
to refine feature extraction and improve the identification of relevant
information. By dynamically focusing on important features and suppressing
irrelevant ones, the attention mechanism enhances the overall model
performance. The proposed architecture, named Att-ClassiGAN, significantly
reduces the reconstruction time compared to traditional CMI approaches.
Furthermore, it outperforms current advanced methods, delivering improved
Normalized Mean Squared Error (NMSE), higher Structural Similarity Index
(SSIM), and better classification outcomes for the reconstructed targets.

</details>


### [290] [From Sleep Staging to Spindle Detection: Evaluating End-to-End Automated Sleep Analysis](https://arxiv.org/abs/2505.05371)
*Niklas Grieger,Siamak Mehrkanoon,Philipp Ritter,Stephan Bialonski*

Main category: eess.SP

TL;DR: 评估了使用机器学习模型进行全自动睡眠分期和纺锤波检测的可行性，发现其能快速重现专家手动分析的关键结果。


<details>
  <summary>Details</summary>
Motivation: 手动睡眠分析耗时、资源密集且存在评估者间不一致性。本研究旨在评估全自动多步骤睡眠分析（睡眠分期和纺锤波检测）在复制专家研究结果方面的可行性，以促进大规模睡眠研究。

Method: 采用最先进的机器学习模型RobustSleepNet进行睡眠分期，随后使用SUMOv2模型进行纺锤波检测，以全自动方式分析睡眠数据，并与一项关于双相情感障碍的专家手动研究结果进行比较。

Result: 全自动分析在定性上重现了专家研究的关键发现（如双相情感障碍患者与对照组在快纺锤波密度上的差异），且分析速度远超手动（数分钟对比数月）。尽管定量结果存在差异，但单个模型的性能达到了或超过了评估者间的一致性。

Conclusion: 全自动睡眠分析方法有潜力促进大规模睡眠研究。研究团队公开了其使用的代码和隐私保护的睡眠分析平台SomnoBot。

Abstract: Automation of sleep analysis, including both macrostructural (sleep stages)
and microstructural (e.g., sleep spindles) elements, promises to enable
large-scale sleep studies and to reduce variance due to inter-rater
incongruencies. While individual steps, such as sleep staging and spindle
detection, have been studied separately, the feasibility of automating
multi-step sleep analysis remains unclear. Here, we evaluate whether a fully
automated analysis using state-of-the-art machine learning models for sleep
staging (RobustSleepNet) and subsequent spindle detection (SUMOv2) can
replicate findings from an expert-based study of bipolar disorder. The
automated analysis qualitatively reproduced key findings from the expert-based
study, including significant differences in fast spindle densities between
bipolar patients and healthy controls, accomplishing in minutes what previously
took months to complete manually. While the results of the automated analysis
differed quantitatively from the expert-based study, possibly due to biases
between expert raters or between raters and the models, the models individually
performed at or above inter-rater agreement for both sleep staging and spindle
detection. Our results demonstrate that fully automated approaches have the
potential to facilitate large-scale sleep research. We are providing public
access to the tools used in our automated analysis by sharing our code and
introducing SomnoBot, a privacy-preserving sleep analysis platform.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [291] [High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations](https://arxiv.org/abs/2505.05354)
*Pungponhavoan Tep,Marc Bernacki*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种结合卷积长短期记忆网络和自动编码器的机器学习框架，用于高效、快速地预测金属材料的晶粒长大演化，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于偏微分方程的晶粒长大模拟方法计算成本高昂，限制了材料设计和制造的效率。

Method: 采用一种机器学习框架，该框架结合了卷积长短期记忆网络（Convolutional LSTM）捕捉时空特征和自动编码器（Autoencoder）进行高维数据降维与模式学习。同时，使用了一种包含均方误差、结构相似性指数和边界保持的复合损失函数，以确保预测结果中晶界拓扑结构的完整性。

Result: 该机器学习方法将晶粒长大预测速度提高了多达89倍（计算时间从10分钟降至约10秒），同时保持了高保真度的预测。最佳模型实现了86.71%的结构相似性得分和仅0.07%的平均晶粒尺寸误差，并准确捕捉了晶界的拓扑结构、形态和尺寸分布。

Conclusion: 该机器学习方法能够实现快速的微观结构预测，对于传统模拟耗时过长的应用场景具有重要意义，有望加速材料科学和制造业的创新。

Abstract: Grain growth simulation is crucial for predicting metallic material
microstructure evolution during annealing and resulting final mechanical
properties, but traditional partial differential equation-based methods are
computationally expensive, creating bottlenecks in materials design and
manufacturing. In this work, we introduce a machine learning framework that
combines a Convolutional Long Short-Term Memory networks with an Autoencoder to
efficiently predict grain growth evolution. Our approach captures both spatial
and temporal aspects of grain evolution while encoding high-dimensional grain
structure data into a compact latent space for pattern learning, enhanced by a
novel composite loss function combining Mean Squared Error, Structural
Similarity Index Measurement, and Boundary Preservation to maintain structural
integrity of grain boundary topology of the prediction. Results demonstrated
that our machine learning approach accelerates grain growth prediction by up to
\SI{89}{\times} faster, reducing computation time from \SI{10}{\minute} to
approximately \SI{10}{\second} while maintaining high-fidelity predictions. The
best model (S-30-30) achieving a structural similarity score of
\SI{86.71}{\percent} and mean grain size error of just \SI{0.07}{\percent}. All
models accurately captured grain boundary topology, morphology, and size
distributions. This approach enables rapid microstructural prediction for
applications where conventional simulations are prohibitively time-consuming,
potentially accelerating innovation in materials science and manufacturing.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [292] [Toward Holistic Evaluation of Recommender Systems Powered by Generative Models](https://arxiv.org/abs/2504.06667)
*Yashar Deldjoo,Nikhil Mehta,Maheswaran Sathiamoorthy,Shuai Zhang,Pablo Castells,Julian McAuley*

Main category: cs.IR

TL;DR: 生成式推荐系统（Gen-RecSys）带来更丰富的用户体验，但也引入了新的风险（如内容幻觉、偏见放大）。本文对这些风险进行了分类，并提出了一种全面的评估框架。


<details>
  <summary>Details</summary>
Motivation: 传统的推荐系统准确性指标无法充分捕捉生成式推荐系统带来的新挑战，例如事实正确性、内容安全性或用户意图对齐，因此需要新的评估方法来应对这些风险。

Method: 1. 将Gen-RecSys的评估挑战分为两类：因生成式输出而加剧的现有问题（如偏见、隐私）和全新的风险（如物品幻觉、矛盾解释）。 2. 提出一种整体评估方法，包括基于场景的评估和多指标检查（整合相关性、事实基础、偏见检测和策略合规性）。

Result: 本文的主要贡献是提出了Gen-RecSys评估挑战的分类方法，以及一个旨在全面评估这些系统的整体评估框架，该框架整合了场景评估和多维度指标。

Conclusion: 本文提出的框架旨在指导研究者和实践者全面评估生成式推荐系统，以确保其有效的个性化和负责任的部署。

Abstract: Recommender systems powered by generative models (Gen-RecSys) extend beyond
classical item ranking by producing open-ended content, which simultaneously
unlocks richer user experiences and introduces new risks. On one hand, these
systems can enhance personalization and appeal through dynamic explanations and
multi-turn dialogues. On the other hand, they might venture into unknown
territory-hallucinating nonexistent items, amplifying bias, or leaking private
information. Traditional accuracy metrics cannot fully capture these
challenges, as they fail to measure factual correctness, content safety, or
alignment with user intent.
  This paper makes two main contributions. First, we categorize the evaluation
challenges of Gen-RecSys into two groups: (i) existing concerns that are
exacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new
risks (e.g., item hallucinations, contradictory explanations). Second, we
propose a holistic evaluation approach that includes scenario-based assessments
and multi-metric checks-incorporating relevance, factual grounding, bias
detection, and policy compliance. Our goal is to provide a guiding framework so
researchers and practitioners can thoroughly assess Gen-RecSys, ensuring
effective personalization and responsible deployment.

</details>


### [293] [QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort](https://arxiv.org/abs/2505.04732)
*Sriram Gopalakrishnan,Sunandita Patra*

Main category: cs.IR

TL;DR: 论文提出了一种名为 QBD-RankedDatagen 的流程，利用大语言模型（LLMs）和领域专家输入，为“以文搜文”（QBD）任务生成定制化数据集，以降低创建成本和人力。


<details>
  <summary>Details</summary>
Motivation: 现有的“以文搜文”（QBD）任务（如专利匹配、法律案例检索）需要领域特定的数据集来优化检索性能，但这类数据集的创建成本高昂且耗时。

Method: 提出 QBD-RankedDatagen 流程：利用大语言模型（LLMs）结合领域专家输入生成文档评分、排序及解释，以创建定制化QBD搜索数据集。对这些方法在成本、速度和人机交互方面进行了比较，并使用TREC数据集评估，及微调BM25模型。

Result: 提出的流程和方法能显著减少创建定制领域数据集所需的人力，同时仍能获取足够的专家知识来调整检索模型。成功利用生成的数据微调了BM25模型。

Conclusion: QBD-RankedDatagen 提供了一种有效的方法来创建定制化的QBD数据集，能够显著降低人力成本，并为优化特定领域的文档检索模型提供支持。

Abstract: The Query-By-Document (QBD) problem is an information retrieval problem where
the query is a document, and the retrieved candidates are documents that match
the query document, often in a domain or query specific manner. This can be
crucial for tasks such as patent matching, legal or compliance case retrieval,
and academic literature review. Existing retrieval methods, including keyword
search and document embeddings, can be optimized with domain-specific datasets
to improve QBD search performance. However, creating these domain-specific
datasets is often costly and time-consuming. Our work introduces a process to
generate custom QBD-search datasets and compares a set of methods to use in
this problem, which we refer to as QBD-RankedDatagen. We provide a comparative
analysis of our proposed methods in terms of cost, speed, and the human
interface with the domain experts. The methods we compare leverage Large
Language Models (LLMs) which can incorporate domain expert input to produce
document scores and rankings, as well as explanations for human review. The
process and methods for it that we present can significantly reduce human
effort in dataset creation for custom domains while still obtaining sufficient
expert knowledge for tuning retrieval models. We evaluate our methods on QBD
datasets from the Text Retrieval Conference (TREC) and finetune the parameters
of the BM25 model -- which is used in many industrial-strength search engines
like OpenSearch -- using the generated data.

</details>


### [294] [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights](https://arxiv.org/abs/2505.04846)
*Ozan Gokdemir,Carlo Siebenschuh,Alexander Brace,Azton Wells,Brian Hsu,Kyle Hippe,Priyanka V. Setty,Aswathy Ajith,J. Gregory Pauloski,Varuni Sastry,Sam Foreman,Huihuo Zheng,Heng Ma,Bharat Kale,Nicholas Chia,Thomas Gibbs,Michael E. Papka,Thomas Brettin,Francis J. Alexander,Anima Anandkumar,Ian Foster,Rick Stevens,Venkatram Vishwanath,Arvind Ramanathan*

Main category: cs.IR

TL;DR: 提出了HiPerRAG，一个由高性能计算驱动的RAG工作流，通过Oreo进行文档解析和ColTrast进行编码器微调，高效处理数百万科学文献，并在科学问答任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 科学文献量激增导致信息利用不足、重复研究和跨学科合作受限。现有检索增强生成（RAG）技术在扩展处理大规模文献时，面临高昂的计算成本和复杂的语义对齐挑战。

Method: 引入HiPerRAG，一个基于高性能计算（HPC）的RAG工作流。其核心技术包括：1) Oreo，一个高通量多模态文档解析模型；2) ColTrast，一个采用对比学习和后期交互技术的查询感知编码器微调算法，以增强检索精度。

Result: HiPerRAG在现有科学问答基准及两个新引入的基准上表现稳健，SciQ准确率达90%，PubMedQA准确率达76%，优于PubMedGPT和GPT-4等模型。该系统已成功扩展至数千GPU，处理超过360万篇科学文章。

Conclusion: HiPerRAG为处理百万级科学文献提供了一个可扩展的解决方案，有助于统一科学知识并促进跨学科创新。

Abstract: The volume of scientific literature is growing exponentially, leading to
underutilized discoveries, duplicated efforts, and limited cross-disciplinary
collaboration. Retrieval Augmented Generation (RAG) offers a way to assist
scientists by improving the factuality of Large Language Models (LLMs) in
processing this influx of information. However, scaling RAG to handle millions
of articles introduces significant challenges, including the high computational
costs associated with parsing documents and embedding scientific knowledge, as
well as the algorithmic complexity of aligning these representations with the
nuanced semantics of scientific content. To address these issues, we introduce
HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index
and retrieve knowledge from more than 3.6 million scientific articles. At its
core are Oreo, a high-throughput model for multimodal document parsing, and
ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval
accuracy by using contrastive learning and late-interaction techniques.
HiPerRAG delivers robust performance on existing scientific question answering
benchmarks and two new benchmarks introduced in this work, achieving 90%
accuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models
like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs
on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million
document-scale RAG workflows for unifying scientific knowledge and fostering
interdisciplinary innovation.

</details>


### [295] [Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations](https://arxiv.org/abs/2505.04948)
*Md Aminul Islam,Ahmed Sayeed Faruk*

Main category: cs.IR

TL;DR: 该研究提出一种混合框架，结合传统推荐模型与大型语言模型（LLM）进行重排序，以解决LLM在推荐中的位置偏差等局限性，但实验发现LLM重排序并未优于基准模型，且偏差缓解措施效果不佳。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在基于提示的推荐中展现潜力，但面临上下文窗口有限、提示效率低、列表排序困难及位置偏差等问题。

Method: 提出一个混合框架，使用传统推荐模型生成候选集，然后由LLM利用结构化提示对top-k项进行重排序。同时，评估了用户历史记录重排序和指令性提示对减轻位置偏差的效果。

Result: 在MovieLens-100K数据集上的实验表明，随机化用户历史记录能提高排名质量，但基于LLM的重排序并未超越基准模型。用于减少位置偏差的明确指令也无效。

Conclusion: 评估结果揭示了LLM在建模排序上下文和减轻固有偏差方面的局限性。

Abstract: Recommender systems are essential for delivering personalized content across
digital platforms by modeling user preferences and behaviors. Recently, large
language models (LLMs) have been adopted for prompt-based recommendation due to
their ability to generate personalized outputs without task-specific training.
However, LLM-based methods face limitations such as limited context window
size, inefficient pointwise and pairwise prompting, and difficulty handling
listwise ranking due to token constraints. LLMs can also be sensitive to
position bias, as they may overemphasize earlier items in the prompt regardless
of their true relevance. To address and investigate these issues, we propose a
hybrid framework that combines a traditional recommendation model with an LLM
for reranking top-k items using structured prompts. We evaluate the effects of
user history reordering and instructional prompts for mitigating position bias.
Experiments on MovieLens-100K show that randomizing user history improves
ranking quality, but LLM-based reranking does not outperform the base model.
Explicit instructions to reduce position bias are also ineffective. Our
evaluations reveal limitations in LLMs' ability to model ranking context and
mitigate bias. Our code is publicly available at
https://github.com/aminul7506/LLMForReRanking.

</details>


### [296] [QBR: A Question-Bank-Based Approach to Fine-Grained Legal Knowledge Retrieval for the General Public](https://arxiv.org/abs/2505.04883)
*Mingruo Yuan,Ben Kao,Tien-Hsuan Wu*

Main category: cs.IR

TL;DR: 提出一种名为QBR的方法，利用问题库（QB）弥合普通用户与专业法律知识间的差距，以实现更有效的细粒度法律知识检索。


<details>
  <summary>Details</summary>
Motivation: 普通公众因法律知识的专业性和自身理解的缺乏，在检索法律知识时面临挑战。传统信息检索技术难以满足非专业用户的需求，导致法律知识检索非常困难。

Method: 提出QBR方法论，该方法利用一个问题库（QB）作为桥梁来弥合知识差距。通过QB派生训练样本，以增强文档中知识单元的嵌入，从而实现有效的细粒度知识检索。

Result: 实验证明，QBR方法相比传统方法在文档检索方面更准确、高效且可解释，能提升用户对检索结果的理解，并实现高效的细粒度知识检索。

Conclusion: QBR方法通过协助公民解决日常法律问题，展示了其社会影响力，并有效地弥合了法律知识检索中的知识鸿沟。

Abstract: Retrieval of legal knowledge by the general public is a challenging problem
due to the technicality of the professional knowledge and the lack of
fundamental understanding by laypersons on the subject. Traditional information
retrieval techniques assume that users are capable of formulating succinct and
precise queries for effective document retrieval. In practice, however, the
wide gap between the highly technical contents and untrained users makes legal
knowledge retrieval very difficult. We propose a methodology, called QBR, which
employs a Questions Bank (QB) as an effective medium for bridging the knowledge
gap. We show how the QB is used to derive training samples to enhance the
embedding of knowledge units within documents, which leads to effective
fine-grained knowledge retrieval. We discuss and evaluate through experiments
various advantages of QBR over traditional methods. These include more
accurate, efficient, and explainable document retrieval, better comprehension
of retrieval results, and highly effective fine-grained knowledge retrieval. We
also present some case studies and show that QBR achieves social impact by
assisting citizens to resolve everyday legal concerns.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [297] [Proceedings The 13th International Workshop on Theorem proving components for Educational software](https://arxiv.org/abs/2505.04677)
*Julien Narboux,Walther Neuper,Pedro Quaresma*

Main category: cs.LO

TL;DR: 该文集汇编了第13届定理证明教育软件组件国际研讨会 (ThEdu'24) 的8篇经修订的论文，旨在推动定理证明技术在数学教育中的应用与发展。


<details>
  <summary>Details</summary>
Motivation: ThEdu系列致力于利用定理证明技术，促进中学阶段的直观数学学习向STEM教育中更形式化的数学方法的平稳过渡，并为这一过渡提供软件支持。

Method: 本卷收集了ThEdu'24研讨会的成果。该研讨会作为CADE29的卫星活动举办，包括一次特邀报告和14场提交的演讲。会后通过公开征稿，收到9篇投稿，其中8篇经评审接受并修订后收录。

Result: 本卷收录的8篇论文广泛代表了ThEdu的主题范围，既包括侧重于自动演绎研究（同时关注教育应用潜力）的论文，也包括侧重于自动演绎工具和方法在教育环境中应用的论文。

Conclusion: 编者希望本论文集能进一步推动基于定理证明的软件开发，并增进计算机科学家、数学家和教育领域相关者之间的相互理解。同时，已开始筹备下一届ThEdu'25研讨会。

Abstract: The ThEdu series pursues the smooth transition from an intuitive way of doing
mathematics at secondary school to a more formal approach to the subject in
STEM education while favoring software support for this transition by
exploiting the power of theorem-proving technologies. What follows is a brief
description of how the present volume contributes to this enterprise. The 13th
International Workshop on Theorem Proving Components for Educational Software
(ThEdu'24), was a satellite event of the CADE29, part of IJCAR 2024, Nancy,
France. ThEdu'24 was a vibrant workshop, with one invited talk by Jeremy Avigad
(Carnegie Mellon University) and 14 submitted talks. An open call for papers
was then issued and attracted 9 submissions. Eight of those submissions have
been accepted by our reviewers. The resulting revised papers are collected in
the present volume. The contributions in this volume are a faithful
representation of the wide spectrum of ThEdu, ranging from those more focused
on the automated deduction research, not losing track of the possible
applications in an educational setting, to those focused on the applications,
in educational settings, of automated deduction tools and methods. We, the
volume editors, hope that this collection of papers will further promote the
development of theorem-proving-based software and that it will allow to improve
the mutual understanding between computer scientists, mathematicians, and
stakeholders in education. While this volume goes to press, the next edition of
the ThEdu workshop is being prepared: ThEdu'25 will be a satellite event of the
30th international Conference on Automated DEduction (CADE-30), July 28th -
August 2nd, 2025, Stuttgart, Germany.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [298] [SSH-Net: A Self-Supervised and Hybrid Network for Noisy Image Watermark Removal](https://arxiv.org/abs/2505.05088)
*Wenyang Liu,Jianjun Gao,Kim-Hui Yap*

Main category: cs.MM

TL;DR: 该研究提出了一种名为 SSH-Net 的自监督混合网络，专为去除含噪声图像中的可见水印而设计，无需成对训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有可见水印去除方法大多依赖监督学习，需要成对的水印图像和无水印图像，这在现实世界中难以获取。此外，图像本身携带的噪声也增加了去除难度。

Method: 提出了 SSH-Net，一个自监督混合网络。它通过自监督方式利用水印分布合成参考的无水印图像，并采用双网络设计：上层网络（轻量级CNN）专注于去噪，下层网络（包含Transformer模块）处理更复杂的同步去水印和去噪任务，并捕捉长程依赖。在此之前，使用一个共享的CNN特征编码器提取通用特征。

Result: SSH-Net 通过自监督学习和双网络架构，能够有效地在无需成对数据的情况下，去除含噪图像中的可见水印。

Conclusion: SSH-Net 为含噪图像的可见水印去除问题提供了一种有效的自监督解决方案，克服了对成对训练数据的依赖，并能同时处理噪声。

Abstract: Visible watermark removal is challenging due to its inherent complexities and
the noise carried within images. Existing methods primarily rely on supervised
learning approaches that require paired datasets of watermarked and
watermark-free images, which are often impractical to obtain in real-world
scenarios. To address this challenge, we propose SSH-Net, a Self-Supervised and
Hybrid Network specifically designed for noisy image watermark removal. SSH-Net
synthesizes reference watermark-free images using the watermark distribution in
a self-supervised manner and adopts a dual-network design to address the task.
The upper network, focused on the simpler task of noise removal, employs a
lightweight CNN-based architecture, while the lower network, designed to handle
the more complex task of simultaneously removing watermarks and noise,
incorporates Transformer blocks to model long-range dependencies and capture
intricate image features. To enhance the model's effectiveness, a shared
CNN-based feature encoder is introduced before dual networks to extract common
features that both networks can leverage. Our code will be available at
https://github.com/wenyang001/SSH-Net.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [299] [Physics-informed solution reconstruction in elasticity and heat transfer using the explicit constraint force method](https://arxiv.org/abs/2505.04875)
*Conor Rowan,Kurt Maute,Alireza Doostan*

Main category: cs.CE

TL;DR: 针对物理信息神经网络(PINNs)在参数化物理与实际不符时解重构效果不佳的问题，本文提出“显式约束力方法”(ECFM)。该方法通过控制约束引入的源项，改善了重构的可预测性和可定制性，即使在物理参数化不一致时依然有效。


<details>
  <summary>Details</summary>
Motivation: 在实际解重构问题中，PINNs所依赖的参数化控制方程可能与产生测量数据的真实物理现象不一致。这种不一致性导致基于PINNs的方法可能无法满足可解释性、鲁棒性和数据一致性这三个基本标准，从而影响重构质量的评估、对物理损失选择的敏感性以及物理参数的可恢复性。

Method: 本文首先通过弹性力学和热传导案例，论证了标准PINNs中物理损失的制定方式和约束数据的方法如何引入影响重构的“约束力”（即由约束产生的额外源项）。随后，提出了“显式约束力方法”(ECFM)，旨在显式地控制和管理由数据约束引入的这个源项。

Result: 研究表明，由于参数化物理与真实物理之间可能存在的不一致性，标准PINNs方法难以满足可解释性、鲁棒性和数据一致性。而ECFM通过满足这些标准，即使在测量数据有噪声且参数化的缺失物理与被测系统不一致的情况下，也能从含噪声的测量数据中获得更可预测和可定制的重构结果。

Conclusion: “显式约束力方法”(ECFM)通过显式控制约束引入的源项，为PINNs在参数化物理与实际测量系统不一致情况下的解重构问题提供了改进方案。这种方法能够得到更可预测、可定制且更可靠的重构结果，尤其是在处理含噪声数据和物理模型不确定性时。

Abstract: One use case of ``physics-informed neural networks'' (PINNs) is solution
reconstruction, which aims to estimate the full-field state of a physical
system from sparse measurements. Parameterized governing equations of the
system are used in tandem with the measurements to regularize the regression
problem. However, in real-world solution reconstruction problems, the
parameterized governing equation may be inconsistent with the physical
phenomena that give rise to the measurement data. We show that due to assuming
consistency between the true and parameterized physics, PINNs-based approaches
may fail to satisfy three basic criteria of interpretability, robustness, and
data consistency. As we argue, these criteria ensure that (i) the quality of
the reconstruction can be assessed, (ii) the reconstruction does not depend
strongly on the choice of physics loss, and (iii) that in certain situations,
the physics parameters can be uniquely recovered. In the context of elasticity
and heat transfer, we demonstrate how standard formulations of the physics loss
and techniques for constraining the solution to respect the measurement data
lead to different ``constraint forces" -- which we define as additional source
terms arising from the constraints -- and that these constraint forces can
significantly influence the reconstructed solution. To avoid the potentially
substantial influence of the choice of physics loss and method of constraint
enforcement on the reconstructed solution, we propose the ``explicit constraint
force method'' (ECFM) to gain control of the source term introduced by the
constraint. We then show that by satisfying the criteria of interpretability,
robustness, and data consistency, this approach leads to more predictable and
customizable reconstructions from noisy measurement data, even when the
parameterization of the missing physics is inconsistent with the measured
system.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [300] [Community and hyperedge inference in multiple hypergraphs](https://arxiv.org/abs/2505.04967)
*Li Ni,Ziqi Deng,Lin Mu,Lei Zhang,Wenjian Luo,Yiwen Zhang*

Main category: cs.SI

TL;DR: 提出了一种整合多个超图信息的模型，用于揭示高阶结构、预测连接和检测社群。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统（如生物和社会系统）中存在多个相互连接的超图，需要利用这些连接来综合信息，以增强对潜在高阶结构的理解。

Method: 提出了一种基于随机块模型的模型，该模型整合来自多个超图的信息。引入了“超边内部度”概念来量化节点对超边形成的贡献，以表征优先连接现象。该模型能够挖掘社群、预测任意大小的缺失超边以及推断超图间的边。

Result: 实验结果表明，该模型在社群检测、超边预测和超图间边预测任务中表现出色。模型能够分析不同类型的多个超图，也支持在没有超图间边的情况下分析单个超图。

Conclusion: 该研究提供了一个实用且灵活的多超图分析工具，极大地促进了对现实世界高阶系统组织的理解。

Abstract: Hypergraphs, capable of representing high-order interactions via hyperedges,
have become a powerful tool for modeling real-world biological and social
systems. Inherent relationships within these real-world systems, such as the
encoding relationship between genes and their protein products, drive the
establishment of interconnections between multiple hypergraphs. Here, we
demonstrate how to utilize those interconnections between multiple hypergraphs
to synthesize integrated information from multiple higher-order systems,
thereby enhancing understanding of underlying structures. We propose a model
based on the stochastic block model, which integrates information from multiple
hypergraphs to reveal latent high-order structures. Real-world hyperedges
exhibit preferential attachment, where certain nodes dominate hyperedge
formation. To characterize this phenomenon, our model introduces hyperedge
internal degree to quantify nodes' contributions to hyperedge formation. This
model is capable of mining communities, predicting missing hyperedges of
arbitrary sizes within hypergraphs, and inferring inter-hypergraph edges
between hypergraphs. We apply our model to high-order datasets to evaluate its
performance. Experimental results demonstrate strong performance of our model
in community detection, hyperedge prediction, and inter-hypergraph edge
prediction tasks. Moreover, we show that our model enables analysis of multiple
hypergraphs of different types and supports the analysis of a single hypergraph
in the absence of inter-hypergraph edges. Our work provides a practical and
flexible tool for analyzing multiple hypergraphs, greatly advancing the
understanding of the organization in real-world high-order systems.

</details>
