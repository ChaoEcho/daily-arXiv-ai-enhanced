<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 19]
- [cs.CV](#cs.CV) [Total: 16]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.LG](#cs.LG) [Total: 16]
- [cs.NI](#cs.NI) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 本文提出一种对话转录后处理方法，通过结合冻结的音频基础模型（如Whisper）和冻结的LLAMA语言模型，利用轻量连接器，无需任务特定微调即可为转录对话添加说话者特征（如年龄、性别、情感）元数据，并展现了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 在对话转录中，大型语言模型（LLMs）常用于提升文本质量，但目前的后处理步骤缺乏对说话者特征元数据的丰富。本研究旨在探索一个互补的后处理步骤，以补充对话中的说话者信息。

Method: 该方法将冻结的音频基础模型（如Whisper或WavLM）与冻结的LLAMA语言模型耦合，通过轻量级高效连接器桥接音频和语言表示，从而推断说话者属性。此过程无需对任何模型进行任务特定微调。此外，研究还展示了冻结的LLAMA模型能够直接比较x-vectors。

Result: 研究在说话者画像任务上取得了有竞争力的性能，同时保持了模块化和处理速度。具体地，在某些情况下，冻结的LLAMA模型直接比较x-vectors实现了8.8%的等错误率（EER）。

Conclusion: 通过结合冻结的音频和语言模型，并利用高效连接器，可以在对话转录的后处理阶段有效地丰富说话者元数据，且无需微调即可获得良好性能，同时保持系统模块化和高速度。该方法为对话分析提供了新的、高效的途径。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [2] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文提出了一种名为Parity-aware BPE的新型分词算法，旨在解决传统分词方法对低资源语言不公平的问题，并通过牺牲少量全局压缩率，实现了跨语言的更公平的词元计数。


<details>
  <summary>Details</summary>
Motivation: 标准分词算法依赖于基于频率的目标，导致低资源语言的词元化结果过长、形态不合理或包含大量未知词元（<UNK>）。这加剧了不同语言背景用户之间的计算和经济不平等，因此需要一种能纠正这种不平等的改进方法。

Method: 引入Parity-aware Byte Pair Encoding (BPE)，这是常用BPE算法的一种变体。在每个合并步骤中，Parity-aware BPE会最大化当前压缩最差语言的压缩增益，以少量全局压缩为代价换取跨语言的公平性。

Result: 经验证，Parity-aware BPE能够实现更均衡的跨语言词元计数，对全局压缩率影响可忽略不计，且对下游任务中语言模型的性能没有实质性影响。

Conclusion: Parity-aware BPE成功改善了低资源语言的分词公平性，在不显著影响整体压缩率和下游任务性能的情况下，缓解了不同语言用户之间的不平等现象。

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [3] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: 通过引入联合ASR和音高重音检测模型，证明了音高重音检测模块可以显著提升半监督语音表示的ASR性能，并提高音高重音检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入辅助的音高重音检测模块来提升使用半监督语音表示的自动语音识别（ASR）系统的性能，推测现有模型可能需要保留或重新学习重要的韵律线索。

Method: 引入了一个联合ASR和音高重音检测模型，该模型利用半监督语音表示。

Result: 音高重音检测组件的F1分数取得了显著提升，将与现有最佳水平的差距缩小了41%。此外，在LibriSpeech数据集上，联合训练下的ASR性能在有限资源微调条件下将词错误率（WER）降低了28.3%。

Conclusion: 研究结果表明扩展预训练语音模型以保留或重新学习重要的韵律线索（如音高重音）至关重要。

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [4] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 研究评估了大型语言模型（LLMs）的人格稳定性，发现即使是大型模型也存在显著的行为变异性，提示的微小变化、乃至旨在稳定行为的干预措施，都可能导致人格测量值大幅波动。这表明当前LLM缺乏真正的行为一致性基础，其人格对齐策略不足以满足安全关键应用需求。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全部署需要一致的行为模式，但其人格特质尚未被充分理解，这构成了安全部署的障碍。

Method: 提出了PERSIST（PERsonality Stability in Synthetic Text）评估框架，对25个以上（1B-671B参数）开源模型进行了超过50万次响应的测试。研究使用了传统（BFI-44, SD3）和新颖的LLM适用人格测量工具，并系统地改变问题顺序、改写、角色设定和推理模式进行评估。

Result: 1. 即使是400B+的模型也表现出显著的响应变异性（标准差>0.4）。
2. 仅微小的提示重新排序就能使个性测量值偏移高达20%。
3. 旨在稳定行为的干预措施（如思维链推理、详细角色指令、对话历史）反而可能增加变异性。
4. LLM适用工具与以人为中心的版本表现出相同的稳定性，证实了这是架构而非转换限制。

Conclusion: 当前LLMs缺乏真正行为一致性的基础，这种不稳定性持续存在于不同规模的模型和缓解策略中。对于需要可预测行为的安全关键应用，基于人格的对齐策略可能从根本上不不充分。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [5] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: 本文提出RCR-Router，一个模块化、角色感知的上下文路由框架，旨在通过动态选择记忆子集，在多智能体大型语言模型中实现高效、自适应的协作，从而减少令牌消耗并保持或提高答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型多智能体系统协调方案多依赖静态或全上下文路由策略，导致令牌消耗过高、冗余记忆暴露以及跨交互轮次适应性受限。

Method: 引入RCR-Router框架，该框架能根据智能体角色和任务阶段动态选择语义相关的记忆子集，并严格遵守令牌预算。它采用轻量级评分策略指导记忆选择，并将智能体输出迭代集成到共享记忆存储中以进行渐进式上下文优化。此外，还提出一个答案质量评分（Answer Quality Score）指标以更好地评估模型行为。

Result: 在HotPotQA、MuSiQue和2WikiMultihop三个多跳问答基准测试中，RCR-Router在减少高达30%令牌使用量的同时，改善或保持了答案质量。

Conclusion: 研究结果强调了结构化记忆路由和输出感知评估在推动可扩展多智能体大型语言模型系统发展中的重要性。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [6] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 本研究引入一个基准来评估大型语言模型（LLMs）如何对可能揭示人口属性的细微语言标记（如模糊语）做出响应，并发现LLMs会系统性地惩罚某些语言模式。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）可能对隐含人口属性的细微语言标记（即“暗语”）表现出偏见，即使内容质量相同，也可能系统性地惩罚某些语言模式。本研究旨在评估LLMs对这些语言标记的响应，并揭示其潜在的歧视行为。

Method: 本研究引入了一个综合基准来评估LLMs对语言“暗语”的响应。通过使用100对经过验证的问题-回答对，构建了精心设计的访谈模拟。该基准生成受控的语言变体，在保持语义等效的同时隔离特定现象，从而能够精确测量自动化评估系统中的人口偏见。研究还在多个语言维度上验证了该方法。

Result: 研究发现，大型语言模型系统性地惩罚某些语言模式，特别是模糊语（hedging language），即使内容质量相同。使用模糊语的回答平均评分降低了25.6%。此外，该基准被证明在识别模型特定偏见方面是有效的。

Conclusion: 本研究为检测和测量AI系统中的语言歧视建立了一个基础框架。该框架在自动化决策场景中的公平性方面具有广泛的应用前景。

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [7] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 针对视觉活动识别系统中动词语义和图像解释的固有歧义，提出一种视觉-语言聚类框架来构建动词义群，以提供更鲁棒的模型评估，并发现其与人类判断更一致。


<details>
  <summary>Details</summary>
Motivation: 评估视觉活动识别系统面临挑战，因为动词语义和图像解释存在固有的歧义（如同义词、不同视角但同样有效的动词选择）。标准的确切匹配评估方法依赖单一“黄金答案”，无法捕捉这些歧义，导致模型性能评估不完整。

Method: 提出一种视觉-语言聚类框架，用于构建动词义群，旨在提供更鲁棒的评估。将该框架应用于imSitu数据集，分析了每个图像与义群的映射关系，并评估了多个活动识别模型，将聚类评估与标准评估方法进行比较，还进行了人类对齐分析。

Result: 在imSitu数据集上的分析显示，每张图像平均映射到2.8个义群，每个义群代表图像的一个独特视角。聚类评估方法与标准评估方法相比，能更好地与人类判断对齐，提供了更细致的模型性能评估。

Conclusion: 所提出的基于义群的评估框架通过考虑语义歧义，并与人类判断更好地对齐，为视觉活动识别系统提供了更鲁棒和细致的模型性能评估方法。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [8] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 开发了一个多阶段大型语言模型（LLM）框架，用于从非结构化文本中准确、透明地提取与自杀相关的社会健康决定因素（SDoH），旨在支持早期干预和预防。


<details>
  <summary>Details</summary>
Motivation: 理解导致自杀事件的社会健康决定因素（SDoH）对早期干预和预防至关重要。然而，现有数据驱动方法面临因素分布长尾、分析关键压力源以及模型可解释性有限等挑战。

Method: 提出一个多阶段大型语言模型框架，以增强从非结构化文本中提取SDoH因素的能力。该方法与BioBERT、GPT-3.5-turbo和DeepSeek-R1等先进模型进行了比较，并通过自动化比较和试点用户研究评估了模型解释如何提高SDoH因素标注的速度和准确性。

Result: 所提出的框架在SDoH因素提取的总体任务和检索相关上下文的细粒度任务中均表现出性能提升。此外，通过微调小型、特定任务的模型，能在降低推理成本的同时实现相当或更优的性能。多阶段设计不仅增强了提取能力，还提供了中间解释，从而提高了模型的可解释性。

Conclusion: 该方法提高了从非结构化文本中提取与自杀相关的SDoH的准确性和透明度。这些进展有望支持高危个体的早期识别，并为制定更有效的预防策略提供信息。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [9] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 针对对话情感四元组抽取（DiaASQ）中现有方法引入噪音的问题，本文提出基于结构熵最小化算法的子对话划分方法和两步抽取框架，实现了更优性能和更低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有对话情感四元组抽取方法在整个对话范围内学习词语关系，但忽略了对话中存在的语义独立子对话，这种全局学习方式不可避免地引入了额外噪音，影响抽取效果。

Method: 本文提出将对话划分为语义独立的子对话，并引入结构熵最小化算法来精确分区，以保留相关话语并区分不相关话语。在此基础上，设计了一个两步抽取框架：首先在话语层面抽取单个情感元素，然后进而在子对话层面匹配完整的四元组。

Result: 实验结果表明，本文方法在DiaASQ任务上达到了当前最优（state-of-the-art）的性能，并且显著降低了计算成本。

Conclusion: 通过有效地将对话分割成语义独立的子对话，并采用分步抽取策略，本文方法成功解决了传统方法引入噪音的问题，大幅提升了对话情感四元组抽取的准确性和效率。

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [10] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 本文评估了对四种仅解码器大型语言模型（LLM）进行微调在AMR解析任务上的性能。研究发现，简单微调的LLM能达到与复杂SOTA解析器相当的性能，其中LLaMA 3.2表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 探索将仅解码器大型语言模型（LLMs）通过微调应用于抽象意义表示（AMR）解析，作为一种有前景且直接的新方向。

Method: 对Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled四种LLM架构进行微调，并在LDC2020T02 Gold AMR3.0测试集上进行全面评估。

Result: 1. 仅解码器LLM的简单微调可实现与复杂SOTA AMR解析器相当的性能。
2. LLaMA 3.2表现出竞争力，在LDC2020T02测试集上SMATCH F1达到0.804，与APT + Silver (IBM)持平，并接近Graphene Smatch (MBSE)。
3. LLaMA 3.2在语义性能上领先，而Phi 3.5在结构有效性上表现突出。

Conclusion: 简单微调仅解码器LLM是AMR解析的有效方法，能够达到与当前复杂SOTA方法相当的性能，其中LLaMA 3.2展现出强劲的竞争力。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [11] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 本文挑战了多任务学习中多组件PEFT范式，发现单一高秩LoRA或简化的、高相似性多头LoRA表现更优。提出Align-LoRA，通过对齐任务表示，显著提升多任务适应性。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调（PEFT）对大型语言模型（LLMs）的适应至关重要，尤其是在多任务学习（MTL）场景下。当前趋势是使用LoRA变体的多适配器或多头结构，倡导结构多样性以捕获任务特定知识，但本文对此范式提出质疑。

Method: 首先展示高头间相似度的简化多头架构优于复杂的多适配器和多头系统。接着证明增加秩的标准单适配器LoRA也能实现竞争力表现。基于“有效MTL泛化依赖于学习鲁棒共享表示”的假设，提出了Align-LoRA，其核心是引入一个显式损失来对齐共享适配器空间中的任务表示。

Result: 研究表明，高头间相似度的简化多头架构显著优于复杂的多适配器和多头系统。此外，增加秩的标准单适配器LoRA也达到了高度竞争力表现。实验证实，Align-LoRA显著超越了所有基线。

Conclusion: 有效的MTL泛化依赖于学习鲁棒的共享表示，而非隔离任务特定特征。Align-LoRA为LLMs的多任务适应提供了一个更简单、更有效的范式。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [12] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 针对多模态虚假信息，本文提出名为“MultiCheck”的统一框架，通过结合文本和图像编码器、融合模块及对比学习，在Factify 2数据集上实现了0.84的加权F1分数，显著优于基线，证明了多模态推理在事实核查中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前事实核查系统主要依赖文本证据，难以有效应对由文本和图像共同支持的日益增长的多模态虚假信息所带来的挑战。

Method: 本文提出了一个名为“MultiCheck”的统一框架，用于细粒度多模态事实核查。该架构包含专用的文本和图像编码器，一个利用逐元素交互捕获跨模态关系的融合模块，以及一个用于预测声明真实性的分类头。同时，引入对比学习目标以促进共享潜在空间中声明-证据对的语义对齐。

Result: 在Factify 2数据集上的评估显示，所提出方法实现了0.84的加权F1分数，显著优于基线模型。

Conclusion: 研究结果突显了显式多模态推理的有效性，并展示了所提方法在复杂、真实世界场景中进行可扩展和可解释事实核查的潜力。

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [13] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 针对RAG长上下文导致的无限制熵增长和注意力稀释问题，本文提出平衡熵工程RAG（BEE-RAG）框架，通过熵不变性原理稳定注意力，显著提升RAG在不同上下文长度下的性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，RAG成为补充其知识局限的关键方法。然而，RAG因检索信息量大，常面临长上下文问题，导致无限制的熵增长和注意力稀释，从而严重影响系统性能。

Method: 本文提出了平衡熵工程RAG（BEE-RAG）框架，该框架基于熵不变性原理，通过平衡上下文熵来重构注意力动态，使注意力敏感度与上下文长度解耦，从而确保稳定的熵水平。在此基础上，BEE-RAG引入了用于多重要性估计的零样本推理策略，并结合参数高效的自适应微调机制以获得针对不同设置的最优平衡因子。

Result: 在多个RAG任务上进行的广泛实验表明，BEE-RAG框架是有效的。

Conclusion: BEE-RAG框架通过熵工程方法，有效解决了RAG在长上下文场景下的性能挑战，提高了系统的适应性和稳定性。

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [14] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: LLM性能受输入信息位置影响。本文发现模型倾向于关注序列首尾信息（注意力洼地），并提出AttnRank方法，通过重排内容以对齐高注意力位置，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的性能对输入信息的位置高度敏感，研究旨在探究这种位置偏差背后的机制，并利用该机制提升模型表现。

Method: 研究首先通过实验揭示了“注意力洼地”现象，即模型对序列首尾的信息分配更高注意力。在此基础上，提出AttnRank框架，分两阶段进行：1) 使用校准集估计模型的内在位置注意力偏好；2) 将检索到的文档或少样本示例中的关键内容重新排序，使其与高注意力位置对齐。该方法是模型无关、无需训练且即插即用的。

Result: AttnRank在多跳问答和少样本上下文学习任务上，对10种不同架构和规模的大型语言模型均实现了显著性能提升，且无需修改模型参数或训练流程。

Conclusion: 利用模型固有的位置注意力偏好，通过简单的内容重排（AttnRank）可以有效提升LLM的性能，证明了理解和利用这种机制的重要性及实用性。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [15] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 本文提出PrinciplismQA，一个针对医疗领域LLM伦理推理的综合评估基准。研究发现LLM在伦理知识与实际应用间存在显著差距，尤其在“受益”原则上表现不足，并指出微调虽有帮助但需更好对齐伦理知识。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）整合到医疗保健领域需要对其伦理推理能力进行严格评估，而当前基准常常忽视这一领域。

Method: 研究引入了PrinciplismQA，一个包含3,648个问题的综合基准，旨在系统评估LLM与核心医学伦理的对齐程度。该基准以“原则主义”为基础，包含来自权威教科书的多项选择题和来自权威医学伦理案例研究文献的开放式问题，所有内容均经过医学专家验证。

Result: 实验揭示了模型伦理知识与其实际应用之间的显著差距，尤其是在将伦理原则动态应用于现实场景时。大多数LLM在处理与“受益”原则相关的困境时表现挣扎，常过度强调其他原则。领先的是具有强大通用能力的封闭源模型。医学领域微调可以增强模型的整体伦理能力，但进一步的进展需要更好地与医学伦理知识对齐。

Conclusion: PrinciplismQA提供了一个可扩展的框架，用于诊断LLM特定的伦理弱点，从而为开发更平衡和负责任的医疗AI铺平道路。

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [16] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: ATLANTIS团队在SemEval-2025任务3中，针对问答系统中的大模型幻觉检测，探索了基于few-shot prompting、token级分类和模型微调的方法，并在多语言竞赛中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在自然语言生成方面表现出色，但仍易产生幻觉（即不正确或误导性内容），因此需要有效方法来检测这些幻觉文本片段。

Method: 研究方法包括使用或不使用外部上下文，具体技术涉及基于LLM的few-shot prompting、token级别分类，以及在合成数据上对LLM进行微调。

Result: 研究方法在西班牙语赛道中取得了顶级排名，在英语和德语赛道中也取得了有竞争力的成绩。

Conclusion: 该工作强调了整合相关上下文对于减轻幻觉的重要性，并展示了微调模型和提示工程的巨大潜力。

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [17] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 在资源受限环境下，通过知识蒸馏使轻量级模型实现多模态情感推理生成与分类。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖参数量大的多模态大语言模型（MLLMs）进行情感分类，而忽略了资源受限环境下自主多模态情感推理生成的需求。

Method: 提出MulCoT-RD模型，采用“教师-助理-学生”蒸馏范式。首先利用高性能MLLM生成推理数据集，训练一个中等规模的助理模型，再联合训练一个轻量级学生模型以同时进行高效的多模态情感推理生成和分类。

Result: MulCoT-RD模型（仅30亿参数）在四大数据集上的JMSRC任务中表现出色，同时展示了强大的泛化能力和增强的可解释性。

Conclusion: 该研究成功地证明了在资源受限环境下，通过知识蒸馏范式，轻量级模型也能有效地进行多模态情感推理和分类，兼具高性能、鲁棒泛化能力和可解释性。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [18] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 提出一种受人脑启发的功能网络保留剪枝方法，以提高大型语言模型的剪枝效率，解决现有方法忽视神经元交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法忽视了人工神经元之间的交互与协作，导致LLM的宏观功能架构被破坏，进而引起剪枝性能下降。

Method: 将LLM视为一个数字大脑，将其分解为功能网络，并类比神经影像数据中功能性大脑网络的识别。通过保留这些功能网络中的关键神经元来进行LLM剪枝。

Result: 该方法能够成功识别和定位LLM中的功能网络和关键神经元，实现高效的模型剪枝。

Conclusion: 通过识别和保留LLM内部的功能网络，该方法有效解决了传统结构化剪枝中忽视神经元交互的挑战，提升了模型的剪枝效率和性能。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [19] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost是一个创新的后训练框架，无需人工标注指令，纯粹利用代码片段来提升代码大语言模型的性能，并通过多个独特组件实现了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLM的后训练严重依赖难以收集和扩展的高质量人工标注指令，而代码片段资源丰富。这种指令稀缺与代码富余的不平衡是当前训练范式的瓶颈。

Method: 提出CodeBoost框架，核心在于纯粹从代码片段中学习。关键组件包括：1) 最大团策展，选择代表性训练语料；2) 双向预测，学习前向和后向预测目标；3) 错误感知预测，利用正确和不正确输出信号；4) 异构增强，多样化训练分布；5) 异构奖励，通过多类型奖励（如格式正确性、执行反馈）指导学习。

Result: 在多个代码LLM和基准测试上进行的广泛实验表明，CodeBoost始终能提升模型性能。

Conclusion: CodeBoost是一个可扩展且有效的训练管道，证明了其在不依赖人工指令的情况下增强代码LLM的有效性。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [20] [RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration](https://arxiv.org/abs/2508.04797)
*Mohab Kishawy,Ali Abdellatif Hussein,Jun Chen*

Main category: cs.CV

TL;DR: 提出RetinexDual，一个新型基于Retinex理论的UHD图像恢复框架，通过结合空间域的SAMBA和频率域的FIA双分支设计，在多项恢复任务中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: UHD图像恢复（UHD IR）面临挑战：传统下采样方法导致不可逆信息损失；纯频率域方法因丢失降级局部性而无法有效处理空间受限的图像伪影。

Method: 开发了RetinexDual框架，基于Retinex理论，包含两个互补子网络：Scale-Attentive maMBA (SAMBA) 负责校正反射分量，采用粗到精机制减少伪影和恢复细节；Frequency Illumination Adaptor (FIA) 在频域操作，利用全局上下文精确校正颜色和光照畸变。

Result: RetinexDual在去雨、去模糊、去雾和低光图像增强四项UHD IR任务上，定性和定量地超越了最新方法。消融研究证实了各分支独特设计的重要性及其组件的有效性。

Conclusion: RetinexDual通过融合空间域的细节恢复和频域的全局上下文校正，有效解决了UHD图像恢复中的关键问题，并验证了其双分支设计的优越性和各组件的有效性。

Abstract: Advancements in image sensing have elevated the importance of
Ultra-High-Definition Image Restoration (UHD IR). Traditional methods, such as
extreme downsampling or transformation from the spatial to the frequency
domain, encounter significant drawbacks: downsampling induces irreversible
information loss in UHD images, while our frequency analysis reveals that pure
frequency-domain approaches are ineffective for spatially confined image
artifacts, primarily due to the loss of degradation locality. To overcome these
limitations, we present RetinexDual, a novel Retinex theory-based framework
designed for generalized UHD IR tasks. RetinexDual leverages two complementary
sub-networks: the Scale-Attentive maMBA (SAMBA) and the Frequency Illumination
Adaptor (FIA). SAMBA, responsible for correcting the reflectance component,
utilizes a coarse-to-fine mechanism to overcome the causal modeling of mamba,
which effectively reduces artifacts and restores intricate details. On the
other hand, FIA ensures precise correction of color and illumination
distortions by operating in the frequency domain and leveraging the global
context provided by it. Evaluating RetinexDual on four UHD IR tasks, namely
deraining, deblurring, dehazing, and Low-Light Image Enhancement (LLIE), shows
that it outperforms recent methods qualitatively and quantitatively. Ablation
studies demonstrate the importance of employing distinct designs for each
branch in RetinexDual, as well as the effectiveness of its various components.

</details>


### [21] [ACM Multimedia Grand Challenge on ENT Endoscopy Analysis](https://arxiv.org/abs/2508.04801)
*Trong-Thuan Nguyen,Viet-Tham Huynh,Thao Thi Phuong Dao,Ha Nguyen Thi,Tien To Vu Thuy,Uyen Hanh Tran,Tam V. Nguyen,Thanh Dinh Le,Minh-Triet Tran*

Main category: cs.CV

TL;DR: 本文介绍了一个名为ENTRep的耳鼻喉内窥镜图像分析大挑战，旨在通过提供细粒度分类、图像-图像和文本-图像检索功能，解决当前自动化分析领域基准不足的问题。


<details>
  <summary>Details</summary>
Motivation: 耳鼻喉内窥镜图像的自动化分析在临床上至关重要但发展滞后，主要受设备差异、细微病变和精细区分（如左右侧、声带状态）的限制。此外，临床医生不仅需要图像分类，还需可靠的相似病例检索功能，而现有公开基准无法满足这些需求。

Method: 引入了ENTRep，即ACM Multimedia 2025耳鼻喉内窥镜分析大挑战。该挑战整合了细粒度解剖分类、图像到图像检索以及文本到图像检索，并辅以双语（越南语和英语）临床监督。数据集包含由专家标注的图像（带解剖区域和正常/异常状态标签）以及双语叙述性描述。挑战定义了三个基准任务，标准化提交协议，并通过服务器端评分在公共和私有测试集上评估性能。

Result: 报告了表现最佳团队的研究成果，并进行了深入的讨论。

Conclusion: ENTRep成功建立了一个全面的基准平台，有效应对了耳鼻喉内窥镜图像自动化分析中的关键挑战，尤其在细粒度分类和病例检索方面，从而推动了该领域的研究进展。

Abstract: Automated analysis of endoscopic imagery is a critical yet underdeveloped
component of ENT (ear, nose, and throat) care, hindered by variability in
devices and operators, subtle and localized findings, and fine-grained
distinctions such as laterality and vocal-fold state. In addition to
classification, clinicians require reliable retrieval of similar cases, both
visually and through concise textual descriptions. These capabilities are
rarely supported by existing public benchmarks. To this end, we introduce
ENTRep, the ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis,
which integrates fine-grained anatomical classification with image-to-image and
text-to-image retrieval under bilingual (Vietnamese and English) clinical
supervision. Specifically, the dataset comprises expert-annotated images,
labeled for anatomical region and normal or abnormal status, and accompanied by
dual-language narrative descriptions. In addition, we define three benchmark
tasks, standardize the submission protocol, and evaluate performance on public
and private test splits using server-side scoring. Moreover, we report results
from the top-performing teams and provide an insight discussion.

</details>


### [22] [CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework](https://arxiv.org/abs/2508.04816)
*Sriram Mandalika,Lalitha V*

Main category: cs.CV

TL;DR: CoMAD提出一种轻量级、无参数的框架，通过非对称掩蔽和共识门控，将多个自监督Vision Transformer的知识蒸馏到紧凑型学生网络中，实现了紧凑型自监督学习蒸馏的最新SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习范式通常独立预训练，忽略互补洞见，且模型庞大，不适用于资源受限的部署。研究旨在克服这些挑战，将多源知识统一到紧凑模型中。

Method: 引入CoMAD（共识导向掩蔽蒸馏）框架，从MAE、MoCo v3、iBOT三个预训练ViT-Base教师模型中蒸馏知识到紧凑型学生网络。采用非对称掩蔽策略（学生仅见25%补丁，教师接收不同程度的轻度掩蔽），迫使学生在更丰富的上下文中插值缺失特征。教师嵌入通过线性适配器和层归一化与学生空间对齐，并通过结合余弦相似度和教师间一致性的联合共识门控融合。学生通过可见token和重建特征图上的双级KL散度进行训练。

Result: 在ImageNet-1K上，CoMAD的ViT-Tiny达到75.4% Top-1准确率，比之前SOTA提升0.4%。在密集预测迁移任务中，ADE20K上mIoU达47.3%，MS-COCO上box AP达44.5%，mask AP达40.5%，在紧凑型自监督学习蒸馏领域建立了新的SOTA。

Conclusion: CoMAD成功地将多个大型自监督模型的互补知识蒸馏到紧凑型学生网络中，显著提升了资源受限部署场景下的自监督学习性能，并确立了新的最先进水平。

Abstract: Numerous self-supervised learning paradigms, such as contrastive learning and
masked image modeling, learn powerful representations from unlabeled data but
are typically pretrained in isolation, overlooking complementary insights and
yielding large models that are impractical for resource-constrained deployment.
To overcome these challenges, we introduce Consensus-oriented Masked
Distillation (CoMAD), a lightweight, parameter-free framework that unifies
knowledge from multiple current state-of-the-art self-supervised Vision
Transformers into a compact student network. CoMAD distills from three
pretrained ViT-Base teachers, MAE, MoCo v3, and iBOT, each offering distinct
semantic and contextual priors. Rather than naively averaging teacher outputs,
we apply asymmetric masking: the student sees only 25 percent of patches while
each teacher receives a progressively lighter, unique mask, forcing the student
to interpolate missing features under richer contexts. Teacher embeddings are
aligned to the student's space via a linear adapter and layer normalization,
then fused through our joint consensus gating, which weights each token by
combining cosine affinity with inter-teacher agreement. The student is trained
with dual-level KL divergence on visible tokens and reconstructed feature maps,
capturing both local and global structure. On ImageNet-1K, CoMAD's ViT-Tiny
achieves 75.4 percent Top-1, an increment of 0.4 percent over the previous
state-of-the-art. In dense-prediction transfers, it attains 47.3 percent mIoU
on ADE20K, and 44.5 percent box average precision and 40.5 percent mask average
precision on MS-COCO, establishing a new state-of-the-art in compact SSL
distillation.

</details>


### [23] [Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models](https://arxiv.org/abs/2508.04818)
*Mehrdad Moradi,Marco Grasso,Bianca Maria Colosimo,Kamran Paynabar*

Main category: cs.CV

TL;DR: 本文提出了一种名为RADAR的无重建注意力扩散模型，直接从扩散模型生成异常图，解决了现有重建方法的计算昂贵和准确性挑战，并在多个数据集上显著优于现有最先进的异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的异常检测方法依赖重建过程，存在三个主要问题：1) 计算成本高，不适用于实时应用；2) 对复杂模式，重建图像可能不准确；3) 中间噪声水平选择困难，且通常需要预先知道异常信息，不适用于无监督场景。

Method: 引入了RADAR（Reconstruction-free Anomaly Detection with Attention-based diffusion models in Real-time）方法。与当前最先进的重建方法不同，RADAR直接从扩散模型生成异常图，从而避免了重建过程。

Result: RADAR在实际3D打印材料和MVTec-AD数据集上进行了评估，结果显示其在准确率、精确率、召回率和F1分数等所有关键指标上均超越了最先进的基于扩散模型和统计机器学习模型。具体而言，RADAR在MVTec-AD数据集上F1分数提升了7%，在3D打印材料数据集上提升了13%（相较于次优模型）。

Conclusion: RADAR成功克服了基于重建的异常检测方法的局限性，通过直接生成异常图，显著提高了检测准确性和计算效率，为实时异常检测提供了更优的解决方案。

Abstract: Generative models have demonstrated significant success in anomaly detection
and segmentation over the past decade. Recently, diffusion models have emerged
as a powerful alternative, outperforming previous approaches such as GANs and
VAEs. In typical diffusion-based anomaly detection, a model is trained on
normal data, and during inference, anomalous images are perturbed to a
predefined intermediate step in the forward diffusion process. The
corresponding normal image is then reconstructed through iterative reverse
sampling.
  However, reconstruction-based approaches present three major challenges: (1)
the reconstruction process is computationally expensive due to multiple
sampling steps, making real-time applications impractical; (2) for complex or
subtle patterns, the reconstructed image may correspond to a different normal
pattern rather than the original input; and (3) Choosing an appropriate
intermediate noise level is challenging because it is application-dependent and
often assumes prior knowledge of anomalies, an assumption that does not hold in
unsupervised settings.
  We introduce Reconstruction-free Anomaly Detection with Attention-based
diffusion models in Real-time (RADAR), which overcomes the limitations of
reconstruction-based anomaly detection. Unlike current SOTA methods that
reconstruct the input image, RADAR directly produces anomaly maps from the
diffusion model, improving both detection accuracy and computational
efficiency. We evaluate RADAR on real-world 3D-printed material and the
MVTec-AD dataset. Our approach surpasses state-of-the-art diffusion-based and
statistical machine learning models across all key metrics, including accuracy,
precision, recall, and F1 score. Specifically, RADAR improves F1 score by 7% on
MVTec-AD and 13% on the 3D-printed material dataset compared to the next best
model.
  Code available at: https://github.com/mehrdadmoradi124/RADAR

</details>


### [24] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
*Chirag Seth,Divya Naiken,Keyan Lin*

Main category: cs.CV

TL;DR: 本项目利用事件相机和深度学习（CNN-LSTM）实现经济高效的眼球中心跟踪，以预测用户注意力，在VR/AR应用中提升用户体验，模型准确率达81%。


<details>
  <summary>Details</summary>
Motivation: 传统精确眼球追踪需昂贵高速相机，难以应对快速眼动挑战。本研究旨在开发一种经济且可解释的算法，通过眼动分析预测人类注意力，从而改善VR/AR等消费电子设备的用户舒适度和体验。

Method: 研究探索了多种深度学习方法，利用事件相机输入定位眼球中心。其中，CNN-LSTM模型被证明最有效。未来工作将探索逐层相关性传播（LRP）以提升模型可解释性。

Result: CNN-LSTM模型在定位眼球中心位置方面取得了约81%的准确率。

Conclusion: 本研究成功开发了一种基于CNN-LSTM的经济高效眼球追踪算法，实现了眼球中心定位，有望通过预测人类注意力提升VR/AR等消费电子产品的用户体验。未来将侧重于LRP以增强模型的可解释性和预测性能。

Abstract: This research project addresses the challenge of accurately tracking eye
movements during specific events by leveraging previous research. Given the
rapid movements of human eyes, which can reach speeds of 300{\deg}/s, precise
eye tracking typically requires expensive and high-speed cameras. Our primary
objective is to locate the eye center position (x, y) using inputs from an
event camera. Eye movement analysis has extensive applications in consumer
electronics, especially in VR and AR product development. Therefore, our
ultimate goal is to develop an interpretable and cost-effective algorithm using
deep learning methods to predict human attention, thereby improving device
comfort and enhancing overall user experience. To achieve this goal, we
explored various approaches, with the CNN\_LSTM model proving most effective,
achieving approximately 81\% accuracy. Additionally, we propose future work
focusing on Layer-wise Relevance Propagation (LRP) to further enhance the
model's interpretability and predictive performance.

</details>


### [25] [LuKAN: A Kolmogorov-Arnold Network Framework for 3D Human Motion Prediction](https://arxiv.org/abs/2508.04847)
*Md Zahidul Hasan,A. Ben Hamza,Nizar Bouguila*

Main category: cs.CV

TL;DR: LuKAN是一种基于KAN和卢卡斯多项式激活的3D人体运动预测模型，通过小波变换和空间投影，有效平衡预测精度与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动预测方法在预测精度和计算效率之间难以取得平衡。

Method: 本文提出了LuKAN模型，该模型基于科尔莫戈罗夫-阿诺德网络（KANs），并采用卢卡斯多项式作为激活函数。具体步骤包括：首先使用离散小波变换编码时间信息；其次利用空间投影层捕获关节间依赖关系；核心是“时间依赖学习器”，它采用卢卡斯多项式参数化的KAN层进行高效函数逼近；最后通过逆离散小波变换重建运动序列。

Result: 在三个基准数据集上的广泛实验表明，LuKAN模型与现有基线方法相比具有竞争力的性能（包括定量和定性评估）。此外，其紧凑的架构和卢卡斯多项式的线性递推特性确保了计算效率。

Conclusion: LuKAN模型通过创新的架构和激活函数，成功在3D人体运动预测中实现了预测精度和计算效率的有效平衡，为该领域提供了一个高性能且高效的解决方案。

Abstract: The goal of 3D human motion prediction is to forecast future 3D poses of the
human body based on historical motion data. Existing methods often face
limitations in achieving a balance between prediction accuracy and
computational efficiency. In this paper, we present LuKAN, an effective model
based on Kolmogorov-Arnold Networks (KANs) with Lucas polynomial activations.
Our model first applies the discrete wavelet transform to encode temporal
information in the input motion sequence. Then, a spatial projection layer is
used to capture inter-joint dependencies, ensuring structural consistency of
the human body. At the core of LuKAN is the Temporal Dependency Learner, which
employs a KAN layer parameterized by Lucas polynomials for efficient function
approximation. These polynomials provide computational efficiency and an
enhanced capability to handle oscillatory behaviors. Finally, the inverse
discrete wavelet transform reconstructs motion sequences in the time domain,
generating temporally coherent predictions. Extensive experiments on three
benchmark datasets demonstrate the competitive performance of our model
compared to strong baselines, as evidenced by both quantitative and qualitative
evaluations. Moreover, its compact architecture coupled with the linear
recurrence of Lucas polynomials, ensures computational efficiency.

</details>


### [26] [VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence](https://arxiv.org/abs/2508.04852)
*Chenhui Qiang,Zhaoyang Wei,Xumeng Han Zipeng Wang,Siyao Li,Xiangyuan Lan,Jianbin Jiao,Zhenjun Han*

Main category: cs.CV

TL;DR: 现有MLLM评估基准缺乏对细微视觉线索的深层推理评估。本文提出VER-Bench，一个新颖基准，用于评估MLLM识别细粒度视觉线索并结合世界知识进行复杂推理的能力，揭示当前模型在此方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着MLLM快速发展，评估其视觉能力至关重要。然而，现有基准未能有效评估模型对图像中细微、不显眼的局部细节的理解和复杂推理能力，而这些细节对于深刻的视觉理解至关重要。

Method: 引入VER-Bench框架，包含374个精心设计的问题，涵盖地理空间、时间、情境、意图、系统状态和符号推理六种类型。每个问题都配备结构化证据，包括细粒度视觉线索（平均仅占图像0.25%）和基于这些线索的推理，旨在评估MLLM识别并整合这些线索进行复杂推理的能力。

Result: VER-Bench揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性。

Conclusion: 为了实现真正的视觉理解和类人分析，需要增强模型在细粒度视觉证据提取、整合和推理方面的能力。

Abstract: With the rapid development of MLLMs, evaluating their visual capabilities has
become increasingly crucial. Current benchmarks primarily fall into two main
types: basic perception benchmarks, which focus on local details but lack deep
reasoning (e.g., "what is in the image?"), and mainstream reasoning benchmarks,
which concentrate on prominent image elements but may fail to assess subtle
clues requiring intricate analysis. However, profound visual understanding and
complex reasoning depend more on interpreting subtle, inconspicuous local
details than on perceiving salient, macro-level objects. These details, though
occupying minimal image area, often contain richer, more critical information
for robust analysis. To bridge this gap, we introduce the VER-Bench, a novel
framework to evaluate MLLMs' ability to: 1) identify fine-grained visual clues,
often occupying on average just 0.25% of the image area; 2) integrate these
clues with world knowledge for complex reasoning. Comprising 374 carefully
designed questions across Geospatial, Temporal, Situational, Intent, System
State, and Symbolic reasoning, each question in VER-Bench is accompanied by
structured evidence: visual clues and question-related reasoning derived from
them. VER-Bench reveals current models' limitations in extracting subtle visual
evidence and constructing evidence-based arguments, highlighting the need to
enhance models's capabilities in fine-grained visual evidence extraction,
integration, and reasoning for genuine visual understanding and human-like
analysis. Dataset and additional materials are available
https://github.com/verbta/ACMMM-25-Materials.

</details>


### [27] [Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications](https://arxiv.org/abs/2508.04868)
*Noreen Anwar,Guillaume-Alexandre Bilodeau,Wassim Bouachir*

Main category: cs.CV

TL;DR: 提出DAMM，一种新型Transformer目标检测器，通过多模态查询和双流注意力解决遮挡、精细定位和计算效率问题，并在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的目标检测器在处理遮挡、精细定位和计算效率方面存在挑战，这通常源于固定的查询和密集的注意力机制。

Method: 本文提出DAMM（Dual-stream Attention with Multi-Modal queries）框架，引入查询自适应和结构化交叉注意力。DAMM利用三类查询：基于外观的（来自视觉-语言模型）、基于位置的（使用多边形嵌入）和随机学习的。此外，一个双流交叉注意力模块被用于分别精炼语义和空间特征，以提高混乱场景中的定位精度。

Result: DAMM在四个具有挑战性的基准测试中进行了评估，并在平均精度（AP）和召回率方面取得了最先进（SOTA）的性能。

Conclusion: 研究结果表明，多模态查询自适应和双流注意力机制在提升Transformer目标检测器的准确性和效率方面是有效的，尤其是在解决遮挡和精细定位问题上。

Abstract: Transformer-based object detectors often struggle with occlusions,
fine-grained localization, and computational inefficiency caused by fixed
queries and dense attention. We propose DAMM, Dual-stream Attention with
Multi-Modal queries, a novel framework introducing both query adaptation and
structured cross-attention for improved accuracy and efficiency. DAMM
capitalizes on three types of queries: appearance-based queries from
vision-language models, positional queries using polygonal embeddings, and
random learned queries for general scene coverage. Furthermore, a dual-stream
cross-attention module separately refines semantic and spatial features,
boosting localization precision in cluttered scenes. We evaluated DAMM on four
challenging benchmarks, and it achieved state-of-the-art performance in average
precision (AP) and recall, demonstrating the effectiveness of multi-modal query
adaptation and dual-stream attention. Source code is at:
\href{https://github.com/DET-LIP/DAMM}{GitHub}.

</details>


### [28] [Revealing Temporal Label Noise in Multimodal Hateful Video Classification](https://arxiv.org/abs/2508.04900)
*Shuonan Yang,Tailin Chen,Rahul Singh,Jiangbei Yue,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 现有仇恨视频检测受粗粒度标注的噪声影响。本研究通过精细修剪视频来分析和量化这种噪声，发现其严重影响模型性能，并强调了时序感知模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨视频检测方法普遍依赖粗粒度、视频级别的标注，导致标签噪声严重，因为被标记为仇恨的视频常包含大量非仇恨片段，这掩盖了仇恨内容的实际时序特征。

Method: 采用细粒度方法，利用时间戳从HateMM和MultiHateClip数据集中修剪出明确的仇恨片段。对修剪后的片段进行探索性分析，并进行对照实验以量化时间戳噪声对模型决策边界和分类置信度的影响。

Result: 分析揭示了粗粒度标注引入的语义重叠和混淆。对照实验证明，时间戳噪声会根本性地改变模型决策边界并削弱分类置信度，突显了仇恨言论表达的内在上下文依赖性和时序连续性。

Conclusion: 本研究深入揭示了多模态仇恨视频的时序动态，强调了开发具备时序感知能力的模型和基准的重要性，以提升仇恨内容检测的鲁棒性和可解释性。

Abstract: The rapid proliferation of online multimedia content has intensified the
spread of hate speech, presenting critical societal and regulatory challenges.
While recent work has advanced multimodal hateful video detection, most
approaches rely on coarse, video-level annotations that overlook the temporal
granularity of hateful content. This introduces substantial label noise, as
videos annotated as hateful often contain long non-hateful segments. In this
paper, we investigate the impact of such label ambiguity through a fine-grained
approach. Specifically, we trim hateful videos from the HateMM and
MultiHateClip English datasets using annotated timestamps to isolate explicitly
hateful segments. We then conduct an exploratory analysis of these trimmed
segments to examine the distribution and characteristics of both hateful and
non-hateful content. This analysis highlights the degree of semantic overlap
and the confusion introduced by coarse, video-level annotations. Finally,
controlled experiments demonstrated that time-stamp noise fundamentally alters
model decision boundaries and weakens classification confidence, highlighting
the inherent context dependency and temporal continuity of hate speech
expression. Our findings provide new insights into the temporal dynamics of
multimodal hateful videos and highlight the need for temporally aware models
and benchmarks for improved robustness and interpretability. Code and data are
available at
https://github.com/Multimodal-Intelligence-Lab-MIL/HatefulVideoLabelNoise.

</details>


### [29] [Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations](https://arxiv.org/abs/2508.04924)
*Zahidul Islam,Sujoy Paul,Mrigank Rochan*

Main category: cs.CV

TL;DR: 本文提出Highlight-TTA框架，通过测试时自适应（TTA）解决现有视频精彩片段检测模型泛化能力差的问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频精彩片段检测方法使用通用固定模型，难以适应不同测试视频的独特特征、内容和质量，导致泛化能力受限和性能下降。

Method: 提出Highlight-TTA框架，在测试阶段动态调整模型以适应每个测试视频的特性。该框架与主任务（精彩片段检测）和辅助任务（跨模态幻觉）联合优化，并采用元辅助训练方案。在测试时，利用辅助任务对训练好的模型进行自适应。

Result: 在三个最先进的精彩片段检测模型和三个基准数据集上进行的大量实验表明，引入Highlight-TTA显著提升了这些模型的性能，取得了更优越的结果。

Conclusion: Highlight-TTA通过创新的测试时自适应方法，有效解决了视频精彩片段检测中模型的泛化性问题，显著增强了现有检测模型的表现。

Abstract: Existing video highlight detection methods, although advanced, struggle to
generalize well to all test videos. These methods typically employ a generic
highlight detection model for each test video, which is suboptimal as it fails
to account for the unique characteristics and variations of individual test
videos. Such fixed models do not adapt to the diverse content, styles, or audio
and visual qualities present in new, unseen test videos, leading to reduced
highlight detection performance. In this paper, we propose Highlight-TTA, a
test-time adaptation framework for video highlight detection that addresses
this limitation by dynamically adapting the model during testing to better
align with the specific characteristics of each test video, thereby improving
generalization and highlight detection performance. Highlight-TTA is jointly
optimized with an auxiliary task, cross-modality hallucinations, alongside the
primary highlight detection task. We utilize a meta-auxiliary training scheme
to enable effective adaptation through the auxiliary task while enhancing the
primary task. During testing, we adapt the trained model using the auxiliary
task on the test video to further enhance its highlight detection performance.
Extensive experiments with three state-of-the-art highlight detection models
and three benchmark datasets show that the introduction of Highlight-TTA to
these models improves their performance, yielding superior results.

</details>


### [30] [Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens](https://arxiv.org/abs/2508.04928)
*Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong*

Main category: cs.CV

TL;DR: 提出一种基于“Calibration Tokens”的方法，通过对齐潜在嵌入，无需重新训练即可将单目深度估计器（FMDEs）扩展到鱼眼图像，有效解决校准参数变化导致的协变量偏移问题。


<details>
  <summary>Details</summary>
Motivation: 现有的单目深度估计器（FMDEs）虽经大量透视图像训练，但面对鱼眼图像时，由于相机校准参数（内参、畸变）变化引入的协变量偏移，导致深度估计错误，限制了其在鱼眼相机上的应用。

Method: 提出一种自监督的轻量级适应机制“Calibration Tokens”，通过调制FMDEs的潜在嵌入，将鱼眼图像的潜在嵌入分布与透视图像的分布对齐。该方法不依赖真实的鱼眼图像数据，而是利用公开的透视图像数据集，将其重校准为鱼眼图像，并强制训练过程中估计的一致性，从而避免了传统图像空间重校准引入的负面影响。

Result: 在室内外场景中，针对多种FMDEs进行了评估。结果表明，该方法使用一套“Calibration Tokens”即可持续性地优于现有的最先进方法。

Conclusion: 该方法成功地使基于透视图像训练的FMDEs无需重新训练或微调即可应用于鱼眼图像，有效解决了因相机校准变化引起的深度估计挑战。通过在潜在空间进行对齐，提供了一种高效且高性能的解决方案，扩展了现有深度估计器的适用范围。

Abstract: We propose a method to extend foundational monocular depth estimators
(FMDEs), trained on perspective images, to fisheye images. Despite being
trained on tens of millions of images, FMDEs are susceptible to the covariate
shift introduced by changes in camera calibration (intrinsic, distortion)
parameters, leading to erroneous depth estimates. Our method aligns the
distribution of latent embeddings encoding fisheye images to those of
perspective images, enabling the reuse of FMDEs for fisheye cameras without
retraining or finetuning. To this end, we introduce a set of Calibration Tokens
as a light-weight adaptation mechanism that modulates the latent embeddings for
alignment. By exploiting the already expressive latent space of FMDEs, we posit
that modulating their embeddings avoids the negative impact of artifacts and
loss introduced in conventional recalibration or map projection to a canonical
reference frame in the image space. Our method is self-supervised and does not
require fisheye images but leverages publicly available large-scale perspective
image datasets. This is done by recalibrating perspective images to fisheye
images, and enforcing consistency between their estimates during training. We
evaluate our approach with several FMDEs, on both indoors and outdoors, where
we consistently improve over state-of-the-art methods using a single set of
tokens for both. Code available at:
https://github.com/JungHeeKim29/calibration-token.

</details>


### [31] [Toward Errorless Training ImageNet-1k](https://arxiv.org/abs/2508.04941)
*Bo Deng,Levi Heath*

Main category: cs.CV

TL;DR: 本文介绍了一种在ImageNet 2012数据集上使用新方法训练的前馈神经网络，实现了高精度。


<details>
  <summary>Details</summary>
Motivation: 论文旨在展示一种新的训练方法在大型图像分类数据集（ImageNet）上的性能，以达到高精度识别。

Method: 使用一种新的训练方法（[5]中描述）来训练一个前馈人工神经网络，并在ImageNet 2012竞赛数据集上进行评估。

Result: 模型在ImageNet 2012数据集上取得了98.3%的准确率和99.69%的Top-1准确率，平均有285.9个标签被完美分类。最佳模型拥有322,430,160个参数。作者推测未能达到100%准确率的原因是数据集中存在重复图像和不同标签的“双重标记”问题。

Conclusion: 所提出的模型在ImageNet数据集上表现出色，达到了非常高的准确率，但未能达到100%可能归因于数据集本身的双重标记问题。

Abstract: In this paper, we describe a feedforward artificial neural network trained on
the ImageNet 2012 contest dataset [7] with the new method of [5] to an accuracy
rate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are
perfectly classified over the 10 batch partitions of the dataset. The best
performing model uses 322,430,160 parameters, with 4 decimal places precision.
We conjecture that the reason our model does not achieve a 100% accuracy rate
is due to a double-labeling problem, by which there are duplicate images in the
dataset with different labels.

</details>


### [32] [Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models](https://arxiv.org/abs/2508.04942)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: ProMIM是一个即插即用的框架，通过集成掩码图像建模（MIM），增强了视觉语言模型（VLM）的条件提示学习，有效解决了过拟合问题，显著提升了模型对未知类别的泛化能力，且计算成本可忽略不计。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）如CLIP在零样本学习中表现出色，但适应新任务通常需要大量资源。提示学习技术（如CoOp和CoCoOp）虽然提供了高效的适应方法，但往往过拟合于已知类别，限制了它们对未见类别的泛化能力。

Method: 本文提出了ProMIM，一个即插即用的框架，通过将掩码图像建模（MIM）集成到现有VLM管道中，来增强条件提示学习。ProMIM采用一种简单而有效的掩码策略，仅掩码可见图像块，并利用这些表示来指导提示生成，从而产生鲁棒的实例条件提示。它能无缝地增强CoOp和CoCoOp等方法，而无需改变其核心架构。

Result: 在零样本和少样本分类任务中进行的大量实验表明，ProMIM在与现有方法结合使用时，能持续提升模型的泛化性能。此外，它引入的额外计算成本可以忽略不计。

Conclusion: ProMIM提供了一个实用且轻量级的解决方案，可显著提高现有视觉语言模型在真实世界应用中的泛化能力。

Abstract: Vision-language models (VLMs) like CLIP excel in zero-shot learning but often
require resource-intensive training to adapt to new tasks. Prompt learning
techniques, such as CoOp and CoCoOp, offer efficient adaptation but tend to
overfit to known classes, limiting generalization to unseen categories. We
introduce ProMIM, a plug-and-play framework that enhances conditional prompt
learning by integrating masked image modeling (MIM) into existing VLM
pipelines. ProMIM leverages a simple yet effective masking strategy to generate
robust, instance-conditioned prompts, seamlessly augmenting methods like CoOp
and CoCoOp without altering their core architectures. By masking only visible
image patches and using these representations to guide prompt generation,
ProMIM improves feature robustness and mitigates overfitting, all while
introducing negligible additional computational cost. Extensive experiments
across zero-shot and few-shot classification tasks demonstrate that ProMIM
consistently boosts generalization performance when plugged into existing
approaches, providing a practical, lightweight solution for real-world
vision-language applications.

</details>


### [33] [TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring](https://arxiv.org/abs/2508.04943)
*Zhu Xu,Ting Lei,Zhimin Li,Guan Wang,Qingchao Chen,Yuxin Peng,Yang liu*

Main category: cs.CV

TL;DR: 现有弱监督动态场景图生成(WS-DSGG)方法依赖外部目标检测器，但在动态关系感知场景中表现不佳。本文提出TRKT方法，通过关系感知知识挖掘和双流融合模块增强检测器，在Action Genome数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有WS-DSGG方法过度依赖在静态图像上训练的外部目标检测器，这些检测器在动态、关系感知的DSGG场景中表现不佳，导致目标定位不准确和候选框置信度低，因此需要解决外部检测器在WS-DSGG中的局限性。

Method: 提出了一种时间增强关系感知知识迁移（TRKT）方法。该方法包含两个关键组件：1) 关系感知知识挖掘：通过对象和关系类别解码器生成类别特定注意力图，并利用帧间注意力增强策略结合光流来增强注意力图，使其具有运动感知能力。2) 双流融合模块：将这些类别特定注意力图集成到外部检测结果中，以优化目标定位并提高候选框的置信度。

Result: TRKT方法在Action Genome数据集上取得了最先进的性能。

Conclusion: TRKT方法成功解决了WS-DSGG中外部目标检测器面临的挑战，通过有效利用关系感知和运动感知的知识来增强检测能力，显著提升了动态场景图生成的性能。

Abstract: Dynamic Scene Graph Generation (DSGG) aims to create a scene graph for each
video frame by detecting objects and predicting their relationships. Weakly
Supervised DSGG (WS-DSGG) reduces annotation workload by using an unlocalized
scene graph from a single frame per video for training. Existing WS-DSGG
methods depend on an off-the-shelf external object detector to generate pseudo
labels for subsequent DSGG training. However, detectors trained on static,
object-centric images struggle in dynamic, relation-aware scenarios required
for DSGG, leading to inaccurate localization and low-confidence proposals. To
address the challenges posed by external object detectors in WS-DSGG, we
propose a Temporal-enhanced Relation-aware Knowledge Transferring (TRKT)
method, which leverages knowledge to enhance detection in relation-aware
dynamic scenarios. TRKT is built on two key components:(1)Relation-aware
knowledge mining: we first employ object and relation class decoders that
generate category-specific attention maps to highlight both object regions and
interactive areas. Then we propose an Inter-frame Attention Augmentation
strategy that exploits optical flow for neighboring frames to enhance the
attention maps, making them motion-aware and robust to motion blur. This step
yields relation- and motion-aware knowledge mining for WS-DSGG. (2) we
introduce a Dual-stream Fusion Module that integrates category-specific
attention maps into external detections to refine object localization and boost
confidence scores for object proposals. Extensive experiments demonstrate that
TRKT achieves state-of-the-art performance on Action Genome dataset. Our code
is avaliable at https://github.com/XZPKU/TRKT.git.

</details>


### [34] [AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics](https://arxiv.org/abs/2508.04955)
*Stella Su,Marc Harary,Scott J. Rodig,William Lotter*

Main category: cs.CV

TL;DR: AdvDINO是一种领域对抗自监督学习框架，通过整合梯度反转层到DINOv2架构中，提升了标准自监督学习方法在生物医学成像中处理领域漂移的鲁棒性，并在非小细胞肺癌数据上展现出更鲁棒和有生物学意义的特征学习能力。


<details>
  <summary>Details</summary>
Motivation: 标准自监督学习方法对领域漂移（数据源间的系统性差异）的鲁棒性不确定，这在生物医学成像中尤为关键，因为批次效应会掩盖真实的生物信号。

Method: 本文提出了AdvDINO，一个领域对抗自监督学习框架。它将梯度反转层整合到DINOv2架构中，旨在促进领域不变特征的学习。

Result: AdvDINO在非小细胞肺癌患者的六通道多重免疫荧光（mIF）全玻片图像真实队列上应用，能够缓解玻片特异性偏差，学习到比非对抗基线更鲁棒、更具生物学意义的表示。在超过546万mIF图像切片上，该模型发现了具有独特蛋白质组学特征和预后意义的表型簇，并改进了基于注意力多实例学习的生存预测。

Conclusion: AdvDINO在mIF数据上得到了验证，但其广泛适用于其他成像领域（包括放射学、遥感和自动驾驶），这些领域中领域漂移和有限的标注数据阻碍了模型的泛化和可解释性。

Abstract: Self-supervised learning (SSL) has emerged as a powerful approach for
learning visual representations without manual annotations. However, the
robustness of standard SSL methods to domain shift -- systematic differences
across data sources -- remains uncertain, posing an especially critical
challenge in biomedical imaging where batch effects can obscure true biological
signals. We present AdvDINO, a domain-adversarial self-supervised learning
framework that integrates a gradient reversal layer into the DINOv2
architecture to promote domain-invariant feature learning. Applied to a
real-world cohort of six-channel multiplex immunofluorescence (mIF) whole slide
images from non-small cell lung cancer patients, AdvDINO mitigates
slide-specific biases to learn more robust and biologically meaningful
representations than non-adversarial baselines. Across $>5.46$ million mIF
image tiles, the model uncovers phenotype clusters with distinct proteomic
profiles and prognostic significance, and improves survival prediction in
attention-based multiple instance learning. While demonstrated on mIF data,
AdvDINO is broadly applicable to other imaging domains -- including radiology,
remote sensing, and autonomous driving -- where domain shift and limited
annotated data hinder model generalization and interpretability.

</details>


### [35] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: 本文提出了HOW-Seg，一个用于开放世界点云语义分割的人机协同框架，通过构建类原型并结合稀疏人工标注和迭代反馈，高效地实现基类和新类的分割。


<details>
  <summary>Details</summary>
Motivation: 现有开放世界点云语义分割（OW-Seg）方法依赖资源密集型离线增量学习或大量密集标注支持数据，限制了其实用性。为解决这些问题，亟需更高效实用的方法。

Method: HOW-Seg是首个OW-Seg人机协同框架。它直接在查询数据上构建类原型，避免支持数据和查询数据间类内分布偏移导致的偏差。利用稀疏人工标注作为指导进行原型分割。针对初始原型粒度不足，引入分层原型消歧机制来优化模糊原型。进一步，通过稠密条件随机场（CRF）优化精炼原型的标签分配。通过迭代的人机反馈，动态改进预测。

Result: 在稀疏标注下（如每个新类一次点击），HOW-Seg性能媲美或超越5-shot设置下的最先进广义小样本分割（GFS-Seg）方法。使用高级骨干网络和更密集标注时（如每个子场景10次点击），HOW-Seg在S3DIS上达到85.27% mIoU，在ScanNetv2上达到66.37% mIoU，显著优于替代方案。

Conclusion: HOW-Seg通过创新的人机协同和原型驱动方法，克服了现有开放世界点云语义分割方法的局限性，在实现高精度分割的同时，大大降低了对大量标注数据的依赖，展现了其在实际应用中的巨大潜力。

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [36] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出一个基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护。该系统结合振动数据分析与多智能体生成，提供可操作的结构化维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需及时干预以防故障并优化效率。传统异常检测无法提供可操作的维护建议，导致状态监测与实际维护规划之间存在鸿沟，需要更全面的解决方案。

Method: 该系统将轴承振动数据（BPFO, BPFI, BSF, FTF）序列化为自然语言供LLM处理，实现少样本高精度异常检测，并分类故障类型及评估严重性。一个多智能体组件通过向量嵌入和语义搜索处理维护手册，并进行网络搜索以获取全面的程序知识。最终，利用Gemini模型生成包括即时行动、检查清单、纠正措施、零件需求和时间规范的结构化维护建议。

Result: 在轴承振动数据集上的实验验证表明，该系统能有效检测异常并提供情境相关的维护指导。它成功弥合了状态监测与可操作维护规划之间的差距，为工业从业者提供了智能决策支持。

Conclusion: 该工作提升了LLM在工业维护中的应用，提供了一个可扩展的预测性维护框架，适用于各种机械组件和工业部门。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [37] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务智能体工作流的方法，通过明确的工具调用目标，提高了智能体成功率并显著降低了token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法侧重于推理分解，但对地理空间API选择的指导不足，导致智能体效率受限。

Method: GeoFlow为每个智能体提供详细的工具调用目标，以在运行时明确指导地理空间API的调用。

Result: 相比最先进的方法，GeoFlow将智能体成功率提高了6.8%，并将主要大型语言模型家族的token使用量降低了高达四倍。

Conclusion: GeoFlow通过改进智能体的工具调用机制，显著提升了其在地理空间任务中的性能和资源效率。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [38] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 本文提出一个对抗性基准框架，通过棋盘游戏评估LLM的综合性能，弥补传统问答基准的数据依赖局限。研究发现LLM在对抗环境中表现乐观适应，但技能稳定性有待提升。


<details>
  <summary>Details</summary>
Motivation: 主流基于问答（Q&A）的基准方法存在数据依赖性限制，无法全面评估大型语言模型（LLM）在策略推理和智能方面的综合性能。因此，需要一个替代方案来更好地评估LLM在对抗性环境中的表现。

Method: 研究者提出了一个对抗性基准框架，并开发了名为“棋镇（Qi Town）”的专门评估平台。该平台支持5种棋盘游戏，并有20个由LLM驱动的玩家参与。评估方法包括使用Elo评分系统和一种新颖的性能循环图（PLG）来量化LLM的技术能力，同时通过积极情绪分数（PSS）评估其心理素质。评估以循环赛的形式进行。

Result: 实验结果表明，尽管技术存在差异，大多数LLM对胜负保持乐观态度，在面对高压对抗环境时表现出比人类更强的适应性。然而，PLG中循环胜负的复杂关系暴露出LLM在游戏过程中技能发挥的不稳定性。

Conclusion: LLM在对抗性环境中表现出良好的心理韧性和适应性，但其技能发挥的稳定性仍需进一步的解释和探索。该研究提供了一种评估LLM综合性能的新颖有效方法。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [39] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 本研究比较了实现自主网络地理信息系统（AWebGIS）的三种方法，发现基于浏览器执行的微调小型语言模型（SLM）在离线客户端侧实现了最佳性能，同时解决了云端大语言模型（LLM）的隐私和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 当前AWebGIS解决方案主要依赖云端LLM，但这带来了持续互联网访问需求、用户隐私担忧以及因集中化服务器处理导致的可扩展性问题。

Method: 研究比较了三种AWebGIS实现途径：1) 基于云LLM的全自动化在线方法；2) 使用支持向量机和随机森林等传统机器学习分类器的半自动化离线方法；3) 基于微调小型语言模型（如T5-small）并在客户端浏览器执行的全自主离线方法。

Result: 基于SLM的第三种方法表现最佳，精确匹配准确率为0.93，Levenshtein相似度为0.99，ROUGE-1和ROUGE-L得分均为0.98。该客户端计算策略显著减轻了后端服务器的负载。

Conclusion: 研究结果表明，浏览器可执行模型对于AWebGIS解决方案是可行的，并能有效克服当前基于云LLM方案的局限性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [40] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: LLMs通过RL在理想条件下推理能力提升，但在非理想场景（如摘要推理、噪声抑制）下性能显著下降，表明现有方法存在局限性，需在非理想条件下评估模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）的推理能力评估多在理想设置下进行，忽视了其在现实非理想场景中的表现，而人类推理在不完美输入下仍能保持可靠。

Method: 识别并定义了摘要推理、细粒度噪声抑制和上下文过滤三种非理想场景。使用RL（策略梯度算法）微调了三款LLM和一个LVLM，并在八个公共数据集上测试了它们在这些非理想场景下的性能。

Result: 尽管RL微调在理想设置下提升了基线推理能力，但在所有三种非理想场景下，模型的性能均显著下降，暴露出高级推理能力的严重局限。作者提出的场景特定补救方法也未能根本解决这些推理缺陷。

Conclusion: 大型模型（LLMs/LVLMs）的推理能力常被夸大，当前方法在处理非理想场景下的推理问题时存在显著不足。强调了在非理想场景下评估模型性能的重要性。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [41] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一个自我进化的AI智能体，通过元级进化机制克服了现有AI代理策略固定的局限性，使其能学习更好的战略规划。在医疗数据分析任务中，HealthFlow显著优于现有框架，预示着更自主、高效的科学发现AI。


<details>
  <summary>Details</summary>
Motivation: 现有AI智能体在医疗健康研究中因依赖静态、预定义策略而受限，它们只能成为更好的工具使用者，却无法学习成为更好的战略规划者，这在复杂领域（如医疗健康）是关键缺陷。

Method: 引入HealthFlow，一个通过新颖的元级进化机制实现自我进化的AI智能体。它通过从程序性成功和失败中提取经验，自主优化其高层问题解决策略，构建持久的战略知识库。同时，引入EHRFlowBench，一个基于同行评审临床研究的、包含复杂现实健康数据分析任务的新基准进行评估。

Result: 综合实验表明，HealthFlow的自我进化方法显著优于现有最先进的AI智能体框架。

Conclusion: 这项工作标志着AI从构建更好的工具使用者转向设计更智能、自我进化的任务管理者，为更自主、高效的科学发现AI铺平了道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [42] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: LoopPlay，一种基于博弈论的新型算法，通过模拟蛋白质-配体互作用为双人博弈并采用双层循环自博弈训练，将分子对接的准确性提高了约10%。


<details>
  <summary>Details</summary>
Motivation: 现有分子对接多任务学习模型在配体对接方面表现不如蛋白质口袋对接，主要源于配体和蛋白质结构复杂度的差异。

Method: 提出一个将蛋白质-配体相互作用建模为“对接博弈”的双人博弈论框架。为解决此博弈，开发了“循环自博弈”（LoopPlay）算法，通过两级循环交替训练：外循环促进玩家间预测构象的相互适应，内循环则实现玩家对自身预测的动态修正。该算法已从理论上证明收敛。

Result: 在公共基准数据集上，LoopPlay在预测准确结合模式方面比现有最先进方法提高了约10%。

Conclusion: LoopPlay展现出显著提升药物发现中分子对接准确性的巨大潜力。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [43] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 本文探索了大型语言模型（LLMs）在集成大规模、异构、嘈杂城市空间数据集方面的应用，发现其在获得相关特征并结合“审查-改进”方法后，能有效提升空间数据集成能力，成为传统方法的有力替代。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的数据集成方法无法覆盖所有边缘情况，需要大量手动验证和修复。而机器学习方法则需要收集和标注大量的任务特定样本。因此，当前方法在处理大规模、异构、嘈杂的城市空间数据集时存在局限性，促使研究人员寻求更高效的解决方案。

Method: 研究首先分析了LLMs如何推理人类经验介导的环境空间关系。随后，通过为LLMs提供相关特征以减少其对空间推理的依赖，评估了其性能表现。最后，采用并改编了一种“审查-改进”方法，用于纠正LLMs的错误初始响应并保留准确响应。

Result: 研究发现，LLMs虽然展现出空间推理能力，但在将宏观环境与相关的计算几何任务联系起来时存在困难，常产生逻辑不连贯的响应。然而，当获得相关特征时，LLMs能够生成高性能的结果。此外，“审查-改进”方法被证明在纠正错误的初始响应同时保留准确响应方面非常有效。

Conclusion: 研究结果表明，LLMs是传统基于规则启发式方法的有前景且灵活的替代方案，能够显著提升自适应空间数据集成能力。LLMs在实际空间数据集成中具有重要的应用意义，未来研究可探索后期训练、多模态集成方法以及支持多样数据格式。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [44] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 提出一种受人类双加工理论启发的网络代理CogniWeb，通过整合快速直觉和慢速深思过程，解决了现有方法未能有效结合离线学习和在线探索的问题，在网络导航任务中实现了高效率和有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: Web导航是对AGI的严峻考验，因其高熵、动态和组合爆炸的行动空间。现有自主网络代理方法（离线模仿学习或在线探索）未能有效整合这两种范式。

Method: 受人类双加工理论启发，将认知过程分解为快速（系统1）和慢速（系统2）。实现了一个名为CogniWeb的模块化代理架构，能根据任务复杂性自适应地在直觉处理和深思推理间切换，旨在弥合离线学习和在线获取规划能力之间的差距。

Result: 在WebArena上的评估显示，CogniWeb实现了有竞争力的性能（43.96%的成功率），同时显著提高了效率（代币使用量减少75%）。

Conclusion: CogniWeb通过其创新的双加工框架，成功整合了现有网络代理的两种主要范式，在复杂网络导航中展现出高效且高性能的潜力。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [45] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出了MedMKEB，首个用于评估医学多模态大语言模型知识编辑能力的综合基准。


<details>
  <summary>Details</summary>
Motivation: 随着医疗知识不断演进，现有的多模态大语言模型（MLLMs）难以高效更新过时或错误信息。尽管文本知识编辑已有广泛研究，但缺乏针对涉及图像和文本模态的多模态医疗知识编辑的系统基准。

Method: 构建了MedMKEB基准，它基于高质量的医疗视觉问答数据集，并精心设计了反事实纠正、语义泛化、知识迁移和对抗鲁棒性等编辑任务，以评估模型知识编辑的可靠性、通用性、局部性、可移植性和鲁棒性。该基准还结合了人类专家验证以确保准确性。

Result: 通过对现有通用和医学MLLMs进行广泛的单次和序列编辑实验，揭示了当前基于知识的编辑方法在医学领域存在的局限性，强调了开发专用编辑策略的必要性。

Conclusion: MedMKEB将作为一个标准基准，促进可信赖和高效的医学知识编辑算法的发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [46] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一种基于微调Qwen3-8B模型的轻量级模拟电路门尺寸设计框架，通过动态构建损失函数和启发式搜索，实现了跨工艺节点、设计规范和电路拓扑的通用适用性，并在多项任务上超越现有框架，显著减少了设计时间和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，通用、快速、稳定的门尺寸设计方法仍是挑战。现有基于大语言模型（LLM）结合启发式搜索的方法存在模型大、跨工艺节点可移植性差的局限性，因此需要新的轻量级且通用性强的解决方案。

Method: 提出EasySize框架，首次采用微调的Qwen3-8B模型，实现轻量化。该框架利用性能指标的易实现性（EOA）动态构建任务专用损失函数，并通过全局差分进化（DE）和局部粒子群优化（PSO）的启发式搜索，结合反馈增强流程进行门尺寸设计。尽管仅使用350nm节点数据进行微调，但实现了跨节点通用性。

Result: EasySize在未经额外训练的情况下，在180nm、45nm和22nm工艺节点上的5个运算放大器（Op-Amp）网表中表现出色。它在86.67%的任务中超越了广泛使用的基于强化学习的尺寸设计框架AutoCkt，并减少了超过96.67%的仿真资源。

Conclusion: EasySize能显著降低模拟电路门尺寸设计对人工经验和计算资源的依赖，从而加速并简化模拟电路设计流程。该框架未来将开源。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [47] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 该研究通过一项对照实验，评估了苏格拉底式AI导师对学生批判性、独立和反思性思维的促进作用，发现其能显著提升学生能力。论文进一步提出了利用专家AI代理组成的多智能体系统（MAS）作为高等教育的未来教学范式，并提供了一个概念路线图。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式AI正在迅速成为高等教育的核心基础设施，本研究旨在评估对话式AI（如苏格拉底式AI导师）如何积极促进学生的高阶思维发展，并反驳关于AI使用导致技能退化的担忧。

Method: 研究对65名德国职前教师学生进行了对照实验，比较苏格拉底式AI导师（基于建构主义理论的对话模型）与非指令性AI聊天机器人在支持学生研究问题发展方面的效果。同时，提出“编排式多智能体系统（orchestrated MAS）”概念和“调整后的提供-使用模型”以构建新的教学范式。

Result: 实验结果显示，使用苏格拉底式AI导师的学生在批判性、独立性和反思性思维方面获得了显著更多支持，表明对话式AI能激发元认知参与，并挑战了生成式AI导致技能退化的论断。这些发现为采用由专业AI代理组成的多智能体系统提供了概念验证。

Conclusion: 本研究为将AI融入高等教育提供了实证证据和概念路线图，证明对话式AI能够有效促进高阶思维。它支持构建人机协同、教学对齐的混合学习生态系统，并探讨了实施此类系统所需的资金、教师角色、课程、能力和评估实践等系统层面影响，以及其成本效益和可扩展性。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [48] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 针对流程挖掘中事件日志数据缺失问题，本研究提出一种基于异构图神经网络（HGNN）的方法，旨在有效重建事件中所有缺失的属性，并在实验中表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 流程挖掘中事件日志的质量至关重要，然而在实际应用中，日志常因数据获取困难（如手动记录或属性收集不全）而导致事件信息缺失。现有追踪或日志重建方法通常依赖于流程模型或机器学习/深度学习模型，但可能无法全面修复所有缺失的事件属性。

Method: 本研究开发了一个异构图神经网络（HGNN）模型。该模型能够将流程挖掘中的复杂多模态执行轨迹表示为图结构，并在给定包含不完整事件的轨迹时，全面预测并返回这些事件中所有缺失的属性。

Result: 通过在两个合成日志和四个真实事件日志上与现有最先进的自编码器方法进行对比评估，结果显示，与主要关注修复部分事件属性的现有无模型方法不同，所提出的异构图神经网络模型在重建所有不同事件属性方面表现出非常好的性能。

Conclusion: 所提出的异构图神经网络（HGNN）模型是解决流程挖掘中事件日志全面属性缺失问题的有效方案，能够克服现有方法在重建全部事件属性方面的局限性，显著提升数据质量。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [49] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一个为知识密集型视觉问答（VQA）设计的查询感知动态RAG系统，通过结合文本和图像检索，有效解决了现有RAG方法的局限性，显著提升了复杂多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在多模态大语言模型（MLLMs）中，通常仅从文本或图像中进行单一检索，这限制了它们处理需要多跳推理或最新事实知识的复杂视觉问答（VQA）任务的能力。

Method: 本文提出QA-Dragon系统，一个查询感知动态RAG系统。它引入了一个领域路由器来识别查询主题以进行领域特定推理，并包含一个搜索路由器来动态选择最优检索策略。通过混合设置协调文本和图像搜索代理，该系统支持多模态、多轮和多跳推理。

Result: QA-Dragon在KDD Cup 2025的Meta CRAG-MM挑战赛中进行了评估，显著提升了基础模型在挑战性场景下的推理性能。它在答案准确性和知识重叠得分方面均取得了显著提升，比基线模型在单源任务上高出5.06%，在多源任务上高出6.35%，在多轮任务上高出5.03%。

Conclusion: QA-Dragon通过其创新的动态检索和多模态整合能力，有效地解决了知识密集型VQA中的复杂推理挑战，为提升MLLMs在实际应用中的性能提供了强大且有效的方法。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [50] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 一个结合RDF图数据库和LLM的框架，用于解决大型维护组织中专家识别和沟通效率低下的问题，实现精准定位与透明推理。


<details>
  <summary>Details</summary>
Motivation: 大型维护组织在识别专家和管理复杂实体关系沟通时面临信息过载、响应时间长等挑战，传统沟通方法无法有效解决。

Method: 提出一个新颖框架，结合RDF图数据库和LLMs，通过规划-编排架构处理自然语言查询，实现精准受众定位并提供透明推理。

Result: 该方案使用户能够通过直观查询（结合设备、制造商、工程师等概念）获得可解释的结果。

Conclusion: 该框架能维护系统信任，并显著提高组织内部的沟通效率。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
*Shruti Saxena,Arijit Khan,Joydeep Chandra*

Main category: cs.LG

TL;DR: NAEx是一个即插即用、模型无关的框架，旨在通过识别关键子图和特征来解释网络对齐模型，以提高决策的可理解性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的网络对齐模型解释性有限，难以理解对齐决策，尤其在高风险领域影响信任建立。

Method: 引入NAEx框架，通过识别影响预测的关键子图和特征来解释对齐模型。它通过以下方式处理跨网络依赖性：1) 通过可学习的边和特征掩码联合参数化图结构和特征空间；2) 引入优化目标，确保解释忠实于原始预测，并能有效比较结构和基于特征的相似性。NAEx是一个归纳式框架。

Result: 在基准数据集上，NAEx与四种代表性NA模型集成后，证明了其有效性和效率。同时引入了专门针对对齐解释性的评估指标。

Conclusion: NAEx成功提高了网络对齐模型的解释性，解决了高风险领域建立信任的关键挑战，并展示了其有效性和高效性。

Abstract: Network alignment (NA) identifies corresponding nodes across multiple
networks, with applications in domains like social networks, co-authorship, and
biology. Despite advances in alignment models, their interpretability remains
limited, making it difficult to understand alignment decisions and posing
challenges in building trust, particularly in high-stakes domains. To address
this, we introduce NAEx, a plug-and-play, model-agnostic framework that
explains alignment models by identifying key subgraphs and features influencing
predictions. NAEx addresses the key challenge of preserving the joint
cross-network dependencies on alignment decisions by: (1) jointly
parameterizing graph structures and feature spaces through learnable edge and
feature masks, and (2) introducing an optimization objective that ensures
explanations are both faithful to the original predictions and enable
meaningful comparisons of structural and feature-based similarities between
networks. NAEx is an inductive framework that efficiently generates NA
explanations for previously unseen data. We introduce evaluation metrics
tailored to alignment explainability and demonstrate NAEx's effectiveness and
efficiency on benchmark datasets by integrating it with four representative NA
models.

</details>


### [52] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: 提出LumiGen，一个LVLM增强的迭代框架，通过闭环反馈机制显著提升文本到图像（T2I）生成在精细控制、文本渲染和姿态表达方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型驱动的T2I生成在处理复杂指令、精细内容控制和语义一致性方面仍面临挑战，尤其是在准确文本渲染、精确姿态生成和复杂构图连贯性上表现不足。

Method: 提出了LumiGen框架，该框架是一个LVLM增强的迭代系统，通过闭环的LVLM驱动反馈机制提升T2I模型性能。它包含智能提示词解析与增强（IPPA）模块用于主动优化提示词，以及迭代视觉反馈与细化（IVFR）模块充当“视觉评论家”以迭代修正和优化生成图像。

Result: LumiGen在LongBench-T2I基准测试中取得了3.08的卓越平均分，优于现有最先进的基线模型，并在文本渲染和姿态表达等关键维度上展现出显著改进。

Conclusion: LVLM的集成被证明能有效提升T2I模型的控制能力和生成质量，特别是在需要精细控制的方面。

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [53] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: MissMecha是一个开源Python工具包，用于在MCAR、MAR和MNAR假设下，模拟、可视化和评估异构表格数据（包含数值和分类特征）中的缺失数据。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集中的数据不完整是一个持续存在的挑战，现有工具在模拟缺失数据方面存在碎片化、机制受限且仅关注数值变量的问题，无法处理异构表格数据的复杂性。

Method: 开发了MissMecha，一个支持MCAR、MAR和MNAR假设的开源Python工具包。它能够模拟、可视化和评估缺失数据，并支持数值和分类特征。工具包含可视化诊断、MCAR测试工具和类型感知的插补评估指标。

Result: MissMecha能够对混合类型表格数据集进行机制感知的缺失数据研究，为处理不完整数据的研究人员和实践者提供了一个统一的平台。

Conclusion: MissMecha旨在支持数据质量研究、基准测试和教育，为处理不完整数据的研究人员和从业人员提供一个统一的平台。

Abstract: Incomplete data is a persistent challenge in real-world datasets, often
governed by complex and unobservable missing mechanisms. Simulating missingness
has become a standard approach for understanding its impact on learning and
analysis. However, existing tools are fragmented, mechanism-limited, and
typically focus only on numerical variables, overlooking the heterogeneous
nature of real-world tabular data. We present MissMecha, an open-source Python
toolkit for simulating, visualizing, and evaluating missing data under MCAR,
MAR, and MNAR assumptions. MissMecha supports both numerical and categorical
features, enabling mechanism-aware studies across mixed-type tabular datasets.
It includes visual diagnostics, MCAR testing utilities, and type-aware
imputation evaluation metrics. Designed to support data quality research,
benchmarking, and education,MissMecha offers a unified platform for researchers
and practitioners working with incomplete data.

</details>


### [54] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
*Nan Li,Wanting Yang,Marie Siew,Zehui Xiong,Binbin Chen,Shiwen Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: 针对扩散模型在边缘设备上的计算和隐私挑战，本文提出了一个基于LoRA的集群感知分层联邦聚合框架，以实现高效、可扩展、个性化且隐私保护的边缘AIGC服务。


<details>
  <summary>Details</summary>
Motivation: 扩散模型计算密集，不适用于资源受限的边缘设备。现有云解决方案在多用户边缘AIGC场景中，无法有效解决隐私、个性化效率和通信成本问题。当前边缘AIGC应用在效率和可扩展性方面也存在局限。

Method: 提出了一种新颖的集群感知分层联邦聚合框架。该框架利用LoRA进行参数高效的本地微调；首先根据任务需求相似性对客户端进行聚类，然后进行簇内聚合以增强个性化。随后，通过簇间知识交互实现混合风格内容生成。通过联邦学习协作，同时训练用户本地个性化模型和服务器端带有多个LoRA适配器的共享全局模型。所有用于聚类和推理的提示在传输前进行编码，以进一步缓解明文泄露风险。

Result: 该框架实现了加速收敛，并在边缘约束下，为可扩展的多用户个性化AIGC服务保持了实用性。同时实现了高效的边缘推理并缓解了明文泄露的风险。

Conclusion: 所提出的框架成功克服了在边缘设备上部署扩散模型的挑战，为多用户AIGC服务提供了一个可扩展、个性化、高效且隐私保护的解决方案。

Abstract: Diffusion models (DMs) have emerged as powerful tools for high-quality
content generation, yet their intensive computational requirements for
inference pose challenges for resource-constrained edge devices. Cloud-based
solutions aid in computation but often fall short in addressing privacy risks,
personalization efficiency, and communication costs in multi-user edge-AIGC
scenarios. To bridge this gap, we first analyze existing edge-AIGC applications
in personalized content synthesis, revealing their limitations in efficiency
and scalability. We then propose a novel cluster-aware hierarchical federated
aggregation framework. Based on parameter-efficient local fine-tuning via
Low-Rank Adaptation (LoRA), the framework first clusters clients based on the
similarity of their uploaded task requirements, followed by an intra-cluster
aggregation for enhanced personalization at the server-side. Subsequently, an
inter-cluster knowledge interaction paradigm is implemented to enable
hybrid-style content generation across diverse clusters.Building upon federated
learning (FL) collaboration, our framework simultaneously trains personalized
models for individual users at the devices and a shared global model enhanced
with multiple LoRA adapters on the server,enabling efficient edge inference;
meanwhile, all prompts for clustering and inference are encoded prior to
transmission, thereby further mitigating the risk of plaintext leakage. Our
evaluations demonstrate that the framework achieves accelerated convergence
while maintaining practical viability for scalable multi-user personalized AIGC
services under edge constraints.

</details>


### [55] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
*Pengtao Dang,Tingbo Guo,Sha Cao,Chi Zhang*

Main category: cs.LG

TL;DR: 该研究提出并验证了一个大型多模态模型（LMMM），通过在多领域任务上训练，能显著提升少样本学习（FSL）在数据稀缺科学领域的泛化能力，并为此构建了M3FD数据集和M3F框架。


<details>
  <summary>Details</summary>
Motivation: 少样本学习（FSL）在生物医学、环境、材料和机械科学等领域至关重要，因为这些领域的样本有限，数据收集成本高昂、耗时或受伦理限制。传统的FSL方法可能无法充分解决这些挑战，需要更高效、泛化能力更强的模型。

Method: 研究提出了一种创新的FSL方法，证明了在多样化领域、任务类型和输入模态的独立任务上训练的大型多模态模型（LMMM）可以显著提高FSL模型的泛化能力。为此，他们：1) 构建了一个包含2D RGB图像、2D/3D医学扫描、表格和时间序列数据集的Multi-Modal Model Few-shot Dataset (M3FD，超过1万个少样本)。2) 引入了Multi-Modal Model for Few-shot learning framework (M3F)，一个专门为数据受限科学应用定制的模块化LMMM框架。3) 通过在M3FD上微调M3F，提高了模型性能。4) 为M3FD提供了用户友好的查询、任务特定采样和预处理工具。

Result: 通过在M3FD上微调，M3F显著提升了模型性能，使其在现实世界的FSL部署中成为可行方案。该LMMM在同类型任务上，表现优于基于传统元学习的模型。

Conclusion: 研究成果提供了一个统一、可扩展的解决方案，显著降低了在数据稀缺的科学领域应用LMMMs的门槛，促进了FSL在这些领域的实际部署和应用，并为复杂FSL数据的获取和研究可复现性提供了支持。

Abstract: Few-shot learning (FSL) is a machine learning paradigm that aims to
generalize models from a small number of labeled examples, typically fewer than
10 per class. FSL is particularly crucial in biomedical, environmental,
materials, and mechanical sciences, where samples are limited and data
collection is often prohibitively costly, time-consuming, or ethically
constrained. In this study, we present an innovative approach to FSL by
demonstrating that a Large Multi-Modal Model (LMMM), trained on a set of
independent tasks spanning diverse domains, task types, and input modalities,
can substantially improve the generalization of FSL models, outperforming
models based on conventional meta-learning on tasks of the same type. To
support this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,
over 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,
tabular and time-course datasets, from which we manually curated FSL tasks such
as classification. We further introduced M3F (Multi-Modal Model for Few-shot
learning framework), a novel Large Multi-Modal Model framework tailored for
data-constrained scientific applications. M3F supports a wide range of
scientific data types through a modular pipeline. By fine-tuning the model on
M3FD, M3F improves model performance, making LMMM feasible for real-world FSL
deployment. The source code is located at https://github.com/ptdang1001/M3F. To
democratize access to complex FSL data and promote reproducibility for public
usage, M3FD is paired with a flexible and user-friendly tool that enables
efficient querying, task-specific sampling, and preprocessing. Together, our
dataset and framework offer a unified, scalable solution that significantly
lowers the barrier to applying LMMMs in data-scarce scientific domains.

</details>


### [56] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: 本文提出AttriLens-Mol，一个属性引导的强化学习框架，用于优化LLM在分子性质预测中的推理过程，有效提升预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在分子性质预测中展现潜力，但它们通常依赖人工设计的提示，且现有推理模型（如DeepSeek-R1）的推理过程可能冗长且缺乏相关性。

Method: 引入AttriLens-Mol框架，通过引入三种奖励机制来引导模型的推理：1) 格式奖励，鼓励基于属性的结构化输出；2) 计数奖励，避免列举无关属性；3) 合理性奖励，利用高级LLMs和RDKit验证生成属性的相关性。该方法旨在隐式地激发模型关于相关分子属性的内在知识。

Result: 实验结果表明，AttriLens-Mol显著提升了7B模型（R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1）在内分布和外分布数据集上的性能，取得了与现有监督微调模型及高级LLMs（如GPT-4o、DeepSeek-R1）相当或更优的结果。此外，通过该方法提取的属性作为可解释决策树模型的特征时，相比于通过提示LLM生成的属性，表现出更优的性能和更强的可解释性。

Conclusion: AttriLens-Mol通过属性引导的强化学习，有效地解决了LLMs在分子性质预测中推理冗余和不相关的问题，能够激发更相关和具预测性的分子属性，从而显著提升了预测性能和可解释性。

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [57] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.LG

TL;DR: 提出PA-RNet，一个鲁棒的多模态时间序列预测框架，旨在解决文本模态中常见的噪声干扰问题，并通过噪声分离和跨模态注意力机制提升模型性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，多模态时间序列数据，特别是文本模态，常受到干扰。现有方法忽视文本数据中固有的扰动（如无关、嘈杂、模糊内容），这些扰动会严重降低模型性能，尤其当噪声强度变化或源于结构不一致时。

Method: 提出PA-RNet（Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting）框架。该框架包含一个扰动感知投影模块和跨模态注意力机制，旨在有效分离文本嵌入中的噪声，同时保持语义信息。理论上，证明了PA-RNet对文本输入的Lipschitz连续性，并证明所提出的扰动模块可以降低预期预测误差。此外，引入了一个文本扰动管道，用于系统评估模型在不同文本噪声水平下的鲁棒性。

Result: 在不同领域和时间设置下的大量实验表明，PA-RNet始终优于现有最先进的基线方法。

Conclusion: PA-RNet有效解决了多模态时间序列预测中文本模态的噪声问题，通过其创新的噪声分离机制，显著提升了模型的泛化能力、预测性能和在噪声条件下的稳定性。

Abstract: In real-world applications, multimodal time series data often suffer from
interference, especially in the textual modality. Existing methods for
multimodal time series forecasting often neglect the inherent perturbations
within textual data, where irrelevant, noisy, or ambiguous content can
significantly degrade model performance, particularly when the noise exhibits
varying intensity or stems from structural inconsistencies. To address this
challenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for
Multimodal Time Series Forecasting), a robust multimodal forecasting framework.
PA-RNet features a perturbation-aware projection module and a cross-modal
attention mechanism to effectively separate noise from the textual embeddings
while maintaining semantically meaningful representations, thereby enhancing
the model's generalization ability. Theoretically, we establish the Lipschitz
continuity of PA-RNet with respect to textual inputs and prove that the
proposed perturbation module can reduce expected prediction error, offering
strong guarantees of stability under noisy conditions. Furthermore, we
introduce a textual perturbation pipeline that can be seamlessly incorporated
into existing multimodal time series forecasting tasks, allowing for systematic
evaluation of the model's robustness in the presence of varying levels of
textual noise. Extensive experiments across diverse domains and temporal
settings demonstrate that PA-RNet consistently outperforms state-of-the-art
baselines.

</details>


### [58] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
*Mehmet Emre Akbulut,Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Manuel Roveri*

Main category: cs.LG

TL;DR: InfoQ是一种训练无关的混合精度量化方法，通过评估量化对网络信息流的影响来分配位宽，显著提高搜索效率并提升量化模型的精度。


<details>
  <summary>Details</summary>
Motivation: 混合精度量化对资源受限设备部署深度神经网络至关重要，但寻找最优位宽是复杂的组合优化问题。现有方法计算成本高昂，或因依赖局部属性而无法捕捉量化误差的全局级联效应。

Method: InfoQ提出了一种训练无关的位宽搜索框架。它通过量化不同位宽的层，并通过单次前向传播测量后续层互信息的变化，以量化每层量化对网络信息流的影响。这些敏感度分数被用于构建整数线性规划问题，在给定预算下高效地最小化总敏感度，从而分配位宽。

Result: InfoQ的搜索阶段无需再训练，提供了优越的搜索时间/精度权衡（所需数据量比SOTA方法LIMPQ少两个数量级）。在ImageNet数据集上，MobileNetV2和ResNet18在实现高压缩率（14X和10.66X）的同时，精度提高了高达1%。

Conclusion: InfoQ通过关注量化对全局信息流的影响，提供了一种高效、精确且训练无关的混合精度量化解决方案，显著提升了模型在资源受限设备上的部署性能。

Abstract: Mixed-precision quantization (MPQ) is crucial for deploying deep neural
networks on resource-constrained devices, but finding the optimal bit-width for
each layer represents a complex combinatorial optimization problem. Current
state-of-the-art methods rely on computationally expensive search algorithms or
local sensitivity heuristic proxies like the Hessian, which fail to capture the
cascading global effects of quantization error. In this work, we argue that the
quantization sensitivity of a layer should not be measured by its local
properties, but by its impact on the information flow throughout the entire
network. We introduce InfoQ, a novel framework for MPQ that is training-free in
the bit-width search phase. InfoQ assesses layer sensitivity by quantizing each
layer at different bit-widths and measuring, through a single forward pass, the
resulting change in mutual information in the subsequent layers. This
quantifies how much each layer quantization impacts the network information
flow. The resulting scores are used to formulate bit-width allocation as an
integer linear programming problem, which is solved efficiently to minimize
total sensitivity under a given budget (e.g., model size or BitOps). Our
retraining-free search phase provides a superior search-time/accuracy trade-off
(using two orders of magnitude less data compared to state-of-the-art methods
such as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2
and ResNet18 on ImageNet at high compression rates (14X and 10.66X).

</details>


### [59] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
*Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: 本研究评估了开源大语言模型（LLMs）作为动态胰岛素给药代理在模拟器中的零样本推理能力，并与强化学习（RL）代理进行了比较。结果显示，LLMs在稳定患者队列中表现良好，但存在局限性（如幻觉和逻辑不一致），强调了精准提示工程和混合方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 基于强化学习（RL）的动态治疗方案在临床应用中面临复杂的工程需求和患者安全保障的挑战。大语言模型（LLMs）因其能通过语言提示自然地嵌入隐式先验知识和临床启发式，无需环境特定训练，有望提供一种互补的解决方案。

Method: 研究在一个一型糖尿病（Type 1 diabetes）体内模拟器中，严格评估了开源LLMs（如Qwen2.5-7B）作为动态胰岛素给药代理的零样本推理性能。研究将LLMs的表现与经过专门训练的小型神经网络强化学习代理（SRAs）进行了比较。同时，探究了链式思考（CoT）推理以及对潜在临床状态的明确推理对LLMs性能的影响。

Result: 精心设计的零样本提示使小型LLMs在稳定患者队列中实现了与经过广泛训练的SRAs相当甚至更优的临床性能。然而，LLMs也表现出显著局限性，特别是在引入链式思考（CoT）推理时，导致胰岛素给药过于激进，并出现算术幻觉、时间误解和临床逻辑不一致等关键故障模式。此外，纳入对潜在临床状态的明确推理获得的性能增益微乎其微，表明当前模型在仅通过文本推理捕捉复杂隐藏生理动态方面存在局限。

Conclusion: 研究结果倡导将LLMs谨慎而乐观地整合到临床工作流程中。强调了有针对性的提示工程、仔细的验证以及可能结合语言推理与结构化生理建模的混合方法，对于实现安全、稳健和临床有效的决策支持系统至关重要。

Abstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold
promise for automating complex clinical decision-making, yet their practical
deployment remains hindered by the intensive engineering required to inject
clinical knowledge and ensure patient safety. Recent advancements in large
language models (LLMs) suggest a complementary approach, where implicit prior
knowledge and clinical heuristics are naturally embedded through linguistic
prompts without requiring environment-specific training. In this study, we
rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in
silico Type 1 diabetes simulator, comparing their zero-shot inference
performance against small neural network-based RL agents (SRAs) explicitly
trained for the task. Our results indicate that carefully designed zero-shot
prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or
superior clinical performance relative to extensively trained SRAs,
particularly in stable patient cohorts. However, LLMs exhibit notable
limitations, such as overly aggressive insulin dosing when prompted with
chain-of-thought (CoT) reasoning, highlighting critical failure modes including
arithmetic hallucination, temporal misinterpretation, and inconsistent clinical
logic. Incorporating explicit reasoning about latent clinical states (e.g.,
meals) yielded minimal performance gains, underscoring the current model's
limitations in capturing complex, hidden physiological dynamics solely through
textual inference. Our findings advocate for cautious yet optimistic
integration of LLMs into clinical workflows, emphasising the necessity of
targeted prompt engineering, careful validation, and potentially hybrid
approaches that combine linguistic reasoning with structured physiological
modelling to achieve safe, robust, and clinically effective decision-support
systems.

</details>


### [60] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 针对现有电力恢复决策因社区报修量差异导致不公平的问题，本文提出一个名为EPOPR的AI框架，通过融合不确定性预测和自适应强化学习，显著提高了电力恢复的效率并降低了社区间的不公平性。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件频发，凸显了高效公平电力系统恢复的紧迫性。现有基于报修量的方法因弱势社区报修量少而导致不公平，使他们遭受更长的停电。研究旨在提出一种兼顾效率与公平的电力恢复策略，并应对修复时长预测的异方差性及强化学习决策可能损害公平性的挑战。

Method: 设计了一个名为EPOPR的“预测-优化”框架，包含两个关键组件：1) 公平化保形分位数回归（Equity-Conformalized Quantile Regression），用于不确定性感知的修复时长预测；2) 时空注意力强化学习（Spatial-Temporal Attentional RL），用于适应不同区域的不确定性水平，以实现公平的决策。

Result: 实验结果显示，与现有最佳基线相比，EPOPR将平均停电时长减少了3.60%，并将不同社区之间的不公平性降低了14.19%。

Conclusion: EPOPR框架有效解决了电力系统恢复中的效率和公平性问题，为实现公平且高效的电力恢复提供了可靠的解决方案，尤其在处理预测不确定性和平衡效率与公平方面表现出色。

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [61] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu*

Main category: cs.LG

TL;DR: 提出联邦持续推荐(FCRec)新任务，并设计F3CRec框架，结合客户端自适应回放内存和服务器端项目级时间均值，以在联邦环境中长期维持推荐质量，同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐(FedRec)系统难以应对非静态数据流导致推荐质量随时间下降；持续学习推荐(CLRec)虽能处理偏好演变但需集中数据，与联邦学习的隐私保护目标冲突。因此，需要一种能在保护隐私的同时适应数据流变化的联邦持续推荐方法。

Method: 提出F3CRec框架以解决FCRec任务，旨在平衡知识保留与适应性。核心组件包括：1. 客户端：自适应回放内存，根据用户特有变化选择性保留过去偏好。2. 服务器端：项目级时间均值，在整合新知识的同时保留原有信息。

Result: 大量实验证明，F3CRec在联邦环境中维护推荐质量方面显著优于现有方法。

Conclusion: F3CRec成功将联邦学习的隐私保护与持续学习适应数据流的能力结合，有效解决了联邦持续推荐的挑战，在保护隐私的前提下实现了长期稳定的推荐质量。

Abstract: The increasing emphasis on privacy in recommendation systems has led to the
adoption of Federated Learning (FL) as a privacy-preserving solution, enabling
collaborative training without sharing user data. While Federated
Recommendation (FedRec) effectively protects privacy, existing methods struggle
with non-stationary data streams, failing to maintain consistent recommendation
quality over time. On the other hand, Continual Learning Recommendation (CLRec)
methods address evolving user preferences but typically assume centralized data
access, making them incompatible with FL constraints. To bridge this gap, we
introduce Federated Continual Recommendation (FCRec), a novel task that
integrates FedRec and CLRec, requiring models to learn from streaming data
while preserving privacy. As a solution, we propose F3CRec, a framework
designed to balance knowledge retention and adaptation under the strict
constraints of FCRec. F3CRec introduces two key components: Adaptive Replay
Memory on the client side, which selectively retains past preferences based on
user-specific shifts, and Item-wise Temporal Mean on the server side, which
integrates new knowledge while preserving prior information. Extensive
experiments demonstrate that F3CRec outperforms existing approaches in
maintaining recommendation quality over time in a federated environment.

</details>


### [62] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
*Lin Jiang,Yu Yang,Guang Wang*

Main category: cs.LG

TL;DR: 本文提出一个基于多智能体强化学习的以人为中心网约车派单系统HCRide，在不牺牲整体效率的前提下，显著提升了乘客公平性和司机偏好。


<details>
  <summary>Details</summary>
Motivation: 现有网约车派单系统多侧重于运营商收入，可能导致乘客和司机体验不佳。本研究旨在设计一个在考虑乘客公平性和司机偏好的同时，不损害整体系统效率的以人为中心的网约车系统。

Method: 为解决乘客公平性与司机偏好之间的潜在冲突，本文设计了HCRide系统。该系统基于一种新颖的多智能体强化学习算法Habic (Harmonization-oriented Actor-Bi-Critic)，包含多智能体竞争机制、动态Actor网络和Bi-Critic网络，以优化系统效率并兼顾乘客公平性和司机偏好。

Result: 使用深圳和纽约市的真实网约车数据集进行广泛评估。实验结果表明，与现有先进基线相比，HCRide有效提升了系统效率2.02%、公平性5.39%以及司机偏好10.21%。

Conclusion: HCRide成功解决了网约车派单中效率与公平/偏好之间的平衡难题，实现了以人为本的设计理念，显著提升了多项关键指标，证明了其在实际应用中的有效性。

Abstract: Order dispatch systems play a vital role in ride-hailing services, which
directly influence operator revenue, driver profit, and passenger experience.
Most existing work focuses on improving system efficiency in terms of operator
revenue, which may cause a bad experience for both passengers and drivers.
Hence, in this work, we aim to design a human-centered ride-hailing system by
considering both passenger fairness and driver preference without compromising
the overall system efficiency. However, it is nontrivial to achieve this target
due to the potential conflicts between passenger fairness and driver preference
since optimizing one may sacrifice the other. To address this challenge, we
design HCRide, a Human-Centered Ride-hailing system based on a novel
multi-agent reinforcement learning algorithm called Harmonization-oriented
Actor-Bi-Critic (Habic), which includes three major components (i.e., a
multi-agent competition mechanism, a dynamic Actor network, and a Bi-Critic
network) to optimize system efficiency and passenger fairness with driver
preference consideration. We extensively evaluate our HCRide using two
real-world ride-hailing datasets from Shenzhen and New York City. Experimental
results show our HCRide effectively improves system efficiency by 2.02%,
fairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art
baselines.

</details>


### [63] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: 提出统一流匹配框架，实现对长序列带标记事件的非自回归联合建模，显著提升预测精度和生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络时间点过程模型多为自回归式，预测长序列带标记事件时效率低下且易累积误差，是实际应用中的一大挑战。

Method: 提出一种统一的流匹配框架，通过连续和离散流匹配，实现对带标记时间点过程的非自回归、事件间隔时间和事件类型联合建模。该方法通过学习连续时间流，无需顺序解码即可生成连贯的长序列事件轨迹。

Result: 在六个真实世界基准测试中，模型在准确性和生成效率方面均显著优于自回归和基于扩散的基线模型。

Conclusion: 本研究提出的流匹配框架有效解决了长序列带标记事件建模中效率低和误差累积的问题，为相关应用提供了更优的解决方案。

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [64] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
*Robert Frenken,Sidra Ghayour Bhatti,Hanqin Zhang,Qadeer Ahmed*

Main category: cs.LG

TL;DR: 本文提出了一种多阶段CAN总线入侵检测框架，结合无监督变分图自编码器(VGAE)进行异常检测和监督知识蒸馏图注意力网络(KD-GAT)进行分类，有效处理数据不平衡，并显著提升了F1-score和效率。


<details>
  <summary>Details</summary>
Motivation: 控制器局域网(CAN)协议是车载通信标准，但因缺乏内置安全机制而易受网络攻击。现有方法在处理CAN流量入侵检测时，尤其在数据不平衡场景下性能不足。

Method: 研究构建了一个多阶段入侵检测框架。该框架将CAN总线活动编码为图序列以捕捉时序和关系依赖。它利用VGAE进行基于选择性欠采样的结构异常检测和类别不平衡处理，随后通过KD-GAT进行鲁棒攻击分类。所用的学生GAT模型实现了大幅参数压缩。

Result: 实验在六个公共CAN入侵数据集上进行，结果显示该框架在准确性和效率方面具有竞争力。与现有方法相比，平均F1-score提高了16.2%，在高度不平衡数据集上F1-score甚至提升了高达55%。此外，学生GAT模型在保持高性能的同时，参数量减少了96%。

Conclusion: 该多阶段入侵检测框架为CAN总线提供了一个鲁棒且高效的安全解决方案，特别擅长处理高度不平衡的数据集，显著提升了车载网络安全防御能力。

Abstract: The Controller Area Network (CAN) protocol is a standard for in-vehicle
communication but remains susceptible to cyber-attacks due to its lack of
built-in security. This paper presents a multi-stage intrusion detection
framework leveraging unsupervised anomaly detection and supervised graph
learning tailored for automotive CAN traffic. Our architecture combines a
Variational Graph Autoencoder (VGAE) for structural anomaly detection with a
Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack
classification. CAN bus activity is encoded as graph sequences to model
temporal and relational dependencies. The pipeline applies VGAE-based selective
undersampling to address class imbalance, followed by GAT classification with
optional score-level fusion. The compact student GAT achieves 96% parameter
reduction compared to the teacher model while maintaining strong predictive
performance. Experiments on six public CAN intrusion datasets--Car-Hacking,
Car-Survival, and can-train-and-test--demonstrate competitive accuracy and
efficiency, with average improvements of 16.2% in F1-score over existing
methods, particularly excelling on highly imbalanced datasets with up to 55%
F1-score improvements.

</details>


### [65] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
*Haoyu Zhang,Shihao Zhang,Ian Colbert,Rayan Saab*

Main category: cs.LG

TL;DR: 本研究首次为OPTQ/GPTQ和Qronos等流行的训练后量化（PTQ）算法提供了严格的量化误差理论边界。


<details>
  <summary>Details</summary>
Motivation: 训练后量化（PTQ）是降低大型深度神经网络成本的关键工具，其中OPTQ（又称GPTQ）因其高效和高性能而广受欢迎。然而，OPTQ缺乏严格的定量理论保证，阻碍了对其工作原理的深入理解和优化。

Method: 通过分析OPTQ的迭代过程，推导了依赖于校准数据和正则化参数的非渐近2-范数误差边界；为OPTQ的随机变体建立了更强的无穷范数误差边界；并将分析扩展到最新的PTQ算法Qronos。

Result: 首次为OPTQ（确定性和随机变体）以及Qronos（确定性和随机变体）提供了定量误差边界。这些边界为按范数递减排序特征等实际设计选择提供了理论依据，并指导了正则化参数的选择。随机变体的无穷范数误差边界对下游层和非线性激活尤其有用，并有助于解释Qronos的经验优势。

Conclusion: 本研究为广泛采用的训练后量化算法提供了坚实的理论基础和定量误差保证，不仅验证了现有实践，也为未来算法的设计和参数选择提供了重要指导。

Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the
memory and compute costs of modern deep neural networks, including large
language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as
GPTQ-has emerged as a leading method due to its computational efficiency and
strong empirical performance. Despite its widespread adoption, however, OPTQ
lacks rigorous quantitative theoretical guarantees. This paper presents the
first quantitative error bounds for both deterministic and stochastic variants
of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ
algorithm. We analyze how OPTQ's iterative procedure induces quantization error
and derive non-asymptotic 2-norm error bounds that depend explicitly on the
calibration data and a regularization parameter that OPTQ uses. Our analysis
provides theoretical justification for several practical design choices,
including the widely used heuristic of ordering features by decreasing norm, as
well as guidance for selecting the regularization parameter. For the stochastic
variant, we establish stronger infinity-norm error bounds, which enable control
over the required quantization alphabet and are particularly useful for
downstream layers and nonlinearities. Finally, we extend our analysis to
Qronos, providing new theoretical bounds, for both its deterministic and
stochastic variants, that help explain its empirical advantages.

</details>


### [66] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
*Aleksander Boruch-Gruszecki,Yangtian Zi,Zixuan Wu,Tejas Oberoi,Carolyn Jane Anderson,Joydeep Biswas,Arjun Guha*

Main category: cs.LG

TL;DR: 本文提出了Agnostics，一个语言无关的后训练流程，旨在提升大型语言模型在低资源编程语言上的代码生成能力，通过统一的外部行为验证和强化学习实现，并在多个低资源语言上取得了显著的性能提升和新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在Python、JavaScript等高资源语言的代码编写方面表现出色，但在Lua、Julia、R、OCaml和Fortran等对科学工程至关重要的低资源语言上却表现不佳。这不仅因为预训练数据缺乏，还因为后训练面临瓶颈，即每种新语言都需要新的数据集、测试工具和强化学习基础设施。

Method: 引入Agnostics，一个语言无关的后训练流程，其核心思想是仅通过代码的外部可观察行为来判断其正确性，从而允许单一验证器测试任何语言的解决方案。具体方法包括：1) 使用LLM将现有单元测试数据集重写为I/O格式；2) 提供一个简短的配置以指导验证器编译和运行目标语言；3) 在鲁棒的代码执行环境中应用可验证奖励的强化学习（RLVR）。

Result: 将Agnostics应用于Lua、Julia、R、OCaml和Fortran这五种低资源语言，取得了以下成果：1) 将Qwen-3 4B模型的性能提升至可与16B-70B量级的开源模型媲美的水平；2) 能够良好地扩展到更大、更多样的模型系列（如Qwen-3 8B、DeepSeek Coder 6.7B Instruct、Phi 4 Mini）；3) 对于参数量不超过16B的模型，在MultiPL-E和新引入的多语言LiveCodeBench上，达到了新的pass@1最佳结果（State-of-the-Art）。

Conclusion: Agnostics成功解决了LLMs在低资源编程语言代码生成方面的挑战，通过其语言无关的后训练流程，显著提升了模型性能。研究团队将发布相关的语言无关训练数据集、训练代码和即用配置，从而使任何编程语言的强化学习后训练变得简单易行，仅需编辑一个简短的YAML文件即可。

Abstract: Large language models (LLMs) already excel at writing code in high-resource
languages such as Python and JavaScript, yet stumble on low-resource languages
that remain essential to science and engineering. Besides the obvious shortage
of pre-training data, post-training itself is a bottleneck: every new language
seems to require new datasets, test harnesses, and reinforcement-learning (RL)
infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that
eliminates this per-language engineering. The key idea is to judge code solely
by its externally observable behavior, so a single verifier can test solutions
written in any language. Concretely, we (i) use an LLM to rewrite existing
unit-test datasets into an I/O format, (ii) supply a short configuration that
tells the verifier how to compile and run a target language, and (iii) apply
reinforcement learning with verifiable rewards (RLVR) in a robust code
execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and
Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other
16B-70B open-weight models; (2) scales cleanly to larger and diverse model
families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for
${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on
MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X,
Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use
configurations, making RL post-training in any programming language as simple
as editing a short YAML file.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [67] [TeraRIS NOMA-MIMO Communications for 6G and Beyond Industrial Networks](https://arxiv.org/abs/2508.05130)
*Ali Raza,Muhammad Farhan Khan,Zeeshan Alam,Muhammad Saad,Ilyas Saleem,Muhammad Ahmed Mohsin,Muhammad Ali Jamshed*

Main category: cs.NI

TL;DR: 该论文提出了一个结合RIS、THz通信和NOMA的联合框架，旨在提升智能工业通信，并通过优化功率分配策略，显著提高了和速率，并验证了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为满足未来6G及以上网络中工业自动化和实时通信的关键需求，即提高频谱效率、覆盖范围和可靠性，从而增强智能工业通信。

Method: 本文提出了一个集成可重构智能表面（RIS）、太赫兹（THz）通信和非正交多址（NOMA）的联合框架。在该框架下，研究了两种功率分配策略：一种优化近端和远端工业节点间的功率分配；另一种优先考虑网络需求。通过仿真评估了和速率和中断概率，并与固定功率分配方案进行了对比。

Result: 所提出的方案在30 dBm功率下，相比固定功率分配方案，总和速率增益高达23%。仿真结果验证了理论分析。

Conclusion: RIS辅助的NOMA MIMO框架对于太赫兹使能的工业通信是有效且鲁棒的。

Abstract: This paper presents a joint framework that integrates reconfigurable
intelligent surfaces (RISs) with Terahertz (THz) communications and
non-orthogonal multiple access (NOMA) to enhance smart industrial
communications. The proposed system leverages the advantages of RIS and THz
bands to improve spectral efficiency, coverage, and reliability key
requirements for industrial automation and real-time communications in future
6G networks and beyond. Within this framework, two power allocation strategies
are investigated: the first optimally distributes power between near and far
industrial nodes, and the second prioritizes network demands to enhance system
performance further. A performance evaluation is conducted to compare the sum
rate and outage probability against a fixed power allocation scheme. Our scheme
achieves up to a 23% sum rate gain over fixed PA at 30 dBm. Simulation results
validate the theoretical analysis, demonstrating the effectiveness and
robustness of the RIS-assisted NOMA MIMO framework for THz enabled industrial
communications.

</details>


### [68] [Modular Design and Experimental Evaluation of 5G Mobile Cell Architectures Based on Overlay and Integrated Models](https://arxiv.org/abs/2508.05249)
*José Ruela,Ivan Cojocaru,André Coelho,Rui Campos,Manuel Ricardo*

Main category: cs.NI

TL;DR: 本文提出5G移动蜂窝（MC）的概念、架构与性能评估，旨在为5G基础设施受限或无线电条件恶劣的区域提供连接。


<details>
  <summary>Details</summary>
Motivation: 在固定5G基础设施有限或无线电条件恶劣的区域，难以提供可靠的5G无线连接。

Method: 研究了两种MC设计方法：叠加模型和基于集成接入与回传（IAB）的模型，并讨论了它们的协议栈和架构影响。使用OpenAirInterface (OAI)实现的仿真测试平台进行性能验证，考虑了不同的MC部署位置。

Result: 研究结果验证了MC概念的可行性，并表明MC的部署位置对网络性能有显著影响。

Conclusion: 本研究有助于网络运营商和服务提供商在海港、工业和公共安全等环境中，选择和部署MC架构，以实现临时覆盖扩展和容量增强。

Abstract: This paper presents the concept, architectural design, and performance
evaluation of a 5G Mobile Cell (MC) used to provide 5G wireless connectivity to
User Equipment (UE) in areas with limited fixed 5G infrastructures or subject
to adverse radio conditions. We consider two main approaches to MC design: an
overlay model, where the MC obtains backhaul connectivity from a 5G overlay
network, and an Integrated Access and Backhaul (IAB)-based model, discussing
their protocol stacks and architectural implications. In order to validate the
MC's performance, we employ an emulation-based testbed using the
OpenAirInterface (OAI) implementation, considering different MC positions. The
results validate the MC concept and demonstrate that MC positioning
significantly influences network performance. This paper has the potential to
aid network operators and service providers in selecting and deploying MC
architectures for temporary coverage extension and capacity reinforcement in
different environments, including seaports, industrial scenarios, and public
safety.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [69] [A Design for an Early Quantum Network](https://arxiv.org/abs/2508.04967)
*Yuan Li,Chen Zhang,Hao Zhang,Tao Huang,Yunjie Liu*

Main category: quant-ph

TL;DR: 针对早期量子网络，提出一种兼容现有量子中继技术的通用设计，并通过离散事件模拟评估其在资源受限和性能不佳条件下的可行性，分析了关键网络参数对保真度和完成时间的影响，并探究了中心控制器的决策。


<details>
  <summary>Details</summary>
Motivation: 随着量子信息技术的发展，量子网络对应用的关键指标（如保真度和请求完成时间）要求严格，而早期量子网络面临资源有限和性能不佳的挑战，亟需一个能最大化适应多样化量子应用需求的设计。

Method: 提出了一种兼容现有三种量子中继技术的早期量子网络设计，并详细描述了所需的网络标识符和量子请求实现过程。通过基于离散事件建模的仿真来评估设计的可行性，仿真考虑了早期网络中的各种噪声和不完美参数。此外，研究了中心控制器在路径选择之外的决策，例如截止时间选择和网络资源分配。

Result: 仿真分析了早期网络中存在的各类噪声和不完美参数对所生成纠缠态的保真度以及请求完成时间的影响。同时，研究了中心控制器在路径选择之外对截止时间选择和网络资源分配等决策的作用。

Conclusion: 本研究提出的早期量子网络设计及其可行性评估，有助于理解在资源受限和性能不佳条件下，如何优化网络以满足多样化的量子应用需求，为未来量子网络的发展提供了初步的设计框架和决策参考。

Abstract: With the rapid advancement of quantum information technology, quantum
networks have become essential for supporting diverse applications, which often
have stringent demands for key metrics such as fidelity and request completion
time. In this work, we propose a design for early-stage quantum networks that
is compatible with the three existing quantum repeater technologies. The design
aims to maximize the ability of the network to accommodate the diverse needs of
quantum applications, even under conditions of limited quantum resources and
suboptimal network performance. We have also described the required identifiers
in the quantum network and the specific process for implementing quantum
requests. To assess the feasibility of our design, we conduct simulations based
on discrete-event modeling of quantum networks. The simulations consider
various types of noise and imperfect parameters that might exist in early-stage
networks. We analyze the impact of these parameters on the fidelity of the
generated entangled states and the request completion time. Furthermore, we
investigated additional decisions that the central controller can make beyond
path selection, such as the choice of cutoff time and the allocation of network
resources to requests.

</details>
