{"id": "2505.06416", "pdf": "https://arxiv.org/pdf/2505.06416", "abs": "https://arxiv.org/abs/2505.06416", "authors": ["Elias Lumer", "Anmol Gulati", "Vamse Kumar Subbiah", "Pradeep Honaganahalli Basavaraju", "James A. Burke"], "title": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents", "categories": ["cs.CL"], "comment": "17 pages", "summary": "Recent advancements in Large Language Models (LLMs) and the introduction of\nthe Model Context Protocol (MCP) have significantly expanded LLM agents'\ncapability to interact dynamically with external tools and APIs. However,\nexisting tool selection frameworks do not integrate MCP servers, instead\nrelying heavily on error-prone manual updates to monolithic local tool\nrepositories, leading to duplication, inconsistencies, and inefficiencies.\nAdditionally, current approaches abstract tool selection before the LLM agent\nis invoked, limiting its autonomy and hindering dynamic re-querying\ncapabilities during multi-turn interactions. To address these issues, we\nintroduce ScaleMCP, a novel tool selection approach that dynamically equips LLM\nagents with a MCP tool retriever, giving agents the autonomy to add tools into\ntheir memory, as well as an auto-synchronizing tool storage system pipeline\nthrough CRUD (create, read, update, delete) operations with MCP servers as the\nsingle source of truth. We also propose a novel embedding strategy, Tool\nDocument Weighted Average (TDWA), designed to selectively emphasize critical\ncomponents of tool documents (e.g. tool name or synthetic questions) during the\nembedding process. Comprehensive evaluations conducted on a created dataset of\n5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models,\nand 5 retriever types, demonstrate substantial improvements in tool retrieval\nand agent invocation performance, emphasizing ScaleMCP's effectiveness in\nscalable, dynamic tool selection and invocation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faScaleMCP\uff0c\u4e00\u79cd\u65b0\u7684\u5de5\u5177\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7MCP\u5de5\u5177\u68c0\u7d22\u5668\u548c\u81ea\u52a8\u540c\u6b65\u5de5\u5177\u5b58\u50a8\u7cfb\u7edf\uff0c\u8d4b\u4e88LLM\u4ee3\u7406\u52a8\u6001\u9009\u62e9\u548c\u4f7f\u7528\u5de5\u5177\u7684\u81ea\u4e3b\u6743\uff0c\u5e76\u5f15\u5165TDWA\u5d4c\u5165\u7b56\u7565\u4f18\u5316\u5de5\u5177\u68c0\u7d22\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u7684\u5de5\u5177\u9009\u62e9\u6846\u67b6\u672a\u96c6\u6210\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae (MCP) \u670d\u52a1\u5668\uff0c\u4f9d\u8d56\u6613\u51fa\u9519\u7684\u624b\u52a8\u66f4\u65b0\u672c\u5730\u5de5\u5177\u5e93\uff0c\u5bfc\u81f4\u91cd\u590d\u3001\u4e0d\u4e00\u81f4\u548c\u4f4e\u6548\u3002\u6b64\u5916\uff0c\u5f53\u524d\u65b9\u6cd5\u5728\u4ee3\u7406\u8c03\u7528\u524d\u8fdb\u884c\u5de5\u5177\u9009\u62e9\uff0c\u9650\u5236\u4e86\u5176\u81ea\u4e3b\u6027\u548c\u52a8\u6001\u91cd\u65b0\u67e5\u8be2\u80fd\u529b\u3002", "method": "\u5f15\u5165ScaleMCP\u65b9\u6cd5\uff1a1. \u52a8\u6001\u4e3aLLM\u4ee3\u7406\u914d\u5907MCP\u5de5\u5177\u68c0\u7d22\u5668\uff0c\u4f7f\u5176\u80fd\u81ea\u4e3b\u5c06\u5de5\u5177\u6dfb\u52a0\u5230\u5185\u5b58\u30022. \u901a\u8fc7CRUD\u64cd\u4f5c\u4e0eMCP\u670d\u52a1\u5668\uff08\u4f5c\u4e3a\u552f\u4e00\u771f\u5b9e\u6765\u6e90\uff09\u5b9e\u73b0\u81ea\u52a8\u540c\u6b65\u7684\u5de5\u5177\u5b58\u50a8\u7cfb\u7edf\u3002\u540c\u65f6\u63d0\u51faTDWA\uff08\u5de5\u5177\u6587\u6863\u52a0\u6743\u5e73\u5747\uff09\u5d4c\u5165\u7b56\u7565\uff0c\u4ee5\u5728\u5d4c\u5165\u8fc7\u7a0b\u4e2d\u9009\u62e9\u6027\u5f3a\u8c03\u5de5\u5177\u6587\u6863\u7684\u5173\u952e\u90e8\u5206\u3002", "result": "\u5728\u5305\u542b5000\u4e2a\u91d1\u878d\u6307\u6807MCP\u670d\u52a1\u5668\u7684\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\uff0c\u901a\u8fc710\u79cdLLM\u6a21\u578b\u30015\u79cd\u5d4c\u5165\u6a21\u578b\u548c5\u79cd\u68c0\u7d22\u5668\u7c7b\u578b\u8fdb\u884c\u7684\u5168\u9762\u8bc4\u4f30\u8868\u660e\uff0cScaleMCP\u5728\u5de5\u5177\u68c0\u7d22\u548c\u4ee3\u7406\u8c03\u7528\u6027\u80fd\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "ScaleMCP\u5728\u53ef\u6269\u5c55\u3001\u52a8\u6001\u7684\u5de5\u5177\u9009\u62e9\u548c\u8c03\u7528\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\u7684\u6027\u80fd\u3002"}}
{"id": "2505.06418", "pdf": "https://arxiv.org/pdf/2505.06418", "abs": "https://arxiv.org/abs/2505.06418", "authors": ["Ming Liu", "Liwen Wang", "Wensheng Zhang"], "title": "Is your multimodal large language model a good science tutor?", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate impressive performance\non scientific reasoning tasks (e.g., ScienceQA). However, most existing\nbenchmarks focus narrowly on the accuracy of the final answer while ignoring\nother metrics. In particular, when applying MLLMs to educational contexts, the\ngoal is not only correctness but also the ability to teach. In this paper, we\npropose a framework that evaluates MLLMs as science tutors using a\ncomprehensive educational rubric and a simulated student model that judges the\nteaching performance of the tutors. Given a list of candidate MLLM science\ntutors, we use rubric-based student judgments to produce a range of tutor\nperformance scores, identifying both strong and weak tutors. Using the training\nsection of the ScienceQA dataset, we then construct a data set of pairwise\ncomparisons between the outputs of strong and weak tutors. This enables us to\napply multiple preference optimization methods to fine-tune an underperforming\ntutor model (Qwen2-VL-2B) into more effective ones. Our results also show that\nstrong problem-solving skills do not guarantee high-quality tutoring and that\nperformance optimization-guided refinements can yield more educationally\naligned tutor models. This approach opens avenues for building MLLMs that serve\nnot only as problem solvers, but as genuinely helpful educational assistants.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u548c\u6539\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b (MLLM) \u4f5c\u4e3a\u79d1\u5b66\u8f85\u5bfc\u6559\u5e08\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u6559\u5b66\u80fd\u529b\u800c\u975e\u4ec5\u4ec5\u7b54\u6848\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9 MLLM \u7684\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u53ea\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u7684\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u5176\u4ed6\u6307\u6807\uff0c\u5c24\u5176\u662f\u5728\u6559\u80b2\u573a\u666f\u4e2d\uff0c\u6a21\u578b\u7684\u6559\u5b66\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002", "method": "1. \u63d0\u51fa\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u7efc\u5408\u6559\u80b2\u8bc4\u4f30\u6807\u51c6\u548c\u6a21\u62df\u5b66\u751f\u6a21\u578b\u6765\u5224\u65ad MLLM \u4f5c\u4e3a\u79d1\u5b66\u8f85\u5bfc\u6559\u5e08\u7684\u6559\u5b66\u8868\u73b0\u30022. \u57fa\u4e8e\u5b66\u751f\u5224\u65ad\u5bf9\u5019\u9009 MLLM \u8f85\u5bfc\u6559\u5e08\u8fdb\u884c\u8bc4\u5206\uff0c\u533a\u5206\u51fa\u5f3a\u5f31\u8f85\u5bfc\u6559\u5e08\u30023. \u5229\u7528 ScienceQA \u8bad\u7ec3\u96c6\u6784\u5efa\u5f3a\u5f31\u8f85\u5bfc\u6559\u5e08\u8f93\u51fa\u7684\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u96c6\u30024. \u5e94\u7528\u591a\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5bf9\u8868\u73b0\u6b20\u4f73\u7684\u8f85\u5bfc\u6a21\u578b (Qwen2-VL-2B) \u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347\u5176\u6559\u5b66\u6548\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f3a\u5927\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u5e76\u4e0d\u7b49\u540c\u4e8e\u9ad8\u8d28\u91cf\u7684\u8f85\u5bfc\u80fd\u529b\u3002\u901a\u8fc7\u504f\u597d\u4f18\u5316\u5f15\u5bfc\u7684\u6539\u8fdb\u53ef\u4ee5\u4ea7\u751f\u66f4\u7b26\u5408\u6559\u80b2\u9700\u6c42\u7684\u8f85\u5bfc\u6a21\u578b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6b20\u4f73\u6a21\u578b\u7684\u6559\u5b66\u8868\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u4e0d\u4ec5\u80fd\u89e3\u51b3\u95ee\u9898\uff0c\u8fd8\u80fd\u6210\u4e3a\u771f\u6b63\u6709\u7528\u7684\u6559\u80b2\u52a9\u624b\u7684 MLLM \u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2505.06496", "pdf": "https://arxiv.org/pdf/2505.06496", "abs": "https://arxiv.org/abs/2505.06496", "authors": ["Erik Nijkamp", "Bo Pang", "Egor Pakhomov", "Akash Gokul", "Jin Qu", "Silvio Savarese", "Yingbo Zhou", "Caiming Xiong"], "title": "xGen-small Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce xGen-small, a family of 4B and 9B Transformer decoder models\noptimized for long-context applications. Our vertically integrated pipeline\nunites domain-balanced, frequency-aware data curation; multi-stage pre-training\nwith quality annealing and length extension to 128k tokens; and targeted\npost-training via supervised fine-tuning, preference learning, and online\nreinforcement learning. xGen-small delivers strong performance across various\ntasks, especially in math and coding domains, while excelling at long context\nbenchmarks.", "AI": {"tldr": "\u4ecb\u7ecdxGen-small\uff0c\u4e00\u4e2a\u4e3a\u957f\u4e0a\u4e0b\u6587\u5e94\u7528\u4f18\u5316\u76844B\u548c9B\u53c2\u6570Transformer\u89e3\u7801\u5668\u6a21\u578b\u7cfb\u5217\u3002", "motivation": "\u5f00\u53d1\u5728\u957f\u4e0a\u4e0b\u6587\u5e94\u7528\u4e2d\u8868\u73b0\u66f4\u4f18\u7684Transformer\u6a21\u578b\u3002", "method": "\u91c7\u7528\u5782\u76f4\u6574\u5408\u7684\u6d41\u7a0b\uff0c\u5305\u62ec\uff1a1) \u6784\u5efa4B\u548c9B\u53c2\u6570\u7684Transformer\u89e3\u7801\u5668\u6a21\u578b\uff1b2) \u9886\u57df\u5e73\u8861\u3001\u9891\u7387\u611f\u77e5\u7684\u6570\u636e\u7ba1\u7406\uff1b3) \u591a\u9636\u6bb5\u9884\u8bad\u7ec3\uff0c\u542b\u8d28\u91cf\u9000\u706b\u5e76\u5c06\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55\u81f3128k token\uff1b4) \u76ee\u6807\u5bfc\u5411\u7684\u540e\u8bad\u7ec3\uff0c\u5305\u62ec\u6709\u76d1\u7763\u5fae\u8c03\u3001\u504f\u597d\u5b66\u4e60\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002", "result": "xGen-small\u5728\u591a\u79cd\u4efb\u52a1\uff08\u5c24\u5176\u662f\u5728\u6570\u5b66\u548c\u7f16\u7801\u9886\u57df\uff09\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5e76\u5728\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "xGen-small\u662f\u4e00\u7cfb\u5217\u6210\u529f\u7684\u957f\u4e0a\u4e0b\u6587Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u5176\u7efc\u5408\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5728\u591a\u4e2a\u9886\u57df\uff08\u7279\u522b\u662f\u6570\u5b66\u548c\u7f16\u7801\uff09\u53ca\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002"}}
{"id": "2505.06538", "pdf": "https://arxiv.org/pdf/2505.06538", "abs": "https://arxiv.org/abs/2505.06538", "authors": ["Xinyue Lou", "You Li", "Jinan Xu", "Xiangyu Shi", "Chi Chen", "Kaiyu Huang"], "title": "Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model", "categories": ["cs.CL"], "comment": "Work in Progress", "summary": "The rapid development of multimodal large reasoning models (MLRMs) has\ndemonstrated broad application potential, yet their safety and reliability\nremain critical concerns that require systematic exploration. To address this\ngap, we conduct a comprehensive and systematic safety evaluation of 11 MLRMs\nacross 5 benchmarks and unveil prevalent safety degradation phenomena in most\nadvanced models. Moreover, our analysis reveals distinct safety patterns across\ndifferent benchmarks: significant safety degradation is observed across\njailbreak robustness benchmarks, whereas safety-awareness benchmarks\ndemonstrate less pronounced degradation. In particular, a long thought process\nin some scenarios even enhances safety performance. Therefore, it is a\npotential approach to addressing safety issues in MLRMs by leveraging the\nintrinsic reasoning capabilities of the model to detect unsafe intent. To\noperationalize this insight, we construct a multimodal tuning dataset that\nincorporates a safety-oriented thought process. Experimental results from\nfine-tuning existing MLRMs with this dataset effectively enhances the safety on\nboth jailbreak robustness and safety-awareness benchmarks. This study provides\na new perspective for developing safe MLRMs. Our dataset is available at\nhttps://github.com/xinyuelou/Think-in-Safety.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u5927\u63a8\u7406\u6a21\u578b (MLRMs) \u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u5b89\u5168\u9000\u5316\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u6784\u5efa\u5305\u542b\u5b89\u5168\u5bfc\u5411\u601d\u7ef4\u8fc7\u7a0b\u7684\u591a\u6a21\u6001\u5fae\u8c03\u6570\u636e\u96c6\u6765\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u63a8\u7406\u6a21\u578b (MLRMs) \u53d1\u5c55\u8fc5\u901f\u4e14\u5e94\u7528\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5176\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u6027\u63a2\u7d22\uff0c\u662f\u4e9f\u5f85\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "1. \u5bf911\u4e2aMLRMs\u57285\u4e2a\u57fa\u51c6\u4e0a\u8fdb\u884c\u5168\u9762\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u3002 2. \u53d1\u73b0\u6a21\u578b\u5185\u5728\u7684\u63a8\u7406\u80fd\u529b\uff08\u5982\u66f4\u957f\u7684\u601d\u8003\u8fc7\u7a0b\uff09\u6709\u52a9\u4e8e\u68c0\u6d4b\u4e0d\u5b89\u5168\u610f\u56fe\u3002 3. \u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u5b89\u5168\u5bfc\u5411\u601d\u7ef4\u8fc7\u7a0b\u7684\u591a\u6a21\u6001\u5fae\u8c03\u6570\u636e\u96c6\u3002 4. \u4f7f\u7528\u8be5\u6570\u636e\u96c6\u5bf9\u73b0\u6709MLRMs\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u591a\u6570\u5148\u8fdb\u7684MLRMs\u8868\u73b0\u51fa\u666e\u904d\u7684\u5b89\u5168\u9000\u5316\u73b0\u8c61\uff0c\u5c24\u5176\u5728\u8d8a\u72f1\u9c81\u68d2\u6027\u57fa\u51c6\u4e0a\u9000\u5316\u663e\u8457\uff0c\u800c\u5728\u5b89\u5168\u610f\u8bc6\u57fa\u51c6\u4e0a\u9000\u5316\u8f83\u8f7b\u3002\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\uff0c\u8f83\u957f\u7684\u601d\u8003\u8fc7\u7a0b\u751a\u81f3\u80fd\u63d0\u5347\u5b89\u5168\u6027\u80fd\u3002\u5229\u7528\u65b0\u6784\u5efa\u7684\u6570\u636e\u96c6\u5fae\u8c03MLRMs\u540e\uff0c\u5176\u5728\u8d8a\u72f1\u9c81\u68d2\u6027\u548c\u5b89\u5168\u610f\u8bc6\u57fa\u51c6\u4e0a\u7684\u5b89\u5168\u6027\u5747\u5f97\u5230\u6709\u6548\u589e\u5f3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u5b89\u5168\u7684MLRMs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u89c6\u89d2\uff0c\u5373\u5229\u7528\u6a21\u578b\u5185\u5728\u7684\u63a8\u7406\u80fd\u529b\u6765\u589e\u5f3a\u5176\u5b89\u5168\u6027\u3002\u7814\u7a76\u6784\u5efa\u7684\u5b89\u5168\u5bfc\u5411\u601d\u7ef4\u8fc7\u7a0b\u5fae\u8c03\u6570\u636e\u96c6\u8bc1\u660e\u4e86\u6b64\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2505.06375", "pdf": "https://arxiv.org/pdf/2505.06375", "abs": "https://arxiv.org/abs/2505.06375", "authors": ["Nahshon Mokua Obiri", "Kristof Van Laerhoven"], "title": "A Comprehensive Data Description for LoRaWAN Path Loss Measurements in an Indoor Office Setting: Effects of Environmental Factors", "categories": ["cs.NI", "cs.AR", "cs.LG", "eess.SP"], "comment": "This is a peer-reviewed article with the help of IEEE Access editors.\n  The relevant DOI will be availed soon", "summary": "This paper presents a comprehensive dataset of LoRaWAN technology path loss\nmeasurements collected in an indoor office environment, focusing on quantifying\nthe effects of environmental factors on signal propagation. Utilizing a network\nof six strategically placed LoRaWAN end devices (EDs) and a single indoor\ngateway (GW) at the University of Siegen, City of Siegen, Germany, we\nsystematically measured signal strength indicators such as the Received Signal\nStrength Indicator (RSSI) and the Signal-to-Noise Ratio (SNR) under various\nenvironmental conditions, including temperature, relative humidity, carbon\ndioxide (CO$_2$) concentration, barometric pressure, and particulate matter\nlevels (PM$_{2.5}$). Our empirical analysis confirms that transient phenomena\nsuch as reflections, scattering, interference, occupancy patterns (induced by\nenvironmental parameter variations), and furniture rearrangements can alter\nsignal attenuation by as much as 10.58 dB, highlighting the dynamic nature of\nindoor propagation. As an example of how this dataset can be utilized, we\ntested and evaluated a refined Log-Distance Path Loss and Shadowing Model that\nintegrates both structural obstructions (Multiple Walls) and Environmental\nParameters (LDPLSM-MW-EP). Compared to a baseline model that considers only\nMultiple Walls (LDPLSM-MW), the enhanced approach reduced the root mean square\nerror (RMSE) from 10.58 dB to 8.04 dB and increased the coefficient of\ndetermination (R$^2$) from 0.6917 to 0.8222. By capturing the extra effects of\nenvironmental conditions and occupancy dynamics, this improved model provides\nvaluable insights for optimizing power usage and prolonging device battery\nlife, enhancing network reliability in indoor Internet of Things (IoT)\ndeployments, among other applications. This dataset offers a solid foundation\nfor future research and development in indoor wireless communication.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5ba4\u5185LoRaWAN\u8def\u5f84\u635f\u8017\u6570\u636e\u96c6\uff0c\u91cf\u5316\u4e86\u73af\u5883\u56e0\u7d20\u5bf9\u4fe1\u53f7\u4f20\u64ad\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8def\u5f84\u635f\u8017\u6a21\u578b\u3002", "motivation": "\u7814\u7a76\u5ba4\u5185\u529e\u516c\u73af\u5883\u4e2d\u73af\u5883\u56e0\u7d20\u5bf9LoRaWAN\u4fe1\u53f7\u4f20\u64ad\u7684\u5177\u4f53\u5f71\u54cd\uff0c\u4ee5\u4f18\u5316\u7f51\u7edc\u90e8\u7f72\u3001\u63d0\u9ad8\u53ef\u9760\u6027\u5e76\u5ef6\u957f\u8bbe\u5907\u7535\u6c60\u5bff\u547d\u3002", "method": "\u5728\u5fb7\u56fd\u9521\u6839\u5927\u5b66\u7684\u5ba4\u5185\u529e\u516c\u73af\u5883\u4e2d\uff0c\u90e8\u7f72\u4e866\u4e2aLoRaWAN\u7ec8\u7aef\u8bbe\u5907\u548c1\u4e2a\u7f51\u5173\uff0c\u7cfb\u7edf\u5730\u6d4b\u91cf\u4e86\u4e0d\u540c\u73af\u5883\u6761\u4ef6\uff08\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u4e8c\u6c27\u5316\u78b3\u6d53\u5ea6\u3001\u6c14\u538b\u3001PM2.5\u6c34\u5e73\uff09\u4e0b\u7684\u63a5\u6536\u4fe1\u53f7\u5f3a\u5ea6\u6307\u793a\uff08RSSI\uff09\u548c\u4fe1\u566a\u6bd4\uff08SNR\uff09\u3002\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u96c6\u6210\u4e86\u7ed3\u6784\u969c\u788d\uff08\u591a\u5899\uff09\u548c\u73af\u5883\u53c2\u6570\u7684\u6539\u8fdb\u5bf9\u6570\u8ddd\u79bb\u8def\u5f84\u635f\u8017\u4e0e\u9634\u5f71\u6a21\u578b\uff08LDPLSM-MW-EP\uff09\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0c\u53cd\u5c04\u3001\u6563\u5c04\u3001\u5e72\u6270\u3001\u5360\u7528\u6a21\u5f0f\uff08\u7531\u73af\u5883\u53c2\u6570\u53d8\u5316\u5f15\u8d77\uff09\u548c\u5bb6\u5177\u91cd\u65b0\u5e03\u7f6e\u7b49\u77ac\u6001\u73b0\u8c61\u53ef\u5bfc\u81f4\u4fe1\u53f7\u8870\u51cf\u53d8\u5316\u9ad8\u8fbe10.58 dB\u3002\u4e0e\u4ec5\u8003\u8651\u591a\u5899\u7684\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u6539\u8fdb\u540e\u7684LDPLSM-MW-EP\u6a21\u578b\u5c06\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u4ece10.58 dB\u964d\u4f4e\u52308.04 dB\uff0c\u51b3\u5b9a\u7cfb\u6570\uff08R\u00b2\uff09\u4ece0.6917\u63d0\u9ad8\u52300.8222\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u6539\u8fdb\u6a21\u578b\u901a\u8fc7\u6355\u6349\u73af\u5883\u6761\u4ef6\u548c\u5360\u7528\u52a8\u6001\u7684\u989d\u5916\u5f71\u54cd\uff0c\u4e3a\u4f18\u5316\u529f\u8017\u3001\u5ef6\u957f\u8bbe\u5907\u7535\u6c60\u5bff\u547d\u548c\u589e\u5f3a\u5ba4\u5185\u7269\u8054\u7f51\uff08IoT\uff09\u90e8\u7f72\u7684\u7f51\u7edc\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u5ba4\u5185\u65e0\u7ebf\u901a\u4fe1\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2505.06356", "pdf": "https://arxiv.org/pdf/2505.06356", "abs": "https://arxiv.org/abs/2505.06356", "authors": ["Karthik Reddy Kanjula", "Surya Guthikonda", "Nahid Alam", "Shayekh Bin Islam"], "title": "Understanding and Mitigating Toxicity in Image-Text Pretraining Datasets: A Case Study on LLaVA", "categories": ["cs.CV"], "comment": "Accepted at ReGenAI CVPR2025 Workshop as Oral", "summary": "Pretraining datasets are foundational to the development of multimodal\nmodels, yet they often have inherent biases and toxic content from the\nweb-scale corpora they are sourced from. In this paper, we investigate the\nprevalence of toxicity in LLaVA image-text pretraining dataset, examining how\nharmful content manifests in different modalities. We present a comprehensive\nanalysis of common toxicity categories and propose targeted mitigation\nstrategies, resulting in the creation of a refined toxicity-mitigated dataset.\nThis dataset removes 7,531 of toxic image-text pairs in the LLaVA pre-training\ndataset. We offer guidelines for implementing robust toxicity detection\npipelines. Our findings underscore the need to actively identify and filter\ntoxic content - such as hate speech, explicit imagery, and targeted harassment\n- to build more responsible and equitable multimodal systems. The\ntoxicity-mitigated dataset is open source and is available for further\nresearch.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLaVA\u56fe\u6587\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u7684\u6bd2\u6027\u5185\u5bb9\uff0c\u5206\u6790\u4e86\u5176\u8868\u73b0\u5f62\u5f0f\uff0c\u63d0\u51fa\u4e86\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u79fb\u9664\u4e867531\u5bf9\u6709\u6bd2\u56fe\u6587\u5bf9\u7684\u4f18\u5316\u6570\u636e\u96c6\u3002", "motivation": "\u591a\u6a21\u6001\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u6765\u6e90\u4e8e\u7f51\u7edc\uff0c\u5e38\u542b\u6709\u56fa\u6709\u7684\u504f\u89c1\u548c\u6709\u6bd2\u5185\u5bb9\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u5065\u5eb7\u53d1\u5c55\u3002", "method": "\u8c03\u67e5LLaVA\u6570\u636e\u96c6\u4e2d\u6bd2\u6027\u7684\u666e\u904d\u6027\u53ca\u5176\u5728\u4e0d\u540c\u6a21\u6001\u7684\u8868\u73b0\uff0c\u5206\u6790\u5e38\u89c1\u6bd2\u6027\u7c7b\u522b\uff0c\u63d0\u51fa\u9488\u5bf9\u6027\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u521b\u5efa\u4f18\u5316\u6570\u636e\u96c6\uff0c\u540c\u65f6\u63d0\u4f9b\u6bd2\u6027\u68c0\u6d4b\u6d41\u7a0b\u6307\u5357\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u6bd2\u6027\u7f13\u89e3\u7684\u6570\u636e\u96c6\uff0c\u4eceLLaVA\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u79fb\u9664\u4e867,531\u5bf9\u6709\u6bd2\u7684\u56fe\u6587\u5bf9\u3002\u8be5\u4f18\u5316\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u4e3b\u52a8\u8bc6\u522b\u548c\u8fc7\u6ee4\u5982\u4ec7\u6068\u8a00\u8bba\u3001\u9732\u9aa8\u56fe\u50cf\u548c\u5b9a\u5411\u9a9a\u6270\u7b49\u6709\u6bd2\u5185\u5bb9\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u6784\u5efa\u66f4\u8d1f\u8d23\u4efb\u548c\u516c\u5e73\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u3002"}}
{"id": "2505.06287", "pdf": "https://arxiv.org/pdf/2505.06287", "abs": "https://arxiv.org/abs/2505.06287", "authors": ["Riccardo Sieve", "Paul Kobialka", "Laura Slaughter", "Rudolf Schlatte", "Einar Broch Johnsen", "Silvia Lizeth Tapia Tarifa"], "title": "BedreFlyt: Improving Patient Flows through Hospital Wards with Digital Twins", "categories": ["cs.AI", "cs.ET", "cs.LO", "D.2.2; D.2.4; J.3"], "comment": "In Proceedings ASQAP 2025, arXiv:2505.02873", "summary": "Digital twins are emerging as a valuable tool for short-term decision-making\nas well as for long-term strategic planning across numerous domains, including\nprocess industry, energy, space, transport, and healthcare. This paper reports\non our ongoing work on designing a digital twin to enhance resource planning,\ne.g., for the in-patient ward needs in hospitals. By leveraging executable\nformal models for system exploration, ontologies for knowledge representation\nand an SMT solver for constraint satisfiability, our approach aims to explore\nhypothetical \"what-if\" scenarios to improve strategic planning processes, as\nwell as to solve concrete, short-term decision-making tasks. Our proposed\nsolution uses the executable formal model to turn a stream of arriving\npatients, that need to be hospitalized, into a stream of optimization problems,\ne.g., capturing daily inpatient ward needs, that can be solved by SMT\ntechniques. The knowledge base, which formalizes domain knowledge, is used to\nmodel the needed configuration in the digital twin, allowing the twin to\nsupport both short-term decision-making and long-term strategic planning by\ngenerating scenarios spanning average-case as well as worst-case resource\nneeds, depending on the expected treatment of patients, as well as ranging over\nvariations in available resources, e.g., bed distribution in different rooms.\nWe illustrate our digital twin architecture by considering the problem of bed\nbay allocation in a hospital ward.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4f18\u5316\u533b\u9662\u4f4f\u9662\u75c5\u623f\u8d44\u6e90\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u53ef\u6267\u884c\u5f62\u5f0f\u5316\u6a21\u578b\u3001\u672c\u4f53\u8bba\u548cSMT\u6c42\u89e3\u5668\u6765\u652f\u6301\u77ed\u671f\u51b3\u7b56\u548c\u957f\u671f\u6218\u7565\u89c4\u5212\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5728\u591a\u4e2a\u9886\u57df\uff08\u5305\u62ec\u533b\u7597\u4fdd\u5065\uff09\u7684\u77ed\u671f\u51b3\u7b56\u548c\u957f\u671f\u6218\u7565\u89c4\u5212\u4e2d\u663e\u793a\u51fa\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u4f18\u5316\u533b\u9662\u8d44\u6e90\uff08\u5982\u4f4f\u9662\u75c5\u623f\u9700\u6c42\uff09\u65b9\u9762\u5b58\u5728\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u91c7\u7528\u53ef\u6267\u884c\u5f62\u5f0f\u5316\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u63a2\u7d22\u5e76\u5c06\u60a3\u8005\u6d41\u8f6c\u5316\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u672c\u4f53\u8fdb\u884c\u77e5\u8bc6\u8868\u793a\u548c\u914d\u7f6e\u6570\u5b57\u5b6a\u751f\uff0c\u5e76\u4f7f\u7528SMT\uff08\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\uff09\u6c42\u89e3\u5668\u89e3\u51b3\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u4ee5\u63a2\u7d22\u201c\u5047\u8bbe\u201d\u60c5\u666f\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u5b57\u5b6a\u751f\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u80fd\u5c06\u5230\u8fbe\u7684\u60a3\u8005\u6d41\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u4f18\u5316\u95ee\u9898\uff08\u5982\u6bcf\u65e5\u75c5\u623f\u9700\u6c42\uff09\uff0c\u5e76\u901a\u8fc7SMT\u6280\u672f\u89e3\u51b3\u3002\u77e5\u8bc6\u5e93\u7528\u4e8e\u5bf9\u6570\u5b57\u5b6a\u751f\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u5176\u80fd\u591f\u751f\u6210\u8986\u76d6\u5e73\u5747\u548c\u6700\u574f\u60c5\u51b5\u8d44\u6e90\u9700\u6c42\u7684\u573a\u666f\uff0c\u5e76\u8003\u8651\u53ef\u7528\u8d44\u6e90\u7684\u53d8\u5316\u3002\u901a\u8fc7\u533b\u9662\u75c5\u623f\u5e8a\u4f4d\u5206\u914d\u95ee\u9898\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u5b57\u5b6a\u751f\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6574\u5408\u53ef\u6267\u884c\u5f62\u5f0f\u5316\u6a21\u578b\u3001\u672c\u4f53\u548cSMT\u6c42\u89e3\u5668\uff0c\u4e3a\u533b\u9662\u8d44\u6e90\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u652f\u6301\u77ed\u671f\u51b3\u7b56\u548c\u901a\u8fc7\u751f\u6210\u4e0d\u540c\u573a\u666f\u6765\u6539\u8fdb\u957f\u671f\u6218\u7565\u89c4\u5212\u3002"}}
{"id": "2505.06229", "pdf": "https://arxiv.org/pdf/2505.06229", "abs": "https://arxiv.org/abs/2505.06229", "authors": ["Aaqib Ayoub Bhat", "Asif Khan", "M. Mursaleen"], "title": "Neural Network Operator-Based Fractal Approximation: Smoothness Preservation and Convergence Analysis", "categories": ["cs.LG", "cs.NA", "math.NA", "28A80, 41A05, 41A25, 41A29, 41A30, 65D05"], "comment": "18 pages", "summary": "This paper presents a new approach of constructing $\\alpha$-fractal\ninterpolation functions (FIFs) using neural network operators, integrating\nconcepts from approximation theory. Initially, we construct $\\alpha$-fractals\nutilizing neural network-based operators, providing an approach to generating\nfractal functions with interpolation properties. Based on the same foundation,\nwe have developed fractal interpolation functions that utilize only the values\nof the original function at the nodes or partition points, unlike traditional\nmethods that rely on the entire original function.\n  Further, we have constructed \\(\\alpha\\)-fractals that preserve the smoothness\nof functions under certain constraints by employing a four-layered neural\nnetwork operator, ensuring that if \\(f \\in C^{r}[a,b]\\), then the corresponding\nfractal \\(f^{\\alpha} \\in C^{r}[a,b]\\). Furthermore, we analyze the convergence\nof these $\\alpha$-fractals to the original function under suitable conditions.\nThe work uses key approximation theory tools, such as the modulus of continuity\nand interpolation operators, to develop convergence results and uniform\napproximation error bounds.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\u6784\u9020\u03b1-\u5206\u5f62\u63d2\u503c\u51fd\u6570\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u9700\u8282\u70b9\u5904\u7684\u51fd\u6570\u503c\uff0c\u80fd\u4fdd\u6301\u539f\u51fd\u6570\u7684\u5149\u6ed1\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6536\u655b\u6027\u548c\u903c\u8fd1\u8bef\u5dee\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u5206\u5f62\u63d2\u503c\u65b9\u6cd5\u9700\u8981\u4f9d\u8d56\u6574\u4e2a\u539f\u59cb\u51fd\u6570\u7684\u9650\u5236\uff0c\u5e76\u63a2\u7d22\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\u751f\u6210\u5177\u6709\u7279\u5b9a\u6027\u8d28\uff08\u5982\u5149\u6ed1\u6027\u4fdd\u6301\uff09\u7684\u5206\u5f62\u63d2\u503c\u51fd\u6570\u3002", "method": "1. \u91c7\u7528\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\uff08\u5305\u62ec\u56db\u5c42\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\uff09\u6784\u9020\u03b1-\u5206\u5f62\u63d2\u503c\u51fd\u6570\u3002 2. \u6240\u6784\u9020\u7684\u5206\u5f62\u63d2\u503c\u51fd\u6570\u4ec5\u5229\u7528\u539f\u59cb\u51fd\u6570\u5728\u8282\u70b9\u6216\u5206\u5272\u70b9\u5904\u7684\u503c\u3002 3. \u8fd0\u7528\u903c\u8fd1\u8bba\u5de5\u5177\uff08\u5982\u8fde\u7eed\u6a21\u548c\u63d2\u503c\u7b97\u5b50\uff09\u5206\u6790\u6536\u655b\u6027\u548c\u63a8\u5bfc\u4e00\u81f4\u903c\u8fd1\u8bef\u5dee\u754c\u3002", "result": "1. \u6210\u529f\u6784\u5efa\u4e86\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\u7684\u03b1-\u5206\u5f62\u63d2\u503c\u51fd\u6570\u3002 2. \u5b9e\u73b0\u4e86\u4ec5\u4f7f\u7528\u8282\u70b9\u51fd\u6570\u503c\u7684\u5206\u5f62\u63d2\u503c\u3002 3. \u5728\u7279\u5b9a\u7ea6\u675f\u4e0b\uff0c\u901a\u8fc7\u56db\u5c42\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\u6784\u5efa\u7684\u03b1-\u5206\u5f62\u80fd\u591f\u4fdd\u6301\u539f\u51fd\u6570\u7684\u5149\u6ed1\u6027\uff08\u82e5\u539f\u51fd\u6570\u4e3aCr\u7c7b\uff0c\u5219\u5206\u5f62\u51fd\u6570\u4e5f\u4e3aCr\u7c7b\uff09\u3002 4. \u5206\u6790\u5e76\u83b7\u5f97\u4e86\u8fd9\u4e9b\u03b1-\u5206\u5f62\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u5411\u539f\u59cb\u51fd\u6570\u6536\u655b\u7684\u7ed3\u679c\u4ee5\u53ca\u4e00\u81f4\u903c\u8fd1\u8bef\u5dee\u754c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7b97\u5b50\u7684\u521b\u65b0\u03b1-\u5206\u5f62\u63d2\u503c\u51fd\u6570\u6784\u9020\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u5bf9\u539f\u59cb\u51fd\u6570\u4fe1\u606f\u4f9d\u8d56\u3001\u4fdd\u6301\u5149\u6ed1\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u5e76\u63d0\u4f9b\u4e86\u6536\u655b\u6027\u5206\u6790\u548c\u8bef\u5dee\u754c\uff0c\u4e3a\u5206\u5f62\u63d2\u503c\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002"}}
{"id": "2505.06548", "pdf": "https://arxiv.org/pdf/2505.06548", "abs": "https://arxiv.org/abs/2505.06548", "authors": ["Aniruddha Roy", "Pretam Ray", "Abhilash Nandy", "Somak Aditya", "Pawan Goyal"], "title": "REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback", "categories": ["cs.CL"], "comment": "11 pages", "summary": "Instruction-based Large Language Models (LLMs) have proven effective in\nnumerous few-shot or zero-shot Natural Language Processing (NLP) tasks.\nHowever, creating human-annotated instruction data is time-consuming,\nexpensive, and often limited in quantity and task diversity. Previous research\nendeavors have attempted to address this challenge by proposing frameworks\ncapable of generating instructions in a semi-automated and task-agnostic manner\ndirectly from the model itself. Many of these efforts have relied on large\nAPI-only parameter-based models such as GPT-3.5 (175B), which are expensive,\nand subject to limits on a number of queries. This paper explores the\nperformance of three open-source small LLMs such as LLaMA 2-7B, LLama 2-13B,\nand Mistral 7B, using a semi-automated framework, thereby reducing human\nintervention, effort, and cost required to generate an instruction dataset for\nfine-tuning LLMs. Furthermore, we demonstrate that incorporating a\nReinforcement Learning (RL) based training algorithm into this LLMs-based\nframework leads to further enhancements. Our evaluation of the dataset reveals\nthat these RL-based frameworks achieve a substantial improvements in 63-66% of\nthe tasks compared to previous approaches.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLaMA 2, Mistral 7B\uff09\u7ed3\u5408\u534a\u81ea\u52a8\u5316\u6846\u67b6\u548c\u5f3a\u5316\u5b66\u4e60\u6765\u751f\u6210\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u4ee5\u964d\u4f4e\u6210\u672c\u548c\u4eba\u529b\u3002", "motivation": "\u4eba\u5de5\u6807\u6ce8\u6307\u4ee4\u6570\u636e\u6210\u672c\u9ad8\u6602\u3001\u8017\u65f6\uff0c\u4e14\u5728\u6570\u91cf\u548c\u4efb\u52a1\u591a\u6837\u6027\u4e0a\u5e38\u53d7\u9650\u5236\u3002\u4ee5\u5f80\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u534a\u81ea\u52a8\u751f\u6210\u6307\u4ee4\uff0c\u4f46\u591a\u4f9d\u8d56\u6602\u8d35\u4e14\u6709\u67e5\u8be2\u9650\u5236\u7684\u5927\u578bAPI\u6a21\u578b\uff08\u5982GPT-3.5\uff09\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u964d\u4f4e\u751f\u6210\u6307\u4ee4\u6570\u636e\u96c6\u7684\u4eba\u529b\u3001\u7cbe\u529b\u548c\u6210\u672c\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u4e09\u79cd\u5c0f\u578b\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLaMA 2-7B, LLaMA 2-13B, Mistral 7B\uff09\uff0c\u5e76\u91c7\u7528\u4e00\u4e2a\u534a\u81ea\u52a8\u5316\u6846\u67b6\u6765\u751f\u6210\u6307\u4ee4\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u5c06\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u8bad\u7ec3\u7b97\u6cd5\u6574\u5408\u5230\u8fd9\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\u4e2d\u3002", "result": "\u5bf9\u6570\u636e\u96c6\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u5148\u524d\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u4e9b\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\u572863-66%\u7684\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u534a\u81ea\u52a8\u5316\u6846\u67b6\u53ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u751f\u6210\u7528\u4e8e\u5fae\u8c03\u7684\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5e72\u9884\u3001\u7cbe\u529b\u548c\u6210\u672c\uff0c\u5e76\u5728\u591a\u6570\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u3002"}}
{"id": "2505.06678", "pdf": "https://arxiv.org/pdf/2505.06678", "abs": "https://arxiv.org/abs/2505.06678", "authors": ["Zijun Zhan", "Yaxian Dong", "Daniel Mawunyo Doe", "Yuqing Hu", "Shuai Li", "Shaohua Cao", "Lei Fan", "Zhu Han"], "title": "Distributionally Robust Contract Theory for Edge AIGC Services in Teleoperation", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Advanced AI-Generated Content (AIGC) technologies have injected new impetus\ninto teleoperation, further enhancing its security and efficiency. Edge AIGC\nnetworks have been introduced to meet the stringent low-latency requirements of\nteleoperation. However, the inherent uncertainty of AIGC service quality and\nthe need to incentivize AIGC service providers (ASPs) make the design of a\nrobust incentive mechanism essential. This design is particularly challenging\ndue to both uncertainty and information asymmetry, as teleoperators have\nlimited knowledge of the remaining resource capacities of ASPs. To this end, we\npropose a distributionally robust optimization (DRO)-based contract theory to\ndesign robust reward schemes for AIGC task offloading. Notably, our work\nextends the contract theory by integrating DRO, addressing the fundamental\nchallenge of contract design under uncertainty. In this paper, contract theory\nis employed to model the information asymmetry, while DRO is utilized to\ncapture the uncertainty in AIGC service quality. Given the inherent complexity\nof the original DRO-based contract theory problem, we reformulate it into an\nequivalent, tractable bi-level optimization problem. To efficiently solve this\nproblem, we develop a Block Coordinate Descent (BCD)-based algorithm to derive\nrobust reward schemes. Simulation results on our unity-based teleoperation\nplatform demonstrate that the proposed method improves teleoperator utility by\n2.7\\% to 10.74\\% under varying degrees of AIGC service quality shifts and\nincreases ASP utility by 60.02\\% compared to the SOTA method, i.e., Deep\nReinforcement Learning (DRL)-based contract theory. The code and data are\npublicly available at https://github.com/Zijun0819/DRO-Contract-Theory.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u5f0f\u9c81\u68d2\u4f18\u5316\uff08DRO\uff09\u7684\u5408\u7ea6\u7406\u8bba\uff0c\u4e3a\u8fdc\u7a0b\u64cd\u4f5c\u4e2d\u7684AIGC\u4efb\u52a1\u5378\u8f7d\u8bbe\u8ba1\u9c81\u68d2\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u4ee5\u5e94\u5bf9\u670d\u52a1\u8d28\u91cf\u4e0d\u786e\u5b9a\u6027\u548c\u4fe1\u606f\u4e0d\u5bf9\u79f0\u95ee\u9898\u3002", "motivation": "\u5148\u8fdb\u7684AIGC\u6280\u672f\u4e3a\u8fdc\u7a0b\u64cd\u4f5c\u6ce8\u5165\u4e86\u65b0\u52a8\u529b\uff0c\u8fb9\u7f18AIGC\u7f51\u7edc\u6ee1\u8db3\u4e86\u5176\u4f4e\u5ef6\u8fdf\u9700\u6c42\u3002\u7136\u800c\uff0cAIGC\u670d\u52a1\u8d28\u91cf\u7684\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u6fc0\u52b1AIGC\u670d\u52a1\u63d0\u4f9b\u5546\uff08ASP\uff09\u7684\u9700\u6c42\uff0c\u4f7f\u5f97\u8bbe\u8ba1\u9c81\u68d2\u7684\u6fc0\u52b1\u673a\u5236\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff08\u8fdc\u7a0b\u64cd\u4f5c\u5458\u5bf9ASP\u5269\u4f59\u8d44\u6e90\u5bb9\u91cf\u4e86\u89e3\u6709\u9650\uff09\u7684\u6311\u6218\u4e0b\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u5f0f\u9c81\u68d2\u4f18\u5316\uff08DRO\uff09\u7684\u5408\u7ea6\u7406\u8bba\u6765\u8bbe\u8ba1\u9c81\u68d2\u7684\u5956\u52b1\u65b9\u6848\u3002\u901a\u8fc7\u5c06DRO\u6574\u5408\u5230\u5408\u7ea6\u7406\u8bba\u4e2d\u6765\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5408\u7ea6\u8bbe\u8ba1\u6311\u6218\uff0c\u5176\u4e2d\u5408\u7ea6\u7406\u8bba\u7528\u4e8e\u5efa\u6a21\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff0cDRO\u7528\u4e8e\u6355\u6349AIGC\u670d\u52a1\u8d28\u91cf\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u9274\u4e8e\u539f\u59cbDRO\u5408\u7ea6\u7406\u8bba\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u4e00\u4e2a\u7b49\u6548\u4e14\u6613\u4e8e\u5904\u7406\u7684\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5757\u5750\u6807\u4e0b\u964d\uff08BCD\uff09\u7684\u7b97\u6cd5\u6765\u6c42\u89e3\u3002", "result": "\u5728\u57fa\u4e8eUnity\u7684\u8fdc\u7a0b\u64cd\u4f5c\u5e73\u53f0\u4e0a\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684AIGC\u670d\u52a1\u8d28\u91cf\u53d8\u5316\u4e0b\uff0c\u53ef\u5c06\u8fdc\u7a0b\u64cd\u4f5c\u5458\u6548\u7528\u63d0\u9ad82.7%\u81f310.74%\uff0c\u5e76\u5c06ASP\u6548\u7528\u6bd4\u73b0\u6709\u6280\u672f\uff08\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5408\u7ea6\u7406\u8bba\uff09\u63d0\u9ad860.02%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684DRO\u5408\u7ea6\u7406\u8bba\u80fd\u591f\u6709\u6548\u8bbe\u8ba1AIGC\u4efb\u52a1\u5378\u8f7d\u7684\u9c81\u68d2\u5956\u52b1\u65b9\u6848\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\uff0c\u5176\u5728\u63d0\u5347\u8fdc\u7a0b\u64cd\u4f5c\u5458\u548cASP\u6548\u7528\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2505.06370", "pdf": "https://arxiv.org/pdf/2505.06370", "abs": "https://arxiv.org/abs/2505.06370", "authors": ["Adhora Madhuri", "Nusaiba Sobir", "Tasnia Binte Mamun", "Taufiq Hasan"], "title": "LMLCC-Net: A Semi-Supervised Deep Learning Model for Lung Nodule Malignancy Prediction from CT Scans using a Novel Hounsfield Unit-Based Intensity Filtering", "categories": ["eess.IV", "cs.CV"], "comment": "9 pages, 5 figures, 6 tables", "summary": "Lung cancer is the leading cause of patient mortality in the world. Early\ndiagnosis of malignant pulmonary nodules in CT images can have a significant\nimpact on reducing disease mortality and morbidity. In this work, we propose\nLMLCC-Net, a novel deep learning framework for classifying nodules from CT scan\nimages using a 3D CNN, considering Hounsfield Unit (HU)-based intensity\nfiltering. Benign and malignant nodules have significant differences in their\nintensity profile of HU, which was not exploited in the literature. Our method\nconsiders the intensity pattern as well as the texture for the prediction of\nmalignancies. LMLCC-Net extracts features from multiple branches that each use\na separate learnable HU-based intensity filtering stage. Various combinations\nof branches and learnable ranges of filters were explored to finally produce\nthe best-performing model. In addition, we propose a semi-supervised learning\nscheme for labeling ambiguous cases and also developed a lightweight model to\nclassify the nodules. The experimental evaluations are carried out on the\nLUNA16 dataset. Our proposed method achieves a classification accuracy (ACC) of\n91.96%, a sensitivity (SEN) of 92.04%, and an area under the curve (AUC) of\n91.87%, showing improved performance compared to existing methods. The proposed\nmethod can have a significant impact in helping radiologists in the\nclassification of pulmonary nodules and improving patient care.", "AI": {"tldr": "\u63d0\u51faLMLCC-Net\uff0c\u4e00\u79cd\u5229\u75283D CNN\u548c\u4ea8\u6c0f\u5355\u4f4d(HU)\u5f3a\u5ea6\u6ee4\u6ce2\u5bf9CT\u56fe\u50cf\u4e2d\u7684\u80ba\u7ed3\u8282\u8fdb\u884c\u5206\u7c7b\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5728LUNA16\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u80ba\u764c\u662f\u5168\u7403\u60a3\u8005\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u65e9\u671f\u8bca\u65ad\u6076\u6027\u80ba\u7ed3\u8282\u5bf9\u964d\u4f4e\u6b7b\u4ea1\u7387\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u672a\u80fd\u5145\u5206\u5229\u7528\u826f\u6027\u548c\u6076\u6027\u7ed3\u8282\u5728\u4ea8\u6c0f\u5355\u4f4d\uff08HU\uff09\u5f3a\u5ea6\u5206\u5e03\u4e0a\u7684\u663e\u8457\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86LMLCC-Net\u6846\u67b6\uff1a1. \u4f7f\u75283D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff083D CNN\uff09\u30022. \u5f15\u5165\u57fa\u4e8eHU\u7684\u53ef\u5b66\u4e60\u5f3a\u5ea6\u6ee4\u6ce2\u9636\u6bb5\uff0c\u540c\u65f6\u8003\u8651\u7ed3\u8282\u7684\u5f3a\u5ea6\u6a21\u5f0f\u548c\u7eb9\u7406\u4fe1\u606f\u30023. LMLCC-Net\u4ece\u591a\u4e2a\u5206\u652f\u63d0\u53d6\u7279\u5f81\uff0c\u6bcf\u4e2a\u5206\u652f\u4f7f\u7528\u72ec\u7acb\u7684\u53ef\u5b66\u4e60HU\u5f3a\u5ea6\u6ee4\u6ce2\u30024. \u63d0\u51fa\u4e86\u7528\u4e8e\u6807\u8bb0\u6a21\u7cca\u75c5\u4f8b\u7684\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6848\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002", "result": "\u5728LUNA16\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8fbe\u5230\u4e8691.96%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff08ACC\uff09\uff0c92.04%\u7684\u7075\u654f\u5ea6\uff08SEN\uff09\u548c91.87%\u7684\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08AUC\uff09\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LMLCC-Net\u901a\u8fc7\u6709\u6548\u5229\u7528HU\u5f3a\u5ea6\u4fe1\u606f\u548c3D CNN\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u80ba\u7ed3\u8282\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u6709\u671b\u8f85\u52a9\u653e\u5c04\u79d1\u533b\u751f\u8fdb\u884c\u8bca\u65ad\uff0c\u4ece\u800c\u6539\u5584\u60a3\u8005\u62a4\u7406\u3002"}}
{"id": "2505.06328", "pdf": "https://arxiv.org/pdf/2505.06328", "abs": "https://arxiv.org/abs/2505.06328", "authors": ["Felix Ocker", "J\u00f6rg Deigm\u00f6ller", "Pavel Smirnov", "Julian Eggert"], "title": "A Grounded Memory System For Smart Personal Assistants", "categories": ["cs.AI", "H.3.3; H.3.4; I.2.1; I.2.5; I.2.7; I.2.10; J.3"], "comment": "8 pages, 5 figures, accepted for the ESWC 2025 TEXT2KG workshop", "summary": "A wide variety of agentic AI applications - ranging from cognitive assistants\nfor dementia patients to robotics - demand a robust memory system grounded in\nreality. In this paper, we propose such a memory system consisting of three\ncomponents. First, we combine Vision Language Models for image captioning and\nentity disambiguation with Large Language Models for consistent information\nextraction during perception. Second, the extracted information is represented\nin a memory consisting of a knowledge graph enhanced by vector embeddings to\nefficiently manage relational information. Third, we combine semantic search\nand graph query generation for question answering via Retrieval Augmented\nGeneration. We illustrate the system's working and potential using a real-world\nexample.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\u7684\u3001\u57fa\u4e8e\u73b0\u5b9e\u7684\u4ee3\u7406AI\u9c81\u68d2\u8bb0\u5fc6\u7cfb\u7edf\u3002", "motivation": "\u5404\u79cd\u4ee3\u7406AI\u5e94\u7528\uff08\u5982\u75f4\u5446\u75c7\u60a3\u8005\u7684\u8ba4\u77e5\u52a9\u624b\u3001\u673a\u5668\u4eba\u6280\u672f\uff09\u9700\u8981\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u57fa\u4e8e\u73b0\u5b9e\u7684\u8bb0\u5fc6\u7cfb\u7edf\u3002", "method": "\u8be5\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1. \u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u56fe\u50cf\u5b57\u5e55\u3001\u5b9e\u4f53\u6d88\u6b67\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u4e00\u81f4\u6027\u4fe1\u606f\u63d0\u53d6\uff09\u8fdb\u884c\u611f\u77e5\u30022. \u5c06\u63d0\u53d6\u7684\u4fe1\u606f\u8868\u793a\u5728\u7531\u5411\u91cf\u5d4c\u5165\u589e\u5f3a\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\uff0c\u4ee5\u6709\u6548\u7ba1\u7406\u5173\u7cfb\u4fe1\u606f\u30023. \u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7ed3\u5408\u8bed\u4e49\u641c\u7d22\u548c\u56fe\u67e5\u8be2\u751f\u6210\u8fdb\u884c\u95ee\u7b54\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u4f8b\u5b50\u5c55\u793a\u4e86\u8be5\u7cfb\u7edf\u7684\u5de5\u4f5c\u65b9\u5f0f\u548c\u6f5c\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e09\u7ec4\u4ef6\u8bb0\u5fc6\u7cfb\u7edf\u4e3a\u4ee3\u7406AI\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u3001\u57fa\u4e8e\u73b0\u5b9e\u7684\u8bb0\u5fc6\u80fd\u529b\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2505.06257", "pdf": "https://arxiv.org/pdf/2505.06257", "abs": "https://arxiv.org/abs/2505.06257", "authors": ["Ahsan Adeel"], "title": "Beyond Attention: Toward Machines with Intrinsic Higher Mental States", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Attending to what is relevant is fundamental to both the mammalian brain and\nmodern machine learning models such as Transformers. Yet, determining relevance\nremains a core challenge, traditionally offloaded to learning algorithms like\nbackpropagation. Inspired by recent cellular neurobiological evidence linking\nneocortical pyramidal cells to distinct mental states, this work shows how\nmodels (e.g., Transformers) can emulate high-level perceptual processing and\nawake thought (imagination) states to pre-select relevant information before\napplying attention. Triadic neuronal-level modulation loops among questions\n($Q$), clues (keys, $K$), and hypotheses (values, $V$) enable diverse, deep,\nparallel reasoning chains at the representation level and allow a rapid shift\nfrom initial biases to refined understanding. This leads to orders-of-magnitude\nfaster learning with significantly reduced computational demand (e.g., fewer\nheads, layers, and tokens), at an approximate cost of $\\mathcal{O}(N)$, where\n$N$ is the number of input tokens. Results span reinforcement learning (e.g.,\nCarRacing in a high-dimensional visual setup), computer vision, and natural\nlanguage question answering.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u54fa\u4e73\u52a8\u7269\u5927\u8111\u542f\u53d1\u7684\u673a\u5236\uff0c\u4f7f Transformer \u7b49\u6a21\u578b\u80fd\u5728\u5e94\u7528\u6ce8\u610f\u529b\u4e4b\u524d\u9884\u5148\u9009\u62e9\u76f8\u5173\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u786e\u5b9a\u76f8\u5173\u6027\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u901a\u5e38\u4f9d\u8d56\u4e8e\u53cd\u5411\u4f20\u64ad\u7b49\u5b66\u4e60\u7b97\u6cd5\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u8be5\u7814\u7a76\u53d7\u5230\u65b0\u76ae\u5c42\u9525\u4f53\u7ec6\u80de\u4e0e\u4e0d\u540c\u7cbe\u795e\u72b6\u6001\uff08\u5982\u9ad8\u7ea7\u611f\u77e5\u5904\u7406\u548c\u60f3\u8c61\uff09\u76f8\u5173\u7684\u795e\u7ecf\u751f\u7269\u5b66\u8bc1\u636e\u7684\u542f\u53d1\u3002", "method": "\u6a21\u578b\u901a\u8fc7\u6a21\u62df\u9ad8\u7ea7\u611f\u77e5\u5904\u7406\u548c\u6e05\u9192\u601d\u7ef4\uff08\u60f3\u8c61\uff09\u72b6\u6001\u6765\u9884\u9009\u76f8\u5173\u4fe1\u606f\u3002\u8fd9\u901a\u8fc7\u95ee\u9898\uff08Q\uff09\u3001\u7ebf\u7d22\uff08K\uff09\u548c\u5047\u8bbe\uff08V\uff09\u4e4b\u95f4\u7684\u4e09\u5143\u795e\u7ecf\u5143\u7ea7\u8c03\u5236\u73af\u8def\u5b9e\u73b0\uff0c\u4ece\u800c\u5728\u8868\u5f81\u5c42\u9762\u5f62\u6210\u591a\u6837\u5316\u3001\u6df1\u5ea6\u7684\u5e76\u884c\u63a8\u7406\u94fe\u3002", "result": "\u5b66\u4e60\u901f\u5ea6\u63d0\u5347\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u8ba1\u7b97\u9700\u6c42\u663e\u8457\u964d\u4f4e\uff08\u4f8b\u5982\uff0c\u66f4\u5c11\u7684\u6ce8\u610f\u529b\u5934\u3001\u5c42\u6570\u548c\u6807\u8bb0\uff09\uff0c\u8ba1\u7b97\u6210\u672c\u8fd1\u4f3c\u4e3a O(N)\u3002\u8be5\u65b9\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\uff08\u5982\u9ad8\u7ef4\u89c6\u89c9\u73af\u5883\u4e0b\u7684\u8d5b\u8f66\u6e38\u620f\uff09\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u7b54\u7b49\u9886\u57df\u5747\u53d6\u5f97\u4e86\u6210\u679c\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62df\u5927\u8111\u4e2d\u9884\u5148\u9009\u62e9\u76f8\u5173\u4fe1\u606f\u7684\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982 Transformer\uff09\u7684\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2505.06552", "pdf": "https://arxiv.org/pdf/2505.06552", "abs": "https://arxiv.org/abs/2505.06552", "authors": ["Doyoung Kim", "Youngjun Lee", "Joeun Kim", "Jihwan Bang", "Hwanjun Song", "Susik Yoon", "Jae-Gil Lee"], "title": "References Indeed Matter? Reference-Free Preference Optimization for Conversational Query Reformulation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Conversational query reformulation (CQR) has become indispensable for\nimproving retrieval in dialogue-based applications. However, existing\napproaches typically rely on reference passages for optimization, which are\nimpractical to acquire in real-world scenarios. To address this limitation, we\nintroduce a novel reference-free preference optimization framework DualReform\nthat generates pseudo reference passages from commonly-encountered\nconversational datasets containing only queries and responses. DualReform\nattains this goal through two key innovations: (1) response-based inference,\nwhere responses serve as proxies to infer pseudo reference passages, and (2)\nresponse refinement via the dual-role of CQR, where a CQR model refines\nresponses based on the shared objectives between response refinement and CQR.\nDespite not relying on reference passages, DualReform achieves 96.9--99.1% of\nthe retrieval accuracy attainable only with reference passages and surpasses\nthe state-of-the-art method by up to 31.6%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDualReform\u7684\u65e0\u53c2\u8003\u5bf9\u8bdd\u5f0f\u67e5\u8be2\u91cd\u6784\uff08CQR\uff09\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u4ece\u4ec5\u5305\u542b\u67e5\u8be2\u548c\u54cd\u5e94\u7684\u5bf9\u8bdd\u6570\u636e\u4e2d\u751f\u6210\u4f2a\u53c2\u8003\u6bb5\u843d\u6765\u4f18\u5316CQR\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u8bdd\u5f0f\u67e5\u8be2\u91cd\u6784\uff08CQR\uff09\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u53c2\u8003\u6bb5\u843d\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u83b7\u53d6\u8fd9\u4e9b\u53c2\u8003\u6bb5\u843d\u4e0d\u5207\u5b9e\u9645\uff0c\u8fd9\u9650\u5236\u4e86CQR\u6280\u672f\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4e86DualReform\uff0c\u4e00\u4e2a\u65e0\u9700\u53c2\u8003\u6bb5\u843d\u7684\u504f\u597d\u4f18\u5316\u6846\u67b6\u3002\u5b83\u901a\u8fc7\u4e24\u4e2a\u5173\u952e\u521b\u65b0\u5b9e\u73b0\u76ee\u6807\uff1a\uff081\uff09\u57fa\u4e8e\u54cd\u5e94\u7684\u63a8\u65ad\uff0c\u5229\u7528\u5bf9\u8bdd\u4e2d\u7684\u54cd\u5e94\u4f5c\u4e3a\u4ee3\u7406\u6765\u63a8\u65ad\u4f2a\u53c2\u8003\u6bb5\u843d\uff1b\uff082\uff09\u901a\u8fc7CQR\u7684\u53cc\u91cd\u89d2\u8272\u8fdb\u884c\u54cd\u5e94\u4f18\u5316\uff0c\u5373\u5229\u7528CQR\u6a21\u578b\u6839\u636e\u54cd\u5e94\u4f18\u5316\u548cCQR\u4e4b\u95f4\u7684\u5171\u540c\u76ee\u6807\u6765\u4f18\u5316\u54cd\u5e94\uff0c\u4ece\u800c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u4f2a\u53c2\u8003\u3002", "result": "\u5c3d\u7ba1\u4e0d\u4f9d\u8d56\u771f\u5b9e\u7684\u53c2\u8003\u6bb5\u843d\uff0cDualReform\u65b9\u6cd5\u8fbe\u5230\u4e86\u4f7f\u7528\u53c2\u8003\u6bb5\u843d\u624d\u80fd\u5b9e\u73b0\u7684\u68c0\u7d22\u51c6\u786e\u7387\u768496.9%\u81f399.1%\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u9ad8\u8fbe31.6%\u3002", "conclusion": "DualReform\u4e3aCQR\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65e0\u53c2\u8003\u4f18\u5316\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u53c2\u8003\u6bb5\u843d\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2505.06764", "pdf": "https://arxiv.org/pdf/2505.06764", "abs": "https://arxiv.org/abs/2505.06764", "authors": ["Stella N. Arinze", "Halima I. Kure", "Augustine O. Nwajana"], "title": "Improving 5G/B5G Network Performance with RFID-Enabled Resource Management Systems", "categories": ["cs.NI", "cs.SY", "eess.SY", "physics.ins-det"], "comment": "13 pages, 7 figures, 5 tables", "summary": "In the rapidly evolving landscape of 5G and B5G (beyond 5G) networks,\nefficient resource optimization is critical to addressing the escalating\ndemands for high-speed, low-latency, and energy efficient communication. This\nstudy explores the integration of Radio Frequency Identification (RFID)\ntechnology as a novel approach to enhance resource management in 5G/B5G\nnetworks. The motivation behind this research lies in overcoming persistent\nchallenges such as spectrum congestion, high latency, and inefficient load\nbalancing, which impede the performance of traditional resource allocation\nmethods. To achieve this, RFID tags were embedded in critical network\ncomponents, including user devices, base stations, and Internet of Things (IoT)\nnodes, enabling the collection of real-time data on device status, location,\nand resource utilization. RFID readers strategically placed across the network\ncontinuously captured this data, which was processed by a centralized\ncontroller using a custom-designed optimization algorithm. This algorithm\ndynamically managed key network resources, including spectrum allocation, load\nbalancing, and energy consumption, ensuring efficient operation under varying\nnetwork conditions. Simulations were conducted to evaluate the performance of\nthe RFID-based model against traditional 4G dynamic resource allocation\ntechniques. The results demonstrated substantial improvements in key\nperformance metrics.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u5c06RFID\u6280\u672f\u96c6\u6210\u52305G/B5G\u7f51\u7edc\u4e2d\u4ee5\u589e\u5f3a\u8d44\u6e90\u7ba1\u7406\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\u5728\u9891\u8c31\u62e5\u585e\u3001\u9ad8\u5ef6\u8fdf\u548c\u8d1f\u8f7d\u5747\u8861\u6548\u7387\u4f4e\u4e0b\u7b49\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u5728\u7f51\u7edc\u7ec4\u4ef6\uff08\u7528\u6237\u8bbe\u5907\u3001\u57fa\u7ad9\u3001IoT\u8282\u70b9\uff09\u4e2d\u5d4c\u5165RFID\u6807\u7b7e\u6536\u96c6\u5b9e\u65f6\u6570\u636e\uff0cRFID\u9605\u8bfb\u5668\u6355\u83b7\u6570\u636e\uff0c\u4e2d\u592e\u63a7\u5236\u5668\u4f7f\u7528\u5b9a\u5236\u4f18\u5316\u7b97\u6cd5\u52a8\u6001\u7ba1\u7406\u9891\u8c31\u3001\u8d1f\u8f7d\u5747\u8861\u548c\u80fd\u8017\u3002\u901a\u8fc7\u4eff\u771f\u4e0e\u4f20\u7edf4G\u52a8\u6001\u8d44\u6e90\u5206\u914d\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8eRFID\u7684\u6a21\u578b\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u76f8\u6bd4\u4f20\u7edf4G\u52a8\u6001\u8d44\u6e90\u5206\u914d\u6280\u672f\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u5c06RFID\u6280\u672f\u96c6\u6210\u52305G/B5G\u7f51\u7edc\u4e2d\uff0c\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u589e\u5f3a\u8d44\u6e90\u7ba1\u7406\u3001\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.06381", "pdf": "https://arxiv.org/pdf/2505.06381", "abs": "https://arxiv.org/abs/2505.06381", "authors": ["Saif Ur Rehman Khan", "Muhammad Nabeel Asim", "Sebastian Vollmer", "Andreas Dengel"], "title": "Robust & Precise Knowledge Distillation-based Novel Context-Aware Predictor for Disease Detection in Brain and Gastrointestinal", "categories": ["cs.CV"], "comment": null, "summary": "Medical disease prediction, particularly through imaging, remains a\nchallenging task due to the complexity and variability of medical data,\nincluding noise, ambiguity, and differing image quality. Recent deep learning\nmodels, including Knowledge Distillation (KD) methods, have shown promising\nresults in brain tumor image identification but still face limitations in\nhandling uncertainty and generalizing across diverse medical conditions.\nTraditional KD methods often rely on a context-unaware temperature parameter to\nsoften teacher model predictions, which does not adapt effectively to varying\nuncertainty levels present in medical images. To address this issue, we propose\na novel framework that integrates Ant Colony Optimization (ACO) for optimal\nteacher-student model selection and a novel context-aware predictor approach\nfor temperature scaling. The proposed context-aware framework adjusts the\ntemperature based on factors such as image quality, disease complexity, and\nteacher model confidence, allowing for more robust knowledge transfer.\nAdditionally, ACO efficiently selects the most appropriate teacher-student\nmodel pair from a set of pre-trained models, outperforming current optimization\nmethods by exploring a broader solution space and better handling complex,\nnon-linear relationships within the data. The proposed framework is evaluated\nusing three publicly available benchmark datasets, each corresponding to a\ndistinct medical imaging task. The results demonstrate that the proposed\nframework significantly outperforms current state-of-the-art methods, achieving\ntop accuracy rates: 98.01% on the MRI brain tumor (Kaggle) dataset, 92.81% on\nthe Figshare MRI dataset, and 96.20% on the GastroNet dataset. This enhanced\nperformance is further evidenced by the improved results, surpassing existing\nbenchmarks of 97.24% (Kaggle), 91.43% (Figshare), and 95.00% (GastroNet).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8681\u7fa4\u4f18\u5316\uff08ACO\uff09\u8fdb\u884c\u6a21\u578b\u9009\u62e9\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u6e29\u5ea6\u7f29\u653e\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u533b\u5b66\u56fe\u50cf\u75be\u75c5\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u56fe\u50cf\u75be\u75c5\u9884\u6d4b\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u65b9\u6cd5\uff0c\u5728\u5904\u7406\u533b\u5b66\u6570\u636e\u7684\u590d\u6742\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u9002\u5e94\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u8681\u7fa4\u4f18\u5316\uff08ACO\uff09\u7b97\u6cd5\u9009\u62e9\u6700\u4f18\u7684\u5e08\u751f\u6a21\u578b\u5bf9\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u9884\u6d4b\u5668\u65b9\u6cd5\uff0c\u6839\u636e\u56fe\u50cf\u8d28\u91cf\u3001\u75be\u75c5\u590d\u6742\u5ea6\u548c\u6559\u5e08\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7b49\u56e0\u7d20\u52a8\u6001\u8c03\u6574\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u6e29\u5ea6\u53c2\u6570\u3002", "result": "\u8be5\u6846\u67b6\u5728\u4e09\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff08Kaggle MRI\u8111\u80bf\u7624\u3001Figshare MRI\u3001GastroNet\uff09\u7684\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523098.01%\u300192.81%\u548c96.20%\uff0c\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u96c6\u6210\u8681\u7fa4\u4f18\u5316\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u6e29\u5ea6\u7f29\u653e\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u63d0\u5347\u533b\u5b66\u56fe\u50cf\u75be\u75c5\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2505.06438", "pdf": "https://arxiv.org/pdf/2505.06438", "abs": "https://arxiv.org/abs/2505.06438", "authors": ["Yankai Zeng", "Gopal Gupta"], "title": "Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming", "categories": ["cs.AI"], "comment": "14 pages", "summary": "As the Large-Language-Model-driven (LLM-driven) Artificial Intelligence (AI)\nbots became popular, people realized their strong potential in Task-Oriented\nDialogue (TOD). However, bots relying wholly on LLMs are unreliable in their\nknowledge, and whether they can finally produce a correct result for the task\nis not guaranteed. The collaboration among these agents also remains a\nchallenge, since the necessary information to convey is unclear, and the\ninformation transfer is by prompts -- unreliable, and malicious knowledge is\neasy to inject. With the help of logic programming tools such as Answer Set\nProgramming (ASP), conversational agents can be built safely and reliably, and\ncommunication among the agents made more efficient and secure. We proposed an\nAdministrator-Assistant Dual-Agent paradigm, where the two ASP-driven bots\nshare the same knowledge base and complete their tasks independently, while the\ninformation can be passed by a Collaborative Rule Set (CRS). The knowledge and\ninformation conveyed are encapsulated and invisible to the users, ensuring the\nsecurity of information transmission. We have constructed AutoManager, a\ndual-agent system for managing the drive-through window of a fast-food\nrestaurant such as Taco Bell in the US. In AutoManager, the assistant bot takes\nthe customer's order while the administrator bot manages the menu and food\nsupply. We evaluated our AutoManager and compared it with the real-world Taco\nBell Drive-Thru AI Order Taker, and the results show that our method is more\nreliable.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u7ba1\u7406\u5458-\u52a9\u624b\u53cc\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u7528\u4e8e\u6784\u5efa\u53ef\u9760\u7684\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u5feb\u9910\u5e97\u5f97\u6765\u901f\u7ba1\u7406\u7cfb\u7edf\u9a8c\u8bc1\u4e86\u5176\u76f8\u8f83\u4e8e\u73b0\u6709LLM\u9a71\u52a8\u673a\u5668\u4eba\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684AI\u673a\u5668\u4eba\u5728\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u4e2d\u5b58\u5728\u77e5\u8bc6\u4e0d\u53ef\u9760\u3001\u4efb\u52a1\u5b8c\u6210\u65e0\u6cd5\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u4e14\u667a\u80fd\u4f53\u95f4\u7684\u534f\u4f5c\u9762\u4e34\u4fe1\u606f\u4f20\u9012\u4e0d\u660e\u786e\u3001\u4e0d\u53ef\u9760\u4ee5\u53ca\u6613\u53d7\u6076\u610f\u77e5\u8bc6\u6ce8\u5165\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ba1\u7406\u5458-\u52a9\u624b\u53cc\u667a\u80fd\u4f53\u8303\u5f0f\u3002\u4e24\u4e2a\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u673a\u5668\u4eba\u5171\u4eab\u540c\u4e00\u77e5\u8bc6\u5e93\uff0c\u72ec\u7acb\u5b8c\u6210\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u534f\u4f5c\u89c4\u5219\u96c6\uff08CRS\uff09\u4f20\u9012\u4fe1\u606f\u3002\u77e5\u8bc6\u548c\u4fe1\u606f\u88ab\u5c01\u88c5\u4e14\u5bf9\u7528\u6237\u4e0d\u53ef\u89c1\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u3002\u6784\u5efa\u4e86\u540d\u4e3aAutoManager\u7684\u7cfb\u7edf\u7528\u4e8e\u5feb\u9910\u5e97\u5f97\u6765\u901f\u7ba1\u7406\uff0c\u5176\u4e2d\u52a9\u624b\u673a\u5668\u4eba\u8d1f\u8d23\u70b9\u9910\uff0c\u7ba1\u7406\u5458\u673a\u5668\u4eba\u8d1f\u8d23\u7ba1\u7406\u83dc\u5355\u548c\u98df\u7269\u4f9b\u5e94\u3002", "result": "\u5bf9AutoManager\u7cfb\u7edf\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u771f\u5b9e\u7684Taco Bell\u5f97\u6765\u901fAI\u70b9\u9910\u7cfb\u7edf\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff08AutoManager\uff09\u66f4\u4e3a\u53ef\u9760\u3002", "conclusion": "\u4f7f\u7528ASP\u9a71\u52a8\u7684\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u534f\u4f5c\u89c4\u5219\u96c6\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u5b89\u5168\u3001\u53ef\u9760\u7684\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u4ee3\u7406\uff0c\u5e76\u4f7f\u4ee3\u7406\u95f4\u901a\u4fe1\u66f4\u9ad8\u6548\u3001\u5b89\u5168\u3002"}}
{"id": "2505.06258", "pdf": "https://arxiv.org/pdf/2505.06258", "abs": "https://arxiv.org/abs/2505.06258", "authors": ["Zhiyu Zhu", "Jiayu Zhang", "Zhibo Jin", "Fang Chen", "Jianlong Zhou"], "title": "ABE: A Unified Framework for Robust and Faithful Attribution-Based Explainability", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Attribution algorithms are essential for enhancing the interpretability and\ntrustworthiness of deep learning models by identifying key features driving\nmodel decisions. Existing frameworks, such as InterpretDL and OmniXAI,\nintegrate multiple attribution methods but suffer from scalability limitations,\nhigh coupling, theoretical constraints, and lack of user-friendly\nimplementations, hindering neural network transparency and interoperability. To\naddress these challenges, we propose Attribution-Based Explainability (ABE), a\nunified framework that formalizes Fundamental Attribution Methods and\nintegrates state-of-the-art attribution algorithms while ensuring compliance\nwith attribution axioms. ABE enables researchers to develop novel attribution\ntechniques and enhances interpretability through four customizable modules:\nRobustness, Interpretability, Validation, and Data & Model. This framework\nprovides a scalable, extensible foundation for advancing attribution-based\nexplainability and fostering transparent AI systems. Our code is available at:\nhttps://github.com/LMBTough/ABE-XAI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aABE\u7684\u7edf\u4e00\u5f52\u56e0\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u6846\u67b6\u5728\u53ef\u6269\u5c55\u6027\u3001\u8026\u5408\u6027\u3001\u7406\u8bba\u7ea6\u675f\u548c\u7528\u6237\u53cb\u597d\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u589e\u5f3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u5f52\u56e0\u65b9\u6cd5\u96c6\u6210\u6846\u67b6\uff08\u5982InterpretDL\u548cOmniXAI\uff09\u5b58\u5728\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\u3001\u9ad8\u8026\u5408\u3001\u7406\u8bba\u7ea6\u675f\u4ee5\u53ca\u7528\u6237\u53cb\u597d\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u963b\u788d\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u900f\u660e\u5ea6\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "method": "\u63d0\u51fa\u4e86ABE\uff08Attribution-Based Explainability\uff09\u7edf\u4e00\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5f62\u5f0f\u5316\u4e86\u57fa\u672c\u5f52\u56e0\u65b9\u6cd5\uff0c\u96c6\u6210\u4e86\u6700\u5148\u8fdb\u7684\u5f52\u56e0\u7b97\u6cd5\uff0c\u786e\u4fdd\u7b26\u5408\u5f52\u56e0\u516c\u7406\uff0c\u5e76\u901a\u8fc7\u56db\u4e2a\u53ef\u5b9a\u5236\u6a21\u5757\uff08\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u9a8c\u8bc1\u3001\u6570\u636e\u4e0e\u6a21\u578b\uff09\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "ABE\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5f00\u53d1\u65b0\u7684\u5f52\u56e0\u6280\u672f\uff0c\u5e76\u4e3a\u63a8\u8fdb\u57fa\u4e8e\u5f52\u56e0\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u5ef6\u4f38\u7684\u57fa\u7840\u3002", "conclusion": "ABE\u6846\u67b6\u4e3a\u63a8\u8fdb\u57fa\u4e8e\u5f52\u56e0\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u548c\u57f9\u80b2\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u5ef6\u4f38\u7684\u57fa\u7840\u3002"}}
{"id": "2505.06569", "pdf": "https://arxiv.org/pdf/2505.06569", "abs": "https://arxiv.org/abs/2505.06569", "authors": ["Woosang Lim", "Zekun Li", "Gyuwan Kim", "Sungyoung Ji", "HyeonJung Kim", "Kyuri Choi", "Jin Hyuk Lim", "Kyungpyo Park", "William Yang Wang"], "title": "MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Long-context (LC) Large Language Models (LLMs) combined with\nRetrieval-Augmented Generation (RAG) hold strong potential for complex\nmulti-hop and large-document tasks. However, existing RAG systems often suffer\nfrom imprecise retrieval, incomplete context coverage under constrained context\nwindows, and fragmented information caused by suboptimal context construction.\nWe introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical\nretrieval framework that compresses and partitions documents into\ncoarse-to-fine granularities, then adaptively merges relevant contexts through\nchunk- and document-level expansions in real time. By starting from the\nfinest-level retrieval and progressively incorporating higher-level and broader\ncontext, MacRAG constructs effective query-specific long contexts, optimizing\nboth precision and coverage. Evaluations on the challenging LongBench\nexpansions of HotpotQA, 2WikiMultihopQA, and Musique confirm that MacRAG\nconsistently surpasses baseline RAG pipelines on single- and multi-step\ngeneration with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish\nMacRAG as an efficient, scalable solution for real-world long-context,\nmulti-hop reasoning. Our code is available at\nhttps://github.com/Leezekun/MacRAG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MacRAG \u7684\u591a\u5c3a\u5ea6\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587 RAG \u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u68c0\u7d22\u548c\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u5408\u5e76\uff0c\u4f18\u5316\u957f\u4e0a\u4e0b\u6587\u548c\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684 RAG \u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u591a\u8df3\u548c\u5927\u578b\u6587\u6863\u4efb\u52a1\u65f6\uff0c\u5e38\u9762\u4e34\u68c0\u7d22\u4e0d\u7cbe\u786e\u3001\u4e0a\u4e0b\u6587\u8986\u76d6\u4e0d\u5b8c\u6574\u4ee5\u53ca\u56e0\u6b21\u4f18\u4e0a\u4e0b\u6587\u6784\u5efa\u5bfc\u81f4\u7684\u4fe1\u606f\u788e\u7247\u5316\u95ee\u9898\u3002", "method": "\u5f15\u5165 MacRAG\uff0c\u4e00\u4e2a\u5206\u5c42\u68c0\u7d22\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u6587\u6863\u538b\u7f29\u5e76\u5212\u5206\u4e3a\u4ece\u7c97\u5230\u7ec6\u7684\u7c92\u5ea6\uff0c\u7136\u540e\u901a\u8fc7\u5b9e\u65f6\u7684\u5757\u7ea7\u548c\u6587\u6863\u7ea7\u6269\u5c55\uff0c\u4ece\u6700\u7ec6\u7c92\u5ea6\u7684\u68c0\u7d22\u5f00\u59cb\uff0c\u9010\u6b65\u5408\u5e76\u66f4\u9ad8\u7ea7\u522b\u548c\u66f4\u5e7f\u6cdb\u7684\u4e0a\u4e0b\u6587\uff0c\u81ea\u9002\u5e94\u5730\u6784\u5efa\u4e0e\u67e5\u8be2\u76f8\u5173\u7684\u6709\u6548\u957f\u4e0a\u4e0b\u6587\u3002", "result": "\u5728 HotpotQA\u30012WikiMultihopQA \u548c Musique \u7684 LongBench \u6269\u5c55\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528 Llama-3.1-8B\u3001Gemini-1.5-pro \u548c GPT-4o \u8fdb\u884c\u8bc4\u4f30\uff0cMacRAG \u5728\u5355\u6b65\u548c\u591a\u6b65\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf RAG \u6d41\u6c34\u7ebf\u3002", "conclusion": "MacRAG \u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u7684\u957f\u4e0a\u4e0b\u6587\u3001\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2505.06789", "pdf": "https://arxiv.org/pdf/2505.06789", "abs": "https://arxiv.org/abs/2505.06789", "authors": ["Fatemeh Shafiei Ardestani", "Niloy Saha", "Noura Limam", "Raouf Boutaba"], "title": "Towards NWDAF-enabled Analytics and Closed-Loop Automation in 5G Networks", "categories": ["cs.NI"], "comment": null, "summary": "The fifth generation of cellular technology (5G) delivers faster speeds,\nlower latency, and improved network service alongside support for a large\nnumber of users and a diverse range of verticals. This brings increased\ncomplexity to network control and management, making closed-loop automation\nessential. In response, the 3rd Generation Partnership Project (3GPP)\nintroduced the Network Data Analytics Function (NWDAF) to streamline network\nmonitoring by collecting, analyzing, and providing insights from network data.\nWhile prior research has focused mainly on isolated applications of machine\nlearning within NWDAF, critical aspects such as standardized data collection,\nanalytics integration in closed-loop automation, and end-to-end system\nevaluation have received limited attention. This work addresses existing gaps\nby presenting a practical implementation of NWDAF and its integration with\nleading open-source 5G core network solutions. We develop a 3GPP-compliant User\nPlane Function (UPF) event exposure service for real-time data collection and\nan ML model provisioning service integrated with MLflow to support end-to-end\nmachine learning lifecycle management. Additionally, we enhance the Session\nManagement Function (SMF) to consume NWDAF analytics and respond accordingly.\nOur evaluation demonstrates the solution's scalability, resource efficiency,\nand effectiveness in enabling closed-loop security management in 5G networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u76845G\u7f51\u7edc\u6570\u636e\u5206\u6790\u529f\u80fd(NWDAF)\u5b9e\u73b0\u65b9\u6848\uff0c\u901a\u8fc7\u4e0e\u5f00\u6e905G\u6838\u5fc3\u7f51\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u95ed\u73af\u81ea\u52a8\u5316\u7ba1\u7406\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b89\u5168\u7ba1\u7406\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "5G\u7f51\u7edc\u5e26\u6765\u4e86\u66f4\u9ad8\u7684\u590d\u6742\u6027\uff0c\u4f7f\u5f97\u95ed\u73af\u81ea\u52a8\u5316\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba13GPP\u5f15\u5165\u4e86NWDAF\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5728\u6807\u51c6\u5316\u6570\u636e\u6536\u96c6\u3001\u5206\u6790\u4e0e\u95ed\u73af\u81ea\u52a8\u5316\u7684\u96c6\u6210\u4ee5\u53ca\u7aef\u5230\u7aef\u7cfb\u7edf\u8bc4\u4f30\u65b9\u9762\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u672c\u6587\u5b9e\u73b0\u4e86\u4e00\u4e2aNWDAF\uff0c\u5e76\u5c06\u5176\u4e0e\u4e3b\u6d41\u5f00\u6e905G\u6838\u5fc3\u7f51\u89e3\u51b3\u65b9\u6848\u96c6\u6210\u3002\u5f00\u53d1\u4e86\u7b26\u54083GPP\u6807\u51c6\u7684UPF\u4e8b\u4ef6\u66b4\u9732\u670d\u52a1\u7528\u4e8e\u5b9e\u65f6\u6570\u636e\u6536\u96c6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u4e0eMLflow\u96c6\u6210\u7684ML\u6a21\u578b\u914d\u7f6e\u670d\u52a1\u6765\u652f\u6301\u7aef\u5230\u7aef\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u7ba1\u7406\u3002\u540c\u65f6\uff0c\u589e\u5f3a\u4e86SMF\u4ee5\u4f7f\u7528NWDAF\u7684\u5206\u6790\u7ed3\u679c\u5e76\u505a\u51fa\u76f8\u5e94\u54cd\u5e94\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u5728\u53ef\u6269\u5c55\u6027\u3001\u8d44\u6e90\u6548\u7387\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u5e76\u80fd\u6709\u6548\u5b9e\u73b05G\u7f51\u7edc\u4e2d\u7684\u95ed\u73af\u5b89\u5168\u7ba1\u7406\u3002", "conclusion": "\u672c\u5de5\u4f5c\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u5b9e\u7528\u7684NWDAF\u5b9e\u73b0\u53ca\u5176\u96c6\u6210\u65b9\u6848\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u73b05G\u7f51\u7edc\u95ed\u73af\u81ea\u52a8\u5316\uff08\u5c24\u5176\u662f\u5728\u5b89\u5168\u7ba1\u7406\u65b9\u9762\uff09\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2505.06389", "pdf": "https://arxiv.org/pdf/2505.06389", "abs": "https://arxiv.org/abs/2505.06389", "authors": ["Adrien Chan-Hon-Tong", "Aur\u00e9lien Plyer", "Baptiste Cadalen", "Laurent Serre"], "title": "Deep Learning-Based Robust Optical Guidance for Hypersonic Platforms", "categories": ["cs.CV"], "comment": null, "summary": "Sensor-based guidance is required for long-range platforms. To bypass the\nstructural limitation of classical registration on reference image framework,\nwe offer in this paper to encode a stack of images of the scene into a deep\nnetwork. Relying on a stack is showed to be relevant on bimodal scene (e.g.\nwhen the scene can or can not be snowy).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u56fe\u50cf\u5806\u6808\u7f16\u7801\u5230\u6df1\u5ea6\u7f51\u7edc\u4e2d\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f20\u611f\u5668\u5f15\u5bfc\uff0c\u4ee5\u514b\u670d\u7ecf\u5178\u914d\u51c6\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u53cc\u6a21\u6001\u573a\u666f\uff08\u5982\u96ea\u5929/\u975e\u96ea\u5929\uff09\u3002", "motivation": "\u8fdc\u7a0b\u5e73\u53f0\u9700\u8981\u57fa\u4e8e\u4f20\u611f\u5668\u7684\u5f15\u5bfc\uff0c\u800c\u7ecf\u5178\u7684\u57fa\u4e8e\u53c2\u8003\u56fe\u50cf\u7684\u914d\u51c6\u65b9\u6cd5\u5b58\u5728\u7ed3\u6784\u6027\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u573a\u666f\u5916\u89c2\u53d8\u5316\u5927\uff08\u5982\u53cc\u6a21\u6001\uff09\u65f6\u3002", "method": "\u5c06\u573a\u666f\u7684\u4e00\u7cfb\u5217\u56fe\u50cf\uff08\u56fe\u50cf\u5806\u6808\uff09\u7f16\u7801\u5230\u4e00\u4e2a\u6df1\u5ea6\u7f51\u7edc\u4e2d\uff0c\u7528\u4e8e\u4f20\u611f\u5668\u5f15\u5bfc\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u53cc\u6a21\u6001\u573a\u666f\uff08\u4f8b\u5982\uff0c\u573a\u666f\u4e2d\u53ef\u80fd\u5b58\u5728\u79ef\u96ea\u6216\u65e0\u79ef\u96ea\u7684\u60c5\u51b5\uff09\u4e0b\uff0c\u4f9d\u8d56\u56fe\u50cf\u5806\u6808\u8fdb\u884c\u7f16\u7801\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u901a\u8fc7\u5c06\u56fe\u50cf\u5806\u6808\u7f16\u7801\u5230\u6df1\u5ea6\u7f51\u7edc\u4e2d\uff0c\u53ef\u4ee5\u6709\u6548\u5904\u7406\u53cc\u6a21\u6001\u573a\u666f\u4e0b\u7684\u4f20\u611f\u5668\u5f15\u5bfc\u95ee\u9898\uff0c\u5e76\u514b\u670d\u4e86\u7ecf\u5178\u914d\u51c6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2505.06464", "pdf": "https://arxiv.org/pdf/2505.06464", "abs": "https://arxiv.org/abs/2505.06464", "authors": ["Tamara Paris", "AJung Moon", "Jin Guo"], "title": "Opening the Scope of Openness in AI", "categories": ["cs.AI"], "comment": "To appear in ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAccT) 2025", "summary": "The concept of openness in AI has so far been heavily inspired by the\ndefinition and community practice of open source software. This positions\nopenness in AI as having positive connotations; it introduces assumptions of\ncertain advantages, such as collaborative innovation and transparency. However,\nthe practices and benefits of open source software are not fully transferable\nto AI, which has its own challenges. Framing a notion of openness tailored to\nAI is crucial to addressing its growing societal implications, risks, and\ncapabilities. We argue that considering the fundamental scope of openness in\ndifferent disciplines will broaden discussions, introduce important\nperspectives, and reflect on what openness in AI should mean. Toward this goal,\nwe qualitatively analyze 98 concepts of openness discovered from topic\nmodeling, through which we develop a taxonomy of openness. Using this taxonomy\nas an instrument, we situate the current discussion on AI openness, identify\ngaps and highlight links with other disciplines. Our work contributes to the\nrecent efforts in framing openness in AI by reflecting principles and practices\nof openness beyond open source software and calls for a more holistic view of\nopenness in terms of actions, system properties, and ethical objectives.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8ba4\u4e3a\u5f53\u524dAI\u5f00\u653e\u6027\u53d7\u5f00\u6e90\u8f6f\u4ef6\u542f\u53d1\uff0c\u4f46\u5176\u5b9e\u8df5\u548c\u76ca\u5904\u65e0\u6cd5\u5b8c\u5168\u79fb\u690d\u5230AI\u9886\u57df\u3002\u901a\u8fc7\u5206\u6790\u8de8\u5b66\u79d1\u768498\u4e2a\u5f00\u653e\u6027\u6982\u5ff5\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u653e\u6027\u5206\u7c7b\u6cd5\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u5b9a\u4e49AI\u5f00\u653e\u6027\uff0c\u5e76\u8bc6\u522b\u5f53\u524d\u8ba8\u8bba\u4e2d\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dAI\u5f00\u653e\u6027\u7684\u6982\u5ff5\u4e3b\u8981\u501f\u9274\u81ea\u5f00\u6e90\u8f6f\u4ef6\uff0c\u4f46\u8fd9\u4e00\u5b9a\u4e49\u65e0\u6cd5\u5b8c\u5168\u9002\u5e94AI\u81ea\u8eab\u7684\u6311\u6218\u53ca\u5176\u65e5\u76ca\u589e\u957f\u7684\u793e\u4f1a\u5f71\u54cd\u3001\u98ce\u9669\u548c\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u4e3aAI\u91cf\u8eab\u5b9a\u5236\u7684\u5f00\u653e\u6027\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u4e3b\u9898\u5efa\u6a21\u53d1\u73b0\u4e8698\u4e2a\u5f00\u653e\u6027\u6982\u5ff5\uff0c\u5e76\u5bf9\u8fd9\u4e9b\u6982\u5ff5\u8fdb\u884c\u4e86\u5b9a\u6027\u5206\u6790\uff0c\u4ece\u800c\u5f00\u53d1\u51fa\u4e00\u4e2a\u5f00\u653e\u6027\u5206\u7c7b\u6cd5\u3002\u8be5\u5206\u7c7b\u6cd5\u88ab\u7528\u4f5c\u5206\u6790\u5de5\u5177\uff0c\u4ee5\u5ba1\u89c6\u5f53\u524d\u5173\u4e8eAI\u5f00\u653e\u6027\u7684\u8ba8\u8bba\uff0c\u8bc6\u522b\u73b0\u6709\u5dee\u8ddd\uff0c\u5e76\u5f3a\u8c03\u4e0e\u5176\u4ed6\u5b66\u79d1\u7684\u8054\u7cfb\u3002", "result": "\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u653e\u6027\u5206\u7c7b\u6cd5\u3002\u5229\u7528\u8be5\u5206\u7c7b\u6cd5\uff0c\u7814\u7a76\u5c06\u5f53\u524dAI\u5f00\u653e\u6027\u7684\u8ba8\u8bba\u7f6e\u4e8e\u66f4\u5e7f\u6cdb\u7684\u5b66\u79d1\u80cc\u666f\u4e0b\uff0c\u8bc6\u522b\u4e86\u73b0\u6709\u8ba8\u8bba\u4e2d\u7684\u4e0d\u8db3\u4e4b\u5904\uff0c\u5e76\u7a81\u51fa\u4e86AI\u5f00\u653e\u6027\u4e0e\u5176\u4ed6\u5b66\u79d1\u5f00\u653e\u6027\u6982\u5ff5\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u53cd\u601d\u8d85\u8d8a\u5f00\u6e90\u8f6f\u4ef6\u7684\u5f00\u653e\u6027\u539f\u5219\u548c\u5b9e\u8df5\uff0c\u4e3a\u6784\u5efaAI\u5f00\u653e\u6027\u6846\u67b6\u505a\u51fa\u4e86\u8d21\u732e\uff0c\u5e76\u547c\u5401\u4ece\u884c\u52a8\u3001\u7cfb\u7edf\u5c5e\u6027\u548c\u4f26\u7406\u76ee\u6807\u7b49\u591a\u4e2a\u7ef4\u5ea6\u5bf9AI\u5f00\u653e\u6027\u91c7\u53d6\u66f4\u5168\u9762\u7684\u89c6\u89d2\u3002"}}
{"id": "2505.06259", "pdf": "https://arxiv.org/pdf/2505.06259", "abs": "https://arxiv.org/abs/2505.06259", "authors": ["Mattia Setzu", "Riccardo Guidotti"], "title": "Fair Clustering with Clusterlets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Given their widespread usage in the real world, the fairness of clustering\nmethods has become of major interest. Theoretical results on fair clustering\nshow that fairness enjoys transitivity: given a set of small and fair clusters,\na trivial centroid-based clustering algorithm yields a fair clustering.\nUnfortunately, discovering a suitable starting clustering can be\ncomputationally expensive, rather complex or arbitrary.\n  In this paper, we propose a set of simple \\emph{clusterlet}-based fuzzy\nclustering algorithms that match single-class clusters, optimizing fair\nclustering. Matching leverages clusterlet distance, optimizing for classic\nclustering objectives, while also regularizing for fairness. Empirical results\nshow that simple matching strategies are able to achieve high fairness, and\nthat appropriate parameter tuning allows to achieve high cohesion and low\noverlap.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7c07\u5143\uff08clusterlet\uff09\u5339\u914d\u7684\u7b80\u5355\u6a21\u7cca\u805a\u7c7b\u7b97\u6cd5\uff0c\u4ee5\u63d0\u5347\u805a\u7c7b\u7ed3\u679c\u7684\u516c\u5e73\u6027\u3002", "motivation": "\u805a\u7c7b\u65b9\u6cd5\u7684\u516c\u5e73\u6027\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u7406\u8bba\u867d\u8bc1\u660e\u516c\u5e73\u6027\u5177\u6709\u4f20\u9012\u6027\uff0c\u53d1\u73b0\u5408\u9002\u7684\u521d\u59cb\u516c\u5e73\u5c0f\u7c07\u7fa4\u5374\u8ba1\u7b97\u6602\u8d35\u3001\u590d\u6742\u6216\u968f\u610f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u57fa\u4e8e\u201c\u7c07\u5143\u201d\uff08clusterlet\uff09\u7684\u7b80\u5355\u6a21\u7cca\u805a\u7c7b\u7b97\u6cd5\u3002\u8fd9\u4e9b\u7b97\u6cd5\u901a\u8fc7\u5339\u914d\u5355\u7c7b\u7c07\u5143\uff0c\u5229\u7528\u7c07\u5143\u8ddd\u79bb\u4f18\u5316\u4f20\u7edf\u805a\u7c7b\u76ee\u6807\uff0c\u540c\u65f6\u5bf9\u516c\u5e73\u6027\u8fdb\u884c\u6b63\u5219\u5316\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7b80\u5355\u7684\u5339\u914d\u7b56\u7565\u80fd\u591f\u5b9e\u73b0\u8f83\u9ad8\u7684\u516c\u5e73\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u9002\u5f53\u7684\u53c2\u6570\u8c03\u6574\u53ef\u4ee5\u83b7\u5f97\u9ad8\u5185\u805a\u5ea6\u548c\u4f4e\u91cd\u53e0\u5ea6\u7684\u805a\u7c7b\u6548\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u7c07\u5143\u7684\u7b80\u5355\u5339\u914d\u7b56\u7565\u4e3a\u5b9e\u73b0\u516c\u5e73\u805a\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u9014\u5f84\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u805a\u7c7b\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u5347\u516c\u5e73\u6027\u3002"}}
{"id": "2505.06591", "pdf": "https://arxiv.org/pdf/2505.06591", "abs": "https://arxiv.org/abs/2505.06591", "authors": ["Anna Wr\u00f3blewska", "Bartosz Grabek", "Jakub \u015awistak", "Daniel Dan"], "title": "Evaluating LLM-Generated Q&A Test: a Student-Centered Study", "categories": ["cs.CL", "cs.HC"], "comment": "accepted to AIED 2025", "summary": "This research prepares an automatic pipeline for generating reliable\nquestion-answer (Q&A) tests using AI chatbots. We automatically generated a\nGPT-4o-mini-based Q&A test for a Natural Language Processing course and\nevaluated its psychometric and perceived-quality metrics with students and\nexperts. A mixed-format IRT analysis showed that the generated items exhibit\nstrong discrimination and appropriate difficulty, while student and expert star\nratings reflect high overall quality. A uniform DIF check identified two items\nfor review. These findings demonstrate that LLM-generated assessments can match\nhuman-authored tests in psychometric performance and user satisfaction,\nillustrating a scalable approach to AI-assisted assessment development.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528AI\u804a\u5929\u673a\u5668\u4eba\uff08GPT-4o-mini\uff09\u81ea\u52a8\u751f\u6210\u95ee\u7b54\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u8bc4\u4f30\u8bc1\u660e\u5176\u5177\u6709\u826f\u597d\u7684\u5fc3\u7406\u6d4b\u91cf\u5b66\u7279\u6027\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "motivation": "\u63a2\u7d22\u4f7f\u7528AI\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u95ee\u7b54\u6d4b\u8bd5\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u671f\u5b9e\u73b0\u53ef\u6269\u5c55\u7684AI\u8f85\u52a9\u6d4b\u8bc4\u5f00\u53d1\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8eGPT-4o-mini\u7684\u81ea\u52a8\u95ee\u7b54\u6d4b\u8bd5\u751f\u6210\u6d41\u7a0b\uff0c\u5e76\u5bf9\u751f\u6210\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u8bfe\u7a0b\u6d4b\u8bd5\u8fdb\u884c\u4e86\u5fc3\u7406\u6d4b\u91cf\u5b66\uff08IRT\u5206\u6790\u3001DIF\u68c0\u67e5\uff09\u548c\u611f\u77e5\u8d28\u91cf\uff08\u5b66\u751f\u4e0e\u4e13\u5bb6\u8bc4\u5206\uff09\u8bc4\u4f30\u3002", "result": "\u751f\u6210\u7684\u6d4b\u8bd5\u9879\u76ee\u5c55\u73b0\u51fa\u826f\u597d\u7684\u533a\u5206\u5ea6\u548c\u9002\u5f53\u96be\u5ea6\u3002\u5b66\u751f\u4e0e\u4e13\u5bb6\u8bc4\u5206\u5747\u8f83\u9ad8\uff0c\u8868\u660e\u6d4b\u8bd5\u6574\u4f53\u8d28\u91cf\u9ad8\uff0c\u5728\u5fc3\u7406\u6d4b\u91cf\u6027\u80fd\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u65b9\u9762\u53ef\u4e0e\u4eba\u5de5\u6d4b\u8bd5\u5ab2\u7f8e\u3002DIF\u68c0\u67e5\u8bc6\u522b\u51fa\u5c11\u91cf\u9700\u5ba1\u67e5\u9879\u76ee\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u8bc4\u4f30\u5728\u8d28\u91cf\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u4e0a\u53ef\u4e0e\u4eba\u5de5\u6d4b\u8bd5\u76f8\u5f53\uff0c\u4e3aAI\u8f85\u52a9\u8bc4\u4f30\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2505.06899", "pdf": "https://arxiv.org/pdf/2505.06899", "abs": "https://arxiv.org/abs/2505.06899", "authors": ["Xinpeng Huang", "Wanqing Jie", "Shiwen Zhang", "Haofu Yang", "Wangjie Qiu", "Qinnan Zhang", "Huawei Huang", "Zehui Xiong", "Shaoting Tang", "Hongwei Zheng", "Zhiming Zheng"], "title": "ContribChain: A Stress-Balanced Blockchain Sharding Protocol with Node Contribution Awareness", "categories": ["cs.NI"], "comment": "Accepted by INFOCOM 2025", "summary": "Existing blockchain sharding protocols have focused on eliminating imbalanced\nworkload distributions. However, even with workload balance, disparities in\nprocessing capabilities can lead to differential stress among shards, resulting\nin transaction backlogs in certain shards. Therefore, achieving stress balance\namong shards in the dynamic and heterogeneous environment presents a\nsignificant challenge of blockchain sharding. In this paper, we propose\nContribChain, a blockchain sharding protocol that can automatically be aware of\nnode contributions to achieve stress balance. We calculate node contribution\nvalues based on the historical behavior to evaluate the performance and\nsecurity of nodes. Furthermore, we propose node allocation algorithm NACV and\naccount allocation algorithm P-Louvain, which both match shard performance with\nworkload to achieve stress balance. Finally, we conduct extensive experiments\nto compare our work with state-of-the-art baselines based on real Ethereum\ntransactions. The evaluation results show that P-Louvain reduces allocation\nexecution time by 86% and the cross-shard transaction ratio by 7.5%. Meanwhile,\nContribChain improves throughput by 35.8% and reduces the cross-shard\ntransaction ratio by 16%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aContribChain\u7684\u533a\u5757\u94fe\u5206\u7247\u534f\u8bae\uff0c\u901a\u8fc7\u8bc4\u4f30\u8282\u70b9\u8d21\u732e\u5e76\u91c7\u7528\u65b0\u7684\u5206\u914d\u7b97\u6cd5\uff08NACV\u548cP-Louvain\uff09\u6765\u5b9e\u73b0\u5206\u7247\u95f4\u7684\u538b\u529b\u5e73\u8861\uff0c\u4ece\u800c\u63d0\u9ad8\u7cfb\u7edf\u541e\u5410\u91cf\u5e76\u51cf\u5c11\u8de8\u5206\u7247\u4ea4\u6613\u3002", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u5206\u7247\u534f\u8bae\u4e3b\u8981\u5173\u6ce8\u5de5\u4f5c\u8d1f\u8f7d\u5747\u8861\uff0c\u4f46\u5ffd\u7565\u4e86\u8282\u70b9\u5904\u7406\u80fd\u529b\u7684\u5dee\u5f02\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5206\u7247\u95f4\u538b\u529b\u4e0d\u5747\u548c\u4ea4\u6613\u79ef\u538b\u3002\u56e0\u6b64\uff0c\u5728\u52a8\u6001\u5f02\u6784\u73af\u5883\u4e2d\u5b9e\u73b0\u5206\u7247\u95f4\u7684\u538b\u529b\u5e73\u8861\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "1. \u63d0\u51faContribChain\u534f\u8bae\uff0c\u6839\u636e\u8282\u70b9\u5386\u53f2\u884c\u4e3a\u8ba1\u7b97\u8d21\u732e\u503c\u4ee5\u8bc4\u4f30\u5176\u6027\u80fd\u548c\u5b89\u5168\u6027\u30022. \u63d0\u51fa\u8282\u70b9\u5206\u914d\u7b97\u6cd5NACV\u548c\u8d26\u6237\u5206\u914d\u7b97\u6cd5P-Louvain\uff0c\u901a\u8fc7\u5339\u914d\u5206\u7247\u6027\u80fd\u4e0e\u5de5\u4f5c\u8d1f\u8f7d\u6765\u5b9e\u73b0\u538b\u529b\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cP-Louvain\u7b97\u6cd5\u5c06\u5206\u914d\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u4e8686%\uff0c\u8de8\u5206\u7247\u4ea4\u6613\u6bd4\u4f8b\u964d\u4f4e\u4e867.5%\u3002ContribChain\u534f\u8bae\u5c06\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u9ad8\u4e8635.8%\uff0c\u8de8\u5206\u7247\u4ea4\u6613\u6bd4\u4f8b\u964d\u4f4e\u4e8616%\u3002", "conclusion": "ContribChain\u901a\u8fc7\u611f\u77e5\u8282\u70b9\u8d21\u732e\u5e76\u91c7\u7528\u4f18\u5316\u7684\u5206\u914d\u7b56\u7565\uff0c\u6709\u6548\u5730\u5b9e\u73b0\u4e86\u5206\u7247\u95f4\u7684\u538b\u529b\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533a\u5757\u94fe\u5206\u7247\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2505.06393", "pdf": "https://arxiv.org/pdf/2505.06393", "abs": "https://arxiv.org/abs/2505.06393", "authors": ["Valfride Nascimento", "Gabriel E. Lima", "Rafael O. Ribeiro", "William Robson Schwartz", "Rayson Laroca", "David Menotti"], "title": "Toward Advancing License Plate Super-Resolution in Real-World Scenarios: A Dataset and Benchmark", "categories": ["cs.CV"], "comment": "Accepted for publication in the Journal of the Brazilian Computer\n  Society", "summary": "Recent advancements in super-resolution for License Plate Recognition (LPR)\nhave sought to address challenges posed by low-resolution (LR) and degraded\nimages in surveillance, traffic monitoring, and forensic applications. However,\nexisting studies have relied on private datasets and simplistic degradation\nmodels. To address this gap, we introduce UFPR-SR-Plates, a novel dataset\ncontaining 10,000 tracks with 100,000 paired low and high-resolution license\nplate images captured under real-world conditions. We establish a benchmark\nusing multiple sequential LR and high-resolution (HR) images per vehicle --\nfive of each -- and two state-of-the-art models for super-resolution of license\nplates. We also investigate three fusion strategies to evaluate how combining\npredictions from a leading Optical Character Recognition (OCR) model for\nmultiple super-resolved license plates enhances overall performance. Our\nfindings demonstrate that super-resolution significantly boosts LPR\nperformance, with further improvements observed when applying majority\nvote-based fusion techniques. Specifically, the Layout-Aware and\nCharacter-Driven Network (LCDNet) model combined with the Majority Vote by\nCharacter Position (MVCP) strategy led to the highest recognition rates,\nincreasing from 1.7% with low-resolution images to 31.1% with super-resolution,\nand up to 44.7% when combining OCR outputs from five super-resolved images.\nThese findings underscore the critical role of super-resolution and temporal\ninformation in enhancing LPR accuracy under real-world, adverse conditions. The\nproposed dataset is publicly available to support further research and can be\naccessed at: https://valfride.github.io/nascimento2024toward/", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u771f\u5b9e\u573a\u666f\u8f66\u724c\u8d85\u5206\u8fa8\u7387\u6570\u636e\u96c6UFPR-SR-Plates\uff0c\u5e76\u8bc1\u660e\u8d85\u5206\u8fa8\u7387\u6280\u672f\u7ed3\u5408\u591a\u5e27OCR\u7ed3\u679c\u878d\u5408\u80fd\u663e\u8457\u63d0\u5347\u6076\u52a3\u6761\u4ef6\u4e0b\u4f4e\u5206\u8fa8\u7387\u8f66\u724c\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u8f66\u724c\u8d85\u5206\u8fa8\u7387\u7814\u7a76\u4f9d\u8d56\u79c1\u6709\u6570\u636e\u96c6\u548c\u7b80\u5316\u7684\u56fe\u50cf\u9000\u5316\u6a21\u578b\uff0c\u96be\u4ee5\u89e3\u51b3\u771f\u5b9e\u4e16\u754c\u76d1\u63a7\u3001\u4ea4\u901a\u76d1\u6d4b\u548c\u53d6\u8bc1\u5e94\u7528\u4e2d\u4f4e\u5206\u8fa8\u7387\uff08LR\uff09\u548c\u9000\u5316\u56fe\u50cf\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "1. \u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b10\u4e07\u5bf9\u771f\u5b9e\u573a\u666f\u4e0b\u4f4e\u5206\u8fa8\u7387\u548c\u9ad8\u5206\u8fa8\u7387\u8f66\u724c\u56fe\u50cf\u7684\u65b0\u6570\u636e\u96c6UFPR-SR-Plates\u3002\n2. \u4f7f\u7528\u6bcf\u8f86\u8f66\u591a\u4e2a\u8fde\u7eed\u7684\u4f4e\u5206\u8fa8\u7387\u548c\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\uff08\u5404\u4e94\u4e2a\uff09\u4ee5\u53ca\u4e24\u79cd\u5148\u8fdb\u7684\u8f66\u724c\u8d85\u5206\u8fa8\u7387\u6a21\u578b\u5efa\u7acb\u57fa\u51c6\u3002\n3. \u7814\u7a76\u4e86\u4e09\u79cd\u878d\u5408\u7b56\u7565\uff0c\u4ee5\u8bc4\u4f30\u7ed3\u5408\u6765\u81ea\u9886\u5148OCR\u6a21\u578b\u5bf9\u591a\u4e2a\u8d85\u5206\u8fa8\u7387\u8f66\u724c\u7684\u9884\u6d4b\u5982\u4f55\u589e\u5f3a\u6574\u4f53\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8d85\u5206\u8fa8\u7387\u80fd\u663e\u8457\u63d0\u5347\u8f66\u724c\u8bc6\u522b\uff08LPR\uff09\u6027\u80fd\uff0c\u5e94\u7528\u57fa\u4e8e\u591a\u6570\u6295\u7968\u7684\u878d\u5408\u6280\u672f\u540e\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002\u5177\u4f53\u800c\u8a00\uff0cLayout-Aware and Character-Driven Network (LCDNet) \u6a21\u578b\u7ed3\u5408\u5b57\u7b26\u4f4d\u7f6e\u591a\u6570\u6295\u7968 (MVCP) \u7b56\u7565\u53d6\u5f97\u4e86\u6700\u9ad8\u7684\u8bc6\u522b\u7387\uff0c\u4ece\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\u76841.7%\u63d0\u5347\u81f3\u8d85\u5206\u8fa8\u7387\u56fe\u50cf\u768431.1%\uff0c\u5728\u7ed3\u5408\u4e94\u4e2a\u8d85\u5206\u8fa8\u7387\u56fe\u50cf\u7684OCR\u8f93\u51fa\u540e\uff0c\u8bc6\u522b\u7387\u9ad8\u8fbe44.7%\u3002", "conclusion": "\u8d85\u5206\u8fa8\u7387\u6280\u672f\u548c\u65f6\u95f4\u4fe1\u606f\uff08\u591a\u5e27\u878d\u5408\uff09\u5bf9\u4e8e\u5728\u771f\u5b9e\u4e16\u754c\u6076\u52a3\u6761\u4ef6\u4e0b\u63d0\u9ad8\u8f66\u724c\u8bc6\u522b\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002\u63d0\u51fa\u7684\u6570\u636e\u96c6\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
